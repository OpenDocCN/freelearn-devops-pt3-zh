<html><head></head><body>
		<div id="_idContainer052">
			<h1 id="_idParaDest-205" class="chapter-number"><a id="_idTextAnchor272"/>11</h1>
			<h1 id="_idParaDest-206"><a id="_idTextAnchor273"/>Classification and Release Management</h1>
			<p>The focus of this chapter will be on how Puppet deploys code and classifies this code to servers. Environments will be examined first, showing how this creates isolated groups of servers with particular versions of modules. We will discuss how this can provide both static and temporary environments. We will show how modern Puppet uses directory-based environments to have environment code in a specific location that <strong class="bold">Puppet Server </strong>can automatically discover. The methods a primary server can use to classify nodes will be discussed, at the most basic level using node definitions in the <strong class="source-inline">site.pp</strong> main manifest file or a collection of manifests, using Hiera lookups within these node definitions or with an <strong class="bold">External Node Classifier </strong>(<strong class="bold">ENC</strong>) script<a id="_idIndexMarker762"/> run by the primary server. The implementation of the <strong class="bold">classification service </strong>for Puppet Enterprise will be discussed, showing how it builds on top of these solutions using its own ENC script and the additional feature of node groups in the <span class="No-Break">web console.</span></p>
			<p>The Puppet agent run will be looked at in detail to show the steps involved and how data is loaded, cached, and refreshed when a catalog <span class="No-Break">is compiled.</span></p>
			<p>It will then be shown how to use the control repo structure with Puppetfiles to manage modules to deploy code into environments using <strong class="source-inline">r10k </strong>or <strong class="source-inline">g10k</strong>, with a discussion of various methods to synchronize code depending on the configuration of the local infrastructure. The PE-specific implementation, <strong class="bold">Code Manager</strong>, built on <strong class="source-inline">r10k</strong>, will then <span class="No-Break">be discussed.</span></p>
			<p>Having reviewed the technical structures for classification and release management, focus will then be put on the challenges and limitations of using this with regulated processes and <span class="No-Break">multiple teams.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li><span class="No-Break">Puppet environments</span></li>
				<li>Understanding <span class="No-Break">node classification</span></li>
				<li><span class="No-Break">Puppet runs</span></li>
				<li>Managing and deploying <span class="No-Break">Puppet code</span></li>
				<li>Lab—classifying and <span class="No-Break">deploying code</span></li>
			</ul>
			<h1 id="_idParaDest-207"><a id="_idTextAnchor274"/>Technical requirements</h1>
			<p>Clone the control repo from <a href="https://github.com/puppetlabs/control-repo">https://github.com/puppetlabs/control-repo</a> to your <strong class="source-inline">controlrepo-chapter11 </strong>GitHub account and update the following files in <span class="No-Break">this repo:</span></p>
			<ul>
				<li><strong class="source-inline">Puppetfile</strong> <span class="No-Break">with </span><a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/Puppetfile"><span class="No-Break">https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/Puppetfile</span></a><span class="No-Break">.</span></li>
				<li>Build a standard cluster with three clients by downloading the <strong class="source-inline">params.json </strong>file from <a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/params.json">https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/params.json</a><a href="https://github.com/PacktPublishing/Puppet-7-for-DevOps-Engineering/blob/main/ch11/params.json "/>and updating it with the location of your control repo and your SSH key for the control repo. Then, run the following command from your <span class="No-Break"><strong class="source-inline">pecdm </strong></span><span class="No-Break">directory:</span><pre class="source-code">
<strong class="bold">bolt --verbose plan run pecdm::provision </strong><strong class="bold">--params</strong><strong class="bold"> @params.json</strong></pre></li>
			</ul>
			<h1 id="_idParaDest-208"><a id="_idTextAnchor275"/>Puppet environments</h1>
			<p>Puppet environments are a <a id="_idIndexMarker763"/>way to define specific versions of modules, manifests, and data to be used for groups of servers. Unfortunately, <em class="italic">environment </em>is a general technology term used for other purposes in organizations, and can easily be confused. The best advice would be to always say <strong class="bold">Puppet code environment </strong>if used in discussions outside of a purely Puppet context. This prevents a Puppet environment being associated directly with <span class="No-Break">anything else.</span></p>
			<p>Modern Puppet environments are dynamic directory-based, which means the  Puppet server—or, in the case of <strong class="source-inline">puppet apply</strong>, the client—will look for the assigned environment to exist within a directory. Several variables set the location of related directories, including the <strong class="source-inline">environments </strong>directory itself, and we strongly recommend leaving all these settings at default to avoid confusion and issues. We will now look at the levels of code directories and paths within <span class="No-Break">an environment.</span></p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor276"/>Environment directories and paths</h2>
			<p>The first level is the code <a id="_idIndexMarker764"/>and data directory set by the <strong class="source-inline">codedir </strong>variable in <strong class="source-inline">puppet.conf</strong>, defaulting to <strong class="source-inline">/etc/puppetlabs/code </strong>for Unix and <strong class="source-inline">%PROGRAMDATA%\PuppetLabs\code </strong>for Windows (this is normally <strong class="source-inline">C:\ProgramData\PuppetLabs\code</strong>). Puppet Server does not use the <strong class="source-inline">codedir </strong>setting in <strong class="source-inline">puppet.conf </strong>and uses <strong class="source-inline">jruby-puppet.master-code-dir </strong>in <strong class="source-inline">puppetserver.conf</strong>, so both would need to be set <span class="No-Break">if changed.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Prior to <strong class="source-inline">Puppet 3.3</strong>, environments were declared in the <strong class="source-inline">puppet.conf </strong>file and each environment had to be declared in a section with <strong class="source-inline">modulepath </strong>and <strong class="source-inline">manifests </strong>variables set. This is still technically possible in Puppet today if <strong class="source-inline">codedir </strong>was not set but there is no reason to implement <span class="No-Break">this approach.</span></p>
			<p>The code and data directory contains two directories. First, there is a module directory to provide global user modules included in the default <strong class="source-inline">basemodulepath </strong>variable in <strong class="source-inline">puppet.conf</strong>. This <strong class="source-inline">basemodulepath </strong>variable by default contains <strong class="source-inline">$codedir/modules:/opt/puppetlabs/puppet/modules </strong>on Unix and <strong class="source-inline">$codedir\modules </strong>on Windows. The extra directory for Unix is used by the PE Server installation to place modules used to configure PE. These modules are prefixed with <strong class="source-inline">pe </strong>to avoid confusion with any modules that are already in use <span class="No-Break">in environments.</span></p>
			<p>The second directory is an environment directory; by the default setting of <strong class="source-inline">environmentpath </strong>in <strong class="source-inline">puppet.conf</strong>, this is <strong class="source-inline">$codedir/environments </strong>and is where environments will <span class="No-Break">be viewed.</span></p>
			<p class="callout-heading">NOTE</p>
			<p class="callout">The <strong class="source-inline">codedir </strong>directory is used to contain global Hiera data and configuration and, by default, <strong class="source-inline">hiera_config </strong>settings. If it finds a <strong class="source-inline">$codedir/hiera.yaml </strong>file, it will override the default <strong class="source-inline">$confdir/hiera.yaml </strong>file, which is now standard, as discussed in <a href="B18492_09.xhtml#_idTextAnchor233"><span class="No-Break"><em class="italic">Chapter 9</em></span></a><span class="No-Break">.</span></p>
			<p>Within the <strong class="source-inline">environments </strong>directory, each<a id="_idIndexMarker765"/> environment to be created will have a directory that can have a name containing lowercase letters, numbers, and underscores. Each environment directory can contain <span class="No-Break">the following:</span></p>
			<ul>
				<li>Puppet modules in directories specified <span class="No-Break">by </span><span class="No-Break"><strong class="source-inline">$modulepath</strong></span></li>
				<li>Hiera data configured in a <strong class="source-inline">hiera.yaml</strong> file in <span class="No-Break">the directory</span></li>
				<li>Classification data in a manifest or set of manifests in a directory specified <span class="No-Break">by </span><span class="No-Break"><strong class="source-inline">$manifest</strong></span></li>
				<li>Environment configuration data in an <strong class="source-inline">environment.conf </strong>file in <span class="No-Break">the directory</span></li>
			</ul>
			<p>Having reviewed the directories and paths of environments, we will now look at the environment configuration files in <span class="No-Break">more detail.</span></p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor277"/>Environment configuration files</h2>
			<p>Environment configuration data can<a id="_idIndexMarker766"/> be set in an <strong class="source-inline">environment.conf </strong>file within the <strong class="source-inline">environment </strong>directory; this file has an INI-style format like <strong class="source-inline">puppet.conf </strong>but with <span class="No-Break">no sections.</span></p>
			<p>By default, if the <strong class="source-inline">modulepath </strong>environment variable is not set in <strong class="source-inline">environment.conf</strong>, it will be set <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">$environmentpath/$environment/modules:$basemodulepath</strong></span><span class="No-Break">.</span></p>
			<p>So, in Unix-based systems, by default this will be <span class="No-Break">the following:</span></p>
			<pre class="source-code">
<strong class="bold">/etc/puppetlabs/code/environments/$environment/modules: /opt/puppetlabs/puppet/modules</strong></pre>
			<p>In Windows systems, it will <span class="No-Break">be this:</span></p>
			<pre class="source-code">
<strong class="bold">C:/ProgramData/PuppetLabs/code/environments/production/modules;C:/ProgramData/PuppetLabs/code/modules</strong></pre>
			<p>Remember to use a semicolon (<strong class="source-inline">;</strong>) to separate Windows directories in a list and a colon (<strong class="source-inline">:</strong>) for <span class="No-Break">Unix systems.</span></p>
			<p>In the <em class="italic">Managing and deploying Puppet code </em>section, we will discuss how the modules are deployed into this <a id="_idIndexMarker767"/>directory and how to list the contents of each directory <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">modulepath</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Never set a <strong class="source-inline">modulepath </strong>variable to read from another environment directory. In the <em class="italic">Puppet runs </em>section, we will discuss the potentially inconsistent effects of environment data being cached <span class="No-Break">and refreshed.</span></p>
			<p>The <strong class="source-inline">manifest </strong>variable can be a single manifest file or a directory containing multiple manifests that will be read in alphabetical order. Puppet will see this variable as containing a directory if the path ends with a forward slash (<strong class="source-inline">/</strong>) or a full stop (<strong class="source-inline">.</strong>) and will recognize if it is a directory. If there is no setting in <strong class="source-inline">environment.conf</strong>, the default will be a directory at <strong class="source-inline">$environmentpath/$environment/manifests</strong>, which is <strong class="source-inline">/etc/puppetlabs/code/environments/$environment/manifests </strong>for Unix-based systems and <strong class="source-inline">C:/ProgramData/PuppetLabs/code/environments/$environment/manifests </strong>for Windows-based systems. The directory environment will never use the global <strong class="source-inline">manifest </strong>setting from <strong class="source-inline">puppet.conf</strong>. In the next section, we will go into further detail about how node definitions and Hiera lookups can be used to classify servers in this environment with <span class="No-Break">these manifests.</span></p>
			<p>The <strong class="source-inline">environment_timeout </strong>variable states how long Puppet Server will cache a particular environment, overriding what is set. Puppet advises not to set this in <strong class="source-inline">environment.conf</strong>, only using the global version in <strong class="source-inline">puppet.conf</strong>, and to only use <strong class="source-inline">0 </strong>or <strong class="source-inline">unlimited</strong>. The role of caching will be discussed further in the <em class="italic">Puppet runs </em>section of <span class="No-Break">this chapter.</span></p>
			<p>The <strong class="source-inline">config_version </strong>variable can set a script to run once the catalog has compiled and return the output as part of the logging. If not set by default, a script will return the time the catalog was compiled in the Unix epoch format (the number of seconds that have elapsed since January 1, 1970 midnight UTC/GMT). For the default epoch script, the output will appear <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
<strong class="bold">Info: Applying configuration version '1663239677'</strong></pre>
			<p>A more useful example will be shown when using Git-based deployment solutions in the <em class="italic">Managing and deploying Puppet </em><span class="No-Break"><em class="italic">code </em></span><span class="No-Break">section.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout"><strong class="source-inline">environment.conf </strong>and the <strong class="source-inline">config_version </strong>script can use the <strong class="source-inline">basemodulepath</strong>, <strong class="source-inline">environment</strong>, and <strong class="source-inline">codedir </strong><span class="No-Break">global variables.</span></p>
			<p>Now that we have reviewed<a id="_idIndexMarker768"/> the configuration of environments, it is useful to understand how we can validate the configuration and the types of <span class="No-Break">environments deployed.</span></p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor278"/>Environment validation and deployment</h2>
			<p>The settings discussed in <strong class="source-inline">puppet.conf </strong>and <strong class="source-inline">environment.conf </strong>can be checked by using the <strong class="source-inline">puppet config print </strong>command, deploying the <strong class="source-inline">--environment </strong>flag to look at a particular environment<a id="_idIndexMarker769"/> and <strong class="source-inline">--section </strong>for a particular section in <strong class="source-inline">puppet.conf</strong>. For example, to check the <strong class="source-inline">codedir </strong>variable in <strong class="source-inline">puppet.conf </strong>and the <strong class="source-inline">modulepath </strong>variable in the production environment, the following commands could <span class="No-Break">be run:</span></p>
			<pre class="source-code">
<strong class="bold">puppet config print codedir</strong>
<strong class="bold">puppet config print --environment production modulepath</strong></pre>
			<p>By default, Puppet Server will create a production environment but a Puppet client running <strong class="source-inline">apply </strong>will not. For both scenarios, production is the default environment Puppet will run from. In the next section of this chapter, we will show how servers get classified into <span class="No-Break">other environments.</span></p>
			<p>There are three environmental strategies: permanent, temporary, and organizational silos. Permanent environments are long-lived and the environment naming typically matches the server’s use, such as if the server is a product or development server. Temporary environments are those that can be used in situations such as testing changes before they are promoted, while organizational silo environments reflect divided infrastructure where different teams such as Windows and Linux teams own different servers and have different environments. These strategies can be mixed together as required to meet your <span class="No-Break">organization’s approach.</span></p>
			<p>Now that we’ve learned about Puppet code environments, we will see how to classify clients based on their use in an environment and set of modules from <span class="No-Break">that environment.</span></p>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor279"/>Understanding node classification</h1>
			<p>Classification of a node involves finding which environment a node should use, which classes should be applied to <a id="_idIndexMarker770"/>a node, and which parameters should be applied to a node. The ideal scenario is to have a single role class applied to a host, but the business logic can be more complicated. This applies to both agent runs to the Puppet Server and <strong class="source-inline">puppet </strong><span class="No-Break"><strong class="source-inline">apply </strong></span><span class="No-Break">runs.</span></p>
			<p>Having defined what node classification is, we will now look at the methods that can be used for classification, taking node definitions first as the <span class="No-Break">simplest approach.</span></p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor280"/>Node definitions</h2>
			<p>The most basic method of node<a id="_idIndexMarker771"/> classification is using a <strong class="bold">node definition</strong>, which is a section of Puppet code allowing matching against node names to assign classification information and top-level variables to servers but not the environment. If only using node definitions, the client’s requested environment based on <strong class="source-inline">puppet.conf </strong>will be used. The <a id="_idIndexMarker772"/>node name will be the same as the <strong class="source-inline">certname </strong>setting from <strong class="source-inline">puppet.conf</strong>, which by default is the node’s <strong class="bold">fully qualified domain </strong><span class="No-Break"><strong class="bold">name </strong></span><span class="No-Break">(</span><span class="No-Break"><strong class="bold">FQDN</strong></span><span class="No-Break">).</span></p>
			<p>The syntax of a node definition is set <span class="No-Break">out here:</span></p>
			<ul>
				<li>The <span class="No-Break"><strong class="source-inline">node </strong></span><span class="No-Break">keyword</span></li>
				<li>A node name as<a id="_idIndexMarker773"/> a quoted string, <strong class="bold">regular expression </strong>(<strong class="bold">regex</strong>), <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">default</strong></span></li>
				<li>A mixture of the following Puppet code items within curly <span class="No-Break">braces (</span><span class="No-Break"><strong class="source-inline">{}</strong></span><span class="No-Break">):</span><ul><li><span class="No-Break">Class declarations</span></li><li><span class="No-Break">Variables</span></li><li><span class="No-Break">Resource declarations</span></li><li><span class="No-Break">Collectors</span></li><li><span class="No-Break">Conditional statements</span></li><li><span class="No-Break">Chaining relationships</span></li><li><span class="No-Break">Functions</span></li></ul></li>
			</ul>
			<p>It is recommended to keep node definitions down to a minimum and only use class declarations and variables. If any <a id="_idIndexMarker774"/>manifest contains a node definition, then the node definitions must match all nodes, or compilation for nodes that do not match will fail. This is normally made safe by ensuring there is a default definition even if the default definition contains <span class="No-Break">no code.</span></p>
			<p>A node will only match one node definition, and this is prioritized by <span class="No-Break">the following:</span></p>
			<ul>
				<li>An exact <span class="No-Break">name match</span></li>
				<li>A regex match (multiple regex matches are unpredictable, and only one will <span class="No-Break">be used)</span></li>
				<li><strong class="source-inline">default </strong>(the keyword that nodes will match if they have failed to match any <span class="No-Break">other definition)</span></li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">A prioritization step before <strong class="source-inline">default </strong>would look for any partial matches of the hostname if <strong class="source-inline">strict_hostname_checking </strong>were set to <strong class="source-inline">false </strong>in the <strong class="source-inline">puppet.conf </strong>primary server. To avoid this insecure matching, it is set to <strong class="source-inline">true </strong>by default in Puppet 5.5.19 + and 6.13.0+, and in Puppet 7 onward was removed as <span class="No-Break">an option.</span></p>
			<p>For example, the following code will classify <strong class="source-inline">server1.exampleapp.com </strong>to the <strong class="source-inline">role::oracle </strong>class and <strong class="source-inline">server2.exampleapp.com </strong>and <strong class="source-inline">server3.exampleapp.com </strong>to the <strong class="source-inline">role::apache </strong>class. Any other servers that end with <strong class="source-inline">exampleapp.com </strong>will be classified to <strong class="source-inline">role::example_common_windows </strong>or <strong class="source-inline">role::example_common_linux </strong>depending on the OS family, such as <strong class="source-inline">server5.exampleapp.com</strong>, and any other node will be classified to <strong class="source-inline">role::common</strong>, such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">server1.anotherapp.com</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
node /.exampleapp.com$ {
  if $facts['os']['family'] {
    include role::example_common_windows
  else
    include role::example_common_linux
  }
}
node 'server1.exampleapp.com' {
  include role::oracle
}
node 'server2.exampleapp.com','server3.exampleapp.com' {
  include role::apache
}
node default {
  include role::common
}</pre>
			<p>It is a default to have a <strong class="source-inline">site.pp </strong>file in a <strong class="source-inline">manifest </strong>directory to keep things simple, but multiple manifests in this directory can contain node definitions that could be used to organize the files<a id="_idIndexMarker775"/> based on organization, use case, or ownership. It is clear having many node definitions simply will not scale; a recommended way of keeping node definitions simple is to use a default definition that looks at the certificate of the node to have a <strong class="source-inline">pp_role </strong>extension that contains the name of the role, as shown in this <span class="No-Break">code example:</span></p>
			<pre class="source-code">
node default {
  $role = getvar('trusted.extensions.pp_role')
  if ($role == undef) {
    fail("${trusted['certname']} does not have a pp_role trusted fact")
  }
  elsif (!defined($role)) {
    fail("${role} is not a valid role class")
  }
  else {
    include($role)
  }
}</pre>
			<p>Using the <strong class="source-inline">getvar </strong>function to avoid issues with hosts without certificates and the <strong class="source-inline">defined </strong>function to confirm the declared role is visible in the environment, it will include the role declared in <span class="No-Break">the certificate.</span></p>
			<p>Any code applied outside <a id="_idIndexMarker776"/>of the node definitions will apply to all nodes, but setting uncontrolled global defaults like this is not a recommended approach. In the previous code block, role classes were used, but any class could be included <span class="No-Break">for exceptions.</span></p>
			<p>A local <strong class="source-inline">puppet apply </strong>call will not look for manifests in the <strong class="source-inline">manifest </strong>variable setting from <strong class="source-inline">puppet.conf </strong>but is expected to do what is passed on the command line either via the <strong class="source-inline">–e </strong>flag or by passing a specific <span class="No-Break">manifest file.</span></p>
			<p>Having looked at the code-driven approach of node classification, we will now look at how Hiera data can be used to <span class="No-Break">classify nodes.</span></p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor281"/>Classifying nodes with Hiera</h2>
			<p>A more data-driven approach can be<a id="_idIndexMarker777"/> made in the default node definitions with Hiera arrays using the <strong class="source-inline">lookup </strong>function. While the <strong class="source-inline">lookup </strong>function could be<a id="_idIndexMarker778"/> used outside of the node definition, we recommend avoiding this to ensure, if any other node definition were specifically added for a node, it would have the expected result of only applying the node definition and not a less <span class="No-Break">predictable mix.</span></p>
			<p>The first step would be, as we saw in <a href="B18492_09.xhtml#_idTextAnchor233"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, to ensure an appropriate Hiera hierarchy is in place for each environment, assuming a simple hierarchy of node, OS, and defaults in the <strong class="source-inline">hiera.yaml </strong>environment, as <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
datadir: data 
data_hash: yaml_data 
  - name: "Node data" 
    path: "nodes/%{trusted.certname}.yaml"
  - name: "OS defaults" 
    path: "os/%{facts.os.family}.yaml" 
  - name: "Common data" 
    path: "common.yaml</pre>
			<p>We could then add a<a id="_idIndexMarker779"/> lookup within a <strong class="source-inline">default </strong><span class="No-Break">node</span><span class="No-Break"><a id="_idIndexMarker780"/></span><span class="No-Break"> definition:</span></p>
			<pre class="source-code">
node default {
lookup( {
  'name'          =&gt; 'classes',
  'value_type'    =&gt; Array,
  'default_value' =&gt; [],
  'merge'         =&gt; {
    'strategy'<a id="_idTextAnchor282"/> =&gt; 'unique',
  },
} ).each | $classification | {
  include $classification
}</pre>
			<p>While it would seem more appropriate to call the variable <strong class="source-inline">class</strong>, this is not possible due to <strong class="source-inline">class </strong>being a <span class="No-Break">reserved word.</span></p>
			<p>Data in the environment-level Hiera could then be added to a <strong class="source-inline">common.yaml </strong>file to ensure that by default, servers get the <span class="No-Break"><strong class="source-inline">core</strong></span><span class="No-Break"> role<a id="_idTextAnchor283"/>:</span></p>
			<pre class="source-code">
---
classes:
  - role::core</pre>
			<p>Then, we<a id="_idIndexMarker781"/> create an <strong class="source-inline">os/RedHat.yaml </strong>file in the data file containing the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
---
classes:
  - role::core::redhat</pre>
			<p>This would ensure all servers<a id="_idIndexMarker782"/> from the Red Hat family such as CentOS would get assigned the <strong class="source-inline">role::core::redhat </strong>class. To assign a particular role to a server, we create a <strong class="source-inline">node/exampleapp.example.com.yaml </strong>file, containing the <span class="No-Break">following co<a id="_idTextAnchor284"/>de:</span></p>
			<pre class="source-code">
---
classes:
  - role::docker</pre>
			<p>This would assign the <strong class="source-inline">role::docker </strong>class to the <span class="No-Break"><strong class="source-inline">exampleapp.example.com </strong></span><span class="No-Break">node.</span></p>
			<p>To allow exceptions and a more complex combination setup, hashes instead of arrays could be used, changing the lookup in <strong class="source-inline">site.pp </strong>from a unique to a deep merge strategy and the data from an array to <span class="No-Break">a hash:</span></p>
			<pre class="source-code">
node default {
lookup( {
<strong class="source-inline">  'name'          </strong>=&gt; 'classes',
  '<strong class="source-inline">value_type'    =&gt; Hash,</strong>
  'default_value' =&gt; []
  'merge' =&gt;
    'strategy' =&gt;  'deep',
}).each | $classification | {
  include $classification
}</pre>
			<p>In this case, we could use keys<a id="_idIndexMarker783"/> within Hiera that are only visible in Hiera to take over the role construct and use <a id="_idIndexMarker784"/>profiles directly, setting a <strong class="source-inline">common.yaml </strong>file to ensure the default classification gets a core profile and a <span class="No-Break">security profile:</span></p>
			<pre class="source-code">
---
classes:
base profile: profile::core
security profile: profile::security</pre>
			<p>Then, for a specific server <strong class="source-inline">exampleapp.example.com</strong>, the <strong class="source-inline">security_profile </strong>variable could be set <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">node/exampleapp.example.com.yaml</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
---
classes:
security_profile: profile::security::legacy</pre>
			<p>This would override the security profile key and result in <strong class="source-inline">exampleapp.example.com </strong>being classified as <strong class="source-inline">profile::security::legacy </strong><span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">profile::core</strong></span><span class="No-Break">.</span></p>
			<p>More complex Hiera-based key lookups could be constructed to look up based on Facter values, but since this is not a recommended approach in this book, enough detail has been shown to understand how Hiera can be used. It is worth seeing the <strong class="source-inline">psick </strong>module <a href="https://forge.puppet.com/modules/example42/psick">https://forge.puppet.com/modules/example42/psick</a> by example42 that uses the Hiera approach and can be used to have a preset and staged way of including modules in the Linux case. Including the <strong class="source-inline">psick </strong>class and simply setting the Hiera keys with hashes would be enough to classify <span class="No-Break">a host:</span></p>
			<pre class="source-code">
psick::firstrun::linux_classes
psick::pre::linux_classes
psick::base::linux_classes
psick::profiles::linux_classes</pre>
			<p>Having reviewed the<a id="_idIndexMarker785"/> code and data approaches for classification in detail, we will <a id="_idIndexMarker786"/>now cover the more advanced approach of using <span class="No-Break">ENC scripts.</span></p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor285"/>ENC scripts</h2>
			<p>An ENC is a script that the Puppet Server or a <strong class="source-inline">puppet apply </strong>call can run. The requirements of the script are to<a id="_idIndexMarker787"/> take an argument of the <strong class="source-inline">certname </strong>of the client and return either a nonzero return code for unknown nodes or a YAML output containing the classes, parameters, and environment for catalog compilation. Inside this ENC, it is possible to access various external data source references such as PuppetDB or internal data sources of your organization. It is not important which language the ENC is <span class="No-Break">written in.</span></p>
			<p>An example output would look <span class="No-Break">like this:</span></p>
			<pre class="source-code">
---
classes:
  role::core::windows
  sqlserver_instance:
    features:
      - SQL
    source: E:/
    sql_sysadmin_accounts:
      - myuser
parameters:
  dns_servers:
    - 2001:4860:4860::8888
     - 2001:4860:4860::8844
  mail_server: mail.example.com
  vault_enabled: true
environment: uat</pre>
			<p>In this example, it can be seen the server will have the <strong class="source-inline">role::core::windows </strong>class applied and the <strong class="source-inline">sqlserver_instance </strong>class with associated parameters, a list of parameters that will be global <a id="_idIndexMarker788"/>variables in the catalog, and an environment <a id="_idIndexMarker789"/>of <strong class="bold">user acceptance </strong><span class="No-Break"><strong class="bold">testing </strong></span><span class="No-Break">(</span><span class="No-Break"><strong class="bold">UAT</strong></span><span class="No-Break">).</span></p>
			<p>It would normally be better to pass class parameters via Hiera data but this is just to demonstrate what is possible in the <span class="No-Break">ENC output.</span></p>
			<p>To configure the use of ENC scripts, two variables must be set in <strong class="source-inline">puppet.conf</strong>: first, <strong class="source-inline">node_terminus</strong>, which defaults to <strong class="source-inline">plain</strong>, to only use the manifests to define classification. Setting <strong class="source-inline">node_terminus </strong>to <strong class="source-inline">exec </strong>causes the second variable, <strong class="source-inline">e</strong><strong class="source-inline">xternal_nodes</strong>, to be checked, which should be set to the location of a script. For example, the Foreman project uses an ENC that is defined in <strong class="source-inline">puppet.conf </strong>by its configuration module <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
node_terminus = exec
external_nodes = /etc/puppetlabs/puppet/node.rb</pre>
			<p>The contents of the script can be seen <span class="No-Break">here: </span><a href="https://github.com/theforeman/puppet-puppetserver_foreman/blob/master/files/enc.rb"><span class="No-Break">https://github.com/theforeman/puppet-puppetserver_foreman/blob/master/files/enc.rb</span></a><span class="No-Break">.</span></p>
			<p>The configuration module for placing this script can be found <span class="No-Break">at </span><a href="https://forge.puppet.com/modules/theforeman/puppetserver_foreman"><span class="No-Break">https://forge.puppet.com/modules/theforeman/puppetserver_foreman</span></a><span class="No-Break">.</span></p>
			<p>Developing ENCs is beyond the scope of this book, and it would be advisable to avoid the complexities involved in accessing external data this way as it can be expensive <span class="No-Break">to access.</span></p>
			<p>We have covered how ENC scripts work, but PE uses its own type of ENC script with <span class="No-Break">additional features.</span></p>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor286"/>PE classifier</h2>
			<p>PE provides its own ENC classifier that accesses the classification service API, which is a Clojure app, and stores node group<a id="_idIndexMarker790"/> information in the <strong class="bold">PostgreSQL </strong><span class="No-Break">classification </span><span class="No-Break"><a id="_idIndexMarker791"/></span><span class="No-Break">database.</span></p>
			<p>This is configured by setting <strong class="source-inline">node_terminus = classifier </strong>in <strong class="source-inline">puppet.conf </strong>by the installer and should not be changed as it will not <span class="No-Break">be supported.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout"><strong class="source-inline">node_terminus </strong>for PE used to be called <strong class="source-inline">console </strong>on PE 4 and <span class="No-Break">previous versions.</span></p>
			<p>The node groups come in two types: environment and classification. The environment groups are used to assign environments to nodes, while the classification nodes are intended for assigning classes and adding parameters and variables. The node groups can be viewed and configured from the PE web console in the <strong class="bold">Node </strong><span class="No-Break"><strong class="bold">groups </strong></span><span class="No-Break">section.</span></p>
			<p>All node groups can contain rules to define based on facts or by directly naming servers to be contained by a node group. They can contain any classes with any defined class parameters that will be classified to these matching nodes, parameters known as configuration data that act like Hiera data, acting as overrides and taking precedence over Hiera, and variables that are declared as global variables for <span class="No-Break">the group.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Older versions of PE did not enable configuration data by default and a section in <strong class="source-inline">/etc/puppetlabs/puppet/hiera.yaml </strong>had to <span class="No-Break">be added:</span></p>
			<p class="callout"><strong class="source-inline">hierarchy: - name: "Classifier Configuration Data" </strong><span class="No-Break"><strong class="source-inline">data_hash: classifier_data</strong></span></p>
			<p>By default, as pictured in <span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.1</em>, PE will have an <strong class="bold">All Nodes </strong>node group as a containing parent node group for all configurations, and beneath that split out to <strong class="bold">All Environments</strong>, an environment group acting as a parent group for all declared environment groups, and <strong class="bold">PE Infrastructure</strong>, a classification group used for configuring the <span class="No-Break">PE architecture:</span></p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B18492_11_01.jpg" alt="Figure 11.1 – PE default node groups"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – PE default node groups</p>
			<p>The environment groups are marked in <span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.1 </em>as <strong class="bold">Env group</strong>. The environment node groups by default<a id="_idIndexMarker792"/> use the <strong class="source-inline">trusted.extensions.pp_environment </strong>fact in a rule to match production or development into groups of the same name and ensure the named environment is assigned. If <strong class="source-inline">trusted.extensions.pp_environment </strong>is not set, the <strong class="bold">All environments </strong>node group will act as a catch-all to assign production as the default environment. Using the <strong class="source-inline">pp_enviroment </strong>trusted fact prevents the server from being moved to another environment without regenerating the server certificates, which will require access to both the client and primary server. The <strong class="bold">Development one-time run exception </strong>node group (called <strong class="bold">Agent-specified </strong>in previous PE versions) sets rules to allow development servers to run environments specified by the client. This can be useful when developing modules in feature branches, allowing testing to take place simply by running <strong class="source-inline">puppet agent –</strong><span class="No-Break"><strong class="source-inline">t --environment=myfeaturebranch</strong></span><span class="No-Break">.</span></p>
			<p>Approaches to the development and deployment of environments will be discussed further in the <em class="italic">Managing and deploying Puppet code </em>section, but it may prove necessary to have more environment levels between production and development, in which case the recommended approach would be to create a node group of that environment name under all environments and create a rule matching <strong class="source-inline">trusted.extensions.pp_environment </strong>with your set <span class="No-Break">environment name.</span></p>
			<p>Environment groups should be kept simple, so avoid assigning any class parameters <span class="No-Break">or variables.</span></p>
			<p>When classification groups <a id="_idIndexMarker793"/>are nested, they inherit the definition from their parent group. When creating a group structure, it will make sense to start with a general layer of configuration and narrow it down to classification groups that are more specific. This can be seen in the <strong class="bold">PE Infrastructure </strong>node groups, which start by ensuring general top-level parameters such as <strong class="source-inline">puppet_master_host </strong>are set, which apply to all Puppet infrastructure hosts, and then have specific services and functions such as a compiler or PuppetDB, which will be configured only on a subset <span class="No-Break">of nodes.</span></p>
			<p>It can be confusing because this inheritance applies to rules as well, so if the parent rule has already set a rule limiting nodes, the child node groups’ rules will be combined with the parent node group. This also applies to the pinning of nodes; you cannot just ignore rules and pin any server visible to the primary server. It is also important to note if the child node group contains no rules, it will not apply classification, even that inherited from a <span class="No-Break">parent group.</span></p>
			<p>Further confusion can arise from the purpose of the environment variable in classification node groups; this does not define where the assigned classes will run from but, in fact, tells the node group the environment in which to look for available class names. This can create issues if node groups are shared between development and production nodes and new classes are initially introduced to a development environment before being promoted to production, so it can often be the case that it makes the most sense for application node groups to use the lowest level of environment to have full visibility <span class="No-Break">of classes.</span></p>
			<p>To keep things simple, it is recommended to use straightforward classification roles that are kept as children of all nodes and simply have rules matching <strong class="source-inline">trusted.extensions.pp_role </strong>to a specific class role name, and then assign that role class to the classification <span class="No-Break">role group.</span></p>
			<p>To automate the creation of node groups, the <strong class="source-inline">node_manager </strong>module (<a href="https://forge.puppet.com/modules/WhatsARanjit/node_manager">https://forge.puppet.com/modules/WhatsARanjit/node_manager</a>) can be used to manage them through Puppet<a id="_idIndexMarker794"/> code, which is how the <strong class="source-inline">peadm </strong>module itself configures Puppet node group information. For example, <strong class="source-inline">peadm </strong>ensures that nodes with the <strong class="source-inline">puppet/puppetdb-database </strong>trusted extension are assigned to the <strong class="bold">PE Database </strong>node group with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
node_group { 'PE Database':,
  rule =&gt; ['or',
    ['and', ['=', ['trusted', 'extensions', peadm::oid('peadm_role')], 'puppet/puppetdb-database']],
    ['=', 'name', $primary_host],
  ]
}</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">The <strong class="source-inline">node manager </strong>module has the <strong class="source-inline">purge_behavior </strong>setting, which, if set to <strong class="source-inline">none </strong>for resources, ensures only the specific changes you wish to make are applied to node groups. By default this is set to <strong class="source-inline">all</strong>, removing any settings you have <span class="No-Break">not declared.</span></p>
			<p>Alternatively, the APIs can be used to perform backups and restores of node group data, saving to a file with <strong class="source-inline">/classifier-api/v1/groups </strong>and restoring with <strong class="source-inline">/classifier-api/v1/import-hierarchy</strong>. <strong class="source-inline">Peadm </strong>implements backup and restore classification tasks using these <span class="No-Break">APIs: </span><a href="https://github.com/puppetlabs/puppetlabs-peadm/tree/main/tasks"><span class="No-Break">https://github.com/puppetlabs/puppetlabs-peadm/tree/main/tasks</span></a><span class="No-Break">.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Since PE version 2019.2, a <strong class="source-inline">$pe_node_groups </strong>top-scope variable that returns all node groups <span class="No-Break">is available.</span></p>
			<p>A further method to use external data to <a id="_idIndexMarker795"/>add classes with the <strong class="bold">Puppet Data Service </strong>(<strong class="bold">PDS</strong>) will be shown in <a href="B18492_13.xhtml#_idTextAnchor321"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>. But having reviewed the various <a id="_idIndexMarker796"/>methods of classification, we will now discuss best-practice approaches to <span class="No-Break">classifying nodes.</span></p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor287"/>Recommended approach</h2>
			<p>A mixture of ENCs and node<a id="_idIndexMarker797"/> definition approaches can be used as it will merge the information, but this can make it harder to understand where classification has taken place. It would be best practice to choose one option if possible or at least to be clear on the purpose of each mechanism, such as node definition to match roles based on certificate and Hiera to match <span class="No-Break">node exceptions.</span></p>
			<p>Presuming classification has not already been chosen by your organization or is specific within your configuration model, such as using Foreman or <strong class="source-inline">psick</strong>, we recommend the simple pattern of assigning a default node definition based on the <strong class="source-inline">pp_role </strong>extension in the certificate for open source Puppet: use node groups matching the <strong class="source-inline">pp_role </strong>extension against node group role, and <strong class="source-inline">pp_environment </strong>against the environment to be used for PE. This is what Puppet Support expects and is the built model, but it limits the use of any variables or configuration data within the Hiera <span class="No-Break">data setup.</span></p>
			<p>The other mechanisms in sections <em class="italic">Node definitions </em>and <em class="italic">Classifying nodes with Hiera </em>were discussed since in many organizations, classification will already be in place and will not be easily changed and therefore must be understood. It is important to know if complex classifications must be produced; this can mean data is not being put in the right place or—worse—Puppet is not being used well and too many variations of servers are being produced. When we maintain tight standards with minimal exceptions, servers can be disposed of and rebuilt easily, reducing operational complexity and the cognitive load of <span class="No-Break">support teams.</span></p>
			<p>Now that you have understood how servers are classified to an environment and to classes, we will show how different data is loaded and cached during <span class="No-Break">Puppet runs.</span></p>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor288"/>Puppet runs</h1>
			<p>In this section, the steps of a Puppet run and classification will be detailed. For the case of Puppet runs, a <strong class="source-inline">puppet apply </strong>command should be considered as the equivalent of a Puppet server and client <a id="_idIndexMarker798"/>on the <span class="No-Break">same node.</span></p>
			<p>When a catalog request is made by a client, four things are sent to <span class="No-Break">the server:</span></p>
			<ul>
				<li>The <span class="No-Break">node name</span></li>
				<li>The node’s certificate (not sent <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">apply</strong></span><span class="No-Break">)</span></li>
				<li><span class="No-Break">Facts</span></li>
				<li>The <span class="No-Break">requested environment</span></li>
			</ul>
			<p>The node name is the <strong class="source-inline">certname</strong>, and along with the requested environment is embedded in the API request made—for <span class="No-Break">example, </span><span class="No-Break"><strong class="source-inline">/puppet/v3/catalog/exampleserver.example.com?environment=uat</strong></span><span class="No-Break">.</span></p>
			<p>The certificate can contain extensions, which will be turned into <span class="No-Break">trusted facts.</span></p>
			<p>After the server receives the agent data, it asks the configured node terminus for a node object. In the case of <strong class="source-inline">plain</strong>, this will be blank, or for <strong class="source-inline">exec </strong>or <strong class="source-inline">classifier</strong>, YAML output will be returned containing classes, parameters, <span class="No-Break">and environment.</span></p>
			<p>By default, <strong class="source-inline">puppet.conf </strong>sets <strong class="source-inline">strict-environment-mode </strong>to <strong class="source-inline">false</strong>, and this returned environment will override the agent request; if it is set to <strong class="source-inline">true</strong>, the catalog compilation will fail. The <strong class="source-inline">agent_specified_environment </strong>fact will appear if the agent specified an environment on the <span class="No-Break">Puppet run.</span></p>
			<p>The variables will then be set from the facts as both top-scope variables and the <strong class="source-inline">$facts </strong>hash, extensions in the certificate as trusted facts in the <strong class="source-inline">$trusted </strong>hash, and parameters returned from the node terminus as <span class="No-Break">top-scope variables.</span></p>
			<p>The main manifest will then be evaluated, looking for it to be defined by the environment configuration first and then the client’s <strong class="source-inline">puppet.conf </strong>file if it is unset. If any node definitions exist, Puppet will attempt to match the <strong class="source-inline">certname </strong>and fail compilation if it <span class="No-Break">does not.</span></p>
			<p>Any resources outside of the node definition are evaluated and added to the catalog and any classes. As was noted in the <em class="italic">Node definitions </em>section, it is not recommended to declare anything outside of node definitions. The matching node definition will then evaluate the code, overriding any top-scope variables with variables declared in the node definition, adding resources to the catalog, and loading and declaring classes in the <span class="No-Break">node definition.</span></p>
			<p>Puppet will then load the manifest containing classes declared in the main manifest using the <strong class="source-inline">modulepath </strong>variable configured for the environment. As a class is loaded, the code is evaluated and resources are added to the catalog, and any classes declared within them will be loaded <span class="No-Break">and evaluated.</span></p>
			<p>Puppet then loads and <a id="_idIndexMarker799"/>evaluates the classes that were returned from the <span class="No-Break">node object.</span></p>
			<p>Having seen how Puppet classifies nodes and how agent runs process these classification methods, it is now time to see how the environments are managed and deployed to the primary server to make the right versions of code available to <span class="No-Break">the nodes.</span></p>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor289"/>Managing and deploying Puppet code</h1>
			<p>By default, <a id="_idIndexMarker800"/>just creating the folders and dropping module contents into place combined with the <strong class="source-inline">puppet module install </strong>command to automate <a id="_idIndexMarker801"/>pulling from the Forge API is enough to make modules visible in environments and to allow them to be wrapped up in package management to create versions. But this is not an approach that we recommend as it centralizes the deployment of modules and environments, most likely making a single team a gatekeeper. We will see that control repos provide more <span class="No-Break">flexible control.</span></p>
			<p>The most common approach is to use a Git repository known as a control repo. Puppet provides a template for this repository <span class="No-Break">at </span><a href="https://github.com/puppetlabs/control-repo"><span class="No-Break">https://github.com/puppetlabs/control-repo</span></a><span class="No-Break">.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">The Puppet Forge author example42 provides its own templated control repo for use with its integrations and pre-designed implementation <span class="No-Break">approaches: </span><a href="https://github.com/example42/psick"><span class="No-Break">https://github.com/example42/psick</span></a><span class="No-Break">.</span></p>
			<p>Puppet’s control repo template contains many of the directories and files discussed in the first section of the<a id="_idIndexMarker802"/> chapter, along with Hiera data and some additional files specific to module <a id="_idIndexMarker803"/>deployment. <span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.2 </em>shows the contents of the Puppet <span class="No-Break">control repo:</span></p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B18492_11_02.jpg" alt="Figure 11.2 – File structure of the Puppet control repo template"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2 – File structure of the Puppet control repo template</p>
			<p>In the first section of this chapter, <em class="italic">Puppet environments</em>, we discussed many files and directories, with <strong class="source-inline">environment.conf</strong>, config version scripts, and the <strong class="source-inline">manifests </strong>directory for classification. Also visible is the Hiera configuration in <strong class="source-inline">hiera.yaml </strong>and a data <a id="_idIndexMarker804"/>directory showing a simple initial two layers of nodes, to match specific node names and common data, to act as a default for nodes that do not <a id="_idIndexMarker805"/>match. The <strong class="source-inline">site-modules </strong>directory intends to show that ad hoc plans and tasks can be deployed as part of this control repo as well as potentially give a home to roles and profiles. The <strong class="source-inline">scripts </strong>directory is also worth reviewing to see in the config version script at <a href="https://github.com/puppetlabs/control-repo/blob/production/scripts/config_version.sh">https://github.com/puppetlabs/control-repo/blob/production/scripts/config_version.sh</a> how it will add Git revision control information about the environment to the run. The part that we have not reviewed is the <span class="No-Break">Puppetfile file.</span></p>
			<p>The Puppetfile file is a Ruby-based <strong class="bold">Domain-Specific Language </strong>(<strong class="bold">DSL</strong>) that provides a way to declare which <a id="_idIndexMarker806"/>modules should be downloaded to an environment, where to source them from, and which version to use. It is also possible to override module location settings by declaring <strong class="source-inline">moduledir </strong>as a variable or the <strong class="source-inline">installpath </strong>parameter on a particular module. We do not recommend this as good practice as it can be confusing to users unfamiliar with your environment and, if set to be outside the environment directory, can affect caching and make the environment inconsistent. This will be discussed later in <span class="No-Break">this section.</span></p>
			<p>Puppetfile module declarations at their simplest level contain <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">mod </strong></span><span class="No-Break">keyword</span></li>
				<li>A name in <span class="No-Break">single quotes</span></li>
				<li>Optionally a comma, then a version number or the <strong class="source-inline">:</strong><span class="No-Break"><strong class="source-inline">latest </strong></span><span class="No-Break">keyword</span></li>
			</ul>
			<p>For example, the following code block assumes Puppet Forge as the source and installs the latest version of <strong class="source-inline">dsc-octopusdsc </strong>if the module is not present, but will not result in the module <span class="No-Break">being updated:</span></p>
			<pre class="source-code">
mod 'dsc-octopusdsc'
mod 'puppetlabs-chocolatey', '6.2.0'
mod 'puppetlabs-stdlib' , :latest</pre>
			<p>This piece of code will install <strong class="source-inline">puppetlabs-chocolatey </strong>to the fixed version 6.2.0 and will install <strong class="source-inline">puppetlabs-stdlib </strong>and keep updating it to the latest version. It is important to note this will not result in Puppet Forge dependencies being installed—this must be managed within the Puppetfile manually. Looking at module documentation on the Puppet Forge you will see example code on how to add the modules <span class="No-Break">to Puppetfiles.</span></p>
			<p>To access modules within<a id="_idIndexMarker807"/> other Git repositories, the <strong class="source-inline">git </strong>option and the HTTP address to the<a id="_idIndexMarker808"/> repository should be given. These can then be paired with one of the following options to clone a specific version of the <span class="No-Break">Git repository:</span></p>
			<ul>
				<li><strong class="source-inline">ref</strong>, with a reference to  a tag, a commit, or <span class="No-Break">a branch</span></li>
				<li><strong class="source-inline">tag</strong>, with a <span class="No-Break">specific tag</span></li>
				<li><strong class="source-inline">commit</strong>, with a specific <span class="No-Break">commit reference</span></li>
				<li><strong class="source-inline">branch</strong>, with the name of a branch or the <strong class="source-inline">:control_branch </strong>keyword (which will automatically look up the control repo’s <span class="No-Break">branch name)</span></li>
				<li><strong class="source-inline">default_branch</strong>, a branch to use if all the preceding <span class="No-Break">options fail</span></li>
			</ul>
			<p>The following code demonstrates how the <strong class="source-inline">git </strong>options in the preceding list can be mixed <span class="No-Break">and matched:</span></p>
			<pre class="source-code">
mod 'exampleorg-examplemodule1',
  :git =&gt; 'https://internalgitservice.com/exampleorg/examplemodule1',
  :tag =&gt;  'v.0.1'
mod 'exampleorg-examplemodule2',
  :git =&gt; 'https://internalgitservice.com/exampleorg/examplemodule2',
  :commit =&gt; '68a140bd096a55019b3d5c8c347436b318779161'
mod 'anotherorg-anothermodule',
  :git =&gt; 'https://internalgitservice.com/anotherorg/anothermodule',
  :branch =&gt; :control_branch,
  :default_branch =&gt; 'main'</pre>
			<p>This code block takes <strong class="source-inline">examplemodule1 </strong>at <strong class="source-inline">tag </strong>version <strong class="source-inline">v.0.1 </strong>and <strong class="source-inline">examplemodule2 </strong>at <strong class="source-inline">commit </strong>version <strong class="source-inline">68a140bd096a55019b3d5c8c347436b318779161 </strong>from the same Git organization. For <strong class="source-inline">anothermodule</strong>, if a <a id="_idIndexMarker809"/>branch with the same name as the environment that we are trying to deploy exists, it will use that; otherwise, it will clone at the <span class="No-Break"><strong class="source-inline">main </strong></span><span class="No-Break">branch.</span></p>
			<p>In air-gapped environments where<a id="_idIndexMarker810"/> access to the Puppet Forge API  is limited or in regulated environments where it is an audit requirement to have a company-stored copy of all code, it may prove necessary to download copies of code from the Forge and use it from your organization’s own Git system. In this case, it is strongly advised that you follow the project URL on the module page, perform a Git clone of the source of the Puppet Forge module, and then change the remote directory to your own Git repository copy. This ensures the commit history is maintained and on a regular basis, you can simply clone the code again and add new commits to your own <span class="No-Break">local repository.</span></p>
			<p>Regardless of how Forge modules are downloaded, if they are not coming directly from the Forge at their latest version it is important to frequently check versions and make this part of a regular cycle to test and update. This ensures you are getting the latest features and fixes and<a id="_idIndexMarker811"/> means you avoid having to perform large version upgrades that are harder to test. Following the <strong class="bold">Content and Tooling </strong>(<strong class="bold">CAT</strong>) team at <a href="https://puppetlabs.github.io/content-and-tooling-team/blog/">https://puppetlabs.github.io/content-and-tooling-team/blog/</a> can help keep track of <span class="No-Break">module releases.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">JFrog Artifactory users can use a Puppet Forge plugin to synchronize and host modules internally, as documented <span class="No-Break">at </span><a href="https://www.jfrog.com/confluence/display/JFROG/Puppet+Repositories"><span class="No-Break">https://www.jfrog.com/confluence/display/JFROG/Puppet+Repositories</span></a><span class="No-Break">.</span></p>
			<p>With this structure to manage several environments, it is simply a case of creating branches on the Git repository, with each branch representing an environment that can have its own independent content to <span class="No-Break">be deployed.</span></p>
			<p>To manage deployment, the standard <a id="_idIndexMarker812"/>system used for <strong class="bold"> Open Source Puppet </strong>is known as <strong class="source-inline">r10k</strong>, and the <a id="_idIndexMarker813"/>system used for <strong class="bold">Puppet Code Manager </strong>for PE is based on <strong class="source-inline">r10k </strong>but has further <a id="_idIndexMarker814"/>integrations <span class="No-Break">for PE.</span></p>
			<p>The installation instructions for <strong class="source-inline">r10k </strong>are straightforward and available direct from the repository at <a href="https://forge.puppet.com/modules/puppet/r10k">https://forge.puppet.com/modules/puppet/r10k</a>. Instructions to configure Code Manager in PE either in<a id="_idIndexMarker815"/> node groups or via Hiera are available <span class="No-Break">at </span><a href="https://puppet.com/docs/pe/2021.7/code_mgr_config.html"><span class="No-Break">https://puppet.com/docs/pe/2021.7/code_mgr_config.html</span></a><span class="No-Break">.</span></p>
			<p>In both cases, as part of these instructions, an SSH key will be generated to allow for communication between <strong class="source-inline">r10k </strong>and any Git repositories you <span class="No-Break">have declared.</span></p>
			<p>An alternative option for Puppet Open Source is to use <strong class="source-inline">g10k</strong> <strong class="source-inline">(</strong><a href="https://forge.puppet.com/modules/landcareresearch/g10k">https://forge.puppet.com/modules/landcareresearch/g10k</a>), which is a rewrite of <strong class="source-inline">r10k </strong>in <strong class="bold">Go </strong>and has substantial <span class="No-Break">performance improvements.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can still use <strong class="source-inline">r10k </strong>directly in PE, but this is not an approach Puppet will provide <span class="No-Break">support for.</span></p>
			<p>For open source Puppet, having configured and deployed <strong class="source-inline">r10k</strong>, it is then possible to run a <strong class="source-inline">sudo -H -u puppet r10k deploy production </strong>command to deploy a specific branch or leave off an environment name to deploy all available environments. A Webhook can also be configured using the Sinatra server, as detailed in the <strong class="source-inline">r10k </strong>instructions <span class="No-Break">at </span><a href="https://forge.puppet.com/modules/puppet/r10k/readme#webhook-support"><span class="No-Break">https://forge.puppet.com/modules/puppet/r10k/readme#webhook-support</span></a><span class="No-Break">.</span></p>
			<p>For PE, Puppet Code Manager <a id="_idIndexMarker816"/>is a <strong class="bold">Clojure </strong>application that exposes an <strong class="source-inline">/code-manager </strong>API using a token generated in the PE <strong class="bold">role-based access control </strong>(<strong class="bold">RBAC</strong>) system, which will be <a id="_idIndexMarker817"/>covered in detail in <a href="B18492_14.xhtml#_idTextAnchor340"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>. It can be accessed either directly to the API or by running the <strong class="source-inline">puppet code deploy </strong>command. For example, the following code will generate a token for the currently logged-in user for the next 2 hours and then deploy in the <span class="No-Break">production environment:</span></p>
			<pre class="source-code">
<strong class="bold">puppet-access login --lifetime 2h</strong>
<strong class="bold">puppet code deploy production --wait</strong></pre>
			<p>In either version, to see the deployed modules you can use <strong class="source-inline">puppet module --list</strong>, which will also show any <a id="_idIndexMarker818"/><span class="No-Break">dependency issues.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Puppet Code Manager uses <strong class="source-inline">r10k </strong>underneath. To get more detailed debugging information, the following command can be run, which is used for deploying <span class="No-Break">in production:</span></p>
			<p class="callout"><strong class="source-inline">runuser -u pe-puppet -- /opt/puppetlabs/puppet/bin/r10k -c /opt/puppetlabs/server/data/code-manager/r10k.yaml deploy environment production --puppetfile --</strong><span class="No-Break"><strong class="source-inline">verbose debug2</strong></span></p>
			<p>For these deployments, it is important to<a id="_idIndexMarker819"/> understand caching that can take place. All Puppet code is read and parsed when the environment is loaded—as is the <strong class="source-inline">hiera.yaml </strong>file—and it is not re-read until the environment cache is expired, or the  JRuby instance is refreshed. The <strong class="source-inline">environment.conf </strong>file by default sets this to <strong class="source-inline">unlimited</strong>. While Puppet templates and Hiera data are read anew from disk on every function call, they are not cached. This means that if any local edits take place to Hiera data or Puppet templates outside of <strong class="source-inline">r10k</strong>, they will be viewed. It also means that if environments have module paths that look into other environments, a deployment would result in it only seeing the Hiera and template updates. This is why it is strongly recommended to avoid <span class="No-Break">this approach.</span></p>
			<p>When using compilers to synchronize code, open source Puppet,\ has various options depending on your environment as to how to deploy the code: installing and running <strong class="source-inline">r10k </strong>on every compiler node, performing a <strong class="source-inline">rsync </strong>operation from the primary server to compilers, or using a read-only <strong class="bold">network file share</strong> (<strong class="bold">NFS</strong>) from the primary to all compilers. This choice will be entirely down to what is best for your organization in terms of network configuration and <span class="No-Break">security standards.</span></p>
			<p>On PE, Code Manager has a specific implementation using the file sync client and server, as shown in <span class="No-Break"><em class="italic">Figure 11</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B18492_11_03.jpg" alt="Figure 11.3 – Puppet Code Manager architecture"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – Puppet Code Manager architecture</p>
			<p>A code deployment request will <a id="_idIndexMarker820"/>come in a request with an RBAC token either via the command line or tooling. This will pull down the code to the commit staging directory on the primary <a id="_idIndexMarker821"/>server. The file sync clients for all infrastructure nodes have a polling watcher that sees the deployment and alerts the file sync process. This will result in the file sync process doing one of two things, depending on whether lockless code deploys are enabled (which were introduced in PE 2021.2). If lockless code deploys are not enabled on the relevant server, all JRuby instances will need to be reserved to prevent any catalog runs using inconsistent environments. Remembering how different environment data is cached in the <em class="italic">Puppet runs </em>section, once reserved, the files will be synced into the environment directory, and the JRuby instances released. This does mean code deployments can be impactful <span class="No-Break">on performance.</span></p>
			<p>If lockless code deployment is enabled, symbolic links or symlinks are used for the environment directories, which means the file sync will synchronize to a folder named after the version commit and, on<a id="_idIndexMarker822"/> completion of synchronization, redirect the environment symlink to this new folder. This requires more disk space because more environments <a id="_idIndexMarker823"/>will be deployed at once but ensures catalogs can continue to run since they will use the directory the symlink had when they started to run. To enable lockless code deploys, follow the instructions <span class="No-Break">at </span><a href="https://puppet.com/docs/pe/2021.7/lockless-code-deploys.html"><span class="No-Break">https://puppet.com/docs/pe/2021.7/lockless-code-deploys.html</span></a><span class="No-Break">.</span></p>
			<p>Now that we understand how Puppet deploys code to environments, we will look at workflows that can be used to manage the promotion of module code through <span class="No-Break">those environments.</span></p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor290"/>Creating a workflow</h2>
			<p>There are two <a id="_idIndexMarker824"/>common approaches for creating a workflow to deploy code. The first method is to put the control repo as a central gatekeeper of versions. This means that every module declaration on the Puppetfile has specific versions and typically will have the lowest-level environment updated with a specific reference such as <strong class="source-inline">tag</strong>, <strong class="source-inline">commit</strong>, or <strong class="source-inline">branch</strong>. These changes are tested in feature branches and then promoted through environments by merging the changes from one branch to the next, running the code on servers, and confirming expected results. For example, the steps involved in such as process may include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Creating a feature branch of the control repo and updating the <strong class="source-inline">module1 </strong>tag version from 1.1 <span class="No-Break">to 1.2</span></li>
				<li>Merging the feature branch with the development branch and <span class="No-Break">deploying development</span></li>
				<li>Merging the development branch with the UAT branch and <span class="No-Break">deploying UAT</span></li>
				<li>Merging UAT with production and <span class="No-Break">deploying production</span></li>
			</ul>
			<p>This is not a natural Git flow and does not use the main branch. It is very focused on deployment, requiring a lot more management of environments. This approach can be particularly difficult with multiple teams since it will result in the requirement of a gatekeeper such as the Puppet platform team to manage changes to the Puppetfile control repo and manage the schedule of when code deployments <span class="No-Break">are made.</span></p>
			<p>If this approach is taken, it is advisable to have multiple control repos using the prefix configuration settings—this can be useful for teams that want to use different sets of modules, such as Windows and Linux, or want to have isolation and protection around the control repo and have separate ownership of code and servers but want to <span class="No-Break">share infrastructure.</span></p>
			<p>The second approach is to have all modules in the Puppetfile in the control repo set to use a branch of <strong class="source-inline">control_branch </strong>and a default of <strong class="source-inline">main</strong>. Maintenance of the Puppetfile will then only<a id="_idIndexMarker825"/> involve the addition and removal of modules. The management of versions will be on the modules themselves, with code changes pushed to the main branch from temporary feature branches before being merged into each static environment branch. Here’s <span class="No-Break">an example:</span></p>
			<ul>
				<li>Create a feature branch on <strong class="source-inline">module1 </strong>and control repo testing <span class="No-Break">code changes</span></li>
				<li>Merge the feature branch of <strong class="source-inline">module1 </strong><span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">main</strong></span></li>
				<li>Merge changes of the module branch from main to development, then deploy <span class="No-Break">and test</span></li>
				<li>Merge changes of the module branch from development to UAT, then deploy <span class="No-Break">and test</span></li>
				<li>Merge changes of the module branch from UAT to production, then deploy <span class="No-Break">and test</span></li>
			</ul>
			<p>Using pipelining tools <a id="_idIndexMarker826"/>as part of the <strong class="bold">pull request </strong>(<strong class="bold">PR</strong>) and deployment process is strongly <a id="_idIndexMarker827"/>advised. <strong class="bold">Continuous Delivery for PE </strong>(<strong class="bold">CD4PE</strong>) (discussed in <a href="B18492_14.xhtml#_idTextAnchor340"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>) comes with prebuilt checks to make this easier, but various tools exist, such as Jenkins or GitHub, with which you can ensure the pre-commit hook checks and testing we discussed in <a href="B18492_08.xhtml#_idTextAnchor212"><span class="No-Break"><em class="italic">Chapter 8</em></span></a><em class="italic"> </em>are performed before a PR can <span class="No-Break">be completed.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Some excellent sources of existing pre-commit hooks to copy into place can be found at <a href="https://pre-commit.com/hooks.html">https://pre-commit.com/hooks.html</a>, <a href="https://github.com/pre-commit/pre-commit-hooks">https://github.com/pre-commit/pre-commit-hooks</a>, <span class="No-Break">and </span><a href="https://github.com/mattiasgeniar/puppet-pre-commit-hook"><span class="No-Break">https://github.com/mattiasgeniar/puppet-pre-commit-hook</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-221"><a id="_idTextAnchor291"/>Lab – classifying and deploying code</h1>
			<p>In this lab, complete the <span class="No-Break">following tasks:</span></p>
			<ul>
				<li>Create a node<a id="_idIndexMarker828"/> definition that assigns the <strong class="source-inline">motd </strong>module to any node with <strong class="source-inline">node </strong>in the<a id="_idIndexMarker829"/> certname in the <strong class="source-inline">manifest/site.pp </strong>file of the <span class="No-Break">production environment</span><ul><li>The <strong class="source-inline">motd </strong>module is already in the <strong class="source-inline">Puppetfile </strong>file in the production <span class="No-Break">control repo</span></li><li>The defaults for <strong class="source-inline">motd </strong>should be fine using <span class="No-Break"><strong class="source-inline">include motd</strong></span></li><li>See an example solution <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/default.pp"><span class="No-Break">https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/default.pp</span></a></li></ul></li>
				<li>Create a node definition to assign the <strong class="source-inline">icinga2 </strong>module to all Windows nodes that <span class="No-Break">get created</span><ul><li>The <strong class="source-inline">icinga2 </strong>module is already in the <strong class="source-inline">Puppetfile </strong>file in the production <span class="No-Break">control repo</span></li><li>The defaults for <strong class="source-inline">icigna2 </strong>should be fine using <span class="No-Break"><strong class="source-inline">include incigna2</strong></span></li><li>Windows nodes will always contain <strong class="source-inline">windows-node </strong>in <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">certname</strong></span></li><li>To deploy on the PE web console, run the <strong class="source-inline">peadm code_manager </strong>task from the <strong class="bold">Orchestration </strong>task menu, entering the <strong class="source-inline">'deploy production'  </strong><span class="No-Break">action string</span></li><li>See an example solution <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/node.pp"><span class="No-Break">https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/node.pp</span></a></li></ul></li>
				<li>Create and deploy a development environment, adding the <span class="No-Break"><strong class="source-inline">docker </strong></span><span class="No-Break">module:</span><ul><li>On the GitHub web page, go to your control repo and select the arrow next to the production branch, and <span class="No-Break">type </span><span class="No-Break"><strong class="source-inline">development</strong></span></li><li>Click the text generated below, which should say <strong class="source-inline">create branch: development </strong><span class="No-Break"><strong class="source-inline">from 'production'</strong></span></li><li>Add the line <strong class="source-inline">mod 'puppetlabs-docker'</strong>, latest to <strong class="source-inline">Puppetfile</strong>, making sure you are on the <span class="No-Break">development branch</span></li><li>On the PE web console, run the <strong class="source-inline">peadm code_manager </strong>task from the task menu, entering<a id="_idIndexMarker830"/> the <strong class="source-inline">'deploy development' </strong><span class="No-Break">action string</span></li></ul></li>
				<li>Create a node <a id="_idIndexMarker831"/>group for a role that includes Docker pinning one of your nodes to it and development, then promote the development branch to production <span class="No-Break">and deploy:</span><ul><li>Create a node group called <strong class="source-inline">docker </strong>by selecting <strong class="bold">node groups </strong>under <strong class="bold">inventory </strong>and <strong class="bold">add node groups</strong>, ensuring this node group is under <strong class="bold">All Nodes</strong>, has the environment set to development, and has your choice of node pinned <span class="No-Break">to it</span></li><li>On the <strong class="bold">Development environment </strong>node group, pin your choice of node <span class="No-Break">to it</span></li><li>Under <strong class="bold">Enforcement</strong>, select <strong class="bold">jobs</strong>, run <strong class="bold">puppet</strong>, select your choice of node, and set it to <span class="No-Break"><strong class="source-inline">apply docker</strong></span></li><li>See sample solutions at <a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group1.png">https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group1.png</a>, <a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group2.png"/><a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group2.png">https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group2.png</a>, <span class="No-Break">and </span><a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group3.png"/><a href="https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group3.png"><span class="No-Break">https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch11/docker_group3.png</span></a></li></ul></li>
			</ul>
			<h1 id="_idParaDest-222"><a id="_idTextAnchor292"/>Summary</h1>
			<p>In this chapter, we discussed how Puppet environments can be used to manage specific versions of modules, classification, and data to apply to groups of Puppet clients. The directory structure and variables to configure this <span class="No-Break">was reviewed.</span></p>
			<p>The options to classify servers into environments and to assign classes and parameters were reviewed, looking at node definitions in manifest files, using Hiera in the node definitions to create more complex data-driven calculations, and then ENC scripts that can access sources such as PuppetDB and return YAML output of classes, environment, and parameters for classification. PE was then shown to build on the ENC approach with its own ENC script used in conjunction with node groups to store data on how to classify servers into environments and <span class="No-Break">assign classes.</span></p>
			<p>It was highlighted that the various methods could be used together but the recommended approach was to keep it simple; for open source Puppet, just use a default node definition to look for <strong class="source-inline">pp_role </strong>trusted facts to classify and to put the environment setting in <strong class="source-inline">puppet.conf</strong>, while for PE, it was recommended to use 1-to-1 matching of node groups with <strong class="source-inline">pp_role </strong>and <strong class="source-inline">pp_environment </strong><span class="No-Break">trusted facts.</span></p>
			<p>It was then shown how a Puppet catalog request sends data to the Puppet server and how classification files and scripts are used to generate catalogs highlighting how different types of Puppet resources <span class="No-Break">are cached.</span></p>
			<p>The methods of deploying environments were then shown, using a Git-based Puppet control repo to contain the files and directories of environments, with each Git branch representing a particular environment. The Puppetfile was shown as a way to list which modules should be deployed to an environment, specifying the version and location of <span class="No-Break">the module.</span></p>
			<p>It was then discussed how <strong class="source-inline">r10k </strong>and the PE Code Manager implementation on top of <strong class="source-inline">r10k </strong>can deploy code to servers. For servers using compilers, we reviewed various approaches to keep code deployed on all infrastructure, which would depend on local infrastructure and standards. For PE, it was shown that Code Manager contained <strong class="bold">File sync</strong>, which kept <span class="No-Break">code synchronized.</span></p>
			<p>Workflow approaches were then viewed, showing the more gated and traditional approach of using a control repo with a Puppetfile at set versions and updating the lowest-level environment such as development before pushing these module version changes up through the environments. The second recommended approach showed the control would rely on the modules themselves and the control repo would look for environment-named branches, allowing teams to work and deploy independently. Highlighting the idea in either of these systems is to use a proper pipelining tool with Webhooks to <span class="No-Break">automate deployment.</span></p>
			<p>Having focused on Puppet infrastructure and language for stateful configuration management in this chapter, the next chapter will look at Bolt and orchestrator to show how procedural tasks can be run either using Bolt as an independent tool or through the PE infrastructure via the <span class="No-Break">PE orchestrator.</span></p>
		</div>
	</body></html>