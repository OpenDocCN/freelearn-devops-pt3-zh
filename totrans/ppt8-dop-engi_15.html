<html><head></head><body>
		<div id="_idContainer073">
			<h1 id="_idParaDest-288" class="chapter-number"><a id="_idTextAnchor359"/>15</h1>
			<h1 id="_idParaDest-289"><a id="_idTextAnchor360"/>Approaches to Adoption</h1>
			<p>Having discussed the Puppet language and platform in detail, this chapter will now look at approaches to adoption and implementation. This chapter does make certain assumptions about the most likely adopters of Puppet and their viewpoints. As a result, some of this advice will appear from a Puppet platform team’s point of view but it will look to discuss how all the implementation teams, from application to OS, should work together to <span class="No-Break">boost adoption.</span></p>
			<p>Too often, the view taken by a project or modernization program is that technology alone can solve all the problems of an organization, and existing teams and processes are just in the way and will need to be worked around to deliver the future. The most successful adoptions work with the current teams and embed themselves in their processes. This chapter will cover this by discussing how to choose the right scope and focus to make sure that the implementation can achieve its goals, delivering on a regular interval, and showing value to encourage the adoption. We will discuss how to work with other teams and stakeholders to ensure that Puppet as a technology is not an island that battles for space but can be a platform among many tools that can integrate and maximize benefits. While it is often more practical to start with greenfield newly provisioned servers, we will discuss how to safely and progressively reach the heritage brownfield estate, where understanding the level of configuration drift that has happened and developing automation to remediate can have huge benefits in reducing costly auditing processes. Using Puppet in regulated environments will be discussed in detail as it is often assumed that a tool that commits regular change and has elevated access simply cannot be used. We will see how to present the processes and testing to not only make Puppet safe and secure but also to show it is an integral part of enforcing the requirements of any regulated environment. Finally, we will see where Puppet fits into the cloud, its appropriate uses, and how to avoid mistakes made by public cloud migrations and not leave behind the benefits gained by Puppet in the private <span class="No-Break">data center.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Scope <span class="No-Break">and focus</span></li>
				<li>A platform <span class="No-Break">engineering approach</span></li>
				<li>Managing heritage estates with <span class="No-Break">no-op mode</span></li>
				<li>Adoption in <span class="No-Break">regulated environments</span></li>
				<li>Moving to <span class="No-Break">the cloud</span></li>
			</ul>
			<h1 id="_idParaDest-290"><a id="_idTextAnchor361"/>Scope and focus</h1>
			<p>The <a id="_idIndexMarker1127"/>pressure on scope and focus will depend on why your organization has started using Puppet. If it is an exercise for an individual team, such as the Oracle team, to automate its deployment, the pressure will be less than a transformation program that has bought a large Puppet Enterprise contract. In big transformation programs, it can be tempting to pursue big goals quickly to earn this cost back. This is dangerous because configuration problems are complex, and technologists are prone to optimism about how quickly solutions can be created. Additional pressure can come from sales teams and decision-makers who may have oversold how quickly change can be implemented to get the necessary funding. This is not advocating against having a vision or a Jim Collins-style big hairy audacious goal. The future vision is needed but it has to be shown that it will be an incremental journey of improvement to get there, and these increments will deliver immediate and recurring value. This will develop trust and belief from supporting teams and customers to invest in your platform because you reliably deliver something tangible and not just a <span class="No-Break">distant hope.</span></p>
			<p>The best approach to this delivery is to follow good sprint practices, having epics such as delivering a core OS role or an Oracle role, which can then be broken down to have a small number of focused objectives for each sprint. Each task within an epic should be small enough to be completed in a regular sprint cycle, typically 2 weeks. At the end of each sprint, these features can then be demoed to stakeholders to show progress, benefit, and <span class="No-Break">receive feedback.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">This book does not advocate for any agile methodology; there is a vast collection of books and advice on how to implement agile working practices. What works for your organization will depend on local culture and your team. So, this book’s recommendation would be to research various approaches but remain flexible and find what is comfortable and works well for your team and not just try to fully mimic anyone else’s system. Using techniques such as retrospectives at the end of sprints can help ensure that how you are working is still effective and that actions are taken <span class="No-Break">on issues.</span></p>
			<p>If this approach<a id="_idIndexMarker1128"/> is ignored and the team is split among many objectives, it can easily result in developers working in isolation. When developers work in isolation, other team members cannot help or provide meaningful reviews because they do not have an understanding of the work or why decisions have <span class="No-Break">been made.</span></p>
			<p>If the work is too large and complex, it will result in development problems, which are hard to test and break down to understand. This can lead to frustration between management and developers as nothing will be visible in terms of delivery. The pressure to deliver something can then lead to developer exhaustion and this combined with the difficulties of reviewing and testing large complex work can lead to something risky or incomplete being delivered, simply to deliver something. This erodes confidence and morale in a vicious cycle of pressure and mounting issues <span class="No-Break">to fix.</span></p>
			<p>In the <em class="italic">Adoption in regulated environments </em>section, we will discuss how critical it is to demonstrate an ability to reliably test and deliver to win confidence from change and risk teams in your processes <span class="No-Break">and platform.</span></p>
			<p>With this warning said, if the team does stick to a focus and scope, then an understanding among the team can be built about the ongoing development work and strengthen the review, testing, and learning processes. This produces opportunities for developers to pair on interesting or challenging sections of work and use team breakout sessions to jointly make decisions on coding approaches. As discussed in <a href="B18492_01.xhtml#_idTextAnchor018"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, keeping a Puppet best practices document updated with these decisions helps spread the knowledge further. Most importantly, on review of the submission of code, it becomes something the team has been actively discussing and working on together, not just something that may have only been heard in brief morning meeting updates and something the team has to take the developers’ word on. All of this works toward a better understanding of what the code is intended to do and why the approach has <span class="No-Break">been chosen.</span></p>
			<p>To illustrate this approach, it is common for a base OS to need a security profile for the core build. This security profile will contain various aspects such as core OS user accounts, SSH configuration, kernel settings, and various other important settings. Making this profile the focus of a sprint could result in developers pairing and working on the component modules that make up the profile. With the pairs of developers focusing on elements such as user accounts and building up the profile piece by piece, practical progress will be made and knowledge shared. Depending on the size of the profile and the number of developers, it may make more sense to work on multiple profiles but the aim should still be to limit the scope <span class="No-Break">and focus.</span></p>
			<p>This is <a id="_idIndexMarker1129"/>not to say any development team should expect to get everything their own way and that external pressures will not result in having to split this focus, but it should be strongly represented that it will slow down work and <span class="No-Break">create risk.</span></p>
			<p>The next key thing to understand after the focus and scope of Puppet code are the minimum acceptance criteria for code to be delivered to production. The phrase <strong class="bold">minimum viable product </strong>(<strong class="bold">MVP</strong>) has been tainted as an excuse to release something that is clearly not fit for production with items such as testing to be added later. It is a simple reality this will not happen since there are always new features to develop, creating an operational burden in the future as the code develops further. So, in your organization and platform, the Puppet best practices should lay out what tests the code should pass. An example standard could contain <span class="No-Break">the following:</span></p>
			<ul>
				<li>Code must be clean in PDK validation with accepted <span class="No-Break">listed exceptions</span></li>
				<li>RSpec tests provide 100% coverage <span class="No-Break">of code</span></li>
				<li>ServerSpec tests for the module and passes core <span class="No-Break">Serverspec tests</span></li>
			</ul>
			<p>Another challenge can be scope creep, which can dilute the higher-level scope and focus of how Puppet is used in your organization. When investing in a tool, it is tempting to maximize the return on investment by expanding use cases, and as the implementation becomes successful, other teams will want to attach to that success and try to use a provided tool. Therefore, it needs to be clear what the use case of Puppet is; inappropriate uses such as the distribution of binaries or large-scale synchronization of files need to be called out as inappropriate in platform documentation. In this example, it would put a lot of burden on the infrastructure, as was discussed throughout this book. Also, in this regard of focus, this book would strongly recommend against any policy encouraging mandatory rewriting/re-platforming strategies to Puppet unless the current implementation has maintenance issues or cannot be developed as needed. This sort of rewrite provides little value and, unless the original implementation is well understood, can<a id="_idIndexMarker1130"/> lead to mistakes in the translation, particularly for declarative code since only the method is visible not the intended <span class="No-Break">final state.</span></p>
			<p>Having discussed the scope and focus for Puppet, we will now look at how to manage this approach on heritage servers and handle the history and complexities of <span class="No-Break">brownfield sites.</span></p>
			<h1 id="_idParaDest-291"><a id="_idTextAnchor362"/>Managing heritage estates with no-op mode</h1>
			<p>Heritage can<a id="_idIndexMarker1131"/> be more daunting for implementation; the extent of configuration drift can make it hard to know where to start. Your organization could have been part of several mergers and acquisitions, which have led to not only multiple configuration standards for the core organization itself but also for anything that has <span class="No-Break">been onboarded.</span></p>
			<p>A common pattern of adoption is to progressively build up the automation levels in heritage servers to build confidence, and we will step through a common approach <span class="No-Break">to this.</span></p>
			<p>Installing an agent on all nodes to gather facts is a common starting point, and having this data stored in PuppetDB to create a valuable CMDB source. Then, as was discussed in <a href="B18492_13.xhtml#_idTextAnchor321"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, this data can be sent to services such as ServiceNow to integrate with central CMDB services. In Puppet Enterprise, this gives us access to the package view and the ability to manage patching, as was demonstrated in <a href="B18492_14.xhtml#_idTextAnchor340"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>. This rollout gives immediate capability and a better understanding of the estate without even having written <span class="No-Break">any code.</span></p>
			<p>The next step is to consider orchestration. It is likely there are common scripts and tasks performed manually or semi-automatically by various teams on the heritage estate. Taking these scripts and wrapping them in Bolt projects or Puppet modules and using Bolt or Orchestrator to run these scripts and tasks can deliver greater control and process with these scripts without having to <span class="No-Break">perform rework.</span></p>
			<p>The simplest case is if you are using Puppet Enterprise and have rolled out agents in the first step, in which case, Orchestrator can simply take advantage of the presence of the agent being deployed and use the PCP transport to communicate and take advantage of Puppet Enterprise RBAC and logging systems with Orchestrator. For open source Puppet or Puppet Enterprise users who do not want to buy licenses for heritage, a Bolt server can be used to set up a golden host with SSH keys and WinRM. There is an in-between option<a id="_idIndexMarker1132"/> of using agentless Puppet Enterprise licenses but allowing the Puppet Enterprise host to be used and to still have the RBAC and access logs. It was not discussed in previous chapters but the advantages of agent-based servers are that they are more integrated and can perform more actions and gather more data, and their approach to keys and security is managed by Puppet as part of the product. Agentless approaches can be added without the issue of having to request an agent be installed, which may not be compatible with all servers. Agentless also avoids the potential issues of vulnerabilities and updates of Puppet agent code versions but does have the issue of separate access management, such as deployment and management of <span class="No-Break">SSH keys.</span></p>
			<p>The next step is exactly what was discussed in the <em class="italic">Scope and focus </em>section: looking at a baseline configuration and ideally finding something non-negotiable to start, which must be enforced on your estate. For example, root logins must be turned off or application agents need versions to be upgraded and managed to avoid vulnerabilities. Once these straightforward configurations are managed, it is time to look at server configurations that may have historical exceptions. The difference for heritage servers is even if the pre-existing configuration of the server does not follow current security and build standards, it should first be flagged as an issue before being remediated to avoid causing potential service issues. To flag configuration issues without immediate remediation, a no-op flag pattern at a profile or module level can be used, as discussed in <a href="B18492_08.xhtml#_idTextAnchor212"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>. The configuration drift can then be understood and either accepted as exceptions, which are recorded in Hiera data, or remediated with Puppet by switching from no-op mode to execution mode to apply <span class="No-Break">the configuration.</span></p>
			<p>Once base profiles are complete, this leads to having all the tools available for automated audit reporting and compliance remediation in our <span class="No-Break">heritage estate.</span></p>
			<p>This approach can then be repeated by engaging with application teams to find their needs for configuration and auditing and following the same pattern to build out their own roles and profiles specific to <span class="No-Break">their applications.</span></p>
			<p>Having mentioned different teams involved in the development of Puppet code, it is important to directly address the best approaches to cross-team working <span class="No-Break">in Puppet.</span></p>
			<h1 id="_idParaDest-292"><a id="_idTextAnchor363"/>A platform engineering approach</h1>
			<p>As <a id="_idIndexMarker1133"/>will be clear from the first two sections of this chapter, a common adoption start of Puppet is for core base OS configuration to be created and then to reach out to application teams. This can often lead to a setup where Puppet is a tool of the Linux/Unix operating system team, who dominate the code base and are gatekeepers for the whole platform. To ensure effective cross-team working, what is required is a platform <span class="No-Break">engineering approach.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">More in-depth knowledge about how to run a platform team can be found in books and training such as <a href="https://teamtopologies.com/">https://teamtopologies.com/</a>, and platform engineering has been popularized via communities such <span class="No-Break">as </span><a href="https://platformengineering.org/"><span class="No-Break">https://platformengineering.org/</span></a><span class="No-Break">.</span></p>
			<p>The core concept of platform engineering is to have a platform team who are responsible for managing the tooling, workflows, and development of a self-service platform. This platform should be treated as a product, with its users treated as customers, ensuring their needs are met and that the platform is evangelized throughout the organization. As was discussed in <a href="B18492_01.xhtml#_idTextAnchor018"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, Puppet is likely to be part of a platform along with various other DevOps tools and workflows. <span class="No-Break"><em class="italic">Figure 15</em></span><em class="italic">.1 </em>shows a common <span class="No-Break">toolset choice:</span></p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B18492_15_01.jpg" alt="Figure 15.1 – A common DevOps toolset"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.1 – A common DevOps toolset</p>
			<p>Looking<a id="_idIndexMarker1134"/> exactly where Puppet would fit, this would likely work in a day 0, day 1, and day 2 approach, as shown in <span class="No-Break"><em class="italic">Figure 15</em></span><em class="italic">.2</em>, whereby provisioning would be done by a specialist tool such as Terraform to create the infrastructure on day 0. Then, on day 1, Puppet code would be applied to the client to configure the OS to build and security standards on the infrastructure. The day 2 Puppet role would be to continue to enforce the configuration to avoid configuration drift as unintentional external changes take place or intentional changes to standards result in <span class="No-Break">code changes.</span></p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B18492_15_02.jpg" alt="Figure 15.2 – A day 0, day 1, and day 2 approach"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 15.2 – A day 0, day 1, and day 2 approach</p>
			<p>The key point to think about Puppet code in these platforms is that, ideally, the responsibility for running the Puppet infrastructure should be part of the platform team’s role. This allows separate teams to develop their own code and roles, which they have a clear path to deploy via the <span class="No-Break">self-service platform.</span></p>
			<p>This may <a id="_idIndexMarker1135"/>not always be possible, and often, the Linux team remains running both their own code base and the Puppet infrastructure. In this case, it would be best to still see this as two separate roles and to not prioritize only the needs of the Linux team’s code base over other consumers. The platform team should not try to be a gatekeeper for everyone’s Puppet code, as this blocks developers from using Puppet as a self-service platform. The processes of your organization should cover responsibility and escalation, which will be discussed further in the next section, <em class="italic">Adoption in </em><span class="No-Break"><em class="italic">regulated environments</em></span><span class="No-Break">.</span></p>
			<p>It should also be ensured that the team responsible for managing the heritage estate takes ownership of automation efforts. Bringing in a new team to automate systems without a full understanding of them can be challenging. It may take more time to train and involve the heritage teams, but having them lead the integration efforts can result in a more thorough understanding of the systems and <span class="No-Break">their processes.</span></p>
			<p>While each team is responsible for its own code, it is important to collaboratively develop standards and best practices to ensure that teams have the knowledge to appropriately test and pipeline <span class="No-Break">their tools.</span></p>
			<p>Cross-team collaboration is not just limited to using Puppet but also includes other integration points. It is neither practical nor desirable to rewrite and run everything in Puppet. Creating communities of practice, where various teams across departments can meet, discuss, and showcase their approaches and progress toward automation can foster the exchange of ideas. In some cases, it may even be possible to reuse what others have already developed within your organization. This should not be seen as a competition but as an opportunity for mutual benefit and to exchange skills <span class="No-Break">and ideas.</span></p>
			<p>Evangelism at all levels is crucial. Attending various team meetings, lunch sessions, management meetings, and external vendor or trade body events can help spread the news about your platform and create enthusiasm for further development. External vendor events are often seen as legally complicated, but with careful consideration and consultation with your legal and marketing teams, you can increase the visibility of your platform within your organization and attract external talent by generating interest in your work. Moreover, these external events, such as technical advisory boards, are excellent opportunities to exchange best practices with <span class="No-Break">like-minded organizations.</span></p>
			<p>Although <a id="_idIndexMarker1136"/>already mentioned earlier in the <em class="italic">Scope and focus </em>section, it is worth emphasizing that you should not try to solve every problem brought to you. People will become enthusiastic if you evangelize well but it is essential to be completely honest about the capabilities and fit of your platform. You should clearly communicate what you can realistically deliver and what they can expect to have to commit if they want to onboard or engage with the <span class="No-Break">Puppet platform.</span></p>
			<p>With a scope and focus set and an understanding of collaborative working, the next major thought should be around how regulation and process can affect these ways <span class="No-Break">of working.</span></p>
			<h1 id="_idParaDest-293"><a id="_idTextAnchor364"/>Adoption in regulated environments</h1>
			<p>Working<a id="_idIndexMarker1137"/> in highly regulated environments can be challenging but it is often where Puppet can have the most significant impact. Implementing automation may be more difficult in regulated environments but it is even more challenging to perform large-scale manual actions, making the potential returns on investment significant. The worst approach when trying to adopt new technology is to believe that “the processes just need to change.” This attitude sets up the team for failure later in the process and can lead to a reputation for being sloppy and neglecting process work, resulting in a setup that will not work <span class="No-Break">in production.</span></p>
			<p>The best approach is to engage with change, risk, audit, and other teams involved in the management of processes in your organization before implementing Puppet. Often, despite regular complaints about processes in the organization, no one has engaged with these teams, and they may have their own programs to modernize to which you can align your adoption. Discussing what Puppet is and how you plan to use it in production can provide credible feedback. Even if this feedback requires scaling back your initial ambitions, it is better than treating these teams as gatekeepers, who end up with a limited understanding of your adoption and have to reject things they haven’t had a chance to understand the consequences of or influence <span class="No-Break">the approach.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Invite your process team to the community of practice sessions and demos; you are not on different sides and will find you have far more challenges and objectives in common as you try to deliver value for <span class="No-Break">the organization.</span></p>
			<p>It’s important <a id="_idIndexMarker1138"/>to frame the discussion around what Puppet can do and how your approach to development, testing, and release will work, as well as what scope it will cover. Puppet is a powerful tool that operates at the administrative/root level, so it’s crucial to demonstrate that you are in control and that any risks associated with your processes <span class="No-Break">are understood.</span></p>
			<p>To win the trust of all stakeholders, including process teams, you can show them the possibilities of Puppet and discuss how it can benefit the organization. As discussed in the section on focus and scope, iterative improvements to processes can be made, especially if they are discussed in communities of practice sessions. This way, multiple teams and departments can agree on improvements that benefit the organization as a whole without compromising security <span class="No-Break">and risk.</span></p>
			<p>This approach may not seem revolutionary, but in regulated environments, change cannot happen quickly. Therefore, it is important to focus on what can be done within the current constraints, show how your solution fits into this, and work with stakeholders to modernize or improve processes. This requires patience and consistency to win teams over. After completing the view of a traditional private data center environment, it is important to consider how this approach differs in <span class="No-Break">the cloud.</span></p>
			<h1 id="_idParaDest-294"><a id="_idTextAnchor365"/>Moving to the cloud</h1>
			<p>The move to <a id="_idIndexMarker1139"/>the public cloud has huge opportunities, particularly in terms of flexibility, with opportunities to use cloud-specific technologies to reduce the operational burden on your organization. For example, the ease of using availability zones for compilers to reduce the risk of data center failures is a complex feature to implement in private <span class="No-Break">data centers.</span></p>
			<p>Unfortunately, there <a id="_idIndexMarker1140"/>are two commonly seen anti-patterns for the cloud adoption approach. The first is a wholesale copy of all infrastructure, processes, and components as they work in the private data centers to the public cloud. This often happens with “cloud-first” programs, which tend to be a result of <strong class="bold">Chief Information Officers’ </strong>(<strong class="bold">CIOs</strong>) disappointment in the take up of public cloud resources. This <a id="_idIndexMarker1141"/>forces deployments into the public cloud before organizations are ready and understand what is a suitable fit. This results in surprise bills as the infrastructure deployed is not planned to be flexible and ignores the rental nature of the public cloud, and many of the solutions that make sense in a private data center are far better implemented in cloud-native solutions in the <span class="No-Break">public cloud.</span></p>
			<p>The second is where everything is left behind, which can be seen with application teams or departments that are frustrated with internal processes and time to delivery. They may have justification for their frustrations but rarely have the experience; sadly, the lessons hard won in private data centers are lost and good practices in audit, configuration, and testing must be rebuilt as auditors find issues with the new <span class="No-Break">fractured setup.</span></p>
			<p>You should consider what is really being done in the public cloud; when looking at how to deploy Puppet infrastructure, the multi-region patterns and tactics mentioned in <a href="B18492_13.xhtml#_idTextAnchor321"><span class="No-Break"><em class="italic">Chapter 13</em></span></a><em class="italic"> </em>show the options. Simply, we can have public cloud servers managed by Puppet infrastructure in a private data center, or the Puppet infrastructure could be migrated to the public cloud and manage both private data centers and the public cloud, or have separate Puppet infrastructure for private data centers and the <span class="No-Break">public cloud.</span></p>
			<p>This choice depends on implementation aims. Is the public cloud going to be used to provide flexible capacity for the private data centers, for example, by providing an alternate site that can be built in disaster recovery? Or is the public cloud being used to start a new way of working with a more cloud-native approach and new teams? In the first case, it is more likely you will want the configuration of servers to be the same with a shared code base, and having a single pane of glass could be advantageous for the team’s managing infrastructure. In this case, deciding whether the infrastructure should be located privately or publicly will come down to cost and whether you intend to take advantage of cloud-native features such as the flexibility of availability sets and load balancers, which could allow compilers to be added <span class="No-Break">on demand.</span></p>
			<p>In the second case, where a fresh start with new teams looking for a new approach is being made, having a separate infrastructure will make the most sense, reviewing what is useful in the current build and what is only relevant to the private data center. As was addressed in the <em class="italic">a platform engineering approach </em>section, this involves finding out the requirements of the teams working in the cloud and ensuring Puppet is used as part of a platform <a id="_idIndexMarker1142"/>to meet these needs. The cloud teams should then be able to use the APIs to self-service while gaining the advantage of Puppet providing the audit and security requirements of your organization in <span class="No-Break">the cloud.</span></p>
			<p>It can also be an opportunity to move from heavily customized standards used in the traditional organization and even consider adopting compliance to implement CIS standards, which was mentioned in <a href="B18492_14.xhtml#_idTextAnchor340"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>. This will be a cost consideration as to whether it makes sense to have your own team maintaining <span class="No-Break">these standards.</span></p>
			<h1 id="_idParaDest-295"><a id="_idTextAnchor366"/>Summary</h1>
			<p>In this chapter, we discussed how to look beyond just pure technology consideration and make the adoption of Puppet a success. We reviewed how to choose a focus and scope to allow Puppet to be delivered in iterations of continuous improvement, using a regular delivery cadence and methods such as sprints with a small focus for the team to work together on. We talked about breaking down this focus into deliverables that can be collaboratively worked on and demoed on a regular cycle. We also covered allowing the Puppet team to build confidence and learn as decisions are made together and coding practice is established while showing meaningful returns and progress to management and stakeholders. We discussed how the use cases of Puppet should be outlined and ensure that the temptation to maximize the return from Puppet does not result in unsuited tasks trying to be shoehorned in, which can destabilize the reliability and performance of the Puppet infrastructure and give general <span class="No-Break">maintenance headaches.</span></p>
			<p>The approach to adopting a heritage estate was then reviewed showing how even with estates fractured by changes in standards and strategies as well as company mergers and acquisitions, can follow a progressive adoption pattern to slowly reduce configuration drift over time and gather information about <span class="No-Break">the estate.</span></p>
			<p>We looked at rolling out an agent with no configuration first and gathering facts to create an asset view, which could feed into a CMDB and, in the case of Puppet Enterprise, using built-in integrations to manage patching and packaging. We then showed that orchestration could be considered to wrap up current scripts and give better automation. This could be done using fully licensed Puppet Enterprise via PCP or WinRM/SSH connections on an agentless license in Puppet Enterprise, or using a Bolt server with WinRM/SSH connections. This would depend on your license considerations and the need for RBAC and logging. We then covered forming a baseline of stateful Puppet code looking for mandatory settings to enforce and using no-op where appropriate to get a current view of the estate, slowly building a profile where exceptions could be accepted into Hiera or drift could be remediated. Having established this baseline, we discussed repeating this process with application teams to bring heritage applications under control and then use the configuration data to automate <span class="No-Break">audit reporting.</span></p>
			<p>We discussed how to work across multiple teams, establishing a Puppet platform team that championed the platform and provided APIs and self-service to teams, setting standards for teams to adopt and use Puppet well, but not gatekeeping <span class="No-Break">their delivery.</span></p>
			<p>Deployment into regulated environments was shown to be something that worked well with Puppet by communicating how Puppet worked to key process teams, such as change and risk management, and addressing the processes your implementation would use to develop and deploy code into production while taking on board how best to integrate with the current process. Winning the confidence of the process stakeholders and operation teams can lead to changing processes in the future to <span class="No-Break">further automation.</span></p>
			<p>Finally, public cloud adoption was reviewed, discussing two of the biggest issues suffered in the public cloud with either a <em class="italic">cloud-first</em> policy resulting in a poorly thought out lift and shift of technology and process, or application teams going it alone and forgetting the lessons of automation for security and audit made in private data centers. We explained that you should consider the purpose of your public cloud. Is it an extension of the data center and something you would want to be brought into view of an in-house Puppet server, something you are moving to? Moving Puppet infrastructure into the public cloud can be something that starts to adopt the flexibility of the cloud. Is it something different with a new approach and an opportunity to take new Puppet infrastructure with code optimized for cloud adoption or taken from compliance as old customized in-house standards can be left for industry-standard CIS approaches? The key action was shown to be meeting application teams and ensuring the APIs and platform approach is available to them so they do not worry about core infrastructure build and security configuration but only what is useful to them and that they should be able to manage via <span class="No-Break">self service.</span></p>
			<p>Throughout this book, it has been shown how Puppet’s stateful approach can reduce drift and technical debt, automating audit reporting and giving a standard way to deliver change, even in heavily regulated environments, and providing a platform that users can trust to meet their infrastructure requirements and freeing up teams to work on delivering their products to customers. Configuration management is a complex problem with no silver bullet solutions but we have shown with a considered iterative approach how, by working with the processes of your organization and involving everyone, Puppet can bring transformational change to <span class="No-Break">your organization.</span></p>
		</div>
	</body></html>