<html><head></head><body>
		<div id="_idContainer187">
			<h1 id="_idParaDest-196" class="chapter-number"><a id="_idTextAnchor231"/><st c="0">12</st></h1>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor232"/><st c="3">Looking Ahead with Copilots, ChatOps, and AI-Infused Applications</st></h1>
			<p><st c="69">We are currently living in times wherein building applications augmented with </st><strong class="bold"><st c="148">a</st></strong><strong class="bold"><st c="149">rtificial intelligence</st></strong><st c="171"> (</st><strong class="bold"><st c="173">AI</st></strong><st c="175">) has</st><a id="_idIndexMarker1485"/><st c="181"> become very straightforward. </st><st c="211">The ability to plug in </st><strong class="bold"><st c="234">l</st></strong><strong class="bold"><st c="235">arge </st></strong><strong class="bold"><st c="240">l</st></strong><strong class="bold"><st c="241">anguage </st></strong><strong class="bold"><st c="249">m</st></strong><strong class="bold"><st c="250">odels</st></strong><st c="255"> (</st><strong class="bold"><st c="257">LLMs</st></strong><st c="261">) to</st><a id="_idIndexMarker1486"/><st c="266"> our applications and enrich them with AI is unlocking new options and allowing organizations to innovate and redefine their business processes. </st><st c="411">This chapter will close this book by talking about the AI-infused low-code/no-code development approach. </st><st c="516">With the introduction of LLMs, such as OpenAI’s </st><strong class="bold"><st c="564">Generative Pre-trained Transformer</st></strong><st c="598"> (</st><strong class="bold"><st c="600">GPT</st></strong><st c="603">) models, we </st><a id="_idIndexMarker1487"/><st c="617">have seen a massive shift in the tools that help makers and developers be more productive with their work and achieve outcomes faster. </st><st c="752">Microsoft Copilot is infusing AI into every Microsoft product, which helps makers and developers build even more apps with the no-code approach by using natural language to describe the desired state. </st><st c="953">We will dive into Copilot for Power Platform and how Copilot can be used across Power Platform products. </st><st c="1058">We will look at the capabilities of AI Builder and understand how to extend Power Platform’s capabilities with the Azure OpenAI models through the use of custom connectors. </st><st c="1231">The chapter will finish with a discussion of ChatOps. </st><st c="1285">We will look at how it can enrich existing DevOps processes and how we can use Copilot Studio to help us implement ChatOps in </st><span class="No-Break"><st c="1411">the organization.</st></span></p>
			<p><st c="1428">We will cover the following </st><span class="No-Break"><st c="1457">main topics:</st></span></p>
			<ul>
				<li><st c="1469">The era of AI and the rise </st><span class="No-Break"><st c="1497">of GPTs</st></span></li>
				<li><st c="1504">Microsoft Copilot and Copilot in </st><span class="No-Break"><st c="1538">Power Platform</st></span></li>
				<li><st c="1552">Copilot usage from the perspective of </st><span class="No-Break"><st c="1591">a maker</st></span></li>
				<li><st c="1598">Extending business solutions with AI Builder and </st><span class="No-Break"><st c="1648">Azure OpenAI</st></span></li>
				<li><st c="1660">ChatOps and </st><span class="No-Break"><st c="1673">Copilot Studio</st></span></li>
			</ul>
			<h1 id="_idParaDest-198"><a id="_idTextAnchor233"/><st c="1687">Technical requirements</st></h1>
			<p><st c="1710">To follow along this chapter, we recommend having these requirements </st><span class="No-Break"><st c="1780">in place:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="1789">A Power Platform subscription</st></strong><st c="1819">: We can sign up for a Power Platform development plan (</st><a href="https://powerapps.microsoft.com/en-us/developerplan/"><st c="1876">https://powerapps.microsoft.com/en-us/developerplan/</st></a><st c="1929">), if we already have a Microsoft Entra ID work account, or we can join the Microsoft 365 developer </st><span class="No-Break"><st c="2030">program (</st></span><a href="https://developer.microsoft.com/en-us/microsoft-365/dev-program"><span class="No-Break"><st c="2039">https://developer.microsoft.com/en-us/microsoft-365/dev-program</st></span></a><span class="No-Break"><st c="2103">).</st></span></li>
				<li><strong class="bold"><st c="2106">An Azure subscription</st></strong><st c="2128">: We can provision a free Azure account following the guidance at </st><a href="https://azure.microsoft.com/en-us/free"><st c="2195">https://azure.microsoft.com/en-us/free</st></a><st c="2233">. Once provisioned, the Azure portal can be accessed </st><span class="No-Break"><st c="2286">at </st></span><a href="https://portal.azure.com/"><span class="No-Break"><st c="2289">https://portal.azure.com/</st></span></a><span class="No-Break"><st c="2314">.</st></span></li>
				<li><strong class="bold"><st c="2315">An Azure DevOps Services organization</st></strong><st c="2353">: We can create a DevOps organization any time for </st><span class="No-Break"><st c="2405">free (</st></span><a href="https://learn.microsoft.com/en-us/azure/devops/user-guide/sign-up-invite-teammates"><span class="No-Break"><st c="2411">https://learn.microsoft.com/en-us/azure/devops/user-guide/sign-up-invite-teammates</st></span></a><span class="No-Break"><st c="2494">).</st></span></li>
				<li><strong class="bold"><st c="2497">A GitHub handle and a repository</st></strong><st c="2530">: As an alternative to creating a DevOps organization, we can sign up for a free account (</st><a href="https://github.com/signup"><st c="2621">https://github.com/signup</st></a><st c="2647">). </st><st c="2651">For access to GitHub Enterprise Cloud we can obtain a 30-day </st><span class="No-Break"><st c="2712">trial (</st></span><a href="mailto:https://docs.github.com/en/enterprise-cloud@latest/admin/overview/setting-up-a-trial-of-github-enterprise-cloud"><span class="No-Break"><st c="2719">https://docs.github.com/en/enterprise-cloud@latest/admin/overview/setting-up-a-trial-of-github-enterprise-cloud</st></span></a><span class="No-Break"><st c="2831">).</st></span></li>
				<li><strong class="bold"><st c="2834">A Microsoft 365 or Teams license</st></strong><st c="2867">: To get access to Teams, a Microsoft 365 trial license or Teams license is required. </st><st c="2954">We can use Teams </st><span class="No-Break"><st c="2971">exploratory (</st></span><a href="https://learn.microsoft.com/en-us/microsoftteams/teams-exploratory"><span class="No-Break"><st c="2984">https://learn.microsoft.com/en-us/microsoftteams/teams-exploratory</st></span></a><span class="No-Break"><st c="3051">).</st></span></li>
				<li><strong class="bold"><st c="3054">Visual Studio Code</st></strong><st c="3073">: You could use another IDE or text editing tool of </st><span class="No-Break"><st c="3126">choice instead.</st></span></li>
			</ul>
			<h1 id="_idParaDest-199"><a id="_idTextAnchor234"/><st c="3141">The era of AI and the rise of GPTs</st></h1>
			<p><st c="3176">This section will</st><a id="_idIndexMarker1488"/><st c="3194"> provide a helicopter view of how we came to this point in time where innovation with AI has almost become a commodity. </st><st c="3314">We will explore the GPTs that have shaken the world and made a huge impact on society and global industries. </st><st c="3423">Now, app makers can even use these </st><a id="_idIndexMarker1489"/><st c="3458">GPT models in business solutions across Power Platform services, but we will come to that later. </st><st c="3555">Let’s first start at </st><span class="No-Break"><st c="3576">the beginning.</st></span></p>
			<p><st c="3590">GPTs have been on the market for some time already. </st><st c="3643">They have disrupted the market and brought some fear to people, but they have also brought new ideas for innovation. </st><st c="3760">Since everyone can access these models, anyone can innovate and build inspiring solutions using AI. </st><st c="3860">This means that the competitive advantage when using AI that’s built using publicly available LLMs has decreased. </st><st c="3974">This pushes companies to be innovative with ideas on how to use this new technology in their business processes. </st><st c="4087">However, like with any project, in AI infused projects too, how fast we can bring a reliable and secure solution to the market is very important. </st><st c="4233">Here is where innovation and development should follow DevSecOps processes that allow organizations to bring reliable solutions to </st><span class="No-Break"><st c="4364">the market.</st></span></p>
			<p><st c="4375">In order to understand the current situation, we need to go back </st><span class="No-Break"><st c="4441">in time.</st></span></p>
			<h2 id="_idParaDest-200"><a id="_idTextAnchor235"/><st c="4449">Introduction to AI</st></h2>
			<p><st c="4468">AI is an intelligent </st><a id="_idIndexMarker1490"/><st c="4490">computer system that uses mathematical algorithms and statistical models to simulate human thinking when analyzing data in order to </st><span class="No-Break"><st c="4622">make decisions.</st></span></p>
			<p><st c="4637">In 1955, computer scientist John McCarthy came up with the term AI. </st><st c="4706">This term describes the concept of machines that can exhibit human-like intelligence. </st><st c="4792">However, the origins of AI date even further back. </st><st c="4843">In 1940, Alan Turing created a machine learning algorithm that was</st><a id="_idIndexMarker1491"/><st c="4909"> used to crack the Enigma code. </st><st c="4941">This led to the creation of the </st><strong class="bold"><st c="4973">Turing test</st></strong><st c="4984"> later in 1950. </st><st c="5000">This test is used to determine whether a machine can mimic human intelligence under specific conditions. </st><st c="5105">After so many years, AI experts now debate whether the Turing test is still relevant due to the advancements in AI models and natural </st><span class="No-Break"><st c="5239">language understanding.</st></span></p>
			<p><st c="5262">Described in a simple way, behind artificial intelligence is a computer science and engineering fields that create various algorithms that power these AI systems. </st><st c="5426">Algorithms are described as a set of rules and programmed instructions that an AI system follows to process and analyze data. </st><st c="5552">These algorithms can be used for things such as sentiment analysis, object detection, and more. </st><st c="5648">AI models follow algorithms and have been taught on a large dataset with representative data in order to make use of these algorithms and solve specific tasks </st><span class="No-Break"><st c="5807">or problems.</st></span></p>
			<p><st c="5819">Once an AI model is trained on representative data, it understands the relationships in data, which allows it to apply the learning with new, unknown data. </st><st c="5976">A well-known practice for such an approach to training AI is </st><a id="_idIndexMarker1492"/><st c="6037">in </st><strong class="bold"><st c="6040">machine learning</st></strong><st c="6056">. More data and diverse data that we use to train it, the better the trained model will be. </st><st c="6148">For example, training object detection model with more images of an object and providing exact information about each picture, will lead to better results of </st><span class="No-Break"><st c="6306">such model.</st></span></p>
			<p><st c="6317">AI enables computer systems to perform task that find its use in many applications. </st><st c="6402">Through </st><strong class="bold"><st c="6410">n</st></strong><strong class="bold"><st c="6411">atural </st></strong><strong class="bold"><st c="6418">l</st></strong><strong class="bold"><st c="6419">anguage </st></strong><strong class="bold"><st c="6427">p</st></strong><strong class="bold"><st c="6428">rocessing</st></strong><st c="6437"> (</st><strong class="bold"><st c="6439">NLP</st></strong><st c="6442">), a subfield of machine learning, systems can </st><a id="_idIndexMarker1493"/><st c="6490">now understand human language and perform operations such as language detection, language translation, and sentiment analysis over a text. </st><st c="6629">Expanding this with voice, Microsoft claims that they reached human parity in conversational speech recognition back in 2016. </st><st c="6755">By adding computer vision, machines are even able, with the support of AI, to understand </st><span class="No-Break"><st c="6844">visual objects.</st></span></p>
			<p><st c="6859">There are also other subsets of machine</st><a id="_idIndexMarker1494"/><st c="6899"> learning, such as </st><strong class="bold"><st c="6918">reinforcement learning</st></strong><st c="6940"> and, going even</st><a id="_idIndexMarker1495"/><st c="6956"> further, </st><strong class="bold"><st c="6966">neural networks</st></strong><st c="6981">. Neural networks are a model which is inspired by the way human brains function. </st><st c="7063">Neural networks consist of neurons, which are interconnected nodes that are grouped in layers. </st><st c="7158">Neurons receive an input, which is used in the computational function to determine to which neuron in the next layer the data will be sent. </st><st c="7298">Neural</st><a id="_idIndexMarker1496"/><st c="7304"> networks can be used for very complex </st><span class="No-Break"><st c="7343">data relationships.</st></span></p>
			<p><st c="7362">One might ask why we are talking about all of these models. </st><st c="7423">Well, this is where GPT </st><span class="No-Break"><st c="7447">comes in.</st></span></p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor236"/><st c="7456">GPTs</st></h2>
			<p><st c="7461">AI advancements in the </st><a id="_idIndexMarker1497"/><st c="7485">last few years have brought us generative AI. </st><st c="7531">Generative AI</st><a id="_idIndexMarker1498"/><st c="7544"> is a type of AI that uses LLMs. </st><st c="7577">Generative AIs are capable of responding to prompts by generating new content with text, image, speech, or even video. </st><st c="7696">There are many LLMs available; however, one of the most recognizable is GPT due to the popularity of </st><a id="_idIndexMarker1499"/><st c="7797">OpenAI’s </st><strong class="bold"><st c="7806">ChatGPT</st></strong><st c="7813">. It is always fascinating to see how much time certain technology needs to reach 100 million monthly average users. </st><st c="7930">It only took </st><a id="_idIndexMarker1500"/><st c="7943">ChatGPT two months to reach 100 million monthly average users. </st><st c="8006">This also shows how new innovative solutions are reducing the time needed to hit this </st><span class="No-Break"><st c="8092">big milestone.</st></span></p>
			<p><st c="8106">GPTs are part of LLMs or text-generation models that are capable of producing new content (hence, </st><em class="italic"><st c="8205">generative</st></em><st c="8215">), have been trained on a large dataset (hence, </st><em class="italic"><st c="8264">pre-trained</st></em><st c="8275">), and use neural networks to process the input request and provide output (</st><span class="No-Break"><st c="8352">hence, </st></span><span class="No-Break"><em class="italic"><st c="8360">transformer</st></em></span><span class="No-Break"><st c="8371">).</st></span></p>
			<p><st c="8374">As mentioned earlier, many LLMs are available, including those that are made available to open source communities. </st><st c="8490">Currently, the most well-known and popular GPTs include OpenAI’s GPTs. </st><st c="8561">OpenAI has also other models available that serve their own purposes. </st><st c="8631">With each new version of a given GPT, we can see it become more sophisticated and knowledgeable. </st><st c="8728">In May 2024, OpenAI </st><a id="_idIndexMarker1501"/><st c="8748">introduced </st><strong class="bold"><st c="8759">GPT-4o</st></strong><st c="8765">, also</st><a id="_idIndexMarker1502"/><st c="8771"> known as </st><strong class="bold"><st c="8781">omni</st></strong><st c="8785">, which is a multimodal model that accepts both text and images as inputs and can produce text as output. </st><st c="8891">During the announcement, OpenAI highlighted how the new GPT-4o model is able to interact with the users through audio, visual, and text. </st><st c="9028">OpenAI also presented a new model that is able </st><a id="_idIndexMarker1503"/><st c="9075">to turn text into a </st><a id="_idIndexMarker1504"/><st c="9095">video, called </st><strong class="bold"><st c="9109">OpenAI Sora</st></strong><st c="9120">, in </st><span class="No-Break"><st c="9125">February 2024.</st></span></p>
			<p><st c="9139">Other models that are currently already available include </st><span class="No-Break"><st c="9198">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="9212">GPT-4 Turbo</st></strong><st c="9224">, </st><strong class="bold"><st c="9226">GPT-4</st></strong><st c="9231">, and </st><strong class="bold"><st c="9237">GPT-3.5 Turbo</st></strong><st c="9250"> are</st><a id="_idIndexMarker1505"/><st c="9254"> models that</st><a id="_idIndexMarker1506"/><st c="9266"> can </st><a id="_idIndexMarker1507"/><st c="9271">understand instructions in natural language and generate outputs in natural language </st><span class="No-Break"><st c="9356">or code</st></span></li>
				<li><strong class="bold"><st c="9363">DALL-E</st></strong><st c="9370"> (text to image) is</st><a id="_idIndexMarker1508"/><st c="9389"> a model for generating images with a provided natural </st><span class="No-Break"><st c="9444">language instruction</st></span></li>
				<li><strong class="bold"><st c="9464">Whisper</st></strong><st c="9472"> is a model </st><a id="_idIndexMarker1509"/><st c="9484">that converts audio </st><span class="No-Break"><st c="9504">into text</st></span></li>
			</ul>
			<p><st c="9513">Although LLMs have paved the way for generative AI, we also see the emergence of small language models. </st><st c="9618">These are much smaller in size due to small training data sizes but are capable of running locally on devices, which opens the door to new innovation ideas </st><span class="No-Break"><st c="9774">for organizations.</st></span></p>
			<p><st c="9792">AI models require components such as data, AI algorithms or models, and extensive computational capacity for their operation. </st><st c="9919">Microsoft has formed a partnership with OpenAI and opened up Microsoft Azure Cloud for OpenAI to leverage computational power for the research and development of new models. </st><st c="10093">In return, the partnership specifies that OpenAI GPT models are exclusively available on Microsoft platforms. </st><st c="10203">They are available for consumption as part of the Azure OpenAI service. </st><st c="10275">This allows customers who are either already using Azure or would like to do so to use a secure and compliant platform to build secure enterprise applications utilizing AI capabilities. </st><st c="10461">The partnership enables Microsoft to integrate OpenAI LLMs into their own products and build new functionalities that help boost user productivity. </st><st c="10609">A good example of such a product is GitHub Copilot, which </st><a id="_idIndexMarker1510"/><st c="10667">acts like an AI pair programmer. </st><st c="10700">It helps developers understand and produce code while using IDEs such as Visual Studio, Visual Studio Code, JetBrains IDEs, and Neovim. </st><st c="10836">Another example of such collaboration is the various copilots for Microsoft </st><a id="_idIndexMarker1511"/><st c="10912">products and services, which integrate into various tools and enrich the user experience by helping users achieve results faster and </st><span class="No-Break"><st c="11045">more effectively.</st></span></p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor237"/><st c="11062">Responsible AI</st></h2>
			<p><st c="11077">With the advancements</st><a id="_idIndexMarker1512"/><st c="11099"> in AI, concerns about its potential misuse have become valid. </st><st c="11162">Therefore, the responsible use of AI is imperative. </st><st c="11214">Microsoft, as well as other companies, communities, and individuals, has recognized this and has begun taking an active share to advocate for the need for responsible use. </st><st c="11386">Microsoft has made significant investments internally to make sure its AI systems are designed with responsibility </st><span class="No-Break"><st c="11501">in mind.</st></span></p>
			<p><st c="11509">Microsoft has made</st><a id="_idIndexMarker1513"/><st c="11528"> its </st><strong class="bold"><st c="11533">responsible AI standard</st></strong><st c="11556">, which lays down practical guidance on how to ensure organizations use AI responsibly. </st><st c="11644">It is defined by six responsible AI principles that will guide</st><a id="_idIndexMarker1514"/><st c="11706"> AI development </st><span class="No-Break"><st c="11722">and use:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="11730">Fairness</st></strong><st c="11739">: AI systems should treat all people equally, without bias </st><span class="No-Break"><st c="11799">or discrimination</st></span></li>
				<li><strong class="bold"><st c="11816">Reliability and safety</st></strong><st c="11839">: AI systems should perform reliably and prioritize safety in order to prevent </st><span class="No-Break"><st c="11919">undesired consequences</st></span></li>
				<li><strong class="bold"><st c="11941">Privacy and security</st></strong><st c="11962">: AI systems should be secure and maintain privacy by protecting </st><span class="No-Break"><st c="12028">user data</st></span></li>
				<li><strong class="bold"><st c="12037">Inclusiveness</st></strong><st c="12051">: AI systems should engage a wide range of users and be inclusive by considering </st><span class="No-Break"><st c="12133">diverse perspectives</st></span></li>
				<li><strong class="bold"><st c="12153">Transparency</st></strong><st c="12166">: AI decisions and processes should be understandable, with clear explanations in order to </st><span class="No-Break"><st c="12258">improve trust</st></span></li>
				<li><strong class="bold"><st c="12271">Accountability</st></strong><st c="12286">: Developers </st><a id="_idIndexMarker1515"/><st c="12300">and organizations should be held accountable for the developed </st><span class="No-Break"><st c="12363">AI systems</st></span></li>
			</ul>
			<p><st c="12373">Apart from the responsible AI principles, we should ensure that AI systems are developed in a compliant and governed way in order to be compliant with local regulatory requirements. </st><st c="12556">Microsoft also went a step further and implemented a five-point blueprint that focuses on governing AI. </st><st c="12660">These are the principles that make sure that AI is used responsibly and in compliance with government AI safety standards. </st><st c="12783">They also ensure that we maintain control over AI systems so they can be </st><span class="No-Break"><st c="12856">used safely.</st></span></p>
			<p><st c="12868">Microsoft has integrated</st><a id="_idIndexMarker1516"/><st c="12893"> responsible AI practices not just into the copilots but also into other tools and the culture of people. </st><st c="12999">They have done this to promote the safe and responsible use </st><span class="No-Break"><st c="13059">of AI.</st></span></p>
			<h1 id="_idParaDest-203"><a id="_idTextAnchor238"/><st c="13065">Microsoft Copilots and Copilots in Power Platform</st></h1>
			<p><st c="13115">Microsoft has placed copilots</st><a id="_idIndexMarker1517"/><st c="13145"> in many Microsoft products for enabling different scenarios. </st><st c="13207">This section will start with explaining what a copilot is, then go through explaining what some of the available copilots are and how they can be used. </st><st c="13359">We will then focus on understanding the capabilities of copilots in </st><span class="No-Break"><st c="13427">Power Platform.</st></span></p>
			<p><st c="13442">Microsoft uses the term copilot to describe an AI assistant that is capable of retrieving information and performing specific tasks such as summarization and content generation. </st><st c="13621">Copilots utilize LLMs, such as OpenAI’s GPT model, to respond to user prompts. </st><st c="13700">Not all copilots behave the same way. </st><st c="13738">Some copilots are more generic, such as Microsoft Copilot, while others are product-specific, such as </st><strong class="bold"><st c="13840">Copilots for Microsoft 365</st></strong><st c="13866"> or </st><strong class="bold"><st c="13870">Copilot for Power Platform</st></strong><st c="13896">. These </st><a id="_idIndexMarker1518"/><st c="13904">copilots operate within the context of a specific </st><a id="_idIndexMarker1519"/><st c="13954">product and are aware of the data and operations that are available in the </st><span class="No-Break"><st c="14029">specific product.</st></span></p>
			<p><st c="14046">All these copilots share a common conversational chat experience with users. </st><st c="14124">However, when we look at the copilots, we can see that some copilots are integrated into the product itself and that their main task is to support users to be more productive while using a specific product, such as copilots in Power Platform. </st><st c="14367">Other copilots are also product-specific, such as Copilot for Microsoft 365 or Copilot for Sales, and they come with a standard set of functionalities that includes a copilot component, but they can also be extensible with the support of Copilot Studio. </st><st c="14621">The last group of copilots would be custom copilots, which a user can build by themself on either Copilot Studio or using Azure AI services and </st><a id="_idIndexMarker1520"/><st c="14765">expose through different channels for </st><span class="No-Break"><st c="14803">user consumption.</st></span></p>
			<p><st c="14820">Examples of copilots include </st><span class="No-Break"><st c="14850">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="14864">Microsoft Copilot</st></strong><st c="14882">: This uses</st><a id="_idIndexMarker1521"/><st c="14894"> OpenAI LLMs to provide responses to a user’s prompt in a chat-like experience. </st><st c="14974">It can search for a result across the web and can summarize responses to a specific question while providing links to relevant </st><span class="No-Break"><st c="15101">content sources.</st></span></li>
				<li><strong class="bold"><st c="15117">Copilot for Microsoft 365</st></strong><st c="15143">: This </st><a id="_idIndexMarker1522"/><st c="15151">generates responses anchored in organizational data that a user has access to. </st><st c="15230">It utilizes Microsoft Graph and LLMs and is integrated within Microsoft 365 suite (Word, Excel, Teams, and so on) and aims to improve </st><span class="No-Break"><st c="15364">personal productivity.</st></span></li>
				<li><strong class="bold"><st c="15386">GitHub Copilot</st></strong><st c="15401">: This is an </st><a id="_idIndexMarker1523"/><st c="15415">AI pair programmer or code completion tool that helps developers during the SDLC. </st><st c="15497">It is grounded around coding-related topics, so it can provide code suggestions, explain code, build unit tests, </st><span class="No-Break"><st c="15610">and more.</st></span></li>
			</ul>
			<h2 id="_idParaDest-204"><a id="_idTextAnchor239"/><st c="15619">Copilots in Power Platform</st></h2>
			<p><st c="15646">AI in Power </st><a id="_idIndexMarker1524"/><st c="15659">Platform has been present for a few years now. </st><st c="15706">In 2019, AI Builder</st><a id="_idIndexMarker1525"/><st c="15725"> was introduced in Power Platform, which helped incorporate AI models into the business process and enrich apps and flows. </st><st c="15848">In 2021, a capability to turn natural language prompts to Power Fx functions was introduced in Power Apps. </st><st c="15955">Since then, new AI capabilities have come to Power Platform </st><span class="No-Break"><st c="16015">each year.</st></span></p>
			<p><st c="16025">Enabling copilots in Power Platform brings the platform closer to no-code development with assistance from AI. </st><st c="16137">This means that no matter whether we are pro-developers, low-code app makers, or people who are just learning to work with Power Platform, copilots in Power Platform will provide us with the ability to use natural language in order to generate meaningful business-oriented solutions. </st><st c="16421">This helps makers and organizations save time and </st><span class="No-Break"><st c="16471">boost productivity.</st></span></p>
			<p><st c="16490">Each product in the Power Platform family includes its own copilot. </st><st c="16559">These copilots act as AI assistants that hold product-specific capabilities that can be used as a maker or as a user of the business solution built on </st><span class="No-Break"><st c="16710">Power Platform.</st></span></p>
			<p><st c="16725">Copilots are integrated into the product and always share the product’s main screen, which makes it </st><a id="_idIndexMarker1526"/><st c="16826">convenient</st><a id="_idIndexMarker1527"/><st c="16836"> for makers or users to be more productive while working on the solution as it does not require them to leave the context of </st><span class="No-Break"><st c="16961">the work:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="16970">Copilot in Power Apps</st></strong><st c="16992">: This enables</st><a id="_idIndexMarker1528"/><st c="17007"> makers to build new or edit existing applications by using natural language descriptions and write or understand the Power Fx functions. </st><st c="17145">As a user, we can use the copilot component in the app that allows us to get answers about the data used in </st><span class="No-Break"><st c="17253">the application.</st></span></li>
				<li><strong class="bold"><st c="17269">Copilot in Power Automate</st></strong><st c="17295">: Using </st><a id="_idIndexMarker1529"/><st c="17304">this, makers can create new flows with the needed connectors to support problem descriptions in natural language. </st><st c="17418">We can also alter existing flows and get inspiration for business processes. </st><st c="17495">Soon, we will be able to build AI flows where LLMs will create dynamic automation flows and, utilizing multimodal models through voice record instructions, build Power Automate desktop flows. </st><st c="17687">Users are able to get insights into the processes and flows analyzed by Power Automate </st><span class="No-Break"><st c="17774">Process Mining.</st></span></li>
				<li><strong class="bold"><st c="17789">Copilot in Copilot Studio</st></strong><st c="17815">: Makers</st><a id="_idIndexMarker1530"/><st c="17824"> can create new custom copilots with a conversational builder, as well as create and alter topics using </st><span class="No-Break"><st c="17928">natural language.</st></span></li>
				<li><strong class="bold"><st c="17945">Copilot in Power Pages</st></strong><st c="17968">: This</st><a id="_idIndexMarker1531"/><st c="17975"> facilitates the creation of external websites and pages, allowing us to add forms, text content, and AI-generated code using a natural language chat interface. </st><st c="18136">Users can leverage a custom copilot chat experience and a GenAI-enriched search experience reasoned over </st><span class="No-Break"><st c="18241">search results.</st></span></li>
				<li><strong class="bold"><st c="18256">Copilot for Power BI</st></strong><st c="18277">: This</st><a id="_idIndexMarker1532"/><st c="18284"> helps build report pages across cloud services and Power BI Desktop. </st><st c="18354">As users, we can get answers to questions about the data in the model, get a summarization of the reports, </st><span class="No-Break"><st c="18461">and more.</st></span></li>
			</ul>
			<p class="callout-heading"><st c="18470">Copilots in Power Platform – preview capabilities</st></p>
			<p class="callout"><st c="18520">It is important to note that some of the copilots’ capabilities in Power Platform are in preview. </st><st c="18619">These are not meant for production use. </st><st c="18659">In order to access them, we might need to have our environment </st><a id="_idIndexMarker1533"/><st c="18722">set to </st><strong class="bold"><st c="18729">early release cycle</st></strong><st c="18748"> (</st><a href="https://learn.microsoft.com/en-gb/power-platform/admin/early-release"><st c="18750">https://learn.microsoft.com/en-gb/power-platform/admin/early-release</st></a><st c="18818">). </st><st c="18822">We can use sandbox environments using a </st><strong class="bold"><st c="18862">preview URL</st></strong><st c="18873"> (Power Apps: </st><a href="https://make.preview.powerapps.com/"><st c="18887">https://make.preview.powerapps.com/</st></a><st c="18922">) or by enabling </st><strong class="bold"><st c="18940">Try the new data experience</st></strong><st c="18967"> in the Power Apps </st><span class="No-Break"><st c="18986">home screen.</st></span></p>
			<p><st c="18998">Some of the </st><a id="_idIndexMarker1534"/><st c="19011">copilots’ configuration settings can be turned on or </st><a id="_idIndexMarker1535"/><st c="19064">off in </st><strong class="bold"><st c="19071">Power Platform admin center</st></strong><st c="19098"> | </st><strong class="bold"><st c="19101">Settings</st></strong><st c="19109">. Under </st><strong class="bold"><st c="19117">Tenant settings</st></strong><st c="19132">, we can find configuration settings that we can enable or disable based on the organi</st><a id="_idTextAnchor240"/><st c="19218">zation’s policy, as can be seen in </st><span class="No-Break"><em class="italic"><st c="19254">Figure 12</st></em></span><span class="No-Break"><em class="italic"><st c="19263">.1</st></em></span><span class="No-Break"><st c="19265">:</st></span></p>
			<div>
				<div id="_idContainer166" class="IMG---Figure">
					<img src="image/B22208_12_1.jpg" alt="" role="presentation"/><st c="19267"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="19954">Figure 12.1 – Enabling or disabling copilots in Power Platform</st></p>
			<p><st c="20016">Some of these</st><a id="_idIndexMarker1536"/><st c="20030"> settings </st><a id="_idIndexMarker1537"/><st c="20040">include capabilities such as enabling data collection, an ability for users to send feedback, and abilities to enable or disable copilot preview features in </st><span class="No-Break"><st c="20197">Power Apps.</st></span></p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor241"/><st c="20208">Copilots’ usage from the perspective of a maker</st></h1>
			<p><st c="20256">In this section, we </st><a id="_idIndexMarker1538"/><st c="20277">will take a look at how copilots in Power Platform can be used to generate Power Apps canvas applications with data tables on Dataverse and supported by flows in Power Automate. </st><st c="20455">This demonstrates how AI is helping app makers get additional support during the low-code development with copilots and shift toward a </st><span class="No-Break"><st c="20590">no-code approach.</st></span></p>
			<p><st c="20607">One of the benefits that using copilots in Power Platform provides is that such an approach enables makers to build prototypes of solutions much faster. </st><st c="20761">This is because prototypes do not need to have all the functionalities of an application up and running, but are there to provide a look and feel of the idea. </st><st c="20920">With the help of copilots in the Power Platform app, makers can build mockups of an application or flow using natural language descriptions and quickly validate the feasibility of the idea for a business application. </st><st c="21137">For each step of the provided suggestions, we can revert the changes made by Copilot by clicking the </st><strong class="bold"><st c="21238">Undo</st></strong><st c="21242"> button. </st><st c="21251">This makes it easy to test ideas and revert back in case we are not satisfied with the </st><span class="No-Break"><st c="21338">suggested work.</st></span></p>
			<p><st c="21353">Copilots in Power Platform all have the same user experience. </st><st c="21416">On the home screen of the service, we can find a big text input component, which allows us to add descriptions of what we would like to do. </st><st c="21556">Prompts that we write to the copilot should be clear and specific, as this will help it return more relevant results for the ask. </st><st c="21686">In order to achieve better results using copilots, we should provide more details on the context of the ask or, if needed, provide some examples of how something should </st><span class="No-Break"><st c="21855">be achieved:</st></span></p>
			<div>
				<div id="_idContainer167" class="IMG---Figure">
					<img src="image/B22208_12_2.jpg" alt="" role="presentation"/><st c="21867"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="23342">Figure 12.2 – Copilot in Power Platform on the home page</st></p>
			<p><st c="23398">On the Power Apps home screen (</st><a href="https://make.powerapps.com/"><st c="23430">https://make.powerapps.com/</st></a><st c="23458">), we are going to start by describing the idea of an application that we would like to build. </st><st c="23554">Since more or less any business application relies on data, Copilot will go ahead and start creating a data schema in Dataverse as our data source to manage data. </st><st c="23717">During this step, copilot extracts the context </st><a id="_idIndexMarker1539"/><st c="23764">of our prompt and, based on the inputs, starts creating an </st><span class="No-Break"><st c="23823">entity-relationship diagram.</st></span></p>
			<p><st c="23851">We can use prompt suggestions to alter a data schema, add more tables, configure the relationship between them, add more test data in the tables, and more. </st><st c="24008">The </st><strong class="bold"><st c="24012">View prompts</st></strong><st c="24024"> button acts as a prompt guide and gives us suggestions of what copilot can do. </st><st c="24104">This includes the abilities to create tables and relationships, alter tables and columns, and serve as inspiration, with suggestions based on the current data </st><span class="No-Break"><st c="24263">schema design:</st></span></p>
			<div>
				<div id="_idContainer168" class="IMG---Figure">
					<img src="image/B22208_12_3.jpg" alt="" role="presentation"/><st c="24277"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="25279">Figure 12.3 – Rich data model creation</st></p>
			<p><st c="25317">Once we click </st><strong class="bold"><st c="25332">Save and open app</st></strong><st c="25349">, Copilot will use this data schema to create a sample application</st><a id="_idIndexMarker1540"/><st c="25415"> with separate screens that have forms to perform operations over tables, as well as a separate welcome screen that can serve as a navigation </st><span class="No-Break"><st c="25557">between screens.</st></span></p>
			<p><st c="25573">In Power Apps Studio, we can utilize copilot to ask questions on how we can achieve things in Power Apps. </st><st c="25680">This utilizes Bing Search to find relevant content and provide us with guidance. </st><st c="25761">For example, we can ask a question such as “</st><em class="italic"><st c="25805">How can I add a picture to an image component</st></em><st c="25851">?” and it will produce the response relevant to the question. </st><st c="25913">In this case, that would be step-by-step guidance on how to achieve this with a relevant link to the documentation explaining the process. </st><st c="26052">We can ask it to add some specific components, such as a button or text label to the screen, but at this point, we might still need to do some tasks manually, as it is not yet able to complete </st><span class="No-Break"><st c="26245">all tasks.</st></span></p>
			<p><st c="26255">Building Power Fx formulas can be challenging sometimes, especially for someone who is working with Power Platform for the first time. </st><st c="26391">Similar to the capabilities of GitHub Copilot, to support developers, now we are able to use comments in a natural language to generate Power Fx formulas. </st><st c="26546">It also works the other way around, helping understand what a formula does by clicking a copilot icon next to the formula box and selecting </st><strong class="bold"><st c="26686">Explain </st></strong><span class="No-Break"><strong class="bold"><st c="26694">this formula</st></strong></span><span class="No-Break"><st c="26706">:</st></span></p>
			<div>
				<div id="_idContainer169" class="IMG---Figure">
					<img src="image/B22208_12_4.jpg" alt="" role="presentation"/><st c="26708"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="27811">Figure 12.4 – Using copilot to provide Power Fx formula suggestions</st></p>
			<p><st c="27878">As developers, we can </st><a id="_idIndexMarker1541"/><st c="27901">also get a view of the code in the Power Apps Studio directly. </st><st c="27964">By selecting the three dots next to a screen or a component (or right-clicking), we can now see a </st><strong class="bold"><st c="28062">View code (preview)</st></strong><st c="28081"> option, which shows a code in YAML format for the selected part. </st><st c="28147">This allows us to copy the code and discuss it with other developers, make changes in the code directly, or even use copy/paste to place only this part in another screen </st><span class="No-Break"><st c="28317">or application.</st></span></p>
			<p><st c="28332">If we switch gears to Power Automate, copilot allows us to complete similar tasks there. </st><st c="28422">That means using natural language to describe the flow we would like to create and perform changes to existing flows, such as adding actions to the flow, configuring the parameters of actions, </st><span class="No-Break"><st c="28615">and more.</st></span></p>
			<p><st c="28624">With the advancements in AI, soon, we will be able to build AI flows, where AI will determine how to build an automation plan with all the conditions needed to fulfill requirements. </st><st c="28807">We will also soon be able to use voice to record instructions for building a Power Automate </st><span class="No-Break"><st c="28899">Desktop flow.</st></span></p>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="image/B22208_12_5.jpg" alt="" role="presentation"/><st c="28912"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="29699">Figure 12.5 – Copilot in Power Automate</st></p>
			<p><st c="29738">We have to keep in mind that at this time, some of the copilot features are still in preview. </st><st c="29833">From a DevOps </st><a id="_idIndexMarker1542"/><st c="29847">perspective, we can see one main problem currently, and that is that the ability to use the same building approach is not enabled from the </st><span class="No-Break"><st c="29986">solution’s level.</st></span></p>
			<p><st c="30003">We mentioned in </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="30020">Chapter 4</st></em></span></a><st c="30029"> that we should be starting off building our Power Platform components from within solution explorer. </st><st c="30131">There we use an existing solution or create a new one, since solutions enable us to move applications between environments and manage dependencies required by our solution components. </st><st c="30315">The current approach of development with the copilots is starting from the designer experience instead of from the solution explorer. </st><st c="30449">This way, all components that we create through copilot’s initial designer experience will be added to the </st><strong class="bold"><st c="30556">Default Solution</st></strong><st c="30572"> and be unmanaged. </st><st c="30591">Currently, a copilot-first approach for building business applications does not support starting from the solution, which leaves us only with the option of adding existing components to a new solution and making sure all required dependencies are added to the solution. </st><st c="30861">However, if we would like to start with the manual creation of custom copilot, we can first create a solution and, from there, create new components (such as a Power Apps application). </st><st c="31046">We</st><a id="_idIndexMarker1543"/><st c="31048"> hope that the copilot experience for the initial creation of apps and other components will also be enabled through the </st><span class="No-Break"><st c="31169">solution approach.</st></span></p>
			<h1 id="_idParaDest-206"><a id="_idTextAnchor242"/><st c="31187">Extending business solutions with AI Builder and 
Azure OpenAI</st></h1>
			<p><st c="31249">Now that we have seen how AI is helping us build Power Platform components, we will look for ways to infuse AI capabilities into our applications and flows. </st><st c="31407">This section will go through the AI Builder capabilities and how it compares to Azure OpenAI. </st><st c="31501">We will take a look at how to set up a custom connector to connect to Azure OpenAI, where we will use our Azure OpenAI model of choice to enrich the user experience or improve our business process in </st><span class="No-Break"><st c="31701">Power Platform.</st></span></p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor243"/><st c="31716">Introducing AI Builder</st></h2>
			<p><st c="31739">AI Builder is a Power </st><a id="_idIndexMarker1544"/><st c="31762">Platform service that allows makers to utilize different AI models and prompts inside their solutions without requiring coding or special data science knowledge. </st><st c="31924">It allows organizations to improve their business processes by adding additional AI capabilities, which can help automate manual and repetitive tasks and help achieve </st><span class="No-Break"><st c="32091">better outcomes.</st></span></p>
			<p><st c="32107">It can be integrated into Power Apps applications through a Power Fx formula or by using AI Builder components. </st><st c="32220">AI Builder can also be used in Power Automate workflows by using AI Builder actions. </st><st c="32305">We also have the option to use its capabilities in plugins within </st><span class="No-Break"><st c="32371">Copilot Studio.</st></span></p>
			<h3><st c="32386">AI models</st></h3>
			<p><st c="32396">AI Builder</st><a id="_idIndexMarker1545"/><st c="32407"> comes with a </st><a id="_idIndexMarker1546"/><st c="32421">set of pre-built models that are commonly used in many business processes. </st><st c="32496">When we require more custom-built models specific to our data, we can build custom models and train them on a </st><span class="No-Break"><st c="32606">custom dataset.</st></span></p>
			<p><st c="32621">AI models can be grouped together based on the type of data that they use. </st><st c="32697">These groups can hold both pre-built and </st><span class="No-Break"><st c="32738">custom models:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="32752">Document processing</st></strong><st c="32772">: This group contains models such as invoice processing, text recognition, document processing as a custom model, and a business </st><span class="No-Break"><st c="32902">card reader</st></span></li>
				<li><strong class="bold"><st c="32913">Text processing</st></strong><st c="32929">: Here, we can find models that are used for text processing, such as key phrase extraction, sentiment analysis, language detection, and </st><span class="No-Break"><st c="33067">category classification</st></span></li>
				<li><strong class="bold"><st c="33090">Image processing</st></strong><st c="33107">: Models that extract information from images, such as image description to generate descriptions of an image or object detection in images, are </st><span class="No-Break"><st c="33253">found here</st></span></li>
				<li><strong class="bold"><st c="33263">Structured data processing</st></strong><st c="33290">: Only one custom model so far can make forecasts and predict outcomes </st><span class="No-Break"><st c="33362">using data</st></span></li>
			</ul>
			<p><st c="33372">Each model has its own specifics and requirements in order to get the best result. </st><st c="33456">To learn more about each specific model, we recommend going through the </st><span class="No-Break"><st c="33528">documentation: </st></span><a href="https://learn.microsoft.com/en-us/ai-builder/model-types"><span class="No-Break"><st c="33543">https://learn.microsoft.com/en-us/ai-builder/model-types</st></span></a><span class="No-Break"><st c="33599">.</st></span></p>
			<p><st c="33600">With pre-built models, we do not require any special configuration – they are ready to be used out of the box and do not require any training. </st><st c="33744">We can use the component or connector action, point it to the data, and receive an output. </st><st c="33835">When using a custom model, we are building a model that is specific to a line of business. </st><st c="33926">It has to be trained first with the historical data in order to be able to complete specific tasks. </st><st c="34026">For document processing, we</st><a id="_idIndexMarker1547"/><st c="34053"> would </st><a id="_idIndexMarker1548"/><st c="34060">require at least five examples that use the same layout in order to train a </st><span class="No-Break"><st c="34136">model accurately.</st></span></p>
			<h3><st c="34153">AI prompts</st></h3>
			<p><st c="34164">AI prompts allow</st><a id="_idIndexMarker1549"/><st c="34181"> makers to build prompts that will instruct an LLM on the</st><a id="_idIndexMarker1550"/><st c="34238"> kind of task it has to perform. </st><st c="34271">The more precise the instruction is, the better the outcome of the task will be. </st><st c="34352">AI Builder has pre-built prompts that build these instructions to GPT faster, such as tasks around text summarization, text classification, sentiment analysis, drafting a reply, and more. </st><st c="34540">However, just as before with AI models, makers have the opportunity to create custom AI prompts. </st><st c="34637">With the</st><a id="_idIndexMarker1551"/><st c="34645"> help of </st><strong class="bold"><st c="34654">prompt engineering</st></strong><st c="34672">, we can provide instructions that will guide a GPT model to the needed outcome. </st><st c="34753">It is important to know that the quality of instructions will have a direct impact on the output. </st><st c="34851">AI prompts allow us to provide input variables and Dataverse data, which creates prompts that are highly dynamic and related to our </st><span class="No-Break"><st c="34983">business process.</st></span></p>
			<p><st c="35000">AI Builder currently uses GPT-3.5-Turbo or GPT-4 (in preview) for AI prompts. </st><st c="35079">These are powered by </st><span class="No-Break"><st c="35100">Azure OpenAI.</st></span></p>
			<p><st c="35113">As creating a prompt is important and as there are other parameters that define how the model will behave, such as model selection and temperature settings, it’s a good idea to learn more about building AI prompts </st><span class="No-Break"><st c="35328">at </st></span><a href="https://learn.microsoft.com/en-us/ai-builder/create-a-custom-prompt"><span class="No-Break"><st c="35331">https://learn.microsoft.com/en-us/ai-builder/create-a-custom-prompt</st></span></a><span class="No-Break"><st c="35398">.</st></span></p>
			<p><st c="35399">As a safety precaution, we recommend implementing human inspection of the response before using the </st><a id="_idIndexMarker1552"/><st c="35500">response in an important business process, where a </st><a id="_idIndexMarker1553"/><st c="35551">wrong or irrelevant response could bring harm or have </st><span class="No-Break"><st c="35605">negative implications.</st></span></p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor244"/><st c="35627">Using AI models and AI prompts</st></h2>
			<p><st c="35658">We can start </st><a id="_idIndexMarker1554"/><st c="35672">creating</st><a id="_idIndexMarker1555"/><st c="35680"> AI models or AI prompts from </st><a id="_idIndexMarker1556"/><st c="35710">the </st><span class="No-Break"><strong class="bold"><st c="35714">AI hub</st></strong></span><span class="No-Break"><st c="35720">:</st></span></p>
			<ol>
				<li><st c="35722">In Power Apps or Power Automate, we can find the AI hub in the left navigation menu. </st><st c="35807">In case we do not see it there yet, we can find it under </st><strong class="bold"><st c="35864">More</st></strong><st c="35868"> and pin it to the left navigation bar from there or by going to </st><strong class="bold"><st c="35933">More</st></strong><st c="35937"> | </st><strong class="bold"><st c="35940">Discover all</st></strong><st c="35952">, where we will find </st><strong class="bold"><st c="35973">AI hub</st></strong><st c="35979"> and can pin it to the left </st><span class="No-Break"><st c="36007">navigation menu.</st></span></li>
				<li><st c="36023">Once we are in </st><strong class="bold"><st c="36039">AI hub</st></strong><st c="36045">, we can start building AI prompts and models. </st><st c="36092">There, we can also find a document automation solution that combines the RPA process and AI to extract information from various documents and proceed with the document </st><span class="No-Break"><st c="36260">processing workflow.</st></span></li>
				<li><st c="36280">Starting with AI prompts – in </st><strong class="bold"><st c="36311">AI hub</st></strong><st c="36317">, select </st><strong class="bold"><st c="36326">Prompts</st></strong><st c="36333">. There, we will see a list of all pre-built prompts and the option of creating a custom prompt </st><span class="No-Break"><st c="36429">with GPT.</st></span><p class="list-inset"><st c="36438">AI prompts are made of the </st><strong class="bold"><st c="36466">Prompt</st></strong><st c="36472">, which should be precise and clear, and </st><strong class="bold"><st c="36513">Prompt settings</st></strong><st c="36528">. We can configure multiple input variables and add them to the prompt to make it highly dynamic. </st><st c="36626">We can use data from Dataverse to additionally ground the GPT model with the knowledge source. </st><st c="36721">Outputs can be text or JSON and the latter option could sometimes be more suitable, as we have more control over the presentation layer. </st><st c="36858">In </st><strong class="bold"><st c="36861">Settings</st></strong><st c="36869">, we can select the model and temperature we’d like </st><span class="No-Break"><st c="36921">to use.</st></span></p></li>
				<li><st c="36928">Now that we have created an AI prompt, we can add it to our application or flow. </st><st c="37010">When we are developing our canvas app inside Power Apps Studio, we can find AI prompts or AI models in the </st><span class="No-Break"><strong class="bold"><st c="37117">Data</st></strong></span><span class="No-Break"><st c="37121"> section.</st></span></li>
				<li><st c="37130">In the left navigation bar, click on </st><strong class="bold"><st c="37168">Data</st></strong><st c="37172"> | </st><strong class="bold"><st c="37175">Add data</st></strong><st c="37183">, which opens an option to select a data source. </st><st c="37232">There, we can use the search bar to find our AI prompt or model and add </st><a id="_idIndexMarker1557"/><st c="37304">them</st><a id="_idIndexMarker1558"/><st c="37308"> to </st><span class="No-Break"><st c="37312">our application:</st></span></li>
			</ol>
			<div>
				<div id="_idContainer171" class="IMG---Figure">
					<img src="image/B22208_12_6.jpg" alt="" role="presentation"/><st c="37328"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37553">Figure 12.6 – Adding an AI prompt to the canvas app</st></p>
			<ol>
				<li value="6"><st c="37604">In order to use the AI prompt or AI model, we will trigger it from the Power </st><span class="No-Break"><st c="37682">Fx function:</st></span><pre class="source-code"><st c="37694">
Set(varComplaint, 'Example - Custom prompt Complaint Accommodation'.Predict(txtComplaint.Text,txtApartmentName.Text))</st></pre></li>			</ol>
			<p><st c="37812">In the preceding code, we can see an example of the Power Fx function that stores the response of the AI prompt as a variable, which can then later be consumed in the application based on our business process. </st><st c="38023">In Power Apps, we can find AI Builder components that are focused on specific AI models and can be implemented in the application through the component to enable some additional capabilities, such as a receipt and form processor, object detection, </st><span class="No-Break"><st c="38271">and more.</st></span></p>
			<p><st c="38280">Adding AI prompts and AI models in Power Automate is as easy as adding any other action in </st><span class="No-Break"><st c="38372">the workflow:</st></span></p>
			<ol>
				<li><st c="38385">In the Power Automate designer, when working on our workflow, click </st><strong class="bold"><st c="38454">Add an action</st></strong><st c="38467"> in the place where we would like to add </st><span class="No-Break"><st c="38508">AI capability.</st></span></li>
				<li><st c="38522">Search for </st><strong class="bold"><st c="38534">AI Builder</st></strong><st c="38544"> and select a model or prompt type from </st><span class="No-Break"><st c="38584">the list.</st></span></li>
				<li><st c="38593">We first select the model type and, in the next step, we can link a connector action to our model </st><span class="No-Break"><st c="38692">or prompt.</st></span><p class="list-inset"><st c="38702">Related to the preceding example, where we used a custom AI prompt, we can find our custom AI prompt by using the Power Automate action: </st><strong class="bold"><st c="38840">AI Builder</st></strong><st c="38850"> | </st><strong class="bold"><st c="38853">Create text with GPT using </st></strong><span class="No-Break"><strong class="bold"><st c="38880">a prompt</st></strong></span><span class="No-Break"><st c="38888">.</st></span></p></li>
				<li><st c="38889">We authenticate to a connector and, under </st><strong class="bold"><st c="38932">Parameters</st></strong><st c="38942"> | </st><strong class="bold"><st c="38945">Prompt</st></strong><st c="38951">, select our prompt from </st><span class="No-Break"><st c="38976">the list.</st></span></li>
				<li><st c="38985">We provide any inputs if needed and continue building </st><span class="No-Break"><st c="39040">our flow.</st></span></li>
			</ol>
			<p><st c="39049">In any subsequent </st><a id="_idIndexMarker1559"/><st c="39068">action, we </st><a id="_idIndexMarker1560"/><st c="39079">will be able to use the output from the previous actions, which is the same for AI Builder actions. </st><st c="39179">As an example, in </st><span class="No-Break"><em class="italic"><st c="39197">Figure 12</st></em></span><em class="italic"><st c="39206">.7</st></em><st c="39208">, we are using outputs from the generated complaint response, built by GenAI, in the </st><strong class="bold"><st c="39293">Approvals</st></strong><st c="39302"> action, to allow reviewers to review whether the generated complaint reply is appropriat</st><a id="_idTextAnchor245"/><a id="_idTextAnchor246"/><st c="39391">e or not. </st><st c="39402">If it is, we send the complaint message to </st><span class="No-Break"><st c="39445">the customer:</st></span></p>
			<div>
				<div id="_idContainer172" class="IMG---Figure">
					<img src="image/B22208_12_7.jpg" alt="" role="presentation"/><st c="39458"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="40301">Figure 12.7 – Integrating AI Builder with Power Automate</st></p>
			<p class="callout-heading"><st c="40357">Important notes</st></p>
			<p class="callout"><st c="40373">From the perspective of</st><a id="_idIndexMarker1561"/><st c="40397"> using </st><a id="_idIndexMarker1562"/><st c="40404">solutions for packaging our business applications, we need to keep in mind that AI models and prompts are not considered as app dependency. </st><st c="40544">We will need to manually add AI prompts and models to our solution to accompany the app </st><span class="No-Break"><st c="40632">or flow.</st></span></p>
			<p class="callout"><st c="40640">Also, AI models and prompts use AI Builder credits. </st><st c="40693">Different model types consume different amounts of credits, so make sure to review the licensing guide (</st><a href="https://go.microsoft.com/fwlink/?linkid=2085130"><st c="40797">https://go.microsoft.com/fwlink/?linkid=2085130</st></a><st c="40845">) to better understand the credit utilization for </st><span class="No-Break"><st c="40896">your project.</st></span></p>
			<h3><st c="40909">AI Builder ALM</st></h3>
			<p><st c="40924">Whenever we </st><a id="_idIndexMarker1563"/><st c="40937">create a custom AI model or AI prompt that we would like to reuse across environments, we can apply the same principles of application life cycle management that we have already covered in the previous chapters with other Power </st><span class="No-Break"><st c="41165">Platform components.</st></span></p>
			<p><st c="41185">Since an AI model or prompt cannot be created from within solution explorer, a custom AI model or AI prompt first needs to be created using AI Builder, where we can train the AI model with our collection of data or build a custom AI prompt. </st><st c="41427">We recommend following an environment strategy and developing a custom model in a development or sandbox environment and from there deploying it to other target environments. </st><st c="41602">Once the model has been trained, we need to publish it so that we can add it to </st><span class="No-Break"><st c="41682">the solution.</st></span></p>
			<p><st c="41695">Since the model is not considered an application or flow dependency, we need to manually add the custom AI model or AI prompt along with the app or flow that will be using it. </st><st c="41872">At this stage, we are ready to add existing models to solutions. </st><st c="41937">We need to be aware that when a model is added to the solution, only the model executable is added to the solution and not the data that was used for training. </st><st c="42097">This is why when we use models such as document processing, object detection, or entity extraction, the modification of models in the target environment won’t be possible, as the data is not transferred to the target environment. </st><st c="42327">In such cases and if modifications are needed, a new model should be created in the </st><span class="No-Break"><st c="42411">target environment.</st></span></p>
			<p><st c="42430">As part of the ALM for AI Builder, we should also consider implementing a </st><strong class="bold"><st c="42505">continuous improvement process</st></strong><st c="42535"> to improve our models. </st><st c="42559">So far, we can automate this approach with</st><a id="_idIndexMarker1564"/><st c="42601"> the </st><a id="_idIndexMarker1565"/><st c="42606">out-of-the-box capabilities only for custom document processing models. </st><st c="42678">However, we should implement a feedback loop that at least informs owners of AI models or prompts about the relevancy and appropriateness of the model by using different metrics to measure that. </st><st c="42873">One of these can be the model confidence score. </st><st c="42921">However, we can also incorporate a manual review process, as we have seen in an example earlier. </st><st c="43018">In order to achieve continuous improvement for a custom document processing model, we can implement a Power Automate flow that uses the </st><strong class="bold"><st c="43154">Save file to AI Builder feedback loop</st></strong><st c="43191"> AI Builder action whenever the total confidence score of an existing AI model is below a certain threshold. </st><st c="43300">A detailed description of this process is documented </st><span class="No-Break"><st c="43353">here: </st></span><a href="https://learn.microsoft.com/en-us/ai-builder/feedback-loop"><span class="No-Break"><st c="43359">https://learn.microsoft.com/en-us/ai-builder/feedback-loop</st></span></a><span class="No-Break"><st c="43417">.</st></span></p>
			<p><st c="43418">Once we are ready with our solution, we can use the CI/CD pipelines that we have configured in the previous chapters to export the solution and have the source code added to a repository. </st><st c="43607">After that, we can follow the DevOps process and, once ready, we can use our import pipeline to import the models to the target environment. </st><st c="43748">After that, models and prompts can be used in applications and flows. </st><st c="43818">In case we are using managed pipelines or pipelines for all, we only need to make sure that we have AI Builder components</st><a id="_idIndexMarker1566"/><st c="43939"> added to </st><span class="No-Break"><st c="43949">the solution.</st></span></p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor247"/><st c="43962">Introducing Azure OpenAI</st></h2>
			<p><st c="43987">Sometimes, makers and</st><a id="_idIndexMarker1567"/><st c="44009"> organizations would like to use the latest version of GPT models or have maybe already built models on Azure OpenAI, where they have grounded models around their company data. </st><st c="44186">They might want to reuse the work that they have already done on Azure OpenAI for other applications, or maybe the included version of the GPT model in Power Platform is the one they wish to use. </st><st c="44382">Luckily, Power Platform is a very extensible platform and supports such cases </st><span class="No-Break"><st c="44460">as well.</st></span></p>
			<p><st c="44468">As we have already mentioned in </st><a href="B22208_09.xhtml#_idTextAnchor149"><span class="No-Break"><em class="italic"><st c="44501">Chapter 9</st></em></span></a><st c="44510">, Power Platform supports many pro-dev integration scenarios between Azure and Power Platform. </st><st c="44605">Building fusion development teams would help us to bring relevant engineers to the project. </st><st c="44697">We can then distribute tasks to data scientists, AI architects, or similar roles that would make sure that the models are designed and fine-tuned in Azure OpenAI. </st><st c="44860">Developers or more seasoned app makers will make sure that custom connectors are integrated with Azure OpenAI. </st><st c="44971">And lastly, app makers will use custom connectors as part of the business application or flow, to produce the outcome for which they </st><span class="No-Break"><st c="45104">are built.</st></span></p>
			<p><st c="45114">The Azure OpenAI service is a PaaS service that brings OpenAI models to the Azure cloud platform. </st><st c="45213">Models are exposed through a REST API endpoint through which we can consume these LLMs while benefiting from the security, scalability, and reliability of the Azure platform. </st><st c="45388">These models support different tasks that span across NLP, computer vision, speech, </st><span class="No-Break"><st c="45472">and more.</st></span></p>
			<p><st c="45481">Azure OpenAI is designed for data scientists and AI engineers, who need more control over the models, by enabling them to fine-tune the models, generate embeddings, apply content filters, and more. </st><st c="45680">Additionally, in AI Builder, we can use GPT-4 over text with AI prompts. </st><st c="45753">Azure OpenAI provides other LLM models and if we take a look at the Azure AI service in general, we can see that there are also other LLM models as well as SLM models available that we can utilize. </st><st c="45951">This way, we can go beyond text and get the support of multimodality if needed, such as with the latest GPT-4o or other models such as Whisper or GPT-4 Turbo with Vision. </st><st c="46122">With all the advancements in AI, as well as optimizing hardware and AI operations, it is just a matter of time until Power Platform becomes richer with additional LLM models that will also support multimodality out of </st><span class="No-Break"><st c="46340">the box.</st></span></p>
			<h3><st c="46348">Integrating Azure OpenAI with Power Platform</st></h3>
			<p><st c="46393">Azure OpenAI </st><a id="_idIndexMarker1568"/><st c="46407">provides a UI experience, called </st><strong class="bold"><st c="46440">Azure OpenAI Studio</st></strong><st c="46459">, through </st><a id="_idIndexMarker1569"/><st c="46469">which</st><a id="_idIndexMarker1570"/><st c="46474"> users can build, test, and manage their Azure OpenAI deployments. </st><st c="46541">To start using it, Azure OpenAI service can be provisioned manually using Azure portal, using Azure CLI, or using infrastructure as code approach that we have already familiarized ourselves with in the </st><span class="No-Break"><st c="46743">previous chapter.</st></span></p>
			<p><st c="46760">To better understand the process of creating Azure OpenAI resources and model deployment, we recommend going through this documentation </st><span class="No-Break"><st c="46897">article: </st></span><a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource"><span class="No-Break"><st c="46906">https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource</st></span></a><span class="No-Break"><st c="46987">.</st></span></p>
			<p><st c="46988">The Azure OpenAI model can be grounded around the organizational data, keeping the data secure within the organizational Azure subscription. </st><st c="47130">Our new Azure OpenAI service can now be used in custom-developed applications using REST API and SDKs. </st><st c="47233">In Power Platform, it can be integrated </st><span class="No-Break"><st c="47273">using connectors.</st></span></p>
			<p class="callout-heading"><st c="47290">Access to Azure OpenAI services</st></p>
			<p class="callout"><st c="47322">Before provisioning Azure OpenAI service in our Azure subscription for the first time, we must submit an application to have access to Azure OpenAI services granted. </st><st c="47489">This can be done using a form that is accessible </st><span class="No-Break"><st c="47538">at </st></span><a href="https://aka.ms/oai/access"><span class="No-Break"><st c="47541">https://aka.ms/oai/access</st></span></a><span class="No-Break"><st c="47566">.</st></span></p>
			<p><st c="47567">We have already seen examples of building custom connectors in </st><a href="B22208_09.xhtml#_idTextAnchor149"><span class="No-Break"><em class="italic"><st c="47631">Chapter 9</st></em></span></a><st c="47640">. However, we will provide specifics that should be considered when connecting to the Azure OpenAI se</st><a id="_idTextAnchor248"/><st c="47741">rvice. </st><st c="47749">We can find all the required information within Azure </st><span class="No-Break"><st c="47803">OpenAI Studio:</st></span></p>
			<div>
				<div id="_idContainer173" class="IMG---Figure">
					<img src="image/B22208_12_8.jpg" alt="" role="presentation"/><st c="47817"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="48216">Figure 12.8 – The Azure OpenAI chat playground</st></p>
			<p><st c="48262">Here are </st><span class="No-Break"><st c="48272">the steps:</st></span></p>
			<ol>
				<li><st c="48282">In Power Apps</st><a id="_idIndexMarker1571"/><st c="48296"> or</st><a id="_idIndexMarker1572"/><st c="48299"> Power Automate, select </st><strong class="bold"><st c="48323">Custom connectors</st></strong><st c="48340"> in the left navigation bar and click on </st><strong class="bold"><st c="48381">New custom connector</st></strong><st c="48401"> | </st><strong class="bold"><st c="48404">Create </st></strong><span class="No-Break"><strong class="bold"><st c="48411">from blank</st></strong></span><span class="No-Break"><st c="48421">.</st></span></li>
				<li><st c="48422">Among other data, we need to provide </st><strong class="bold"><st c="48460">Host</st></strong><st c="48464">. This would be our Azure OpenAI service’s endpoint URL in the </st><strong class="source-inline"><st c="48527">&lt;name&gt;.openai.azure.com</st></strong><st c="48550"> format, as shown in </st><span class="No-Break"><em class="italic"><st c="48571">Figure 12</st></em></span><span class="No-Break"><em class="italic"><st c="48580">.8</st></em></span><span class="No-Break"><st c="48582">.</st></span></li>
				<li><st c="48583">Within the </st><strong class="bold"><st c="48595">Security</st></strong><st c="48603"> tab, we specify </st><strong class="bold"><st c="48620">API Key</st></strong><st c="48627"> as the authentication type, which is added in the </st><strong class="bold"><st c="48678">Header</st></strong><st c="48684"> location. </st><st c="48695">This key is what we will provide at the creation of the connection in Power Platform. </st><st c="48781">It can be found next to the endpoint URL, as seen in </st><span class="No-Break"><em class="italic"><st c="48834">Figure 12</st></em></span><em class="italic"><st c="48843">.8</st></em><st c="48845">, or in the Azure portal by going to </st><strong class="bold"><st c="48882">Azure OpenAI resource</st></strong><st c="48903"> | </st><strong class="bold"><st c="48906">Resource Management</st></strong><st c="48925"> | </st><strong class="bold"><st c="48928">Keys </st></strong><span class="No-Break"><strong class="bold"><st c="48933">and Endpoints</st></strong></span><span class="No-Break"><st c="48946">.</st></span></li>
				<li><st c="48947">In the </st><strong class="bold"><st c="48955">Definition</st></strong><st c="48965"> tab, click </st><strong class="bold"><st c="48977">New action</st></strong><st c="48987"> to define the chat completion API operation. </st><st c="49033">In the </st><strong class="bold"><st c="49040">Request</st></strong><st c="49047"> part, we can use </st><strong class="bold"><st c="49065">Import from sample</st></strong><st c="49083"> to create an HTTP POST request. </st><st c="49116">Under </st><strong class="bold"><st c="49122">URL</st></strong><st c="49125">, we provide the complete endpoint URL, which can also be found in </st><strong class="bold"><st c="49192">Azure OpenAI Chat playground</st></strong><st c="49220"> | </st><strong class="bold"><st c="49223">View code</st></strong><st c="49232">, as can be seen in </st><span class="No-Break"><em class="italic"><st c="49252">Figure 12</st></em></span><em class="italic"><st c="49261">.8</st></em><st c="49263">. The chat completions API also requires a body with a message that contains content for a system and user roles. </st><st c="49377">We can include a sample payload with a message from Azure OpenAI Chat Playground to facilitate adding </st><span class="No-Break"><st c="49479">the parameters.</st></span><p class="list-inset"><st c="49494">Actions can be further customized in the </st><strong class="bold"><st c="49536">Definition</st></strong><st c="49546"> tab to make sure that we are providing the required information for </st><span class="No-Break"><st c="49615">the model.</st></span></p></li>
				<li><st c="49625">Once we are satisfied, we can proceed to the </st><strong class="bold"><st c="49671">Test</st></strong><st c="49675"> tab, where we will create a connection by providing the API key for Azure OpenAI service. </st><st c="49766">After that, we can test </st><span class="No-Break"><st c="49790">the connector.</st></span></li>
				<li><st c="49804">Once we have a working connector, we can utilize it in our Power Platform solutions in the same way as with any </st><span class="No-Break"><st c="49917">other connector.</st></span></li>
			</ol>
			<p><st c="49933">Microsoft has</st><a id="_idIndexMarker1573"/><st c="49947"> recently </st><a id="_idIndexMarker1574"/><st c="49957">published a premium </st><strong class="bold"><st c="49977">Azure OpenAI connector</st></strong><st c="49999"> (in preview) for</st><a id="_idIndexMarker1575"/><st c="50016"> Azure Logic Apps and it also lights up in Power Platform. </st><st c="50075">We can expect that at some point, it will be announced as a generally available connector for Azure OpenAI. </st><st c="50183">Azure OpenAI connector simplifies building connections between Azure OpenAI service and Power Platform solutions, allowing makers to utilize the chat completion operation against their Azure OpenAI GPT models. </st><st c="50393">However, since the connector is in preview, we would recommend still building and using custom connectors that connect to </st><span class="No-Break"><st c="50515">Azure OpenAI:</st></span></p>
			<div>
				<div id="_idContainer174" class="IMG---Figure">
					<img src="image/B22208_12_9.jpg" alt="" role="presentation"/><st c="50528"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="50813">Figure 12.9 – Creating connections to Azure OpenAI</st></p>
			<p><st c="50863">Once the connector is announced and becomes generally available, we can use it in the same way as any other connector, as we have seen with AI Builder in the </st><span class="No-Break"><st c="51022">previous example.</st></span></p>
			<p><st c="51039">It is also good to </st><a id="_idIndexMarker1576"/><st c="51059">remember</st><a id="_idIndexMarker1577"/><st c="51067"> the possibility of using </st><strong class="bold"><st c="51093">connection references</st></strong><st c="51114"> in our </st><a id="_idIndexMarker1578"/><st c="51122">solutions, as mentioned in </st><a href="B22208_10.xhtml#_idTextAnchor172"><span class="No-Break"><em class="italic"><st c="51149">Chapter 10</st></em></span></a><st c="51159">. Using the deployment settings file (as seen in the following snippet) allows us to move our solution more effectively </st><span class="No-Break"><st c="51279">between environments:</st></span></p>
			<pre class="source-code"><st c="51300">
"ConnectionReferences": [
    {
      "LogicalName": "&lt;CONNECTION-REFERENCE-NAME&gt;",
      "ConnectionId": "&lt;CONNECTION-ID-TARGET-ENVIRONMENT&gt;",
      "ConnectorId": </st><strong class="bold"><st c="51444">"/providers/Microsoft.PowerApps/apis/shared_azureopenai"</st></strong><st c="51500">
    }
  ]</st></pre>			<p><st c="51504">With that, we have seen how easy it is to build AI models and plug them into existing business solutions in order to improve our business processes. </st><st c="51654">Using AI Builder or even Azure OpenAI can support many </st><span class="No-Break"><st c="51709">business processes:</st></span></p>
			<ul>
				<li><st c="51728">Automating expense reports by extracting information from attached invoices </st><span class="No-Break"><st c="51805">and documents</st></span></li>
				<li><st c="51818">Extracting sentiment from the product reviews to respond to </st><span class="No-Break"><st c="51879">them accordingly</st></span></li>
				<li><st c="51895">Writing replies to </st><span class="No-Break"><st c="51915">customer complaints</st></span></li>
				<li><st c="51934">Summarizing the content </st><span class="No-Break"><st c="51959">of meetings</st></span></li>
				<li><st c="51970">Building transcripts of customer calls with </st><span class="No-Break"><st c="52015">speech-to-text operations</st></span></li>
				<li><st c="52040">Translating documents to </st><span class="No-Break"><st c="52066">various languages</st></span></li>
				<li><st c="52083">Identifying </st><span class="No-Break"><st c="52096">fraudulent transactions</st></span></li>
			</ul>
			<p><st c="52119">We will now switch gears </st><a id="_idIndexMarker1579"/><st c="52145">and </st><a id="_idIndexMarker1580"/><st c="52149">move from the specifics of AI Builder and Azure Open AI toward custom copilots or virtual AI assistants and how they can support our </st><span class="No-Break"><st c="52282">DevOps process.</st></span></p>
			<h1 id="_idParaDest-210"><a id="_idTextAnchor249"/><st c="52297">ChatOps and Copilot Studio</st></h1>
			<p><st c="52324">We have already looked into various copilots that are embedded in the product. </st><st c="52404">Now it is time to look at how we can create a custom copilot. </st><st c="52466">This section will focus on a tool that enables us to build custom </st><a id="_idIndexMarker1581"/><st c="52532">copilots: </st><strong class="bold"><st c="52542">Copilot Studio</st></strong><st c="52556">. From there, we will learn </st><a id="_idIndexMarker1582"/><st c="52584">about </st><strong class="bold"><st c="52590">ChatOps</st></strong><st c="52597"> and, through an example, look at how we can use Copilot Studio to build an assistant that will help us with implementing ChatOps practice. </st><st c="52737">We will also look at PAC CLI commands that we can use to support ALM for </st><span class="No-Break"><st c="52810">Copilot Studio.</st></span></p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor250"/><st c="52825">A closer look at Copilot Studio</st></h2>
			<p><st c="52857">We briefly introduced </st><a id="_idIndexMarker1583"/><st c="52880">Copilot Studio at the beginning of the book. </st><st c="52925">Let us refresh what it is. </st><st c="52952">Copilot Studio is a low-code tool for managing custom copilots. </st><st c="53016">It has evolved from a product, previously known </st><a id="_idIndexMarker1584"/><st c="53064">as </st><strong class="bold"><st c="53067">Power Virtual Agents</st></strong><st c="53087"> (</st><strong class="bold"><st c="53089">PVA</st></strong><st c="53092">), that was used to build chatbots. </st><st c="53129">With the introduction of generative AI and the emergence of copilots, Microsoft expanded the functional capabilities of PVA and renamed the product to Copilot Studio. </st><st c="53296">This change resonates well, considering that this tool is not only for building chatbots but also a product that can extend existing copilots with additional custom capabilities. </st><st c="53475">Copilot Studio now allows anyone to build custom copilots with generative </st><span class="No-Break"><st c="53549">AI capabilities.</st></span></p>
			<p><st c="53565">Custom copilots act as AI assistants that can handle different kinds of requests, from performing specific operations that are supported by business process to simply answering questions utilizing the GPT model that is grounded around the business data. </st><st c="53820">Due to their generative AI capabilities, they are more than just chatbots, although we often refer to them as bots. </st><st c="53936">Organizations can build different internal or external bots that will support internal teams, work with customers, help drive internal processes, and more. </st><st c="54092">Given the fact that it is a low-code tool, it enables organizations’ rapid development of copilots that meet business requirements and contribute </st><span class="No-Break"><st c="54238">to ROI.</st></span></p>
			<p><st c="54245">Copilot Studio comes with a set of predefined and system topics. </st><st c="54311">It also allows us to create our own custom </st><a id="_idIndexMarker1585"/><st c="54354">topics. </st><st c="54362">Topics</st><a id="_idIndexMarker1586"/><st c="54368"> are a fundamental building block of copilot. </st><st c="54414">They define a specific part of the conversation between a user and a copilot, allowing natural interaction and communication. </st><st c="54540">Each topic includes a trigger, which could be represented as a set of trigger phrases and a set of conversation nodes. </st><st c="54659">These elements together define the conversational path that a topic can follow. </st><st c="54739">Nodes could represent a message or a question that the bot will place to a user. </st><st c="54820">Nodes can run an action such as triggering a Power Automate workflow or utilizing any of the connectors available in Power Platform. </st><st c="54953">They could also involve topic management capabilities, such as setting up variables, checking the conditions of certain values, calling other topics, and more. </st><st c="55113">Building topics allows us to have complete control over the conversation between the bot and </st><span class="No-Break"><st c="55206">the user.</st></span></p>
			<div>
				<div id="_idContainer175" class="IMG---Figure">
					<img src="image/B22208_12_10.jpg" alt="" role="presentation"/><st c="55215"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="56164">Figure 12.10 – The Copilot Studio topic authoring experience</st></p>
			<p><st c="56224">From a generative AI </st><a id="_idIndexMarker1587"/><st c="56246">perspective, Copilot Studio allows organizations to enhance user productivity and improve conversation flow by enabling generative answers and </st><span class="No-Break"><st c="56389">generative actions.</st></span></p>
			<p><st c="56408">Generative answers</st><a id="_idIndexMarker1588"/><st c="56427"> is a functionality whereby a GPT uses different knowledge sources, such as public websites, internal SharePoint sites, various documents, custom data sources, and more, to generate answers to questions. </st><st c="56631">When the generative answers functionality is enabled, we can add GPT-powered answers to any custom topic as well as use a fallback system topic that triggers whenever no other topics can be matched. </st><st c="56830">Copilot Studio also allows integration with the Azure OpenAI model instead of using the embedded GPT model inside Copilot Studio. </st><st c="56960">In this case, the user’s question is sent to Azure OpenAI, where an answer is prepared and sent back to Copilot Studio, which then presents this answer to </st><span class="No-Break"><st c="57115">the user.</st></span></p>
			<p><strong class="bold"><st c="57124">Generative mode</st></strong><st c="57140">, also</st><a id="_idIndexMarker1589"/><st c="57146"> previously known as </st><strong class="bold"><st c="57167">generative actions</st></strong><st c="57185">, allows us to build highly dynamic chatbots by connecting various actions (connector actions, Power Automate flows, AI Builder prompts, or Bot Framework skills) with our bot, together with all custom and system topics, and allow generative AI to determine on its own how to respond to a user request by picking the most appropriate action or topic to continue </st><span class="No-Break"><st c="57546">the conversation.</st></span></p>
			<p><st c="57563">After we have developed a bot, we can test its functionalities directly in Copilot Studio. </st><st c="57655">Once we are satisfied with the work, we can expose custom copilots through different channels. </st><st c="57750">They can be published via Microsoft Teams or custom websites. </st><st c="57812">We can build our own custom application that will implement chat capabilities with a custom copilot, publish this on internal SharePoint, or deploy it to various other communication channels, such as Facebook Messenger, Twilio, Slack, Direct Line API, </st><span class="No-Break"><st c="58064">and more.</st></span></p>
			<p><st c="58073">Let’s continue by </st><a id="_idIndexMarker1590"/><st c="58092">learning what ChatOps is and then taking a look at how to implement a ChatOps process using </st><span class="No-Break"><st c="58184">Copilot Studio.</st></span></p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor251"/><st c="58199">What is ChatOps</st></h2>
			<p><st c="58215">The term ChatOps is </st><a id="_idIndexMarker1591"/><st c="58236">not new; it’s been with us for more than 10 years and was introduced by GitHub. </st><st c="58316">ChatOps has somehow dissolved in today’s DevOps community, as people are not talking about it that much. </st><st c="58421">However, we can see that many DevOps teams have implemented parts of ChatOps practices in communication platforms such as Teams or Slack. </st><st c="58559">We can see that even though DevOps communities do not talk that much about ChatOps, DevOps engineers do recognize the benefits of ChatOps and might have already implemented some ChatOps practices inside their team channels without even knowing that these are </st><span class="No-Break"><st c="58818">ChatOps practices.</st></span></p>
			<p><st c="58836">ChatOps is a practice also known as a </st><em class="italic"><st c="58875">conversation-driven DevOps</st></em><st c="58901">. It uses a chatbot and a communication platform, such as Microsoft Teams or Slack, to support developers and IT operations teams by automating different DevOps-related tasks. </st><st c="59077">This would include tasks such as creating new issues or work items, provisioning infrastructure, creating new a branch in a repository, approving pull requests, deploying applications, </st><span class="No-Break"><st c="59262">and more.</st></span></p>
			<p><st c="59271">There are many benefits of ChatOps. </st><st c="59308">ChatOps can increase and improve collaboration and communication between teams, which also allows better knowledge sharing and visibility into the DevOps process and project. </st><st c="59483">It allows certain processes to be automated and provided to members through a unified communication platform. </st><st c="59593">As we are automating tasks, the operations can be done faster. </st><st c="59656">Such an approach also helps to reduce any potential human error during the process. </st><st c="59740">Team members also have an overview of the history of operations that were performed by team members. </st><st c="59841">It promotes increased sharing within the team so that team members can help each other. </st><st c="59929">Just as with DevOps, it is not all about tools and processes here but also about people </st><span class="No-Break"><st c="60017">and culture.</st></span></p>
			<p><st c="60029">ChatOps can</st><a id="_idIndexMarker1592"/><st c="60041"> be paired with chatbots to help deliver automation capabilities. </st><st c="60107">With the recent announcements around custom copilots with agent capabilities in Copilot Studio, we believe that the frequency of cases of using chatbots and custom copilots to support DevOps processes and IT operations can </st><span class="No-Break"><st c="60330">only increase.</st></span></p>
			<p><st c="60344">A </st><em class="italic"><st c="60347">custom copilot with agent capabilities</st></em><st c="60385"> is a new feature in Copilot Studio (it was announced during the Microsoft Build 2024 conference and is not yet available) that enables makers to create copilots that are triggered by events rather than just user conversation. </st><st c="60612">They can support long-running and complex processes with less human interaction. </st><st c="60693">We could create a custom copilot that would respond to a given event in Azure DevOps or GitHub Enterprise and understand the outcomes of the event. </st><st c="60841">An example would be that if a new task has been assigned to the engineer, the custom copilot could open a feature branch for that engineer and notify the engineer about the planned work. </st><st c="61028">It might also execute a series of actions when a build fails. </st><st c="61090">Both of these examples could be handled completely by utilizing generative AI capabilities and registered actions in </st><span class="No-Break"><st c="61207">Copilot Studio.</st></span></p>
			<p><st c="61222">Let’s expand what could be other use cases for support DevOps processes with the capabilities accessible in Copilot Studio </st><span class="No-Break"><st c="61346">already today.</st></span></p>
			<h3><st c="61360">Use cases for ChatOps</st></h3>
			<p><st c="61382">We can start building</st><a id="_idIndexMarker1593"/><st c="61404"> our ChatOps practices by covering simple yet </st><span class="No-Break"><st c="61450">relevant cases.</st></span></p>
			<p><st c="61465">The first set of use cases focuses on informing team members about a specific activity. </st><st c="61554">Using a communication platform, such as Microsoft Teams, we can start bringing in information from our version control system and project management tools. </st><st c="61710">While DevOps team members work on their projects, they might sometimes miss some important changes to the project. </st><st c="61825">This is why we can bring information to their team chat room and provide them with curated content, such as information about new pull requests, failed pipeline executions, the creation of tasks or new bugs, and more. </st><st c="62043">We should also consider implementing a mechanism of notifying team members about </st><span class="No-Break"><st c="62124">any incident.</st></span></p>
			<p><st c="62137">When providing the information to the team chat channel, we should make sure that we do not overload them with all the information that is available. </st><st c="62288">We should filter the content and post what is relevant, which is something that teams can decide to set. </st><st c="62393">However, these types of activities are informational in nature, informing of an activity. </st><st c="62483">Whenever we would like to perform an action based on this information or based on the task, we should look at the other set of activities that can be delivered through a bot, or in our case, a </st><span class="No-Break"><st c="62676">custom copilot.</st></span></p>
			<p><st c="62691">Here in the second part of activities that we can implement through ChatOps, we can place any activities that teams would like to automate. </st><st c="62832">Since custom copilots, through Copilot Studio, can integrate with many first-party and third-party tools through connectors, as well as custom connectors, the options are limitless. </st><st c="63014">We can call a connector or an API to obtain information that is relevant to the project, such as getting all bugs for the project or allowing team members to ask general questions about how to do some activities. </st><st c="63227">We can integrate with tools such as Azure DevOps or GitHub to create new issues or bug work items, or we can call Terraform or Power Automate flow to provision a new environment through a process that we have already discussed in the previous chapter. </st><st c="63479">We can set activities such as pull request approvals and more. </st><st c="63542">As we can see, the options </st><a id="_idIndexMarker1594"/><st c="63569">are </st><span class="No-Break"><st c="63573">almost limitless.</st></span></p>
			<p class="callout-heading"><st c="63590">Authorization before the operation</st></p>
			<p class="callout"><st c="63625">Chatbots can be shared among all team members of a given project. </st><st c="63692">Using Microsoft Teams and Copilot Studio allows us to utilize Microsoft Entra ID as an identity management system. </st><st c="63807">Connectors and actions that we register should authorize users in order to verify whether those users have permission to perform a task before launching it. </st><st c="63964">This prevents them from performing some </st><span class="No-Break"><st c="64004">sensitive actions.</st></span></p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor252"/><st c="64022">Integrating Microsoft Teams with GitHub and Azure DevOps</st></h2>
			<p><st c="64079">Let us take a </st><a id="_idIndexMarker1595"/><st c="64094">look at how we can integrate </st><a id="_idIndexMarker1596"/><st c="64123">Microsoft Teams with Azure DevOps</st><a id="_idIndexMarker1597"/><st c="64156"> or </st><a id="_idIndexMarker1598"/><st c="64160">GitHub so that the changes in our project are reflected in the common team channel. </st><st c="64244">Both of these tools have native integrations with Microsoft Teams. </st><st c="64311">In order to configure notifications from Azure DevOps or GitHub to Microsoft Teams, we need to install a connector in Microsoft Teams. </st><st c="64446">In the Microsoft Teams team channel, we right-click on a channel and select </st><strong class="bold"><st c="64522">Manage channel</st></strong><st c="64536">. When we are in channel settings, we can see the </st><strong class="bold"><st c="64586">Connectors</st></strong><st c="64596"> section, where we click </st><strong class="bold"><st c="64621">Edit</st></strong><st c="64625">. This opens a new screen with all connectors for a specific channel. </st><st c="64695">Here, we can use the search feature to find either Azure DevOps or GitHub Enterprise. </st><st c="64781">We click on </st><strong class="bold"><st c="64793">Configure</st></strong><st c="64802"> and follow the process of setting up </st><span class="No-Break"><st c="64840">a connector.</st></span></p>
			<p><st c="64852">Currently, for GitHub Enterprise, only the following events are supported: issues, pull requests, push, and comments for all these categories. </st><st c="64996">When configuring the GitHub connector, we are also provided with very detailed step-by-step guidance on how to configure </st><span class="No-Break"><st c="65117">the webhook:</st></span></p>
			<div>
				<div id="_idContainer176" class="IMG---Figure">
					<img src="image/B22208_12_11.jpg" alt="" role="presentation"/><st c="65129"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="65370">Figure 12.11 – An example of a GitHub notification in Teams</st></p>
			<p><st c="65429">Azure</st><a id="_idIndexMarker1599"/><st c="65435"> DevOps </st><a id="_idIndexMarker1600"/><st c="65443">supports </st><a id="_idIndexMarker1601"/><st c="65452">event </st><a id="_idIndexMarker1602"/><st c="65458">notifications about completed builds, pushed code, and operations with pull request, releases, and work items. </st><st c="65569">We also have more granular control for these event types, such as only receiving information when new work items of the </st><strong class="bold"><st c="65689">Bug</st></strong><st c="65692"> type have been added to the project. </st><st c="65730">Once we add a connector, the wizard will guide us through the process and create service hook subscriptions in </st><span class="No-Break"><st c="65841">Azure DevOps:</st></span></p>
			<div>
				<div id="_idContainer177" class="IMG---Figure">
					<img src="image/B22208_12_12.jpg" alt="" role="presentation"/><st c="65854"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="66217">Figure 12.12 – Creating service hook subscriptions through the connector for Azure DevOps</st></p>
			<p><st c="66306">In addition to receiving notifications, Azure DevOps integrates with MS Teams by allowing us to add tabs to the channel. </st><st c="66428">These tabs can display the Azure DevOps dashboard or</st><a id="_idIndexMarker1603"/><st c="66480"> Kanban </st><a id="_idIndexMarker1604"/><st c="66488">board, which</st><a id="_idIndexMarker1605"/><st c="66500"> provides </st><a id="_idIndexMarker1606"/><st c="66510">us with real-time information about the project’s current state. </st><st c="66575">Team members now do not need to change the context and switch tools to get </st><span class="No-Break"><st c="66650">this information.</st></span></p>
			<p><st c="66667">GitHub provides additional capabilities in regards to integration with Microsoft Teams. </st><st c="66756">We can use </st><strong class="bold"><st c="66767">GitHub integration for Microsoft Teams</st></strong><st c="66805">, which installs a chatbot in Microsoft Teams, through which we can also receive notifications about the project, open or close issues, comment on pull requests, and more. </st><st c="66977">The installation link can be found </st><span class="No-Break"><st c="67012">at </st></span><a href="https://teams.github.com/"><span class="No-Break"><st c="67015">https://teams.github.com/</st></span></a><span class="No-Break"><st c="67040">.</st></span></p>
			<div>
				<div id="_idContainer178" class="IMG---Figure">
					<img src="image/B22208_12_13.jpg" alt="" role="presentation"/><st c="67041"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="67560">Figure 12.13 – GitHub and Microsoft Teams integrations through the chatbot</st></p>
			<p><st c="67634">GitHub’s bot already points us in the direction of chatbot-supported ChatOps practices. </st><st c="67723">Let us look at how</st><a id="_idIndexMarker1607"/><st c="67741"> we </st><a id="_idIndexMarker1608"/><st c="67745">can </st><a id="_idIndexMarker1609"/><st c="67749">build</st><a id="_idIndexMarker1610"/><st c="67754"> our own custom copilot to support ChatOps with </st><span class="No-Break"><st c="67802">Copilot Studio.</st></span></p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor253"/><st c="67817">Building ChatOps for Power Platform with Copilot Studio</st></h2>
			<p><st c="67873">We will proceed </st><a id="_idIndexMarker1611"/><st c="67890">by creating a simple ChatOps chatbot with Copilot Studio to </st><a id="_idIndexMarker1612"/><st c="67950">demonstrate how Copilot Studio can be used to support </st><span class="No-Break"><st c="68004">DevOps tasks.</st></span></p>
			<p><st c="68017">We will head to Copilot Studio at </st><a href="https://copilotstudio.microsoft.com/"><st c="68052">https://copilotstudio.microsoft.com/</st></a><st c="68088"> and click on </st><strong class="bold"><st c="68102">Create</st></strong><st c="68108"> | </st><span class="No-Break"><strong class="bold"><st c="68111">New copilot</st></strong></span><span class="No-Break"><st c="68122">:</st></span></p>
			<div>
				<div id="_idContainer179" class="IMG---Figure">
					<img src="image/B22208_12_14.jpg" alt="" role="presentation"/><st c="68124"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="68864">Figure 12.14 – Creating a new custom copilot</st></p>
			<p><st c="68908">If our environment is located in the United States region, we will be offered a conversational</st><a id="_idIndexMarker1613"/><st c="69003"> creation approach. </st><st c="69023">However, we will click </st><strong class="bold"><st c="69046">Skip to configure</st></strong><st c="69063">, fill in</st><a id="_idIndexMarker1614"/><st c="69072"> the  </st><strong class="bold"><st c="69077">Name</st></strong><st c="69081"> and </st><strong class="bold"><st c="69086">Description</st></strong><st c="69097"> fields for our copilot, and click </st><strong class="bold"><st c="69132">Create</st></strong><st c="69138">. This will provision our copilot with </st><span class="No-Break"><st c="69177">prebuilt topics.</st></span></p>
			<p><st c="69193">If we would like to enhance our copilot with generative answers that are grounded around our data, we can select the </st><strong class="bold"><st c="69311">Knowledge</st></strong><st c="69320"> tab on top, then click </st><span class="No-Break"><strong class="bold"><st c="69344">Add knowledge</st></strong></span><span class="No-Break"><st c="69357">:</st></span></p>
			<div>
				<div id="_idContainer180" class="IMG---Figure">
					<img src="image/B22208_12_15.jpg" alt="" role="presentation"/><st c="69359"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="70070">Figure 12.15 – Adding knowledge to our copilot</st></p>
			<p><st c="70116">Here, we will use the </st><strong class="bold"><st c="70139">Files</st></strong><st c="70144"> option</st><a id="_idIndexMarker1615"/><st c="70151"> to upload any file that contains relevant </st><a id="_idIndexMarker1616"/><st c="70194">information that might be useful for our team. </st><st c="70241">This could be some document with general guidance or project-specific documentation. </st><st c="70326">We can upload a file by dragging and dropping it or by using the </st><strong class="bold"><st c="70391">click to browse</st></strong><st c="70406"> option. </st><st c="70415">This enables our copilot to be able to answer questions about this document’s topic. </st><st c="70500">It takes a few minutes for the document to be indexed and ready to use. </st><st c="70572">The documents are stored in Dataverse </st><span class="No-Break"><st c="70610">file storage.</st></span></p>
			<p><st c="70623">Once ready, we can already test this capability using the </st><strong class="bold"><st c="70682">Test your </st></strong><span class="No-Break"><strong class="bold"><st c="70692">copilot</st></strong></span><span class="No-Break"><st c="70699"> option.</st></span></p>
			<p><st c="70707">In the copilot </st><strong class="bold"><st c="70723">Overview</st></strong><st c="70731"> section, go to </st><strong class="bold"><st c="70747">Knowledge</st></strong><st c="70756"> | </st><strong class="bold"><st c="70759">Allow the AI to use its own general knowledge (preview)</st></strong><st c="70814">, where we can enable or disable general knowledge that the GPT model has. </st><st c="70889">This is the data on which GPT has been trained. </st><st c="70937">For now, Copilot Studio still uses GPT-3.5-Turbo, with a cutoff date of September 2021. </st><st c="71025">We recommend disabling it for </st><span class="No-Break"><st c="71055">this case.</st></span></p>
			<p><st c="71065">The next step is to enable some action in our copilot. </st><st c="71121">Whichever scenario we would like to enable, we either need to create a topic or add an action to our copilot. </st><st c="71231">Let’s start with </st><span class="No-Break"><st c="71248">topics first.</st></span></p>
			<p><st c="71261">We select </st><strong class="bold"><st c="71272">Topics</st></strong><st c="71278"> from the top menu. </st><st c="71298">There, we can see that we have some prebuilt topics named </st><strong class="bold"><st c="71356">Lesson 1</st></strong><st c="71364">, </st><strong class="bold"><st c="71366">Lesson 2</st></strong><st c="71374">, and </st><strong class="bold"><st c="71380">Lesson 3</st></strong><st c="71388">. These are prebuilt topics that we do not need, so we can delete or disable them. </st><st c="71471">We can do this by selecting the three dots next to each of them and switching the status to disabled or by </st><span class="No-Break"><st c="71578">clicking </st></span><span class="No-Break"><strong class="bold"><st c="71587">Delete</st></strong></span><span class="No-Break"><st c="71593">.</st></span></p>
			<p><st c="71594">We will create a new topic by clicking </st><strong class="bold"><st c="71634">Add a topic</st></strong><st c="71645"> | </st><strong class="bold"><st c="71648">From blank</st></strong><st c="71658">. We could also use Copilot in Copilot Studio and describe what kind of topic we need and let Copilot come up with a rough proposal of the conversation flow using the provided description. </st><st c="71847">We are now inside the designer, where we can author a topic. </st><st c="71908">We can specify a few phrases that will trigger this topic by clicking </st><strong class="bold"><st c="71978">Edit</st></strong><st c="71982"> inside </st><strong class="bold"><st c="71990">Phrases</st></strong><st c="71997"> in the </st><strong class="bold"><st c="72005">Trigger</st></strong><st c="72012"> node. </st><st c="72019">Phrases refer to user utterances, or phrases, that will trigger </st><span class="No-Break"><st c="72083">this topic.</st></span></p>
			<p><st c="72094">Once phrases have been </st><a id="_idIndexMarker1617"/><st c="72118">added, we can continue by selecting Add node, which</st><a id="_idIndexMarker1618"/><st c="72169"> is represented with a plus (</st><strong class="bold"><st c="72198">+</st></strong><st c="72200">) sign. </st><st c="72208">Here, we can add conversational nodes that control the conversation. </st><st c="72277">For this example, we will go to </st><strong class="bold"><st c="72309">Call an action</st></strong><st c="72323"> | </st><strong class="bold"><st c="72326">Connector (preview)</st></strong><st c="72345"> and search for </st><strong class="bold"><st c="72361">Azure DevOps</st></strong><st c="72373">. We can select any action that we would like to add to our copilot to support ChatOps. </st><st c="72461">For example, we will select </st><strong class="bold"><st c="72489">Create a work item</st></strong><st c="72507">. This adds a connector action with all inputs that we have to configure in order for this connector action to </st><span class="No-Break"><st c="72618">work properly:</st></span></p>
			<div>
				<div id="_idContainer181" class="IMG---Figure">
					<img src="image/B22208_12_16.jpg" alt="" role="presentation"/><st c="72632"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="73355">Figure 12.16 – Adding an action to a topic</st></p>
			<p><st c="73397">Instead of manually providing</st><a id="_idIndexMarker1619"/><st c="73427"> the values, we can create a conversation path</st><a id="_idIndexMarker1620"/><st c="73473"> before this connector action with a set of questions, where we will be asking user questions and storing responses to the variables that will be used as parameters for the connector action. </st><st c="73664">An alternative to this is to utilize generative mode in Copilot Studio, register connector actions, and let generative AI figure out which values are missing from the context of the user’s question. </st><st c="73863">Generative AI can then provide a set of questions to the user to retrieve missing values for the connector action. </st><st c="73978">Let us use generative mode in Copilot Studio and add generative actions. </st><st c="74051">First, we will need to enable generative mode. </st><st c="74098">We need to go to </st><strong class="bold"><st c="74115">Settings</st></strong><st c="74123"> | </st><strong class="bold"><st c="74126">Generative AI</st></strong><st c="74139"> | </st><strong class="bold"><st c="74142">Generative (preview)</st></strong><st c="74162">. Keep in mind that this functionality is currently still in preview and should not be used on production cases. </st><st c="74275">It currently only works for copilots </st><span class="No-Break"><st c="74312">in English.</st></span></p>
			<div>
				<div id="_idContainer182" class="IMG---Figure">
					<img src="image/B22208_12_17.jpg" alt="" role="presentation"/><st c="74323"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="75830">Figure 12.17 – Enabling generative mode (preview) in custom copilot</st></p>
			<p><st c="75897">Once selected, click </st><strong class="bold"><st c="75919">Save</st></strong><st c="75923"> above this setting. </st><st c="75944">With this, we allow generative AI to determine which action or topic it should call based on the user’s message. </st><st c="76057">This also changes our triggers for</st><a id="_idIndexMarker1621"/><st c="76091"> topics. </st><st c="76100">Instead of phrases, they are converted to topic </st><a id="_idIndexMarker1622"/><st c="76148">descriptions. </st><st c="76162">A topic description holds information about what our topic does. </st><st c="76227">An example of a topic description can be seen in </st><span class="No-Break"><em class="italic"><st c="76276">Figure 12</st></em></span><em class="italic"><st c="76285">.18</st></em><st c="76288">. This is used by the GPT model to determine which action or topic to call. </st><st c="76364">The better the desc</st><a id="_idTextAnchor254"/><st c="76383">ription of the action or topic is, the better the chances are that the GPT model will call the right action </st><span class="No-Break"><st c="76492">or topic:</st></span></p>
			<div>
				<div id="_idContainer183" class="IMG---Figure">
					<img src="image/B22208_12_18.jpg" alt="" role="presentation"/><st c="76501"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="76600">Figure 12.18 – Triggering topics in generative mode</st></p>
			<p><st c="76651">We can close the copilot settings by clicking </st><strong class="bold"><st c="76698">X</st></strong><st c="76699"> in the top-right corner of Copilot Studio. </st><st c="76743">Next, we will click </st><strong class="bold"><st c="76763">Actions</st></strong><st c="76770"> | </st><strong class="bold"><st c="76773">Add an action</st></strong><st c="76786"> in the top menu bar. </st><st c="76808">Here, we can use the search bar to find all available actions for Azure DevOps or GitHub connector. </st><st c="76908">We can select the connector action </st><a id="_idIndexMarker1623"/><st c="76943">that we would like to enable, such as </st><strong class="bold"><st c="76981">Create an issue</st></strong><st c="76996"> from</st><a id="_idIndexMarker1624"/><st c="77001"> GitHub, and proceed to the </st><span class="No-Break"><st c="77029">configuration options:</st></span></p>
			<div>
				<div id="_idContainer184" class="IMG---Figure">
					<img src="image/B22208_12_19.jpg" alt="" role="presentation"/><st c="77051"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="77612">Figure 12.19 – Adding connector actions in Copilot Studio</st></p>
			<p><st c="77669">Each connector action comes with a set of inputs and outputs. </st><st c="77732">We can set input values statically or let generative AI understand the context of a user’s message and try to extract the right entities from the message and feed them to the input parameters. </st><st c="77925">For the output, we can let AI dynamically generate an output message, or we configure it manually. </st><st c="78024">We will leave the default settings as they are and allow the AI to ask us questions for each parameter that is required. </st><st c="78145">In </st><strong class="bold"><st c="78148">Outputs</st></strong><st c="78155">, we will configure the default setting and let the AI dynamically generate a response. </st><st c="78243">With this, we have now enabled the </st><strong class="bold"><st c="78278">Create new issue</st></strong><st c="78294"> action in our copilot. </st><st c="78318">We can continue enabling other actions that we would like to have in our </st><span class="No-Break"><st c="78391">ChatOps process.</st></span></p>
			<p><st c="78407">Lastly, we will create an integration with a Power Automate workflow for a more complex process. </st><st c="78505">Flows can be registered as actions in the same way as we have seen earlier. </st><st c="78581">Alternatively, we can build a topic and add a node to call the Power Automate flow. </st><st c="78665">Since we have changed the generative AI settings for our copilot to generative mode, we need to provide</st><a id="_idIndexMarker1625"/><st c="78768"> precise and clear information about our topic. </st><st c="78816">After </st><a id="_idIndexMarker1626"/><st c="78822">describing the topic, we can add a flow by adding a conversation node using the plus sign | </st><strong class="bold"><st c="78914">Call an action</st></strong><st c="78928"> | </st><strong class="bold"><st c="78931">Basic actions</st></strong><st c="78944"> | </st><strong class="bold"><st c="78947">Create a flow</st></strong><st c="78960">. This opens Power Automate separately with the input trigger and output action, both referring to the integration </st><span class="No-Break"><st c="79075">with copilot:</st></span></p>
			<div>
				<div id="_idContainer185" class="IMG---Figure">
					<img src="image/B22208_12_20.jpg" alt="" role="presentation"/><st c="79088"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="79804">Figure 12.20 – Creating a flow for copilot</st></p>
			<p><st c="79846">We can continue this process for building topics and flows, as well as connecting to actions that will support our </st><span class="No-Break"><st c="79962">ChatOps process.</st></span></p>
			<p><st c="79978">Once we are satisfied </st><a id="_idIndexMarker1627"/><st c="80001">with the work and would like to deploy it to Microsoft Teams, we will need to publish the bot. </st><st c="80096">In the top right in our copilot, we have the </st><strong class="bold"><st c="80141">Publish</st></strong><st c="80148"> option. </st><st c="80157">A popup appears where we have to confirm the publishing process with </st><strong class="bold"><st c="80226">Publish</st></strong><st c="80233">. We can head back to </st><strong class="bold"><st c="80255">Copilot Studio copilot</st></strong><st c="80277"> | </st><strong class="bold"><st c="80280">Channels</st></strong><st c="80288"> | </st><strong class="bold"><st c="80291">Microsoft Teams</st></strong><st c="80306">. We can click </st><strong class="bold"><st c="80321">Turn on Teams</st></strong><st c="80334"> to enable this bot in Teams. </st><st c="80364">Here, we have </st><strong class="bold"><st c="80378">Availability options</st></strong><st c="80398">, which allows us to share the copilot in the Teams app store. </st><st c="80461">Going back to the Teams settings, we have the </st><strong class="bold"><st c="80507">Open copilot</st></strong><st c="80519"> option, which opens copilot as an application in Teams. </st><st c="80576">Our bot</st><a id="_idIndexMarker1628"/><st c="80583"> is now ready to talk to users and run DevOps operations. </st><st c="80641">If we would like to add the copilot to a Teams channel, we have an ability under </st><strong class="bold"><st c="80722">Edit details</st></strong><st c="80734"> to allow users from the same tenant to add this copilot to a team. </st><st c="80802">However, this will enable users to add copilot to any team they are part of. </st><st c="80879">We would recommend looking at the Teams administration options and managing the roll-out of the copilot via Teams </st><span class="No-Break"><st c="80993">from there.</st></span></p>
			<p><st c="81004">In the following figure, we </st><a id="_idIndexMarker1629"/><st c="81033">can see an example of a successful deployment of a custom copilot into Microsoft Teams. </st><st c="81121">We can see how the generative AI capability is able to switch between topics, perform operations, and even ask questions to get values for all of the </st><a id="_idIndexMarker1630"/><span class="No-Break"><st c="81271">required parameters:</st></span></p>
			<div>
				<div id="_idContainer186" class="IMG---Figure">
					<img src="image/B22208_12_21.jpg" alt="" role="presentation"/><st c="81291"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="82167">Figure 12.21 – Using a custom copilot in Microsoft Teams</st></p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor255"/><st c="82223">ALM for Copilot Studio</st></h2>
			<p><st c="82246">Copilot </st><a id="_idIndexMarker1631"/><st c="82255">Studio, in the same way as other Power Platform products, supports application life cycle management through solutions. </st><st c="82375">We should start</st><a id="_idIndexMarker1632"/><st c="82390"> by going to </st><strong class="bold"><st c="82403">Solutions </st></strong><st c="82413">and clicking </st><strong class="bold"><st c="82426">New solution</st></strong><st c="82438"> or opening an existing one. </st><st c="82467">Once we are in the solution, we can click </st><strong class="bold"><st c="82509">New</st></strong><st c="82512"> | </st><strong class="bold"><st c="82515">Chatbot</st></strong><st c="82522"> to start working on our custom copilot in Copilot Studio. </st><st c="82581">Using this approach lets us ensure that any potential connectors that we might be using and registering inside copilot as an action will be added to the solution as a </st><span class="No-Break"><st c="82748">connection reference.</st></span></p>
			<p><st c="82769">We can follow the same approach for exporting and importing solutions as we have already seen in the previous chapters using Azure DevOps </st><span class="No-Break"><st c="82908">or GitHub.</st></span></p>
			<p><st c="82918">Since we can utilize different connectors in Copilot Studio, it is imperative to have valid DLP policies in place, which will make sure that in any given environment only connectors that are allowed by organizational policies can </st><span class="No-Break"><st c="83149">be used.</st></span></p>
			<p><st c="83157">Apart from the approach mentioned earlier, we can utilize PAC CLI specifically for copilot management. </st><st c="83261">We can use these commands and package them into scripts if we would like to maintain ALM only for our </st><span class="No-Break"><st c="83363">custom copilots.</st></span></p>
			<p><st c="83379">Using the following PAC CLI command, we can export the YAML template file of </st><span class="No-Break"><st c="83457">our copilot:</st></span></p>
			<pre class="source-code"><st c="83469">
pac copilot extract-template --bot &lt;BOT-ID&gt; --templateFileName &lt;templateName&gt;.yaml</st></pre>			<p><st c="83552">This serves two purposes. </st><st c="83579">First, we can export the entire copilot as code, store it in the repository, and collaborate on it through code. </st><st c="83692">Second, using this approach, we can build templates for our organizational copilots. </st><st c="83777">We can use this approach to prepare a template as a wireframe or starting point for how our organization’s copilots should look per specific department. </st><st c="83930">This will include some predefined topics as a starting point. </st><st c="83992">We can then export the definition of such copilots as template files and store those files somewhere in a central repository. </st><st c="84118">When someone requests a specific copilot, we can create it with these prebuilt topics inside using the template files that we have prepared in advance, and share the copilot with the right people. </st><st c="84315">The import process can be done using the following PAC </st><span class="No-Break"><st c="84370">CLI command.</st></span></p>
			<p><st c="84382">Before we can import the copilot to the target environment, we need to make sure that the </st><strong class="source-inline"><st c="84473">connectionReferences</st></strong><st c="84493"> part is updated correctly to reflect the appropriate value in the target environment. </st><st c="84580">In the created template YAML file, at the bottom of the file, we can find connection references, as can be seen in the </st><span class="No-Break"><st c="84699">following snippet:</st></span></p>
			<pre class="source-code"><st c="84717">
connectionReferences:
  - managedProperties:
      isCustomizable: false
</st><strong class="bold"><st c="84783">    connectionId: &lt;CONNECTION-ID-TARGET-ENVIRONMENT&gt;</st></strong><st c="84831">
    connectorId: /providers/Microsoft.PowerApps/apis/shared_visualstudioteamservices
    connectionReferenceLogicalName: template.connectionreference.cr6a8_chatOpsDemo.cr.SyS11HJP
    displayName: cr6a8_chatOpsDemo.cr.SyS11HJP
connectorDefinitions:
  - connectorId: /providers/Microsoft.PowerApps/apis/shared_visualstudioteamservices</st></pre>			<p><st c="85151">Additionally, we </st><a id="_idIndexMarker1633"/><st c="85169">need to make sure that we have the solution ready in the </st><a id="_idIndexMarker1634"/><st c="85226">target environment before launching this command. </st><st c="85276">We can either create a new solution or use an </st><span class="No-Break"><st c="85322">existing one.</st></span></p>
			<p><st c="85335">Once all of this has been set, we can launch the command </st><span class="No-Break"><st c="85393">for import:</st></span></p>
			<pre class="console"><st c="85404">
pac copilot create --environment &lt;ENVIRONMENT_ID&gt; --schemaName &lt;SCHEMA_NAME&gt; --templateFileName &lt;TEMPLATE-FILE&gt;.yaml --displayName &lt;DISPLAY-NAME&gt; --solution &lt;SOLUTON-NAME&gt;</st></pre>			<p><st c="85576">If any error comes up, this will be logged in the </st><strong class="source-inline"><st c="85627">pac-log.txt</st></strong><st c="85638"> file, as written in </st><span class="No-Break"><st c="85659">the error.</st></span></p>
			<p><st c="85669">Now that the copilot has been provisioned, we can share the copilot with the group of makers. </st><st c="85764">If we share the copilot with users individually, they get the maker role to co-edit the bot. </st><st c="85857">If we share </st><a id="_idIndexMarker1635"/><st c="85869">it with the security</st><a id="_idIndexMarker1636"/><st c="85889"> group, then the users in the security group get </st><span class="No-Break"><st c="85938">use-only permissions.</st></span></p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor256"/><st c="85959">Summary</st></h1>
			<p><st c="85967">In this chapter, we took a helicopter view of AI, as well as a hot topic for the last two years: GPTs. </st><st c="86071">AI has become an integral part of our daily tasks. </st><st c="86122">It is everywhere, in almost every application that we use. </st><st c="86181">Organizations are looking for ways to be innovative with AI or simply to improve business processes to be more effective. </st><st c="86303">Either way, it is on us to ensure that we build AI solutions in a responsible, ethical, and safe way, as we learned in this chapter. </st><st c="86436">Next, we looked at how Microsoft is building AI assistants, called Copilots, into every product so that we can all be more productive while using these tools. </st><st c="86595">We looked specifically into copilot in Power Platform and how we, as makers, can benefit from it to quickly set up data schemas, prototype applications, flows, </st><span class="No-Break"><st c="86755">and more.</st></span></p>
			<p><st c="86764">As organizations are finding ways to innovate with AI, they might be faced with the question of which AI services are available for use in Power Platform. </st><st c="86920">The next section focused on understanding AI Builder and its components such as AI models and AI prompts. </st><st c="87026">We looked at how we can use them in our applications, as well as apply the ALM process across AI Builder components. </st><st c="87143">However, AI Builder is not the only service that can be used to enhance our business applications with AI. </st><st c="87250">Azure OpenAI provides organizations with safe and reliable OpenAI models that can be used in any flow or application, as </st><span class="No-Break"><st c="87371">we learned.</st></span></p>
			<p><st c="87382">We close the chapter by focusing on custom copilots with Copilot Studio and ChatOps. </st><st c="87468">We introduced Copilot Studio, which enables us to build custom copilots or simple chatbots. </st><st c="87560">With AI infused into Copilot Studio, we can build a rich conversational AI experience for internal or external audiences in a matter of hours, not months. </st><st c="87715">Copilot Studio is a platform that can support business processes including support around ChatOps. </st><st c="87814">So, at the end of this part, we looked at ChatOps, which extends DevOps by providing a conversational experience with a bot that is capable of performing DevOps-oriented operations. </st><st c="87996">Lastly, we looked practically at how the ChatOps process can be supported by Copilot Studio and what some small specialties are when it comes to ALM for </st><span class="No-Break"><st c="88149">Copilot Studio.</st></span></p>
			<p><st c="88164">With this, we will close this book. </st><st c="88201">It has been a journey through different stages of the DevOps life cycle, from planning the business solutions to building pipelines, managing DevSecOps, taking care of the environment life cycle, understanding best practices, and closing with AI and ChatOps. </st><st c="88460">We hope that by now, we have managed to demonstrate that Microsoft Power Platform is a robust and mature platform that is extensible and ready to empower organizations and individuals to build their applications and support their business process with the services and features available in </st><span class="No-Break"><st c="88751">Power Platform.</st></span></p>
			<h1 id="_idParaDest-217"><a id="_idTextAnchor257"/><st c="88766">Further reading</st></h1>
			<ul>
				<li><st c="88782">Microsoft on responsible AI </st><span class="No-Break"><st c="88811">practices: </st></span><a href="https://www.microsoft.com/en-us/ai/responsible-ai"><span class="No-Break"><st c="88822">https://www.microsoft.com/en-us/ai/responsible-ai</st></span></a></li>
				<li><st c="88871">Azure OpenAI </st><span class="No-Break"><st c="88885">Service: </st></span><a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/overview"><span class="No-Break"><st c="88894">https://learn.microsoft.com/en-us/azure/ai-services/openai/overview</st></span></a></li>
				<li><st c="88961">Copilot Studio </st><span class="No-Break"><st c="88977">guidance: </st></span><a href="https://learn.microsoft.com/en-us/microsoft-copilot-studio/guidance/"><span class="No-Break"><st c="88987">https://learn.microsoft.com/en-us/microsoft-copilot-studio/guidance/</st></span></a></li>
				<li><st c="89055">Documentation on GitHub and Microsoft Teams </st><span class="No-Break"><st c="89100">integrations: </st></span><a href="https://github.com/integrations/microsoft-teams/blob/master/Readme.md"><span class="No-Break"><st c="89114">https://github.com/integrations/microsoft-teams/blob/master/Readme.md</st></span></a></li>
				<li><st c="89183">Details on the Azure DevOps and Microsoft Teams </st><span class="No-Break"><st c="89232">integration: </st></span><a href="https://learn.microsoft.com/en-us/azure/devops/service-hooks/services/teams?view=azure-devops"><span class="No-Break"><st c="89245">https://learn.microsoft.com/en-us/azure/devops/service-hooks/services/teams?view=azure-devops</st></span></a></li>
				<li><st c="89338">The PAC CLI command for </st><span class="No-Break"><st c="89363">copilot: </st></span><a href="https://learn.microsoft.com/en-us/power-platform/developer/cli/reference/copilot"><span class="No-Break"><st c="89372">https://learn.microsoft.com/en-us/power-platform/developer/cli/reference/copilot</st></span></a></li>
			</ul>
		</div>
	<div id="charCountTotal" value="89452"/></body></html>