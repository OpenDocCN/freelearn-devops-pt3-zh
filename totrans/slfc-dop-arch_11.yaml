- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Data Seeding Your Development Environments
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据种植在您的开发环境中
- en: In this chapter, we delve into the importance and process of populating your
    development environments with realistic data, which is crucial for accurate development
    and testing. We will also explore data masking as a fundamental technique to ensure
    sensitive data remains protected throughout this process.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨填充开发环境以实现真实数据的重要性和过程，这对准确的开发和测试至关重要。我们还将探讨数据掩码作为确保敏感数据在整个过程中保持保护的基本技术。
- en: 'We will cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主要主题：
- en: '**The benefits of accurate data for development and testing**: We will look
    at how data in our development environments brings realism, improved error detection,
    opportunities for performance tuning, and helps meet compliance and validation
    needs.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确数据对开发和测试的好处**：我们将查看开发环境中的数据如何带来真实感、改善错误检测、提供性能调优的机会，并帮助满足合规性和验证需求。'
- en: '**Seeding data in your environments**: In this section, we explore practical
    steps for getting test data into your Salesforce orgs – from data generation to
    import – and discuss how these processes can be automated while being mindful
    of complex data relationships.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在您的环境中种植数据**：在这一部分，我们将探讨将测试数据导入 Salesforce 组织的实际步骤——从数据生成到导入——并讨论如何在注意复杂数据关系的同时自动化这些过程。'
- en: '**Protecting sensitive data with data masking**: Finally, we ensure we understand
    the importance of data masking, with a look at how to implement it. We’ll discuss
    compliance best practices and some tools to help implement them.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过数据掩码保护敏感数据**：最后，我们将确保理解数据掩码的重要性，并讨论如何实施它。我们还将讨论合规最佳实践以及一些帮助实现这些实践的工具。'
- en: By the end of this chapter, you will have garnered a comprehensive understanding
    of how to seed realistic data in your development environments while ensuring
    the protection of sensitive information through data masking.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将全面了解如何在开发环境中种植真实数据，同时通过数据掩码确保敏感信息的保护。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: There are many ways to seed your Salesforce development environments with realistic
    data for testing, each with its own requirements. If you’re not using a dedicated
    Salesforce DevOps solution that includes this capability, then you can use tools
    and APIs provided by Salesforce themselves.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方式可以将 Salesforce 开发环境种植为真实数据用于测试，每种方式都有其要求。如果您没有使用包括此功能的专用 Salesforce DevOps
    解决方案，则可以使用 Salesforce 提供的工具和 API。
- en: While the Data Import Wizard is built into Salesforce, Data Loader is a separate
    download but does come with its own dependencies. You can find out more, including
    the download links, at [https://developer.salesforce.com/tools/data-loader](https://developer.salesforce.com/tools/data-loader).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据导入向导内置于 Salesforce 中，数据加载器是一个独立的下载工具，但它有自己的依赖项。您可以在[https://developer.salesforce.com/tools/data-loader](https://developer.salesforce.com/tools/data-loader)了解更多信息，包括下载链接。
- en: To make use of Bulk API, you would need to write a script in your programming
    language of choice, thus making the programming language itself a requirement.
    An example is given later for Python, but other languages that can make REST calls
    could be used instead. We will standardize Bulk API V2 for this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Bulk API，您需要用您选择的编程语言编写脚本，从而使编程语言本身成为一种要求。本章后面会给出 Python 的示例，但也可以使用其他能够进行
    REST 调用的语言。我们将在本章中统一使用 Bulk API V2。
- en: The benefits of accurate data for development and testing
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确数据对开发和测试的好处
- en: Creating a realistic development environment is a cornerstone of effective system
    development, especially in complex and data-driven platforms such as Salesforce.
    One of the most critical aspects of establishing this realism is ensuring the
    accuracy and integrity of data used for development and testing purposes. High-quality,
    realistic data lays the essential groundwork for understanding how the system
    will truly behave once deployed in a live production environment. This is crucial
    for enabling developers to make informed design decisions and foresee potential
    pitfalls or issues early in the development life cycle.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个现实的开发环境是有效系统开发的基石，特别是在像 Salesforce 这样复杂且数据驱动的平台上。建立这种现实感的最关键方面之一是确保用于开发和测试的数据的准确性和完整性。高质量、真实的数据为理解系统在部署到实际生产环境后如何运行奠定了必要的基础。这对于帮助开发人员做出明智的设计决策，并在开发生命周期早期预见潜在的陷阱或问题至关重要。
- en: The primary benefit of accurate, high-fidelity data is the sheer level of realism
    it brings into the development environment. When developers and **quality assurance**
    (**QA**) testers have access to data that mirrors real-world data, they gain invaluable
    perspective into how the system will function under live operational conditions.
    This realism permeates various facets of the development process, including the
    **user interface** (**UI**) and user experience design, core functionality testing,
    integration testing, performance testing, and more. Utilizing accurate data ensures
    the system is comprehensively evaluated and prepared for the intricacies and demands
    of production deployment.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 精确的高保真数据的主要好处在于它为开发环境带来了极高的现实感。当开发人员和**质量保证**（**QA**）测试人员能够访问与真实世界数据相似的数据时，他们能够从中获得关于系统在实际操作条件下如何运行的宝贵视角。这种现实感渗透到开发过程的各个方面，包括**用户界面**（**UI**）和用户体验设计、核心功能测试、集成测试、性能测试等。利用准确的数据可以确保系统在生产部署的复杂性和需求面前得到全面评估和准备。
- en: Accurate test data also plays an indispensable role in effective error detection
    and debugging. Bugs, defects, and inconsistencies in system behavior tend to surface
    when subjected to real-world data conditions and usage patterns. Unlike synthetic
    datasets or placeholder data, high-fidelity test data carries the full complexity,
    diversity, and nuances of actual live data. This means issues that may go undetected
    with fabricated or sample data will be revealed when exercising the system with
    accurate datasets. Early detection of defects then allows issues to be addressed
    promptly before they cascade into bigger problems down the line.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 精准的测试数据还在有效的错误检测和调试中扮演着不可或缺的角色。当系统在真实数据条件和使用模式下运行时，缺陷、缺点和行为不一致的问题往往会显现出来。与合成数据集或占位符数据不同，高保真测试数据包含了实际数据的全部复杂性、多样性和细微差别。这意味着，使用伪造数据或样本数据可能无法发现的问题，将在使用准确的数据集时被揭示出来。早期发现缺陷能够使问题得到及时处理，从而避免它们发展成更大的问题。
- en: Performance tuning and optimization is yet another area where accurate test
    data delivers immense value. The performance profile and system behavior under
    real-world data loads can deviate substantially from that observed using synthetic
    datasets. By leveraging accurate load-testing data, developers can simulate real-world
    usage patterns and data volumes, identifying any bottlenecks, slowdowns, or capacity
    limitations. This enables precise performance tuning to ensure optimal throughput
    and responsiveness when the system goes live.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 性能调优和优化是另一个精准测试数据能带来巨大价值的领域。在真实数据负载下，性能剖面和系统行为可能与使用合成数据集时观察到的有显著偏差。通过利用准确的负载测试数据，开发人员可以模拟现实世界中的使用模式和数据量，识别任何瓶颈、缓慢或容量限制。这使得精确的性能调优成为可能，从而确保系统上线时能够达到最佳的吞吐量和响应性。
- en: Additionally, realistic test data plays a crucial role in compliance testing
    and validating adherence to regulatory requirements. In highly regulated industries
    where standards compliance is mandatory, comprehensive testing with precise, real-world
    data is essential. This confirms that the system consistently meets necessary
    compliance needs when running real workloads. Compliance testing with inaccurate
    data carries the risk of missing violations that could occur in production.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，真实的测试数据在合规性测试中也起着至关重要的作用，确保符合监管要求。在那些要求标准合规的高度监管行业中，使用精准的真实数据进行全面测试至关重要。这能够确认系统在运行实际工作负载时，始终满足必要的合规性需求。若使用不准确的数据进行合规性测试，可能会错过生产环境中出现的违规问题。
- en: The many benefits of highly accurate test data in development and testing cannot
    be overstated. It brings realism to the entire development life cycle, enables
    proactive defect detection, allows performance optimization, and ensures compliance
    validation. In development teams, it can also help to reduce ramp time for new
    developers and/or new development environments, as rather than having to build
    up realistic data piece by piece over time, a consistent, known good dataset can
    be set up relatively quickly Making the effort to curate accurate test data pays
    dividends in building highly reliable systems that function smoothly in production
    environments. This makes it a foundational pillar of effective Salesforce development
    and **continuous delivery** (**CD**) workflows.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 高度准确的测试数据在开发和测试中的许多好处不容小觑。它为整个开发生命周期带来了现实感，能够主动发现缺陷，进行性能优化，并确保合规验证。在开发团队中，它还可以帮助减少新开发人员和/或新开发环境的适应时间，因为与其花时间逐步构建现实数据，不如相对快速地设置一个一致的、已知良好的数据集。花时间精心整理准确的测试数据有助于构建在生产环境中平稳运行的高度可靠的系统。这使其成为有效的
    Salesforce 开发和**持续交付**（**CD**）工作流的基础支柱。
- en: Seeding data in your environments
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在你的环境中种植数据
- en: Seeding development and testing environments with large volumes of high-fidelity,
    realistic data is indispensable for emulating the behavior of live production
    systems on Salesforce’s inherently data-centric platform. Thoroughly seeding sandboxes
    with representative data enables comprehensive validation under real-world conditions.
    However, accomplishing this efficiently at scale requires thoughtful implementation
    of robust tools, automation, and data modeling best practices.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 向开发和测试环境中种植大量高保真、现实的数据，对于模拟 Salesforce 数据中心平台上实时生产系统的行为是不可或缺的。彻底地向沙盒环境种植具有代表性的数据，使得在现实条件下能够进行全面的验证。然而，在规模上高效完成这一任务需要精心实施强大的工具、自动化和数据建模最佳实践。
- en: There are several approaches to providing your environments with data, and we’ll
    look at each of them in turn. We’ll start with the decision to either mirror your
    production data or generate dummy data, then look at options available for loading
    that data. By the end of this section, you should be in a strong position to get
    your environment data ready.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 提供数据给你的环境有多种方法，我们将逐一介绍每一种方法。我们将从决定是镜像生产数据还是生成虚拟数据开始，然后查看加载这些数据的可选方案。通过本节的学习，你应该能够为你的环境准备好数据。
- en: Working with production data
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用生产数据
- en: Seeding development environments with data is a crucial task to ensure that
    the testing and development carried out in these environments are reflective of
    real-world scenarios. In Salesforce, this often involves populating environments
    such as sandboxes with sample data from production – something that isn’t done
    by default by Salesforce and therefore falls upon developers, architects, and
    admins to carry out. This process not only furnishes the environments with realistic
    data but also fosters a better understanding of how the system will behave in
    production-like circumstances.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 向开发环境种植数据是一个至关重要的任务，确保在这些环境中进行的测试和开发能够反映真实的场景。在 Salesforce 中，这通常涉及将生产环境中的示例数据填充到沙盒等环境中——这是
    Salesforce 默认不做的，因此需要开发人员、架构师和管理员来完成。这个过程不仅为环境提供了现实数据，还促进了对系统在类似生产环境中的行为的更好理解。
- en: The initial step in this seeding process is the extraction of data from the
    production environment. Salesforce provides various tools and functionalities
    to aid in this task. The data extracted can be a replica of the production data
    or a subset thereof, depending on the needs of the development or testing scenario
    and the capacity of your target sandbox environment. It’s imperative to select
    a representative sample of data that encapsulates different data scenarios likely
    to be encountered in production.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个种植过程的初步步骤是从生产环境中提取数据。Salesforce 提供了多种工具和功能来帮助完成这一任务。提取的数据可以是生产数据的副本或其中的一个子集，具体取决于开发或测试场景的需要以及目标沙盒环境的容量。必须选择一个能够涵盖可能在生产环境中遇到的不同数据场景的代表性数据样本。
- en: Once the data is extracted, the next step is to import this data into the development
    environment, such as a sandbox. Tools such as the Salesforce Data Loader, Import
    Wizard, and Bulk API come into play here. They facilitate the import of data at
    different scales, ensuring that development environments are populated with data
    in an efficient and streamlined manner. We’ll look at each of these tools later
    in this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被提取，下一步是将这些数据导入到开发环境中，如沙盒（Sandbox）。此时，Salesforce 数据加载器（Data Loader）、导入向导（Import
    Wizard）和批量 API（Bulk API）等工具发挥作用。它们支持不同规模的数据导入，确保开发环境中的数据能够高效且顺利地填充。我们将在本章后续部分介绍这些工具。
- en: A critical consideration during this data seeding process is the potential presence
    of sensitive data, especially **personally identifiable information** (**PII**).
    When transferring data from production to development environments, it’s paramount
    to ensure that sensitive information is handled securely. This often requires
    the masking of sensitive data to prevent unauthorized access or exposure. As this
    topic is significant, we will delve into the details of data masking in a later
    section, focusing for now on the data seeding process.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一数据种植过程中，一个关键考虑因素是敏感数据的潜在存在，特别是**个人身份信息**（**PII**）。当将数据从生产环境转移到开发环境时，确保敏感信息的安全处理至关重要。这通常需要对敏感数据进行掩码处理，以防止未经授权的访问或泄露。由于这一话题的重要性，我们将在后续章节深入探讨数据掩码技术，目前我们将集中讨论数据种植过程。
- en: The seeding of data from production to development environments is a meticulous
    process that necessitates a keen understanding of the tools and practices involved.
    By accurately replicating production-data scenarios in development environments,
    developers and testers are better equipped to understand, test, and fine-tune
    the system, thus significantly contributing to the development of robust and reliable
    changes.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从生产环境到开发环境的数据种植是一个细致的过程，需要深入理解所涉及的工具和方法。通过在开发环境中准确复制生产数据场景，开发人员和测试人员能够更好地理解、测试和优化系统，从而在构建健壮且可靠的变更中起到重要作用。
- en: Challenges and constraints in loading production data
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载生产数据时的挑战与约束
- en: Production data is not without its challenges and issues. Salesforce orgs typically
    have various validation rules and automated processes (such as workflows, process
    builders, or triggers) to maintain data integrity and automate business processes.
    These can become roadblocks when seeding data. For instance, an org might have
    a validation rule that prevents the insertion of Opportunities at the “Closed
    Won” stage, as real data is expected to progress through the entire sales process.
    This poses a significant challenge when you need to seed data that bypasses these
    usual stages for testing purposes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 生产数据并非没有挑战和问题。Salesforce 组织通常会有各种验证规则和自动化流程（例如工作流、流程构建器或触发器），以维护数据完整性并自动化业务流程。在进行数据种植时，这些自动化流程可能会成为障碍。例如，一个组织可能会有一个验证规则，防止在“已关闭赢单”阶段插入商机，因为真实数据预计会经过整个销售过程。这在需要插入绕过这些通常阶段的测试数据时，构成了一个重要挑战。
- en: One approach to overcome this challenge is to create complex scripts that simulate
    the actual life cycle of records. This means scripting the insertion of Opportunities
    at an initial stage and then programmatically moving them through the required
    stages to reach “Closed Won.” This approach respects existing validation and automation
    but can be time-consuming and complex to implement.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 克服这一挑战的一种方法是创建复杂的脚本，模拟记录的实际生命周期。这意味着在初始阶段插入商机，然后通过编程方式将其推进到所需阶段，最终到达“已关闭赢单”阶段。这种方法尊重现有的验证和自动化，但实施起来可能既耗时又复杂。
- en: Another strategy is to temporarily disable certain validation rules and automation
    during the data seeding process. This can be risky, as it involves altering the
    production environment’s configuration, and should be done with extreme caution.
    It’s crucial to ensure that these changes are well-documented and reversed post-seeding.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种策略是暂时禁用数据种植过程中某些验证规则和自动化。这种做法具有一定风险，因为它涉及修改生产环境的配置，必须谨慎进行。确保这些更改已被充分记录，并在数据种植后恢复至原始状态至关重要。
- en: Salesforce offers tools and features that allow bypassing certain automation
    during data loads. For example, using Data Loader with the “Insert Null Values”
    option or specific API headers can help bypass some automation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce 提供了一些工具和功能，允许在数据加载过程中绕过某些自动化。例如，使用数据加载器（Data Loader）并选择“插入空值（Insert
    Null Values）”选项，或使用特定的 API 头信息，可以帮助绕过一些自动化过程。
- en: It’s important to understand that bypassing standard processes for data seeding
    can have implications for testing. If the seeded data doesn’t go through the usual
    business processes, it may not accurately represent real-world scenarios. Therefore,
    while bypassing validation and automation can make data seeding easier, it’s crucial
    to balance this with the need for realistic testing environments.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，绕过标准的数据种子流程可能会对测试产生影响。如果种子数据没有经过通常的业务流程，它可能无法准确地代表现实世界的场景。因此，尽管绕过验证和自动化可以让数据种子过程变得更容易，但仍然需要在此过程中平衡真实测试环境的需求。
- en: Generating test data
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成测试数据
- en: If it is not possible for you to use copies of production data, whether because
    of policy or access, then an alternative is to generate realistic mock data. The
    starting point is generating sufficiently large and diverse synthetic datasets
    that mimic actual business data variability. High-quality data synthesis tools
    and libraries produce plausible objects, relationships, and volumes that mirror
    operational data. This far surpasses limited manual data entry for exercising
    system functionality.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你无法使用生产数据的副本，无论是由于政策原因还是访问限制，另一种选择是生成真实的模拟数据。起点是生成足够大且多样的合成数据集，以模仿实际业务数据的变异性。高质量的数据合成工具和库能够生成合理的对象、关系和数据量，反映出运营数据。这远远超过了有限的手动数据输入，能够更好地测试系统功能。
- en: 'For Salesforce environments, several tools and libraries are at the disposal
    of developers and testers to generate realistic data. Here are some notable ones:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Salesforce 环境，开发人员和测试人员可以使用多种工具和库来生成真实的数据。以下是一些值得注意的工具：
- en: '**Mockaroo**: Mockaroo is an online tool that allows you to generate custom
    datasets. It provides a user-friendly interface to design your data schema and
    can generate thousands of rows of realistic test data that can then be imported
    into Salesforce.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mockaroo**：Mockaroo 是一个在线工具，允许你生成自定义数据集。它提供了一个用户友好的界面，用于设计你的数据架构，并且可以生成成千上万行真实的测试数据，这些数据可以导入
    Salesforce。'
- en: '**GenerateData.com**: As with Mockaroo, [GenerateData.com](http://GenerateData.com)
    is an online tool for creating large datasets of custom test data. It also provides
    flexibility to define a data structure that can be used within Salesforce.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GenerateData.com**：与 Mockaroo 类似， [GenerateData.com](http://GenerateData.com)
    是一个在线工具，用于创建自定义测试数据的大型数据集。它还提供了定义数据结构的灵活性，这些结构可以在 Salesforce 中使用。'
- en: '**Snowfakery**: Snowfakery is a tool designed by Salesforce.org for generating
    realistic, complex, and related data for testing purposes. It allows users to
    create “recipes,” which are instructions for generating data.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Snowfakery**：Snowfakery 是 Salesforce.org 设计的一个工具，用于生成真实、复杂且相关的数据，以供测试使用。它允许用户创建“食谱”，即生成数据的指令。'
- en: '**Data Generation Toolkit**: This tool can help generate complex data in Salesforce,
    providing realistic test data based on a predefined schema.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据生成工具包**：此工具可以帮助在 Salesforce 中生成复杂数据，根据预定义的架构提供真实的测试数据。'
- en: Importing test data
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入测试数据
- en: Importing synthesized data securely into the target Salesforce org is a crucial
    step in preparing the environment for development and testing. Salesforce provides
    several tools to facilitate this task, each suited to different scales and complexities
    of data loading.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将合成数据安全地导入目标 Salesforce 组织是为开发和测试准备环境的关键步骤。Salesforce 提供了多种工具来简化这个过程，每种工具适用于不同规模和复杂度的数据加载。
- en: Import Wizard
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入向导
- en: The Salesforce Import Wizard offers an intuitive interface for importing smaller
    datasets into Salesforce. For example, to import a CSV file with 200 new leads,
    you would navigate to the **Leads** object in Salesforce, click on **Import Leads**,
    and then follow the steps to map the CSV columns to the appropriate Salesforce
    fields.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce 导入向导提供了一个直观的界面，用于将较小的数据集导入 Salesforce。例如，要导入一个包含 200 个新线索的 CSV 文件，你可以导航到
    Salesforce 中的**线索**对象，点击**导入线索**，然后按照步骤将 CSV 列与 Salesforce 中的相应字段进行映射。
- en: The Import Wizard allows you to easily map fields and initiate the import with
    just a few clicks, making it ideal for less complex data imports or smaller data
    volumes. Once the CSV columns are mapped to Salesforce fields, you simply click
    to import the data. With just a few clicks, the Import Wizard provides a user-friendly
    way to get CSV data into Salesforce. There are some limitations with this approach,
    though – you can only import one object at a time, and any lookup fields need
    to be mapped by their underlying ID values, as there is no lookup-by-name logic
    for this process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 导入向导允许您轻松地映射字段并通过几次点击启动导入，使其非常适合较为简单的数据导入或较小的数据量。一旦将 CSV 列映射到 Salesforce 字段，您只需点击导入数据。导入向导通过几次点击提供了一种用户友好的方式将
    CSV 数据导入到 Salesforce。然而，这种方法也有一些限制——您一次只能导入一个对象，并且任何查找字段需要通过其底层 ID 值进行映射，因为该过程没有按名称查找的逻辑。
- en: Bulk API
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Bulk API
- en: The Salesforce Bulk API is designed for programmatically importing large volumes
    of data. For example, to import a CSV file with 2 million account records, you
    could write a script in Python or Java that leverages Bulk API. The script would
    read the CSV file, map the data to the appropriate Salesforce object fields, and
    then use Bulk API to load the records.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce Bulk API 旨在用于编程方式导入大量数据。例如，要导入包含 200 万个帐户记录的 CSV 文件，您可以编写一个 Python
    或 Java 脚本，利用 Bulk API。该脚本将读取 CSV 文件，将数据映射到相应的 Salesforce 对象字段，然后使用 Bulk API 加载记录。
- en: Bulk API V2 handles the complexities of large-scale data loading such as batching
    records and recovering from errors. So, for large or complex datasets, Bulk API
    is preferred over the Import Wizard. With a script to map fields and manage the
    import process, Bulk API enables efficient loading of millions of records into
    Salesforce.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Bulk API V2 处理大规模数据加载的复杂性，如记录分批和错误恢复。因此，对于大型或复杂的数据集，推荐使用 Bulk API 而不是导入向导。通过脚本映射字段和管理导入过程，Bulk
    API 能够高效地将数百万条记录加载到 Salesforce 中。
- en: Bulk API V2 is also capable of importing records for different objects in a
    single operation. This feature sets Bulk API V2 apart from more declarative, straightforward
    tools provided by Salesforce, but requires architects to prepare their datasets
    for success.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Bulk API V2 还可以在一次操作中导入不同对象的记录。这个功能使 Bulk API V2 与 Salesforce 提供的更具声明性、直接的工具有所区别，但它要求架构师为数据集的成功导入做准备。
- en: The foremost step in preparing your dataset for Bulk API V2 operations is to
    thoroughly understand the relationships between different objects you intend to
    import. Salesforce data models often involve intricate relationships such as lookups
    and master-detail links. Ensuring that these relationships are correctly represented
    in your dataset is crucial. This means carefully mapping out parent and child
    records and understanding how they interlink, which can significantly impact import
    order and data integrity.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备数据集进行 Bulk API V2 操作的最关键步骤是彻底了解您打算导入的不同对象之间的关系。Salesforce 数据模型通常涉及复杂的关系，例如查找关系和主从关系。确保这些关系在数据集中正确表示至关重要。这意味着需要仔细映射父子记录并理解它们之间的联系，这将显著影响导入顺序和数据的完整性。
- en: Once the object relationships are clear, the next step is preparing and serializing
    the data for Bulk API V2\. This process involves formatting the data into a compatible
    format (usually CSV or JSON). Special attention must be paid to the way relationships
    are represented in this data. For instance, external IDs can be used to link related
    records instead of Salesforce IDs, which may not be available prior to the import.
    This step often involves cleansing and transforming data to ensure it aligns with
    Salesforce’s data standards and constraints.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦对象关系清晰，下一步是为 Bulk API V2 准备和序列化数据。此过程涉及将数据格式化为兼容的格式（通常为 CSV 或 JSON）。在这一步骤中，必须特别注意如何在数据中表示关系。例如，可以使用外部
    ID 来链接相关记录，而不是 Salesforce ID，因为在导入之前，Salesforce ID 可能不可用。这一步通常涉及数据清洗和转换，以确保其符合
    Salesforce 的数据标准和约束。
- en: Perhaps the most critical aspect of using Bulk API V2 for multiple objects is
    determining the order of operation. Since Salesforce enforces referential integrity,
    parent records must be imported before their children. Therefore, devising a strategic
    import sequence is essential. This might involve creating a dependency tree or
    hierarchy that clearly outlines the order in which different objects should be
    seeded.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Bulk API V2进行多个对象导入时，或许最关键的方面是确定操作顺序。由于Salesforce强制执行引用完整性，父记录必须在子记录之前导入。因此，制定一个战略性的导入顺序至关重要。这可能涉及创建一个依赖关系树或层级结构，清晰地列出不同对象应导入的顺序。
- en: While Bulk API V2 is capable of processing large volumes of data efficiently,
    with large datasets, there’s always a risk of errors or partial successes due
    to data quality issues or Salesforce limits (such as governor limits). Preparing
    for these scenarios involves setting up appropriate error-handling and retry mechanisms.
    This could include parsing error responses from Bulk API and adjusting the dataset
    or the import process accordingly.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Bulk API V2能够高效处理大量数据，但在处理大数据集时，始终存在因数据质量问题或Salesforce限制（如治理限制）而导致错误或部分成功的风险。为这些情况做好准备，包括设置适当的错误处理和重试机制。这可能包括解析Bulk
    API的错误响应，并根据需要调整数据集或导入过程。
- en: Successfully importing records for different objects using Salesforce’s Bulk
    API V2 is a complex yet achievable task. It requires a deep understanding of the
    data model, meticulous preparation of the dataset, strategic planning of the import
    sequence, robust error handling, and thorough testing and validation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Salesforce的Bulk API V2成功导入不同对象的记录是一项复杂但可实现的任务。它需要对数据模型有深入理解，精心准备数据集，合理规划导入顺序，强大的错误处理能力以及全面的测试和验证。
- en: 'An example Python script that imports records into the Account object is shown
    next. This script makes use of the `salesforce-bulk` library, which you can add
    to your Python project with `pip` `install salesforce-bulk`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个示例Python脚本，它将记录导入到账户对象中。该脚本使用`salesforce-bulk`库，你可以通过`pip install salesforce-bulk`将其添加到你的Python项目中：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Data Loader
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据加载器
- en: The Salesforce Data Loader provides a balance between the easy-to-use Import
    Wizard and the fully programmatic Bulk API. With both a **graphical UI** (**GUI**)
    and command-line options that support scripting integration, Data Loader can efficiently
    import datasets ranging from thousands to millions of records.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce数据加载器提供了一个平衡，介于易用的导入向导和完全程序化的Bulk API之间。数据加载器不仅支持**图形用户界面**（**GUI**），还有支持脚本集成的命令行选项，可以高效地导入从数千到数百万条记录的数据集。
- en: For example, to import 75,000 contact records with related account data from
    a CSV file, you would launch Data Loader, authenticate to your Salesforce org,
    select the Contact object, map the CSV columns to Salesforce fields, and start
    the import process.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要从CSV文件中导入75,000条联系人记录及其相关账户数据，你需要启动数据加载器，验证你的Salesforce组织，选择联系人对象，将CSV列映射到Salesforce字段，并开始导入过程。
- en: Data Loader handles batching and mapping complex data relationships. So, for
    medium-sized datasets or imports requiring some customization, Data Loader strikes
    a useful middle ground between the simplicity of the Import Wizard and the scripting
    of Bulk API.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载器处理批量操作并映射复杂的数据关系。因此，对于中等规模的数据集或需要一定自定义的导入，数据加载器在导入向导的简单性和Bulk API脚本化之间找到一个有用的平衡点。
- en: Data load automation
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据加载自动化
- en: Automating the end-to-end seeding workflow through scripts or software is pivotal
    for efficiency, consistency, and reliability in preparing development environments
    for realistic testing and development. Manual processes tend to be slow, repetitive,
    and error-prone, making them less ideal for tasks that require precision and speed.
    In contrast, automation eradicates these issues by scripting the processes of
    data generation, transformation, validation, and loading into the Salesforce environment.
    This ensures identical datasets in each sandbox or scratch org without the need
    for manual intervention, thereby saving time and reducing the likelihood of errors.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过脚本或软件自动化端到端的数据种植工作流程，对于提高开发环境的效率、一致性和可靠性至关重要，从而为现实测试和开发做好准备。人工过程通常较慢、重复且容易出错，因此不适合需要精度和速度的任务。相比之下，自动化通过脚本化数据生成、转换、验证和加载过程，消除了这些问题，确保每个沙盒或临时组织中的数据集完全相同，无需人工干预，从而节省时间并减少错误的可能性。
- en: A practical approach to this automation could involve scripting the data generation
    process to create a sizable and diverse dataset that closely mirrors actual business
    data. This script could be scheduled to run at specified intervals or triggered
    by certain events, ensuring a continuous supply of fresh data for development
    and testing activities.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种自动化的实际方法可能涉及编写数据生成过程的脚本，以创建一个相当大且多样化的数据集，尽可能接近实际业务数据。这个脚本可以安排在指定的时间间隔运行，或者根据特定事件触发，确保为开发和测试活动提供持续的最新数据。
- en: Following data generation, an automated data transformation process could be
    implemented to ensure that the data aligns with the schema and business logic
    of the Salesforce environment it will be loaded into. This could include tasks
    such as field mapping, data type conversion, and data cleansing, all of which
    prepare the data for loading. Also consider data truncation – if the data generation
    is from production and the amount of data goes beyond the capacity of the target
    sandboxes, this will need attending to, of course.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据生成后，可以实施自动化的数据转换过程，确保数据与它将要加载的 Salesforce 环境的架构和业务逻辑保持一致。这可能包括字段映射、数据类型转换和数据清理等任务，所有这些都为数据加载做好准备。同时，也要考虑数据截断——如果数据生成来自生产环境，并且数据量超出了目标沙箱的容量，当然需要特别处理。
- en: Validation is a key step in this automated workflow, ensuring the accuracy and
    relevance of the data before it’s loaded into the development environment. Automated
    validation scripts could be developed to check the data for consistency, completeness,
    and adherence to business rules, thus ensuring that the data is of high quality
    and representative of real-world scenarios.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 验证是自动化工作流中的关键步骤，确保数据在加载到开发环境之前的准确性和相关性。可以开发自动化验证脚本来检查数据的一致性、完整性和是否遵循业务规则，从而确保数据具有高质量，并能代表实际场景。
- en: The data loading process is the final step, where some of the tools we discussed
    earlier, such as Salesforce Data Loader or Bulk API, could be scripted to automate
    the data loading process. For instance, a script could be written to use Data
    Loader to import the data, handle any errors that arise during the import, and
    log the results of the import for review. This would ensure that the data is loaded
    into the Salesforce environment efficiently and reliably.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载过程是最后一步，在这一过程中，我们之前讨论过的一些工具，例如 Salesforce 数据加载器或 Bulk API，可以通过脚本自动化数据加载过程。例如，可以编写一个脚本，使用数据加载器导入数据，处理导入过程中出现的任何错误，并记录导入结果以供审核。这将确保数据高效且可靠地加载到
    Salesforce 环境中。
- en: The overarching benefit of this automation is the assurance of consistency across
    different development environments. By scripting the entire data seeding workflow,
    close-to-identical datasets can be ensured in each environment, thus providing
    a uniform landscape for testing and development. This is particularly beneficial
    in agile or **continuous integration/continuous deployment** (**CI/CD**) setups,
    where consistency and speed are of the essence. We talk of “close to” identical
    because taking source data from prod (and transforming/masking) on request could
    mean different results when done a week apart.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这种自动化的总体好处是确保不同开发环境之间的一致性。通过脚本化整个数据播种工作流，可以确保每个环境中的数据集几乎相同，从而为测试和开发提供统一的环境。这在敏捷或**持续集成/持续部署**（**CI/CD**）设置中尤为重要，因为一致性和速度至关重要。我们说是“接近”相同，因为从生产环境提取源数据（并进行转换/屏蔽）时，根据请求的时间间隔不同，可能会导致不同的结果。
- en: A continuous data seeding setup could be established to keep development environments
    constantly updated with fresh data, which is beneficial for ongoing testing and
    development, especially in dynamic projects with frequently changing requirements.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 可以建立持续的数据播种设置，使开发环境始终保持更新的最新数据，这对于持续的测试和开发非常有利，尤其是在需求频繁变化的动态项目中。
- en: Handling relationships
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理关系
- en: When extracting and seeding data into development environments, you should capture
    and recreate relational links and dependencies between different objects and records.
    Salesforce data has intricate, interconnected relationships between various entities
    such as Accounts, Contacts, Opportunities, and so on. If you don’t maintain these
    relationships while seeding data, you can quickly break data integrity and cause
    cascading issues in the seeded datasets.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据提取并导入开发环境时，您应捕捉并重建不同对象和记录之间的关系链接和依赖。Salesforce数据具有复杂的、相互关联的关系，涉及诸如账户、联系人、机会等多个实体。如果在导入数据时不保持这些关系，可能会迅速破坏数据完整性，并导致种子数据集中的级联问题。
- en: To maintain data integrity, you should study the object metadata and data model
    to gain a clear understanding of key relationships and dependencies between objects.
    For example, Contacts have a relationship to Accounts via the `AccountId` field.
    Opportunities have relationships to Accounts and Contacts.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了维护数据完整性，您应研究对象元数据和数据模型，以清晰地了解对象之间的关键关系和依赖。例如，联系人通过`AccountId`字段与账户相关联。机会与账户和联系人之间存在关系。
- en: When you move on to extracting this data, care should be taken to extract related
    parent and child records together. For example, Accounts should be extracted along
    with their child Contacts and Opportunities. The related `ContactId` and `OpportunityId`
    fields need to be populated correctly to link records.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当您开始提取这些数据时，应该小心地一起提取相关的父记录和子记录。例如，账户应该与其子记录（如联系人和机会）一起提取。相关的`ContactId`和`OpportunityId`字段需要正确填充，以链接记录。
- en: Similarly, when importing datasets into target environments, these same dependencies
    need to be handled appropriately. This includes importing data in the correct
    order so that dependencies are in place in advance. Parent records such as Accounts
    must be inserted first before child records such as Contacts and Opportunities,
    and any external ID fields used for relationships should be mapped to field values
    from the target environment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在将数据集导入目标环境时，需要适当处理这些相同的依赖关系。这包括按正确顺序导入数据，以便提前建立依赖关系。必须先插入父记录（如账户），然后再插入子记录（如联系人和机会），并且任何用于关系的外部ID字段都应映射到目标环境中的字段值。
- en: For advanced relationships such as junction objects and many-to-many relationships,
    mapping the relationship fields and inserting records in the right order is equally
    important. Testing the inserted datasets to validate relationships is highly recommended.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于如连接对象和多对多关系等高级关系，映射关系字段并按正确顺序插入记录同样重要。建议测试插入的数据集以验证关系。
- en: Considerations for test-data management
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试数据管理的注意事项
- en: In each of these scenarios, it’s paramount to ensure that data integrity is
    maintained and sensitive information is handled securely during the import process.
    Leveraging these tools responsibly and in accordance with the scale of data to
    be imported will streamline the data injection process, making the Salesforce
    org ready for development and testing activities.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些场景中，确保数据完整性得到维护，并且在导入过程中安全地处理敏感信息至关重要。负责任地使用这些工具，并根据要导入的数据规模进行操作，将简化数据注入过程，使Salesforce组织为开发和测试活动做好准备。
- en: 'Equally important is enforcing tight security protocols on generated data.
    Some steps toward achieving that are listed next:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是对生成的数据实施严格的安全协议。以下是实现这一目标的一些步骤：
- en: '**Data sanitization**: Sensitive information should be anonymized or masked
    before use in sandboxes'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据清洗**：敏感信息应在用于沙盒环境之前进行匿名化或屏蔽。'
- en: '**Data protection**: Data security policies should be defined and implemented
    through encryption, tokenization, masking, and similar techniques'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据保护**：应通过加密、令牌化、屏蔽和类似技术来定义并实施数据安全政策。'
- en: '**Data access**: Access controls on data loading tools should be properly configured'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据访问**：数据加载工具的访问控制应配置正确。'
- en: Data seeding creates representative Salesforce environments to enable authentic
    validation. Realistic datasets, bulk loading tools, automation, modeling relationships,
    and stringent security considerations are all best practices for seamless, efficient
    seeding. Investing in these techniques pays dividends through improved testing,
    fewer defects, and smoother production deployments.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 数据播种创建了代表性的Salesforce环境，以便进行真实的验证。现实的数据集、大量加载工具、自动化、建模关系和严格的安全措施是确保数据播种顺利高效的最佳实践。投资这些技术将带来更好的测试、更少的缺陷和更平滑的生产部署。
- en: Protecting sensitive data with data masking
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过数据掩码保护敏感数据
- en: Safeguarding sensitive data is a top priority when managing vast amounts of
    information, especially in Salesforce environments. Data masking has emerged as
    a vital technique to address privacy, compliance, security, and confidentiality
    concerns that come with handling sensitive data in test and development environments.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理大量信息时，保护敏感数据是首要任务，尤其是在Salesforce环境中。数据掩码已经成为解决隐私、合规、安全和保密问题的关键技术，尤其是在处理测试和开发环境中的敏感数据时。
- en: Understanding data masking
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解数据掩码
- en: Data masking, also called **data obfuscation** or **anonymization**, protects
    sensitive details by replacing, encrypting, or altering the original data with
    modified, fictional versions. This retains the utility of the data for testing
    needs while eliminating the risks of exposing sensitive information.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据掩码，也称为**数据混淆**或**匿名化**，通过替换、加密或更改原始数据，使用修改过的虚构版本来保护敏感信息。这保留了数据在测试中的效用，同时消除了暴露敏感信息的风险。
- en: 'Common data masking approaches include the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的数据掩码方法包括以下几种：
- en: '**Static data masking (SDM)**: Masking the data at rest before transfer to
    testing environments'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**静态数据掩码（SDM）**：在将数据转移到测试环境之前对数据进行静态掩码'
- en: '**Dynamic data masking (DDM)**: Real-time masking as the data is accessed'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态数据掩码（DDM）**：在数据访问时进行实时掩码'
- en: '**Format-preserving encryption (FPE)**: Encrypting data while retaining the
    original data format'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式保留加密（FPE）**：加密数据同时保持原始数据格式'
- en: Privacy concerns
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐私问题
- en: Data masking upholds privacy by ensuring personally identifiable and confidential
    data remains secure in testing environments with lower security controls compared
    to production. Individuals and organizations expect their data to be handled securely,
    and masking helps preserve that confidentiality. This can be especially important
    in a situation where third-party contractors are brought in to work on a project
    for a customer. Full-time employees might have access to the production environment
    and its data, but contractors are less likely to.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 数据掩码通过确保在安全性较低的测试环境中仍然保护个人身份信息和机密数据，来维护隐私。个人和组织期望他们的数据能够得到安全处理，而掩码有助于保护这种保密性。在需要第三方承包商为客户的项目工作时，这一点尤其重要。全职员工可能有权限访问生产环境及其数据，但承包商不太可能拥有这些权限。
- en: Compliance and regulatory requirements
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 合规性和监管要求
- en: Data masking also meets compliance needs by adhering to regulations that mandate
    data protection, such as the **General Data Protection Regulation** (**GDPR**)
    and the **Health Insurance Portability and Accountability Act** (**HIPAA**). This
    builds trust with customers and stakeholders. Compliance is about more than just
    avoiding penalties – it maintains crucial trust.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 数据掩码还通过遵守规定的数据保护法规来满足合规需求，例如**通用数据保护条例**（**GDPR**）和**健康保险流通与问责法案**（**HIPAA**）。这有助于与客户和利益相关者建立信任。合规不仅仅是为了避免处罚——它保持着至关重要的信任。
- en: Security and confidentiality
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全性与保密性
- en: In addition, data masking reduces threats of unauthorized data access and breaches.
    It strengthens security by converting sensitive details into realistic but fictional
    data, reducing risk considerably.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，数据掩码通过将敏感信息转换为真实但虚构的数据，减少了未经授权的数据访问和泄露威胁，从而显著降低了风险，增强了安全性。
- en: Implementing data masking
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施数据掩码
- en: 'Implementing data masking in Salesforce is critical to ensure the privacy and
    security of sensitive information, especially when transferring data from production
    to less secure development or testing environments. There are several approaches
    to enable data masking in Salesforce, and we’ll look at a few of these in turn:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在Salesforce中实施数据掩码对确保敏感信息的隐私和安全至关重要，特别是在将数据从生产环境转移到较不安全的开发或测试环境时。有几种方法可以在Salesforce中启用数据掩码，接下来我们将依次介绍其中的几种：
- en: '**Programmatic masking**: You can write your own custom code to implement data
    masking programmatically. This gives full control over how data is masked to meet
    specific needs. However, it requires expertise in both the data structure and
    Salesforce platform and can be time-intensive to develop and maintain.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编程掩码**：你可以编写自定义代码来实现数据掩码编程。这可以完全控制数据掩码的方式，以满足特定需求。然而，它需要对数据结构和Salesforce平台有深入了解，并且可能需要投入大量时间来开发和维护。'
- en: '**Salesforce Data Mask**: This is Salesforce’s own managed data masking solution.
    It helps comply with data regulations by masking sensitive fields and objects,
    both standard and custom. Different masking levels can be configured based on
    data sensitivity, and once masked, the data cannot be unmasked or replicated in
    other environments in a readable form. Data Mask is installed and configured in
    a production org, and then masking is executed from sandboxes created from that
    production org. This helps protect regulated data such as PII in sandboxes mirroring
    production, enabling faster testing.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Salesforce数据掩码**：这是Salesforce自有的托管数据掩码解决方案。它通过掩码敏感字段和对象（包括标准和自定义字段）来帮助遵守数据法规。可以根据数据敏感性配置不同的掩码级别，掩码后的数据无法恢复或在其他环境中以可读形式复制。数据掩码安装并配置在生产组织中，然后在从该生产组织创建的沙盒中执行掩码。这有助于保护沙盒中与生产环境相同的受管数据，如PII，从而加快测试速度。'
- en: '**DevOps tools with masking**: Tools such as Gearset and DataMasker have built-in
    data masking capabilities. For example, Gearset can kick off a data deployment
    and then mask selected data according to configured settings before loading to
    the destination org. DataMasker quickly masks large datasets, prevents email and
    automation accidents, and aids compliance with regulations such as GDPR and HIPAA.
    It integrates with DevOps tools such as Copado and provides realistic masking
    formats.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带有数据掩码的DevOps工具**：如Gearset和DataMasker等工具具有内置的数据掩码功能。例如，Gearset可以启动数据部署，然后根据配置的设置在加载到目标组织之前掩码选定的数据。DataMasker可以快速掩码大型数据集，防止电子邮件和自动化事故，并帮助遵守GDPR和HIPAA等法规。它与DevOps工具如Copado集成，并提供真实的掩码格式。'
- en: These methods provide options to fit different technical skills, resources,
    and requirements. They ensure sensitive information remains protected while still
    enabling meaningful development and testing work on Salesforce environments –
    a crucial balance to strike. The right data masking approach is key to safeguarding
    privacy while allowing progress.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法提供了适应不同技术技能、资源和需求的选项。它们确保敏感信息得到保护，同时仍能在Salesforce环境中进行有意义的开发和测试工作——这是一个需要平衡的关键。正确的数据掩码方法是保护隐私并推动进展的关键。
- en: Compliance and best practices
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合规性和最佳实践
- en: 'Managing test data for your testing and development environments needs a meticulous
    approach to comply with data protection laws and follow best practices. Some key
    regulations related to sensitive data include GDPR, the **Children’s Online Privacy
    Protection Act** (**COPPA**), the **Personal Information Protection Law** (**PIPL**),
    HIPAA, and the **California Consumer Privacy Act** (**CCPA**), but this is not
    an exhaustive list. Here’s an overview of the aforementioned regulations:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 管理测试数据以满足数据保护法并遵循最佳实践，需要细致的方法。与敏感数据相关的一些主要法规包括GDPR、**儿童在线隐私保护法**（**COPPA**）、**个人信息保护法**（**PIPL**）、HIPAA和**加利福尼亚消费者隐私法案**（**CCPA**），但这并不是一个详尽无遗的列表。以下是上述法规的概述：
- en: GDPR imposes robust requirements for handling EU citizen data, requiring you
    to handle data responsibly and for clearly stated purposes
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GDPR对处理欧盟公民数据提出了严格要求，要求你负责任地处理数据并明确声明用途。
- en: COPPA protects children’s online privacy, placing specific requirements on websites
    or services for children
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COPPA保护儿童的在线隐私，对面向儿童的网站或服务提出了具体要求。
- en: China’s PIPL is like GDPR, focusing on safeguarding the personal information
    of Chinese citizens
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中国的PIPL类似于GDPR，重点保护中国公民的个人信息。
- en: HIPAA is related to healthcare data and is primarily of note in that industry,
    as it requires the secure handling of patient health data, outlining protections
    for confidentiality, integrity, and availability
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HIPAA与医疗保健数据相关，主要在该行业中引起注意，因为它要求安全处理患者的健康数据，概述了对机密性、完整性和可用性的保护措施。
- en: CCPA underscores protecting California residents’ personal information
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CCPA强调保护加利福尼亚居民的个人信息。
- en: Beyond these regulations, there are some best practices that it is important
    to follow. Using data masking to obscure sensitive details while keeping data’s
    testing utility is recommended – some may choose to implement custom approaches
    to randomize data within specific ranges to maintain a degree of relevance. For
    example, take the `AnnualRevenue` field on Account – while a number, they’d never
    expect 1 or something and want to keep a similar sort of range to randomized data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些规定外，还有一些最佳实践是必须遵循的。建议使用数据屏蔽来隐匿敏感细节的同时保持数据的测试效用——有些人可能会选择实施自定义方法，以在特定范围内随机化数据，从而保持一定的相关性。例如，以`AnnualRevenue`字段为例——虽然它是一个数字，但他们不会期望看到1或某个非常低的值，而是希望保持一个类似的随机数据范围。
- en: Encryption adds security during the storage and transmission of sensitive data.
    Applying strong access controls ensures only those with authorized access can
    view your data, with **role-based access control** (**RBAC**) enabling tiered
    access. Excluding sensitive data from source control repositories prevents unauthorized
    access and breaches, even inadvertently.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 加密在存储和传输敏感数据过程中增加了安全性。应用强大的访问控制确保只有授权用户才能查看您的数据，而**基于角色的访问控制**（**RBAC**）则实现了分层访问。将敏感数据排除在源代码管理库之外，防止未经授权的访问和泄漏，即使是无意间的。
- en: With masking or dummy data, maintaining data relationships and formats is key
    for realistic, meaningful testing. This includes preserving referential integrity
    and aligning with application logic so that your test data isn’t the cause of
    any issues or errors, creating false negatives in your testing work.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用屏蔽或虚拟数据时，保持数据关系和格式的完整性对于现实且有意义的测试至关重要。这包括保持引用完整性并与应用逻辑对齐，以确保测试数据不会引起任何问题或错误，从而避免在测试过程中出现假阴性。
- en: Complying with regulations and following best practices in data management is
    vital for secure, effective testing. The goal with dummy or obfuscated real data
    is to ensure privacy and security while enabling productive testing and development.
    This careful data management greatly contributes to reliable, smooth DevOps processes,
    facilitating the transition from development to production with data integrity.
    A great best practice to start this process is to use the data classification
    metadata fields provided by Salesforce and ensure they’re accurate and populated
    for new fields going forward. Accurate information here will help audits, masking,
    and third-party tools.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 遵守规定并遵循数据管理的最佳实践，对于安全且高效的测试至关重要。使用虚拟数据或经过屏蔽的真实数据的目标是确保隐私和安全，同时支持高效的测试和开发。谨慎的数据管理对于可靠且顺利的DevOps流程有着重要贡献，促进了从开发到生产的过渡，同时保持数据完整性。一个很好的最佳实践是使用Salesforce提供的数据分类元数据字段，并确保它们准确无误，且对新字段进行正确填充。这里的准确信息将有助于审计、屏蔽和第三方工具的使用。
- en: Tools and resources
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具和资源
- en: Having the right tools and resources is critical when undertaking data seeding
    and masking in Salesforce. Assembling a robust toolkit and connecting with a network
    of resources can significantly enhance efficiency and enable effective data management
    practices for secure, productive testing environments.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行Salesforce的数据种植和屏蔽时，拥有正确的工具和资源至关重要。组建一个强大的工具包并与资源网络连接，可以显著提高效率，并使得有效的数据管理实践得以实现，为安全且高效的测试环境提供支持。
- en: Salesforce provides powerful native tools such as Data Mask for masking sensitive
    information in sandboxes, essential for data privacy compliance during testing.
    Data loaders such as Salesforce Data Loader and third parties are crucial for
    automating data import and export between environments and external systems.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce提供了强大的本地工具，如Data Mask，用于在沙箱环境中屏蔽敏感信息，这对于测试过程中遵循数据隐私合规性至关重要。像Salesforce
    Data Loader这样的数据加载工具以及第三方工具在自动化环境之间及外部系统间的数据导入导出中起着关键作用。
- en: Additional data masking tools such as DataMasker and DevOps tools with built-in
    masking functionality provide different techniques to protect data while retaining
    utility. Encryption tools add an extra layer of security for data at rest and
    in transit, helping keep it secure throughout its life cycle. Access control solutions
    such as role-based systems help manage authorized access to sensitive data, whether
    that is in Salesforce itself or in connected systems.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的数据屏蔽工具，如DataMasker和具有内置屏蔽功能的DevOps工具，提供了不同的技术来保护数据的同时保持其实用性。加密工具为静态和传输中的数据增加了额外的安全层，帮助确保数据在其生命周期中的安全性。
- en: Tapping into online communities, forums, documentation, training materials,
    conferences, and experts provides invaluable insights on the latest tools, trends,
    and best practices for Salesforce data management, seeding, masking, and compliance.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 参与在线社区、论坛、文档、培训材料、会议和专家的互动，能够提供关于Salesforce数据管理、数据播种、数据掩码和合规性方面最新工具、趋势和最佳实践的宝贵见解。
- en: Having a toolkit tailored to your needs and connecting with a network of resources
    enables successful navigation of the intricacies of Salesforce data management.
    This empowers organizations to boost efficiency, ensure compliance, and build
    secure, productive testing environments through effective data practices.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一套量身定制的工具包，并与资源网络连接，可以帮助你成功应对Salesforce数据管理的复杂性。这使得组织能够通过有效的数据实践，提高效率，确保合规性，并构建安全、富有成效的测试环境。
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the importance of seeding development environments
    with accurate, realistic data to ensure robust testing and development within
    Salesforce.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了为开发环境提供准确、真实的数据的重要性，以确保在Salesforce中进行强有力的测试和开发。
- en: We explored using sample data from production environments, as well as the alternative
    approach of data generation with the various tools available for generating and
    importing test data.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了使用来自生产环境的示例数据，以及另一种通过各种工具生成和导入测试数据的替代方法。
- en: We covered the importance of data masking, to protect sensitive information
    to comply with global data protection regulations such as GDPR and HIPAA, and
    looked at best practices for managing data in non-production environments.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了数据掩码的重要性，以保护敏感信息并遵守全球数据保护法规（如GDPR和HIPAA），并探讨了在非生产环境中管理数据的最佳实践。
- en: These techniques and strategies can be brought together as an approach to effective
    data management in your development and testing environments. You will then be
    well equipped to meet the security and compliance needs of your organization while
    having a working set of data to accelerate your development life cycle.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术和策略可以作为一种有效的数据管理方法，应用于你的开发和测试环境。这样，你将能够充分满足组织的安全性和合规性需求，同时拥有一套工作数据，加速开发生命周期。
- en: In the next chapter, we’ll start to examine the dedicated Salesforce DevOps
    products available on the market, starting with an in-depth exploration of Gearset.
    We’ll examine its capabilities and features and how it fits into the broader landscape
    of Salesforce DevOps tools.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始研究市场上专为Salesforce DevOps设计的产品，首先深入探索Gearset。我们将考察其功能和特点，以及它如何融入Salesforce
    DevOps工具的广泛生态中。
