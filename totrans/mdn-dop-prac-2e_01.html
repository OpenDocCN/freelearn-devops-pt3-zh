<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer016">
			<h1 id="_idParaDest-15" class="chapter-number"><a id="_idTextAnchor016"/>1</h1>
			<h1 id="_idParaDest-16"><a id="_idTextAnchor017"/>The Modern Way of DevOps</h1>
			<p>This first chapter will provide some background knowledge of DevOps practices, processes, and tools. We will understand modern DevOps and how it differs from traditional DevOps. We will also introduce containers and understand in detail how containers within the cloud change the entire IT landscape so that we can build on this book’s base. While this book does not entirely focus on containers and their orchestration, modern DevOps practices heavily <span class="No-Break">emphasize it.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>What <span class="No-Break">is DevOps?</span></li>
				<li>Introduction to <span class="No-Break">cloud computing</span></li>
				<li>Understanding modern <span class="No-Break">cloud-native applications</span></li>
				<li>Modern DevOps versus <span class="No-Break">traditional DevOps</span></li>
				<li>The need <span class="No-Break">for containers</span></li>
				<li><span class="No-Break">Container architecture</span></li>
				<li>Containers and modern <span class="No-Break">DevOps practices</span></li>
				<li>Migrating to containers from <span class="No-Break">virtual machines</span></li>
			</ul>
			<p>By the end of this chapter, you should understand the following <span class="No-Break">key aspects:</span></p>
			<ul>
				<li>What DevOps is and what role it plays in the modern <span class="No-Break">IT landscape</span></li>
				<li>What cloud computing is and how it has changed <span class="No-Break">IT services</span></li>
				<li>What a modern cloud-native application looks like and how it has <span class="No-Break">changed DevOps</span></li>
				<li>Why we need containers and what problems <span class="No-Break">they solve</span></li>
				<li>The container architecture and how <span class="No-Break">it works</span></li>
				<li>How containers contribute to modern <span class="No-Break">DevOps practices</span></li>
				<li>The high-level steps of moving from a virtual machine-based architecture <span class="No-Break">to containers</span></li>
			</ul>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor018"/><a id="_idTextAnchor019"/>What is DevOps?</h1>
			<p>As you know, software development and operations were traditionally handled by separate teams with distinct roles and responsibilities. Developers focused on writing code and creating new features, while operations teams focused on deploying and managing the software in production environments. This separation often led to communication gaps, slow release cycles, and <span class="No-Break">inefficient processes.</span></p>
			<p><strong class="bold">DevOps</strong> bridges <a id="_idIndexMarker000"/>the gap between development and operations by promoting a culture of collaboration, shared responsibilities, and continuous feedback using automation throughout the software development <span class="No-Break">life cycle.</span></p>
			<p>It is a set of principles and practices, as well as a philosophy, that encourage the participation of the development and operations teams in the entire software development life cycle, including software maintenance and operations. To implement this, organizations manage several processes and tools that help automate the software delivery process to improve speed and <a id="_idIndexMarker001"/>agility, reduce the cycle time of code release through <strong class="bold">continuous integration and continuous delivery</strong> (<strong class="bold">CI/CD</strong>) pipelines, and monitor the applications running <span class="No-Break">in production.</span></p>
			<p>A DevOps team<a id="_idIndexMarker002"/> should ensure that instead of having a clear set of siloed groups that do development, operations, and QA, they have a single team that takes care of the entire SDLC life cycle – that is, the team will build, deploy, and monitor the software. The combined team owns the whole application instead of certain functions. That does not mean that people don’t have specialties, but the idea is to ensure that developers know something about operations and that operations engineers know something about development. The QA team<a id="_idIndexMarker003"/> works hand in hand with developers and operations engineers to understand the business requirements and various issues faced in the field. Based on these learnings, they need to ensure that the product they are developing meets business requirements and addresses problems encountered in <span class="No-Break">the field.</span></p>
			<p>In a traditional development team, the source of the backlog is the business and its architects. However, for a <a id="_idIndexMarker004"/>DevOps team, there are two sources of their daily backlog – the business and its architects and the customers and issues that they face while they’re operating their application in production. Therefore, instead of following a linear path of software delivery, DevOps practices generally follow an infinity loop, as shown in the <a id="_idIndexMarker005"/><span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer007" class="IMG---Figure">
					<img src="image/B19877_Figure_1.01.jpg" alt="Figure 1.1 – DevOps infinity loop" width="1287" height="626"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – DevOps infinity loop</p>
			<p>To ensure smooth interoperability between people of different skill sets, DevOps focuses heavily on automation and tools. DevOps aims to ensure that we try to automate repeatable tasks as much as possible and focus on more important things. This ensures product quality and speedy delivery. DevOps focuses on <em class="italic">people</em>, <em class="italic">processes</em>, and <em class="italic">tools</em>, giving the most importance to people and the least to tools. We generally use tools to automate processes that help people achieve the <span class="No-Break">right goals.</span></p>
			<p>Some of the fundamental ideas and jargon that a DevOps engineer generally encounters are as follows. We are going to focus heavily on each throughout <span class="No-Break">this book:</span></p>
			<ul>
				<li><strong class="bold">Continuous </strong><span class="No-Break"><strong class="bold">integration</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CI</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p>CI is a software<a id="_idIndexMarker006"/> development practice that involves frequently merging code changes from multiple developers into a shared repository, typically several times a day. This ensures that your developers regularly merge code into a central repository where automated builds and tests run to provide real-time feedback to the team. This reduces cycle time significantly and improves the quality of code. This process aims to minimize bugs within the code early within the cycle rather than later during the test phases. It detects integration issues early and ensures that the software always remains in a <span class="No-Break">releasable state.</span></p>
			<ul>
				<li><strong class="bold">Continuous </strong><span class="No-Break"><strong class="bold">delivery</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CD</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p>CD is all about shipping your <a id="_idIndexMarker007"/>tested software into your production environment whenever it is ready. So, a CD pipeline will build your changes into packages and run integration and system tests on them. Once you have thoroughly tested your code, you can automatically (or on approval) deploy changes to your test and production environments. So, CD aims to have the latest set of tested artifacts ready <span class="No-Break">to deploy.</span></p>
			<ul>
				<li><strong class="bold">Infrastructure as </strong><span class="No-Break"><strong class="bold">Code</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">IaC</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p>IaC is a practice in software<a id="_idIndexMarker008"/> development that involves managing and provisioning infrastructure resources, such as servers, networks, and storage, using code and configuration files rather than manual processes. IaC treats infrastructure as software, enabling teams to define and manage infrastructure resources in a programmable and version-controlled manner. With the advent of virtual machines, containers, and the cloud, technology infrastructure has become virtual to a large extent. This means we can build infrastructure through API calls and templates. With modern tools, we can also build infrastructure in the cloud declaratively. This means that you can now build IaC, store the code needed to build the infrastructure within a source code repository such as Git, and use a CI/CD pipeline to spin and manage <span class="No-Break">the infrastructure.</span></p>
			<ul>
				<li><strong class="bold">Configuration as </strong><span class="No-Break"><strong class="bold">code</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CaC</strong></span><span class="No-Break">)</span></li>
			</ul>
			<p>CaC is a practice in <a id="_idIndexMarker009"/>software development and system administration that involves managing and provisioning configuration settings using code and version control systems. It treats configuration settings as code artifacts, enabling teams to define, store, and manage configuration in a programmatic and reproducible manner. Historically, servers used to be built manually from scratch and seldom changed. However, with elastic infrastructure in place and an emphasis on automation, the configuration can also be managed using code. CaC goes hand in hand with IaC for building scalable, fault-tolerant infrastructure so that your application can <span class="No-Break">run seamlessly.</span></p>
			<ul>
				<li><strong class="bold">Monitoring </strong><span class="No-Break"><strong class="bold">and logging</strong></span></li>
			</ul>
			<p>Monitoring<a id="_idIndexMarker010"/> and logging are essential practices in software development and operations that involve capturing and analyzing data about the behavior and performance of software applications and systems. They provide insights into the software’s health, availability, and performance, enabling teams to identify issues, troubleshoot problems, and make informed decisions for improvement. Monitoring and logging come under observability, which is a crucial area for any DevOps team – that is, knowing when your application has issues and exceptions using monitoring and triaging them using logging. These practices and tools form your eye, and it is a critical area in the DevOps stack. In addition, they contribute a lot to building the backlog of a <span class="No-Break">DevOps team.</span></p>
			<ul>
				<li><strong class="bold">Communication </strong><span class="No-Break"><strong class="bold">and collaboration</strong></span></li>
			</ul>
			<p>Communication and collaboration<a id="_idIndexMarker011"/> are crucial aspects of DevOps practices. They promote effective teamwork, knowledge sharing, and streamlined workflows across development, operations, and other stakeholders involved in the software delivery life cycle. Communication and collaboration make a DevOps team function well. Gone are the days when communication used to be through emails. Instead, modern DevOps teams manage their backlog using ticketing and Agile tools, keep track of their knowledge articles and other <a id="_idIndexMarker012"/>documents using a wiki, and <a id="_idIndexMarker013"/>communicate instantly using chat and <strong class="bold">instant messaging</strong> (<span class="No-Break"><strong class="bold">IM</strong></span><span class="No-Break">) tools.</span></p>
			<p>While these are just a few core aspects of DevOps practices and tools, there have been recent changes with the advent of containers and the cloud – that is, the modern cloud-native application stack. Now that we’ve covered a few buzzwords in this section, let’s understand what we mean by the cloud and <span class="No-Break">cloud computing.</span></p>
			<h1 id="_idParaDest-18"><a id="_idTextAnchor020"/>Introduction to cloud computing</h1>
			<p>Traditionally, software applications used to<a id="_idIndexMarker014"/> run on servers that ran on in-house computers (servers), known as <strong class="bold">data centers</strong>. This meant that an organization would have to buy and manage physical computer and networking infrastructure, which used to be a considerable capital expenditure, plus they had to spend quite a lot on operating expenses. In addition, servers used to fail and required maintenance. This meant smaller companies who wanted to try things would generally not start because of the <a id="_idIndexMarker015"/>huge <strong class="bold">capital expenditure</strong> (<strong class="bold">CapEx</strong>) involved. This suggested that projects had to be well planned, budgeted, and architected well, and then infrastructure was ordered and provisioned accordingly. This also meant that quickly scaling infrastructure with time would not be possible. For example, suppose you started small and did not anticipate much traffic on the site you were building. Therefore, you ordered and provisioned fewer resources, and the site suddenly became popular. In that case, your servers won’t be able to handle that amount of traffic and will probably crash. Scaling that quickly would involve buying new hardware and then adding it to the data center, which would take time, and your business may lose that window <span class="No-Break">of opportunity.</span></p>
			<p>To solve this problem, internet giants such as Amazon, Microsoft, and Google started building public infrastructure to run their internet systems, eventually leading them to launch it for public use. This led to a new phenomenon known <a id="_idIndexMarker016"/>as <span class="No-Break"><strong class="bold">cloud computing</strong></span><span class="No-Break">.</span></p>
			<p>Cloud computing refers <a id="_idIndexMarker017"/>to delivering on-demand computing resources, such as servers, storage, databases, networking, software, and analytics, over the internet. Rather than hosting these resources locally on physical infrastructure, cloud computing allows organizations to access <a id="_idIndexMarker018"/>and utilize<a id="_idIndexMarker019"/> computing services provided by <strong class="bold">cloud service providers</strong> (<strong class="bold">CSPs</strong>). Some of the leading public CSPs <a id="_idIndexMarker020"/>are <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), <strong class="bold">Microsoft Azure</strong>, and <strong class="bold">Google </strong><span class="No-Break"><strong class="bold">Cloud Platform</strong></span><span class="No-Break">.</span></p>
			<p>In cloud computing, the CSP owns, maintains, and manages the underlying infrastructure and resources, while the users or organizations leverage these resources for their applications <span class="No-Break">and services.</span></p>
			<p>Simply put, cloud computing is nothing but using someone else’s data center to run your application, which should be on demand. It should have a control panel through a web portal, APIs, and so on over the internet to allow you to do so. In exchange for these services, you need to pay rent for the resources you provision (or use) on a <span class="No-Break">pay-as-you-go basis.</span></p>
			<p>Therefore, cloud computing offers several benefits and opens new doors for businesses like never before. Some of these benefits are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Scalability</strong>: Resources <a id="_idIndexMarker021"/>on the cloud are scalable. This means you can add new servers or resources to existing servers when needed. You can also automate scaling with traffic for your application. This means that if you need one server to run your application, and suddenly because of popularity or peak hours, you need five, your application can automatically scale to five servers using cloud computing APIs and inbuilt management resources. This gives businesses a lot of power as they can now start small, and they do not need to bother much about future popularity <span class="No-Break">and scale.</span></li>
				<li><strong class="bold">Cost savings</strong>: Cloud computing follows a <strong class="bold">pay-as-you-go</strong> model, where users only pay for the resources and services they consume. This eliminates the need for upfront CapEx on hardware and infrastructure. It is always cheaper to rent for businesses rather than invest in computing hardware. Therefore, as you pay only for the resources you need at a certain period, there is no need to overprovision resources to cater to the future load. This results in substantial cost savings for most small and <span class="No-Break">medium organizations.</span></li>
				<li><strong class="bold">Flexibility</strong>: Cloud resources are no longer only servers. You can get many other things, such as simple object storage solutions, network and block storage, managed databases, container services, and more. These provide you with a lot of flexibility regarding what you do with <span class="No-Break">your application.</span></li>
				<li><strong class="bold">Reliability</strong>: Cloud computing <a id="_idIndexMarker022"/>resources are bound by <strong class="bold">service-level agreements</strong> (<strong class="bold">SLAs</strong>), sometimes in the order of 99.999% availability. This means that most of your cloud resources will never go down; if they do, you will not notice this because of <span class="No-Break">built-in redundancy.</span></li>
				<li><strong class="bold">Security</strong>: Since cloud computing companies run applications for various clients, they often have a stricter security net than you can build on-premises. They have a team of security experts manning the estate 24/7, and they have services that offer encryption, access control, and threat detection by default. As a result, when architected correctly, an <a id="_idIndexMarker023"/>application running on the cloud is much <span class="No-Break">more secure.</span></li>
			</ul>
			<p>There are a variety of cloud computing services on offer, including <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Infrastructure-as-a-Service</strong> (<strong class="bold">IaaS</strong>) is <a id="_idIndexMarker024"/>similar to running your application on servers. It is a cloud computing service model that provides virtualized computing resources over the internet. With IaaS, organizations can access and manage fundamental IT infrastructure components, such as virtual machines, storage, and networking, without investing in <a id="_idIndexMarker025"/>and maintaining physical hardware. In the IaaS model, the CSP owns and manages the underlying physical infrastructure, including servers, storage devices, networking equipment, and data centers. Users or organizations, on the other hand, have control over the <strong class="bold">operating systems</strong> (<strong class="bold">OSs</strong>), applications, and configurations running on the <span class="No-Break">virtualized infrastructure.</span></li>
				<li><strong class="bold">Platform-as-a-Service</strong> (<strong class="bold">PaaS</strong>) gives <a id="_idIndexMarker026"/>you an abstraction where you can focus on your code and leave your application management to <a id="_idIndexMarker027"/>the cloud service. It is a cloud computing service model that provides a platform and environment for developers to build, deploy, and manage applications without worrying about underlying infrastructure components. PaaS abstracts the complexities of infrastructure management, allowing developers to focus on application development and deployment. In the PaaS model, the CSP offers a platform that includes OSs, development frameworks, runtime environments, and various tools and services needed to support the application development life cycle. Users or organizations can leverage these platform resources to develop, test, deploy, and scale <span class="No-Break">their applications.</span></li>
				<li><strong class="bold">Software-as-a-Service</strong> (<strong class="bold">SaaS</strong>) provides<a id="_idIndexMarker028"/> a pre-built application for your consumption, such as a <a id="_idIndexMarker029"/>monitoring service that’s readily available for you to use that you can easily plug and play with your application. In the SaaS model, the CSP hosts and manages the software application, including infrastructure, servers, databases, and maintenance. Users or organizations can access the application through a web browser or a thin client application. They typically pay a subscription fee based on usage, and the software is delivered as a service <span class="No-Break">on demand.</span></li>
			</ul>
			<p>The advent of the cloud has led to a new buzzword in the industry called cloud-native applications. We’ll look at them in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-19"><a id="_idTextAnchor021"/>Understanding modern cloud-native applications</h1>
			<p>When we say cloud-native, we talk about applications built to run natively on the cloud. A cloud-native application is designed to run in the cloud taking full advantage of the capabilities and benefits of the cloud using cloud services as much <span class="No-Break">as possible.</span></p>
			<p>These <a id="_idIndexMarker030"/>applications are inherently <strong class="bold">scalable</strong>, <strong class="bold">flexible</strong>, and <strong class="bold">resilient</strong> (fault-tolerant). They rely on cloud services and automation to a <span class="No-Break">large extent.</span></p>
			<p>Some of the characteristics of a modern cloud-native application are <span class="No-Break">as follows:</span></p>
			<p><strong class="bold">Microservices architecture</strong>: Modern cloud-native applications typically follow the microservices architecture. Microservices<a id="_idIndexMarker031"/> are applications that are broken down into multiple smaller, loosely coupled parts with<a id="_idIndexMarker032"/> independent business functions. Independent microservices can be written in different programming languages based on the need or specific functionality. These smaller parts can then independently scale, are flexible to run, and are resilient <span class="No-Break">by design.</span></p>
			<p><strong class="bold">Containerization</strong>: Microservices <a id="_idIndexMarker033"/>applications typically use containers to run. Containers <a id="_idIndexMarker034"/>provide a <strong class="bold">consistent</strong>, <strong class="bold">portable</strong>, and <strong class="bold">lightweight</strong> environment for applications to run, ensuring that they have all the necessary dependencies and configurations bundled together. Containers can run the same on all environments and <span class="No-Break">cloud platforms.</span></p>
			<p><strong class="bold">DevOps and automation</strong>: Cloud-native applications heavily use modern DevOps practices and tools and <a id="_idIndexMarker035"/>therefore rely on automation to a considerable extent. This streamlines development, testing, and operations for your application. Automation also brings about <a id="_idIndexMarker036"/><strong class="bold">scalability</strong>, <strong class="bold">resilience,</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">consistency</strong></span><span class="No-Break">.</span></p>
			<p><strong class="bold">Dynamic orchestration</strong>: Cloud-native applications are built to scale and are inherently meant to be fault <a id="_idIndexMarker037"/>tolerant. These applications are typically <strong class="bold">ephemeral </strong>(<strong class="bold">transient</strong>); therefore, replicas of services can come and go as needed. Dynamic orchestration platforms such as <strong class="bold">Kubernetes</strong> and <strong class="bold">Docker Swarm</strong> are used to manage these services. These tools help run your application under changing demands and <span class="No-Break">traffic patterns.</span></p>
			<p><strong class="bold">Use of cloud-native data services</strong>: Cloud-native applications typically use managed cloud data services such as <strong class="bold">storage</strong>, <strong class="bold">databases</strong>, <strong class="bold">caching</strong>, and <strong class="bold">messaging</strong> systems to allow for<a id="_idIndexMarker038"/> communication between <span class="No-Break">multiple services.</span></p>
			<p>Cloud-native systems emphasize DevOps, and modern DevOps has emerged to manage them. So, now, let’s look at the difference between traditional and <span class="No-Break">modern DevOps.</span></p>
			<h1 id="_idParaDest-20"><a id="_idTextAnchor022"/>Modern DevOps versus traditional DevOps</h1>
			<p>DevOps’ traditional <a id="_idIndexMarker039"/>approach involved establishing a DevOps <a id="_idIndexMarker040"/>team consisting of <strong class="bold">Dev</strong>, <strong class="bold">QA</strong>, and <strong class="bold">Ops</strong> members and working toward creating better software faster. However, while there would be a focus on automating software delivery, automation tools such as <strong class="bold">Jenkins</strong>, <strong class="bold">Git</strong>, and<a id="_idIndexMarker041"/> others<a id="_idIndexMarker042"/> were installed and maintained manually. This led to another problem as we now had to manage another set of IT infrastructure. It finally boiled down to infrastructure and configuration, and the focus was to automate the <span class="No-Break">automation process.</span></p>
			<p>With the advent of containers and the recent boom in the public cloud landscape, DevOps’ modern approach came into the picture, which involved automating everything. From provisioning infrastructure to configuring tools and processes, there is code for everything. So, now, we have <strong class="bold">IaC</strong>, <strong class="bold">CaC</strong>, <strong class="bold">immutable infrastructure</strong>, and <strong class="bold">containers</strong>. I call this approach to DevOps modern DevOps, and it will be the focus of <span class="No-Break">this book.</span></p>
			<p>The following<a id="_idIndexMarker043"/> table describes some of the key similarities and<a id="_idIndexMarker044"/> differences between modern DevOps and <span class="No-Break">traditional DevOps:</span></p>
			<table id="table001-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Aspect</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Modern DevOps</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Traditional DevOps</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Software Delivery</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Emphasis on CI/CD pipelines, automated testing, and <span class="No-Break">deployment automation.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Emphasis on CI/CD pipelines, automated testing, and <span class="No-Break">deployment automation.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Infrastructure management</span></p>
						</td>
						<td class="No-Table-Style">
							<p>IaC is commonly used to provision and manage infrastructure resources. Cloud platforms and containerization technologies are <span class="No-Break">often utilized.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Manual provisioning and configuration of infrastructure is done, often relying on traditional data centers and <span class="No-Break">limited automation.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Application deployment</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Containerization and container orchestration technologies, such as Docker and Kubernetes, are widely adopted to ensure application portability <span class="No-Break">and scalability.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Traditional deployment methods are used, such as deploying applications directly on virtual machines or physical servers <span class="No-Break">without containerization.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Scalability <span class="No-Break">and resilience</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Utilizes the auto-scaling capabilities of cloud platforms and container orchestration to handle varying workloads. Focuses on high availability and <span class="No-Break">fault tolerance.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scalability is achieved through vertical scaling (adding resources to existing servers) or manual capacity planning. High availability is achieved by adding redundant servers manually. Elasticity is non-existent, and fault tolerance is not <span class="No-Break">a focus.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Monitoring <span class="No-Break">and logging</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Extensive use of monitoring tools, log aggregation, and real-time analytics to gain insights into application and <span class="No-Break">infrastructure performance.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Limited monitoring and logging practices, with fewer tools and <span class="No-Break">analytics available.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Collaboration <span class="No-Break">and culture</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Emphasizes collaboration, communication, and shared ownership between development and operations teams (<span class="No-Break">DevOps culture).</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Emphasizes collaboration, communication, and shared ownership between development and operations teams (<span class="No-Break">DevOps culture).</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Security</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Security is integrated into the development process with the use of <strong class="bold">DevSecOps</strong> practices. Security testing and vulnerability scanning <span class="No-Break">are automated.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Security measures are often applied manually and managed by a separate security team. There is limited automated security testing in <span class="No-Break">the SDLC.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Speed <span class="No-Break">of deployment</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Rapid and frequent deployment of software updates through automated pipelines, enabling <span class="No-Break">faster time-to-market.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Rapid application deployments, but automated infrastructure deployments are <span class="No-Break">often lacking.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.1 – Key similarities and differences between modern DevOps and traditional DevOps</p>
			<p>It’s<a id="_idIndexMarker045"/> important to note that the distinction<a id="_idIndexMarker046"/> between modern DevOps and traditional DevOps is not strictly binary as organizations can adopt various practices and technologies along a spectrum. The modern DevOps approach generally focuses on leveraging cloud technologies, automation, containerization, and DevSecOps principles to enhance collaboration, agility, and software development and <span class="No-Break">deployment efficiency.</span></p>
			<p>As we discussed previously, containers help implement modern DevOps and form the core of the practice. We’ll have a look at containers in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-21"><a id="_idTextAnchor023"/>The need for containers</h1>
			<p>Containers <a id="_idIndexMarker047"/>are<a id="_idTextAnchor024"/> in vogue lately and for excellent reason. They solve the computer architecture’s most critical problem – <em class="italic">running reliable, distributed software with near-infinite scalability in any </em><span class="No-Break"><em class="italic">computing environment</em></span><span class="No-Break">.</span></p>
			<p>They have enabled an entirely new discipline in software engineering – <em class="italic">microservices</em>. They have also introduced the <em class="italic">package once deploy anywhere</em> concept in technology. Combined with the cloud and distributed applications, containers with container orchestration technology have led to a new buzzword in the industry – <em class="italic">cloud-native</em> – changing the IT ecosystem like <span class="No-Break">never before.</span></p>
			<p>Before we delve into more technical details, let’s understand containers in plain and <span class="No-Break">simple words.</span></p>
			<p>Containers<a id="_idIndexMarker048"/> derive their n<a id="_idTextAnchor025"/>ame from shipping cont<a id="_idTextAnchor026"/>ainers. I will explain containers using a shipping container analogy for better understanding. Historically, because of transportation improvements, a lot of stuff moved across multiple geographies. With various goods being transported in different modes, loading and unloading goods was a massive issue at every transportation point. In addition, with rising labor costs, it was impractical for shipping companies to operate at scale while keeping <span class="No-Break">prices low.</span></p>
			<p>Also, it resulted in frequent damage to items, and goods used to get misplaced or mixed up with other consignments because there was no isolation. There was a need for a standard way of transporting goods that provided the necessary isolation between consignments and allowed for easy loading and unloading of goods. The shipping industry came up with shipping containers as an elegant solution to <span class="No-Break">this problem.</span></p>
			<p>Now, shipping containers have simplified a lot of things in the shipping industry. With a standard container, we can ship goods from one place to another by only moving the container. The same container can be used on roads, loaded on trains, and transported via ships. The operators of these vehicles don’t need to worry about what is inside the container most of the time. The following figure depicts the entire workflow graphically for ease <span class="No-Break">of understandin<a id="_idTextAnchor027"/>g:</span></p>
			<div>
				<div id="_idContainer008" class="IMG---Figure">
					<img src="image/B19877_Figure_1.02.jpg" alt="Figure 1.2 – Shipping container workflow" width="1649" height="452"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Shipping container workflow</p>
			<p>Similarly, there have been issues with software portability and compute resource management in the software industry. In a standard software development life cycle, a piece of software moves through multiple environments, and sometimes, numerous applications share <a id="_idTextAnchor028"/>the same OS. There may be differences in the configuration between environments, so software that may have worked in a development environment may not work in a test environment. Something that worked in test may also not work <span class="No-Break">in production.</span></p>
			<p>Also, when you have multiple applications running within a single machine, there is no isolation between them. One application can drain compute resources from another application, and that may lead to <span class="No-Break">runtime issues.</span></p>
			<p>Repackaging and reconfiguring applications is required in every step of deployment, so it takes a lot of time and effort and is <span class="No-Break">sometimes error-prone.</span></p>
			<p>In the software industry, containers solve these problems by providing isolation between application and compute resource management, which provides an optimal solution to <span class="No-Break">these issues.</span></p>
			<p>The software<a id="_idIndexMarker049"/> industry’s biggest challenge is to provide application isolation and manage external dependencies elegantly so <a id="_idTextAnchor029"/>that they can run on any platform, irrespective of the OS or the infrastructure. Software is written in numerous programming languages and uses various dependencies and frameworks. This leads to a scenario called the <strong class="bold">matrix </strong><span class="No-Break"><strong class="bold">of he<a id="_idTextAnchor030"/><a id="_idTextAnchor031"/>ll</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-22"><a id="_idTextAnchor032"/>The matrix of hell</h2>
			<p>Let’s say you’re<a id="_idIndexMarker050"/> preparing a server that will<a id="_idTextAnchor033"/> run multiple applications for multiple teams. Now, assume that you don’t have a virtualized infrastructure and that you need to run everything on one physical machine, as shown in the <span class="No-Break">following diagr<a id="_idTextAnchor034"/>am:</span></p>
			<div>
				<div id="_idContainer009" class="IMG---Figure">
					<img src="image/B19877_Figure_1.03.jpg" alt="Figure 1.3 – Applications on a physical server" width="1206" height="766"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Applications on a physical server</p>
			<p>One applica<a id="_idTextAnchor035"/>tion<a id="_idIndexMarker051"/> uses one particular version of a dependency, while another application uses a different one, and you end up managing two versions of the same software in one system. When you scale your system to fit multiple applications, you will be managing hundreds of dependencies and various versions that cater to different applications. It will slowly turn out to be unmanageable within one physical system. This scenario is known as the <strong class="bold">matrix of hell</strong> in popular <span class="No-Break">computing nomenclature.</span></p>
			<p>Multiple solutions come out of the matrix of hell, but there are two notable technological contributions – <em class="italic">virtual machines</em> <span class="No-Break">and </span><span class="No-Break"><em class="italic">contain<a id="_idTextAnchor036"/><a id="_idTextAnchor037"/>ers</em></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-23"><a id="_idTextAnchor038"/>Virtual machines</h2>
			<p>A <strong class="bold">virtual mac<a id="_idTextAnchor039"/>hine</strong> emulates <a id="_idIndexMarker052"/>an OS using a technology called a <strong class="bold">hypervisor</strong>. A hyper<a id="_idTextAnchor040"/>visor<a id="_idIndexMarker053"/> can run as software on a physical host OS or run as firmware on a bare-metal machine. Virtual machines run as a virtual guest OS on the hypervisor. With this technology, you can subdivide a sizeable physical machine into multiple smaller virtual machines, each catering to a particular application. This has revolutionized computing infrastructure for almost two decades and is still in use today. Some of the most popular <a id="_idIndexMarker054"/>hypervisors on the <a id="_idIndexMarker055"/>market<a id="_idIndexMarker056"/> are <strong class="bold">VMware</strong> and <span class="No-Break"><strong class="bold">Oracle VirtualBox</strong></span><span class="No-Break">.</span></p>
			<p>The following diagram<a id="_idTextAnchor041"/> shows the same stack on virtual machines. You can see that each application now contains a <a id="_idIndexMarker057"/>dedicated guest OS, each of which has its own libraries <span class="No-Break">and depe<a id="_idTextAnchor042"/>ndencies:</span></p>
			<div>
				<div id="_idContainer010" class="IMG---Figure">
					<img src="image/B19877_Figure_1.04.jpg" alt="Figure 1.4 – Applications on virtual machines" width="1650" height="966"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – Applications on virtual machines</p>
			<p>Though the approach is acceptable, it is like using an entire ship for your goods rather than a simple container from the shipping container analogy. Virtual machines are heavy on resources as you need a heavy guest OS layer to isolate applications rather than something more lightweight. We need to allocate dedicated CPU and memory to a virtual machine; resource sharing is suboptimal since people tend to overprovision virtual machines to cater to peak load. They are also slower to start, and virtual machine scaling is traditionally more cumbersome as multiple moving parts and technologies are involved. Therefore, automating horizontal scaling (handling more traffic from users by adding more machines to the resource pool) using virtual machines is not very straightforward. Also, sysadmins now have to deal with multiple servers rather than numerous libraries and dependencies in one. It is better than before, but it is not optimal from a compute resource point<a id="_idTextAnchor043"/><a id="_idTextAnchor044"/> <span class="No-Break">of view.</span></p>
			<h2 id="_idParaDest-24"><a id="_idTextAnchor045"/>Containers</h2>
			<p>This is where containers come into the<a id="_idIndexMarker058"/> picture. Containers solve the matrix of hell without involving a heavy guest OS layer between them. Instead, they isolate the application <a id="_idTextAnchor046"/>runtime and dependencies by encapsulating them to create an abstraction called containers. Now, you have multiple containers that run on a single OS. Numerous applications running on containers can share the same infrastructure. As a result, they do not waste your computing resources. You also do not have to worry about application libraries and dependencies as they are isolated from other applications – a win-win situation <span class="No-Break">for everyone!</span></p>
			<p>Containers run on container runtimes. While <strong class="bold">Docker</strong> is the <a id="_idIndexMarker059"/>most popular and more or less <a id="_idIndexMarker060"/>the de facto <a id="_idIndexMarker061"/>container runtime, other options are available on the market, such as <strong class="bold">Rkt</strong> and <strong class="bold">Containerd</strong>. They all use the same Linux <a id="_idIndexMarker062"/>kernel <strong class="bold">cgroups</strong> feature, whose basis comes from the combined efforts of Google, IBM, OpenVZ, and SGI to <a id="_idIndexMarker063"/>embed <strong class="bold">OpenVZ </strong>into the main Linux kernel. OpenVZ was an early attempt at implementing features to provide virtual environments within a Linux kernel without using a guest OS layer, which we now <span class="No-Break">c<a id="_idTextAnchor047"/><a id="_idTextAnchor048"/>all containers.</span></p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor049"/>It works on my machine</h2>
			<p>You might have heard this phrase many times in your career. It is a typical situation where you have err<a id="_idTextAnchor050"/>atic developers worrying your test team with “<em class="italic">But, it works on my machine</em>” answers and your testing team responding with “<em class="italic">We are not going to deliver your machine to the client.</em>” Containers use the <em class="italic">Build once, run anywhere</em> and the <em class="italic">Package once, deploy anywhere</em> concepts and solve the <em class="italic">It works on my machine</em> syndrome. As containers need a container runtime, they can run on any machine in the same way. A standardized setup for applications also means that the sysadmin’s job is reduced to just taking care of the container runtime and servers and delegating the application’s responsibilities to the development team. This reduces the admin overhead from software delivery, and software development teams can now spearhead development without many external dependencies – a great power indeed! Now, let’s look at how containers are design<a id="_idTextAnchor051"/><a id="_idTextAnchor052"/>ed to <span class="No-Break">do that.</span></p>
			<h1 id="_idParaDest-26"><a id="_idTextAnchor053"/>Container architecture</h1>
			<p>In most cases, you can visualize containers <a id="_idIndexMarker064"/>as mini virtual machines – at least, they seem like they are. But, in reality, they are just computer programs running within an OS. So, let’s look at a high-level diagram of what an application stack within contain<a id="_idTextAnchor054"/>ers <span class="No-Break">looks like:</span></p>
			<div>
				<div id="_idContainer011" class="IMG---Figure">
					<img src="image/B19877_Figure_1.05.jpg" alt="Figure 1.5 – Applications on containers" width="1650" height="923"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – Applications on containers</p>
			<p>As we can see, we have the compute infrastructure right at the bottom, forming the base, followed by the host OS and a container runtime (in this case, Docker) running on top of it. We then have multiple containerized applications using the container runtime, running as separate processes over the host operating system using <em class="italic">namespaces</em> <span class="No-Break">and </span><span class="No-Break"><em class="italic">cgroups</em></span><span class="No-Break">.</span></p>
			<p>As you may have noticed, we do not have a guest OS layer within it, which is something we have with virtual machines. Each container is a <em class="italic">software program</em> that runs on the Kernel userspace and shares the same OS and associated runtime and other dependencies, with only the required libraries and dependencies within the container. Containers do not inherit the OS environment variables. You have to set them separately for <span class="No-Break">each container.</span></p>
			<p>Containers replicate the filesystem, and though they are present on disk, they are isolated from other containers. This makes containers run applications in a secure environment. A separate container filesystem means that containers don’t have to communicate to and fro with the OS filesystem, which results in faster execution than <span class="No-Break">virtual machines.</span></p>
			<p>Containers were designed to use Linux <em class="italic">namespaces</em> to provide isolation and <em class="italic">cgroups</em> to offer restrictions on CPU, memory, and disk <span class="No-Break">I/O consumption.</span></p>
			<p>Thi<a id="_idTextAnchor055"/>s means that if you list the OS processes, you will see the container process running alongside other processes, as <a id="_idIndexMarker065"/>shown in the <span class="No-Break">follow<a id="_idTextAnchor056"/>ing screenshot:</span></p>
			<div>
				<div id="_idContainer012" class="IMG---Figure">
					<img src="image/B19877_Figure_1.06.jpg" alt="Figure 1.6 – OS processes" width="1525" height="1149"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.6 – OS processes</p>
			<p>However, when you list the container’s processes, you will only see the container process, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
$ docker exec -it mynginx1 bash
root@4ee264d964f8:/# pstree
nginx---nginx</pre>			<p>This is how namespaces provide a degree of isolation <span class="No-Break">between containers.</span></p>
			<p>Cgroups<a id="_idIndexMarker066"/> play a role in limiting the amount of computing resources a group of processes can use. For example, if you add processes to a cgroup, you can limit the CPU, memory, and disk I/O the processes can use. In addition, you can measure and monitor resource usage and stop a group of processes when an application goes astray. All these features form the core of containerization technology, which we will see later in <span class="No-Break">this book.</span></p>
			<p>Once we ha<a id="_idTextAnchor057"/>ve <a id="_idIndexMarker067"/>independently running containers, we also need to understand how they interact. Therefore, we’ll have a look at container networking in <a id="_idTextAnchor058"/><a id="_idTextAnchor059"/>the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor060"/>Container networking</h2>
			<p>Conta<a id="_idTextAnchor061"/>iners are separate network entities within the OS. Docker runtimes use network drivers to define networking between containers, and they are software-defined networks. <strong class="bold">Container networking</strong> works<a id="_idIndexMarker068"/> by using software to manipulate the <em class="italic">host iptables</em>, connect with external network interfaces, create tunnel networks, and perform other activities to allow connections to and <span class="No-Break">from containers.</span></p>
			<p>While there are various types of network configurations you can implement with containers, it is good to know about some widely used ones. Don’t worry too much if the details are overwhelming – you will understand them while completing the hands-on exercises later in this book, and it is not a hard requirement to know all of this to follow the text. For now, let’s look at various types of container networks that you <span class="No-Break">can define:</span></p>
			<ul>
				<li><strong class="bold">No<a id="_idTextAnchor062"/>ne</strong>: This is<a id="_idIndexMarker069"/> a fully isolated network, and your containers cannot communicate with the external world. They are assigned a loopback interface and cannot connect with an external network interface. You can use this network to test your containers, stage your container for future use, or run a container that does not require any external connection, such as <span class="No-Break">batch processing.</span><a id="_idTextAnchor063"/></li>
				<li><strong class="bold">Bridge</strong>: The<a id="_idIndexMarker070"/> bridge network is the default network type in most container runtimes, including Docker, and uses the <strong class="source-inline">docker0</strong> interface for default containers. The bridge network manipulates IP tables to provide <strong class="bold">Network Address Translation</strong> (<strong class="bold">NAT</strong>) between<a id="_idIndexMarker071"/> the container and host network, allowing external network connectivity. It also does not result in port conflicts, enabling network isolation between containers running on a host. Therefore, you can run multiple applications that use the same container port within a single host. A bridge network allows containers within a single host to communicate using the container IP addresses. However, they don’t permit communication with c<a id="_idTextAnchor064"/>ontainers running on a different host. Therefore, you should not use the bridge network for clustered <a id="_idIndexMarker072"/>configuration (using multiple servers in tandem to run <span class="No-Break">your containers).</span></li>
				<li><strong class="bold">Host</strong>: Host <a id="_idIndexMarker073"/>networking uses the network namespace of the host machine for al<a id="_idTextAnchor065"/>l the containers. It is similar to running multiple applications within your host. While a host network is simple to implement, visualize, and troubleshoot, it is prone to port-conflict issues. While containers use the host network for all communications, it does not have the power to manipulate the host network interfaces unless it is running in privileged mode. Host networking does not use NAT, so it is fast and communicates at bare-metal speeds. Therefore, you can use host networking to optimize performance. However, since it has no network isolation between containers, from a security and management point of view, in most cases, you should avoid using the <span class="No-Break">host netw<a id="_idTextAnchor066"/>ork.</span></li>
				<li><strong class="bold">Underlay</strong>: Underlay <a id="_idIndexMarker074"/>exposes the host network interfaces directly to containers. This means you can run your containers directly on the network interfaces instead of using a bridge network. There are several underlay networks, the most notable being MACvlan and IPvlan. MACvlan allows you to assign a MAC address to every container so that your container looks like a physical device. This is beneficial for migrating your existing stack to containers, especially when your application needs to run on a physical machine. MACvlan also provides complete isolation to your host networking, so you can use this mode if you have a strict security requirement. MACvlan has limitations as it cannot work with network switches with a security policy to disallow MAC spoofing. It is also constrained to the MAC address ceiling of some network interface cards, such as Broadcom, which only allows 512 MAC addresses <span class="No-Break">per interface<a id="_idTextAnchor067"/>.</span></li>
				<li><strong class="bold">Overlay</strong>: Don’t confuse<a id="_idIndexMarker075"/> overlay with underlay – even though they seem like antonyms, they are not. Overlay networks allow communication between containers on different host machines via a networking tunnel. Therefore, from a container’s perspective, they seem to interact with containers on a single host, even when they are located elsewhere. It overcomes the bridge network’s limitations and is especially useful for cluster configuration, especial<a id="_idTextAnchor068"/>ly when using a container orchestrator such as Kubernetes or Docker Swarm. Some popular overlay<a id="_idIndexMarker076"/> technologies<a id="_idIndexMarker077"/> container runtimes and orchestrators use <a id="_idIndexMarker078"/>are <strong class="bold">flannel</strong>, <strong class="bold">calico</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="bold">VXLAN</strong></span><span class="No-Break">.</span></li>
			</ul>
			<p>Before we delve into the technicalities of different kinds of networks, let’s understand the nuances of container networking. For this discussion, we’ll talk about Docker <span class="No-Break">in particular.</span></p>
			<p>Every Docker container<a id="_idIndexMarker079"/> running on a host is<a id="_idIndexMarker080"/> assigned a unique IP address. If you <strong class="source-inline">exec</strong> (open a shell session) into the container and run <strong class="source-inline">hostname -I</strong>, you should see something like <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ docker exec -it mynginx1 bash
root@4ee264d964f8:/# hostname -I
172.17.0.2</pre>			<p>This allows different containers to communicate with each other through a simple TCP/IP link. The Docker daemon<a id="_idIndexMarker081"/> acts as the DHCP server for every container. Here, you can define virtual networks for a group of containers and club them together to provide network isolation if you desire. You can also connect a container to multiple networks to share it for two <span class="No-Break">different roles.</span></p>
			<p>Docker assigns every container a unique hostname that defaults to the container ID. However, this can be overridden easily, provided you use unique hostnames in a particular network. So, if you <strong class="source-inline">exec</strong> into a container and run <strong class="source-inline">hostname</strong>, you should see the container ID as the hostname, <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
$ docker exec -it mynginx1 bash
root@4ee264d964f8:/# hostname
4ee264d964f8</pre>			<p>This allows containers to act as separate network entities rather than simple software programs, and you can easily visualize containers as mini <span class="No-Break">virtual machines.</span></p>
			<p>Containers<a id="_idIndexMarker082"/> also inherit the host OS’s DNS settings, so you don’t have to worry too much if you want all the containers to share the same DNS settings. If you’r<a id="_idTextAnchor069"/>e going to define a separate DNS configuration for your containers, you can easily do so by passing a few flags. Docker containers do not inherit entries in the <strong class="source-inline">/etc/hosts</strong> file, so you must define them by declaring them while creating the container using the <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">run</strong></span><span class="No-Break"> command.</span></p>
			<p>If your containers need a proxy server, you must set that either in the Docker container’s environment variables or by adding the default proxy to the <strong class="source-inline">~/.</strong><span class="No-Break"><strong class="source-inline">docker/config.json</strong></span><span class="No-Break"> file.</span></p>
			<p>So far, we’ve discussed containers and what they are. Now, let’s discuss how containers are revolutionizing the world of DevOps and how it was necessary to spell<a id="_idTextAnchor070"/><a id="_idTextAnchor071"/><a id="_idTextAnchor072"/> this outright at <span class="No-Break">the beginning.</span></p>
			<h1 id="_idParaDest-28"><a id="_idTextAnchor073"/>Containers and modern DevOps practices</h1>
			<p>Containers and <a id="_idIndexMarker083"/>modern DevOps practices are highly complementary and have transformed how we approach software development <span class="No-Break">and deployment.</span></p>
			<p>Containers have a great synergy with modern DevOps practices as they provide the necessary infrastructure encapsulation, portability, scalability, and agility to enable rapid and efficient software delivery. With modern DevOps practices such as CI/CD, IaC, and microservices, containers form a powerful foundation for organizations to achieve faster time-to-market, improved software quality, and enhanced <span class="No-Break">operatio<a id="_idTextAnchor074"/>nal efficiency.</span></p>
			<p>Containers follow<a id="_idIndexMarker084"/> DevOps practices right from the start. If you look at a typical container build and deployment workflow, this is what <span class="No-Break">you’ll get:</span></p>
			<ol>
				<li>First, code your app in whatever language <span class="No-Break">you wish.</span></li>
				<li>Then, create a <strong class="bold">Dockerfile</strong> that <a id="_idIndexMarker085"/>contains a series of steps to install the application dependencies and environment configuration to run <span class="No-Break">your app.</span></li>
				<li>Next, use the Dockerfile to create container images by doing <span class="No-Break">the following:</span></li>
			</ol>
			<p>a) Build the <span class="No-Break">container image.</span></p>
			<p>b) Run the <span class="No-Break">container image.</span></p>
			<p>c) Unit test the app running on <span class="No-Break">the container.</span></p>
			<ol>
				<li value="4">Then, push the image to a container registry <a id="_idIndexMarker086"/>such <span class="No-Break">as </span><span class="No-Break"><strong class="bold">DockerHub</strong></span><span class="No-Break">.</span></li>
				<li>Finally, create containers from container images and run them in <span class="No-Break">a cluster.</span></li>
			</ol>
			<p>You can embed these steps<a id="_idIndexMarker087"/> beautifully in th<a id="_idTextAnchor075"/>e CI/CD pipeline example <span class="No-Break">shown here:</span></p>
			<div>
				<div id="_idContainer013" class="IMG---Figure">
					<img src="image/B19877_Figure_1.07.jpg" alt="Figure 1.7 – Container CI/CD pipeline example" width="1717" height="657"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.7 – Container CI/CD pipeline example</p>
			<p>This means your <a id="_idIndexMarker088"/>application and its runtime dependencies are all defined in the code. You follow configuration management from the very beginning, a<a id="_idTextAnchor076"/>llowing developers to treat containers like ephemeral workloads (ephemeral workloads are temporary workloads that are dispensable, and if one disappears, you can spin up another one without it having any functional impact). You can replace them if they misbehave – something that was not very elegant with <span class="No-Break">virtual machines.</span></p>
			<p>Containers fit very well within modern CI/CD practices as you now have a standard way of building and deploying applications, irrespective of the language you code in. You don’t have to manage expensive build and deployment software as you get everything out of the box <span class="No-Break">with containers.</span></p>
			<p>Containers <a id="_idIndexMarker089"/>rarely run on their own, and it is a standard <a id="_idIndexMarker090"/>practice <a id="_idIndexMarker091"/>in the <a id="_idIndexMarker092"/>industry to plug <a id="_idIndexMarker093"/>them<a id="_idIndexMarker094"/> into<a id="_idIndexMarker095"/> a container<a id="_idIndexMarker096"/> orchestrator<a id="_idIndexMarker097"/> such as <strong class="bold">Kubernetes</strong> o<a id="_idTextAnchor077"/>r use <a id="_idIndexMarker098"/>a <strong class="bold">Container-as-a-Service</strong> (<strong class="bold">CaaS</strong>) platform <a id="_idIndexMarker099"/>such as <strong class="bold">AWS ECS</strong> and <strong class="bold">EKS</strong>, <strong class="bold">Google Cloud Run</strong> and <strong class="bold">Kubernetes Engine</strong>, <strong class="bold">Azure ACS</strong> and <strong class="bold">AKS</strong>, <strong class="bold">Oracle OCI</strong> and <strong class="bold">OKE</strong>, and others. Popular <strong class="bold">Function-as-a-Service</strong> (<strong class="bold">FaaS</strong>) plat<a id="_idTextAnchor078"/>forms such as <strong class="bold">AWS Lambda</strong>, <strong class="bold">Google Functions</strong>, <strong class="bold">Azure Functions</strong>, and <strong class="bold">Oracle Functions</strong> also run<a id="_idIndexMarker100"/> containers in the<a id="_idIndexMarker101"/> background. So, though<a id="_idIndexMarker102"/> they may have <a id="_idIndexMarker103"/>abstracted <a id="_idIndexMarker104"/>the underlying mechanism from you, you may already be using <span class="No-Break">containers unknowingly.</span></p>
			<p>As containers are lightweight, you can build smaller parts of applications into containers to manage them independently. Combine that with a container orchestrator such as Kubernetes, and you get a distributed microservices architecture running with ease. These smaller parts can then scale, auto-heal, and get released independently of others, which means you can release them into production quicker than before and much <span class="No-Break">more reliably.</span></p>
			<p>You can also plug <a id="_idIndexMarker105"/>in a <strong class="bold">service mesh</strong> (infrastructure components that allow you to discover, list, manage, and allow communication between multiple components (services) of your microservices application) such<a id="_idIndexMarker106"/> as <strong class="bold">Istio</strong> on top, and you will get advanced Ops features such as traffic management, security, and observability with ease. You can then do<a id="_idIndexMarker107"/> cool stuff such <a id="_idIndexMarker108"/>as <strong class="bold">blue/green deployments</strong> and <strong class="bold">A/B testing</strong>, operational tests in production <a id="_idIndexMarker109"/>with <strong class="bold">traffic mirroring</strong>, <strong class="bold">geolocation-<a id="_idTextAnchor079"/>based routing</strong>, and <a id="_idIndexMarker110"/><span class="No-Break">much more.</span></p>
			<p>As a result, large and small enterprises are embracing containers quicker than ever, and the field is growing exponentially. According to <a href="http://businesswire.com">businesswire.com</a>, the application container market shows a compounded growth of 31% per annum and will reach $6.9 billion by 2025. The exponential growth of 30.3% per annum in the cloud, expected to reach over $2.4 billion by 2025, has also contributed <span class="No-Break">to this.</span></p>
			<p>Therefore, modern DevOps engineers must understand containers and the relevant technologies to ship and deliver containerized applications effectively. This does not mean that virtual machines are unnecessary, and we cannot completely ignore the role of IaaS-based solutions in the market, so we will also cover some config management with <strong class="bold">Ansible</strong> in<a id="_idIndexMarker111"/> further <a id="_idIndexMarker112"/>chapters. Due to the advent of the cloud, IaC has been gaining much momen<a id="_idTextAnchor080"/><a id="_idTextAnchor081"/>tum recently, so we will also cover <strong class="bold">Terraform</strong> as an<a id="_idIndexMarker113"/> <span class="No-Break">IaC tool.</span></p>
			<h1 id="_idParaDest-29">Migrati<a id="_idTextAnchor082"/>ng from virtual machines to containers</h1>
			<p>As we see the <a id="_idIndexMarker114"/>technology market moving toward containers, DevOps engineers have a crucial task – <em class="italic">migrating applications running on virtual machines so that they can run on containers</em>. Well, this is in most DevOps engineers’ job descriptions and is one of the most critical things <span class="No-Break">we do.</span></p>
			<p>While, in theory, containerizing an application is as simple as writing a few steps, practically speaking, it can be a complicated beast, especially if you are not using config management to set up your virtual machines. Virtual machines that run on current enterprises these days were created from a lot of manual labor by toiling sysadmins, improving the servers piece by piece, and making it hard to reach out to the paper trail of hotfixes they might have made <span class="No-Break">until now.</span></p>
			<p>Since containers follow config management principles from the very beginning, it is not as simple as picking up the virtual machine image and using a converter to convert it into a <span class="No-Break">Docker container.</span></p>
			<p>Migrating a legacy application running on virtual machines req<a id="_idTextAnchor083"/><a id="_idTextAnchor084"/>uires numerous steps. Let’s ta<a id="_idTextAnchor085"/>ke a look at them in <span class="No-Break">more detail.</span></p>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor086"/>Discovery</h2>
			<p>First, we start <a id="_idIndexMarker115"/>with the <span class="No-Break">discovery phase:</span></p>
			<ul>
				<li>Understand the different parts of <span class="No-Break">your applications</span></li>
				<li>Assess what parts of the legacy applications you can containerize and whether it is technically possible to <span class="No-Break">do so</span></li>
				<li>Define a migration scope and agree<a id="_idTextAnchor087"/><a id="_idTextAnchor088"/> on the clear goals and benefits of the mig<a id="_idTextAnchor089"/>ration <span class="No-Break">with timelines</span></li>
			</ul>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor090"/>Application requirement assessment</h2>
			<p>Once the <a id="_idIndexMarker116"/>discovery phase is complete, we need to do the application <span class="No-Break">requirement assessment:</span></p>
			<ul>
				<li>Assess if it is a better idea to break the application into smaller parts. If so, then what would the application parts be, and how will they interact with <span class="No-Break">each other?</span></li>
				<li>Assess what aspects of the architecture, its performance, and its security you need to cater to regarding your application, and think about the container <span class="No-Break">world’s equivalent.</span></li>
				<li>Understand the relevant risks and decide on <span class="No-Break">mitigation approaches.</span></li>
				<li>Understand the migration principle and decide on a migration approach, such as what part of the application you sho<a id="_idTextAnchor091"/>uld containerize first. Always start with the <a id="_idTextAnchor092"/><a id="_idTextAnchor093"/>application with the least amount of external <span class="No-Break">dependencies first.</span></li>
			</ul>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor094"/>Container infrastructure design</h2>
			<p>Container<a id="_idIndexMarker117"/> infrastructure design involves creating a robust and scalable environment to support the deployment and management of <span class="No-Break">containerized applications.</span></p>
			<p>Designing a container infrastructure involves considering factors such as scalability, networking, storage, security, automation, and monitoring. It’s crucial to align the infrastructure design with the specific requirements and goals of the containerized applications and to follow best practices for effi<a id="_idTextAnchor095"/>cient and reliable container deployment <span class="No-Break">and management.</span></p>
			<p>Once we’ve assessed all our requirements, architecture, and other aspects, we can move on to container <span class="No-Break">infrastructure design:</span></p>
			<ul>
				<li>Understand the current and future scale of operations when you make this decision. You can choose from many options based on your application’s complexity. The right questions include; how many containers do we need to run on the platform? What kind of dependencies do these containers have on each other? How frequently are we going to deploy changes to the components? What is the potential traffic the application can receive? What is the traffic pattern on <span class="No-Break">the application?</span></li>
				<li>Based on the answers you get to the preceding questions, you need to understand what sort of infrastructure you will run your application on. Will it be on-premises or the cloud, and will you use a managed Kubernetes cluster or self-host and manage one? You can also look at options such as CaaS for <span class="No-Break">lightweight applications.</span></li>
				<li>How will you monitor and operate your containers? Will it require installing specialist tools? Will it require integrating with the existing monitoring tool stack? Understand the feasibility and make an appropriate <span class="No-Break">design decision.</span></li>
				<li>How will<a id="_idIndexMarker118"/> you secure your containers? Are there any regulatory and compliance requi<a id="_idTextAnchor096"/><a id="_idTextAnchor097"/>rements regarding security? Does the chosen solution cater <span class="No-Break">to them?</span></li>
			</ul>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor098"/>Containerizing the application</h2>
			<p>Containerizing an<a id="_idIndexMarker119"/> application involves packaging the application and its dependencies into a container image, which can be deployed and run consistently across <span class="No-Break">different environments.</span></p>
			<p>Containerizing an application offers benefits such as improved portability, scalability, and reproducibility. It simplifies the deployment process and allows for consistent appli<a id="_idTextAnchor099"/>cation behavior across <span class="No-Break">different environments.</span></p>
			<p>Once we’ve considered all aspects of the design, we can now start containerizing <span class="No-Break">the application:</span></p>
			<ul>
				<li>This is where we look into the application and create a Dockerfile containing the steps to create the container just as it is currently. This requires a lot of brainstorming and assessment, mostly if config management tools don’t build your application by running on a virtual machine such as Ansible. It can take a long time to figure out how the application was installed, <a id="_idTextAnchor100"/>and you need to write the exact steps <span class="No-Break">for this.</span></li>
				<li>If you plan to break your application into smaller parts, you may need to build your application <span class="No-Break">from scratch.</span></li>
				<li>You must <a id="_idIndexMarker120"/>decide on a test suite that works on your<a id="_idTextAnchor101"/><a id="_idTextAnchor102"/> parallel virtual machine-based application and improve it <span class="No-Break">over time.</span></li>
			</ul>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor103"/>Testing</h2>
			<p>Testing <a id="_idIndexMarker121"/>containerized applications is an important step to ensure their functionality, performance, <span class="No-Break">and compatibility.</span></p>
			<p>By implementing a comprehensive testing strategy, you can ensure the reliability, performance, and security of your containerized application. Testing at various levels, integrating automation, and closely monitoring the application’s behavior will help you identify and resolve issues early in the development life cycle, leading to a more robus<a id="_idTextAnchor104"/>t and reliable <span class="No-Break">containerized application.</span></p>
			<p>Once we’ve containerized the application, the next step in the process <span class="No-Break">is testing:</span></p>
			<ul>
				<li>To prove whether your containerized application works exactly like the one in the virtual machine, you need to do extensive testing to prove that you haven’t missed any details or parts you should have considered previously. Run an existing test suite or the one you created for <span class="No-Break">the container.</span></li>
				<li>Running an existing test suite can be the right approach, but you also need to consider the software’s non-functional aspects. Benchmarking the original application is a good start, and you need to understand the overhead the container solution is putting in. You also need to fine-tune your application so that it fits the <span class="No-Break">performance metrics.</span></li>
				<li>You also need to consider the importance of security and how you can bring it into the container world. Penetration testing w<a id="_idTextAnchor105"/><a id="_idTextAnchor106"/>ill reveal a lot of security loopholes that you might not be <span class="No-Break">aware of.</span></li>
			</ul>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor107"/>Deployment and rollout</h2>
			<p>Deploying <a id="_idIndexMarker122"/>and rolling out a containerized application involves deploying the container images to the target environm<a id="_idTextAnchor108"/>ent and making the application available <span class="No-Break">for use.</span></p>
			<p>Once we’ve tested our containers and are confident enough, we can roll out our application <span class="No-Break">to production:</span></p>
			<ul>
				<li>Finally, we roll out our application to production and learn from there if further changes are needed. We then return to the discovery process until we have perfected <span class="No-Break">our application.</span></li>
				<li>You must define and develop an automated runbook and a CI/CD pipeline to reduce cycle time and troubleshoot <span class="No-Break">issues quickly.</span></li>
				<li>Doing A/B testing with the container applications running in parallel can help you realize any potential issues before you switch all the traffic to the <span class="No-Break">new solution.</span></li>
			</ul>
			<p>The following <a id="_idIndexMarker123"/>diagram summarizes these steps, and as you can see, this process is cyclic. This means that you may have to revisit these steps from time to time<a id="_idTextAnchor109"/> based on what you learned from the operating containers <span class="No-Break">in production:</span></p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B19877_Figure_1.08.jpg" alt="Figure 1.8 – Migrating from virtual machines to containers" width="1222" height="497"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.8 – Migrating from virtual machines to containers</p>
			<p>Now, let’s understand what we need to do to ensure that we migrate from virtual machines to contai<a id="_idTextAnchor110"/><a id="_idTextAnchor111"/>ners with the least friction and also attain the best <span class="No-Break">possible outcome.</span></p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor112"/>What applications should go in containers?</h2>
			<p>In your journey of moving fr<a id="_idTextAnchor113"/>om virtual machines to containers, you first need to assess what can and can’t go in containers. Broadly speaking, there are two kinds of application workloads you can have – <strong class="bold">s<a id="_idTextAnchor114"/>tateless</strong> and <strong class="bold">stateful</strong>. While stateless workloads do not store state and are computing powerhouses, such as APIs and functions, stateful applications, such as data<a id="_idTextAnchor115"/>bases, require persistent storage <span class="No-Break">to function.</span></p>
			<p>Though it is possible to containerize any application that can run on a Linux virtual machine, stateless applications<a id="_idIndexMarker124"/> become the first low-hanging fruits you may want to look at. It is relatively easy to containerize these workloads because they don’t have storage dependencies. The more storage dependencies you have, the more complex your application becomes <span class="No-Break">in containers.</span></p>
			<p>Secondly, you also need to assess the form of infrastructure you want to host your applications on. For example, if you plan to run your entire tech stack on Kubernetes, you would like to avoid a heterogeneous environment wherever possible. In that scenario, you may also wish to containerize<a id="_idIndexMarker125"/> stateful applications. With web services and the middleware layer, most applications rely on some form of state to function correctly. So, in any case, you would end up <span class="No-Break">managing storage.</span></p>
			<p>Though this might open up Pandora’s box, there is no standard agreement within the industry regarding containerizing databases. While some experts are naysayers for its use in production, a sizeable population sees no issues. The primary reason is insufficient data to support or disprove using a containerized database <span class="No-Break">in production.</span></p>
			<p>I suggest that you proceed with caution regarding databases. While I am not opposed to containerizing databases, you must consider various factors, such as allocating proper memory, CPU, disk, and every dependency you have on virtual machines. Also, it would help if you looked into the behavioral aspects of the team. If you have a team of DBAs managing the database within production, they might not be very comfortable dealing with another layer of complexity – <span class="No-Break">containers.</span></p>
			<p>We can su<a id="_idTextAnchor116"/>mmarize these high-level assessment<a id="_idIndexMarker126"/> steps using the <span class="No-Break">following flowchart:</span></p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B19877_Figure_1.09.jpg" alt="Figure 1.9 – Virtual machine to container migration assessment" width="1289" height="2032"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.9 – Virtual<a id="_idTextAnchor117"/> machine to container migration assessment</p>
			<p>This<a id="_idIndexMarker127"/> flowchart accounts for the most common factors that are considered during the assessment. You also need to factor in situations that are unique to your organization. So, it is a good idea to take those into account as well before making <span class="No-Break">any decisions.</span></p>
			<p>Let’s look at some use cases that are suitable for containerization to get a fair understanding. The following types of applications are commonly deployed <span class="No-Break">using containers:</span></p>
			<ul>
				<li><strong class="bold">Microservices architecture</strong>: Applications that follow a microservices architecture, where the<a id="_idIndexMarker128"/> functionality is divided into small, independent services, are well-suited for containerization. Each microservice can be packaged as a separate container, enabling easier development, deployment, scaling, and management of the <span class="No-Break">individual services.</span></li>
				<li><strong class="bold">Web applications</strong>: Web applications, including frontend applications, backend APIs, and web services, can be containerized. Containers provide a consistent runtime environment, making <a id="_idIndexMarker129"/>it easier to package and deploy web applications across different environments, such as development, testing, <span class="No-Break">and production.</span></li>
				<li><strong class="bold">Stateful applications</strong>: Containers can also be used to run stateful applications that require persistent <a id="_idIndexMarker130"/>data storage. By leveraging container orchestration platforms’ features, such as persistent volumes or stateful sets, stateful applications such as databases, content management systems, or file servers can be containerized and <span class="No-Break">managed effectively.</span></li>
				<li><strong class="bold">Batch processing or scheduled jobs</strong>: Applications that perform batch processing <a id="_idIndexMarker131"/>tasks or scheduled jobs, such as data processing, periodic backups, or report generation, can benefit from containerization. Containers provide a controlled and isolated environment for running these jobs, ensuring consistent execution <span class="No-Break">and reproducibility.</span></li>
				<li><strong class="bold">CI/CD tools</strong>: Containerizing CI/CD tools such as Jenkins, GitLab CI/CD, or CircleCI allows for consistent and reproducible build, test, and deployment pipelines. Containers make it<a id="_idIndexMarker132"/> easier to manage dependencies, isolate build environments, and enable rapid deployment of <span class="No-Break">CI/CD infrastructure.</span></li>
				<li><strong class="bold">Development and testing environments</strong>: Containers are valuable for creating isolated and reproducible <a id="_idIndexMarker133"/>development and testing environments. Developers can use containers to package their applications along with the required dependencies, libraries, and development tools. This enables consistent development and testing experiences across different machines and <span class="No-Break">team members.</span></li>
				<li><strong class="bold">Internet of Things</strong> (<strong class="bold">IoT</strong>) <strong class="bold">applications</strong>: Containers can be used to deploy and manage applications in IoT <a id="_idIndexMarker134"/>scenarios. They provide lightweight and portable runtime environments for IoT applications, enabling easy deployment across edge devices, gateways, or <span class="No-Break">cloud infrastructures.</span></li>
				<li><strong class="bold">Machine learning and data analytics applications</strong>: Containerization is increasingly used to deploy<a id="_idIndexMarker135"/> machine learning models and data science applications. Containers encapsulate the necessary dependencies, libraries, and runtime environments, allowing for seamless deployment and scaling of <span class="No-Break">data-intensive applications.</span></li>
			</ul>
			<p>It’s important to note that not all applications are ideal candidates for containerization. Applications with heavy graphical interfaces, legacy monolithic architectures tightly coupled to the underlying infrastructure, or applications that require direct hardware access may not be suitable for containerization. Virt<a id="_idTextAnchor118"/><a id="_idTextAnchor119"/>ual machines or other deployment approaches may be more appropriate in<a id="_idTextAnchor120"/> <span class="No-Break">such cases.</span></p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor121"/>Breaking the applications into smaller pieces</h2>
			<p>You get the most out of containers if you run parts of your application independently <span class="No-Break">of others.</span></p>
			<p>This approach has numerous benefits, <span class="No-Break">as follows:</span></p>
			<ul>
				<li>You can release your<a id="_idIndexMarker136"/> application more often as you can now change a part of your application without this impacting something else; your deployments will also take less time <span class="No-Break">to run.</span></li>
				<li>Your application parts can scale independently of each other. For example, if you have a shopping app and your <em class="italic">orders</em> module is jam-packed, it can scale more than the <em class="italic">reviews</em> module, which may be far less busy. With a monolith, your entire application would scale with traffic, and this would not be the most optimized approach from a resource consumption point <span class="No-Break">of view.</span></li>
				<li>Something that impacts one part of the application does not compromise your entire system. For example, customers can still add items to their cart and check out orders if the <em class="italic">reviews</em> module <span class="No-Break">is down.</span></li>
			</ul>
			<p>However, you should also not break your application into tiny components. This will result in considerable management overhead as you will not be able to distinguish between what is what. In terms of the shopping website example, it is OK to have an <em class="italic">order</em> container, a <em class="italic">reviews</em> container, a <em class="italic">shopping cart</em> container, and a <em class="italic">catalog</em> container. However, it is not OK to have <em class="italic">create order</em>, <em class="italic">delete order</em>, and <em class="italic">update order</em> containers. That would be overkill. Breaking your application into logical components that fit your business is the <span class="No-Break">right way.</span></p>
			<p>But should you break<a id="_idTextAnchor122"/> your application into smaller parts as the very first step? Well, it depends. Most people will want to <a id="_idIndexMarker137"/>get a <strong class="bold">return on investment</strong> (<strong class="bold">ROI</strong>) out of their containerization work. Suppose you do a lift and shift from virtual machines to containers, even though you are dealing with very few variables, and you can go into containers quickly. In that case, you don’t get any benefits out of it – especially if your application is a massive monolith. Instead, you would add some application overhead because of the container layer. So, rearchit<a id="_idTextAnchor123"/><a id="_idTextAnchor124"/>ecting your application to fit in the container landscape is the key to <span class="No-Break">going ahead.</span></p>
			<h1 id="_idParaDest-38"><a id="_idTextAnchor125"/>Are we there yet?</h1>
			<p>So, you might be wondering, are we there yet? Not really! Virtual machines<a id="_idIndexMarker138"/> are to stay for a very long time. They have a good reason to exist, and while containers solve most problems, not everything can be containerized. Many legacy s<a id="_idTextAnchor126"/>ystems are running on virtual machines that cannot be migrated <span class="No-Break">to containers.</span></p>
			<p>With the advent of the cloud, <em class="italic">virtualized infrastructure</em> forms its base, and virtual machines are at its core. Most containers run on <a id="_idIndexMarker139"/>virtual machines within the cloud, and though you might be running containers in a cluster of nodes, these nodes would still be <span class="No-Break">virtual machines.</span></p>
			<p>However, the best thing about the container<a id="_idIndexMarker140"/> era is that it sees virtual machines as part of a standard setup. You install a container runtime on your virtual machines and do not need to distinguish between them. You can run your applications within containers on any virtual machine you wish. With a container orchestrator such as <em class="italic">Kubernetes</em>, you also benefit from the orchestrator deciding where to run the containers while considering various factors – resource availability is among the <span class="No-Break">most critical.</span></p>
			<p>This book will look at various aspects of modern DevOps practices, including managing cloud-based infrastructure, virtual machines, and containers. While we will mainly cover containers, we will also look at config management with equal importance using Ansible and learn how to spin up infrastructure <span class="No-Break">with Terraform.</span></p>
			<p>We will also look into modern CI/CD practices and learn how to deliver an application into production efficiently and error-free. For this, we will cover tools such as <strong class="bold">Jenkins</strong> and <strong class="bold">Argo CD</strong>. This <a id="_idIndexMarker141"/>book will give you everyt<a id="_idTextAnchor127"/><a id="_idTextAnchor128"/>hing you need to<a id="_idIndexMarker142"/> undertake a modern DevOps engineer role in the cloud and <span class="No-Break">container era.</span></p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor129"/>Summary</h1>
			<p>In this chapter, we understood modern DevOps, the cloud, and modern cloud-native applications. We then looked at how the software industry is quickly moving toward containers and how, with the cloud, it is becoming more critical for a modern DevOps engineer to have the required skills to deal with both. Then, we took a peek at the container architecture and discussed some high-level steps in moving from a virtual machine-based architecture to a <span class="No-Break">containerized one.</span></p>
			<p>In the next chapter, we will look at source code managem<a id="_idTextAnchor130"/><a id="_idTextAnchor131"/>ent with <strong class="bold">Git</strong>, which will form the base of everything we will do in the rest of <span class="No-Break">this book.</span></p>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor132"/>Questions</h1>
			<p>Answer the following questions to test your knowledge of <span class="No-Break">this chapter:</span></p>
			<ol>
				<li>Cloud computing is more expensive than <span class="No-Break">on-premises</span><span class="No-Break">. (True/False)</span></li>
				<li>Cloud computing requires more <strong class="bold">Capital</strong> <strong class="bold">Expenditure</strong> (<strong class="bold">CapEx</strong>) than <strong class="bold">Operating Expenditure</strong> (<span class="No-Break"><strong class="bold">OpEx</strong></span><span class="No-Break">)</span><span class="No-Break">. (True/False)</span></li>
				<li>Which of the following is true about cloud-native applications? (<span class="No-Break">Choose three)</span></li>
			</ol>
			<p>A. They typically follow the <span class="No-Break">microservices architecture</span></p>
			<p>B. They are <span class="No-Break">typically monoliths</span></p>
			<p>C. They <span class="No-Break">use containers</span></p>
			<p>D. They use <span class="No-Break">dynamic orchestration</span></p>
			<p>E. They use <span class="No-Break">on-premises databases</span></p>
			<ol>
				<li value="4">Containers need a hypervisor to <span class="No-Break">run</span><span class="No-Break">. (True/False)</span></li>
				<li>Which of the following statements regarding containers is <em class="italic">not</em> correct? (<span class="No-Break">Choose one)</span></li>
			</ol>
			<p>A. Containers are virtual machines within <span class="No-Break">virtual machines</span></p>
			<p>B. Containers are simple <span class="No-Break">OS processes</span></p>
			<p>C. Containers use cgroups to <span class="No-Break">provide isolation</span></p>
			<p>D. Containers use a <span class="No-Break">container runtime</span></p>
			<p>E. A container is an <span class="No-Break">ephemeral workload</span></p>
			<ol>
				<li value="6">All applications can be <span class="No-Break">containerized</span><span class="No-Break">. (True/False)</span></li>
				<li>Which of the following is a container runtime? (<span class="No-Break">Choose two)</span></li>
			</ol>
			<p><span class="No-Break">A. Docker</span></p>
			<p><span class="No-Break">B. Kubernetes</span></p>
			<p><span class="No-Break">C. Containerd</span></p>
			<p>D. <span class="No-Break">Docker Swarm</span></p>
			<ol>
				<li value="8">What kind of applications should you choose to <span class="No-Break">containerize first?</span></li>
			</ol>
			<p><span class="No-Break">A. APIs</span></p>
			<p><span class="No-Break">B. Databases</span></p>
			<p><span class="No-Break">C. Mainframes</span></p>
			<ol>
				<li value="9">Containers follow CI/CD principles out of the <span class="No-Break">box</span><span class="No-Break">. (True/False)</span></li>
				<li>Which of the following is an advantage of breaking your applications into multiple parts? (<span class="No-Break">Choose four)</span></li>
			</ol>
			<p>A. <span class="No-Break">Fault isolation</span></p>
			<p>B. Shorter release <span class="No-Break">cycle time</span></p>
			<p>C. Independent, <span class="No-Break">fine-grained scaling</span></p>
			<p>D. Application <span class="No-Break">architecture simplicity</span></p>
			<p>E. <span class="No-Break">Simpler infrastructure</span></p>
			<ol>
				<li value="11">While breaking an application into microservices, which aspect should <span class="No-Break">you consider?</span></li>
			</ol>
			<p>A. Breaking applications into as many tiny components <span class="No-Break">as possible</span></p>
			<p>B. Breaking applications into <span class="No-Break">logical components</span></p>
			<ol>
				<li value="12">What kind of application should you <span class="No-Break">containerize first?</span></li>
			</ol>
			<p><span class="No-Break">A. Stateless</span></p>
			<p><span class="No-Break">B. Stateful</span></p>
			<ol>
				<li value="13">Which of the following are examples of CaaS? (<span class="No-Break">Choose three</span><span class="No-Break">)</span></li>
			</ol>
			<p>A. <span class="No-Break">Azure Functions</span></p>
			<p>B. Google <span class="No-Break">Cloud Run</span></p>
			<p>C. <span class="No-Break">Amazon ECS</span></p>
			<p>D. <span class="No-Break">Azure ACS</span></p>
			<p>E. <span class="No-Break">Oracle Functions</span></p>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor133"/>Answers</h1>
			<ol>
				<li value="1"><span class="No-Break">False</span></li>
				<li><span class="No-Break">False</span></li>
				<li>A, <span class="No-Break">C, D</span></li>
				<li><span class="No-Break">False</span></li>
				<li>A</li>
				<li><span class="No-Break">False</span></li>
				<li><span class="No-Break">A, C</span></li>
				<li>A</li>
				<li><span class="No-Break">True</span></li>
				<li>A, B, <span class="No-Break">C, E</span></li>
				<li>B</li>
				<li>A</li>
				<li>B, <span class="No-Break">C, D</span></li>
			</ol>
		</div>
	</div>
</div>
</body></html>