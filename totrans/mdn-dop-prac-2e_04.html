<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer040">
			<h1 id="_idParaDest-106" class="chapter-number"><a id="_idTextAnchor399"/>4</h1>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor400"/> Creating and Managing Container Images</h1>
			<p>In the previous chapter, we covered containerization with Docker, where we installed Docker and ran our first container. We covered some core fundamentals, including Docker volumes, mounts, storage drivers, and logging drivers. We also covered Docker Compose as a declarative method of <span class="No-Break">managing containers.</span></p>
			<p>Now, we will discuss the core building blocks of containers: container images. Container images also fulfill a core principle of modern DevOps practices: config as code. Therefore, understanding container images, how they work, and how to build an image effectively is very important for a modern <span class="No-Break">DevOps engineer.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li><a id="_idTextAnchor401"/><span class="No-Break">Docker architecture</span></li>
				<li>Understanding <span class="No-Break">Docker images</span></li>
				<li>Understanding Dockerfiles, components, <span class="No-Break">and directives</span></li>
				<li>Building and managing <span class="No-Break">Docker images</span></li>
				<li>Flattening <span class="No-Break">Docker images</span></li>
				<li>Optimizing containers with <span class="No-Break">distroless images</span></li>
				<li>Understanding <span class="No-Break">Docker registries</span></li>
			</ul>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor402"/><a id="_idTextAnchor403"/>Technical requirements</h1>
			<p>For this chapter, we assume that you have Docker installed on a Linux machine running Ubuntu 18.04 Bionic LTS or later with sudo access. You can read <a href="B19877_03.xhtml#_idTextAnchor220"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Containerization with Docker</em>, for more details on how to <span class="No-Break">do that.</span></p>
			<p>You will also need to clone a GitHub repository for some of the exercises in this chapter, which you can find at <a href="https://github.com/PacktPublishing/Modern-DevOps-Practices-2e">https://github.com/PacktPublishing/Modern-DevOps-Practices-2e</a>. Also, you need a Docker Hub account for most of the activities. To create one, go <span class="No-Break">to </span><a href="https://hub.docker.com/"><span class="No-Break">https://hub.docker.com/</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor404"/><a id="_idTextAnchor405"/>Docker architecture</h1>
			<p>Imagine you’re a <a id="_idIndexMarker369"/>passionate chef dedicated to creating mouthwatering dishes that satisfy hungry customers. In your kitchen, which is a magical place called Docker, you have special powers to plan, make, and showcase your culinary creations. Let’s break down the <span class="No-Break">key parts:</span></p>
			<p><strong class="bold">Ingredients (Application Code and Dependencies)</strong>: Imagine your kitchen has shelves filled with ingredients such <a id="_idIndexMarker370"/>as flour, eggs, and spices. These ingredients <a id="_idIndexMarker371"/>come together in a specific way to make a dish. Similarly, your application code and dependencies work together to build <span class="No-Break">your application.</span></p>
			<p><strong class="bold">Recipe (Image)</strong>: Each recipe is like a plan for a particular dish. Imagine having a recipe for chocolate cake or pasta carbonara. These <a id="_idIndexMarker372"/>recipes are like the building blocks for your creations. In the same way, a Docker image is a plan for making your <span class="No-Break">Docker container.</span></p>
			<p><strong class="bold">Recipe Cards (Dockerfile)</strong>: Your cooking journey involves using special recipe cards called Dockerfiles. These <a id="_idIndexMarker373"/>cards show you the important steps and ingredients (commands) to follow. For example, a Dockerfile for a chocolate cake might have steps such as “Mix the flour and sugar” or “Add eggs and cocoa powder.” These Dockerfiles guide your helpers (Docker) in making the <span class="No-Break">dish (container).</span></p>
			<p><strong class="bold">Cooked Dish (Container)</strong>: When <a id="_idIndexMarker374"/>someone wants a dish, you use the recipe (image) to make it. Then, you have a fresh, hot dish ready to serve. These dishes are separate, but they can be made again and again (thanks to the recipe), just like <span class="No-Break">a container.</span></p>
			<p><strong class="bold">Kitchen Staff (Docker Engine)</strong>: In your<a id="_idIndexMarker375"/> bustling kitchen, your helpers (Docker Engine) play a big role. They do the hard work, from getting ingredients to following the recipe and serving the dish. You give them instructions (Docker commands), and they make it happen. They even clean up after making <span class="No-Break">each dish.</span></p>
			<p><strong class="bold">Special Set Menu (Docker Compose)</strong>: Sometimes, you want to serve a special meal with multiple dishes that go well together. Think of a meal with an appetizer, a main course, and a dessert. Using <a id="_idIndexMarker376"/>Docker Compose is like creating a special menu for that occasion. It lists recipes (images) for each part of the meal and how they should be served. You can even customize it to create a whole meal experience with just <span class="No-Break">one command.</span></p>
			<p><strong class="bold">Storage Area (Volumes)</strong>: In your kitchen, you need a place to keep ingredients and dishes. Think of Docker volumes<a id="_idIndexMarker377"/> as special storage areas where you can keep important things, such as data and files, that multiple dishes (containers) <span class="No-Break">can use.</span></p>
			<p><strong class="bold">Communication Channels (Networks)</strong>: Your kitchen is a busy place with lots of talking and interacting. In Docker, networks<a id="_idIndexMarker378"/> are like special communication paths that help different parts of your kitchen (containers) talk to <span class="No-Break">each other.</span></p>
			<p>So, Docker is like your magical kitchen where you make dishes (containers) using plans (Dockerfiles) and ingredients (images) with the assistance of your kitchen helpers (Docker Engine). You can even serve entire meals (Docker Compose) and use special storage areas (volumes) and communication paths (networks) to make your dishes even more amazing. Just like a chef gets better with practice, exploring Docker will help you become a master of DevOps in no time! Now, let’s dive deeper into Docker architecture to understand <span class="No-Break">its nuances!</span></p>
			<p>As <a id="_idTextAnchor406"/>we already know, Docker uses the <em class="italic">build once, run anywhere</em> concept. Docker packages applications into images. Docker images form the blueprint of containers, so a container is an instance of <span class="No-Break">an image.</span></p>
			<p>A container image packages applications and their dependencies, so they are a single immutable unit you can run on any machine that runs Docker. You can also visualize them as a snapshot of <span class="No-Break">the container.</span></p>
			<p>We can build and store Docker im<a id="_idTextAnchor407"/>ages in a Docker registry, such<a id="_idIndexMarker379"/> as <strong class="bold">Docker Hub</strong>, and then download and use those images in the system where we want to deploy them. Images comprise several layers, which helps break images into multiple parts. The layers tend to be reusable stages that other images can build upon. This also means we don’t have to transmit the entire image over a network when changing images. We only transmit the delta, which saves a lot of network I/O. We will talk about the layered filesystem in detail later in <span class="No-Break">this chapter.</span></p>
			<p>The<a id="_idTextAnchor408"/> following diagram shows the components<a id="_idIndexMarker380"/> Docker uses to orchestrate the <span class="No-Break">following activities:</span></p>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/B19877_Figure_4.01.jpg" alt="Figure 4.1 – Docker architecture" width="1142" height="558"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Docker architecture</p>
			<p> The <span class="No-Break">components are:</span></p>
			<ul>
				<li><strong class="bold">Docker daemon</strong>: This <a id="_idIndexMarker381"/>process runs on the servers that we want to run our containers on. They deploy and run containers on the <span class="No-Break">Docker server.</span></li>
				<li><strong class="bold">Docker registries</strong>: These<a id="_idIndexMarker382"/> store and distribute <span class="No-Break">Docker images.</span></li>
				<li><strong class="bold">Docker client</strong>: This is<a id="_idIndexMarker383"/> the command-line utility that we’ve been using to issue <strong class="source-inline">docker</strong> commands to the <span class="No-Break">Do<a id="_idTextAnchor409"/>cker daemon.</span></li>
			</ul>
			<p>Now that we understand Docker architecture’s key components and how Docker images play <a id="_idTextAnchor410"/>an essential role, let’s understand Docker images and their components, directives, and registrie<a id="_idTextAnchor411"/><a id="_idTextAnchor412"/>s <span class="No-Break">in detail.</span></p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor413"/>Understanding Docker images</h1>
			<p><a id="_idTextAnchor414"/>Docker images<a id="_idIndexMarker384"/> form the blueprint of Docker containers. Just like you need a blueprint for a shipping container to determine its size and what goods it will contain, a Docker image specifies what packages, source code, dependencies, and libraries it needs to use. It also determines what it needs to do for the source code to <span class="No-Break">run effectively.</span></p>
			<p>Technically, it consists of a series of steps you would perform on a base OS image to get your application up and running. This may include installing packages and dependencies, copying the source code to the correct folder, building your code to generate a binary, and <span class="No-Break">so on.</span></p>
			<p>You can store Docker images in a container registry, a centralized location from where your Docker machines can pull images to <span class="No-Break">create containers.</span></p>
			<p>Docker images use a layered filesystem. Instead of a huge monolithic block on the filesystem that comprises the template to run containers, we have many layers, one on top of <a id="_idTextAnchor415"/>the other. But what does this mean? What problem does this solve? Let’s have a look in the <a id="_idTextAnchor416"/><a id="_idTextAnchor417"/><span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-111">The layered filesys<a id="_idTextAnchor418"/>tem</h2>
			<p>Layers in <a id="_idIndexMarker385"/>Docker are intermediate Docker images. The idea is that every<a id="_idIndexMarker386"/> Dockerfile statement we execute on top of a layer changes something within the layer and builds a new one. The subsequent statement modifies the current one to generate the next one. The final layer executes the Docker <strong class="source-inline">CMD</strong> or <strong class="source-inline">ENTRYPOINT</strong> command, and the resulting image comprises several layers arranged one on top of the other. Let’s understand this by looking at a <span class="No-Break">simple example.</span></p>
			<p>If we pull the <em class="italic">Flask application</em> we built in the previous chapter, we will see <span class="No-Break">the following:</span></p>
			<pre class="console">
$ docker pull bharamicrosystems/python-flask-redis
Using default tag: latest
latest: Pulling from bharamicrosystems/python-flask-redis
188c0c94c7c5: Pull complete
a2f4f20ac898: Pull complete
f8a5b284ee96: Pull complete
28e9c106bfa8: Pull complete
8fe1e74827bf: Pull complete
95618753462e: Pull complete
03392bfaa2ba: Pull complete
4de3b61e85ea: Pull complete
266ad40b3bdb: Pull complete
Digest: sha256:bb40a44422b8a7fea483a775fe985d4e05f7e5c59b0806a2
4f6cca50edadb824
Status: Downloaded newer image for bharamicrosystems/python-flask-redis:latest
docker.io/bharamicrosystems/python-flask-redis:latest</pre>			<p>As you<a id="_idIndexMarker387"/> can see, many <strong class="source-inline">Pull complete</strong> statements are beside random <a id="_idIndexMarker388"/>IDs. These are called <strong class="bold">layers</strong>. The current layer contains just the differences between the previous and current filesystem. A container image comprises <span class="No-Break">several layers.</span></p>
			<p><a id="_idTextAnchor419"/>Containers contain an additional writable filesystem on top of the image layers. This is the layer where your containers modify the filesystem to provide the <span class="No-Break">expected functionality.</span></p>
			<p>There are several advantages of using layers instead of merely copying the entire filesystem of the container. Since image layers are read-only, multiple containers created from an image share the same layered filesystem, decreasing the overall disk and network footprint. Layers also allow you to share filesystems between images. For example, if two images come from a single base image, both images share the same <span class="No-Break">base layer.</span></p>
			<p>The following diagram shows a Python application that runs on an Ubuntu OS. At a high level, you will see a base layer (Ubuntu OS) and Python installed on top of it. On top of Python, we’ve installed the Python app. All these components form the image. When we create a container out of the image and run it, we get the writable filesystem on top as <a id="_idTextAnchor420"/>the <span class="No-Break">final layer:</span></p>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/B19877_Figure_4.02.jpg" alt="Figure 4.2 – Container layers" width="1407" height="748"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Container l<a id="_idTextAnchor421"/>ayers</p>
			<p>So, you can <a id="_idIndexMarker389"/>create multiple Python app images from the same base image and customize them according to <span class="No-Break">your needs.</span></p>
			<p>The writable<a id="_idIndexMarker390"/> filesystem is unique for every container you spin from container images, even if you create containers fr<a id="_idTextAnchor422"/><a id="_idTextAnchor423"/>om the <span class="No-Break">same image.</span></p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor424"/>Image history</h2>
			<p>To understand images and<a id="_idIndexMarker391"/> their layers, you can always inspect the <span class="No-Break">image history.</span></p>
			<p>Let’s inspect the history of the last Docker image by running the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker history bharamicrosystems/python-flask-redis
IMAGE         CREATED      CREATED BY                                     SIZE    COMMENT
6d33489ce4d9  2 years ago  /bin/sh -c #(nop)  CMD ["flask" "run"]         0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop) COPY dir:61bb30c35fb351598…  1.2kB
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  EXPOSE 5000                 0B
&lt;missing&gt;     2 years ago  /bin/sh -c pip install -r requirements.txt     11.2MB
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop) COPY file:4346cf08412270cb…  12B
&lt;missing&gt;     2 years ago  /bin/sh -c apk add --no-cache gcc musl-dev l…  143MB
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV FLASK_RUN_HOST=0.0.0.0  0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV FLASK_APP=app.py        0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  CMD ["python3"]             0B
&lt;missing&gt;     2 years ago  /bin/sh -c set -ex;   wget -O get-pip.py "$P…  7.24MB
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV PYTHON_GET_PIP_SHA256…  0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV PYTHON_GET_PIP_URL=ht…  0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV PYTHON_PIP_VERSION=20…  0B
&lt;missing&gt;     2 years ago  /bin/sh -c cd /usr/local/bin  &amp;&amp; ln -s idle3…  32B
&lt;missing&gt;     2 years ago  /bin/sh -c set -ex  &amp;&amp; apk add --no-cache --…  28.3MB
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV PYTHON_VERSION=3.7.9    0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV GPG_KEY=0D96DF4D4110E…  0B
&lt;missing&gt;     2 years ago  /bin/sh -c set -eux;  apk add --no-cache   c…  512kB
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV LANG=C.UTF-8            0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  ENV PATH=/usr/local/bin:/…  0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop)  CMD ["/bin/sh"]             0B
&lt;missing&gt;     2 years ago  /bin/sh -c #(nop) ADD file:f17f65714f703db90…  5.57MB</pre>			<p>As you can see, there are several layers, and every layer has associated commands. You can also see when the layers were created and the size of the disk space occupied by each.<a id="_idTextAnchor425"/> Some layers do not <a id="_idIndexMarker392"/>occupy any disk space, as they haven’t added anything new to the filesystem, such as <strong class="source-inline">CMD</strong> and <strong class="source-inline">EXPOSE</strong> directives. These perform some functions, but they do not write anything to the filesystem. While commands such as <strong class="source-inline">apk add</strong> write to the filesystem, you can see them taking up <span class="No-Break">disk space.</span></p>
			<p>Every layer modifies the<a id="_idIndexMarker393"/> old layer in some way, so every layer is just a delta of the <span class="No-Break">filesystem configuration.</span></p>
			<p>In the next section, we will deep dive into Dockerfiles and find out how we can build Docker images and see what the layered arc<a id="_idTextAnchor426"/><a id="_idTextAnchor427"/>hitecture <span class="No-Break">looks like.</span></p>
			<h1 id="_idParaDest-113">Understanding Dockerfiles, components, and d<a id="_idTextAnchor428"/>irecti<a id="_idTextAnchor429"/>ves</h1>
			<p>A Dockerfile<a id="_idIndexMarker394"/> is a simple file th<a id="_idTextAnchor430"/>at constitutes a series of steps to build a Docker image. Each step is known as a <strong class="bold">directive</strong>. There are different kinds of directives. Let’s look at a simple example to understand<a id="_idIndexMarker395"/> how <span class="No-Break">this works.</span></p>
			<p>We will create a simple NGINX container by building the image from scratch rather than using the one available on Docker Hub. NGINX<a id="_idIndexMarker396"/> is very popular web server software that you can use for a variety of applications; for example, it can serve as a load balancer or a <span class="No-Break">reverse proxy.</span></p>
			<p>Start by creating <span class="No-Break">a</span><span class="No-Break"><a id="_idIndexMarker397"/></span><span class="No-Break"> Dockerfile:</span></p>
			<pre class="console">
$ vim Dockerfile
FROM ubuntu:bionic
RUN apt update &amp;&amp; apt install -y curl
RUN apt update &amp;&amp; apt install -y nginx
CMD ["nginx", "-g", "daemon off;"]</pre>			<p>Let’s look at each line and <a id="_idIndexMarker398"/>directive one by one to understand how this <span class="No-Break">Dockerfil<a id="_idTextAnchor431"/>e works:</span></p>
			<ul>
				<li>The <strong class="source-inline">FROM</strong> directive<a id="_idIndexMarker399"/> specifies what the base image for this container should be. This means we are using another image as the base and will be building layers on top of it. We use the <strong class="source-inline">ubuntu:bionic</strong> package as the base image for this build since we want to run NGINX <span class="No-Break">on<a id="_idTextAnchor432"/> Ubuntu.</span></li>
				<li>The <strong class="source-inline">RUN</strong> directives<a id="_idIndexMarker400"/> specify the commands we need to run on<a id="_idTextAnchor433"/> a particular layer. You can run more than one command by separati<a id="_idTextAnchor434"/>ng them with  <strong class="source-inline">&amp;&amp;</strong>. We want to run multiple commands in a single line if we’re going to club dependent commands in a single layer. Every layer should meet a particular objective. In the preceding example, the first <strong class="source-inline">RUN</strong> directive is used to install <strong class="source-inline">curl</strong>, while the next <strong class="source-inline">RUN</strong> directive is used to <span class="No-Break">install </span><span class="No-Break"><strong class="source-inline">nginx</strong></span><span class="No-Break">.</span></li>
				<li>You might be wondering why we have <strong class="source-inline">apt update</strong> before every installation. This is required, as Docker builds images using layers. So, one layer should not have implicit dependencies on the previous one. In this example, if we omit <strong class="source-inline">apt update</strong> while installing <strong class="source-inline">nginx</strong>, and if we want to update the <strong class="source-inline">nginx</strong> version without changing anything in the directive containing <strong class="source-inline">apt update</strong> (that is, the line that installs <strong class="source-inline">curl</strong>), when we run the build, <strong class="source-inline">apt update</strong> will not run again, so your <strong class="source-inline">nginx</strong> installation <span class="No-Break">m<a id="_idTextAnchor435"/>ight fail.</span></li>
				<li>The <strong class="source-inline">CMD</strong> directive<a id="_idIndexMarker401"/> specifies a list of commands that we need to run when the built image runs as a container. This is the default command that will be executed, and its output will end up in the container logs. Your container can contain one or more <strong class="source-inline">CMD</strong> directives. For a long-running process such as NGINX, the last <strong class="source-inline">CMD</strong> should contain something that will not pass control back to the shell and continue to run for the container’s lifetime. In this case, we run <strong class="source-inline">nginx -g daemon off;</strong>, which is a <a id="_idIndexMarker402"/>standard way of running NGINX in <span class="No-Break">the foreground.</span></li>
			</ul>
			<p>Some directives can easily be confused with each other, such as <strong class="source-inline">ENTRYPOINT</strong> and <strong class="source-inline">CMD</strong> or <strong class="source-inline">CMD</strong> and <strong class="source-inline">RUN</strong>. These a<a id="_idTextAnchor436"/>lso test how<a id="_idTextAnchor437"/> solid your Docker fundamenta<a id="_idTextAnchor438"/><a id="_idTextAnchor439"/>ls are, so let’s look <span class="No-Break">at both.</span></p>
			<h2 id="_idParaDest-114">Can we use ENTRYPOINT inste<a id="_idTextAnchor440"/>ad of CMD?</h2>
			<p>Instead of <strong class="source-inline">CMD</strong>, you can<a id="_idIndexMarker403"/> use <strong class="source-inline">ENTRYPOINT</strong>. While they serve a similar purpose, they are two very different directives. Every Docker container has a default <strong class="source-inline">ENTRYPOINT</strong> – <strong class="source-inline">/bin/sh -c</strong>. Anything you add to <strong class="source-inline">CMD</strong> is appended post-<strong class="source-inline">ENTRYPOINT</strong> and executed; for example, <strong class="source-inline">CMD ["nginx", "-g", "daemon off;"]</strong> will be generated as <strong class="source-inline">/bin/sh -c nginx -g daemon off;</strong>. If you use a custom <strong class="source-inline">ENTRYPOINT</strong> instead, the commands you use while launching the container will be appended after it. So, if you define <strong class="source-inline">ENTRYPOINT ["nginx", "-g"]</strong> and use<strong class="source-inline"> docker run nginx daemon off;</strong>, you will get a <span class="No-Break">similar result.</span></p>
			<p>To get a similar result <a id="_idIndexMarker404"/>without adding any <strong class="source-inline">CMD</strong> arguments while launching the container, you can also use <strong class="source-inline">ENTRYPOINT ["nginx", "-g", "</strong><span class="No-Break"><strong class="source-inline">daemon off;"]</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Use <strong class="source-inline">ENTRYPOINT</strong> unless there is a need for a specific <strong class="source-inline">CMD</strong> requirement. Using <strong class="source-inline">ENTRYPOINT</strong> ensures that users cannot change the default behavior of your container, so it’s a more <span class="No-Break">secure alternative.</span></p>
			<p>No<a id="_idTextAnchor441"/><a id="_idTextAnchor442"/>w, let’s look at <strong class="source-inline">RUN</strong> <span class="No-Break">versus </span><span class="No-Break"><strong class="source-inline">CMD</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-115">Are RUN and C<a id="_idTextAnchor443"/>MD the sa<a id="_idTextAnchor444"/>me?</h2>
			<p>No, <strong class="source-inline">RUN</strong> and <strong class="source-inline">CMD</strong> are different and serve different purposes. While <strong class="source-inline">RUN</strong> is used to build the container and only modifies the filesystem while building it, <strong class="source-inline">CMD</strong> commands are only executed on the writable container layer after the container <span class="No-Break">is running.</span></p>
			<p>While there can be several <strong class="source-inline">RUN</strong> statements in a Dockerfile, each modifying the existing layer and generating the next, if a Dockerfile contains<a id="_idIndexMarker405"/> more than one <strong class="source-inline">CMD</strong> command, all but the last one <span class="No-Break">are ignored.</span></p>
			<p>The <strong class="source-inline">RUN</strong> directives<a id="_idIndexMarker406"/> are used to execute statements within the container filesystem to build and customize the container image, thus modifying the image layers. The idea of using a <strong class="source-inline">CMD</strong> command is to provide the default command(s) with the container image that will be executed at runtime. This only changes the writeable containe<a id="_idTextAnchor445"/>r fil<a id="_idTextAnchor446"/>esystem. You can also override the commands by passing a custom command in the <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">run</strong></span><span class="No-Break"> statement.</span></p>
			<p>Now, let’s go ahead an<a id="_idTextAnchor447"/><a id="_idTextAnchor448"/>d build our first <span class="No-Break">container image.</span></p>
			<h2 id="_idParaDest-116">Buil<a id="_idTextAnchor449"/>ding our first container</h2>
			<p>Building a container<a id="_idIndexMarker407"/> image is very simple. It is actually a one-line command: <strong class="source-inline">docker build -t &lt;image-name&gt;:version &lt;build_context&gt;</strong>. While we will discuss building container images in detail in the <em class="italic">Building and managing container images</em> section, let’s first build <span class="No-Break">the Dockerfile:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/nginx-hello-world .
[+] Building 50.0s (7/7) FINISHED
 =&gt; [internal] load .dockerignore 0.0s
 =&gt; =&gt; transferring context: 2B 0.0s
 =&gt; [internal] load build definition from Dockerfile 0.1s
 =&gt; =&gt; transferring dockerfile: 171B 0.0s
 =&gt; [internal] load metadata for docker.io/library/ubuntu:bionic 2.4s
 =&gt; [1/3] FROM docker.io/library/ubuntu:bionic@sha256:152dc042… 2.8s
 =&gt; =&gt; resolve docker.io/library/ubuntu:bionic@sha256:152dc04… 0.0s
 =&gt; =&gt; sha256:152dc042… 1.33kB / 1.33kB 0.0s
 =&gt; =&gt; sha256:dca176c9… 424B / 424B 0.0s
 =&gt; =&gt; sha256:f9a80a55… 2.30kB / 2.30kB 0.0s
 =&gt; =&gt; sha256:7c457f21… 25.69MB / 25.69MB 1.0s
 =&gt; =&gt; extracting sha256:7c457f21… 1.6s
 =&gt; [2/3] RUN apt update &amp;&amp; apt install -y curl 22.4s
 =&gt; [3/3] RUN apt update &amp;&amp; apt install -y nginx 21.6s
 =&gt; exporting to image 0.6s
 =&gt; =&gt; exporting layers 0.6s
 =&gt; =&gt; writing image sha256:9d34cdda… 0.0s
 =&gt; =&gt; naming to docker.io/&lt;your_dockerhub_user&gt;/nginx-hello-world</pre>			<p>You might have <a id="_idIndexMarker408"/>noticed that the name of the container had a prefix in front of it. That is your Docker Hub account name. The name of the image has a structure <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">&lt;registry-url&gt;/&lt;account-name&gt;/&lt;container-image-name&gt;:&lt;version&gt;</strong></span><span class="No-Break">.</span></p>
			<p>Here, we have <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="source-inline">registry-url</strong>: The URL to the Docker registry – def<a id="_idTextAnchor450"/>aults <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">docker.io</strong></span></li>
				<li><strong class="source-inline">account-name</strong>: The user or account that owns <span class="No-Break">the image</span></li>
				<li><strong class="source-inline">container-image-name</strong>: The container <span class="No-Break">image’s name</span></li>
				<li><strong class="source-inline">version</strong>: The <span class="No-Break">image version</span></li>
			</ul>
			<p>Now, let’s create a container out of the image using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker run -d -p 80:80 &lt;your_dockerhub_user&gt;/nginx-hello-world
092374c4501560e96a13444ce47cb978b961cf8701af311884bfe…
$ docker ps
CONTAINER ID  IMAGE            COMMAND       CREATED     STATUS   PORTS               NAMES
092374c45015  &lt;your_dockerhub  "nginx -g     28 seconds  Up 27    0.0.0.0:80-&gt;80/     loving_
              _user&gt;/nginx-    'daemon of…"  ago         seconds  tcp, :::80-&gt;80/tcp  noether
              hello-world                                                                     </pre>			<p>Here, we can see that the container is up <span class="No-Break">and running.</span></p>
			<p>If we run <strong class="source-inline">curl localhost</strong>, we get the default <strong class="source-inline">nginx</strong> <span class="No-Break"><strong class="source-inline">html</strong></span><span class="No-Break"> response:</span></p>
			<pre class="console">
$ curl localhost
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
...
&lt;/body&gt;
&lt;/html&gt;</pre>			<p>That’s great! We have built our first image using <span class="No-Break">a Dockerfile.</span></p>
			<p>What if we wanted to customize the image according to our r<a id="_idTextAnchor451"/>equirements? Practically speaking, no one would want an NGINX container just responding with the default <strong class="source-inline">Welcome to nginx!</strong> message, so let’s create an index page and use <span class="No-Break">that instead:</span></p>
			<pre class="console">
$ vim index.html
Hello World! This is my first docker image!</pre>			<p>This one outputs a <a id="_idIndexMarker409"/>custom message instead of the default NGINX <span class="No-Break">HTML page.</span></p>
			<p>We all know that the default NGINX directory containing the <strong class="source-inline">index.html</strong> file is <strong class="source-inline">/var/www/html</strong>. If we can copy the <strong class="source-inline">index.html</strong> file into this directory, it should sort out <span class="No-Break">our problem.</span></p>
			<p>So, modify the Dockerfile so that it includes <span class="No-Break">the following:</span></p>
			<pre class="console">
$ vim Dockerfile
FROM ubuntu:bionic
RUN apt update &amp;&amp; apt install -y curl
RUN apt update &amp;&amp; apt install -y nginx
WORKDIR /var/www/html/
ADD index.html ./
CMD ["nginx", "-g", "daemon off;"]</pre>			<p>Here, we’ve added two directives to the file: <strong class="source-inline">WORKDIR</strong> and <strong class="source-inline">ADD</strong>. Let’s understand what each <span class="No-Break">one does:</span></p>
			<ul>
				<li><strong class="source-inline">WORKDIR</strong>: This defines the current working directory, which is <strong class="source-inline">/var/www/html</strong> in this case. The last <strong class="source-inline">WORKDIR</strong> in the Dockerfile also specifies the working directory when the container is executed. So, if you <strong class="source-inline">exec</strong> into a running container, you will land in the last defined <strong class="source-inline">WORKDIR</strong>. <strong class="source-inline">WORKDIR</strong> can be absolute as well as relative to the current <span class="No-Break">working directory.</span></li>
				<li><strong class="source-inline">ADD</strong>: This adds a local file to the container filesystem – the working directory, in this case. You can also use a <strong class="source-inline">COPY</strong> directive here instead of <strong class="source-inline">ADD</strong>, though <strong class="source-inline">ADD</strong> offers some more features, such as downloading file<a id="_idTextAnchor452"/>s from a URL and using an archive such as a TAR or <span class="No-Break">ZIP package.</span></li>
			</ul>
			<p>When we build this file, we<a id="_idIndexMarker410"/> expect the <strong class="source-inline">index.html</strong> file to be copied to the <strong class="source-inline">/var/www/html</strong> directory within the container filesystem. Let’s have <span class="No-Break">a look:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/nginx-hello-world .
[+] Building 1.6s (10/10) FINISHED
 =&gt; [internal] load build definition from Dockerfile 0.0s
 =&gt; =&gt; transferring dockerfile: 211B 0.0s
 =&gt; [internal] load .dockerignore 0.0s
 =&gt; =&gt; transferring context: 2B 0.0s
 =&gt; [internal] load metadata for docker.io/library/ubuntu:bionic 1.4s
 =&gt; [1/5] FROM docker.io/library/ubuntu:bionic@sha256:152dc042… 0.0s
 =&gt; [internal] load build context 0.0s
 =&gt; =&gt; transferring context: 81B 0.0s
 =&gt; CACHED [2/5] RUN apt update &amp;&amp; apt install -y curl 0.0s
 =&gt; CACHED [3/5] RUN apt update &amp;&amp; apt install -y nginx 0s
 =&gt; [4/5] WORKDIR /var/www/html/ 0.0s
 =&gt; [5/5] ADD index.html ./ 0.0s
 =&gt; exporting to image 0.0s
 =&gt; =&gt; exporting layers 0.0s
 =&gt; =&gt; writing image sha256:cb2e67bd… 0.0s
 =&gt; =&gt; naming to docker.io/&lt;your_dockerhub_user&gt;<a id="_idTextAnchor453"/>/nginx-hello-world</pre>			<p>This time, the build was much faster! When we executed the Docker build, it used a lot of layers from the cache. That is one of the advantages of layered architecture; you only build the changing part and use the existing one the way <span class="No-Break">it is.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Always add source code after installing packages and dependencies. The source code changes frequently and the packages more or less remain the same. This will result in faster builds and save a lot of <span class="No-Break">CI/CD time.</span></p>
			<p>Let’s rerun the <a id="_idIndexMarker411"/>container and see what we get. Note that you need to remove the old container before <span class="No-Break">doing so:</span></p>
			<pre class="console">
$ docker ps
CONTAINER ID  IMAGE            COMMAND       CREATED     STATUS   PORTS               NAMES
092374c45015  &lt;your_dockerhub  "nginx -g     28 seconds  Up 27    0.0.0.0:80-&gt;80/     loving_
              _user&gt;/nginx-    'daemon of…"  ago         seconds  tcp, :::80-&gt;80/tcp  noether
              hello-world                                                                     
$ docker rm 092374c45015 -f
092374c45015</pre>			<p>At this point, we can’t see the container anymore. Now, let’s rerun the container using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker run -d -p 80:80 &lt;your_dockerhub_user&gt;/nginx-hello-world
cc4fe116a433c505ead816fd64350cb5b25c5f3155bf5eda8cede5a4…
$ docker ps
CONTAINER ID  IMAGE            COMMAND       CREATED     STATUS   PORTS               NAMES
cc4fe116a433  &lt;your_dockerhub  "nginx -g     52 seconds  Up 50    0.0.0.0:80-&gt;80/     eager_
              _user&gt;/nginx-    'daemon of…"  ago         seconds  tcp, :::80-&gt;80/tcp  gates
              hello-world                                                            </pre>			<p>Here, we can see that the container is up and running. Let’s use <strong class="source-inline">curl localhost</strong> to see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ curl localhost
Hello World! This is my first docker image!</pre>			<p>Here, we get a custom message instead of the default NGINX <span class="No-Break">HTML response!</span></p>
			<p>This looks good <a id="_idIndexMarker412"/>enough for now, but I will discuss a few more directives to make this image more reliable. First, we haven’t explicitly documented what port this container should expose. This works perfectly fine, as we know that NGINX runs on port <strong class="source-inline">80</strong>, but what if someone wants to use your image and doesn’t know the port? In that scenario, it is best practice to define the port explicitly. We will use the <strong class="source-inline">EXPOSE</strong> directive <span class="No-Break">for that.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Always use the <strong class="source-inline">EXPOSE</strong> directive to give more clarity and meaning to <span class="No-Break">your image.</span></p>
			<p>We also need to define the action to the container process if someone sends a <strong class="source-inline">docker stop</strong> command. While most processes take the hint and kill the process, it makes sense to explicitly specify what <strong class="source-inline">STOPSIGNAL</strong> the container should send on a <strong class="source-inline">docker stop</strong> command. We will use the <strong class="source-inline">STOPSIGNAL</strong> directive <span class="No-Break">for that.</span></p>
			<p>Now, while Docker monitors the container process and keeps it running unless it receives a <strong class="source-inline">SIGTERM</strong> or a stop, what would happen if your container process hangs for some reason? While your application is in a hung state, Docker still thinks it is running as your process is still running. Therefore, monitoring the application through an explicit health check would make sense. We will use the <strong class="source-inline">HEALTHCH<a id="_idTextAnchor454"/>ECK</strong> directive <span class="No-Break">for this.</span></p>
			<p>Let’s combine all these aspects and see what we get in <span class="No-Break">the Dockerfile:</span></p>
			<pre class="console">
$ vim Dockerfile
FROM ubuntu:bionic
RUN apt update &amp;&amp; apt install -y curl
RUN apt update &amp;&amp; apt install -y nginx
WORKDIR /var/www/html/
ADD index.html ./
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
STOPSIGNAL SIGTERM
HEALTHCHECK --interval=60s --timeout=10s --start-period=20s --retries=3 CMD curl -f 
localhost</pre>			<p>While <strong class="source-inline">EXPOSE</strong> and <strong class="source-inline">STOPSIGNAL</strong> are<a id="_idIndexMarker413"/> self-explanatory, let’s look at the <strong class="source-inline">HEALTHCHECK</strong> directive. The <strong class="source-inline">HEALTHCHECK</strong> directive runs a command (hence <strong class="source-inline">CMD</strong>) called <strong class="source-inline">curl -f localhost</strong>. So, this container will report itself as healthy until the result of the <strong class="source-inline">curl</strong> command is <span class="No-Break">a success.</span></p>
			<p>The <strong class="source-inline">HEALTHCHECK</strong> directive also contains the following <span class="No-Break">optional fields:</span></p>
			<ul>
				<li><strong class="source-inline">--interval (default: 30s)</strong>: The interval between two subsequent <span class="No-Break">health checks.</span></li>
				<li><strong class="source-inline">--timeout (default: 30s)</strong>: The health check probe timeout. If the health check times out, it implies a health <span class="No-Break">check failure.</span></li>
				<li><strong class="source-inline">--start-period (default: 0s)</strong>: The time lag between starting the container and the first health check. This allows you to ensure your container is up before a <span class="No-Break">health check.</span></li>
				<li><strong class="source-inline">--retries (default: 3)</strong>: The number of times the probe will retry before<a id="_idTextAnchor455"/> declaring an <span class="No-Break">unhealthy status.</span></li>
			</ul>
			<p>Now, let’s build <span class="No-Break">this container:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/nginx-hello-world .
[+] Building 1.3s (10/10) FINISHED
 =&gt; [internal] load build definition from Dockerfile 0.0s
 =&gt; =&gt; transferring dockerfile: 334B 0.0s
 =&gt; [internal] load .dockerignore 0.0s
 =&gt; =&gt; transferring context: 2B 0.0s
 =&gt; [internal] load metadata for docker.io/library/ubuntu:bionic 1.2s
 =&gt; [1/5] FROM docker.io/library/ubuntu:bionic@sha256:152dc0… 0.0s
 =&gt; [internal] load build context 0.0s
 =&gt; =&gt; transferring context: 31B 0.0s
 =&gt; CACHED [2/5] RUN apt update &amp;&amp; apt install -y curl 0.0s
 =&gt; CACHED [3/5] RUN apt update &amp;&amp; apt install -y nginx 0s
 =&gt; CACHED [4/5] WORKDIR /var/www/html/ 0.0s
 =&gt; CACHED [5/5] ADD index.html ./ 0.0s
 =&gt; exporting to image 0.0s
 =&gt; =&gt; exporting layers 0.0s
 =&gt; =&gt; writing image sha256:bba3123d… 0.0s
 =&gt; =&gt; naming to docker.io/&lt;your_dock<a id="_idTextAnchor456"/>erhub_user&gt;/nginx-hello-world</pre>			<p>It’s time to run <a id="_idIndexMarker414"/>it and see <span class="No-Break">for ourselves:</span></p>
			<pre class="console">
$ docker run -d -p 80:80 &lt;your_dockerhub_user&gt;/nginx-hello-world
94cbf3fdd7ff1765c92c81a4d540df3b4dbe1bd9748c91e2ddf565d8…</pre>			<p>Now that we have successfully launched the container, let’s try <strong class="source-inline">ps</strong> and see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker ps
CONTAINER ID  IMAGE            COMMAND       CREATED     STATUS     PORTS               NAMES
94cbf3fdd7ff  &lt;your_dockerhub  "nginx -g     5 seconds   Up 4       0.0.0.0:80-&gt;80/     wonderful_
              _user&gt;/nginx-    'daemon of…"  ago         (health:   tcp, :::80-&gt;80/tcp  hodgkin
              hello-world                                starting)                     </pre>			<p>As we can see, the container shows <strong class="source-inline">health: starting</strong>, which means the health check hasn’t been started yet, and we are waiting<a id="_idTextAnchor457"/> for the start time <span class="No-Break">to expire.</span></p>
			<p>Let’s wait a while and then try <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">ps</strong></span><span class="No-Break"> again:</span></p>
			<pre class="console">
$ docker ps
CONTAINER ID  IMAGE            COMMAND       CREATED     STATUS     PORTS               NAMES
94cbf3fdd7ff  &lt;your_dockerhub  "nginx -g     2 minutes   Up 2       0.0.0.0:80-&gt;80/     wonderful_
              _user&gt;/nginx-    'daemon of…"  ago         (healthy)  tcp, :::80-&gt;80/tcp  hodgkin
              hello-world                                                                      </pre>			<p>This time, it reports the container as healthy. So, our container is now more reliable, as anyone monitoring it will know what part of the application is healthy and what part <span class="No-Break">is not.</span></p>
			<p>This health check only reports on the container’s health status. It takes no action beyond that. You are responsible for periodically monitoring the containers and writing a script to action <span class="No-Break">unhealthy containers.</span></p>
			<p>One way to <a id="_idIndexMarker415"/>manage this would be to create a script that checks for unhealthy containers and restarts them. You can schedule such a script in your crontab. You can also create a long-running <strong class="source-inline">systemd</strong> script that continuously polls the container processes and checks for the <span class="No-Break">health status.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">While using <strong class="source-inline">HEALTHCHECK</strong> is a great option, you should avoid using it to run your containers on Kubernetes or a similar container orchestrator. You should make use of liveness and readiness probes instead. Similarly, you can define health checks on Docker Compose if you are using it, so use that instead of baking the health check into the <span class="No-Break">container image.</span></p>
			<p>Now, let’s go ahead and l<a id="_idTextAnchor458"/><a id="_idTextAnchor459"/>earn how to build and manage <span class="No-Break">Docker images.</span></p>
			<h1 id="_idParaDest-117">Build<a id="_idTextAnchor460"/>ing and <a id="_idTextAnchor461"/>managing Docker images</h1>
			<p>We built some Docker images in the previous section, so by now, you should know how to write Dockerfiles and create <a id="_idIndexMarker416"/>Docker images from them. We’ve also covered a few best practices regarding it, which, in summary, are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Always add the layers that do not change frequently first, followed by the layers that may change often. For example, install your packages and dependencies first and copy the source code later. Docker builds the Dockerfile from the part you change until the end, so if you change a line that comes later, Docker takes all the existing layers from the cache. Adding more frequently changing parts later in the build helps reduce the build time and will result in a faster <span class="No-Break">CI/CD experience.</span></li>
				<li>Combine multiple commands to create as few layers as possible. Avoid multiple consecutive <strong class="source-inline">RUN</strong> directives. Instead, combine them into a single RUN directive using the <strong class="source-inline">&amp;&amp;</strong> clauses. This will help reduce the overall <span class="No-Break">container footprint.</span></li>
				<li>Only add the required files within your container. Your container does not need the heavyweight package managers and the Go toolkit while running your containers if you have already compiled the code into a binary. We will discuss how to do this in detail in the <span class="No-Break">following sections.</span></li>
			</ul>
			<p>Docker images are<a id="_idIndexMarker417"/> traditionally built using a sequence of steps specified in the Dockerfile. But as we already know, Docker is DevOps-compliant and uses config management practices from the beginning. Most people build their code within the Dockerfile. Therefore, we will also need the programming language library in the build context. With a simple sequential Dockerfile, these programming language tools and libraries end up within the container image. These are known as s<a id="_idTextAnchor462"/><a id="_idTextAnchor463"/>ingle-stage builds, which we will <span class="No-Break">cove<a id="_idTextAnchor464"/>r next.</span></p>
			<h2 id="_idParaDest-118"><a id="_idTextAnchor465"/>Single-stage builds</h2>
			<p>Let’s containerize a simple Go <a id="_idIndexMarker418"/>application that prints <strong class="source-inline">Hello, World!</strong> on the screen. While I am using <strong class="bold">Golang</strong> in this <a id="_idIndexMarker419"/>application, this concept is applicable universally, irrespective of the <span class="No-Break">programming language.</span></p>
			<p>The respective<a id="_idIndexMarker420"/> files for this example are present in the <strong class="source-inline">ch4/go-hello-world/single-stage</strong> directory within this book’s <span class="No-Break">GitHub repository.</span></p>
			<p>Let’s look at the Go application file, <span class="No-Break"><strong class="source-inline">app.go</strong></span><span class="No-Break">, first:</span></p>
			<pre class="console">
package main
import "fmt"
func main() {
    fmt.Println("Hello, World!")
}</pre>			<p>The Dockerfile appears <span class="No-Break">as follows:</span></p>
			<pre class="console">
FROM golang:1.20.5
WORKDIR /tmp
COPY app.go .
RUN GOOS=linux go build -a -installsuffix cgo -o app . &amp;&amp; chmod +x ./app
CMD ["./app"]</pre>			<p>This is standard stuff. We take the <strong class="source-inline">golang:1.20.5</strong> base image, declare a <strong class="source-inline">WORKDIR</strong> <strong class="source-inline">/tmp</strong>, copy <strong class="source-inline">app.go</strong> from the host filesystem to the container, and build the Go application to generate a binary. Finally, we use the <strong class="source-inline">CMD</strong> directive with the generated binary to be executed when we run <span class="No-Break">the container.</span></p>
			<p>Let’s build <span class="No-Break">the Dockerfile:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/go-hello-world:single_stage .
[+] Building 10.3s (9/9) FINISHED
 =&gt; [internal] load build definition from Dockerfile 0.0s
 =&gt; =&gt; transferring dockerfile: 189B 0.0s
 =&gt; [internal] load .dockerignore 0.0s
 =&gt; =&gt; transferring context: 2B 0.0s
 =&gt; [internal] load metadata for docker.io/library/golang:1.20.5 0.6s
 =&gt; [1/4] FROM docker.io/library/golang:1.20.5@sha256:4b1fc02d… 0.0s
 =&gt; [internal] load build context 0.0s
 =&gt; =&gt; transferring context: 27B 0.0s
 =&gt; [2/4] WORKDIR /tmp 0.0s
 =&gt; [3/4] COPY app.go . 0.0s
 =&gt; [4/4] RUN GO111MODULE=off GOOS=linux go build -a -installsuffix cgo -o app .  &amp;&amp; chmod 
+x ./app 9.3s
 =&gt; exporting to image 0.3s
 =&gt; =&gt; exporting layers 0.3s
 =&gt; =&gt; writing image sha256:3fd3d261… 0.0s
 =&gt; =&gt; naming to docker.io/&lt;your_dockerhub_user&gt;/go-hello-world:single_stage</pre>			<p>Now, let’s run the Docker image and see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker run &lt;your_dockerhub_user&gt;/go-hello-world:single_stage
Hello, World!</pre>			<p>We get the expected <a id="_idIndexMarker421"/>response back. Now, let’s run the following command to list <span class="No-Break">the image:</span></p>
			<pre class="console">
$ docker images
REPOSITORY              TAG           IMAGE ID      CREATED        SIZE
&lt;your_dockerhub_user&gt;
/go-hello-world         single_stage  3fd3d26111a1  3 minutes ago  803MB</pre>			<p>This image is huge! It takes 803 MB to print <strong class="source-inline">Hello, World!</strong> on the screen. This is not the most efficient way of building <span class="No-Break">Docker images.</span></p>
			<p>Before we look at the solution, let’s understand why the image is so bloated in the first place. We use the Golang base image, which contains the entire Go toolkit and generates a simple binary. We do not need the complete Go toolkit for this application to run; it can efficiently run in an Alpine <span class="No-Break">Linux image.</span></p>
			<p>Docker<a id="_idIndexMarker422"/> solves this problem by providing multi-stage builds. You can split your build into stages where you can build your code in one stage and then, in the second stage, export the built code to another context that begins with a different base image that is much lighter and only contains those files and components that we need to run the co<a id="_idTextAnchor466"/><a id="_idTextAnchor467"/>de. We’ll have a look at this in<a id="_idTextAnchor468"/> the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor469"/>Multi-stage builds</h2>
			<p>Let’s modify the Dockerfile <a id="_idIndexMarker423"/>according to the multi-stage build process and see what <span class="No-Break">we get.</span></p>
			<p>The respective files for this example are present in the <strong class="source-inline">ch4/go-hello-world/multi-stage</strong> directory within this book’s <span class="No-Break">GitHub repository.</span></p>
			<p>The following is <span class="No-Break">the Dockerfile:</span></p>
			<pre class="source-code">
FROM golang:1.20.5 AS build
WORKDIR /tmp
COPY app.go .
RUN GO111MODULE=off GOOS=linux go build -a -installsuffix cgo -o app . &amp;&amp; chmod +x ./app
FROM alpine:3.18.0
WORKDIR /tmp
COPY <a id="_idTextAnchor470"/>--from=build /tmp/app .
CMD ["./app"]</pre>			<p>The Dockerfile contains two <strong class="source-inline">FROM</strong> directives: <strong class="source-inline">FROM golang:1.20.5 AS build</strong> and <strong class="source-inline">FROM alpine:3.18.0</strong>. The first <strong class="source-inline">FROM</strong> directive also includes an <strong class="source-inline">AS</strong> directive that declares the stage and names it <strong class="source-inline">build</strong>. Anything we do after this <strong class="source-inline">FROM</strong> directive can be accessed using the <strong class="source-inline">build</strong> term until we encounter another <strong class="source-inline">FROM</strong> directive, which would form the second stage. Since the second stage is the one we want to run our image from, we are not using an <span class="No-Break"><strong class="source-inline">AS</strong></span><span class="No-Break"> directive.</span></p>
			<p>In the first stage, we build our Golang code to generate the binary using the <strong class="source-inline">golang</strong> <span class="No-Break">base image.</span></p>
			<p>In the second stage, we use the Alpine base image and copy the <strong class="source-inline">/tmp/app</strong> file from the build stage into our current stage. This is the only file we need to run in the container. The rest were only required to build and bloat our container <span class="No-Break">during runtime.</span></p>
			<p>Let’s build the image <a id="_idIndexMarker424"/>and see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/go-hello-world:multi_stage
[+] Building 12.9s (13/13) FINISHED
 =&gt; [internal] load build definition from Dockerfile 0.0s
 =&gt; =&gt; transferring dockerfile: 259B 0.0s
 =&gt; [internal] load .dockerignore 0.0s
 =&gt; =&gt; transferring context: 2B 0.0s
 =&gt; [internal] load metadata for docker.io/library/alpine:3.18.0 2.0s
 =&gt; [internal] load metadata for docker.io/library/golang:1.20.5 1.3s
 =&gt; [build 1/4] FROM docker.io/library/golang:1.20.5@sha256:4b1fc02d… 0.0s
 =&gt; [stage-1 1/3] FROM docker.io/library/alpine:3.18.0@sha256:02bb6f42… 0.1s
 =&gt; =&gt; resolve docker.io/library/alpine:3.18.0@sha256:02bb6f42… 0.0s
 =&gt; =&gt; sha256:c0669ef3… 528B / 528B 0.0s
 =&gt; =&gt; sha256:5e2b554c… 1.47kB / 1.47kB 0.0s
 =&gt; =&gt; sha256:02bb6f42… 1.64kB / 1.64kB 0.0s
 =&gt; CACHED [build 2/4] WORKDIR /tmp 0.0s
 =&gt; [internal] load build context 0.0s
 =&gt; =&gt; transferring context: 108B 0.0s
 =&gt; [build 3/4] COPY app.go . 0.0s
 =&gt; [build 4/4] RUN GO111MODULE=off GOOS=linux go build -a -installsuffix cgo -o app . &amp;&amp; 
chmod +x ./app 10.3s
 =&gt; [stage-1 2/3] WORKDIR /tmp 0.1s
=&gt; [stage-1 3/3] COPY --from=build /tmp/app . 0.3s
 =&gt; exporting to image 0.1s
 =&gt; =&gt; exporting layers 0.1s
 =&gt; =&gt; writing image sha256:e4b793b3… 0.0s
 =&gt; =&gt; naming to docker.io/&lt;your_<a id="_idTextAnchor471"/>dockerhub_user&gt;/go-hello-world:multi_stage</pre>			<p>Now, let’s run <span class="No-Break">the container:</span></p>
			<pre class="console">
$ docker run &lt;your_dockerhub_user&gt;/go-hello-world:multi_stage .
Hello, World!</pre>			<p>We get the same<a id="_idIndexMarker425"/> output, but this time with a minimal footprint. Let’s look at the image to <span class="No-Break">confirm this:</span></p>
			<pre class="console">
$ docker images
REPOSITORY              TAG          IMAGE ID      CREATED        SIZE
&lt;your_dockerhub_user&gt;
/go-hello-world         multi_stage  e4b793b39a8e  5 minutes ago  9.17MB</pre>			<p>This one occupies just 9.17 MB instead of the huge 803 MB. This is a massive improvement! We have reduced the image size by almost <span class="No-Break">100 times.</span></p>
			<p>That is how we increase <a id="_idIndexMarker426"/>efficiency within our container image. Building efficient images is the key to running production-ready containers, and most professional images you find on Docker Hub use multi-stage builds to create <span class="No-Break">efficient images.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Use multi-stage builds where possible to include minimal content within your image. Consider using an Alpine base image <span class="No-Break">if possible.</span></p>
			<p>In the next section, we will look at managing <a id="_idTextAnchor472"/>images within Docker, some best pra<a id="_idTextAnchor473"/><a id="_idTextAnchor474"/>ctices, and some of the most fre<a id="_idTextAnchor475"/>quently <span class="No-Break">used commands.</span></p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor476"/>Managing Docker images</h2>
			<p>In modern DevOps practices, Docker images<a id="_idIndexMarker427"/> are primarily built either on a developer machine or a CI/CD pipeline. The images are stored in a container registry and then deployed to multiple staging environments and production machines. They might run Docker or a container orchestrator, such as Kubernetes, on top <span class="No-Break">of them.</span></p>
			<p>To efficiently use images, we must understand how to <span class="No-Break">tag them.</span></p>
			<p>Primarily, Docker <a id="_idIndexMarker428"/>pulls the image once when you do a Docker run. This means that once an image with a particular version is on the machine, Docker will not attempt to pull it on every run unless you explicitly <span class="No-Break">pull it.</span></p>
			<p>To pull the image explicitly, you can use the <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">pull</strong></span><span class="No-Break"> command:</span></p>
			<pre class="console">
$ docker pull nginx
Using default tag: latest
latest: Pulling from library/nginx
f03b40093957: Pull complete
eed12bbd6494: Pull complete
fa7eb8c8eee8: Pull complete
7ff3b2b12318: Pull complete
0f67c7de5f2c: Pull complete
831f51541d38: Pull complete
Digest: sha256:af296b18…
Status: Downloaded newer image for nginx:latest
docker.io/library/nginx:latest</pre>			<p>Now, if we attempt to launch a container using this image, it will instantly launch the container without pulling <span class="No-Break">the image:</span></p>
			<pre class="console">
$ docker run nginx
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform 
configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
…
2023/06/10 08:09:07 [notice] 1#1: start worker processes
2023/06/10 08:09:07 [notice] 1#1: start worker process 29
2023/06/10 08:09:07 [notice] 1#1: start worker process 30</pre>			<p>So, using the<a id="_idIndexMarker429"/> latest tag on an image is a bad idea, and the best practice is to use semantic versions as your tag. There are two primary reasons <span class="No-Break">for this:</span></p>
			<ul>
				<li>If you build the latest image every time, orchestrators such as Docker Compose and Kubernetes will assume the image is already on your machine and will not pull your image by default. Using an image pull policy such as <strong class="source-inline">Always</strong> on Kubernetes or a script to pull the image is a waste of network bandwidth. It is also important to note that Docker Hub limits the number of pulls you can make on open source images, so you must limit your pulls to only <span class="No-Break">when necessary.</span></li>
				<li>Docker tags allow you to roll out or roll back your container deployment quickly. If you always use the latest tag, the new build overrides the old one, so there is no way you can roll back a faulty container to the last known good version. Using versioned images in production is also a good idea to ensure your container’s stability. If, for some reason, you lose the local image and decide to rerun your container, you may not get the same version of the software you were already running, as the latest tag changes frequently. So, it’s best to use a particular container version in production <span class="No-Break">for stability.</span></li>
			</ul>
			<p>Images comprise multiple layers, and most of the time, there is a relationship between various versions of containers that run on your server. With time, new versions of images roll out in your production environment, so removing the old images by doing some housekeeping is best. This will reclaim some valuable space the container images occupy, resulting in a <span class="No-Break">cleaner filesystem.</span></p>
			<p>To remove a particular image, you can use the <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">rmi</strong></span><span class="No-Break"> command:</span></p>
			<pre class="console">
$ docker rmi nginx
Error response from daemon: conflict: unable to remove repository reference "nginx" (must 
force) - container d5c84356116f is using its referenced image f9c14fe76d50</pre>			<p>Oh! We get an error, but why? It’s because we have a container running and using <span class="No-Break">this image.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">You cannot remove images currently used by a <span class="No-Break">running container.</span></p>
			<p>First, you will <a id="_idIndexMarker430"/>have to stop and remove the container. Then, you can remove the image using the preceding command. If you want to do everything at once, you can force removal by using the <strong class="source-inline">-f</strong> flag, which will stop the container, remove it, and then remove the image. So, unless you know what you are doing, do not use the <strong class="source-inline">-</strong><span class="No-Break"><strong class="source-inline">f</strong></span><span class="No-Break"> flag:</span></p>
			<pre class="console">
$ docker rmi -f nginx
Untagged: nginx:latest
Untagged: nginx@sha256:af296b18…
Deleted: sha256:f9c14fe7…</pre>			<p>We built our container many times, but wha<a id="_idTextAnchor477"/>t should we do if we need to push it to Docker Hub or other registries? But before we do that, we will have to authenticate it with Docker Hub using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker login</pre>			<p>Now, you can push the image to Docker Hub using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker push &lt;your_dockerhub_user&gt;/nginx-hello-world:latest
The push refers to repository [docker.io/&lt;your_dockerhub_user&gt;/nginx-hello-world]
2b7de406bdcd: Pushed
5f70bf18a086: Pushed
845348333310: Pushed
96a9e6a097c6: Pushed
548a79621a42: Mounted from library/ubuntu
latest: digest: sha256:11ec56f0… size: 1366</pre>			<p>This has pushed <a id="_idIndexMarker431"/>four layers and mounted the rest from Ubuntu. We used Ubuntu as the base image, which is already available on <span class="No-Break">Docker Hub.</span></p>
			<p>If you have multiple tags for the image and you want to push all of them, then you can use the <strong class="source-inline">-a</strong> or <strong class="source-inline">--all-tags</strong> option in the <strong class="source-inline">push</strong> command. This will push all the tags for that <span class="No-Break">particular image:</span></p>
			<pre class="console">
$ docker push -a &lt;your_dockerhub_user&gt;/go-hello-world
The push refers to repository [docker.io/&lt;your_dockerhub_user&gt;/go-hello-world]
9d61dbd763ce: Pushed
5f70bf18a086: Mounted from &lt;your_dockerhub_user&gt;/nginx-hello-world
bb01bd7e32b5: Mounted from library/alpine
multi_stage: digest: sha256:9e1067ca… size: 945
445ef31efc24: Pushed
d810ccdfdc04: Pushed
5f70bf18a086: Layer already exists
70ef08c04fa6: Mounted from library/golang
41cf9ea1d6fd: Mounted from library/golang
d4ebbc3dd11f: Mounted from library/golang
b4b4f5c5ff9f: Mounted from library/golang
b0df24a95c80: Mounted from library/golang
974e52a24adf: Mounted from library/golang
s<a id="_idTextAnchor478"/>ingle_stage: digest: sha256:08b5e52b… size: 2209</pre>			<p>When your build fails for some reason and you make changes to your Dockerfile, it’s possible that the old images’ layers will remain dangling. Therefore, it is best practice to prune the dangling <a id="_idIndexMarker432"/>images at regular intervals. You can use <strong class="source-inline">docker images prune</strong> <span class="No-Break">for this:</span></p>
			<pre class="console">
$ docker images prune
REPOSITORY  TAG  IMAGE ID  CREATED  SIZE</pre>			<p>In the next section, we’ll look at another way t<a id="_idTextAnchor479"/><a id="_idTextAnchor480"/>o improve Docker image efficiency: flatten<a id="_idTextAnchor481"/>ing <span class="No-Break">Docker images.</span></p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor482"/>Flattening Docker images</h2>
			<p>Docker inherently uses<a id="_idIndexMarker433"/> a layered filesystem, and we have already discussed why it is necessary and how it is beneficial in depth. However, in some particular use cases, Docker practitioners have observed that a Docker image with fewer layers performs better. You can reduce layers in an image by flattening it. However, it is still not a best practice, and you need to do this only if you see a performance improvement, as this would result in a <span class="No-Break">filesystem overhead.</span></p>
			<p>To flatten a Docker image, follow <span class="No-Break">these steps:</span></p>
			<ol>
				<li>Run a Docker container with the <span class="No-Break">usual image.</span></li>
				<li>Do a <strong class="source-inline">docker export</strong> of the running container to a <strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">tar</strong></span><span class="No-Break"> file.</span></li>
				<li>Do a <strong class="source-inline">docker import</strong> of the <strong class="source-inline">.tar</strong> file into <span class="No-Break">another image.</span></li>
			</ol>
			<p>Let’s use the <strong class="source-inline">nginx-hello-world</strong> image to flatten it and export it to another image; that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">&lt;your_dockerhub_user&gt;/nginx-hello-world:flat</strong></span><span class="No-Break">.</span></p>
			<p>Before we <a id="_idIndexMarker434"/>move on, let’s get the history of the <span class="No-Break">latest image:</span></p>
			<pre class="console">
$ docker history &lt;your_dockerhub_user&gt;/nginx-hello-world:latest
IMAGE          CREATED      CREATED BY                SIZE            COMMENT
bba3123dde01   2 hours ago  HEALTHCHECK &amp;
                            {["CMD-SHELL" 
                            "curl -f localhos…        0B              buildkit.dockerfile.v0
&lt;missing&gt;      2 hours ago  STOPSIGNAL                0B
                            SIGTERM                   0B              buildkit.dockerfile.v0
&lt;missing&gt;      2 hours ago  CMD ["nginx"  
                            "-g" "daemon off;"]       0B              buildkit.dockerfile.v0
&lt;missing&gt;      2 hours ago  EXPOSE map[80/
                            tcp:{}]                   0B              buildkit.dockerfile.v0
&lt;missing&gt;      2 hours ago  ADD index.html ./ # 
                            buildkit                  44B             buildkit.dockerfile.v0
&lt;missing&gt;      2 hours ago  WORKDIR /var/www/
                            html/                     0B              buildkit.dockerfile.v0
&lt;missing&gt;      2 hours ago  RUN /bin/sh -c apt 
                            update &amp;&amp; apt             57.2MB          buildkit.dockerfile.v0
                            install -y…
&lt;missing&gt;      2 hours ago  RUN /bin/sh -c apt 
                            update &amp;&amp; apt             59.8MB          buildkit.dockerfile.v0
                            install -y…
&lt;missing&gt;      10 days ago  /bin/sh -c #(nop)         0B
                            CMD ["/bin/bash"]
&lt;missing&gt;      10 days ago  /bin/sh -c #(nop) ADD     63.2MB
                            file:3c74e7e08cbf9a876…
&lt;missing&gt;      10 days ago  /bin/sh -c #(nop)  LABEL  0B
                            org.opencontainers.…
&lt;missing&gt;      10 days ago  /bin/sh -c #(nop)  LABEL  0B
                            org.opencontainers.…
&lt;missing&gt;      10 days ago  /bin/sh -c #(nop)  ARG    0B
                            LAUNCHPAD_BUILD_ARCH
&lt;missing&gt;      10 days ago  /bi<a id="_idTextAnchor483"/>n/sh -c #(nop)         0B
                            ARG RELEASE         </pre>			<p>Now, let’s run a <a id="_idIndexMarker435"/>Docker image with the <span class="No-Break">latest image:</span></p>
			<pre class="console">
$ docker run -d --name nginx &lt;your_dockerhub_user&gt;/nginx-hello-world:latest
e2d0c4b884556a353817aada13f0c91ecfeb01f5940e91746f168b…</pre>			<p>Next, let’s take an export out of the <span class="No-Break">running container:</span></p>
			<pre class="console">
$ docker export nginx &gt; nginx-hello-world-flat.tar</pre>			<p>Import <strong class="source-inline">nginx-hello-world-flat.tar</strong> to a new image; that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">&lt;your_dockerhub_user&gt;/nginx-hello-world:flat</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
$ cat nginx-hello-world-flat.tar |  \
docker import - &lt;your_dockerhub_user&gt;/nginx-hello-world:flat 
sha256:57bf5a9ada46191ae1aa16bcf837a4a80e8a19d0bcb9fc…</pre>			<p>Now, let’s list the<a id="_idIndexMarker436"/> images and see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker images
REPOSITORY              TAG     IMAGE ID      CREATED     SIZE
&lt;your_dockerhub_user&gt;/  flat    57bf5a9ada46  34 seconds  177MB
nginx-hello-world                             ago
&lt;your_dockerhub_user&gt;/  latest  bba3123dde01  2 hours 
nginx-hello-world                             ago         180MB</pre>			<p>Here, we can see that the flat image is present and that it occupies less space than the latest image. If we view its history, we should see just a <span class="No-Break">single layer:</span></p>
			<pre class="console">
$ docker history &lt;your_dockerhub_user&gt;/nginx-hello-world:flat
IMAGE         CREATED             CREATED BY  SIZE   COMMEN<a id="_idTextAnchor484"/>T
57bf5a9ada46  About a minute ago              177MB  Imported from -</pre>			<p>It has flattened the image. But is it a best practice to flatten Docker images? Well, it depends. Let’s <a id="_idIndexMarker437"/>understand when and how to flatten Docker images and what you <span class="No-Break">should consider:</span></p>
			<ul>
				<li>Are several applications using a similar base image? If that is the case, then flattening images will only increase the disk footprint, as you won’t be able to take advantage of a <span class="No-Break">layered filesystem.</span></li>
				<li>Consider alternatives to flattening images using a small base image, such <span class="No-Break">as Alpine.</span></li>
				<li>Multi-stage builds are helpful for most complied languages and can reduce your image’s <span class="No-Break">size considerably.</span></li>
				<li>You can also slim down images by using as few layers as possible by combining multiple steps into a single <span class="No-Break"><strong class="source-inline">RUN</strong></span><span class="No-Break"> directive.</span></li>
				<li>Consider whether the benefits of flattening the image outweigh the disadvantages, whether you'll get considerable performance improvements, and whether performance is critical for your <span class="No-Break">application needs.</span></li>
			</ul>
			<p>These<a id="_idIndexMarker438"/> considerations will help you understand your container image footprint and help you manage container images. Remember that although reducing the image’s size is ideal, flattening it should be a <span class="No-Break">last resort.</span></p>
			<p>So far, all the images we’ve used have been derived from a Linux distribution and alwa<a id="_idTextAnchor485"/>ys used a distro as their base image. You can also run a container without using a Linux distro as the base image to <a id="_idTextAnchor486"/><a id="_idTextAnchor487"/>make it more secure. We’ll have a look at how in the <span class="No-Break">nex<a id="_idTextAnchor488"/>t section.</span></p>
			<h1 id="_idParaDest-122">Optimizing containers with dist<a id="_idTextAnchor489"/>roless images</h1>
			<p>Distroless<a id="_idIndexMarker439"/> containers are one of the latest trends in the container world. They are promising because they consider all the aspects of optimizing containers for the Enterprise environment. You should consider three important th<a id="_idTextAnchor490"/><a id="_idTextAnchor491"/>ings while optimizing <a id="_idTextAnchor492"/>containers – performance, security, <span class="No-Break">and cost.</span></p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor493"/>Performance</h2>
			<p>You don’t make <a id="_idIndexMarker440"/>containers out of thin air. You must download images from your container registry and then run the container out of the image. Each step uses network and disk I/O. The bigger the image, the more resources it consumes and the less performance you get f<a id="_idTextAnchor494"/><a id="_idTextAnchor495"/>rom it. Therefore, a smal<a id="_idTextAnchor496"/>ler Docker image naturally <span class="No-Break">performs better.</span></p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor497"/>Security</h2>
			<p>Security is one of the most<a id="_idIndexMarker441"/> important aspects of the current IT landscape. Companies usually focus on this aspect and invest a lot of money and time. Since containers are a relatively new technology, they are vulnerable to hacking, so appropriately securing your containers is important. Standard Linux distributions have a lot of stuff that can allow hackers to access more than they could have if you secured your container properly. Therefo<a id="_idTextAnchor498"/><a id="_idTextAnchor499"/>re, you must e<a id="_idTextAnchor500"/>nsure you only have what you need within <span class="No-Break">the container.</span></p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor501"/>Cost</h2>
			<p>A smaller image also <a id="_idIndexMarker442"/>results in a lower cost. The lower your container footprint, the more containers you can pack within a machine, so there are fewer machines you would need to run your applications. This means you save a lot of money that would accumulate <span class="No-Break">over time.</span></p>
			<p>As a modern DevOps engineer, you must ensure your images are optimized for all these aspects. Distroless images help take care of all of them. Therefore, let’s understand what distroless images are and how to <span class="No-Break">use them.</span></p>
			<p>Distroless images are the most minimal images and only contain your application, dependencies, and the necessary files for your container process to run. Most of the time, you do not need package managers such as <strong class="source-inline">apt</strong> or a shell such as <strong class="source-inline">bash</strong>. Not having a shell has its advantages. For one, it will help you avoid any outside party gaining access to your container while it is running. Your container has a small attack surface and won’t have many <span class="No-Break">security vulnerabilities.</span></p>
			<p>Google provides dist<a id="_idTextAnchor502"/>roless images in their official GCR registry, available on their GitHub page at <a href="https://github.com/GoogleContainerTools/distroless">https://github.com/GoogleContainerTools/distroless</a>. Let’s get hands-on and see what we can do <span class="No-Break">with them.</span></p>
			<p>The required resources<a id="_idIndexMarker443"/> for this exercise are in <strong class="source-inline">ch4/go-hello-world/distroless</strong> in this book’s <span class="No-Break">GitHub repository.</span></p>
			<p>Let’s start by creating <span class="No-Break">a Dockerfile:</span></p>
			<pre class="console">
FROM golang:1.20.5 AS build
WORKDIR /tmp
COPY app.go .
RUN GO111MODULE=off GOOS=linux go build -a -installsuffix cgo -o app . &amp;&amp; chmod +x ./app
FROM gcr.io/distroless/base
WORKDIR /tmp
COPY --from=build /tmp/app .
CMD ["./app"]</pre>			<p>This Dockerfile is similar to the multi-stage build Dockerfile for the <strong class="source-inline">go-hello-world</strong> container, but instead of using <strong class="source-inline">alpine</strong>, it uses <strong class="source-inline">gcr.io/distroless/base</strong> as the base image. This image contains a minimalistic Linux glibc-enabled system and lacks a package manager or a shell. You can use it to run binar<a id="_idTextAnchor503"/>ies compiled in a language such as Go, Rust, <span class="No-Break">or D.</span></p>
			<p>So, let’s build this first using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/go-hello-world:distroless .
[+] Building 7.6s (14/14) FINISHED
 =&gt; [internal] load build definition from Dockerfile 0.0s
 =&gt; =&gt; transferring dockerfile: 268B 0.0s
 =&gt; [internal] load .dockerignore 0.0s
 =&gt; =&gt; transferring context: 2B 0.0s
 =&gt; [internal] load metadata for gcr.io/distroless/base:latest 3.1s
 =&gt; [internal] load metadata for docker.io/library/golang:1.20.5 1.4s
 =&gt; [auth] library/golang:pull token for registry-1.docker.io 0.0s
 =&gt; [stage-1 1/3] FROM gcr.io/distroless/base@
sha256:73deaaf6a207c1a33850257ba74e0f196bc418636cada9943a03d7abea980d6d 3.2s
 =&gt; [build 1/4] FROM docker.io/library/golang:1.20.5@sha256:4b1fc02d 0.0s
 =&gt; [internal] load build context 0.0s
 =&gt; =&gt; transferring context: 108B 0.0s
 =&gt; CACHED [build 2/4] WORKDIR /tmp 0.0s
 =&gt; CACHED [build 3/4] COPY app.go . 0.0s
 =&gt; CACHED [build 4/4] RUN GO111MODULE=off GOOS=linux go build -a -installsuffix cgo -o 
app . &amp;&amp; chmod +x ./app 0.0s
 =&gt; [stage-1 2/3] WORKDIR /tmp 0.9s
 =&gt; [stage-1 3/3] COPY --from=build /tmp/app . 0.3s
 =&gt; exporting to image 0.1s
 =&gt; =&gt; exporting layers 0.1s
 =&gt; =&gt; writing image sha256:51ced401 0.0s
 =&gt; =&gt; naming<a id="_idTextAnchor504"/> to docker.io/&lt;your_dockerhub_user&gt;/go-hello-world:distroless</pre>			<p>Now, let’s run this image and see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker run &lt;your_dockerhub_user&gt;/go-hello-world:distroless
Hello, World!</pre>			<p>It works! Let’s look at the size of <span class="No-Break">the image:</span></p>
			<pre class="console">
$ docker images
REPOSITORY                            TAG         MAGE ID       CREATED        SIZE
&lt;your_dockerhub_user&gt;/go-hello-world  distroless  51ced401d7bf  6 minutes ago  22.3MB</pre>			<p>It’s just 22.3 MB. Yes, it’s <a id="_idIndexMarker444"/>a bit more than the Alpine image, but it does not contain a shell, so it is more secure from that point of view. Also, there are distroless images available for interpreted programming languages, such as Python and Java, that you can<a id="_idTextAnchor505"/> use instead of the bloated image containing <span class="No-Break">the toolkits</span></p>
			<p>Docker images are stored in Docker registries, and we have all been using Docker Hub for a while. In the next section, we’ll u<a id="_idTextAnchor506"/><a id="_idTextAnchor507"/>nderstand what they are and what our options are for s<a id="_idTextAnchor508"/>toring <span class="No-Break">our images.</span></p>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor509"/>Understanding Docker registries</h1>
			<p>A <strong class="bold">Docker registry</strong> is a<a id="_idIndexMarker445"/> stateless, highly scalable server-side application that stores and lets you distribute Docker images. The registry is open source under the permissive <strong class="bold">Apache license</strong>. It is a <a id="_idIndexMarker446"/>storage and distribution system where all your Docker servers can connect and upload and download images as and when needed. It acts as a distribution site for <span class="No-Break">your images.</span></p>
			<p>A Docker registry contains several Docker repositories. A Docker repository holds several versions of a specific image. For example, all the versions of the <strong class="source-inline">nginx</strong> image are stored within a single repository within Docker Hub <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">nginx</strong></span><span class="No-Break">.</span></p>
			<p>By default, Docker interacts with its public Docker registry instance, called Docker Hub, which helps you distribute your images to the broader open <span class="No-Break">source community.</span></p>
			<p>Not all images can be public and open source, and many proprietary activities are ongoing. Docker allows y<a id="_idTextAnchor510"/>ou to use a private Docker registry for a scenario you can host within your infrastructure<a id="_idIndexMarker447"/> called <strong class="bold">Docker Trusted Registry</strong>. Several online options are available, including using a SaaS service, such as GCR, or creating private repositories at <span class="No-Break">Docker Hub.</span></p>
			<p>While the SaaS option is readily a<a id="_idTextAnchor511"/><a id="_idTextAnchor512"/>vailable and intuitive, let’s consider host<a id="_idTextAnchor513"/>ing our private <span class="No-Break">Docker registry.</span></p>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor514"/>Hosting your private Docker registry</h2>
			<p>Docker provides an image that<a id="_idIndexMarker448"/> you can run on any server that has Docker installed. Once the container is up and running, you can use that as the Docker registry. Let’s have <span class="No-Break">a look:</span></p>
			<pre class="console">
$ docker run -d -p 80:5000 --restart=always --name registry registry:2
Unable to find image 'registry:2' locally
2: Pulling from library/registry
8a49fdb3b6a5: Already exists
58116d8bf569: Pull complete
4cb4a93be51c: Pull complete
cbdeff65a266: Pull complete
6b102b34ed3d: Pull complete
Digest: sha256:20d08472…
Status: Downloaded newer image for registry:<a id="_idTextAnchor515"/>2
ae4c4ec9fc7b17733694160b5b3b053bd1a41475dc4282f3eccaa10…</pre>			<p>Since we know <a id="_idIndexMarker449"/>that the registry is running on localhost and listening on port <strong class="source-inline">80</strong>, let’s try to push an image to this registry. First, let’s tag the image to specify <strong class="source-inline">localhost</strong> as the registry. We will add a registry location at the beginning of the Docker tag so that Docker knows where to push the image. We already know that the structure of a Docker tag is <strong class="source-inline">&lt;registry_url&gt;/&lt;user&gt;/&lt;image_name&gt;:&lt;image_version&gt;</strong>. We will use the <strong class="source-inline">docker tag</strong> command to give another name to an existing image, as shown in the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker tag your_dockerhub_user&gt;/nginx-hello-world:latest \ 
localhost/&lt;your_dockerhub_user&gt;/nginx-hello-world:latest</pre>			<p>Now, we can go ahead and push the image to the local <span class="No-Break">Docker registry:</span></p>
			<pre class="console">
$ docker push localhost/&lt;your_dockerhub_user&gt;/nginx-hello-world:latest
The push refers to repository [localhost/your_dockerhub_user/nginx-hello-world]
2b7de406bdcd: Pushed
5f70bf18a086: Pushed
845348333310: Pushed
96a9e6a097c6: Pushed
548a79621a42: Pushed
latest: digest: sha256<a id="_idTextAnchor516"/>:6ad07e74… size: 1366</pre>			<p>And that’s it! It is as simple <span class="No-Break">as that!</span></p>
			<p>There are <a id="_idIndexMarker450"/>other considerations as well since this is too simplistic. You will also have to mount volumes; otherwise, you will lose all the images when you restart the registry container. Also, there is no authentication in place, so anyone accessing this server can push or pull images, but we don’t desire this. Also, communication is insecure, and we want to encrypt the images <span class="No-Break">during transit.</span></p>
			<p>First, let’s create the local directories that we will mount to <span class="No-Break">the containers:</span></p>
			<pre class="console">
$ sudo mkdir -p /mnt/registry/certs
$ sudo mkdir -p /mnt/registry/auth
$ sudo chmod -R 777 /mnt/registry</pre>			<p>Now, let’s generate an <strong class="source-inline">htpasswd</strong> file for adding authentication to the registry. For this, we will run the <strong class="source-inline">htpasswd</strong> command from within a new Docker registry container to create a file on our <span class="No-Break">local directory:</span></p>
			<pre class="console">
$ docker run --entrypoint htpasswd registry:2.7.0 \
-Bbn user pass &gt; /mnt/registry/auth/htpasswd</pre>			<p>The next step is to <a id="_idIndexMarker451"/>generate some self-signed certificates for enabling TLS on the repository. Add your server <a id="_idIndexMarker452"/>name or IP when asked for a <strong class="bold">Fully Qualified Domain Name</strong> (<strong class="bold">FQDN</strong>). You can leave the other fields blank or add appropriate values <span class="No-Break">for them:</span></p>
			<pre class="console">
$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout \ 
/mnt/registry/certs/domain.key -x509 -days 365 -out /mnt/registry/certs/domain.crt </pre>			<p>Before we proceed further, let’s<a id="_idTextAnchor517"/> remove the <span class="No-Break">existing registry:</span></p>
			<pre class="console">
$ docker rm -f registry
registry</pre>			<p>Now, we are<a id="_idIndexMarker453"/> ready to launch our container with the <span class="No-Break">required configuration:</span></p>
			<pre class="console">
$ docker run -d -p 443:443 --restart=always \
--name registry \
  -v /mnt/registry/certs:/certs \
  -v /mnt/registry/auth:/auth \
  -v /mnt/registry/registry:/var/lib/registry \
  -e REGISTRY_HTTP_ADDR=0.0.0.0:443 \
  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \
  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \
  -e REGISTRY_AUTH=htpasswd \
  -e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \
  -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \
  registry:2
02bf92c9c4a6d1d9c9f4b75ba80e82834621b1570f5f7c4a74b215960</pre>			<p>The container is now up and running. Let’s use <strong class="source-inline">https</strong> this time, but before that, let’s <strong class="source-inline">docker login</strong> to the registry. Add the username and password you set while creating the <strong class="source-inline">htpasswd</strong> file (in this case, <strong class="source-inline">user</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">pass</strong></span><span class="No-Break">):</span></p>
			<pre class="console">
$ docker login https://localhost
Username: user
Password:
WARNING! Your password will be stored unencrypted in /root/
.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engin<a id="_idTextAnchor518"/>e/reference/commandline/login/
#credentials-store
Login Succeeded</pre>			<p>Since the<a id="_idIndexMarker454"/> login succeeded, we can go ahead and push our image to <span class="No-Break">the registry:</span></p>
			<pre class="console">
$ docker push localhost/&lt;your_dockerhub_user&gt;/nginx-hello-world
The push refers to repository [localhost/&lt;your_dockerhub_user&gt;/nginx-hello-world]
2b7de406bdcd: Pushed
5f70bf18a086: Pushed
845348333310: Pushed
96a9e6a097c6: Pushed
548a79621a42: Pushed
latest: digest: sha256:6ad07e7425331456a3b8ea118bce36c82af2<a id="_idTextAnchor519"/><a id="_idTextAnchor520"/>42ec14072d483b5dcaa3bd607e65 
size: 1366</pre>			<p>Thi<a id="_idTextAnchor521"/>s time, it works the way we want <span class="No-Break">it to.</span></p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor522"/>Other public registries</h2>
			<p>Apart from running your registry in a<a id="_idIndexMarker455"/> dedicated Docker server, other cloud and on-premises <span class="No-Break">options exist.</span></p>
			<p>Most public cloud providers offer paid online registries and container-hosting solutions that you can easily use while running in the cloud. Some of them are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Amazon Elastic Container Registry</strong> (<strong class="bold">ECR</strong>): This is a popular AWS offering you can use if your<a id="_idIndexMarker456"/> infrastructure runs on AWS. It is a highly available, highly performant, fully managed solution. It can host public and private registries, and you only pay for the storage you consume and the amount of data transferred to the internet. The best part is that it integrates wit<a id="_idTextAnchor523"/>h <span class="No-Break">AWS IAM.</span></li>
				<li><strong class="bold">Google Container Registry</strong> (<a id="_idTextAnchor524"/><strong class="bold">GCR</strong>): Backed by <strong class="bold">Google Cloud Storage </strong>(<strong class="bold">GCS</strong>), GCR is one of the best<a id="_idIndexMarker457"/> choices if you run your <a id="_idIndexMarker458"/>infrastructure on GCP. It hosts both public and private repositories, and you only pay for the storage <span class="No-Break">on GCS.</span></li>
				<li><strong class="bold">Azure Container Registry</strong> (<strong class="bold">ACR</strong>): This fully managed, geo-replicated cont<a id="_idTextAnchor525"/>ainer registry only supports<a id="_idIndexMarker459"/> a private registry. It is a good option if you are running your infrastructure on Azure. Besides storing container images, it also stores Helm charts and other arti<a id="_idTextAnchor526"/>facts that help you manage <span class="No-Break">your containers.</span></li>
				<li><strong class="bold">Oracle Cloud Infrastructure Registry</strong>: Oracle Cloud Infrastructure Registry is a highly available <a id="_idIndexMarker460"/>Oracle-managed container registry. It can host both public and <span class="No-Break">private repositories<a id="_idTextAnchor527"/>.</span></li>
				<li><strong class="bold">CoreOS Quay</strong>: This<a id="_idIndexMarker461"/> supports OAuth and LDAP authentication. It offers both (paid) private and (free) public repositories, automatic security scanning, and automated image builds via integration with GitLab, GitHub, <span class="No-Break">and </span><span class="No-Break"><a id="_idIndexMarker462"/></span><span class="No-Break">Bitbucket.</span></li>
			</ul>
			<p>If you don’t want to go with managed options in the cloud or run on-premises, you can also use distribution management software such as <em class="italic">Sonatype Nexus</em> or <em class="italic">JFrog Artifactory</em>. Both tools support Docker registries out of the box. You can create a Do<a id="_idTextAnchor528"/><a id="_idTextAnchor529"/>cker registry there using fancy UIs, and then use <strong class="source-inline">docker login</strong> to connect to <span class="No-Break">the registry.</span></p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor530"/>Summary</h1>
			<p>In this chapter, we have covered a lot of ground. At this point, you should understand Docker from a hands-on perspective. We started with Docker images, how to use a Dockerfile to build Docker images, the components and directives of the Dockerfile, and how to create efficient images by following some best practices. We also discussed flattening Docker images and improving container security using distroless images. Finally, we discussed Docker registries, how to run a private Docker registry on a Docker server, and how to use other turnkey solutions, such as Sonatype Nexus and <span class="No-Break">JFrog Artifactory.</span></p>
			<p>Here is a quick summary of some best practices for managing Docker containers effectively <span class="No-Break">and efficiently:</span></p>
			<ul>
				<li><strong class="bold">Use Official Images</strong>: Whenever possible, start with official Docker images from reputable sources such as Docker Hub. These images are well-maintained, regularly updated, and often come with better <span class="No-Break">security practices.</span></li>
				<li><strong class="bold">Minimize Containers</strong>: Follow the “one service per container” principle. Each container should have a single responsibility, which helps with maintainability <span class="No-Break">and scaling.</span></li>
				<li><strong class="bold">Optimize Container Sizes</strong>: Keep containers as lightweight as possible. Use Alpine Linux or other minimal base images and remove unnecessary files <span class="No-Break">and dependencies.</span></li>
				<li><strong class="bold">Use Environment Variables</strong>: Store configuration and sensitive data in environment variables rather than hardcoding it into the container. This enhances portability <span class="No-Break">and security.</span></li>
				<li><strong class="bold">Persistent Data</strong>: Store application data outside containers using Docker volumes or bind mounts. This ensures that data persists even if containers are replaced <span class="No-Break">or stopped.</span></li>
				<li><strong class="bold">Container Naming</strong>: Give containers meaningful and unique names. This helps with easy identification <span class="No-Break">and troubleshooting.</span></li>
				<li><strong class="bold">Resource Limits</strong>: Set resource limits (CPU and memory) for containers to prevent one misbehaving container from affecting others on the <span class="No-Break">same host.</span></li>
				<li><strong class="bold">Container Restart Policies</strong>: Define restart policies to determine how containers should behave when they exit or crash. Choose the appropriate policy based on your <span class="No-Break">application’s requirements.</span></li>
				<li><strong class="bold">Docker Compose</strong>: Use Docker Compose to define and manage multi-container applications. It simplifies the deployment and orchestration of <span class="No-Break">complex setups.</span></li>
				<li><strong class="bold">Network Isolation</strong>: Use Docker networks to isolate containers and control communication between them. This enhances security <span class="No-Break">and manageability.</span></li>
				<li><strong class="bold">Health Checks</strong>: Implement health checks in your containers to ensure they run as expected. This helps with automated monitoring <span class="No-Break">and recovery.</span></li>
				<li><strong class="bold">Container Logs</strong>: Redirect container logs to standard output (<strong class="source-inline">stdout</strong>) and standard error (<strong class="source-inline">stderr</strong>) streams. This makes it easier to collect and analyze logs using Docker’s <span class="No-Break">logging mechanisms.</span></li>
				<li><strong class="bold">Security Best Practices</strong>: Keep containers up to date with security patches, avoid running containers as the root, and follow security best practices to <span class="No-Break">avoid vulnerabilities.</span></li>
				<li><strong class="bold">Version Control Dockerfiles</strong>: Store Dockerfiles in version control systems (e.g., Git) and regularly review and <span class="No-Break">update them.</span></li>
				<li><strong class="bold">Container Cleanup</strong>: Regularly remove unused containers, images, and volumes to free up disk space. Consider using tools such as Docker’s built-in <span class="No-Break">prune commands.</span></li>
				<li><strong class="bold">Orchestration Tools</strong>: Explore container orchestration tools such as Kubernetes or Docker Swarm for managing larger and more complex <span class="No-Break">container deployments.</span></li>
				<li><strong class="bold">Documentation</strong>: Maintain clear and up-to-date documentation for your containers and images, including how to run them, their required environment variables, and any other <span class="No-Break">configuration details.</span></li>
				<li><strong class="bold">Backup and Restore</strong>: Establish backup and restore processes for container data and configuration to recover them quickly in case <span class="No-Break">of failures.</span></li>
				<li><strong class="bold">Monitoring and Scaling</strong>: Implement monitoring and alerting for your containers to ensure they run smoothly. Use scaling mechanisms to handle the <span class="No-Break">increased load.</span></li>
			</ul>
			<p>By following these best practices, you can ensure that your Docker container environment is well-organized, secure, maintainable, <span class="No-Break">and s<a id="_idTextAnchor531"/><a id="_idTextAnchor532"/>calable.</span></p>
			<p>In the next chapter, we will delve into container orchestration <span class="No-Break">using Kubernetes.</span></p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor533"/>Questions</h1>
			<ol>
				<li>Docker images use a layered <span class="No-Break">model. </span><span class="No-Break">(True/False)</span></li>
				<li>You can delete an image from a server if a container using that image is already <span class="No-Break">running. </span><span class="No-Break">(True/False)</span></li>
				<li>How do you remove a running container from a server? (<span class="No-Break">Choose two)</span><p class="list-inset">A. <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">rm &lt;container_id&gt;</strong></span></p><p class="list-inset">B. <strong class="source-inline">docker rm -</strong><span class="No-Break"><strong class="source-inline">f &lt;container_id&gt;</strong></span></p><p class="list-inset">C. <strong class="source-inline">docker stop &lt;container_id&gt; &amp;&amp; docker </strong><span class="No-Break"><strong class="source-inline">rm &lt;container_id&gt;</strong></span></p><p class="list-inset">D. <strong class="source-inline">docker stop -</strong><span class="No-Break"><strong class="source-inline">f &lt;container_id&gt;</strong></span></p></li>
				<li>Which of the following options are container build best practices? (<span class="No-Break">Choose four)</span><p class="list-inset">A. Always add layers that don’t frequently change at the beginning of <span class="No-Break">the Dockerfile.</span></p><p class="list-inset">B. Combine multiple steps into a single directive to <span class="No-Break">reduce layers.</span></p><p class="list-inset">C. Only use the required files in the container to keep it lightweight and reduce the <span class="No-Break">attack surface.</span></p><p class="list-inset">D. Use semantic versioning in your Docker tags and avoid the <span class="No-Break">latest version.</span></p><p class="list-inset">E. Include package managers and a shell within the container, as this helps with troubleshooting a <span class="No-Break">running container.</span></p><p class="list-inset">F. Only use an <strong class="source-inline">apt update</strong> at the start of <span class="No-Break">your Dockerfile.</span></p></li>
				<li>You should always flatten Docker images to a single <span class="No-Break">layer</span><span class="No-Break">. (True/False)</span></li>
				<li>A distroless container contains a <span class="No-Break">shell</span><span class="No-Break">. (True/False)</span></li>
				<li>What are some of the ways to improve container efficiency? (<span class="No-Break">Choose four)</span><p class="list-inset">A. Try to use a smaller base image if possible, such <span class="No-Break">as Alpine.</span></p><p class="list-inset">B. Only use multi-stage builds to add the required libraries and dependencies to the container and omit heavyweight toolkits that are <span class="No-Break">not necessary.</span></p><p class="list-inset">C. Use distroless base images <span class="No-Break">where possible.</span></p><p class="list-inset">D. Flatten <span class="No-Break">Docker images.</span></p><p class="list-inset">E. Use single-stage builds to include package managers and a shell, as this will help in troubleshooting <span class="No-Break">in production.</span></p></li>
				<li>It is a best practice to prune Docker images from time to <span class="No-Break">time</span><span class="No-Break">. (True/False)</span></li>
				<li>Health checks should always be baked into your Docker <span class="No-Break">image. </span><span class="No-Break">(True/False)</span></li>
			</ol>
			<h1 id="_idParaDest-131"><a id="_idTextAnchor534"/>Answers</h1>
			<ol>
				<li value="1"><span class="No-Break">True</span></li>
				<li>False – you cannot delete an image that is being used by a <span class="No-Break">running container.</span></li>
				<li><span class="No-Break">B, C</span></li>
				<li>A, B, <span class="No-Break">C, D</span></li>
				<li>False – only flatten Docker images if you'll benefit from <span class="No-Break">better performance.</span></li>
				<li>False – distroless containers do not contain <span class="No-Break">a shell.</span></li>
				<li>A, B, <span class="No-Break">C, D</span></li>
				<li><span class="No-Break">True</span></li>
				<li>False – if you’re using Kubernetes or Docker Compose, use the liveness probes or define health checks with a YAML <span class="No-Break">file instead.</span></li>
			</ol>
		</div>
	</div>
</div>


<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer041" class="Content">
			<h1 id="_idParaDest-132" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor535"/>Part 2:Container Orchestration and Serverless</h1>
			<p>This part will build upon <em class="italic">Part 1</em> and introduce you to managing containers with container orchestration and serverless technologies. In this part, you will learn how to manage containers both on-premises and in the cloud using cutting-edge tools <span class="No-Break">and technologies.</span></p>
			<p>This part has the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B19877_05.xhtml#_idTextAnchor536"><em class="italic">Chapter 5</em></a>, <em class="italic">Container Orchestration with Kubernetes</em></li>
				<li><a href="B19877_06.xhtml#_idTextAnchor668"><em class="italic">Chapter 6</em></a>, <em class="italic">Managing Advanced Kubernetes Resources</em></li>
				<li><a href="B19877_07.xhtml#_idTextAnchor866"><em class="italic">Chapter 7</em></a>, <em class="italic">Containers as a Service (CaaS) and Serverless</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer042" class="Basic-Graphics-Frame">
			</div>
		</div>
	</div>
</div>
</body></html>