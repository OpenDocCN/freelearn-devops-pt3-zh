- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Getting the Ball Rolling with Kubernetes and the Top Three Cloud Platforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When starting your Kubernetes journey, the typical first step is to create a
    Kubernetes cluster to work with. The reason why is that if you, for example, start
    by creating a Kubernetes Manifest (more on this in later chapters), you’ll have
    nowhere to deploy the Manifest to because you don’t have a Kubernetes cluster.
    The other reality when it comes to Kubernetes is there’s a ton of cloud-native
    operations management – things such as monitoring a cluster, automating the deployment
    of a cluster, and scaling a cluster. Because of that, understanding cluster creation
    is a crucial step in your Kubernetes journey.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, you learned not only about why Kubernetes is important
    but also the backstory of why engineers want to use orchestration in today’s world.
    In this chapter, you’re going to hit the ground running by creating and managing
    your very own Kubernetes clusters in the three major clouds – Azure, **Amazon
    Web Services** (**AWS**), and **Google Cloud** **Platform** (**GCP**).
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll be able to fully create, deploy, manage,
    and automate Kubernetes clusters running in the three major clouds. The skills
    that you will pick up from this chapter will also translate across other Kubernetes
    cluster deployments. For example, you’ll be using Terraform to automate the Kubernetes
    cluster creation, and you can use Terraform to deploy Kubernetes clusters in other
    clouds and on-premises environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Kubernetes Service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS EKS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With each of the topics, you’ll learn how to properly run them in a production-level
    environment. Throughout the rest of the chapter, you’ll be working in depth with
    various amounts of hands-on-driven labs, creating resources automatically and
    manually.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the purpose of this chapter, you should already know how to navigate through
    each cloud portal and have a general understanding of how you can automate the
    creation of cloud infrastructure. Although it would be great to dive into those
    topics in this book, these topics are huge and there are whole books out there
    dedicated just to them. Because of that, you should know about automated workflows,
    Terraform, and the cloud prior to getting started.
  prefs: []
  type: TYPE_NORMAL
- en: 'To work inside the cloud, you will need the following, all of which you can
    sign up for and get free credit:'
  prefs: []
  type: TYPE_NORMAL
- en: An Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A GCP account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An infrastructure automation tool such as Terraform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for this chapter is in the GitHub repository or directory found here:
    [https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch2](https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch2).'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Kubernetes Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you’re using Microsoft Azure, you have a few options to choose from when
    using containers and Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Kubernetes** **Service** (**AKS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Container Instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Container** **Apps** (**ACA**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AKS is the primary way to run Kubernetes workloads inside Azure. You do not
    have to worry about managing the Control Plane or API Server and instead, simply
    handle deploying your apps, scaling, and managing or maintaining the cloud infrastructure.
    However, there is still maintenance and management that you need to do for worker
    nodes – for example, if you want to scale Kubernetes clusters, utilize a multi-cloud
    model, or implement some sort of hybrid-cloud model, you would be solely responsible
    for implementing that setup. AKS abstracts the need to worry about managing and
    scaling the Control Plane or API Server, but you’re responsible for everything
    else (scaling workloads, monitoring, and observability).
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: There’s a new service that recently went **Generally Available** (**GA**) at
    Microsoft Build 2022 called ACA. Although we won’t be going into detail about
    ACA in this book, you should know that it’s essentially *serverless Kubernetes*.
    It’s drastically different in comparison to AKS, so if you’re planning on using
    ACA, ensure that you learn about those tech spaces prior.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, you’re going to learn how to create an AKS cluster
    manually first. After that, you’ll take what you learned from a manual perspective
    and learn how to automate it with Terraform. Then, you’ll learn about scaling
    AKS clusters from a vertical-autoscaling perspective. Finally, you’ll wrap up
    with serverless Kubernetes. Let’s dive right in!
  prefs: []
  type: TYPE_NORMAL
- en: Creating an AKS cluster manually
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before managing an AKS cluster, you have to learn how to create one. In today’s
    world, you’ll most likely never do this process manually because of the need for
    every organization to strive toward an automated and repeatable mindset. However,
    because you cannot automate something without doing it manually first, you’ll
    learn how to do that in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the Azure portal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.1 – The Azure portal'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – The Azure portal
  prefs: []
  type: TYPE_NORMAL
- en: 'Search for `azure` `kubernetes services`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Searching for AKS'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – Searching for AKS
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Create** dropdown and choose the **Create a Kubernetes** **cluster**
    option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Creating an AKS cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – Creating an AKS cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose the options for your Kubernetes cluster, including the name of the cluster
    and your Azure resource group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Adding cluster details before its creation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Adding cluster details before its creation
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the **Primary node pool** section, you can choose what **Virtual Machine**
    (**VM**) size you want for your Kubernetes worker nodes, how many should be available,
    and whether or not you want to autoscale. One of the biggest powers behind cloud
    Kubernetes services such as AKS is autoscaling. In production, it’s recommended
    to autoscale when needed. However, you also have to understand that it comes with
    a cost, as extra VMs will be provisioned. Leave everything as the default for
    now and scroll down to the **Primary node** **pool** section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Specifying the worker node size, node count, and scale method'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – Specifying the worker node size, node count, and scale method
  prefs: []
  type: TYPE_NORMAL
- en: Once you have chosen your options, which in a dev environment could be one node,
    but will vary in production, click the blue **Review + create** button. Your AKS
    cluster is now created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you know how to create an AKS cluster manually, it’s time to learn
    how to create it with Terraform so you can ensure repeatable processes throughout
    your environment.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an AKS cluster with automation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many production-level cases, you’ll run the following Terraform code within
    a CI/CD pipeline to ensure repeatability. For the purpose of this section, you
    can run it locally. You’ll first see the `main.tf` configuration and then you’ll
    take a look at `variables.tf`.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s break down the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, there’s the Terraform provider itself. The `azurerm` Terraform provider
    is used to make API calls to Azure programmatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, there’s the `azurerm_kubernetes_cluster` Terraform resource block, which
    is used to create the AKS cluster. There are a few key parameters, including the
    name and `default_node_pool` parameter block. You can specify the VM size, node
    count, and name of the node pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Putting it all together, you’ll have a Terraform configuration that creates
    an AKS cluster in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the Terraform configuration, you’ll need variables to pass
    in. The variables allow your code to stay repeatable – in accordance with the
    **Don’t Repeat Yourself** (**DRY**) principle – so that you don’t have to continuously
    change hardcoded values or create new configurations for each environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`name`: Name of the AKS cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resource_group_name`: The resource group that AKS will reside in'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`location`: The region that the AKS cluster will reside in'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`node_count`: How many Kubernetes worker nodes will be in the AKS cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These variables can be seen in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Putting both the `main.tf` and `variables.tf` configuration files in the same
    directory will create a Terraform module for creating an AKS cluster. You can
    use this for almost any environment, change configurations (such as the node count)
    depending on your needs, and make your process repeatable.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling an AKS cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Scaling an AKS cluster is made possible by implementing the Kubernetes Cluster
    Autoscaler. Much like autoscaling groups for Azure VMs, AKS decides on how and
    why to scale the cluster based on the worker node load, which is the Azure VMs
    in the background. The Cluster Autoscaler is typically deployed to the Kubernetes
    cluster with the `cluster-autoscaler` container image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to the Azure portal and go to the AKS service. Once there, go to **Settings**
    | **Node pools**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Node pools settings'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – Node pools settings
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the three dots as per the following screenshot and choose the **Scale
    node** **pool** option:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Scaling node pools'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 – Scaling node pools
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Scale node pool** pane will come up and you’ll see the option to automatically
    scale the node pool or manually scale it and choose how many nodes you want to
    make available:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Specifying the node count and scale method'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – Specifying the node count and scale method
  prefs: []
  type: TYPE_NORMAL
- en: 'From an automation and repeatability standpoint, you can do the same thing.
    The following is an example of creating the `azurerm_kubernetes_cluster_node_pool`
    Terraform resource with the `enable_auto_scaling` parameter set to `true`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Node pools are simply Azure VMs that run as Kubernetes worker nodes. When thinking
    about autoscaling, remember that horizontal autoscaling comes at a cost. Although
    it’s very much needed, you should limit the amount of Kubernetes worker nodes
    that are available. That way, you can keep track of costs and how many resources
    your containerized apps need.
  prefs: []
  type: TYPE_NORMAL
- en: AKS and Virtual Kubelet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To wrap things up with AKS, there is Virtual Kubelet. Virtual Kubelet isn’t
    AKS-specific. Virtual Kubelet allows you to take Kubernetes and connect it to
    other APIs. A kubelet is the node agent that runs on each node. It’s responsible
    for registering the node with Kubernetes. AKS Virtual Kubelet registers serverless
    container platforms.
  prefs: []
  type: TYPE_NORMAL
- en: In Azure, it’s **Azure Container Instances** (**ACI**). ACI is a way to run
    containers without using Kubernetes. If someone using Kubernetes doesn’t want
    to scale out worker nodes due to cost or management, they can use ACI bursting,
    which uses Virtual Kubelet. It essentially tells Kubernetes to send Deployments,
    Pods, and other workloads to ACI instead of keeping them on the local Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Now that ACA is GA, chances are you’ll see less of this type of implementation.
    However, it’s still a great use case for teams that want to scale, but don’t want
    the overhead of managing large AKS clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Managing and maintaining AKS clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once a Kubernetes cluster is created and running, the mindset shift moves from
    day-one Ops to day-two Ops. Day-two Ops will be focused on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Managing the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and maintaining the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying applications and getting services running
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When managing an AKS cluster, the biggest thing to think about is where the
    configuration exists and what tools you’re using to manage it. For example, the
    Terraform configuration could be in GitHub and you could be managing the cluster
    via Azure Monitor and the rest of the Azure configurations that are available
    in the AKS cluster. Day-two Ops is about making sure the cluster and your configurations
    are running as you expect. The focus is really on the question “*is my environment
    working and performing* *as intended?*”
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to monitoring, alerting, and overall observability, there are
    several options. Azure Monitor and Azure Insights are built into Azure, but if
    you have a multi-cloud or a hybrid-cloud environment, you may want to look at
    other options. That’s where a combination of Prometheus and Grafana can come into
    play. Whichever tool you choose (because there are several) isn’t important. What’s
    important is what you monitor. You’ll need a combination of monitoring the cluster
    itself and the Kubernetes resources (for example, Pods, Services, or Ingresses)
    inside of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Because managing Kubernetes clusters doesn’t differ all that much (other than
    the native cloud tools), it’s safe to assume that whether you’re using AKS, EKS,
    or GKE, the path forward will be the same.
  prefs: []
  type: TYPE_NORMAL
- en: AWS EKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you’re using AWS, you have a few options to choose from when using containers
    and Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: EKS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EKS with Fargate profiles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elastic Container** **Service** (**ECS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EKS is the primary way to run Kubernetes workloads inside AWS. If you don’t
    want to go the Kubernetes route but still want scalability, you can use ECS, which
    gives you the ability to scale and create reliable microservices but without Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: As with AKS, you don’t have to worry about managing the Control Plane or API
    Server when it comes to EKS. You only have to worry about managing and scaling
    worker nodes. If you want to, you can even take it a step further and implement
    EKS with Fargate profiles, which abstracts the Control Plane or API Server and
    the worker nodes to ensure a fully *serverless* *Kubernetes* experience.
  prefs: []
  type: TYPE_NORMAL
- en: As with AKS, in the following few sections, you’re going to learn how to create
    an EKS cluster manually first. After that, you’ll take what you learned from a
    manual perspective and learn how to automate it with Terraform. Then, you’ll learn
    about scaling EKS clusters from a vertical-autoscaling perspective. Finally, you’ll
    wrap up with serverless Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an EKS cluster manually
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Much like AKS clusters, before creating EKS clusters from an automated perspective,
    you must learn how to manually deploy them. In this section, you’ll learn how
    to deploy an EKS cluster with a node group in the AWS Console:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to the AWS portal and search for the EKS service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.9 – The AWS portal'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – The AWS portal
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the orange **Add cluster** button and choose the **Create** option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Adding a cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – Adding a cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'When configuring an EKS cluster, you’ll have to provide a few options to uniquely
    identify it, which include the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The EKS cluster name
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes API version
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The IAM role
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The IAM role is very important because there are specific policies that must
    be attached to the role that you’re assigning to the EKS cluster. Those policies
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AmazonEC2ContainerRegistryReadOnly`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AmazonEKSClusterPolicy`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Without the proceeding policies, the EKS cluster will not work as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Configuring a cluster'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Configuring a cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you’ll need to set up networking. The absolute minimum amount of subnets
    that you want to use is two public subnets with different CIDRs in different availability
    zones. For a full list of recommendations, check out the AWS docs ([https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html](https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Specifying the network configuration'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.12 – Specifying the network configuration
  prefs: []
  type: TYPE_NORMAL
- en: 'When configuring the cluster endpoint access, you have three options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Public** means the EKS cluster is essentially open to the world'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Public and private** means the API Server or Control Plane is open to the
    outside world, but worker node traffic will remain internal'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Private** means the EKS cluster is only available inside the AWS **Virtual
    Private** **Cloud** (**VPC**):'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Configuring cluster API access'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Configuring cluster API access
  prefs: []
  type: TYPE_NORMAL
- en: 'The last piece from a networking perspective is choosing the **Container Networking
    Interface** (**CNI**) and the version of CoreDNS. Choosing the latest typically
    makes the most sense:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.14 – Network add-ons'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.14 – Network add-ons
  prefs: []
  type: TYPE_NORMAL
- en: Click the orange **Next** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The final piece when creating the EKS cluster is the API logging. Regardless
    of where you plan to keep logs, traces, and metrics from an observability perspective,
    you must turn this option *on* if you want your cluster to record any type of
    logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.15 – Configuring observability'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.15 – Configuring observability
  prefs: []
  type: TYPE_NORMAL
- en: After you choose your logging options, click the orange **Next** button and
    you’ll be at the last page to review and create your EKS cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you know how to create an EKS cluster manually, it’s time to learn
    how to create it with Terraform so you can ensure repeatable processes throughout
    your environment.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an EKS cluster with Terraform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many production-level cases, you’ll run the following Terraform code within
    a CI/CD pipeline to ensure repeatability. For the purposes of this section, you
    can run it locally.
  prefs: []
  type: TYPE_NORMAL
- en: First, you’ll see the `main.tf` configuration and then you’ll take a look at
    `variables.tf`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the `main.tf` configuration for AWS EKS is much longer than EKS, let’s
    break it down into chunks for an easier explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, there’s the Terraform provider block. To ensure repeatability throughout
    your team, you can use an S3 bucket backend for storing your `TFSTATE`. The Terraform
    block also includes the AWS Terraform provider:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, the first resource is created. The resources allow an IAM role to be
    attached to the EKS cluster. For EKS to access various components and services
    from AWS, plus worker nodes, there are a few policies that need to be attached:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Following the IAM role are the IAM policies that have to be attached to the
    role. The two policies that you’ll need for a successful EKS deployment are the
    following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`AmazonEKSClusterPolicy`: This provides Kubernetes with the permissions it
    requires to manage resources on your behalf:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '`AmazonEC2ContainerRegistryReadOnly`: This provides read-only access to Elastic
    Container Registry if you decide to put your container images there:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the IAM role and policies are defined, it’s time to create the EKS cluster
    itself. The EKS cluster resource will create EKS itself, enable logging, and attach
    the IAM role that you created earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next resource is another IAM role, which is for the worker nodes. When
    creating an EKS cluster, you’ll have multiple resources that are created because
    you’re creating two sets of services:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The EKS cluster itself with all of its permissions and policies that are needed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Kubernetes worker nodes with all of the permissions and policies needed:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE56]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the IAM role for the worker nodes is created, there are a few policies
    that you’ll need to attach:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`AmazonEKSWorkerNodePolicy`: This provides Kubernetes the permissions it requires
    to manage resources on your behalf:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '`AmazonEKS_CNI_Policy`: This attaches the CNI policy for Kubernetes internal
    networking (kubeproxy):'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '`EC2InstanceProfileForImageBuilderECRContainerBuilds`: EC2 Image Builder uses
    a service-linked role to grant permissions to other AWS services on your behalf:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '`AmazonEC2ContainerRegistryReadOnly`: This provides read-only access to Elastic
    Container Registry if you decide to put your container images there:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '`CloudWatchAgentServerPolicy`: This allows the worker nodes to run the CloudWatch
    agent for monitoring, logging, tracing, and metrics:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The final part once the IAM role and policies have been created is to create
    the EKS node group resource, which is the Kubernetes worker nodes. You’ll define
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The IAM role and subnet IDs:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE91]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The desired scale size for autoscaling:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE93]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE95]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE96]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The policies that the resource depends on:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE98]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE100]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Now that you have the Terraform configuration, you’ll need variables to pass
    in. The variables allow your code to stay repeatable, so you don’t have to continuously
    change hardcoded values or create new configurations for each environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The two variables you’ll need are for the subnet IDs in the VPC of your choosing
    that will work with EKS. You can pass in two public subnet IDs that are in different
    availability zones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: Putting it all together, you’ll have a Terraform configuration that creates
    an AKS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling an EKS cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Scaling an EKS cluster is made possible by implementing the Kubernetes Cluster
    Autoscaler. Much like autoscaling EC2 instances, EKS decides on how and why to
    scale the cluster based on a load perspective. The Cluster Autoscaler is typically
    deployed to the Kubernetes cluster using the `cluster-autoscaler` container image.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the Kubernetes GitHub repo, under the `cluster-autoscaler` directory,
    there’s a list of cloud providers. One of those cloud providers is AWS. Inside
    the AWS directory, there’s an example Kubernetes Manifest called `cluster-autoscaler-autodiscover.yaml`,
    which shows that it’s using the `cluster-autoscaler` container image. It runs
    as a Kubernetes Deployment on your cluster and listens for certain resource limits.
    To autoscale the cluster, you’ll need an IAM role with the `AmazonEKSClusterAutoscalerPolicy`
    policy attached to it.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know about scaling an EKS cluster and how it’s possible with `cluster-autoscaler`,
    let’s talk about serverless Kubernetes with AWS Fargate profiles and how they
    can help automate day-one Ops.
  prefs: []
  type: TYPE_NORMAL
- en: EKS Fargate profiles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The content around Fargate profiles is pretty similar to AKS Virtual Kubelet
    and ACI bursting. However, you don’t need to deploy Virtual Kubelet manually as
    you do in AKS. Instead, you can set up Fargate profiles to act as your Kubernetes
    worker nodes. Virtual Kubelet is still running on Fargate to interact with the
    EKS API Server or Control Plane, but it’s sort of done automatically.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest difference here is that you don’t have to manage the worker nodes.
    Instead, Fargate profiles are like serverless Kubernetes. You deploy the EKS cluster,
    which is the API Server or Control Plane. Then, you deploy a Fargate profile,
    which is where your Kubernetes resources (for example, Deployments, Pods, and
    Services) run. You don’t have to worry about cluster management or maintaining
    EC2 instances that would otherwise be running as your Kubernetes worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a Fargate profile on your EKS cluster, you go into the **Compute** tab
    of the EKS cluster and you’ll see an option for adding or creating a Fargate profile,
    as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – Fargate profiles and compute'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_02_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – Fargate profiles and compute
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know how to create an EKS cluster manually and automatically, and
    are also familiar with the day-two Ops considerations with autoscaling and serverless
    Kubernetes, it’s time to learn about the final *big 3* Kubernetes service – GKE.
  prefs: []
  type: TYPE_NORMAL
- en: GKE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you’re using GCP, you have a few options to choose from when using containers
    and Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: GKE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE Autopilot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Run
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GKE is the primary way to run Kubernetes workloads inside of GCP. If you don’t
    want to go the Kubernetes route but still want scalability, you can use Google
    Cloud Run. Cloud Run gives you the ability to scale and create reliable microservices,
    but without Kubernetes. It supports Node.js, Go, Java, Kotlin, Scala, Python,
    .NET, and Docker.
  prefs: []
  type: TYPE_NORMAL
- en: As with AKS and EKS, you don’t have to worry about managing the Control Plane
    or API Server when it comes to GKE. You only have to worry about managing and
    scaling worker nodes. If you want to, you can even take it a step further and
    implement GKE Autopilot, which abstracts both the Control Plane or API Server
    and the worker nodes to ensure a fully *serverless* *Kubernetes* experience.
  prefs: []
  type: TYPE_NORMAL
- en: There have been many debates inside of container and DevOps communities around
    which Kubernetes service in the cloud is the superior choice. Although we’re not
    here to pick sides, a lot of engineers love GKE and believe it’s a spectacular
    way to implement Kubernetes. Since Kubernetes originated at Google, it makes sense
    that the GKE service would be incredibly reliable with well-thought-out features
    and implementations.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, you will learn about creating a GKE cluster automatically
    using Terraform and how to think about serverless Kubernetes using GKE Autopilot.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We’re skipping a section on scaling the GKE cluster because it’s the same concept
    as the other clouds. It uses the Kubernetes Autoscaler in the background. All
    the autoscalers are considered horizontal autoscalers, as they create new worker
    nodes or VMs to run Kubernetes workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a GKE cluster with Terraform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this chapter, you’ve learned several manual ways of creating a Kubernetes
    cluster in the cloud. Instead of continuing down the manual road, let’s jump right
    into automating the repeatable process of creating a GKE cluster with Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: 'What you’ll find with GKE is that it’s much less code compared to EKS, for
    example. You’ll see the `main.tf` configuration first and then you’ll take a look
    at `variables.tf`. Let’s break down the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you have the Google Terraform provider, for which you’ll need to specify
    the GCP project ID and the region in which you want to deploy the GKE cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, you’ll create the `google_container_cluster` resource, which is the GKE
    cluster. It’ll specify the cluster name, region, and worker node count:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final resource to create is the `google_container_node_pool` resource,
    which is for creating the Kubernetes worker nodes. Here is where you can specify:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The worker node count:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE116]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE117]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE118]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE119]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The GCP scopes (or services) that you want GKE to have access to:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE121]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE122]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE123]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE124]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE125]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE126]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE127]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The VM type or size:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE129]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE130]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE131]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE132]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE133]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE134]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Putting it all together, you’ll have a `main.tf` configuration that you can
    use to set up a GKE cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s take a look at `variables.tf`, which will contain the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The GCP project ID:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE136]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE137]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE138]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The GCP region:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE140]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE141]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE142]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The GCP VPC name that GKE will exist in:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE144]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE145]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE146]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The subnet name inside of the VPC that you want GKE to be attached to:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE148]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE149]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE150]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The code count (Kubernetes worker nodes):'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE152]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE153]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE154]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'The GKE cluster name:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE156]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE157]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE158]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: You’re now ready to put the proceeding code into the appropriate `main.tf` and
    `variables.tf` configuration files to create your GKE environment.
  prefs: []
  type: TYPE_NORMAL
- en: GKE Autopilot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To wrap up the *GKE* section, let’s quickly talk about GKE Autopilot. Autopilot
    is the same concept as EKS Fargate. It’s serverless Kubernetes, which means you
    don’t have to worry about managing the worker nodes for your GKE cluster. Instead,
    you only have to worry about deploying the application(s) and setting up any monitoring,
    logging, traces, alerts, and metrics you’d like to capture from the GKE cluster.
  prefs: []
  type: TYPE_NORMAL
- en: A quick note on multi-cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many engineers just getting started with Kubernetes may not come across it too
    much, but multi-cloud is very much a reality. Just as organizations didn’t want
    to rely on one data center for redundancy, some organizations don’t want only
    one cloud for redundancy. Instead, they want to think about the multi-cloud approach
    – for example, scaling out Kubernetes workloads from AKS to GKE.
  prefs: []
  type: TYPE_NORMAL
- en: This implementation can be rather advanced and require a ton of security-related
    permissions, authentication and authorization capabilities between clouds, and
    heavy networking knowledge to ensure Kubernetes clusters between clouds can communicate
    with each other. Because of that, it’s highly recommended to do extensive research
    before implementing this and ensure that all of the proper testing went as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although a multi-cloud approach may not be at the forefront of everyone’s mind,
    it’s still super crucial to understand how the three clouds work with Kubernetes.
    The reason why is that chances are, throughout your Kubernetes journey, you’ll
    work in one cloud, but when the need arises to work in other clouds, you should
    be prepared.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned about setting up, managing, and maintaining Kubernetes
    clusters across Azure, AWS, and GCP. One of the biggest takeaways is that at the
    end of the day, the setup of Kubernetes across the clouds isn’t really so different.
    They’re all sort of doing the same thing with different service names.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Building Google Cloud Platform Solutions* by Ted Hunter, Steven Porter, and
    Legorie Rajan PS:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/product/building-google-cloud-platform-solutions/9781838647438](https://www.packtpub.com/product/building-google-cloud-platform-solutions/9781838647438)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Hands-On Kubernetes on Azure – Second Edition* by Nills Franssens, Shivakumar
    Gopalakrishnan, and Gunther Lenz:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/product/hands-on-kubernetes-on-azure-second-edition/9781800209671](https://www.packtpub.com/product/hands-on-kubernetes-on-azure-second-edition/9781800209671)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Learning AWS – Second Edition* by Aurobindo Sarkar and Amit Shah:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.packtpub.com/product/learning-aws-second-edition/9781787281066](https://www.packtpub.com/product/learning-aws-second-edition/9781787281066)'
  prefs: []
  type: TYPE_NORMAL
