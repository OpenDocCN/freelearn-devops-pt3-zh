- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding Event-Driven Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Al freir de los huevos lo vera. (It will be seen in the frying of the eggs.)
  prefs: []
  type: TYPE_NORMAL
- en: – Miguel de Cervantes (Don Quixote)
  prefs: []
  type: TYPE_NORMAL
- en: In any application, everything can be divided into **events**. Events are triggered
    either by some interaction with an external actor (either another application
    or a user) or by other events. An application is basically the triggering of multiple
    sequences of events to perform some sort of function. Google Drive, for example,
    is an application, and its function is just storage. Of course, this is an oversimplification
    and there are a lot of things that go into storing, organizing, and serving files,
    but that is the basic gist of it. It functions based on a series of events, each
    of which comes from a certain source.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, different events require different technologies, frameworks, and libraries
    within the system to interact with each other in perfect harmony. When this harmony
    is naturally achieved, it is a thing of beauty. However, it almost never is. There
    is always some sort of bottleneck or some custom part that needs to be made, and
    it almost always concerns the data that comes from an event. You can have the
    perfect tool for your system but it’s useless if it cannot process the events
    that it receives. So, what conclusion did all the brainiacs come up with when
    they realized this? They figured out that there are no perfect systems, nor are
    there perfect events. What is required is a system that is not tightly bound to
    any sort of data processing, a system that can take a bit of human error. Not
    a less precise system, but one that works with the realities of the situation
    that it has been put in: a loosely coupled system.'
  prefs: []
  type: TYPE_NORMAL
- en: Systems such as these are built so that they take events from multiple sources
    and process them for output in the simplest way possible. They break down every
    single event and event handler into their own components. These components then
    interact with other components based entirely on the input they receive and the
    output they give. If it can be helped, no component is fully dependent on the
    other. A system like this may seem inefficient, but when the goal is reliability
    in an unreliable world, it becomes quite appealing.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, now that I have finished my customary monologue, let’s look at how to break
    down that unnecessary monolith. In this chapter, you will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The basic concepts behind and use of **Publisher/Subscriber** (**Pub/Sub**)
    architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The general concept behind **loosely coupled architecture** and why Python is
    already well suited for it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The effective industry standard for breaking down a monolithic application into
    smaller loose components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There will also be some Python, as well as some other things. In fact, that
    is exactly what I am about to get into right now.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following may help you in fully benefiting from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Python installed with the `confluent-kafka` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An open mind (figuratively, not literally; well, if you want to do so literally,
    it’s fine but I don’t recommend it)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Pub/Sub and employing Kafka with Python using the confluent-kafka
    library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we get into what the modern Pub/Sub model is, let’s go into a bit of
    detail about the technology that made this field possible: **Apache Kafka**, the
    third most famous Kafka after Franz and *Kafka on the Shore*. Originally designed
    for use in LinkedIn (a great website), it was made open source in early 2011\.
    The concept behind it was pretty simple: there is a log of information and events
    that any number of systems can consume, and data can be published to the log for
    consumption by these systems. Sound simple enough? Well, it is now, but it took
    some thinking to come up with it. But this is the system that is responsible for
    most modern data infrastructure that we see today. Have you ever gotten a notification
    on your phone? It is because of this library. Have you ever made a contactless
    payment with your phone or credit card? Chances are, Kafka’s in there. Ever gotten
    a notification for a YouTube video? Definitely Kafka.'
  prefs: []
  type: TYPE_NORMAL
- en: In most cases where raw unadulterated Kafka is used, the distributor of information
    is called the **producer** and the receiver of said information is called the
    **consumer**. In most modern nomenclature, as well as with most cloud services,
    they are instead called the **publisher** and the **subscriber**.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 8.1 – Events processing with the \uFEFFPub/\uFEFFSub model](img/B21320_08_1.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Events processing with the Pub/Sub model
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we dive into the use of Kafka and Python in DevOps, we must first look
    at a sample usage of Kafka with Python using the `confluent-kafka` library:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first install the library using `pip`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, as mentioned before, Kafka is divided between a producer and a consumer.
    So, let’s first write a piece of code that creates a producer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code will configure a producer. Replace `host_name` with the name of an
    Apache Kafka cluster (online or locally). Next, we need to use the configured
    producer to send some data. Let’s look at that code now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, `topic` is the location where the publisher or producer will distribute
    their content for it to be consumed. The `key` and the `value` elements are the
    keys and values that will be distributed by the producer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s now add some code for a consumer that will pick up messages sent by the
    producer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The consumer now listens on the same host that the producer sends messages on.
    So, when the producer produces a message, the consumer can consume it. When a
    consumer is subscribed to a topic, that consumer is constantly listening to the
    message at certain intervals. Once the message arrives, it will begin the process
    of interpreting the message and sending it to the appropriate location.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To have the consumer continually listen to the producer for messages, we can
    place it in a loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is simply understanding the way that these Pub/Sub mechanisms work. In
    application, it is much easier since some sort of mechanism to perform this will
    already be provided for you. This is, however, a good way to learn how to make
    custom Pub/Sub structures if you want to, and to just understand Pub/Sub structures
    in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what the key takeaway from this should be: this is how the world works.
    Exactly like this. Most of the things that come to your phone come from this.
    Most of the things that go out of your phone go to this. It’s also true on a more
    fundamental level as well, as we will see in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the importance of events and consequences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alright, so now you are in on the secret. Everything is push and pull. People
    just toss data out there and hope it hits something. And if you’ve also realized
    that that is the most effective approach toward growth and development, kudos
    to you. If you haven’t, well, we are about to go into a little story time.
  prefs: []
  type: TYPE_NORMAL
- en: I currently live in Uppsala, Sweden, and for quite a while, I thought I was
    the only person from Nepal who lived here. Now, Uppsala is a big town by Swedish
    standards and a lot of students from all over the world live here as well. But,
    even if Nepalese people lived here, how would I have known them? Something that
    specific is very hard to find, even in this day and age. But then, the most remarkable
    set of coincidences (some may even say events, eh?) happened, which brought me
    into contact with other people from Nepal. I only realized just how remarkable
    they were once I backtracked through all of them.
  prefs: []
  type: TYPE_NORMAL
- en: I had just recently gotten a job offer (the one that I currently have) in Stockholm
    and I was getting on the train to Stockholm to iron out the details. On the train,
    I met a friend of mine with whom I collaborate on projects at the student union
    in Uppsala. In fact, we had met just the other day to discuss those projects.
    I saw him and sat down next to him, and I saw that he was with two other friends.
    One of them was a teaching assistant on a project that I had to submit the very
    next day. That was cool, but that wasn’t even the most important event that happened
    on the train. His other friend and I got to talking and, through him, I got the
    number of another Nepalese person who was also living in Uppsala. What kismet!
    Through that person, I have actually managed to find almost a dozen others who
    live in the same town as me, who have come on the same journey.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, here’s the thing: I skipped to the end of this story because, in a way,
    that’s how we live our lives, trying to finish something up and get to the end
    of the story to begin a new one. It is how we read, how we consume content, and
    basically, how we behave socially. But, over time, I contemplated the story, and
    I thought back to the set of events that had brought me up to that point, so let’s
    backtrack (and I promise there is a satisfying conclusion to this that isn’t just
    me bragging about my luck):'
  prefs: []
  type: TYPE_NORMAL
- en: I met my friend who introduced me to his friend on the student union developer
    team
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I joined that team to try and make some new friends in Uppsala, but the information
    for that came from a WhatsApp group that I joined based on a recommendation from
    another friend from my faculty
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I became friends with him before we even joined the faculty because we ended
    up on a student nation tour (look up Uppsala student nations for a fun and interesting
    read)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I joined that tour because of the recommendation that I got on my first day
    in Uppsala during my orientation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'But this is the saner half of the event tree that led to this event. The other
    half is even more interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: I was on that train because I went to sign a job contract.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I got the offer for that job because I made a post about having all 11 Google
    Cloud certifications on the Google forums, and the company that I currently work
    for just happened to notice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I made that post exclusively because I got all 11 of those certifications. I
    got the last one on the day before I left for Sweden. Had I only gotten 10, I
    wouldn’t have made it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I got those certifications largely as a sort of reinforcement of the knowledge
    that I wanted to deliver with this book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I got the offer for this book from my publisher after applying for it based
    on the link that I found in one of their other books, which was a Google Cloud
    examination book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, in a roundabout way, writing this book helped me secure the job I have
    today, and it eventually led to me finding more Nepalese people in Uppsala. If
    you couldn’t be bothered with all of that, let me show it to you visually:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – The events that drove a part of my life](img/B21320_08_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – The events that drove a part of my life
  prefs: []
  type: TYPE_NORMAL
- en: The events in our lives lead to the most extraordinary circumstances, and this
    was just one of the events that came about from this whole saga. Several other
    remarkable things happened through all of this that made me realize that the true
    consequences of our actions are truly unpredictable and yet, most of the time,
    a lot better or at least more exciting than anything we could have possibly planned.
  prefs: []
  type: TYPE_NORMAL
- en: Self-indulgent? Probably. But that is the magic of DevOps. Conforming to tight
    structures and solid preconceived notions leads to fear and stunts growth. They
    hide and overshadow opportunities that spontaneity brings. There is no room to
    find, discover, and fail. Yes, fail, because in something so tightly packed as
    a monolith, failure can be disastrous. In something loosely coupled, failure is
    simply a growth opportunity. You can move pieces in and out and iterate to your
    best possible version. You may look at my story and say that a lot of it is luck
    and coincidence – for example, in finding the exact person I needed on the train
    or just happening to have my forum post viewed – but luck is simply an amalgamation
    of one’s sustained attempts. People sometimes get lucky once or twice, but people
    who are not afraid to fail and who go with the flow are found to be lucky a lot
    more. God hates a coward.
  prefs: []
  type: TYPE_NORMAL
- en: So, switching gears to something a little less philosophical, loosely coupled
    architecture is a sort of framework you can use to achieve this kind of meaningful
    event-based system in your workload. This entire passage was initially supposed
    to be the next section before it took a life of its own (spontaneity, amirite?).
    So, let’s dive into the actual nitty-gritty now and see what we can find.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring loosely coupled architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alright, in a vacuum, loosely coupled architecture seems like a bad idea. You
    disperse your components so much that there is no rhyme or reason as to how any
    information gets from one place to another. You can’t count any sort of consistent
    time for all your data to collate into one place for the thing you want to happen
    to actually happen.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are a few factors that make loosely coupled architecture so effective
    in a practical setting. These factors are both philosophical and architectural.
    Firstly, no matter how well you design a system, it will fail somewhere at some
    time. The loosely coupled architecture allows the system to fail gracefully and
    to recover from failures in a way that doesn’t affect other components and users
    of the system. Because each component is isolated, these components can be identified
    after a single failure (a lot of the time, a clone component will succeed). This
    failure can be logged and detected and the correct parties can be notified without
    any interruption to the system. The failed component will not disrupt activities
    and it is not considered to be a bad thing. In fact, failure teaches us the weaknesses
    and shortcomings of the system, which can then be worked on quickly because you
    are only working on that isolated component.
  prefs: []
  type: TYPE_NORMAL
- en: The next factor comes from availability. Loosely coupled architecture offers
    small components that are replicated for each individual use. Now, you would say
    that this is a limit in and of itself since even if you can divide the resources
    between users, there won’t be enough resources to go around. In the past, this
    would have been true, but with modern applications running on the cloud, there
    can be infinite provisioning for services that support a loose architecture. You
    can handle the volume of resources effectively because the scale for the services
    that can run this kind of architecture is nearly infinite. This results in an
    environment where an architecture that will provision based on use becomes the
    optimal architecture. A more tightly coupled architecture might suit more limited
    means, but that is not the case for scenarios with flexible resources and unknown
    loads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the last factor that puts loosely coupled architecture in the lead
    is laziness. Yes, laziness. I have found in my life that the leading cause behind
    my laziness is not the fact that I don’t want to do something, but rather because
    my brain is overwhelmed with useless information about something that I might
    want to do. I started actually getting somewhere when instead of trying to figure
    out these minutiae in a way that was ineffective and useless, I just started doing
    things and figuring them out as I went along. That’s basically why loosely coupled
    architecture is good. There are fewer things to worry about and it is easier to
    work on. Instead of worrying about every single little thing before you even start
    implementing the system, you can just start implementing and worry about optimization
    later. This is perfect for someone like me who uses this approach for practically
    everything, and it’s the same for some of the biggest companies in the world as
    well. If you’ve heard of the Toyota way, it essentially follows the same principle:
    making mistakes and learning from them to get better. You can look it up; I encourage
    you to. But, in conclusion, this type of architecture is for the lazy, pragmatic
    developer who is just trying to get somewhere.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the past several paragraphs, you have endured my philosophical rants, and
    now we get to the more pragmatic part where I show you stuff and try to reinforce
    what I ranted about. So, that is what we’re going to get into right now. We are
    going to make a basic application (just a lambda function, actually) that is triggered
    when an image is uploaded into an S3 bucket, takes the image and resizes it to
    a standard size, deletes the original image, and replaces it with the resized
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This is a simple code for a very simple yet important function. The trigger
    for the image conversion can be placed either at the lambda function or the S3
    bucket itself. If you have ever used one of those online services that convert
    your PDF to a Microsoft Word document or convert your WAVs into MP3s, they basically
    run on this concept. Even with a very minimal interface, they can be very effective
    and quite popular.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps before reading this book, you may have had the misconception that building
    some of these services might be difficult. In the world we live in, they are not.
    Once we have opened these horizons, everything becomes clearer, and one of the
    things that becomes clearest of all is the ability to move on from the old inefficient
    ways into newer, simpler ways. Let’s look at the path to that transition.
  prefs: []
  type: TYPE_NORMAL
- en: Killing your monolith with the strangler fig
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you oppose killing anything (and I understand), simply change the word/s
    in your mind to happier ones (such as “sleeping” or “napping”). But the **strangler
    fig** is being talked about here because it is one of the most prominent methods
    in the **digital transformation** and/or modernization of applications. You may
    have heard the term digital transformation and immediately dismissed it as some
    buzzword, which, fair enough, most of the time when people use that word, it is.
    But open your eyes and ears for a moment and treat the term for what it actually
    is: it is changing old things into new things. It is basically changing your system
    from within while either maintaining the same functionality or increasing functionality.
    It is the breaking of the monolith into a loosely coupled architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For starters, let’s look at the potential structure of a monolithic application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – A basic monolith](img/B21320_08_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – A basic monolith
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s quite crude, but that is basically how most monolithic applications are
    structured. They have a user interface, which interacts with two different types
    of operations: operations on the database and generic data operations (**Misc**
    in the diagram). Even this monolith is rather more divided than regular monoliths
    since we have given it a separate database. The database can also be directly
    within the monolith sometimes.'
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down this monolith is not just about making it disassociated; it is
    about making sure that each component can act as an individual entity in case
    it becomes of use in some other project or in a different way in the same project.
    But to continue with the breaking down of this monolith, we can keep that going
    by first removing the miscellaneous functions that require no interaction with
    the users or the database from the monolith.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Removing miscellaneous APIs from the monolith](img/B21320_08_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Removing miscellaneous APIs from the monolith
  prefs: []
  type: TYPE_NORMAL
- en: So, this diagram indicates that the separation between the monolith and the
    miscellaneous functions divides those functions into individual components. This
    is the foundation of serverless architecture. It is all about exclusively having
    individual functions as individual endpoints to call only for certain use cases.
    This stage helps get the easy stuff out of the way and also helps make it so that
    the people performing the transformation can practically start grasping the concept
    behind it. It’s a lot easier to manage random functions if they are just endpoints
    somewhere that you can call randomly and modify to suit certain needs.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the next step toward breaking down this monolith is the division of the
    user interface and the backend portion that performs the data operations. This
    involves placing an API or a backend for the frontend in between them.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – A fully decoupled architecture](img/B21320_08_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – A fully decoupled architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'The final structure after breaking down the monolith looks like *Figure 8**.5*.
    It’s a bit like my consequences diagram but not as foolish. There are a lot of
    moving parts here, but then again, there are a lot of moving parts in cars too;
    it’s what makes them work. More importantly, let’s look at this from the lens
    of the two things emphasized in this chapter, availability and failure:'
  prefs: []
  type: TYPE_NORMAL
- en: If the user interface for some reason stops loading, it will fall back to a
    different region. This region will have the same capabilities; if it’s further
    from the user, it might be slower, but it will do the job.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The API or backend for the frontend can receive calls from multiple user interfaces
    and can access multiple servers that have access to the database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The backend can then simply be there to connect to the database for operations.
    There is no need for anything there except for queries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The database itself becomes more secure due to the layers present and it becomes
    easier to increase its availability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The miscellaneous functions are simply endpoints that can be put in or taken
    out as it suits the development team.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Well, that is quite the process, isn’t it? But it is one that gives results
    and helps make your application or workload more sustainable and futureproof.
    It doesn’t work for every workload, but it is fantastic in helping older systems
    use modern technology better.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the event-driven architecture that comprises
    a lot of modern application development. You also, hopefully, learned about actions
    and their consequences and how important positive actions are to development and
    your life in general. Lastly, you learned about a way to modernize older applications
    toward this new philosophy through the use of the strangler fig.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will get even more hands-on with Python and learn about
    the role that Python can play in **CI/CD** (short for **continuous integration/continuous
    delivery**). It’s a fun topic and will help you implement the Python skills and
    concepts you’ve been studying in this chapter.
  prefs: []
  type: TYPE_NORMAL
