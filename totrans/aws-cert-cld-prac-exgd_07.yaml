- en: '[*Chapter 5*](B17124_05_Final_SK_ePub.xhtml#_idTextAnchor094): Amazon Simple
    Storage Service (S3)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we look at one of the available storage services on **Amazon
    Web Services** (**AWS**). Many clients who are just starting on their cloud journey
    often consider storage services in the cloud as a stepping stone to going cloud-native
    in the long run. While storage options have become cheaper over the years, the
    fact remains that we continue to consume more and more storage with the passage
    of time. That said, it is vital that organizations also have a smart life cycle
    policy for their storage needs. Companies may be required to keep data for many
    years, and for as long as 7 to 10 years for compliance and regulatory purposes.
    However, at some point, a substantial amount of data is no longer required, and
    purging this data from the network not only makes management easier but also saves
    on cost.
  prefs: []
  type: TYPE_NORMAL
- en: Access to AWS storage services is extremely easy, and rather than procuring
    new storage hardware to host on-premises, it is much easier and more cost-effective
    to use the services offered by a cloud vendor such as AWS. Understandably, there
    will some types of data that need to be stored on-premises primarily because of
    latency issues, but from a security standpoint, AWS offers numerous options to
    ensure that your data is accessible only to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS offers different storage options, and in this chapter, we look at one of
    its flagship products: **Amazon Simple Storage Service** (**Amazon S3**). Amazon
    S3 is an object storage solution and offers very high levels of availability,
    durability, and scalability. AWS also offers other types of storage options, which
    we look at in subsequent chapters.'
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will understand the fundamentals of object storage
    on AWS and how Amazon S3 can help fulfill core storage requirements for your business
    in the cloud. You will also learn how about various features that can be used
    to manage your cloud storage, address regulatory and compliance concerns, and
    design cost-effective solutions. Finally, you will learn how to access your cloud
    storage from on-premises locations and how to migrate large datasets to the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics in this chapter include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to storage options on AWS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Amazon S3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about archiving solutions with Amazon S3 Glacier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connecting your on-premises storage to AWS with Amazon Storage Gateway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Migrating large datasets to AWS with the Amazon Snow Family
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise 5.1—Setting up an Amazon S3 bucket
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise 5.2—Configuring public access to S3 buckets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise 5.3—Enabling versioning on your bucket
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise 5.4—Setting up static website hosting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete the exercises in this chapter, you will need to have an AWS account
    via the AWS Management Console. You will need to be logged in as the IAM user,
    **Alice**, that you created in the last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to storage options on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A storage service provides the necessary infrastructure to enable you to store
    and access data. However, different use cases require varied storage architectures
    to ensure performance, reliability, durability, and the right type of access to
    the data. There are three primary storage options available, and AWS offers services
    to cater to each of these.
  prefs: []
  type: TYPE_NORMAL
- en: Block storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Block storage** is an architectural design that enables the storage of data
    onto media such as a hard disk, in fixed-sized chunks. Data is broken up into
    small blocks and placed on the media in these chunks, with a unique address assigned
    that forms part of its metadata. Block storage makes use of a management software
    (which can be part of the operating system) to organize the blocks of data. When
    a user tries to retrieve a file, the management software identifies the blocks
    to retrieve, reassembles the data, and presents the whole file to the user.'
  prefs: []
  type: TYPE_NORMAL
- en: On AWS, block storage options are available as **Elastic Block Store** (**EBS**).
    These can be configured as volumes attached to your **Elastic Compute Cloud**
    (**EC2**) instances and offer ultra-low latency required for high-performance
    workloads. One advantage of EBS volumes is that they are not directly attached
    to the EC2 instance you deploy, but instead are connected via high-speed network
    links. This allows you to detach an EBS volume from one EC2 instance and attach
    it to another if, for example, the first EC2 instance experiences some sort of
    failure.
  prefs: []
  type: TYPE_NORMAL
- en: Typical use cases include running and managing system files such as those used
    by your operating system, large databases, or for applications such as **enterprise
    resource planning** (**ERP**) solutions. These types of applications require very
    low-latency access to the data and generally make use of **direct-attached storage**
    (**DAS**) or **storage area networks** (**SANs**).
  prefs: []
  type: TYPE_NORMAL
- en: File storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another storage architectural design is **file storage**. The architecture offers
    a centralized location for your corporate data, and files are stored in folders
    and sub-folders. File storage offers a hierarchical structure to store your data,
    and this means you can imitate your real-life counterpart—the filing cabinet—to
    organize your data.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval of the data requires you to know the file and folder structure and
    provide this information. For example, if I need last August's balance sheet Excel
    document, I will need to look in the `2020` folder and the `August` sub-folder,
    and this would enable me to retrieve that specific data.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the nature of file storage, metadata information can be limited, and
    a key limitation to be aware of is that you cannot have unlimited folders and
    sub-folders due to your operating system restrictions. Your hierarchical structure
    can also be the cause of some performance issues, and therefore you need to decide
    on this structure carefully.
  prefs: []
  type: TYPE_NORMAL
- en: File storage lends itself well to being used for file sharing within a corporate
    organization. Because of the folder/sub-folder architecture, it becomes very easy
    to organize your data to fit in well with your organizational structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon offers three different file storage systems, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Elastic File System** (**EFS**)—This is a managed elastic filesystem designed
    to let you share file data without provisioning or managing storage as you would
    with EBS. Your filesystem will grow and shrink as you add and remove data, and
    mount points can only be created on Linux EC2 instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FSx for Lustre**—A high-performance filesystem designed for applications
    that require fast storage and can scale to hundreds of **gigabytes** (**GB**)
    of throughput and millions of **input/output operations per second** (**IOPS**).
    FSx for Lustre is also designed for a wide range of Linux-based EC2 instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FSx for Windows File Server**—Designed for Microsoft Windows EC2 instances
    and offers a fully managed file-share solution, natively supporting the Windows
    file system such as the industry-standard **Server Message Block** (**SMB**) protocol.
    Typical use cases include file-sharing services, local archiving, application
    data sharing, and data protection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By contrast, **object storage** involves storing complete files as individual
    objects. Object storage presents a flat file structure—you create some form of
    container and place your objects within this container without using any folder
    or file-level hierarchy. This is also known as unstructured data. Object storage
    metadata (information about the object—such as its name, and so on), along with
    other attributes, is then used to create a unique identifier to easily locate
    that data in your storage pool. Due to the nature of object storage, the metadata
    can contain a vast array of information, enabling you to use object storage for
    data analytics far more easily than a file-based storage solution.
  prefs: []
  type: TYPE_NORMAL
- en: An additional benefit is that object storage lends itself well to offering higher
    levels of performance, durability, and scalability. In a file-level storage solution,
    the depth of the folder and file structure will often have a limit based on the
    operating system you are using. With object storage, however, you can potentially
    scale to having limitless amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: The flat file structure is another advantage point as this enables you to retrieve
    data much faster due to the extended categorization feature, as opposed to retrieving
    data from a file storage service.
  prefs: []
  type: TYPE_NORMAL
- en: On AWS, object storage options are available with the Amazon S3 service. Amazon
    S3 lets you create containers called **buckets**, within which you place your
    data (objects) in a flat file structure (unstructured manner). You can store and
    retrieve any amount of data—anytime, anywhere.
  prefs: []
  type: TYPE_NORMAL
- en: Typical use cases for object storage include storing digital assets for your
    websites and applications (documents, images, video), the ability to perform analytics
    on your objects, and offering storage solutions to cutting-edge technologies such
    as **Internet of Things** (**IoT**).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked at the three main types of storage options available,
    their key features, and typical use cases. We also highlighted some examples of
    AWS services that offer storage solutions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will introduce you to the Amazon S3 service, which is
    an object storage solution for the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Amazon S3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon S3 is one of Amazon's flagship products, and offers a robust, scalable,
    durable, and cost-effective **object storage** solution in the cloud. Customers
    can use Amazon S3 to store any amount of data for a wide range of use cases, including
    digital media content for websites, data lakes, mobile applications, IoT device
    data, and big data analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 can offer up to 99.999999999% durability and fulfills the storage
    requirements for a majority of clients and their individual business needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'What does eleven 9s of durability mean? According to AWS, if you store 10,000,000
    objects on Amazon S3, then on average you can expect to incur a loss of a single
    object once every 10,000 years. You can review all **frequently asked questions**
    (**FAQs**) for Amazon S3 here: [https://aws.amazon.com/s3/faqs/](https://aws.amazon.com/s3/faqs/).'
  prefs: []
  type: TYPE_NORMAL
- en: Buckets and objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before you can upload any data to Amazon S3, you need to create a container
    called a bucket. Buckets need to have a unique global namespace as their contents
    can be made accessible over the public internet. This means that your bucket names
    must be unique across the AWS ecosystem. For example, a document named `blueberry-muffin.txt`
    stored in a bucket named `just-desserts` can be accessible via the internet in
    two primary ways, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`blueberry-muffin.txt` object is accessible via the S3 **Uniform Resource Locator**
    (**URL**), such as [https://just-desserts.s3.amazonaws.com/blueberry-muffin.txt](https://just-desserts.s3.amazonaws.com/blueberry-muffin.txt).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s3-website` dash (`-`) Region—`http://bucket-name.s3-website-Region.amazonaws.com`.
    For example, our recipe will be available at [http://just-desserts.s3-website-us-east-1.amazonaws.com/blueberry-muffin.txt](http://just-desserts.s3-website-us-east-1.amazonaws.com/blueberry-muffin.txt).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: b) `s3-website` dot (`.`) Region—`http://bucket-name.s3-website.Region.amazonaws.com`.
    For example, our recipe will be available at [http://just-desserts.s3-website.us-east-1.amazonaws.com/blueberry-muffic.txt](http://just-desserts.s3-website.us-east-1.amazonaws.com/blueberry-muffic.txt).
    We look at static website hosting on Amazon S3 later in this chapter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When creating buckets, you may therefore find that common names are not available.
    For example, if you wanted to create a bucket name called `marketing`, then you
    will most likely not be able to use this name as it may have been used already.
    You could instead create a marketing bucket with a unique prefix or suffix to
    get an appropriate name. Most companies will try to associate their bucket names
    with their organization name or project name—for example, your marketing bucket
    name could be `my-company-marketing`. That said, you still cannot solely depend
    on any specific naming convention you define for your buckets, because another
    customer may have chosen the exact same name that you might have wanted, and bucket
    names are defined on a first-come first-serve basis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some key attributes of Amazon S3 buckets are provided here:'
  prefs: []
  type: TYPE_NORMAL
- en: Bucket names must be between 3 and 63 characters long.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bucket names must always be in lowercase letters. They can, however, contain
    numbers, hyphens (`-`), and dots (`.`) only.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bucket names must also begin and end with either a letter or number and should
    not include spaces between the names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bucket names must not be formatted as an `192.168.1.1`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buckets used with `.`) in their names. We discuss Amazon S3TA later in this
    chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You cannot have nested buckets—for example, a bucket within another bucket.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Except for website-style endpoints, you should avoid using dots (`.`) as part
    of your bucket names as they cannot be used with virtual hosted-style endpoints
    using **Secure Sockets Layer** (**SSL**) and the **HyperText Transfer Protocol
    Secure** (**HTTPS**) protocol. Note that the only reason they work with website-style
    endpoints is because static website hosting is only available over HTTP. You can
    get around this problem if you need to serve your content over HTTPS by incorporating
    a Amazon CloudFront distribution point. We discuss CloudFront in [*Chapter 6*](B17124_06_Final_SK_ePub.xhtml#_idTextAnchor122),
    *AWS Networking Services – VPCs, Route53, and CloudFront*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Any data stored in an Amazon S3 bucket is represented as an **object**. An object
    is stored in its entirety within a given bucket rather than with block storage,
    where a file may be broken up into chunks and stored on a given media such as
    a hard disk. As discussed previously, objects are stored in an unstructured manner
    as a **flat filesystem**. This means that accessing an object requires you to
    know its unique ID, which is generally part of the object's metadata. You can
    store an unlimited number of objects within a given bucket, and the maximum size
    of an object on Amazon S3 is 5 **terabytes** (**TB**).
  prefs: []
  type: TYPE_NORMAL
- en: The filename of an object is called a `!`, `-`, `_`, `.`, `*`, and `( )`.
  prefs: []
  type: TYPE_NORMAL
- en: Managing your objects in a bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned previously, objects are stored in a `/`) parameters to help you
    manage and browse your objects in a hierarchical fashion.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first glance, the usage of prefixes and delimiters (`/`) appears as a typical
    folder hierarchy, but the prefixes and delimiters themselves also form part of
    the object''s **key**, as we can see in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Amazon S3 prefixes and delimiter example'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 – Amazon S3 prefixes and delimiter example
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the preceding screenshot, a file (object) called [*Chapter
    5*](B17124_05_Final_SK_ePub.xhtml#_idTextAnchor094) `– Amazon Simple Storage Service
    S3.docx` appears to be stored in a `cloud-practitioner` sub-folder, under another
    sub-folder named `campaign`, in a bucket named `packt-marketing`.
  prefs: []
  type: TYPE_NORMAL
- en: This architecture allows you to better manage your objects, but the fact remains
    that the keys of the object itself comprise those prefixes and delimiters. This
    means that the `development/sourcecodes.php` and `production/sourcecodes.php`
    keys can reside in the same bucket and are considered unique objects because of
    the different prefixes.
  prefs: []
  type: TYPE_NORMAL
- en: Prefixes are also used to help you limit search results to only those keys that
    begin with a specific prefix name. In addition, delimiters enable you to perform
    list operations such that all the keys that share a common prefix can be retrieved
    as a single summary list result.
  prefs: []
  type: TYPE_NORMAL
- en: Prefixes further enhance performance when it comes to accessing your objects
    in Amazon S3\. For example, you can achieve 3,500 `PUT`/`COPY`/`POST`/`DELETE`
    or 5,500`GET`/`HEAD` operations per second per `GET` operations.
  prefs: []
  type: TYPE_NORMAL
- en: Regional hosting – global availability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your buckets and the objects contained within them are globally accessible if
    you define the necessary permissions. However, it is important to realize that
    a given bucket and any objects it holds are stored in one specific Region alone.
    When you create an Amazon S3 bucket in your AWS account using either the web console,
    **command-line interface** (**CLI**), or via **application programming interface**
    (**API**) access, you must specify the **Region** in which you wish to create
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your choice of the Region to create a given bucket is going to depend on several
    factors, including the following ones:'
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing latency by creating buckets closer to end users who need access to
    them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimizing costs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Addressing any regulatory requirements such as data-sovereignty laws
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon will *never* replicate your data outside of the Region in which you create
    it. This offers the assurance that you can meet and adhere to any data-residency
    laws you may be required to follow as a business.
  prefs: []
  type: TYPE_NORMAL
- en: You can, however, replicate the contents of one bucket in a given Region to
    another bucket in a different Region for several use cases, including **disaster
    recovery** (**DR**) or sharing content with your colleagues, such that the data
    is closer to them to reduce overall latency.
  prefs: []
  type: TYPE_NORMAL
- en: Access permissions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create and manage your Amazon S3 buckets and upload and download objects
    to the bucket, you need to define the necessary permissions. By default, only
    the resource owner, which is the AWS account that creates the resource, can access
    a bucket.
  prefs: []
  type: TYPE_NORMAL
- en: However, you can also grant access to other users in your account, as well as
    define permissions for specific **Identity and Access Management** (**IAM**) roles
    to have access to those resources. In addition, you can grant access to users
    in other AWS accounts, and even grant access to members of the public by configuring
    anonymous access. Anonymous access is ideal when you wish to host publicly accessible
    digital assets such as documents, images, and videos for your websites.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 offers two primary methods of granting access to resources such as
    buckets and objects. You can attach a resource-based policy known as a bucket
    policy, or you can attach **access-control lists** (**ACLs**). Let's examine both
    of these methods for granting access next.
  prefs: []
  type: TYPE_NORMAL
- en: Bucket policies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A bucket policy is applied directly to an entire bucket and can be used to grant
    access to both the bucket itself and the objects stored within it. Bucket policies
    can be used to specify different levels of access for different types of objects
    within the same policy document. A bucket policy document is also written in **JavaScript
    Object Notation Format** (**JSON**) format, just like IAM policies are.
  prefs: []
  type: TYPE_NORMAL
- en: With bucket policies, you can also grant anonymous access to object in your
    buckets, such as a web page, image, or video, which means that anyone with the
    S3 object URL can access it.
  prefs: []
  type: TYPE_NORMAL
- en: Bucket policies are very flexible and allow you to grant cross-account access
    too. This means that if users in other AWS accounts are permitted, you can grant
    them access to your buckets by specifying their account ID and their IAM user
    **Amazon Resource Name** (**ARN**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a typical bucket policy granting anonymous access to
    the objects it contains:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Bucket policy example granting anonymous access to the'
  prefs: []
  type: TYPE_NORMAL
- en: contents of the 'packt-marketing' S3 bucket
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 – Bucket policy example granting anonymous access to the contents
    of the 'packt-marketing' S3 bucket
  prefs: []
  type: TYPE_NORMAL
- en: As seen in the preceding screenshot, the policy allows anonymous access by specifying
    the `Principal` attribute as a wildcard (`*`), which indicates everyone. The action
    allowed on the `packt-marketing` bucket is `s3:GetObject`, which restricts access
    to only being able to read/download the object(s).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another element that can be added to a bucket policy is a `Effect` attribute
    of a policy to `Deny` unless the condition is met. For example, you can restrict
    the ability for users to access and download contents from an S3 bucket, unless
    the request originates from a range of IP addresses specified in the condition,
    as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Bucket policy defined with a conditional statement'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Bucket policy defined with a conditional statement
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, you will note that the `Effect` attribute of the
    policy is to deny access unless the `NotIPAddress` condition is met. You will
    need to replace the dummy IP address range shown (`w.x.y.z/c`) with a real IP
    address range for your use case.
  prefs: []
  type: TYPE_NORMAL
- en: Bucket and object ACLs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ACLs are now considered legacy control systems because bucket policies tend
    to be flexible and offer more granular levels of access. You can mostly use ACLs
    to grant anonymous access to objects and buckets, or to other AWS accounts. Since
    ACLs do not allow you to specify an individual IAM user as the grantee of those
    permissions, their use case is limited and preference is given to bucket policies
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: However, certain features require you to configure ACLs instead of bucket policies.
    **Server access logging**, for example, is a feature you can enable to provide
    detailed records for the requests that are made to an Amazon S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: IAM policies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As previously discussed in [*Chapter 4*](B17124_04_Final_SK_ePub.xhtml#_idTextAnchor068),
    *Identity and Access Management*, you can create IAM policies that are assigned
    to IAM identities (such as IAM users, groups of users, or IAM roles) and define
    what they can or cannot do with any specific service and/or resource in your AWS
    account.
  prefs: []
  type: TYPE_NORMAL
- en: You can, therefore, grant your IAM principals access to S3 buckets and objects
    contained within those buckets. However, IAM policies cannot be attached directly
    to the resource. Furthermore, you cannot attach an IAM policy directly to an IAM
    user in another AWS account. You would first need to create an IAM role with the
    necessary permissions and then enable a trust policy for the IAM user in the other
    AWS account to be able to assume the role.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, IAM policies cannot be used to grant anonymous access because of the
    simple principle that IAM policies can only be attached to an IAM identity.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can use a combination of bucket policies, ACLs, and IAM policies to grant
    access. You must remember, however, that any conflicting `Deny` permission will
    always override an `Allow` permission. However, these policy options are not mutually
    exclusive.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right S3 storage class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon S3 allows you store an unlimited amount of data in the cloud. However,
    not all data needs to be treated the same. For example, you may have some data
    that you require instant access to, but also other types of data that may be rarely
    accessed as it represents old archives stored for compliance purposes.
  prefs: []
  type: TYPE_NORMAL
- en: You may also have some data that you can afford to lose because recreating it
    would be easy, whereas other types of data may be simply irreplaceable. Depending
    on the data, its importance, and access patterns, AWS offers different storage
    classes for different use cases. So, for example, if you need to store old archives,
    you have the Amazon Glacier storage class, and if you need instant rapid access
    to your data, you have the Amazon S3 Standard storage class. All storage classes
    offer 99.999999999% **durability** for your data. Durability refers to long-term
    data protection, and AWS offers the necessary infrastructure and processes to
    manage your data, replicate copies, ensure data redundancy, and safeguard against
    degradation or other corruption.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the storage class that you choose to store your data in, AWS also
    offers different levels of **availability**, which determines the percentage of
    time an object is available for retrieval, based on the underlying storage system
    being operational (or the Region and **Availability Zones** (**AZs**) being online
    and accessible). Critical data such as digital assets, medical records, or financial
    statements would be ideal candidates for those storage classes that offer higher
    levels of availability. However, secondary copies of data may not need to be as
    available as the primary copies of the same data.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 charges are based around six cost components. These comprise the storage
    itself (comprising the amount of storage, duration, and storage class your objects
    are placed in), requests and data retrievals, data transfers, use of transfer
    acceleration, data management, and analytics, and the use of an Amazon S3 Object
    Lambda (which is the ability to modify and process data as it is returned to an
    application using Lambda functions). Note—data transferred in from the internet
    to an S3 bucket is free. One way of minimizing costs is to identify data that
    may not require instance access or that may be replaceable and store it in classes
    that are cheaper.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: A key point to note here is that you can host different objects under different
    storage classes within the same bucket. You do not need to create separate buckets
    for each storage class.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at the different storage classes next.
  prefs: []
  type: TYPE_NORMAL
- en: Frequent access
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazon S3 Standard**—This is the default storage class when you upload objects
    to a bucket, unless you specify otherwise. Amazon S3 Standard offers the full
    eleven 9s (99.9999999%) of durability and four 9s (99.99%) of availability. With
    Amazon S3 Standard, your objects are always replicated across a minimum of three
    AZs in the Region you place them in.'
  prefs: []
  type: TYPE_NORMAL
- en: Infrequent access
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon S3 offers two types of infrequent-access storage classes. These can be
    used to store objects that you are not going to frequently access, but at the
    same time, you have instant access to the data when you need it.
  prefs: []
  type: TYPE_NORMAL
- en: AWS offers these classes at lower costs on the condition that you do not access
    your data frequently, as you would with the Standard storage class. To enforce
    the conditions, AWS will charge additional retrieval fees. Furthermore, there
    is a minimum object size of 128 **kilobytes** (**KB**). You can still store objects
    under this minimum size, but those objects will be billed as though it is a minimum
    of 128 KB in size.
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon S3 Standard-Infrequent Access** (**S3 Standard-IA**)—S3 Standard-IA
    is designed for data that is just as critical as with the Standard storage class
    but is infrequently accessed and is therefore ideal for long-term storage, such
    as for backups, and to act as a data store for DR purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon S3 One Zone-Infrequent Access** (**S3 One Zone-IA**)—Data stored in
    this storage class is restricted to one AZ only within the Region you upload it
    to. This reduces your overall availability of the data to 99.5% but is also much
    cheaper than the Standard or the Standard-IA storage classes. This also means
    that if there is an outage of the AZ in which your data is stored, you would have
    to wait for the AZ to come back online before you can access any data. In the
    unlikely event of the destruction of an AZ, you may also lose that data.'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon recommends this class for data that can act as a secondary backup or
    that can be recreated.
  prefs: []
  type: TYPE_NORMAL
- en: Archive storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Often, data needs to be retained for archival purposes so that it is available
    when needed for auditing or reference. More often, regulatory and compliance requirements
    state that certain types of data should retained for *n* number of years. These
    could be financial information or past medical records, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon offers very low-cost storage for such requirements through its archival
    solution, **Amazon Glacier**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Glacier**—This storage class is designed for long-term archiving of
    data that may need to be accessed infrequently and within a few hours.'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving data from Amazon Glacier works differently, however, as it is not
    immediately accessible and requires you to initiate a restore request for the
    data. This restore process can take some time (between a few minutes to 12 hours)
    before the data is available to download, and this depends on the retrieval option
    you choose.
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Glacier Deep Archive**—This is the lowest-cost storage class whereby
    customers can store very old historical data to meet compliance and regulatory
    requirements. Such data may be required to be kept for 7 to 10 years. Retrieval
    times can take 12 hours or more, depending on the retrieval option chosen.'
  prefs: []
  type: TYPE_NORMAL
- en: We discuss the Amazon S3 Glacier retrieval options in more detail later in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Unpredictable access patterns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Normally, your business will have a predictable access pattern for most data—for
    example, newly created data may need to be accessed frequently, such as daily.
    As data gets older it is accessed less frequently, and sometimes very rarely.
    Your access pattern, while predictable in this case, changes over time. AWS offers
    a feature known as lifecycle management that allows you to move data from one
    storage class to another, depending on changes to your access patterns. We look
    at lifecyle management and lifecycle rules later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, however, it is difficult to categorize data as frequently accessed
    or infrequently accessed, simply because of the nature of that data. You might
    be frequently accessing a set of objects for an initial period of a few weeks,
    and those objects may later become infrequently accessed. However, a few months
    down the line, you may need to access those objects again for analysis or some
    form of investigation. This data may now need to be frequently accessed over a
    period once again.
  prefs: []
  type: TYPE_NORMAL
- en: In these scenarios, AWS offers another storage class called the Intelligent-Tiering
    storage class. For this privilege, you are charged a small monitoring fee for
    every object to ensure it is automatically transitioned into the right tier, depending
    on access patterns.
  prefs: []
  type: TYPE_NORMAL
- en: '**Intelligent-Tiering**—This storage class offers automated tiering of data
    depending on your access pattern. Objects are automatically transitioned across
    four different tiers, two of which are latency access tiers designed to move objects
    between frequently accessed and infrequently accessed tiers, and the other two
    being optional archive access tiers:'
  prefs: []
  type: TYPE_NORMAL
- en: Frequent and infrequent tiers—Objects that are frequently accessed (within 30
    days) are placed automatically in the frequent access tier (Standard storage class).
    Any objects not accessed for 30 days are then moved into the infrequent access
    tier (Standard-IA), thereby incurring lower costs. Remember—the minimum object
    size for Standard -IA is set to 128 KB, and objects less than this size are treated
    and charged as if they are a minimum of 128 KB. Any object in the infrequent tier
    that later gets accessed is then automatically moved back into the frequent tier
    and charged accordingly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optional archive access tiers—You can optionally choose to activate the archive
    access tiers. Once activated, this results in the S3 Intelligent-Tiering service
    transition when any object is not accessed for 90 days is moved into the Amazon
    Glacier **Archive Access tier**. If the object is not accessed for 180 days, it
    will be moved into the Amazon **Deep Archive Access tier**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Intelligent-Tiering does not charge a retrieval fee but if objects are archived,
    retrieval can take some time, depending on the retrieval option chosen. The following
    table illustrates the retrieval options available:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 5.1 – Retrieval times for S3 Glacier, Deep Archive, and S3 Intelligent-Tiering
    archive classes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Table_5.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Table 5.1 – Retrieval times for S3 Glacier, Deep Archive, and S3 Intelligent-Tiering
    archive classes
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, you have several retrieval options, and the times will vary
    depending on which archive storage option you select.
  prefs: []
  type: TYPE_NORMAL
- en: S3 on Outposts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Outposts is a fully managed on-premises service that comes with a 42U
    rack that can host the same AWS infrastructure and services at your data center.
    The U refers to rack units or "U-spaces" and is equal to 1.75 inches in height.
    A standard height is 48U (a 7-foot rack). The service allows you to create a pool
    of compute, storage, networking, and database services locally on-premises and
    is ideal if you have workloads running that are very sensitive to low-latency
    access. Amazon Outposts can also be used as a precursor to migrate your entire
    data center to the cloud at a later stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'With Amazon Outposts already widely available, AWS offers yet another storage
    class called **S3 Outpost**. The service offers durability and redundancy by storing
    data across multiple devices and servers hosted on your outposts and is ideal
    for low-latency access, while also enabling you to meet strict data-residency
    requirements. Amazon S3 on Outpost allows you to host 48 TB or 96 TB as part of
    the S3 storage capacity and provides the option to create a maximum of 100 S3
    buckets on each outpost. Have a look at the Amazon S3 performance chart shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Table_5.2_a.jpg)![Figure 5.4 – S3 storage class performance and key
    attributes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Table_5.2_b.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.4 – S3 storage class performance and key attributes
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding screenshot, you can choose which storage class to
    store your objects in depending on your use case. When making this decision, you
    need to consider durability and availability, as well as the minimum size of your
    objects, and ascertain whether you require instant access to those objects.
  prefs: []
  type: TYPE_NORMAL
- en: Versioning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To protect against accidental deletions or overwriting, AWS also offers a feature
    called S3 Versioning. By default, when you create a bucket versioning is disabled,
    which means that if you were to upload an object with the same name (which, as
    mentioned earlier, is called a **key** on AWS) as an existing object in an S3
    bucket, then the original object in the bucket will get overwritten. Sometimes
    this may be exactly what you want, but in most cases, you might want to preserve
    the original version. Often, objects are overwritten simply because the name of
    the object was not changed before performing the upload, and this results in an
    accidental overwrite.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 offers a feature where you can enable versioning on a bucket. The
    setting is applied to the entire bucket and will therefore affect all objects.
    Once versioning is enabled, any object that is uploaded with the same name as
    an existing object will be tagged with a new version ID. Accessing the object
    will yield the latest/current version, but a toggle switch in the console will
    allow you to also see all previous versions in case you need to access an earlier
    version of the object.
  prefs: []
  type: TYPE_NORMAL
- en: If you try to delete an object (without specifying the version ID) in a bucket
    that has had versioning enabled, then the object is not deleted. AWS adds a delete
    marker to the object and hides it from the S3 management console view. Subsequently
    if you need to *restore* the object again to make it visible in the S3 management
    console, you will simply have to delete the delete marker itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should note that buckets can be in one of three states, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Unversioned (default)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Versioning-enabled
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Versioning-suspended
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you enable versioning on a bucket, you can never return to the Unversioned
    state, but you can suspend versioning if you do not want new versions of objects
    being created.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Region and same-Region replication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As previously discussed, to help customers comply with compliance and data-residency
    laws, AWS will never replicate your objects outside of the Region in which you
    create them. However, there is nothing to stop you from replicating your data
    outside of the Region in which you uploaded it if there are no regulatory requirements
    that prevent you from doing so.
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Cross-Region Replication** **(CRR)** is used to asynchronously copy
    objects across AWS buckets in different AWS Regions. You can use CRR to do the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reduce latency**—By copying objects closer to where end users are based,
    you can minimize latency in accessing those objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increase operational efficiency**—If you run applications across multiple
    Regions that need access to the same set of data, maintaining multiple copies
    in those Regions increases efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Meet regulatory and compliance requirements**—Your organization compliance
    and regulatory requirements may require you to store copies of data thousands
    of kilometers away for DR purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to CRR, Amazon S3 also enables you to configure replication services
    between buckets in the same Region. This is known as **Same-Region Replication**
    (**SRR**), which can help you achieve the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Log Data Aggregation**—You may be collecting log data from several sources
    and applications. You can collate these datasets in a single log management bucket
    via replication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Replicating between development and production accounts**—If you use separate
    development and production accounts and need to use datasets in each, you can
    use replication to move objects from your development accounts to production accounts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance requirements**—You may be required to maintain multiple copies
    of your data to adhere to data-residency laws. SRR can help you copy data between
    multiple buckets to ensure you have more than one copy for compliance purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to note that both buckets must be configured with versioning
    enabled in order to set up CRR or SRR. You can also replicate objects across Regions
    or within the same Region, in either the same AWS account or across multiple AWS
    accounts. Finally, you can replicate objects into different storage classes from
    its original storage class, which means that your replicated objects can reside
    in a cheaper storage class, if perhaps they are being used simply as a backup
    copy—for example, your original objects can reside in the Standard storage class,
    but the replicated objects can be placed into the Standard-IA storage class. This
    will reduce your overall costs of storage.
  prefs: []
  type: TYPE_NORMAL
- en: Another feature of the replication service is support for multiple destination
    buckets. You can configure S3 Replication (multi-destination), which enables you
    to replicate data from one source bucket to multiple destination buckets, either
    within the same Region, across Regions, or a combination of both.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 Lifecycle Management Amazon S3 offers unlimited amount of storage.
    This means that it is very easy to upload any amount of data you create and simply
    forget about it. At the same time, let's not forget that Amazon S3 charges you
    for the total amount of storage consumed, and the cost also depends on the storage
    class in which you place your objects.
  prefs: []
  type: TYPE_NORMAL
- en: Often, the bulk of your data is going to be infrequently accessed, especially
    after the initial period in which the data was created. This makes it essential
    to have some mechanism for moving objects you no longer need frequent access to
    into a cheaper storage class, to manage your storage costs effectively. In addition,
    you may also host a lot of archive data that you no longer require after a period,
    even for compliance and auditing purposes. For example, some regulations state
    that certain types of data need only be kept for a maximum of 7 years.
  prefs: []
  type: TYPE_NORMAL
- en: Manually trying to manage vast quantities of data can be a tiresome affair,
    often involving the creation of scripts and tools to review the data stored in
    the cloud. Instead, you can use a reliable solution by Amazon S3, known as Amazon
    S3 Lifecycle Management.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon S3 Lifecycle Management actions can be applied to your Amazon S3 buckets.
    These can be applied to the entire bucket or a subset of data by defining a prefix.
    These actions fall into two main categories, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transition actions**—These allow you to move objects from one storage class
    to another after a certain period of time has passed. For example, if you know
    that you are going to be infrequently accessing a particular dataset after 60
    days, you can set a rule to move that data from the Standard storage class to
    the Standard-IA storage class 60 days after creation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expiration actions**—These allow you to delete objects from the S3 storage
    system after a set number of days. For example, if you do not require old log
    files after 365 days, you can set a rule to automatically expire those objects
    after 365 days, which will purge them from the storage platform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use a combination of transition actions and expiration actions as well.
    For example, you may have log data that you frequently access for the first 30
    days. After that, you may still need to revisit that data for a period of 180
    days, post which you no longer require it. You can set a combination rule to transition
    the log files after 30 days of creation from the Standard class to the Standard-IA
    class, then create another expiration action to purge the data after 180 days.
  prefs: []
  type: TYPE_NORMAL
- en: You can also apply different lifecycle actions to versioned data—for example,
    you can have one set of rules and actions against the current version of your
    objects and another set for previous versions. This further allows you to manage
    your objects more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: S3 encryption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All data uploaded to Amazon S3 is encrypted in transit using the HTTPS protocol.
    However, data stored on S3 is not modified in any way, which means that if you
    are uploading sensitive data in plaintext, the data is stored unencrypted by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add an additional layer of security, you can encrypt the data before storing
    it in S3\. This is known as encryption at rest. AWS offers two options for encrypting
    your data at rest, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Server-side encryption**—When you upload (create) an object, Amazon S3 encrypts
    it before saving it to disk, and when you download/request an object, it is automatically
    decrypted by the S3 service. You have three mutually exclusive options when deciding
    to encrypt your objects using server-side encryption, outlined as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a) **Server-side encryption** with **Amazon S3-managed keys** (**SSE-S3**)—
    Amazon encrypts your data with a 256-bit **Advanced Encryption Standard** (**AES-256**).
    Each object is encrypted with a unique key, and the key itself is further encrypted
    with a master key that AWS rotates and manages for you.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) **Server-side encryption** with **customer master keys** (**CMKs**) stored
    in AWS **Key Management Service** (**SSE-KMS**)—This is similar to SSE-S3 but
    with added features, including the ability to create and manage your own CMKs,
    as well as an auditing feature that shows when your CMK was used and by whom.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) **Server-side encryption** with **customer provided keys** (**CPKs**) (**SSE-C**)—Encryption
    is performed by Amazon S3, but with CPKs. This is ideal if you need to follow
    regulatory requirements of creating and managing your own keys.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Client-side encryption**—This is where data is encrypted on the client side
    and the encrypted data is then uploaded to Amazon S3\. The full encryption process
    is therefore managed by the customer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static website hosting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to storing data, Amazon S3 also offers a service for hosting complete
    websites for your company. The only limitation is that the web hosting service
    is designed to host static websites only, as opposed to dynamic websites.
  prefs: []
  type: TYPE_NORMAL
- en: The primary difference is that while the content stored on Amazon S3 to deliver
    the complete website can be changed and updated, it remains constant and *static*,
    and all users accessing the site will see the same content.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic websites use server-side scripting to deliver dynamic content that changes
    in-flight depending on various parameters, and generally connect to a backend
    database to fetch content.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, static websites can also provide complete end-to-end solutions
    and serve several use cases at a fraction of the cost. In addition to hosting
    and delivering digital assets such as **HyperText Transfer Markup** (**HTML**)
    files, **Cascading Style Sheets** (**CSS**), **Portable Document Format** (**PDF**)
    documents, images, and videos, you can also host client-side scripts that run
    in the client browser to offer additional features that can include interactive
    elements—for example, you can run a client-side script on a S3 static website
    to collect email addresses for potential customers and store them with a third-party
    email-campaign service provider. You can also host scripts that access additional
    AWS services. Having lambda functions and, potentially, **Elastic Container Service**
    (**ECS**) or **Elastic Kubernetes Service** (**EKS**) as backends allows you to
    run anything starting from a static website. Ultimately, you have a wide range
    of use cases for hosting static websites on Amazon S3\. Owing to its highly available
    and scalable nature to handle large volumes of traffic, Amazon S3 can prove to
    be a better solution than hosting static sites across a fleet of EC2 instances,
    depending on your use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of considering the Amazon S3 static website hosting service include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Developing a product-prelaunch website**—Often, when you need to advertise
    a pre-launch campaign of a new product range, you may not be able to gauge the
    amount of traffic you might generate. Hosting the same solution on a fleet of
    EC2 instances may be more costly since you may need to scale out fast and utilize
    a large server farm if your marketing campaigns have been particularly successful.
    By way of contrast, the scalable nature of S3 will ensure that demand is met automatically
    with the inflow of large amounts of traffic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Offloading**—With Amazon S3, you get a highly scalable, reliable, and low-latency
    data storage solution. Even if you host dynamic websites that run on expensive
    EC2 instances and EBS volumes, you are likely to have a large volume of static
    content (such as documents, images, and videos, for example). You could offload
    such static content to an S3 bucket and reference it via API calls from all sites
    hosted on EC2 instances. The benefits include low storage costs for your digital
    assets and, because your servers are kept lean, you also get better performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**"Lite" version of website or "Under Maintenance" banners**—Sometimes, you
    need to host an alternative version of your site when you are performing upgrades
    or rolling out major updates. By hosting a *lite* static version of your site
    on an S3 bucket, you can easily redirect request to the S3 buckets during periods
    of maintenance or major updates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we looked at the fundamentals of Amazon S3 on AWS and learned
    about its various features. In the next section, we look at some additional services,
    covering transfer of data and archiving.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3TA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you host an S3 bucket in a specific Region but require users across the globe
    to upload objects to it, your users may experience longer and unexpected variable
    speeds for uploads and downloads over the internet, depending on where they are
    based. S3TA reduces this speed variability that is often experienced due to the
    architecture of the public internet. S3TA routes your uploads via Amazon CloudFront's
    globally distributed edge locations and AWS backbone networks. This, in turn,
    gives faster speeds and consistently low latency for your data transfers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a screenshot of a S3TA speed checker that uploads a sample file from
    your browser to various S3 Regions and compares the speed results between standard
    internet upload versus uploads via S3TA. You can try out the speed test at [https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html](https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Amazon S3TA speed test'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.5 – Amazon S3TA speed test
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we introduced you to the Amazon S3 service and discussed its
    various feature sets. Amazon S3 is an object storage solution designed to help
    customers store any amount of data in the cloud. With features such as versioning,
    CRR/SRR, encryption, and static website hosting, you can use Amazon S3 for a wide
    range of use cases at affordable storage costs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we look at some additional features of the Amazon Glacier
    services, which offer an archival storage solution.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about archiving solutions with Amazon S3 Glacier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier in this chapter, we introduced you to the Amazon S3 Glacier and Glacier
    Deep Archive storage classes. Amazon Glacier offers long-term storage at very
    a low cost and is intended to be used for archival storage. The architecture offers
    the same 99.999999999% (eleven 9s) of durability so that in the event of a major
    disaster, you can rest assured that your old archives will be available to recover
    if the need arises. The technology works differently from standard S3 storage.
    The archives need to be requested before you can access/download them, which involves
    a two-step process of first creating a retrieval job and then downloading your
    data once the job is complete.
  prefs: []
  type: TYPE_NORMAL
- en: This retrieval process can take some time and depends on your chosen retrieval
    options, as previously discussed. However, the upside to this delay in being able
    to access your data is that you get some of the cheapest storage options on the
    Amazon platform.
  prefs: []
  type: TYPE_NORMAL
- en: Archives and vaults
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As with other Amazon S3 storage classes, you can store any amount of data in
    the Glacier class. However, your objects are stored as archives, and an archive
    can contain either a single file or multiple files clubbed together in a `.zip`
    or `.tar` format. The size of your archive can between 1 byte and 40 terabytes.
    On Amazon S3, a single object can only be a maximum of 5 TB.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, archives can be grouped and stored in vaults. When you create a
    vault, you need to specify the Region in which it will be created. Vaults also
    let you define access and notification policies, and you can have up to 1,000
    vaults per Region. A vault policy enables you to define who can access it and
    which actions can be performed on it. You can also define vault lock policies,
    such as **Write Once Read Many** (**WORM)**, or time-based record-retention policies
    for regulatory archives.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As previously discussed, access to your archives in Amazon Glacier is not instantaneous.
    Depending on the Glacier storage class you choose (Glacier versus Deep Archive),
    you have the following different retrieval options available:'
  prefs: []
  type: TYPE_NORMAL
- en: a) **Amazon S3 Glacier Retrieval Options**
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard**—This is the default retrieval option and typically takes between
    3 and 5 hours to complete, before your data is made available to download.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expedited**—If you need urgent access to just a subset of your archives,
    you can opt for the Expedited retrieval option. Naturally, the cost of retrieval
    is higher than the other options. Furthermore, Expedited retrievals are made available
    within 1 to 5 minutes for archives of up to 250 **megabytes** (**MB**). In addition,
    two types of expedited retrieval options are available: On-Demand and Provisioned.
    With On-Demand, your retrieval requests are generally fulfilled within a 5-minute
    period, although during periods of high demand, this may take longer. Optionally,
    you can purchase Provisioned capacity, which ensures available retrieval capacity
    when you need it the most.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bulk** —This is designed to help you retrieve large amounts of data at the
    lowest-cost retrieval option and typically takes between 5 to 12 hours to complete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: b) **Amazon S3 Glacier Deep Archive Retrieval Options**
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard**—Retrieval of your deep archives can be achieved within 12 hours.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bulk**—Retrieval of **petabytes** (**PB**) of data within 48 hours can be
    achieved, and it is also the lowest-cost option available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we looked at archiving solutions with the Amazon S3 Glacier
    service and how you can store data for many years to fulfill compliance and regulatory
    requirements. In the next section, we look at how you can connect your on-premises
    storage services to Amazon S3\.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting your on-premises storage to AWS with Amazon Storage Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon Storage Gateway is an on-premises solution that enables you to connect
    your on-premises servers and storage systems to the Amazon S3 cloud environment.
    The service involves installing the Storage Gateway **virtual machines** (**VMs**)
    on-premises and connecting your servers to them. The gateway uses industry-standard
    protocols to then transfer data between your servers and the Amazon S3 platform.
    The VM can be deployed on either VMware ESXi or a Microsoft Hyper-V hypervisor.
    Optionally, you can also order a hardware appliance, which is a physical server
    that comes pre-installed and configured with the Storage Gateway software. This
    reduces the administration time involved in setting up your own VMs and integrates
    with your existing storage systems over protocols such as **Network File System**
    (**NFS**), SMB, and **Internet Small Computer Systems Interface** (**iSCSI**).
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Storage Gateway enables your on-premises application to connect to the
    AWS storage systems *transparently* over standard protocols such as NFS/SMB, **Virtual
    Transport Layer** (**VTL**), and iSCSI. Connectivity between the Storage Gateway
    VMs or hardware appliance to the AWS platform can be established over the internet,
    through secure IPsec **virtual private network** (**VPN**) tunnels or via AWS
    Direct Connect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon S3 Storage Gateway supports different use cases with the following deployment
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**File Gateway**—Enables you to use standard NFS SMB protocols to store data
    in Amazon S3\. Data is also cached locally, enabling low-latency access. Here,
    there are two options available, as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a) **Amazon S3 File Gateway**—This service enables you to present a file-server
    solution to your on-premises servers and access Amazon S3, where you can store
    and retrieve objects in Amazon S3 using industry-standard file protocols such
    as NFS and SMB. Furthermore, because the data is ultimately stored in S3, you
    benefit from all its features such as versioning, bucket policies, CRR, and so
    on.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) **Amazon FSx File Gateway**—This service allows you to connect your on-premises
    Windows servers or Windows-based applications (as well as Linux and macOS systems)
    to the cloud-hosted Amazon FSx for Windows File Server with low latency, and the
    ability to set up and access a virtually unlimited number of Windows file shares
    in the cloud. Amazon FSx File Gateway offers full support for SMB protocol support,
    as well as integration with **Active Directory** (**AD**) and the ability to configure
    access controls using ACLs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Volume Gateway**—Enables you to present block storage volumes to your on-premises
    servers over the iSCSI protocol. Volume Gateway can be used to asynchronously
    back up your data to Amazon S3 and comes in two different modes, outlined as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cache mode**—The bulk of your data is stored in Amazon S3, with only the
    most frequently accessed data stored locally in the cachefor low-latency connectivity.
    This means that you do not need very large amounts of local storage, which helps
    reduce your capital expenditure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stored mode**—Your data is stored locally and available for low-latency access
    on premises. This is particularly useful if your application is sensitive to latency
    for data access. The data is then asynchronously backed up to Amazon S3 and can
    be used for DR purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tape Gateway**—Many organizations use backup software solutions for their
    on-premises backup needs (for example, Veritas Backup Exec and NetBackup). Often,
    these applications back up data to physical tapes, which most companies store
    off-site. However, the tape drives, tapes, and off-site storage facilities can
    become very costly. The Tape Gateway solution comes to the rescue by enabling
    you to present virtual tapes to your backup software applications over iSCSI.
    Tape Gateway stores these virtual tapes in a **virtual tape library** (**VTL**),
    which is backed up by Amazon S3\. Data is written to these virtual tapes, which
    results in the Tape Gateway solution asynchronously uploading the data to Amazon
    S3\. When you need to restore the data, it is downloaded to the local cache, and
    the backup application can restore it to a location you specify on premises.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To manage long-term storage of old data, you can transition virtual tapes between
    Amazon S3 and Amazon S3 Glacier or Amazon S3 Glacier Deep Archive. If you later
    need to access the data on an **archived virtual tape**, you need to retrieve
    the tape and present it to your Tape Gateway solution.
  prefs: []
  type: TYPE_NORMAL
- en: Note that retrieval of an archived tape from Glacier will take between 3 and
    5 hours and from Deep Archive can take up to 12 hours.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked at how you connect your on-premises applications
    to the Amazon S3 storage service using the Storage Gateway solution. In the next
    section, we look at how you can migrate large volumes of data to the cloud using
    alternative offline methods, which is particularly useful when you have limited
    internet bandwidth.
  prefs: []
  type: TYPE_NORMAL
- en: Migrating large datasets to AWS with the AWS Snow Family
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many companies looking to move to the cloud generally host vast amounts of data
    on premises. While it is possible to transfer data over the public internet into
    Amazon S3, customers with vast amounts of data may need to consider offline methods
    of transfer due to bandwidth limitations.
  prefs: []
  type: TYPE_NORMAL
- en: AWS offers rugged devices that can be delivered to your on-premises location.
    These include the **Snowcone**, **Snowball**, and **Snowmobile** devices.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Snowball
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At its very basic offering, you simply copy large amounts of data to the device
    and ship it back to AWS to have the data imported into Amazon S3\. These devices
    are known as AWS Snowball devices and are part of the Snow Family of devices.
  prefs: []
  type: TYPE_NORMAL
- en: These edge devices come with compute and storage capabilities contained in highly
    rugged, tamper-proof devices. The devices feature a **Trusted Platform Module**
    (**TPM**) chip that detects unauthorized modifications to hardware, software,
    or firmware. These devices can be used for storage and data processing at your
    on-premises locations. Often, customers will use Snowball edge devices for migrations,
    data collections, and processing with or without internet connectivity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon Snowball comes in *two flavors*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Snowball Edge Compute Optimized**—These devices offer both storage and computing
    resources and can be used for **machine learning** (**ML**), analytics, and any
    local computing tasks. The devices come with 52 **virtual central processing units**
    (vCPUs), 208 GB of memory, and an optional NVIDIA Tesla V100 **graphics processing
    unit** (**GPU**). In terms of storage, the device offers 42 TB of **hard-disk
    drive** (**HDD**) capacity and 7.68 TB of **solid-state drive** (**SSD**) capacity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Snowball Edge Storage Optimized**—These devices offer larger storage capacity
    and are ideal for data migration tasks. With 80 TB of HDD and 1 TB of **serial
    advanced technology attachment** (**SATA**) SDD volumes, you can start moving
    large volumes of data to the cloud. The device also comes with 40 vCPUs and 80
    GB of memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Snowcone
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The smallest member of the AWS Snow Family, these devices are the smallest ever
    and weigh just 4.5 **pounds** (**lb**) (2.1 **kilograms** (**kg**)). Snowcone
    devices come with 8 TB of usable storage and are designed for outside use in areas
    of low network connectivity. Examples include IoT, vehicular, and drone use cases.
  prefs: []
  type: TYPE_NORMAL
- en: The device also offers compute capabilities with two vCPUs and 4 GB of memory,
    as well as USB-C power using a cord and optional battery.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Snowmobile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you need to transfer exabyte-scale data to the cloud, then you are going
    need an extremely large 45-foot-long *rugged* shipping container. Amazon Snowmobile
    can transfer up to 100 PB of data to the cloud and assist in all your data center
    migration efforts.
  prefs: []
  type: TYPE_NORMAL
- en: The shipping container is delivered on-site and an AWS team member will work
    with your team to connect a high-speed switch from Snowmobile to your local network.
  prefs: []
  type: TYPE_NORMAL
- en: With 24/7 video surveillance, optional escort security, and 256-bit encryption,
    you have access to the most secure way of transferring sensitive data to Amazon
    S3\.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we reviewed offline methods to transfer large amounts of data
    to the cloud and assist in your data migration efforts. The Amazon Snow Family
    offers more than just storage containers—these devices come with high levels of
    compute capabilities to perform data processing, analytics, and ML tasks as you
    copy data to them as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we review some of the key points highlighted in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.1 – Setting up an Amazon S3 bucket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this exercise, we will create an Amazon S3 bucket and upload an object to
    it. More specifically, we will upload a single web page document and test access
    to it after the upload. Since we plan to later *use* this bucket to host a static
    website and make content accessible to anyone on the internet, you will need to
    disable the **Block Public Access** setting, as discussed in the access permissions
    settings earlier in this chapter. Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: On your computer, create a new file using a standard text editor of your choice
    (Notepad on Windows or TextEdit on Mac).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following lines of code to the document:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, save it with a filename of `index` with a `.html` extension—so, the filename
    with the extension should be `index.html`. This will create a simple web page
    object for you. You may need to set the **Save as type** option to **All Files**,
    as illustrated in the following screenshot:![Figure 5.6 – Saving a file with a
    .html extension to create a web page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.6 – Saving a file with a .html extension to create a web page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, log in to your AWS account as the IAM user, **Alice**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the Amazon S3 console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Create bucket**, as illustrated in the following screenshot:![Figure
    5.7 – List of buckets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.7 – List of buckets
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the name of the bucket, type in your name followed by a hyphen (`-`) and
    the word `webpage`. Make sure there are no spaces in the name and that all lowercase
    letters are used. Assuming that the name you have chosen has not already been
    taken by another customer of AWS, you should be able to use this bucket name.
    If you get an error when you create the bucket, stating that the name is not available,
    you will simply need to choose a different name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For `us-east-1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, under the **Block Public Access settings for bucket** sub-heading, uncheck
    he box for **Block all public access**. Note that for general use cases, you do
    not want to unblock public access unless your use case demands it, such as when
    trying to configure static website hosting, which we will look at later in *Exercise
    5.4*. If you do not need anonymous access such as that from end users on the public
    internet, you must always correctly configure your permissions using bucket policies,
    ACLs, or access point policies, to ensure you leverage the **principal of least
    privilege** (**PoLP**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, check the box to state that you acknowledge that the preceding settings
    could make the bucket and its objects publicly accessible, as illustrated in the
    following screenshot:![Figure 5.8 – Turning off block all public access on your
    bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.8 – Turning off block all public access on your bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Leave all other settings as default and click on the **Create bucket** button
    at the bottom of the screen. Your Amazon S3 bucket has now been created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, in your list of buckets in the main S3 console, select the bucket you
    just created. This will take you to the current list of objects in the bucket.
    You will note that there will be none at present.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will notice an **Upload** button. Click on this button and you will have
    the option to add files and folders, as per the following screenshot:![Figure
    5.9 – Uploading object to your bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.9 – Uploading object to your bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add the `index.html` file you created/downloaded earlier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll toward the bottom of the screen and click the **Upload** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your file will be uploaded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will note a green banner at the top of the screen to say that the upload
    has been successful. Now, go ahead and click **Exit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You are then presented with the contents of the bucket you just created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can now click on the `index.html` file in the **Objects** list, which will
    take you to the Amazon S3 properties page of the file itself.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that each object has its own URL accessible from the internet (as long
    as the permissions are correctly set), as we can see in the following screenshot:![Figure
    5.10 – Uploading the index.html object to your bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.10 – Uploading the index.html object to your bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you try to click on this object URL to open it up in another browser window,
    you will find that you cannot access it. Instead, you get an **Access Denied**
    error message. This is because access to an object via its URL has the same effect
    as trying to anonymously read the object over the public internet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although we disabled the `Allow` rule to grant access to them. You could click
    on the **Permissions** tab of the object itself and set up an ACL to enable public
    access for this object. However, as discussed previously, using bucket policies
    is a better option as these offer more features and granular control.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, we will set up a bucket policy to see how we can allow
    public access to this file.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.2 – Configuring public access to S3 buckets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this exercise, we will configure the Amazon S3 bucket with a `index.html`
    web page you created earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that you could choose to restrict access to only a set of known users—for
    example, if you wanted only IAM users in your AWS account to have access to the
    objects. You can also configure cross-account access, in which you define principals
    that belong to another AWS account and grant them specific levels of access.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, we want to grant anonymous access to the `index.html` page
    because ultimately, we will be building out a static website hosting service using
    this bucket in later exercises. Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate back to the S3 console and click on the bucket you just created, as
    illustrated in the following screenshot:![Figure 5.11 – Successful upload
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.11 – Successful upload
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Permissions** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will note that the **Block public access** has been disabled and is in an
    **Off** state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll further down until you get to **Bucket Policies**, and then click **Edit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following policy, replacing the values in the placeholder `Your-Bucket-Name`
    with the name of your S3 bucket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Click **Save Changes**. If you copied the policy correctly, the policy validator
    will not throw up any errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should then get a confirmation that the policy has been saved and, more
    importantly, you will note that the bucket's contents are now publicly accessible,
    as illustrated in the following screenshot:![Figure 5.12 – S3 Bucket permissions
    tab
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.12 – S3 Bucket permissions tab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click on the **Objects** tab again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `index.html` file to open its **S3 Properties** pane.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-mouse click on the object URL and open it in a new browser tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should find that the web page is now accessible from your browser, as illustrated
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Your index.html page in a browser window'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.13 – Your index.html page in a browser window
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have disabled block public access on this bucket as we will eventually
    be configuring it for static website hosting. In this exercise, we also uploaded
    the object, `index.html`, which is a recipe document written in HTML code.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, you will learn how to configure versioning on your bucket.
    Versioning will help you create previous copies of an object so that new uploads
    of updated content for the same object are stored as new versions of the object.
    This will enable you to prevent against accidental changes to your objects by
    being able to restore a previous version, as we will see in the upcoming exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.3 – Enabling versioning on your bucket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this exercise, we will enable versioning on the Amazon S3 bucket. As you
    update existing objects with newer versions, you can rest assured that if you
    need to revert to an older version, those versions will still exist in your bucket.
    Obviously, if you try to delete a specific version of the object itself, then
    it will be purged from the S3 platform. However, enabling versioning can help
    prevent against accidental deletions and overwrites. Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate back to the S3 console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the bucket you created earlier in *Exercise 5.1*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Properties** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will see an **Edit the Bucket Versioning** option to edit the state. At
    present, the versioning will be set to **disabled**. Note that once again you
    can suspend versioning actions, but you will not be able to disable them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Edit** in the **Bucket Versioning** section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Enable**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Save Changes**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s try to test the versioning feature next, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the location where you saved the `index.html` web page on your computer.
    Open the file with your text editor using Notepad or TextEdit (for Mac).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace the word `Blueberry` in the existing `<H1>` tag within the document
    to `Chocolate`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the file without changing the format or extension.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate back to your Amazon S3 console in your AWS account and click on the
    bucket you created earlier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Objects**, as illustrated in the following screenshot:![Figure 5.14
    – List of objects in your Amazon S3 bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.14 – List of objects in your Amazon S3 bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Upload**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Add Files**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the same `index.html` file you updated moments ago and click **Upload**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Exit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `index.html` fileagain to open up its **S3 Properties** window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Object URL**, right-mouse click on the URL and open in a new browser
    window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should find that the web page has been updated with the word **Chocolate**,
    as illustrated in the following screenshot:![Figure 5.15 – Your index.html page
    showcasing the recipe
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.15 – Your index.html page showcasing the recipe
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the Amazon S3 management console, click on the **Versions** tab, as illustrated
    in the following screenshot:![Figure 5.16 – Bucket version tab
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.16 – Bucket version tab
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that there are two versions—the original version, which has a version ID
    of `null`, and a newer version with a `null` is because it was created/uploaded
    to the bucket before we enabled versioning. Going forward, all new updates to
    this file will be assigned a new version ID, allowing you to preserve older versions
    if you ever need to access them again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this exercise, you learned how to configure versioning on your bucket. You
    were able to upload and manage multiple versions of the same object, and you discovered
    how unversioned objects have a version ID of `null`, whereas versioned objects
    have a version ID comprised of a series of characters unique to that version.
    You also discovered how to display a list of available versions of your objects
    in a version-enabled bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.4 – Setting up static website hosting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this exercise, we will configure the bucket to host a static website. When
    configured with a static website hosting service, the bucket will be configured
    with a website endpoint that you can distribute to your users, who can then access
    all the pages (assuming they are linked) using the standard HTML protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure your bucket for static website hosting, you need a minimum of
    two files— an `index.html` file and an `error.html` file. An error file is simply
    a file that the S3 static website hosting service will redirect to if there is
    a problem with the `index.html` file—for example, if it cannot find the `index.html`
    page. You could use the `error.html` file to broadcast the fact that perhaps the
    site is under maintenance. Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new HTML file using your text editor as before (either Notepad on Windows
    or TextEdit on a Mac). However, in this file, simply add a line of text along
    the lines of `This site is under maintenance`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the file as `error.html`, making sure to set the file types to **All Types**
    if you are using a Windows machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate back to the S3 console and click on your S3 bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Properties** and then scroll toward the bottom of the page, until
    you find the **Static website hosting** section heading.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Edit** and select the **Enable** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For **Hosting type**, select **Host a static website**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under the `index.html`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under the `error.html`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave all the remaining settings at their defaults and click **Save changes**
    at the bottom of the page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click on the **Objects** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Upload** and click **Add files**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `error.html` file and click **Upload**. You should then see a screen
    like this:![Figure 5.17 – Upload of updated index page to your bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.17 – Upload of updated index page to your bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Exit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this stage, your bucket has been configured for static website hosting. To
    test it, you need to access your website via the S3 website URL endpoint.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the S3 console, while still viewing the contents of the buckets (under **Objects**),
    click on the **Properties** tab again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll down till you reach the **Static website hosting** section, and you will
    note the URL is provided under the **Bucket website endpoint** heading, as illustrated
    in the following screenshot:![Figure 5.18 – Enabling static website hosting on
    your bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.18 – Enabling static website hosting on your bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Navigate to the provided URL in a new browser window, and you should find that
    the website opens with the recipe web page, as illustrated in the following screenshot:![Figure
    5.19 – Updated index.html page with the wrong heading (Chocolate)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.19 – Updated index.html page with the wrong heading (Chocolate)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you will note, the recipe is for a blueberry muffin, but the heading has
    changed to **Chocolate**. Assuming that this was an error in the update, we can
    easily revert to the previous version of this web page because we have already
    configured the bucket for versioning.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate back to the Amazon S3 bucket so that you are looking at the actual
    contents of the bucket under the **Objects** tab, as illustrated in the following
    screenshot:![Figure 5.20 – List of updated objects in your bucket
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.20 – List of updated objects in your bucket
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Notice the **List versions** toggle just below the **Objects** sub-heading.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click this toggle switch to list out all versions of all objects in your bucket,
    as illustrated in the following screenshot:![Figure 5.21 – List of objects and
    their individual versions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.21 – List of objects and their individual versions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you will note, there are two versions of the `index.html` page. The latest
    version has got a version ID and contains an incorrect recipe heading.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the checkbox to select this version and then click the **Delete** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You are then prompted to confirm your delete request by typing in the phrase
    `permanently delete` in the provided textbox, as illustrated in the following
    screenshot:![Figure 5.22 – Deleting incorrect version of the index.html page
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.22 – Deleting incorrect version of the index.html page
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click **Delete objects**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Exit**, and you will note that the version has now been deleted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on **Properties** again and then scroll down to the **Static website
    hosting** section. Open up the website URL in a new browser tab and you should
    see that the older, correct version of the web page is now displayed, as illustrated
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Previous recipe page with the correct heading (Blueberry)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.23 – Previous recipe page with the correct heading (Blueberry)
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you learned how to configure your bucket with static website
    hosting. You learned how, in this particular lab exercise, we made an error in
    the title of our web page and we were able to revert to an older versioning of
    the same document, thanks to having versioning enabled earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon S3 is one of AWS's flagship storage products and comes with unlimited
    amounts of storage capacity that is highly scalable and durable.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned about the core feature of Amazon S3, including
    versioning, lifecycle management, and replication services, and how Amazon S3
    meets a wide range of use cases. You also learned how you can build and deploy
    static website hosting on an Amazon S3 bucket and its various applications in
    the real world.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed how Amazon S3 comes with a wide range of security tools such
    as the ability to create granular access permissions via bucket policies and ACLs,
    as well as encryption of data in transit and at rest. You have also learned how
    you can connect your on-premises workloads to the Amazon S3 platform using Amazon
    Storage Gateway via the internet, a VPN, or AWS Direct Connect services.
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking to migrate large amounts of data to the cloud, you can use
    the Amazon Snowball service to help you transfer large volumes of data, using
    rugged and tamper-resistant devices that are shipped to your on-premises location.
    Once you get the data copied, you simply ship it back to AWS to have your data
    imported into your S3 environment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we discuss networking services, focusing on the **Amazon
    Virtual Private Cloud** (**VPC**) service, among others. We also look at the Amazon
    Direct Connect service and at how you can connect your on-premises network with
    your AWS cloud services using VPN technologies.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we look at some review questions for this chapter to test
    your knwoledge.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a few questions to test your knowledge:'
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following is true regarding Amazon S3? (Select 2 answers)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 is object-based storage.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 is an example of file storage.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 is an example of block storage.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The Amazon S3 One Zone-IA storage class offers 99.5% of availability. Amazon
    S3 can be configured as shared mount volumes for Linux-based EC2 instances.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You wish to enforce a policy on an S3 bucket that grants anonymous access to
    its content if users connect to the data from the corporate and branch offices
    as part of your security strategy. Which S3 configuration feature will enable
    you to define the IP ranges from where you will allow access to the data?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Security groups
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Bucket policy
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: NTFS permissions
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Network ACLs** (**NACLs**)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service is the most cost-effective if you need to host static website
    content for an upcoming product launch?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon EC2
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon EFS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure ExpressRoute
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which Amazon S3 storage class enables you to optimize costs by automatically
    moving data to the most cost-effective access tier, while ensuring that frequently
    accessed data is made available immediately?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 Standard
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 One-Zone IA
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Snowball
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 Intelligent-Tiering
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which Amazon S3 service can be configured to automatically migrate data from
    one storage class to another after a set number of days as a means of reducing
    your costs, especially where frequent instant access may not be required to that
    subset of data?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Static website hosting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lifecycle management
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Storage transition
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: S3 migration
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When retrieving data from Amazon Glacier, what is the typical time taken by
    a Standard retrieval option to make the archive available for download?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 20 minutes
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 24 hours
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 3 to 5 hours
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 90 seconds
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which feature of the Amazon S3 platform enables you to upload content to a centralized
    bucket from across any location via Amazon edge locations, ensuring faster transfer
    speeds and avoidance of public internet congestion?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3TA
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS S3 Storage Gateway
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon VPC
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CloudFront
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Your on-premises applications require access to a centrally managed cloud storage
    service. The application running on your servers need to be able to store and
    retrieve files as durable objects on Amazon S3 over standard NFS-based access
    with local caching. Which AWS service can help you deliver a solution to meet
    the aforementioned requirements?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Storage Gateway— Amazon S3File Gateway
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS EFS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Redshift
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: EBS volumes
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You are looking to migrate your on-premises data to the cloud. As part of a
    one-time data migration effort, you need to transfer over 900 TB of data to Amazon
    S3 in a couple of weeks. Which is the most cost-effective strategy to transfer
    this amount of data to the cloud?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Amazon RDS service
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Amazon Snowball service
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Amazon VPN connection between your on-premises network and AWS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use AWS Rain
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
