- en: '[*Chapter 5*](B17124_05_Final_SK_ePub.xhtml#_idTextAnchor094): Amazon Simple
    Storage Service (S3)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[*第 5 章*](B17124_05_Final_SK_ePub.xhtml#_idTextAnchor094): Amazon 简单存储服务（S3）'
- en: In this chapter, we look at one of the available storage services on **Amazon
    Web Services** (**AWS**). Many clients who are just starting on their cloud journey
    often consider storage services in the cloud as a stepping stone to going cloud-native
    in the long run. While storage options have become cheaper over the years, the
    fact remains that we continue to consume more and more storage with the passage
    of time. That said, it is vital that organizations also have a smart life cycle
    policy for their storage needs. Companies may be required to keep data for many
    years, and for as long as 7 to 10 years for compliance and regulatory purposes.
    However, at some point, a substantial amount of data is no longer required, and
    purging this data from the network not only makes management easier but also saves
    on cost.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍 **Amazon Web Services**（**AWS**）的其中一项存储服务。许多刚开始云端之旅的客户，往往将云存储服务视为长期走向云原生的垫脚石。虽然存储选项这些年来变得更为便宜，但事实依然是，随着时间的推移，我们对存储的需求不断增加。话虽如此，组织在处理存储需求时，必须制定一个智能的生命周期政策。公司可能需要根据合规性和监管要求保留数据长达
    7 到 10 年。然而，随着时间的推移，某些数据不再需要保存，从网络中清除这些数据不仅能简化管理，还能节省成本。
- en: Access to AWS storage services is extremely easy, and rather than procuring
    new storage hardware to host on-premises, it is much easier and more cost-effective
    to use the services offered by a cloud vendor such as AWS. Understandably, there
    will some types of data that need to be stored on-premises primarily because of
    latency issues, but from a security standpoint, AWS offers numerous options to
    ensure that your data is accessible only to you.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 AWS 存储服务非常简单，与其购买新的存储硬件来进行本地托管，不如使用 AWS 等云供应商提供的服务，既简单又具有成本效益。当然，某些类型的数据可能需要本地存储，主要是由于延迟问题，但从安全角度来看，AWS
    提供了多种选项，确保您的数据仅对您可访问。
- en: 'AWS offers different storage options, and in this chapter, we look at one of
    its flagship products: **Amazon Simple Storage Service** (**Amazon S3**). Amazon
    S3 is an object storage solution and offers very high levels of availability,
    durability, and scalability. AWS also offers other types of storage options, which
    we look at in subsequent chapters.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 提供不同的存储选项，本章将介绍其旗舰产品之一：**Amazon 简单存储服务**（**Amazon S3**）。Amazon S3 是一种对象存储解决方案，提供非常高的可用性、耐久性和可扩展性。AWS
    还提供其他类型的存储选项，我们将在后续章节中进行探讨。
- en: By the end of this chapter, you will understand the fundamentals of object storage
    on AWS and how Amazon S3 can help fulfill core storage requirements for your business
    in the cloud. You will also learn how about various features that can be used
    to manage your cloud storage, address regulatory and compliance concerns, and
    design cost-effective solutions. Finally, you will learn how to access your cloud
    storage from on-premises locations and how to migrate large datasets to the cloud.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解 AWS 对象存储的基础知识，以及 Amazon S3 如何帮助满足您企业在云端的核心存储需求。您还将学习如何使用各种功能来管理您的云存储、解决合规性和法规问题，并设计具有成本效益的解决方案。最后，您将学习如何从本地位置访问云存储，并如何将大型数据集迁移到云端。
- en: 'The topics in this chapter include the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主题包括以下内容：
- en: Introduction to storage options on AWS
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 存储选项简介
- en: Introduction to Amazon S3
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon S3 简介
- en: Learning about archiving solutions with Amazon S3 Glacier
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解 Amazon S3 Glacier 的归档解决方案
- en: Connecting your on-premises storage to AWS with Amazon Storage Gateway
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Storage Gateway 将您的本地存储连接到 AWS
- en: Migrating large datasets to AWS with the Amazon Snow Family
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Snow Family 将大型数据集迁移到 AWS
- en: Exercise 5.1—Setting up an Amazon S3 bucket
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习 5.1—设置一个 Amazon S3 存储桶
- en: Exercise 5.2—Configuring public access to S3 buckets
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习 5.2—配置 S3 存储桶的公共访问
- en: Exercise 5.3—Enabling versioning on your bucket
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习 5.3—启用存储桶的版本控制
- en: Exercise 5.4—Setting up static website hosting
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习 5.4—设置静态网站托管
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To complete the exercises in this chapter, you will need to have an AWS account
    via the AWS Management Console. You will need to be logged in as the IAM user,
    **Alice**, that you created in the last chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成本章中的练习，您需要通过 AWS 管理控制台拥有一个 AWS 账户。您需要使用上章创建的 IAM 用户 **Alice** 登录。
- en: Introduction to storage options on AWS
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 存储选项简介
- en: A storage service provides the necessary infrastructure to enable you to store
    and access data. However, different use cases require varied storage architectures
    to ensure performance, reliability, durability, and the right type of access to
    the data. There are three primary storage options available, and AWS offers services
    to cater to each of these.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 存储服务提供了必要的基础设施，帮助你存储和访问数据。然而，不同的使用场景需要不同的存储架构，以确保性能、可靠性、持久性和对数据的正确访问类型。AWS 提供了三种主要的存储选项，每一种都能满足不同的需求。
- en: Block storage
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 块存储
- en: '**Block storage** is an architectural design that enables the storage of data
    onto media such as a hard disk, in fixed-sized chunks. Data is broken up into
    small blocks and placed on the media in these chunks, with a unique address assigned
    that forms part of its metadata. Block storage makes use of a management software
    (which can be part of the operating system) to organize the blocks of data. When
    a user tries to retrieve a file, the management software identifies the blocks
    to retrieve, reassembles the data, and presents the whole file to the user.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**块存储**是一种架构设计，它将数据存储在硬盘等介质上，分成固定大小的块。数据被拆分成小块，并按这些块放置在介质上，每个块分配一个唯一的地址，作为其元数据的一部分。块存储利用管理软件（通常是操作系统的一部分）来组织这些数据块。当用户尝试检索文件时，管理软件会识别要检索的块，重新组装数据，并将整个文件呈现给用户。'
- en: On AWS, block storage options are available as **Elastic Block Store** (**EBS**).
    These can be configured as volumes attached to your **Elastic Compute Cloud**
    (**EC2**) instances and offer ultra-low latency required for high-performance
    workloads. One advantage of EBS volumes is that they are not directly attached
    to the EC2 instance you deploy, but instead are connected via high-speed network
    links. This allows you to detach an EBS volume from one EC2 instance and attach
    it to another if, for example, the first EC2 instance experiences some sort of
    failure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 上，块存储选项包括**弹性块存储**（**EBS**）。这些可以配置为附加到你的**弹性计算云**（**EC2**）实例的卷，并提供高性能工作负载所需的超低延迟。EBS
    卷的一个优点是，它们并不是直接附加到你部署的 EC2 实例，而是通过高速网络连接。这使得你可以将一个 EBS 卷从一个 EC2 实例上卸载，并将其附加到另一个实例上，例如，当第一个
    EC2 实例发生故障时。
- en: Typical use cases include running and managing system files such as those used
    by your operating system, large databases, or for applications such as **enterprise
    resource planning** (**ERP**) solutions. These types of applications require very
    low-latency access to the data and generally make use of **direct-attached storage**
    (**DAS**) or **storage area networks** (**SANs**).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的使用场景包括运行和管理系统文件，例如操作系统使用的文件、大型数据库，或者像**企业资源规划**（**ERP**）解决方案这样的应用程序。这些类型的应用程序需要非常低延迟的数据访问，通常会使用**直接附加存储**（**DAS**）或**存储区域网络**（**SANs**）。
- en: File storage
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文件存储
- en: Another storage architectural design is **file storage**. The architecture offers
    a centralized location for your corporate data, and files are stored in folders
    and sub-folders. File storage offers a hierarchical structure to store your data,
    and this means you can imitate your real-life counterpart—the filing cabinet—to
    organize your data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种存储架构设计是**文件存储**。该架构为您的企业数据提供了一个集中的位置，文件存储在文件夹和子文件夹中。文件存储提供了一种层次结构来存储数据，这意味着你可以模仿现实生活中的文件柜来组织数据。
- en: Retrieval of the data requires you to know the file and folder structure and
    provide this information. For example, if I need last August's balance sheet Excel
    document, I will need to look in the `2020` folder and the `August` sub-folder,
    and this would enable me to retrieve that specific data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的检索需要你了解文件和文件夹结构并提供相关信息。例如，如果我需要查看去年八月的资产负债表 Excel 文件，我需要查找`2020`文件夹和`August`子文件夹，这样我就能检索到那个特定的数据。
- en: Due to the nature of file storage, metadata information can be limited, and
    a key limitation to be aware of is that you cannot have unlimited folders and
    sub-folders due to your operating system restrictions. Your hierarchical structure
    can also be the cause of some performance issues, and therefore you need to decide
    on this structure carefully.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文件存储的特性，元数据可能有限，需要注意的一个关键限制是，由于操作系统的限制，你不能无限制地创建文件夹和子文件夹。你的层次结构也可能导致一些性能问题，因此你需要仔细决定这一结构。
- en: File storage lends itself well to being used for file sharing within a corporate
    organization. Because of the folder/sub-folder architecture, it becomes very easy
    to organize your data to fit in well with your organizational structure.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon offers three different file storage systems, outlined as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '**Elastic File System** (**EFS**)—This is a managed elastic filesystem designed
    to let you share file data without provisioning or managing storage as you would
    with EBS. Your filesystem will grow and shrink as you add and remove data, and
    mount points can only be created on Linux EC2 instances.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FSx for Lustre**—A high-performance filesystem designed for applications
    that require fast storage and can scale to hundreds of **gigabytes** (**GB**)
    of throughput and millions of **input/output operations per second** (**IOPS**).
    FSx for Lustre is also designed for a wide range of Linux-based EC2 instances.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FSx for Windows File Server**—Designed for Microsoft Windows EC2 instances
    and offers a fully managed file-share solution, natively supporting the Windows
    file system such as the industry-standard **Server Message Block** (**SMB**) protocol.
    Typical use cases include file-sharing services, local archiving, application
    data sharing, and data protection.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object storage
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By contrast, **object storage** involves storing complete files as individual
    objects. Object storage presents a flat file structure—you create some form of
    container and place your objects within this container without using any folder
    or file-level hierarchy. This is also known as unstructured data. Object storage
    metadata (information about the object—such as its name, and so on), along with
    other attributes, is then used to create a unique identifier to easily locate
    that data in your storage pool. Due to the nature of object storage, the metadata
    can contain a vast array of information, enabling you to use object storage for
    data analytics far more easily than a file-based storage solution.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: An additional benefit is that object storage lends itself well to offering higher
    levels of performance, durability, and scalability. In a file-level storage solution,
    the depth of the folder and file structure will often have a limit based on the
    operating system you are using. With object storage, however, you can potentially
    scale to having limitless amounts of data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: The flat file structure is another advantage point as this enables you to retrieve
    data much faster due to the extended categorization feature, as opposed to retrieving
    data from a file storage service.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: On AWS, object storage options are available with the Amazon S3 service. Amazon
    S3 lets you create containers called **buckets**, within which you place your
    data (objects) in a flat file structure (unstructured manner). You can store and
    retrieve any amount of data—anytime, anywhere.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Typical use cases for object storage include storing digital assets for your
    websites and applications (documents, images, video), the ability to perform analytics
    on your objects, and offering storage solutions to cutting-edge technologies such
    as **Internet of Things** (**IoT**).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked at the three main types of storage options available,
    their key features, and typical use cases. We also highlighted some examples of
    AWS services that offer storage solutions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will introduce you to the Amazon S3 service, which is
    an object storage solution for the cloud.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Amazon S3
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon S3 is one of Amazon's flagship products, and offers a robust, scalable,
    durable, and cost-effective **object storage** solution in the cloud. Customers
    can use Amazon S3 to store any amount of data for a wide range of use cases, including
    digital media content for websites, data lakes, mobile applications, IoT device
    data, and big data analytics.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 can offer up to 99.999999999% durability and fulfills the storage
    requirements for a majority of clients and their individual business needs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'What does eleven 9s of durability mean? According to AWS, if you store 10,000,000
    objects on Amazon S3, then on average you can expect to incur a loss of a single
    object once every 10,000 years. You can review all **frequently asked questions**
    (**FAQs**) for Amazon S3 here: [https://aws.amazon.com/s3/faqs/](https://aws.amazon.com/s3/faqs/).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Buckets and objects
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before you can upload any data to Amazon S3, you need to create a container
    called a bucket. Buckets need to have a unique global namespace as their contents
    can be made accessible over the public internet. This means that your bucket names
    must be unique across the AWS ecosystem. For example, a document named `blueberry-muffin.txt`
    stored in a bucket named `just-desserts` can be accessible via the internet in
    two primary ways, outlined as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '`blueberry-muffin.txt` object is accessible via the S3 **Uniform Resource Locator**
    (**URL**), such as [https://just-desserts.s3.amazonaws.com/blueberry-muffin.txt](https://just-desserts.s3.amazonaws.com/blueberry-muffin.txt).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s3-website` dash (`-`) Region—`http://bucket-name.s3-website-Region.amazonaws.com`.
    For example, our recipe will be available at [http://just-desserts.s3-website-us-east-1.amazonaws.com/blueberry-muffin.txt](http://just-desserts.s3-website-us-east-1.amazonaws.com/blueberry-muffin.txt).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: b) `s3-website` dot (`.`) Region—`http://bucket-name.s3-website.Region.amazonaws.com`.
    For example, our recipe will be available at [http://just-desserts.s3-website.us-east-1.amazonaws.com/blueberry-muffic.txt](http://just-desserts.s3-website.us-east-1.amazonaws.com/blueberry-muffic.txt).
    We look at static website hosting on Amazon S3 later in this chapter.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: When creating buckets, you may therefore find that common names are not available.
    For example, if you wanted to create a bucket name called `marketing`, then you
    will most likely not be able to use this name as it may have been used already.
    You could instead create a marketing bucket with a unique prefix or suffix to
    get an appropriate name. Most companies will try to associate their bucket names
    with their organization name or project name—for example, your marketing bucket
    name could be `my-company-marketing`. That said, you still cannot solely depend
    on any specific naming convention you define for your buckets, because another
    customer may have chosen the exact same name that you might have wanted, and bucket
    names are defined on a first-come first-serve basis.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建存储桶时，您可能会发现常见的名称不可用。例如，如果您想创建名为`marketing`的存储桶，那么您很可能无法使用这个名称，因为它可能已经被使用了。您可以通过创建带有独特前缀或后缀的营销存储桶来获得合适的名称。大多数公司会尝试将存储桶名称与其组织名称或项目名称相关联——例如，您的营销存储桶名称可以是`my-company-marketing`。也就是说，您仍然不能仅依赖于您为存储桶定义的任何特定命名约定，因为另一个客户可能选择了您可能想要的相同名称，并且存储桶名称是按先到先得的原则定义的。
- en: 'Some key attributes of Amazon S3 buckets are provided here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Amazon S3 存储桶的一些关键属性：
- en: Bucket names must be between 3 and 63 characters long.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储桶名称必须介于 3 到 63 个字符之间。
- en: Bucket names must always be in lowercase letters. They can, however, contain
    numbers, hyphens (`-`), and dots (`.`) only.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储桶名称必须始终为小写字母。然而，它们只能包含数字、连字符（`-`）和点（`.`）。
- en: Bucket names must also begin and end with either a letter or number and should
    not include spaces between the names.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储桶名称必须以字母或数字开头和结尾，并且名称之间不能包含空格。
- en: Bucket names must not be formatted as an `192.168.1.1`).
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储桶名称不能格式化为`192.168.1.1`）。
- en: Buckets used with `.`) in their names. We discuss Amazon S3TA later in this
    chapter.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储桶名称不能包含`。）`。我们将在本章后面讨论 Amazon S3TA。
- en: You cannot have nested buckets—for example, a bucket within another bucket.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不能创建嵌套的存储桶——例如，在一个存储桶中再创建一个存储桶。
- en: Important note
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: Except for website-style endpoints, you should avoid using dots (`.`) as part
    of your bucket names as they cannot be used with virtual hosted-style endpoints
    using **Secure Sockets Layer** (**SSL**) and the **HyperText Transfer Protocol
    Secure** (**HTTPS**) protocol. Note that the only reason they work with website-style
    endpoints is because static website hosting is only available over HTTP. You can
    get around this problem if you need to serve your content over HTTPS by incorporating
    a Amazon CloudFront distribution point. We discuss CloudFront in [*Chapter 6*](B17124_06_Final_SK_ePub.xhtml#_idTextAnchor122),
    *AWS Networking Services – VPCs, Route53, and CloudFront*.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了网站风格的端点，您应避免在存储桶名称中使用点（`.`），因为它们无法与使用**安全套接字层**（**SSL**）和**安全超文本传输协议**（**HTTPS**）的虚拟托管风格端点一起使用。请注意，它们与网站风格的端点一起使用的唯一原因是静态网站托管仅通过
    HTTP 提供。如果您需要通过 HTTPS 提供内容，可以通过结合使用 Amazon CloudFront 分发点来解决此问题。我们将在[ *第6章* ](B17124_06_Final_SK_ePub.xhtml#_idTextAnchor122)中讨论
    CloudFront，*AWS 网络服务 – VPC、Route53 和 CloudFront*。
- en: Any data stored in an Amazon S3 bucket is represented as an **object**. An object
    is stored in its entirety within a given bucket rather than with block storage,
    where a file may be broken up into chunks and stored on a given media such as
    a hard disk. As discussed previously, objects are stored in an unstructured manner
    as a **flat filesystem**. This means that accessing an object requires you to
    know its unique ID, which is generally part of the object's metadata. You can
    store an unlimited number of objects within a given bucket, and the maximum size
    of an object on Amazon S3 is 5 **terabytes** (**TB**).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在 Amazon S3 存储桶中的任何数据都表示为一个**对象**。对象是完整地存储在给定存储桶中，而不是像块存储那样，文件可能会被拆分成块并存储在硬盘等介质上。如前所述，对象是以**扁平文件系统**的方式存储的。这意味着访问一个对象需要知道它的唯一
    ID，这通常是对象元数据的一部分。您可以在一个存储桶中存储无限数量的对象，且 Amazon S3 上单个对象的最大大小为 5 **TB**（**太字节**）。
- en: The filename of an object is called a `!`, `-`, `_`, `.`, `*`, and `( )`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对象的文件名被称为`!`、`-`、`_`、`.`、`*`和`()`。
- en: Managing your objects in a bucket
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理存储桶中的对象
- en: As mentioned previously, objects are stored in a `/`) parameters to help you
    manage and browse your objects in a hierarchical fashion.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，对象存储在`/`）参数中，帮助您以层次化方式管理和浏览对象。
- en: 'At first glance, the usage of prefixes and delimiters (`/`) appears as a typical
    folder hierarchy, but the prefixes and delimiters themselves also form part of
    the object''s **key**, as we can see in the following screenshot:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Amazon S3 prefixes and delimiter example'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_01.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 – Amazon S3 prefixes and delimiter example
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the preceding screenshot, a file (object) called [*Chapter
    5*](B17124_05_Final_SK_ePub.xhtml#_idTextAnchor094) `– Amazon Simple Storage Service
    S3.docx` appears to be stored in a `cloud-practitioner` sub-folder, under another
    sub-folder named `campaign`, in a bucket named `packt-marketing`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: This architecture allows you to better manage your objects, but the fact remains
    that the keys of the object itself comprise those prefixes and delimiters. This
    means that the `development/sourcecodes.php` and `production/sourcecodes.php`
    keys can reside in the same bucket and are considered unique objects because of
    the different prefixes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Prefixes are also used to help you limit search results to only those keys that
    begin with a specific prefix name. In addition, delimiters enable you to perform
    list operations such that all the keys that share a common prefix can be retrieved
    as a single summary list result.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Prefixes further enhance performance when it comes to accessing your objects
    in Amazon S3\. For example, you can achieve 3,500 `PUT`/`COPY`/`POST`/`DELETE`
    or 5,500`GET`/`HEAD` operations per second per `GET` operations.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Regional hosting – global availability
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your buckets and the objects contained within them are globally accessible if
    you define the necessary permissions. However, it is important to realize that
    a given bucket and any objects it holds are stored in one specific Region alone.
    When you create an Amazon S3 bucket in your AWS account using either the web console,
    **command-line interface** (**CLI**), or via **application programming interface**
    (**API**) access, you must specify the **Region** in which you wish to create
    it.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'Your choice of the Region to create a given bucket is going to depend on several
    factors, including the following ones:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing latency by creating buckets closer to end users who need access to
    them
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimizing costs
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Addressing any regulatory requirements such as data-sovereignty laws
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon will *never* replicate your data outside of the Region in which you create
    it. This offers the assurance that you can meet and adhere to any data-residency
    laws you may be required to follow as a business.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: You can, however, replicate the contents of one bucket in a given Region to
    another bucket in a different Region for several use cases, including **disaster
    recovery** (**DR**) or sharing content with your colleagues, such that the data
    is closer to them to reduce overall latency.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Access permissions
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create and manage your Amazon S3 buckets and upload and download objects
    to the bucket, you need to define the necessary permissions. By default, only
    the resource owner, which is the AWS account that creates the resource, can access
    a bucket.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建和管理您的 Amazon S3 桶并上传和下载对象到桶中，您需要定义必要的权限。默认情况下，只有资源所有者，即创建资源的 AWS 账户，才能访问桶。
- en: However, you can also grant access to other users in your account, as well as
    define permissions for specific **Identity and Access Management** (**IAM**) roles
    to have access to those resources. In addition, you can grant access to users
    in other AWS accounts, and even grant access to members of the public by configuring
    anonymous access. Anonymous access is ideal when you wish to host publicly accessible
    digital assets such as documents, images, and videos for your websites.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您还可以授予您账户中其他用户的访问权限，并为特定的**身份和访问管理**（**IAM**）角色定义权限，以使其能够访问这些资源。此外，您还可以授予其他
    AWS 账户的用户访问权限，甚至通过配置匿名访问来授予公众成员访问权限。当您希望为网站托管公开可访问的数字资产（如文档、图片和视频）时，匿名访问是理想的选择。
- en: Amazon S3 offers two primary methods of granting access to resources such as
    buckets and objects. You can attach a resource-based policy known as a bucket
    policy, or you can attach **access-control lists** (**ACLs**). Let's examine both
    of these methods for granting access next.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 S3 提供两种主要方法来授予对资源（如桶和对象）的访问权限。您可以附加一个称为桶策略的基于资源的策略，或者您可以附加**访问控制列表**（**ACL**）。接下来，让我们研究这两种授予访问权限的方法。
- en: Bucket policies
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 桶策略
- en: A bucket policy is applied directly to an entire bucket and can be used to grant
    access to both the bucket itself and the objects stored within it. Bucket policies
    can be used to specify different levels of access for different types of objects
    within the same policy document. A bucket policy document is also written in **JavaScript
    Object Notation Format** (**JSON**) format, just like IAM policies are.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 桶策略直接应用于整个桶，并可用于授予对桶本身及其中存储的对象的访问权限。桶策略可用于为同一策略文档中的不同类型对象指定不同级别的访问权限。桶策略文档也采用**JavaScript
    对象表示法格式**（**JSON**），就像 IAM 策略一样。
- en: With bucket policies, you can also grant anonymous access to object in your
    buckets, such as a web page, image, or video, which means that anyone with the
    S3 object URL can access it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用桶策略，您还可以授予对桶中对象的匿名访问权限，例如网页、图片或视频，这意味着任何拥有 S3 对象 URL 的人都可以访问它。
- en: Bucket policies are very flexible and allow you to grant cross-account access
    too. This means that if users in other AWS accounts are permitted, you can grant
    them access to your buckets by specifying their account ID and their IAM user
    **Amazon Resource Name** (**ARN**).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 桶策略非常灵活，允许您授予跨账户访问权限。这意味着，如果其他 AWS 账户的用户被允许访问，您可以通过指定其账户 ID 和 IAM 用户的**亚马逊资源名称**（**ARN**）来授予他们对您桶的访问权限。
- en: 'Here is an example of a typical bucket policy granting anonymous access to
    the objects it contains:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的桶策略示例，授予匿名访问它所包含对象的权限：
- en: '![Figure 5.2 – Bucket policy example granting anonymous access to the'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.2 – 桶策略示例，授予匿名访问权限'
- en: contents of the 'packt-marketing' S3 bucket
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '''packt-marketing'' S3 桶的内容'
- en: '](img/B17124_05_02.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17124_05_02.jpg)'
- en: Figure 5.2 – Bucket policy example granting anonymous access to the contents
    of the 'packt-marketing' S3 bucket
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 桶策略示例，授予对 'packt-marketing' S3 桶内容的匿名访问权限
- en: As seen in the preceding screenshot, the policy allows anonymous access by specifying
    the `Principal` attribute as a wildcard (`*`), which indicates everyone. The action
    allowed on the `packt-marketing` bucket is `s3:GetObject`, which restricts access
    to only being able to read/download the object(s).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，策略通过将 `Principal` 属性指定为通配符（`*`）来允许匿名访问，这表示所有人。对 `packt-marketing` 桶的允许操作是
    `s3:GetObject`，这限制了只能读取/下载对象。
- en: 'Another element that can be added to a bucket policy is a `Effect` attribute
    of a policy to `Deny` unless the condition is met. For example, you can restrict
    the ability for users to access and download contents from an S3 bucket, unless
    the request originates from a range of IP addresses specified in the condition,
    as illustrated in the following screenshot:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 桶策略中可以添加的另一个元素是策略的 `Effect` 属性，该属性设置为 `Deny`，除非满足特定条件。例如，您可以限制用户访问和下载 S3 桶中的内容，除非请求来自条件中指定的
    IP 地址范围，如下图所示：
- en: '![Figure 5.3 – Bucket policy defined with a conditional statement'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.3 – 定义有条件语句的桶策略'
- en: '](img/B17124_05_03.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17124_05_03.jpg)'
- en: Figure 5.3 – Bucket policy defined with a conditional statement
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 使用条件语句定义的桶策略
- en: In the preceding screenshot, you will note that the `Effect` attribute of the
    policy is to deny access unless the `NotIPAddress` condition is met. You will
    need to replace the dummy IP address range shown (`w.x.y.z/c`) with a real IP
    address range for your use case.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，你会注意到策略的`Effect`属性是拒绝访问，除非满足`NotIPAddress`条件。你需要将示例中的虚拟IP地址范围（`w.x.y.z/c`）替换为适合你使用案例的真实IP地址范围。
- en: Bucket and object ACLs
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 桶和对象ACL
- en: ACLs are now considered legacy control systems because bucket policies tend
    to be flexible and offer more granular levels of access. You can mostly use ACLs
    to grant anonymous access to objects and buckets, or to other AWS accounts. Since
    ACLs do not allow you to specify an individual IAM user as the grantee of those
    permissions, their use case is limited and preference is given to bucket policies
    instead.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ACL现在被视为遗留的控制系统，因为桶策略通常更灵活，且提供更细粒度的访问控制。你通常可以使用ACL为对象和桶授予匿名访问权限，或授予其他AWS账户访问权限。由于ACL不允许你指定单个IAM用户作为这些权限的受益人，因此它们的使用案例有限，通常更倾向于使用桶策略。
- en: However, certain features require you to configure ACLs instead of bucket policies.
    **Server access logging**, for example, is a feature you can enable to provide
    detailed records for the requests that are made to an Amazon S3 bucket.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，某些功能需要你配置ACL而非桶策略。例如，**服务器访问日志**是一项你可以启用的功能，用于提供对Amazon S3桶请求的详细记录。
- en: IAM policies
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IAM策略
- en: As previously discussed in [*Chapter 4*](B17124_04_Final_SK_ePub.xhtml#_idTextAnchor068),
    *Identity and Access Management*, you can create IAM policies that are assigned
    to IAM identities (such as IAM users, groups of users, or IAM roles) and define
    what they can or cannot do with any specific service and/or resource in your AWS
    account.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[*第4章*](B17124_04_Final_SK_ePub.xhtml#_idTextAnchor068)中所讨论的，*身份和访问管理*，你可以创建分配给IAM身份（如IAM用户、用户组或IAM角色）的IAM策略，并定义它们可以或不能对你的AWS账户中的任何特定服务和/或资源执行的操作。
- en: You can, therefore, grant your IAM principals access to S3 buckets and objects
    contained within those buckets. However, IAM policies cannot be attached directly
    to the resource. Furthermore, you cannot attach an IAM policy directly to an IAM
    user in another AWS account. You would first need to create an IAM role with the
    necessary permissions and then enable a trust policy for the IAM user in the other
    AWS account to be able to assume the role.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以授予IAM主体对S3桶及其中包含的对象的访问权限。然而，IAM策略不能直接附加到资源上。此外，你不能将IAM策略直接附加到另一个AWS账户中的IAM用户。你需要首先创建一个拥有必要权限的IAM角色，然后为另一个AWS账户中的IAM用户启用信任策略，以便该用户能够承担此角色。
- en: Finally, IAM policies cannot be used to grant anonymous access because of the
    simple principle that IAM policies can only be attached to an IAM identity.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，IAM策略不能用于授予匿名访问权限，因为有一个简单的原则：IAM策略只能附加到IAM身份上。
- en: Note
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can use a combination of bucket policies, ACLs, and IAM policies to grant
    access. You must remember, however, that any conflicting `Deny` permission will
    always override an `Allow` permission. However, these policy options are not mutually
    exclusive.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以结合使用桶策略、ACL和IAM策略来授予访问权限。然而，你必须记住，任何冲突的`Deny`权限都会始终覆盖`Allow`权限。不过，这些策略选项并不是相互排斥的。
- en: Choosing the right S3 storage class
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择正确的S3存储类
- en: Amazon S3 allows you store an unlimited amount of data in the cloud. However,
    not all data needs to be treated the same. For example, you may have some data
    that you require instant access to, but also other types of data that may be rarely
    accessed as it represents old archives stored for compliance purposes.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊S3允许你在云中存储无限量的数据。然而，并非所有数据都需要相同的处理方式。例如，你可能有些数据需要即时访问，但也有其他类型的数据可能很少被访问，因为它们是为了合规目的存储的旧档案。
- en: You may also have some data that you can afford to lose because recreating it
    would be easy, whereas other types of data may be simply irreplaceable. Depending
    on the data, its importance, and access patterns, AWS offers different storage
    classes for different use cases. So, for example, if you need to store old archives,
    you have the Amazon Glacier storage class, and if you need instant rapid access
    to your data, you have the Amazon S3 Standard storage class. All storage classes
    offer 99.999999999% **durability** for your data. Durability refers to long-term
    data protection, and AWS offers the necessary infrastructure and processes to
    manage your data, replicate copies, ensure data redundancy, and safeguard against
    degradation or other corruption.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the storage class that you choose to store your data in, AWS also
    offers different levels of **availability**, which determines the percentage of
    time an object is available for retrieval, based on the underlying storage system
    being operational (or the Region and **Availability Zones** (**AZs**) being online
    and accessible). Critical data such as digital assets, medical records, or financial
    statements would be ideal candidates for those storage classes that offer higher
    levels of availability. However, secondary copies of data may not need to be as
    available as the primary copies of the same data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 charges are based around six cost components. These comprise the storage
    itself (comprising the amount of storage, duration, and storage class your objects
    are placed in), requests and data retrievals, data transfers, use of transfer
    acceleration, data management, and analytics, and the use of an Amazon S3 Object
    Lambda (which is the ability to modify and process data as it is returned to an
    application using Lambda functions). Note—data transferred in from the internet
    to an S3 bucket is free. One way of minimizing costs is to identify data that
    may not require instance access or that may be replaceable and store it in classes
    that are cheaper.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: A key point to note here is that you can host different objects under different
    storage classes within the same bucket. You do not need to create separate buckets
    for each storage class.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at the different storage classes next.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Frequent access
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazon S3 Standard**—This is the default storage class when you upload objects
    to a bucket, unless you specify otherwise. Amazon S3 Standard offers the full
    eleven 9s (99.9999999%) of durability and four 9s (99.99%) of availability. With
    Amazon S3 Standard, your objects are always replicated across a minimum of three
    AZs in the Region you place them in.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Infrequent access
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon S3 offers two types of infrequent-access storage classes. These can be
    used to store objects that you are not going to frequently access, but at the
    same time, you have instant access to the data when you need it.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: AWS offers these classes at lower costs on the condition that you do not access
    your data frequently, as you would with the Standard storage class. To enforce
    the conditions, AWS will charge additional retrieval fees. Furthermore, there
    is a minimum object size of 128 **kilobytes** (**KB**). You can still store objects
    under this minimum size, but those objects will be billed as though it is a minimum
    of 128 KB in size.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon S3 Standard-Infrequent Access** (**S3 Standard-IA**)—S3 Standard-IA
    is designed for data that is just as critical as with the Standard storage class
    but is infrequently accessed and is therefore ideal for long-term storage, such
    as for backups, and to act as a data store for DR purposes.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon S3 One Zone-Infrequent Access** (**S3 One Zone-IA**)—Data stored in
    this storage class is restricted to one AZ only within the Region you upload it
    to. This reduces your overall availability of the data to 99.5% but is also much
    cheaper than the Standard or the Standard-IA storage classes. This also means
    that if there is an outage of the AZ in which your data is stored, you would have
    to wait for the AZ to come back online before you can access any data. In the
    unlikely event of the destruction of an AZ, you may also lose that data.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Amazon recommends this class for data that can act as a secondary backup or
    that can be recreated.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Archive storage
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Often, data needs to be retained for archival purposes so that it is available
    when needed for auditing or reference. More often, regulatory and compliance requirements
    state that certain types of data should retained for *n* number of years. These
    could be financial information or past medical records, for example.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Amazon offers very low-cost storage for such requirements through its archival
    solution, **Amazon Glacier**.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Glacier**—This storage class is designed for long-term archiving of
    data that may need to be accessed infrequently and within a few hours.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving data from Amazon Glacier works differently, however, as it is not
    immediately accessible and requires you to initiate a restore request for the
    data. This restore process can take some time (between a few minutes to 12 hours)
    before the data is available to download, and this depends on the retrieval option
    you choose.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Glacier Deep Archive**—This is the lowest-cost storage class whereby
    customers can store very old historical data to meet compliance and regulatory
    requirements. Such data may be required to be kept for 7 to 10 years. Retrieval
    times can take 12 hours or more, depending on the retrieval option chosen.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: We discuss the Amazon S3 Glacier retrieval options in more detail later in this
    chapter.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Unpredictable access patterns
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Normally, your business will have a predictable access pattern for most data—for
    example, newly created data may need to be accessed frequently, such as daily.
    As data gets older it is accessed less frequently, and sometimes very rarely.
    Your access pattern, while predictable in this case, changes over time. AWS offers
    a feature known as lifecycle management that allows you to move data from one
    storage class to another, depending on changes to your access patterns. We look
    at lifecyle management and lifecycle rules later in this chapter.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, however, it is difficult to categorize data as frequently accessed
    or infrequently accessed, simply because of the nature of that data. You might
    be frequently accessing a set of objects for an initial period of a few weeks,
    and those objects may later become infrequently accessed. However, a few months
    down the line, you may need to access those objects again for analysis or some
    form of investigation. This data may now need to be frequently accessed over a
    period once again.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: In these scenarios, AWS offers another storage class called the Intelligent-Tiering
    storage class. For this privilege, you are charged a small monitoring fee for
    every object to ensure it is automatically transitioned into the right tier, depending
    on access patterns.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '**Intelligent-Tiering**—This storage class offers automated tiering of data
    depending on your access pattern. Objects are automatically transitioned across
    four different tiers, two of which are latency access tiers designed to move objects
    between frequently accessed and infrequently accessed tiers, and the other two
    being optional archive access tiers:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Frequent and infrequent tiers—Objects that are frequently accessed (within 30
    days) are placed automatically in the frequent access tier (Standard storage class).
    Any objects not accessed for 30 days are then moved into the infrequent access
    tier (Standard-IA), thereby incurring lower costs. Remember—the minimum object
    size for Standard -IA is set to 128 KB, and objects less than this size are treated
    and charged as if they are a minimum of 128 KB. Any object in the infrequent tier
    that later gets accessed is then automatically moved back into the frequent tier
    and charged accordingly.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optional archive access tiers—You can optionally choose to activate the archive
    access tiers. Once activated, this results in the S3 Intelligent-Tiering service
    transition when any object is not accessed for 90 days is moved into the Amazon
    Glacier **Archive Access tier**. If the object is not accessed for 180 days, it
    will be moved into the Amazon **Deep Archive Access tier**.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Intelligent-Tiering does not charge a retrieval fee but if objects are archived,
    retrieval can take some time, depending on the retrieval option chosen. The following
    table illustrates the retrieval options available:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 5.1 – Retrieval times for S3 Glacier, Deep Archive, and S3 Intelligent-Tiering
    archive classes'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Table_5.1.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Table 5.1 – Retrieval times for S3 Glacier, Deep Archive, and S3 Intelligent-Tiering
    archive classes
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, you have several retrieval options, and the times will vary
    depending on which archive storage option you select.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: S3 on Outposts
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Outposts is a fully managed on-premises service that comes with a 42U
    rack that can host the same AWS infrastructure and services at your data center.
    The U refers to rack units or "U-spaces" and is equal to 1.75 inches in height.
    A standard height is 48U (a 7-foot rack). The service allows you to create a pool
    of compute, storage, networking, and database services locally on-premises and
    is ideal if you have workloads running that are very sensitive to low-latency
    access. Amazon Outposts can also be used as a precursor to migrate your entire
    data center to the cloud at a later stage.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'With Amazon Outposts already widely available, AWS offers yet another storage
    class called **S3 Outpost**. The service offers durability and redundancy by storing
    data across multiple devices and servers hosted on your outposts and is ideal
    for low-latency access, while also enabling you to meet strict data-residency
    requirements. Amazon S3 on Outpost allows you to host 48 TB or 96 TB as part of
    the S3 storage capacity and provides the option to create a maximum of 100 S3
    buckets on each outpost. Have a look at the Amazon S3 performance chart shown
    in the following screenshot:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Table_5.2_a.jpg)![Figure 5.4 – S3 storage class performance and key
    attributes'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Table_5.2_b.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.4 – S3 storage class performance and key attributes
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding screenshot, you can choose which storage class to
    store your objects in depending on your use case. When making this decision, you
    need to consider durability and availability, as well as the minimum size of your
    objects, and ascertain whether you require instant access to those objects.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Versioning
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To protect against accidental deletions or overwriting, AWS also offers a feature
    called S3 Versioning. By default, when you create a bucket versioning is disabled,
    which means that if you were to upload an object with the same name (which, as
    mentioned earlier, is called a **key** on AWS) as an existing object in an S3
    bucket, then the original object in the bucket will get overwritten. Sometimes
    this may be exactly what you want, but in most cases, you might want to preserve
    the original version. Often, objects are overwritten simply because the name of
    the object was not changed before performing the upload, and this results in an
    accidental overwrite.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 offers a feature where you can enable versioning on a bucket. The
    setting is applied to the entire bucket and will therefore affect all objects.
    Once versioning is enabled, any object that is uploaded with the same name as
    an existing object will be tagged with a new version ID. Accessing the object
    will yield the latest/current version, but a toggle switch in the console will
    allow you to also see all previous versions in case you need to access an earlier
    version of the object.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: If you try to delete an object (without specifying the version ID) in a bucket
    that has had versioning enabled, then the object is not deleted. AWS adds a delete
    marker to the object and hides it from the S3 management console view. Subsequently
    if you need to *restore* the object again to make it visible in the S3 management
    console, you will simply have to delete the delete marker itself.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'You should note that buckets can be in one of three states, outlined as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Unversioned (default)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Versioning-enabled
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Versioning-suspended
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you enable versioning on a bucket, you can never return to the Unversioned
    state, but you can suspend versioning if you do not want new versions of objects
    being created.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Region and same-Region replication
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As previously discussed, to help customers comply with compliance and data-residency
    laws, AWS will never replicate your objects outside of the Region in which you
    create them. However, there is nothing to stop you from replicating your data
    outside of the Region in which you uploaded it if there are no regulatory requirements
    that prevent you from doing so.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Cross-Region Replication** **(CRR)** is used to asynchronously copy
    objects across AWS buckets in different AWS Regions. You can use CRR to do the
    following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '**Reduce latency**—By copying objects closer to where end users are based,
    you can minimize latency in accessing those objects.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increase operational efficiency**—If you run applications across multiple
    Regions that need access to the same set of data, maintaining multiple copies
    in those Regions increases efficiency.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Meet regulatory and compliance requirements**—Your organization compliance
    and regulatory requirements may require you to store copies of data thousands
    of kilometers away for DR purposes.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to CRR, Amazon S3 also enables you to configure replication services
    between buckets in the same Region. This is known as **Same-Region Replication**
    (**SRR**), which can help you achieve the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '**Log Data Aggregation**—You may be collecting log data from several sources
    and applications. You can collate these datasets in a single log management bucket
    via replication.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Replicating between development and production accounts**—If you use separate
    development and production accounts and need to use datasets in each, you can
    use replication to move objects from your development accounts to production accounts.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance requirements**—You may be required to maintain multiple copies
    of your data to adhere to data-residency laws. SRR can help you copy data between
    multiple buckets to ensure you have more than one copy for compliance purposes.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to note that both buckets must be configured with versioning
    enabled in order to set up CRR or SRR. You can also replicate objects across Regions
    or within the same Region, in either the same AWS account or across multiple AWS
    accounts. Finally, you can replicate objects into different storage classes from
    its original storage class, which means that your replicated objects can reside
    in a cheaper storage class, if perhaps they are being used simply as a backup
    copy—for example, your original objects can reside in the Standard storage class,
    but the replicated objects can be placed into the Standard-IA storage class. This
    will reduce your overall costs of storage.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Another feature of the replication service is support for multiple destination
    buckets. You can configure S3 Replication (multi-destination), which enables you
    to replicate data from one source bucket to multiple destination buckets, either
    within the same Region, across Regions, or a combination of both.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3 Lifecycle Management Amazon S3 offers unlimited amount of storage.
    This means that it is very easy to upload any amount of data you create and simply
    forget about it. At the same time, let's not forget that Amazon S3 charges you
    for the total amount of storage consumed, and the cost also depends on the storage
    class in which you place your objects.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Often, the bulk of your data is going to be infrequently accessed, especially
    after the initial period in which the data was created. This makes it essential
    to have some mechanism for moving objects you no longer need frequent access to
    into a cheaper storage class, to manage your storage costs effectively. In addition,
    you may also host a lot of archive data that you no longer require after a period,
    even for compliance and auditing purposes. For example, some regulations state
    that certain types of data need only be kept for a maximum of 7 years.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Manually trying to manage vast quantities of data can be a tiresome affair,
    often involving the creation of scripts and tools to review the data stored in
    the cloud. Instead, you can use a reliable solution by Amazon S3, known as Amazon
    S3 Lifecycle Management.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon S3 Lifecycle Management actions can be applied to your Amazon S3 buckets.
    These can be applied to the entire bucket or a subset of data by defining a prefix.
    These actions fall into two main categories, outlined as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '**Transition actions**—These allow you to move objects from one storage class
    to another after a certain period of time has passed. For example, if you know
    that you are going to be infrequently accessing a particular dataset after 60
    days, you can set a rule to move that data from the Standard storage class to
    the Standard-IA storage class 60 days after creation.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expiration actions**—These allow you to delete objects from the S3 storage
    system after a set number of days. For example, if you do not require old log
    files after 365 days, you can set a rule to automatically expire those objects
    after 365 days, which will purge them from the storage platform.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use a combination of transition actions and expiration actions as well.
    For example, you may have log data that you frequently access for the first 30
    days. After that, you may still need to revisit that data for a period of 180
    days, post which you no longer require it. You can set a combination rule to transition
    the log files after 30 days of creation from the Standard class to the Standard-IA
    class, then create another expiration action to purge the data after 180 days.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: You can also apply different lifecycle actions to versioned data—for example,
    you can have one set of rules and actions against the current version of your
    objects and another set for previous versions. This further allows you to manage
    your objects more effectively.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: S3 encryption
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All data uploaded to Amazon S3 is encrypted in transit using the HTTPS protocol.
    However, data stored on S3 is not modified in any way, which means that if you
    are uploading sensitive data in plaintext, the data is stored unencrypted by default.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'To add an additional layer of security, you can encrypt the data before storing
    it in S3\. This is known as encryption at rest. AWS offers two options for encrypting
    your data at rest, outlined as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '**Server-side encryption**—When you upload (create) an object, Amazon S3 encrypts
    it before saving it to disk, and when you download/request an object, it is automatically
    decrypted by the S3 service. You have three mutually exclusive options when deciding
    to encrypt your objects using server-side encryption, outlined as follows:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a) **Server-side encryption** with **Amazon S3-managed keys** (**SSE-S3**)—
    Amazon encrypts your data with a 256-bit **Advanced Encryption Standard** (**AES-256**).
    Each object is encrypted with a unique key, and the key itself is further encrypted
    with a master key that AWS rotates and manages for you.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) **Server-side encryption** with **customer master keys** (**CMKs**) stored
    in AWS **Key Management Service** (**SSE-KMS**)—This is similar to SSE-S3 but
    with added features, including the ability to create and manage your own CMKs,
    as well as an auditing feature that shows when your CMK was used and by whom.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) **Server-side encryption** with **customer provided keys** (**CPKs**) (**SSE-C**)—Encryption
    is performed by Amazon S3, but with CPKs. This is ideal if you need to follow
    regulatory requirements of creating and managing your own keys.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Client-side encryption**—This is where data is encrypted on the client side
    and the encrypted data is then uploaded to Amazon S3\. The full encryption process
    is therefore managed by the customer.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static website hosting
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to storing data, Amazon S3 also offers a service for hosting complete
    websites for your company. The only limitation is that the web hosting service
    is designed to host static websites only, as opposed to dynamic websites.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: The primary difference is that while the content stored on Amazon S3 to deliver
    the complete website can be changed and updated, it remains constant and *static*,
    and all users accessing the site will see the same content.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic websites use server-side scripting to deliver dynamic content that changes
    in-flight depending on various parameters, and generally connect to a backend
    database to fetch content.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, static websites can also provide complete end-to-end solutions
    and serve several use cases at a fraction of the cost. In addition to hosting
    and delivering digital assets such as **HyperText Transfer Markup** (**HTML**)
    files, **Cascading Style Sheets** (**CSS**), **Portable Document Format** (**PDF**)
    documents, images, and videos, you can also host client-side scripts that run
    in the client browser to offer additional features that can include interactive
    elements—for example, you can run a client-side script on a S3 static website
    to collect email addresses for potential customers and store them with a third-party
    email-campaign service provider. You can also host scripts that access additional
    AWS services. Having lambda functions and, potentially, **Elastic Container Service**
    (**ECS**) or **Elastic Kubernetes Service** (**EKS**) as backends allows you to
    run anything starting from a static website. Ultimately, you have a wide range
    of use cases for hosting static websites on Amazon S3\. Owing to its highly available
    and scalable nature to handle large volumes of traffic, Amazon S3 can prove to
    be a better solution than hosting static sites across a fleet of EC2 instances,
    depending on your use case.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of considering the Amazon S3 static website hosting service include
    the following:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '**Developing a product-prelaunch website**—Often, when you need to advertise
    a pre-launch campaign of a new product range, you may not be able to gauge the
    amount of traffic you might generate. Hosting the same solution on a fleet of
    EC2 instances may be more costly since you may need to scale out fast and utilize
    a large server farm if your marketing campaigns have been particularly successful.
    By way of contrast, the scalable nature of S3 will ensure that demand is met automatically
    with the inflow of large amounts of traffic.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Offloading**—With Amazon S3, you get a highly scalable, reliable, and low-latency
    data storage solution. Even if you host dynamic websites that run on expensive
    EC2 instances and EBS volumes, you are likely to have a large volume of static
    content (such as documents, images, and videos, for example). You could offload
    such static content to an S3 bucket and reference it via API calls from all sites
    hosted on EC2 instances. The benefits include low storage costs for your digital
    assets and, because your servers are kept lean, you also get better performance.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**"Lite" version of website or "Under Maintenance" banners**—Sometimes, you
    need to host an alternative version of your site when you are performing upgrades
    or rolling out major updates. By hosting a *lite* static version of your site
    on an S3 bucket, you can easily redirect request to the S3 buckets during periods
    of maintenance or major updates.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we looked at the fundamentals of Amazon S3 on AWS and learned
    about its various features. In the next section, we look at some additional services,
    covering transfer of data and archiving.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3TA
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you host an S3 bucket in a specific Region but require users across the globe
    to upload objects to it, your users may experience longer and unexpected variable
    speeds for uploads and downloads over the internet, depending on where they are
    based. S3TA reduces this speed variability that is often experienced due to the
    architecture of the public internet. S3TA routes your uploads via Amazon CloudFront's
    globally distributed edge locations and AWS backbone networks. This, in turn,
    gives faster speeds and consistently low latency for your data transfers.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a screenshot of a S3TA speed checker that uploads a sample file from
    your browser to various S3 Regions and compares the speed results between standard
    internet upload versus uploads via S3TA. You can try out the speed test at [https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html](https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html):'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Amazon S3TA speed test'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_05.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.5 – Amazon S3TA speed test
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we introduced you to the Amazon S3 service and discussed its
    various feature sets. Amazon S3 is an object storage solution designed to help
    customers store any amount of data in the cloud. With features such as versioning,
    CRR/SRR, encryption, and static website hosting, you can use Amazon S3 for a wide
    range of use cases at affordable storage costs.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we look at some additional features of the Amazon Glacier
    services, which offer an archival storage solution.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Learning about archiving solutions with Amazon S3 Glacier
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier in this chapter, we introduced you to the Amazon S3 Glacier and Glacier
    Deep Archive storage classes. Amazon Glacier offers long-term storage at very
    a low cost and is intended to be used for archival storage. The architecture offers
    the same 99.999999999% (eleven 9s) of durability so that in the event of a major
    disaster, you can rest assured that your old archives will be available to recover
    if the need arises. The technology works differently from standard S3 storage.
    The archives need to be requested before you can access/download them, which involves
    a two-step process of first creating a retrieval job and then downloading your
    data once the job is complete.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: This retrieval process can take some time and depends on your chosen retrieval
    options, as previously discussed. However, the upside to this delay in being able
    to access your data is that you get some of the cheapest storage options on the
    Amazon platform.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Archives and vaults
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As with other Amazon S3 storage classes, you can store any amount of data in
    the Glacier class. However, your objects are stored as archives, and an archive
    can contain either a single file or multiple files clubbed together in a `.zip`
    or `.tar` format. The size of your archive can between 1 byte and 40 terabytes.
    On Amazon S3, a single object can only be a maximum of 5 TB.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, archives can be grouped and stored in vaults. When you create a
    vault, you need to specify the Region in which it will be created. Vaults also
    let you define access and notification policies, and you can have up to 1,000
    vaults per Region. A vault policy enables you to define who can access it and
    which actions can be performed on it. You can also define vault lock policies,
    such as **Write Once Read Many** (**WORM)**, or time-based record-retention policies
    for regulatory archives.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval options
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As previously discussed, access to your archives in Amazon Glacier is not instantaneous.
    Depending on the Glacier storage class you choose (Glacier versus Deep Archive),
    you have the following different retrieval options available:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: a) **Amazon S3 Glacier Retrieval Options**
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard**—This is the default retrieval option and typically takes between
    3 and 5 hours to complete, before your data is made available to download.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expedited**—If you need urgent access to just a subset of your archives,
    you can opt for the Expedited retrieval option. Naturally, the cost of retrieval
    is higher than the other options. Furthermore, Expedited retrievals are made available
    within 1 to 5 minutes for archives of up to 250 **megabytes** (**MB**). In addition,
    two types of expedited retrieval options are available: On-Demand and Provisioned.
    With On-Demand, your retrieval requests are generally fulfilled within a 5-minute
    period, although during periods of high demand, this may take longer. Optionally,
    you can purchase Provisioned capacity, which ensures available retrieval capacity
    when you need it the most.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bulk** —This is designed to help you retrieve large amounts of data at the
    lowest-cost retrieval option and typically takes between 5 to 12 hours to complete.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: b) **Amazon S3 Glacier Deep Archive Retrieval Options**
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard**—Retrieval of your deep archives can be achieved within 12 hours.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bulk**—Retrieval of **petabytes** (**PB**) of data within 48 hours can be
    achieved, and it is also the lowest-cost option available.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we looked at archiving solutions with the Amazon S3 Glacier
    service and how you can store data for many years to fulfill compliance and regulatory
    requirements. In the next section, we look at how you can connect your on-premises
    storage services to Amazon S3\.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Connecting your on-premises storage to AWS with Amazon Storage Gateway
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon Storage Gateway is an on-premises solution that enables you to connect
    your on-premises servers and storage systems to the Amazon S3 cloud environment.
    The service involves installing the Storage Gateway **virtual machines** (**VMs**)
    on-premises and connecting your servers to them. The gateway uses industry-standard
    protocols to then transfer data between your servers and the Amazon S3 platform.
    The VM can be deployed on either VMware ESXi or a Microsoft Hyper-V hypervisor.
    Optionally, you can also order a hardware appliance, which is a physical server
    that comes pre-installed and configured with the Storage Gateway software. This
    reduces the administration time involved in setting up your own VMs and integrates
    with your existing storage systems over protocols such as **Network File System**
    (**NFS**), SMB, and **Internet Small Computer Systems Interface** (**iSCSI**).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Storage Gateway enables your on-premises application to connect to the
    AWS storage systems *transparently* over standard protocols such as NFS/SMB, **Virtual
    Transport Layer** (**VTL**), and iSCSI. Connectivity between the Storage Gateway
    VMs or hardware appliance to the AWS platform can be established over the internet,
    through secure IPsec **virtual private network** (**VPN**) tunnels or via AWS
    Direct Connect.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon S3 Storage Gateway supports different use cases with the following deployment
    options:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '**File Gateway**—Enables you to use standard NFS SMB protocols to store data
    in Amazon S3\. Data is also cached locally, enabling low-latency access. Here,
    there are two options available, as follows:'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a) **Amazon S3 File Gateway**—This service enables you to present a file-server
    solution to your on-premises servers and access Amazon S3, where you can store
    and retrieve objects in Amazon S3 using industry-standard file protocols such
    as NFS and SMB. Furthermore, because the data is ultimately stored in S3, you
    benefit from all its features such as versioning, bucket policies, CRR, and so
    on.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) **Amazon FSx File Gateway**—This service allows you to connect your on-premises
    Windows servers or Windows-based applications (as well as Linux and macOS systems)
    to the cloud-hosted Amazon FSx for Windows File Server with low latency, and the
    ability to set up and access a virtually unlimited number of Windows file shares
    in the cloud. Amazon FSx File Gateway offers full support for SMB protocol support,
    as well as integration with **Active Directory** (**AD**) and the ability to configure
    access controls using ACLs.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Volume Gateway**—Enables you to present block storage volumes to your on-premises
    servers over the iSCSI protocol. Volume Gateway can be used to asynchronously
    back up your data to Amazon S3 and comes in two different modes, outlined as follows:'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cache mode**—The bulk of your data is stored in Amazon S3, with only the
    most frequently accessed data stored locally in the cachefor low-latency connectivity.
    This means that you do not need very large amounts of local storage, which helps
    reduce your capital expenditure.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stored mode**—Your data is stored locally and available for low-latency access
    on premises. This is particularly useful if your application is sensitive to latency
    for data access. The data is then asynchronously backed up to Amazon S3 and can
    be used for DR purposes.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tape Gateway**—Many organizations use backup software solutions for their
    on-premises backup needs (for example, Veritas Backup Exec and NetBackup). Often,
    these applications back up data to physical tapes, which most companies store
    off-site. However, the tape drives, tapes, and off-site storage facilities can
    become very costly. The Tape Gateway solution comes to the rescue by enabling
    you to present virtual tapes to your backup software applications over iSCSI.
    Tape Gateway stores these virtual tapes in a **virtual tape library** (**VTL**),
    which is backed up by Amazon S3\. Data is written to these virtual tapes, which
    results in the Tape Gateway solution asynchronously uploading the data to Amazon
    S3\. When you need to restore the data, it is downloaded to the local cache, and
    the backup application can restore it to a location you specify on premises.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To manage long-term storage of old data, you can transition virtual tapes between
    Amazon S3 and Amazon S3 Glacier or Amazon S3 Glacier Deep Archive. If you later
    need to access the data on an **archived virtual tape**, you need to retrieve
    the tape and present it to your Tape Gateway solution.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Note that retrieval of an archived tape from Glacier will take between 3 and
    5 hours and from Deep Archive can take up to 12 hours.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked at how you connect your on-premises applications
    to the Amazon S3 storage service using the Storage Gateway solution. In the next
    section, we look at how you can migrate large volumes of data to the cloud using
    alternative offline methods, which is particularly useful when you have limited
    internet bandwidth.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Migrating large datasets to AWS with the AWS Snow Family
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many companies looking to move to the cloud generally host vast amounts of data
    on premises. While it is possible to transfer data over the public internet into
    Amazon S3, customers with vast amounts of data may need to consider offline methods
    of transfer due to bandwidth limitations.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: AWS offers rugged devices that can be delivered to your on-premises location.
    These include the **Snowcone**, **Snowball**, and **Snowmobile** devices.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: AWS Snowball
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At its very basic offering, you simply copy large amounts of data to the device
    and ship it back to AWS to have the data imported into Amazon S3\. These devices
    are known as AWS Snowball devices and are part of the Snow Family of devices.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: These edge devices come with compute and storage capabilities contained in highly
    rugged, tamper-proof devices. The devices feature a **Trusted Platform Module**
    (**TPM**) chip that detects unauthorized modifications to hardware, software,
    or firmware. These devices can be used for storage and data processing at your
    on-premises locations. Often, customers will use Snowball edge devices for migrations,
    data collections, and processing with or without internet connectivity.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon Snowball comes in *two flavors*, as follows:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '**Snowball Edge Compute Optimized**—These devices offer both storage and computing
    resources and can be used for **machine learning** (**ML**), analytics, and any
    local computing tasks. The devices come with 52 **virtual central processing units**
    (vCPUs), 208 GB of memory, and an optional NVIDIA Tesla V100 **graphics processing
    unit** (**GPU**). In terms of storage, the device offers 42 TB of **hard-disk
    drive** (**HDD**) capacity and 7.68 TB of **solid-state drive** (**SSD**) capacity.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Snowball Edge Storage Optimized**—These devices offer larger storage capacity
    and are ideal for data migration tasks. With 80 TB of HDD and 1 TB of **serial
    advanced technology attachment** (**SATA**) SDD volumes, you can start moving
    large volumes of data to the cloud. The device also comes with 40 vCPUs and 80
    GB of memory.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Snowcone
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The smallest member of the AWS Snow Family, these devices are the smallest ever
    and weigh just 4.5 **pounds** (**lb**) (2.1 **kilograms** (**kg**)). Snowcone
    devices come with 8 TB of usable storage and are designed for outside use in areas
    of low network connectivity. Examples include IoT, vehicular, and drone use cases.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The device also offers compute capabilities with two vCPUs and 4 GB of memory,
    as well as USB-C power using a cord and optional battery.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Snowmobile
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you need to transfer exabyte-scale data to the cloud, then you are going
    need an extremely large 45-foot-long *rugged* shipping container. Amazon Snowmobile
    can transfer up to 100 PB of data to the cloud and assist in all your data center
    migration efforts.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: The shipping container is delivered on-site and an AWS team member will work
    with your team to connect a high-speed switch from Snowmobile to your local network.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: With 24/7 video surveillance, optional escort security, and 256-bit encryption,
    you have access to the most secure way of transferring sensitive data to Amazon
    S3\.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we reviewed offline methods to transfer large amounts of data
    to the cloud and assist in your data migration efforts. The Amazon Snow Family
    offers more than just storage containers—these devices come with high levels of
    compute capabilities to perform data processing, analytics, and ML tasks as you
    copy data to them as well.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we review some of the key points highlighted in this chapter.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.1 – Setting up an Amazon S3 bucket
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this exercise, we will create an Amazon S3 bucket and upload an object to
    it. More specifically, we will upload a single web page document and test access
    to it after the upload. Since we plan to later *use* this bucket to host a static
    website and make content accessible to anyone on the internet, you will need to
    disable the **Block Public Access** setting, as discussed in the access permissions
    settings earlier in this chapter. Proceed as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: On your computer, create a new file using a standard text editor of your choice
    (Notepad on Windows or TextEdit on Mac).
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following lines of code to the document:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, save it with a filename of `index` with a `.html` extension—so, the filename
    with the extension should be `index.html`. This will create a simple web page
    object for you. You may need to set the **Save as type** option to **All Files**,
    as illustrated in the following screenshot:![Figure 5.6 – Saving a file with a
    .html extension to create a web page
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_06.jpg)'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.6 – Saving a file with a .html extension to create a web page
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, log in to your AWS account as the IAM user, **Alice**.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the Amazon S3 console.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Create bucket**, as illustrated in the following screenshot:![Figure
    5.7 – List of buckets
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_07.jpg)'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.7 – List of buckets
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the name of the bucket, type in your name followed by a hyphen (`-`) and
    the word `webpage`. Make sure there are no spaces in the name and that all lowercase
    letters are used. Assuming that the name you have chosen has not already been
    taken by another customer of AWS, you should be able to use this bucket name.
    If you get an error when you create the bucket, stating that the name is not available,
    you will simply need to choose a different name.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For `us-east-1`.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, under the **Block Public Access settings for bucket** sub-heading, uncheck
    he box for **Block all public access**. Note that for general use cases, you do
    not want to unblock public access unless your use case demands it, such as when
    trying to configure static website hosting, which we will look at later in *Exercise
    5.4*. If you do not need anonymous access such as that from end users on the public
    internet, you must always correctly configure your permissions using bucket policies,
    ACLs, or access point policies, to ensure you leverage the **principal of least
    privilege** (**PoLP**).
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, check the box to state that you acknowledge that the preceding settings
    could make the bucket and its objects publicly accessible, as illustrated in the
    following screenshot:![Figure 5.8 – Turning off block all public access on your
    bucket
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_08.jpg)'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.8 – Turning off block all public access on your bucket
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Leave all other settings as default and click on the **Create bucket** button
    at the bottom of the screen. Your Amazon S3 bucket has now been created.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, in your list of buckets in the main S3 console, select the bucket you
    just created. This will take you to the current list of objects in the bucket.
    You will note that there will be none at present.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will notice an **Upload** button. Click on this button and you will have
    the option to add files and folders, as per the following screenshot:![Figure
    5.9 – Uploading object to your bucket
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_09.jpg)'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.9 – Uploading object to your bucket
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add the `index.html` file you created/downloaded earlier.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll toward the bottom of the screen and click the **Upload** button.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your file will be uploaded.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will note a green banner at the top of the screen to say that the upload
    has been successful. Now, go ahead and click **Exit**.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You are then presented with the contents of the bucket you just created.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can now click on the `index.html` file in the **Objects** list, which will
    take you to the Amazon S3 properties page of the file itself.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that each object has its own URL accessible from the internet (as long
    as the permissions are correctly set), as we can see in the following screenshot:![Figure
    5.10 – Uploading the index.html object to your bucket
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_10.jpg)'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.10 – Uploading the index.html object to your bucket
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you try to click on this object URL to open it up in another browser window,
    you will find that you cannot access it. Instead, you get an **Access Denied**
    error message. This is because access to an object via its URL has the same effect
    as trying to anonymously read the object over the public internet.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although we disabled the `Allow` rule to grant access to them. You could click
    on the **Permissions** tab of the object itself and set up an ACL to enable public
    access for this object. However, as discussed previously, using bucket policies
    is a better option as these offer more features and granular control.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, we will set up a bucket policy to see how we can allow
    public access to this file.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.2 – Configuring public access to S3 buckets
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this exercise, we will configure the Amazon S3 bucket with a `index.html`
    web page you created earlier.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Remember that you could choose to restrict access to only a set of known users—for
    example, if you wanted only IAM users in your AWS account to have access to the
    objects. You can also configure cross-account access, in which you define principals
    that belong to another AWS account and grant them specific levels of access.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'In this exercise, we want to grant anonymous access to the `index.html` page
    because ultimately, we will be building out a static website hosting service using
    this bucket in later exercises. Proceed as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Navigate back to the S3 console and click on the bucket you just created, as
    illustrated in the following screenshot:![Figure 5.11 – Successful upload
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_11.jpg)'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.11 – Successful upload
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Permissions** tab.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will note that the **Block public access** has been disabled and is in an
    **Off** state.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll further down until you get to **Bucket Policies**, and then click **Edit**.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following policy, replacing the values in the placeholder `Your-Bucket-Name`
    with the name of your S3 bucket:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Click **Save Changes**. If you copied the policy correctly, the policy validator
    will not throw up any errors.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should then get a confirmation that the policy has been saved and, more
    importantly, you will note that the bucket's contents are now publicly accessible,
    as illustrated in the following screenshot:![Figure 5.12 – S3 Bucket permissions
    tab
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_12.jpg)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.12 – S3 Bucket permissions tab
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click on the **Objects** tab again.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `index.html` file to open its **S3 Properties** pane.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-mouse click on the object URL and open it in a new browser tab.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should find that the web page is now accessible from your browser, as illustrated
    in the following screenshot:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Your index.html page in a browser window'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_13.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.13 – Your index.html page in a browser window
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have disabled block public access on this bucket as we will eventually
    be configuring it for static website hosting. In this exercise, we also uploaded
    the object, `index.html`, which is a recipe document written in HTML code.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, you will learn how to configure versioning on your bucket.
    Versioning will help you create previous copies of an object so that new uploads
    of updated content for the same object are stored as new versions of the object.
    This will enable you to prevent against accidental changes to your objects by
    being able to restore a previous version, as we will see in the upcoming exercises.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.3 – Enabling versioning on your bucket
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this exercise, we will enable versioning on the Amazon S3 bucket. As you
    update existing objects with newer versions, you can rest assured that if you
    need to revert to an older version, those versions will still exist in your bucket.
    Obviously, if you try to delete a specific version of the object itself, then
    it will be purged from the S3 platform. However, enabling versioning can help
    prevent against accidental deletions and overwrites. Proceed as follows:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Navigate back to the S3 console.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the bucket you created earlier in *Exercise 5.1*.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Properties** tab.
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will see an **Edit the Bucket Versioning** option to edit the state. At
    present, the versioning will be set to **disabled**. Note that once again you
    can suspend versioning actions, but you will not be able to disable them.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Edit** in the **Bucket Versioning** section.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Enable**.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Save Changes**.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s try to test the versioning feature next, as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the location where you saved the `index.html` web page on your computer.
    Open the file with your text editor using Notepad or TextEdit (for Mac).
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace the word `Blueberry` in the existing `<H1>` tag within the document
    to `Chocolate`.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the file without changing the format or extension.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate back to your Amazon S3 console in your AWS account and click on the
    bucket you created earlier.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Objects**, as illustrated in the following screenshot:![Figure 5.14
    – List of objects in your Amazon S3 bucket
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_14.jpg)'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.14 – List of objects in your Amazon S3 bucket
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Upload**.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Add Files**.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the same `index.html` file you updated moments ago and click **Upload**.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Exit**.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `index.html` fileagain to open up its **S3 Properties** window.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Object URL**, right-mouse click on the URL and open in a new browser
    window.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should find that the web page has been updated with the word **Chocolate**,
    as illustrated in the following screenshot:![Figure 5.15 – Your index.html page
    showcasing the recipe
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_15.jpg)'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.15 – Your index.html page showcasing the recipe
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the Amazon S3 management console, click on the **Versions** tab, as illustrated
    in the following screenshot:![Figure 5.16 – Bucket version tab
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_16.jpg)'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.16 – Bucket version tab
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that there are two versions—the original version, which has a version ID
    of `null`, and a newer version with a `null` is because it was created/uploaded
    to the bucket before we enabled versioning. Going forward, all new updates to
    this file will be assigned a new version ID, allowing you to preserve older versions
    if you ever need to access them again.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this exercise, you learned how to configure versioning on your bucket. You
    were able to upload and manage multiple versions of the same object, and you discovered
    how unversioned objects have a version ID of `null`, whereas versioned objects
    have a version ID comprised of a series of characters unique to that version.
    You also discovered how to display a list of available versions of your objects
    in a version-enabled bucket.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 5.4 – Setting up static website hosting
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this exercise, we will configure the bucket to host a static website. When
    configured with a static website hosting service, the bucket will be configured
    with a website endpoint that you can distribute to your users, who can then access
    all the pages (assuming they are linked) using the standard HTML protocol.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure your bucket for static website hosting, you need a minimum of
    two files— an `index.html` file and an `error.html` file. An error file is simply
    a file that the S3 static website hosting service will redirect to if there is
    a problem with the `index.html` file—for example, if it cannot find the `index.html`
    page. You could use the `error.html` file to broadcast the fact that perhaps the
    site is under maintenance. Proceed as follows:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Create a new HTML file using your text editor as before (either Notepad on Windows
    or TextEdit on a Mac). However, in this file, simply add a line of text along
    the lines of `This site is under maintenance`.
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the file as `error.html`, making sure to set the file types to **All Types**
    if you are using a Windows machine.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate back to the S3 console and click on your S3 bucket.
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Properties** and then scroll toward the bottom of the page, until
    you find the **Static website hosting** section heading.
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Edit** and select the **Enable** option.
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For **Hosting type**, select **Host a static website**.
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under the `index.html`.
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under the `error.html`.
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave all the remaining settings at their defaults and click **Save changes**
    at the bottom of the page.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click on the **Objects** tab.
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Upload** and click **Add files**.
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `error.html` file and click **Upload**. You should then see a screen
    like this:![Figure 5.17 – Upload of updated index page to your bucket
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_17.jpg)'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.17 – Upload of updated index page to your bucket
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Exit**.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this stage, your bucket has been configured for static website hosting. To
    test it, you need to access your website via the S3 website URL endpoint.
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the S3 console, while still viewing the contents of the buckets (under **Objects**),
    click on the **Properties** tab again.
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scroll down till you reach the **Static website hosting** section, and you will
    note the URL is provided under the **Bucket website endpoint** heading, as illustrated
    in the following screenshot:![Figure 5.18 – Enabling static website hosting on
    your bucket
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_18.jpg)'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.18 – Enabling static website hosting on your bucket
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Navigate to the provided URL in a new browser window, and you should find that
    the website opens with the recipe web page, as illustrated in the following screenshot:![Figure
    5.19 – Updated index.html page with the wrong heading (Chocolate)
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_19.jpg)'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.19 – Updated index.html page with the wrong heading (Chocolate)
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you will note, the recipe is for a blueberry muffin, but the heading has
    changed to **Chocolate**. Assuming that this was an error in the update, we can
    easily revert to the previous version of this web page because we have already
    configured the bucket for versioning.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate back to the Amazon S3 bucket so that you are looking at the actual
    contents of the bucket under the **Objects** tab, as illustrated in the following
    screenshot:![Figure 5.20 – List of updated objects in your bucket
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_20.jpg)'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.20 – List of updated objects in your bucket
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Notice the **List versions** toggle just below the **Objects** sub-heading.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click this toggle switch to list out all versions of all objects in your bucket,
    as illustrated in the following screenshot:![Figure 5.21 – List of objects and
    their individual versions.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_21.jpg)'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.21 – List of objects and their individual versions.
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you will note, there are two versions of the `index.html` page. The latest
    version has got a version ID and contains an incorrect recipe heading.
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the checkbox to select this version and then click the **Delete** button.
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You are then prompted to confirm your delete request by typing in the phrase
    `permanently delete` in the provided textbox, as illustrated in the following
    screenshot:![Figure 5.22 – Deleting incorrect version of the index.html page
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_05_22.jpg)'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 5.22 – Deleting incorrect version of the index.html page
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click **Delete objects**.
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Exit**, and you will note that the version has now been deleted.
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on **Properties** again and then scroll down to the **Static website
    hosting** section. Open up the website URL in a new browser tab and you should
    see that the older, correct version of the web page is now displayed, as illustrated
    in the following screenshot:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Previous recipe page with the correct heading (Blueberry)'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_05_23.jpg)'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.23 – Previous recipe page with the correct heading (Blueberry)
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you learned how to configure your bucket with static website
    hosting. You learned how, in this particular lab exercise, we made an error in
    the title of our web page and we were able to revert to an older versioning of
    the same document, thanks to having versioning enabled earlier.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-390
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon S3 is one of AWS's flagship storage products and comes with unlimited
    amounts of storage capacity that is highly scalable and durable.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned about the core feature of Amazon S3, including
    versioning, lifecycle management, and replication services, and how Amazon S3
    meets a wide range of use cases. You also learned how you can build and deploy
    static website hosting on an Amazon S3 bucket and its various applications in
    the real world.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed how Amazon S3 comes with a wide range of security tools such
    as the ability to create granular access permissions via bucket policies and ACLs,
    as well as encryption of data in transit and at rest. You have also learned how
    you can connect your on-premises workloads to the Amazon S3 platform using Amazon
    Storage Gateway via the internet, a VPN, or AWS Direct Connect services.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking to migrate large amounts of data to the cloud, you can use
    the Amazon Snowball service to help you transfer large volumes of data, using
    rugged and tamper-resistant devices that are shipped to your on-premises location.
    Once you get the data copied, you simply ship it back to AWS to have your data
    imported into your S3 environment.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we discuss networking services, focusing on the **Amazon
    Virtual Private Cloud** (**VPC**) service, among others. We also look at the Amazon
    Direct Connect service and at how you can connect your on-premises network with
    your AWS cloud services using VPN technologies.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we look at some review questions for this chapter to test
    your knwoledge.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a few questions to test your knowledge:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following is true regarding Amazon S3? (Select 2 answers)
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 is object-based storage.
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 is an example of file storage.
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 is an example of block storage.
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The Amazon S3 One Zone-IA storage class offers 99.5% of availability. Amazon
    S3 can be configured as shared mount volumes for Linux-based EC2 instances.
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You wish to enforce a policy on an S3 bucket that grants anonymous access to
    its content if users connect to the data from the corporate and branch offices
    as part of your security strategy. Which S3 configuration feature will enable
    you to define the IP ranges from where you will allow access to the data?
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Security groups
  id: totrans-405
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Bucket policy
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: NTFS permissions
  id: totrans-407
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Network ACLs** (**NACLs**)'
  id: totrans-408
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service is the most cost-effective if you need to host static website
    content for an upcoming product launch?
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon EC2
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon EFS
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure ExpressRoute
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which Amazon S3 storage class enables you to optimize costs by automatically
    moving data to the most cost-effective access tier, while ensuring that frequently
    accessed data is made available immediately?
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 Standard
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 One-Zone IA
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Snowball
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3 Intelligent-Tiering
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which Amazon S3 service can be configured to automatically migrate data from
    one storage class to another after a set number of days as a means of reducing
    your costs, especially where frequent instant access may not be required to that
    subset of data?
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Static website hosting
  id: totrans-420
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lifecycle management
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Storage transition
  id: totrans-422
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: S3 migration
  id: totrans-423
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When retrieving data from Amazon Glacier, what is the typical time taken by
    a Standard retrieval option to make the archive available for download?
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 20 minutes
  id: totrans-425
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 24 hours
  id: totrans-426
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 3 to 5 hours
  id: totrans-427
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 90 seconds
  id: totrans-428
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which feature of the Amazon S3 platform enables you to upload content to a centralized
    bucket from across any location via Amazon edge locations, ensuring faster transfer
    speeds and avoidance of public internet congestion?
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon S3TA
  id: totrans-430
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS S3 Storage Gateway
  id: totrans-431
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon VPC
  id: totrans-432
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CloudFront
  id: totrans-433
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Your on-premises applications require access to a centrally managed cloud storage
    service. The application running on your servers need to be able to store and
    retrieve files as durable objects on Amazon S3 over standard NFS-based access
    with local caching. Which AWS service can help you deliver a solution to meet
    the aforementioned requirements?
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Storage Gateway— Amazon S3File Gateway
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS EFS
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Redshift
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: EBS volumes
  id: totrans-438
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You are looking to migrate your on-premises data to the cloud. As part of a
    one-time data migration effort, you need to transfer over 900 TB of data to Amazon
    S3 in a couple of weeks. Which is the most cost-effective strategy to transfer
    this amount of data to the cloud?
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Amazon RDS service
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Amazon Snowball service
  id: totrans-441
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the Amazon VPN connection between your on-premises network and AWS
  id: totrans-442
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Use AWS Rain
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
