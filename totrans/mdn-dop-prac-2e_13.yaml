- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Securing and Testing Your CI/CD Pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we looked at **Continuous Integration** (**CI**) and
    **Continuous Deployment/Delivery** (**CD**) with GitOps as the central concept.
    Both concepts and the tooling surrounding them help us deliver better software
    faster. However, one of the most critical aspects of technology is security and
    quality assurance. Though security was not considered in DevOps’ initial days,
    with the advent of **DevSecOps**, modern DevOps now places a great emphasis on
    it. In this chapter, we’ll try to understand the concepts surrounding container
    applications’ security and testing and how to apply them within CI and CD.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Securing and testing CI/CD pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revisiting the Blog Application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container vulnerability scanning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary authorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Release gating with pull requests and deploying our application in production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security and testing best practices for modern DevOps pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, we will spin up a cloud-based Kubernetes cluster, **Google
    Kubernetes Engine** (**GKE**), for the exercises. Currently, **Google Cloud Platform**
    (**GCP**) provides a free $300 trial for 90 days, so you can go ahead and sign
    up for one at [https://console.cloud.google.com/](https://console.cloud.google.com/).
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also need to clone the following GitHub repository for some of the
    exercises:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Modern-DevOps-Practices-2e](https://github.com/PacktPublishing/Modern-DevOps-Practices-2e).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the Cloud Shell offering available on GCP to follow this chapter.
    Go to Cloud Shell and start a new session. Run the following commands to clone
    the repository into your home directory to access the required resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to set the project ID and enable a few GCP APIs that we will use
    in this chapter. To do so, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now, in the next section, let’s look at how to secure and test CI/CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Securing and testing CI/CD pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With continuous cyber threats and the ongoing war between cybersecurity experts
    and cybercriminals, security has always been the top priority for most organizations,
    and it also forms a significant part of a mature organization’s investment.
  prefs: []
  type: TYPE_NORMAL
- en: However, security comes with its costs. Most organizations have cybersecurity
    teams that audit their code regularly and give feedback. However, that process
    is generally slow and happens when most of the code is already developed and difficult
    to modify.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, while most organizations significantly emphasize automated testing,
    many still heavily depend on manual testing. Manual testing is not only labor-intensive
    but also lacks repeatability. DevOps places great importance on automating tests
    to ensure that they can be repeated with every release, enabling the detection
    of existing issues and thorough testing of new features. Additionally, automation
    is essential for efficiently conducting regression testing on bug fixes, as manual
    testing in such cases is inefficient.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, embedding security and testing at the early stages of development
    is an essential goal for modern DevOps. Embedding security with DevOps has led
    to the concept of DevSecOps, where developers, cybersecurity experts, and operations
    teams work together to create better and more secure software faster.
  prefs: []
  type: TYPE_NORMAL
- en: Securing and testing your software using CI/CD pipelines offers various significant
    business advantages. Firstly, it ensures security by protecting sensitive data,
    preventing vulnerabilities, and ensuring compliance. Secondly, it improves quality
    and reliability through early issue detection, consistency, and higher product
    quality. This leads to cost reduction by reducing rework, speeding up time to
    market, and optimizing resource usage. Additionally, it mitigates risks by increasing
    resilience and enabling stress testing. Moreover, it ensures business continuity
    through disaster recovery and efficient rollback procedures. Furthermore, it provides
    a competitive advantage by fostering faster innovation and market responsiveness.
    Finally, it enhances reputation and customer trust by building confidence in your
    products and services and safeguarding your brand’s reputation. In essence, securing
    and testing CI/CD pipelines is both a technical necessity and a strategic business
    imperative that enhances security, quality, and reliability while reducing costs
    and risks, ultimately leading to improved customer satisfaction, business continuity,
    and a competitive edge in the market.
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways of embedding security within the software supply chain.
    Some of these might include static code analysis, security testing, and applying
    organization-specific security policies within the process, but the idea of security
    is not to slow down development. Instead of human input, we can always use tools
    that can significantly improve the security posture of the software we develop.
    Similarly, testing need not be manual and slow and, instead, should use automation
    to plug in seamlessly with the CI/CD process.
  prefs: []
  type: TYPE_NORMAL
- en: '**CI/CD pipelines** are one of the essential features of modern DevOps, and
    they orchestrate all processes and combine all tools to deliver better software
    faster, but how would you secure them? You may want to ask the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: How do I scan a container image for vulnerabilities?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I store and manage sensitive information and secrets securely?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I ensure that my application is tested before deployment to production?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I ensure that only tested and approved container images are deployed
    in production?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Throughout this chapter, we will try to answer these using best practices and
    tooling. For reference, look at the following workflow diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – Secure CI/CD workflow](img/B19877_13_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – Secure CI/CD workflow
  prefs: []
  type: TYPE_NORMAL
- en: 'As depicted in the previous figure, we need to modify the CI pipeline to include
    an additional step for vulnerability scanning. We also require two CD pipelines,
    one for the Dev environment and another for Prod. To enhance reusability, we’ll
    restructure our GitHub Actions workflow. We’ll divide the workflows into parent
    and child workflows. Let’s begin by examining the CD workflow for the Dev environment
    to get an overview:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The workflow begins with a `name`, followed by a declaration of `on push branches
    dev`. This configuration ensures that the workflow triggers with every push to
    the `dev` branch. We define multiple jobs in sequence, each depending on the previous
    one using the `needs` attribute. Each job invokes a child workflow specified by
    the `uses` attribute, and it provides GitHub secrets to these child workflows
    by setting `inherit` for the `secrets` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'The workflow accomplishes the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Sets up the Dev Kubernetes cluster, configures Argo CD and supporting tools
    to establish the environment, and deploys the sample Blog App.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Executes integration tests on the deployed Blog App.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the tests pass, it utilizes binary authorization (more details to follow)
    to attest images, ensuring that only tested artifacts are allowed for deployment
    to production.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initiates a pull request for deployment to the Prod environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a similar manner, we have the following Prod CD Workflow file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This workflow is similar to the Dev workflow but does not include the `binary-auth`
    and `raise-pull-request` steps, as they are unnecessary at this stage. To understand
    it better, let’s begin by examining the Dev workflow. The initial step of the
    Dev workflow involves creating the environment and deploying the application.
    However, before we proceed, let’s revisit the Blog App in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the Blog Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we already discussed the Blog App in the last chapter, let’s look at the
    services and their interactions again in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – The Blog App services and interactions](img/B19877_13_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – The Blog App services and interactions
  prefs: []
  type: TYPE_NORMAL
- en: We’ve already created CI and CD pipelines for building, testing, and pushing
    our Blog Application microservices containers using GitHub Actions and deploying
    them using Argo CD in a GKE cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you remember, we created the following resources for the application to
    run seamlessly:'
  prefs: []
  type: TYPE_NORMAL
- en: '**MongoDB** – We deployed an auth-enabled MongoDB database with root credentials.
    The credentials were injected via environment variables sourced from a Kubernetes
    **Secret** resource. To persist our database data, we created a **PersistentVolume**
    mounted to the container, which we provisioned dynamically using a **PersistentVolumeClaim**.
    As the container is stateful, we used a **StatefulSet** to manage it and, therefore,
    a headless Service to expose the database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Posts, reviews, ratings, and users** – The posts, reviews, ratings, and users
    microservices interacted with MongoDB through the root credentials injected via
    environment variables sourced from the same **Secret** resource as MongoDB. We
    deployed them using their respective **Deployment** resources and exposed all
    of them via individual **ClusterIP** Services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frontend** – The frontend microservice does not need to interact with MongoDB,
    so there was no interaction with the **Secret** resource. We deployed this service
    as well using a **Deployment** resource. As we wanted to expose the service on
    the internet, we created a **LoadBalancer** Service for it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can summarize them in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – The Blog App – Kubernetes resources and interactions](img/B19877_13_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – The Blog App – Kubernetes resources and interactions
  prefs: []
  type: TYPE_NORMAL
- en: In subsequent sections, we will cover all aspects of implementing this workflow,
    starting with vulnerability scanning.
  prefs: []
  type: TYPE_NORMAL
- en: Container vulnerability scanning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Perfect software is costly to write and maintain, and every time someone makes
    changes to running software, the chances of breaking something are high. Apart
    from other bugs, changes also add a lot of software vulnerabilities. You cannot
    avoid these as software developers. Cybersecurity experts and cybercriminals are
    at constant war with each other, evolving with time. Every day, a new set of vulnerabilities
    are found and reported.
  prefs: []
  type: TYPE_NORMAL
- en: In containers, vulnerabilities can exist on multiple fronts and may be completely
    unrelated to what you’re responsible for. Well, developers write code, and excellent
    ones do it securely. Still, you never know whether a base image may contain vulnerabilities
    your developers might completely overlook. In modern DevOps, vulnerabilities are
    expected, and the idea is to mitigate them as much as possible. We should reduce
    vulnerabilities, but doing so manually is time-consuming, leading to toil.
  prefs: []
  type: TYPE_NORMAL
- en: Several tools are available on the market that provide container vulnerability
    scanning. Some of them are open source tools such as **Anchore**, **Clair**, **Dagda**,
    **OpenSCAP**, Sysdig’s **Falco**, or **Software-as-a-Service** (**SaaS**) services
    available with **Google Container Registry** (**GCR**), **Amazon Elastic Container
    Registry** (**ECR**), and **Azure Defender**. For this chapter, we’ll discuss
    **Anchore Grype**.
  prefs: []
  type: TYPE_NORMAL
- en: Anchore Grype ([https://github.com/anchore/grype](https://github.com/anchore/grype))
    is a container vulnerability scanner that scans your images for known vulnerabilities
    and reports their severity. Based on that, you can take appropriate actions to
    prevent vulnerabilities by including a different base image or modifying the layers
    to remove vulnerable components.
  prefs: []
  type: TYPE_NORMAL
- en: Anchore Grype is a simple **Command-Line Interface** (**CLI**)-based tool that
    you can install as a binary and run anywhere—within your local system or your
    CI/CD pipelines. You can also configure it to fail your pipeline if the vulnerability
    level increases above a particular threshold, thereby embedding security within
    your automation—all this happening without troubling your development or security
    team.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s go ahead and see Anchore Grype in action.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Anchore Grype
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we want to implement vulnerability scanning within our CI pipelines, let’s
    modify the `mdo-posts` repository we created in [*Chapter 11*](B19877_11.xhtml#_idTextAnchor1412).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s clone the repository first using the following command and `cd` into
    the `workflows` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Anchore Grype offers an installation script within its GitHub repository that
    you can download and run, and it should set it up for you. We’ll modify the `build.yaml`
    file to include the following step before the `Login to Docker Hub` step so that
    we can install Grype within our CI workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Next, we need to use Grype to scan our images for vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Scanning images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run container vulnerability scanning, we can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will report a list of vulnerabilities with severities—`Negligible`, `Low`,
    `Medium`, `High`, `Critical`, or `Unknown`—within the image. We can also set a
    threshold within Grype to fail when any vulnerabilities are equal to or worse
    than it. For example, if we don’t want to allow any `Critical` vulnerabilities
    in the container, we can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'To do so, we will add the following step within the `build.yaml` file after
    the `Build the Docker` `image` step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As we’ve made all the changes, let’s push the modified CI pipeline using the
    following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As soon as we push the image, we will see the following in the GitHub Actions
    tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – Vulnerability scan failure](img/B19877_13_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – Vulnerability scan failure
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, Grype has reported several vulnerabilities with one being `Critical`.
    It has also failed the CI pipeline. That is automated vulnerability scanning in
    action. This will discover vulnerabilities and only allow builds to end up in
    your container registry if they meet minimum security standards.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to fix the issue here, so let’s look at a more recent image and see
    whether it can fix the problem. Therefore, instead of using `python:3.7-alpine`,
    we will use `python:alpine3.18`. Let’s do that and push our code to GitHub using
    the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s revisit GitHub Actions and see what we get in the `build` output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.5 – Vulnerability scan success](img/B19877_13_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – Vulnerability scan success
  prefs: []
  type: TYPE_NORMAL
- en: The vulnerability scan did not stop our CI build this time, as no `Critical`
    vulnerabilities were found.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Continually update the base image with time, as newer ones contain fewer vulnerabilities
    and fix older ones.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve secured the image for vulnerabilities, our CI pipeline is complete.
    You can replicate this process for other microservices as needed. Let’s proceed
    to discuss CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: If you remember, in the last chapter, following the GitOps model, we stored
    the manifests of all resources on Git. However, due to security concerns with
    Kubernetes Secrets, we used **SealedSecrets** to manage them securely.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this may not be the ideal solution for all teams due to the following
    inherent issues:'
  prefs: []
  type: TYPE_NORMAL
- en: SealedSecrets are reliant on the controller that encrypts them. If we lose this
    controller, we also lose the ability to recreate the secret, essentially losing
    the Secret forever.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to the Secret is limited to logging in to the cluster and using `kubectl`,
    which doesn’t provide non-admins with the ability to manage secrets. While this
    approach might suit some teams, it may not suit others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, we will explore managing secrets using a Secrets management tool
    to establish a standardized method for centrally managing secrets with more granular
    control over access. Let’s delve into this topic in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Managing secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software always requires access to sensitive information such as user data,
    credentials, **Open Authorization** (**OAuth**) tokens, passwords, and other information
    known as secrets. Developing and managing software while keeping all these aspects
    secure has always been a concern. The CI/CD pipelines might deal with them as
    they build and deliver working software by combining code and other dependencies
    from various sources that may include sensitive information. Keeping these bits
    secure is of utmost importance; therefore, the need arises to use modern DevOps
    tools and techniques to embed security within the CI/CD pipelines themselves.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most application code requires access to sensitive information. These are called
    **secrets** in the DevOps world. A secret is any data that helps someone prove
    their identity, authenticate, and authorize privileged accounts, applications,
    and services. Some of the potential candidates that constitute secrets are listed
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: Passwords
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API tokens, GitHub tokens, and any other application key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secure Shell** (**SSH**) keys'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transport Layer Security** (**TLS**), **Secure Sockets Layer** (**SSL**),
    and **Pretty Good Privacy** (**PGP**) private keys'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One-time passwords
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good example could be a container requiring access to an API key to authenticate
    with a third-party API or a username and password to authenticate with a backend
    database. Developers need to understand where and how to store secrets so that
    they are not exposed inadvertently to people who are not supposed to view them.
  prefs: []
  type: TYPE_NORMAL
- en: When we run a CI/CD pipeline, it becomes imperative to understand how we place
    those secrets as, in CI/CD pipelines, we build everything from the source. “*Do
    not store secrets with code*” is a prominent piece of advice we’ve all heard.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Never store hardcoded secrets within CI/CD pipelines or store secrets in a source
    code repository such as Git.
  prefs: []
  type: TYPE_NORMAL
- en: How can we access secrets without including them in our code to run a fully
    automated GitOps-based CI/CD pipeline? Well, that’s something we need to figure
    out.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: When using containers, the thing to avoid is baking the secrets within an image.
    While this is a prominent piece of advice, many developers do this inadvertently,
    leading to many security holes. It is very insecure, and you should avoid doing
    it at all costs.
  prefs: []
  type: TYPE_NORMAL
- en: You can overcome this problem by using some form of **secrets management solution**.
    A secrets management solution or a **key management solution** helps store and
    manage your secrets and secure them with encryption at rest and in transit. There
    are secrets management tools within cloud providers, such as **Secret Manager**
    in GCP and **Amazon Web Services** (**AWS**), or you can use a third-party tool,
    such as **HashiCorp Vault**, if you want to go cloud agnostic. All these solutions
    provide APIs to create and query secrets at runtime, and they secure the API via
    HTTPS to allow encryption in transit. That way, you don’t need to store your secrets
    with code or bake it within an image.
  prefs: []
  type: TYPE_NORMAL
- en: In this discussion, we’ll use the **Secret Manager** solution offered by GCP
    to store secrets, and we will access them while running the CI/CD pipeline. Secret
    Manager is Google Cloud’s secrets management system, which helps you store and
    manage secrets centrally. It is incredibly secure and uses **Hardware Security
    Modules** (**HSMs**) to harden your secrets further.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will look at improving the CI/CD pipeline of our Blog Application,
    which we discussed in the last chapter, and will use the same sample application.
    Therefore, let’s go ahead and create the `mongodb-creds` Secret in Google Cloud
    Secret Manager.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Secret in Google Cloud Secret Manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s create a secret called `external-secrets`, where we will pass the MongoDB
    credentials in JSON format. To do so, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding command, we echo a JSON containing `MONGO_INITDB_ROOT_USERNAME`
    and `PASSWORD` directly into the `gcloud secrets create` command. We have specified
    a particular location to avoid replicating it in other regions as a cost-saving
    measure. However, it’s highly recommended to replicate secrets to prevent potential
    loss in case of a zonal outage. The JSON is stored as a new version of our secret.
    Secret Manager utilizes versioning for secrets, so any new value assigned to the
    secret (`external-secrets`) is versioned and stored within Secret Manager. You
    can reference a specific version either by its version number or by using the
    `latest` keyword to access the most recent version.
  prefs: []
  type: TYPE_NORMAL
- en: As seen in the output, we’ve created the first version of our secret (`version
    1`). Typically, this is done during development and should remain outside the
    CI/CD process. Instead of storing the Secret resource manifest in your source
    code repository, you can keep it in Secret Manager.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve created the secret, we must access it within our application.
    To achieve this, we require a tool to access the secret stored in Secret Manager
    from the Kubernetes cluster. For this purpose, we will use **External** **Secrets
    Operator**.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing external secrets using External Secrets Operator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: External Secrets Operator ([https://external-secrets.io/latest/](https://external-secrets.io/latest/))
    is a Kubernetes operator used in Kubernetes clusters to manage external secrets
    securely. It is designed to automate the retrieval and management of secrets stored
    in external secret stores such as AWS Secret Manager, GCP Secret Manager, Hashicorp
    Vault, and so on, and inject them into Kubernetes pods as Kubernetes Secrets.
    Operators are a way to extend Kubernetes functionality and automate tasks.
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'External Secrets Operator serves as a bridge between the Kubernetes cluster
    and external secret management systems. We define an `ExternalSecret` custom resource
    within the Kubernetes cluster, which the operator monitors. When an `ExternalSecret`
    resource is created or updated, the operator interacts with the external secret
    store specified in the `ClusterSecretStore` CRD to retrieve the secret data. It
    then creates or updates the corresponding Kubernetes Secrets. This process is
    illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – External Secret Operator](img/B19877_13_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – External Secret Operator
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, this process has a lot of benefits, some of which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Enhanced Security**: Secrets remain in a dedicated, secure secret store'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automation**: Automates the retrieval and rotation of secrets'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplified Deployment**: Eases the management of secrets within Kubernetes
    applications'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compatibility**: Works with various external secret stores, making it versatile'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s go ahead and install External Secrets Operator on our Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Installing External Secrets Operator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'External Secrets Operator is available as a `manifests/argocd/external-secrets.yaml`
    manifest file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The application manifest creates an `external-secrets` application on the `argocd`
    namespace within the `default` project. It downloads the `0.9.4` revision from
    the `external-secrets` Helm chart repository and deploys the chart on the Kubernetes
    cluster on the `external-secrets` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install this application, we need to apply this manifest using Terraform.
    Therefore, to do so, we make the following entry in the `app.tf` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: To deploy this, we must check these files into source control. Let’s clone the
    `mdo-environments` repository that we created in the last chapters.
  prefs: []
  type: TYPE_NORMAL
- en: If you haven’t followed the last chapters, you can do the following to set a
    baseline. Feel free to skip the next section if you’ve already set up your environment
    in [*Chapter 12*](B19877_12.xhtml#_idTextAnchor1554)*, Continuous Deployment/Delivery
    with* *Argo CD*.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the baseline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To ensure continuity with the last chapters, let’s start by creating a service
    account for Terraform to interact with our GCP project using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You will see a file called `key-file` created within your working directory.
    Now, create a new repository called `mdo-environments` with a `README.md` file
    on GitHub, rename the `main` branch to `prod`, and create a new branch called
    `dev` using GitHub. Navigate to `https://github.com/<your_github_user>/mdo-environments/settings/secrets/actions/new`
    and create a secret named `GCP_CREDENTIALS`. For the value, print the `key-file`
    file, copy its contents, and paste it into the **values** field of the GitHub
    secret.
  prefs: []
  type: TYPE_NORMAL
- en: Next, create another secret, `PROJECT_ID`, and specify your GCP project ID within
    the **values** field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to create a GCS bucket for Terraform to use as a remote backend.
    To do this, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'So, now that all the prerequisites are met, we can clone our repository and
    copy the baseline code. Run the following commands to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As we’re now on the baseline, let’s proceed further to install external secrets
    with Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: Installing external secrets with Terraform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s configure our local repository to install the external secrets manifest.
    To do so, copy the application manifest and `app.tf` file using the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we’re all set up and ready, let’s go ahead and commit and push our
    code using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As soon as we push the code, we’ll see that the GitHub Actions workflow has
    been triggered. To access the workflow, go to `https://github.com/<your_github_user>/mdo-environments/actions`.
    Soon, the workflow will apply the configuration, create the Kubernetes cluster,
    and deploy Argo CD, the Sealed Secrets controller, and External Secrets Operator.
  prefs: []
  type: TYPE_NORMAL
- en: Once the workflow is successful, we can do the following to access the Argo
    Web UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'We must first authenticate with the GKE cluster. To do so, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To utilize the Argo CD Web UI, you will require the external IP address of
    the `argo-server` service. To get that, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: So, now we know that Argo CD is accessible on `https://34.122.51.25/`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will run the following commands to reset the admin password:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, allow two minutes for the new credentials to be generated. After that,
    execute the following command to retrieve the password:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As we now have the credentials, log in, and you will see the following page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Argo CD Web UI – home page](img/B19877_13_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Argo CD Web UI – home page
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, there are three applications – `SealedSecret` manifest that we
    created in the last chapter, as it was generated by a different Sealed Secrets
    controller.
  prefs: []
  type: TYPE_NORMAL
- en: 'We don’t need the Sealed Secrets operator; we will use Google Cloud Secret
    Manager instead. So, let’s remove it from our cluster using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We’ve removed the Sealed Secrets operator, and the Argo CD Web UI should reflect
    that shortly. However, the Blog Application will remain degraded as the `mongodb-creds`
    Secret is still missing. In the next section, we will use External Secrets Operator
    to generate the `mongodb-creds` Secret.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the MongoDB Kubernetes Secret using External Secrets Operator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To generate the `mongodb-creds` secret, we would need to create the following
    resources:'
  prefs: []
  type: TYPE_NORMAL
- en: A `Secret` resource – This is a standard Kubernetes Secret resource containing
    the service account credentials for Kubernetes to connect with GCP Secret Manager.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `ClusterSecretStore` resource – This resource contains configuration for connecting
    with the secret store (GCP Secret Manager in this case) and uses the `Secret`
    resource for the service account credentials.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An `ExternalSecret` resource – This resource contains configuration to generate
    the required Kubernetes Secret (`mongodb-creds`) out of the extracted Secret from
    the secret store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, let’s go ahead and define the `Secret` resource first:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the `Secret` resource, we first need to create a GCP service account
    to interact with Secret Manager using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As we’re following the principle of least privilege, we will add the following
    role-binding to provide access only to the `external-secrets` secret, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s generate the service account key file using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, copy the contents of the `key.json` file into a new GitHub Actions secret
    called `GCP_SM_CREDENTIALS`. We will use GitHub Actions to set this value during
    runtime dynamically; therefore, the following secret manifest will contain a placeholder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the `ClusterSecretStore` resource next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The manifest defines the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A `ClusterSecretStore` resource called `gcp-backend`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A provider configuration of the `gcpsm` type using auth information in the `gcpsm-secret`
    secret we defined before
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let’s look at the `ExternalSecret` resource manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The manifest defines an `ExternalSecret` resource with the following specs:'
  prefs: []
  type: TYPE_NORMAL
- en: It is named `mongodb-creds` in the `blog-app` namespace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It refers to the `gcp-backend` `ClusterSecretStore` that we defined.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It maps `MONGO_INITDB_ROOT_USERNAME` from the `external-secrets` Secret Manager
    secret to the `MONGO_INITDB_ROOT_USERNAME` key of the `mongodb-creds` Kubernetes
    secret. It does the same for `MONGO_INITDB_ROOT_PASSWORD`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let’s deploy these resources by using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This should trigger a GitHub Actions workflow again, and soon, we should see
    `ClusterSecretStore` and `ExternalSecret` created. To check that, run the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The same should be reflected in the `blog-app` application on Argo CD, and
    the application should come up clean, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.8 – blog-app showing as Healthy](img/B19877_13_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.8 – blog-app showing as Healthy
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then access the application by getting the frontend service external
    IP using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'You can access the application by visiting `http://<EXTERNAL_IP>` from a browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.9 – Blog App home page](img/B19877_13_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.9 – Blog App home page
  prefs: []
  type: TYPE_NORMAL
- en: 'And as we can see, we can access the Blog App successfully. That is proper
    secret management, as we did not store the secret in the source code repository
    (Git). We did not view or log the secret while applying it, meaning there is no
    trace of this secret anywhere in the logs, and only the application or people
    who have access to the namespace where this application is running can access
    it. Now, let’s look at another crucial aspect: testing your application.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing your application within the CD pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Until now, we’ve deployed our application on a Kubernetes cluster and manually
    verified that it is running. We have two options moving forward: either proceed
    with manual testing or create automated tests, also known as a **test suite**.
    While manual testing is the traditional approach, DevOps heavily emphasizes automating
    tests to integrate them into your CD pipeline. This way, we can eliminate many
    repetitive tasks, often called **toil**.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve developed a Python-based integration test suite for our application, covering
    various scenarios. One significant advantage of this test suite is that it treats
    the application as a black box. It remains unaware of how the application is implemented,
    focusing solely on simulating end user interactions. This approach provides valuable
    insights into the application’s functional aspects.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, since this is an integration test, it assesses the entire application
    as a cohesive unit, in contrast to the unit tests we ran in our CI pipeline, where
    we tested each microservice in isolation.
  prefs: []
  type: TYPE_NORMAL
- en: Without further delay, let’s integrate the integration test into our CD pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: CD workflow changes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Till now, we have the following within our CD workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Both the Dev and Prod CD workflows contain the following jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, they are both calling the `create-cluster.yml` workflow, which
    creates our environment and deploys our application. We need to run integration
    tests both within the Dev and Prod environments; therefore, we need to change
    both workflows to include the `Run Integration Tests` step as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the step calls the `run-tests.yml` workflow. That is the workflow
    that will be doing the integration tests. Let’s look at the workflow to understand
    it better:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The workflow performs the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: It is triggered exclusively through a `workflow` call.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It has the `./tests` working directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It checks out the committed code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It installs the `gcloud` CLI and authenticates with Google Cloud using the `GCP_CREDENTIALS`
    service account credentials.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It connects `kubectl` to the Kubernetes cluster to retrieve the application
    URL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the application URL, it executes the integration test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let’s proceed to update the workflow and add tests using the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This should trigger the Dev CD GitHub Actions workflow again. You should see
    something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Added tests workflow run](img/B19877_13_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.10 – Added tests workflow run
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, there are two steps in our workflow, and both are now successful.
    To explore what was tested, you can click on the **Run Integration Tests** step,
    and it should show you the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.11 – The Run Integration Tests workflow step](img/B19877_13_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.11 – The Run Integration Tests workflow step
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the **Run Integration Tests** step reports that all tests have
    passed.
  prefs: []
  type: TYPE_NORMAL
- en: While images are being built, deployed, and tested using your CI/CD toolchain,
    there is nothing in between to prevent someone from deploying an image in your
    Kubernetes cluster. You might be scanning all your images for vulnerabilities
    and mitigating them, but somewhere, someone might bypass all controls and deploy
    containers directly to your cluster. So, how can you prevent such a situation?
    The answer to that question is through binary authorization. Let’s explore this
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Binary authorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Binary authorization** is a deploy-time security mechanism that ensures that
    only trusted binary files are deployed within your environments. In the context
    of containers and Kubernetes, binary authorization uses signature validation and
    ensures that only container images signed by a trusted authority are deployed
    within your Kubernetes cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: Using binary authorization gives you tighter control over what is deployed in
    your cluster. It ensures that only tested containers and those approved and verified
    by a particular authority (such as security tooling or personnel) are present
    in your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Binary authorization works by enforcing rules within your cluster via an admission
    controller. This means you can create rulesets only to allow images signed by
    an attestation authority to be deployed in your cluster. Your **quality assurance**
    (**QA**) team can be a good attestor in a practical scenario. You can also embed
    the attestation within your CI/CD pipelines. The attestation means your images
    have been tested and scanned for vulnerabilities and have passed a minimum standard
    to be ready to be deployed to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'GCP provides binary authorization embedded within GKE, based on the open source
    project **Kritis** ([https://github.com/grafeas/kritis](https://github.com/grafeas/kritis)).
    It uses a **public key infrastructure** (**PKI**) to attest and verify images—so
    your images are signed by an attestor authority using the private key, and Kubernetes
    verifies the images by using the public key. The following diagram explains this
    beautifully:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.12 – Binary authorization process](img/B19877_13_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.12 – Binary authorization process
  prefs: []
  type: TYPE_NORMAL
- en: In the hands-on exercise, we will set up binary authorization and a PKI using
    Google Cloud KMS. Next, we will create a QA attestor and an attestation policy
    for all binary auth-enabled GKE clusters, ensuring that only attested images can
    be deployed. Since our application is now tested, the next step is to attest the
    tested images. So, let’s proceed to set up binary authorization within our Dev
    CD workflow in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up binary authorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we’re using GitOps right from the beginning, we will use Terraform to set
    up binary authorization for us. We’ll start by setting up some GitHub Actions
    secrets. Go to `https://github.com/<your_github_user>/mdo-environments/settings/secrets/actions`
    and create the following secrets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We’ll then create a `binaryauth.tf` file with the following resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll begin by creating a Google KMS key ring. Since binary authorization utilizes
    PKI for creating and verifying attestations, this key ring will enable our attestor
    to digitally sign attestations for images. Please note the `count` attribute defined
    in the following code. This ensures that it is created exclusively in the `dev`
    environment, where we intend to use the attestor for attesting images after testing
    our app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then use a Google-provided `binary-authorization` Terraform module
    to create our `quality-assurance` attestor. That attestor uses the Google KMS
    key ring we created before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we will create a binary authorization policy that specifies the cluster’s
    behavior when deploying a container. In this scenario, our objective is to deploy
    only attested images. However, we will make a few exceptions, allowing Google-provided
    system images, Argo CD, and External Secrets Operator images. We will set the
    `global_policy_evaluation_mode` attribute to `ENABLE` to avoid enforcing the policy
    on system images managed by Google.
  prefs: []
  type: TYPE_NORMAL
- en: The `admission_whitelist_patterns` section defines container image patterns
    permitted to be deployed without attestations. This includes patterns for Google-managed
    system images, the Argo CD registry, the External Secrets registry, and the Redis
    container used by Argo CD.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `defaultAdmissionRule` section mandates attestation using the attestor
    we created. Therefore, any other images would require attestation to run on the
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'To enforce the binary authorization policy within a cluster, we must also enable
    binary authorization. To do so, we add the following block within the `cluster.tf`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This dynamic block is created exclusively when the branch name is `prod`. The
    reason for this approach is our intention to deploy our code to the Dev environment
    without image attestation, conduct testing, and then attest the images if the
    tests succeed. Therefore, only the Prod cluster should disallow unattested images.
    To achieve this, we will include the following steps in the Dev CD workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, this calls the `attest-images.yml` workflow. Let’s look at
    that now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The YAML file performs several tasks, including the installation of `gcloud`
    and authentication with GCP. It also installs the `gcloud beta` CLI and, importantly,
    attests images.
  prefs: []
  type: TYPE_NORMAL
- en: To attest images, it searches the `blog-app.yaml` manifest for all images. For
    each image, it checks whether the image is in the `sha256` digest format. If yes,
    it proceeds to attest the image.
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting that the workflow verifies that images are specified using
    a `sha256` digest format rather than a tag in the image definition. This choice
    is crucial when working with binary authorization. Why? Because binary authorization
    requires deploying images with their `sha256` digest instead of a tag. This precaution
    is essential because, with tags, anyone can associate a different image with the
    same tag as the attested image and push it to the container registry. In contrast,
    a digest is a hash generated from a Docker image. Therefore, as long as the image’s
    content remains unchanged, the digest remains the same. This prevents any attempts
    to bypass binary authorization controls.
  prefs: []
  type: TYPE_NORMAL
- en: 'The format for specifying images in this manner is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, before pushing the changes to the remote repository, let’s replace
    the image tags with `sha256` digests. Use the following commands to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify whether the changes were successful, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the images have been updated. Now, let’s proceed to push the
    changes to the remote repository using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s review the Dev CD workflow on GitHub Actions, where we should observe
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.13 – Dev CD workflow – Attest Images](img/B19877_13_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.13 – Dev CD workflow – Attest Images
  prefs: []
  type: TYPE_NORMAL
- en: 'As is evident, the workflow has successfully configured binary authorization
    and attested our images. To verify, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the attestations have been successfully created. Having deployed
    our application in the Dev environment, tested it, and attested all the images
    within, we can now proceed with deploying the code to the Prod environment. This
    involves merging our code with the `prod` branch, and we will implement pull request
    gating for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Release gating with pull requests and deployment to production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The process of pull request gating is straightforward. At the end of the Dev
    CD workflow, we’ll introduce a step to initiate a pull request to merge `dev`
    into the `prod` branch. Human approval is required to proceed with merging the
    pull request. This step highlights how various organizations may adopt different
    methods to verify and promote tested code. Some may opt for automated merging,
    while others may prioritize human-triggered actions. Once the code is successfully
    merged into the `prod` branch, it triggers the Prod CD workflow. This workflow
    creates the Prod environment and deploys our application. It also executes the
    same integration test we ran in the Dev environment to ensure the deployed application
    in Prod remains intact.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the step we’ll add to the Dev CD workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, this step invokes the `raise-pr.yml` file. Let’s look at that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'This workflow does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Checks out the code from the repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raises a pull request to merge with the `prod` branch using the `GH_TOKEN` secret
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To enable the workflow’s functionality, we need to define a GitHub token. This
    token allows the workflow to act on behalf of the current user when creating the
    pull request. Here are the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://github.com/settings/personal-access-tokens/new](https://github.com/settings/personal-access-tokens/new).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new token with `mdo-environments` repository, granting it the `read-write`
    pull request permission. This approach aligns with the principle of least privilege,
    offering more granular control.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the token is created, copy it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, create a GitHub Actions secret named `GH_TOKEN` and paste the copied token
    as the value. You can do this by visiting `https://github.com/<your_github_user>/mdo-environments/settings/secrets/actions`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, let’s proceed to copy the workflow files using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We’re ready to push this code to GitHub. Run the following commands to commit
    and push the changes to your GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'This should trigger a GitHub Actions workflow in your GitHub repository, and
    you should observe something similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.14 – Raising a pull request](img/B19877_13_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.14 – Raising a pull request
  prefs: []
  type: TYPE_NORMAL
- en: GitHub has generated a pull request to merge the code into the `prod` branch,
    and the Dev CD workflow is running as anticipated. We can now review the pull
    request and merge the code into the `prod` branch.
  prefs: []
  type: TYPE_NORMAL
- en: Merging code and deploying to prod
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As demonstrated in the previous section, the Dev CD workflow created our environment,
    deployed the application, tested it, and attested application images. It then
    automatically initiated a pull request to merge the code into the `prod` branch.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve entered the `prod` branch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we know the pull request has been created, let’s proceed to inspect and
    approve it. To do so, go to `https://github.com/<your_github_user>/mdo-environments/pulls`,
    where you will find the pull request. Click on the pull request, and you will
    encounter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.15 – Pull request](img/B19877_13_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.15 – Pull request
  prefs: []
  type: TYPE_NORMAL
- en: We see that the pull request is ready to merge. Click on `prod` branch.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you go to `https://github.com/<your_user>/mdo-environments/actions`, you’ll
    find that the Prod CD workflow has been triggered. When you click on the workflow,
    you will see a workflow run like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.16 – Prod CD workflow](img/B19877_13_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.16 – Prod CD workflow
  prefs: []
  type: TYPE_NORMAL
- en: When we merged the pull request, it automatically triggered the Prod CD workflow
    as it would react to any new changes in the `prod` branch. The workflow did its
    job by building the Prod environment, deploying our application, and testing it.
    Note that binary authorization is enabled for this cluster.
  prefs: []
  type: TYPE_NORMAL
- en: To confirm that binary authorization is functioning correctly, let’s perform
    some checks to ensure unattested images cannot be deployed.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s establish a connection to the `prod` cluster using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s attempt to deploy a pod to your cluster using an `nginx` image. Please
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Now, as expected, the deployment failed, but there’s something else to note
    if you examine the reason. The failure happened because we specified a tag instead
    of a `sha256` digest. Let’s attempt to deploy the image again, but this time,
    with a digest.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, let’s retrieve the image digest and set it as a variable called `DIGEST`
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s redeploy the image using the digest with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: This time, the deployment was denied for a valid reason, confirming that binary
    authorization functions correctly. This ensures the security of your Kubernetes
    cluster, preventing the deployment of unattested images and giving you complete
    control over your environment. With this in place, any issues that arise won’t
    stem from deploying untested or vulnerable images.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve covered a lot of ground in integrating security and QA into our CI/CD
    pipelines. Now, let’s explore some best practices for securing modern DevOps pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Security and testing best practices for modern DevOps pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tooling is not the only thing that will help you in your DevSecOps journey.
    Here are some helpful tips that can help you address security risks and have a
    more secure culture within your organization.
  prefs: []
  type: TYPE_NORMAL
- en: Adopt a DevSecOps culture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adopting a DevSecOps approach is critical in implementing modern DevOps. Therefore,
    it is vital to embed security within an organization’s culture. You can achieve
    that by implementing effective communication and collaboration between the *development*,
    *operations*, and *security* teams. While most organizations have a security policy,
    it mustn’t be followed just to comply with rules and regulations. Instead, employees
    should cross-skill and upskill themselves to adopt a DevSecOps approach and embed
    security early on during development. Security teams need to learn how to write
    code and work with APIs, while developers need to understand security and use
    automation to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Establish access control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You have heard about the **Principle of Least Privilege** (**PoLP**) several
    times in this book. Well, that is what you need to implement for a better security
    posture, which means you should make all attempts to grant only the required privileges
    to people to do their job, and nothing more. Reduce the just-in-case syndrome
    by making the process of giving access easier so that people don’t feel hindered,
    and as a result, they do not seek more privileges than they require.
  prefs: []
  type: TYPE_NORMAL
- en: Implement shift left
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Shifting left means embedding security into software at the earlier stages of
    software development. This means security experts need to work closely with developers
    to enable them to build secure software right from the start. The security function
    should not be review-only but should actively work with developers and architects
    to develop a security-hardened design and code.
  prefs: []
  type: TYPE_NORMAL
- en: Manage security risks consistently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should accept risks, which are inevitable, and should have a **Standard
    Operating Procedure** (**SOP**) should an attack occur. You should have straightforward
    and easy-to-understand policies and practices from a security standpoint in all
    aspects of software development and infrastructure management, such as **configuration
    management**, **access controls**, **vulnerability testing**, **code review**,
    and **firewalls**.
  prefs: []
  type: TYPE_NORMAL
- en: Implement vulnerability scanning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open source software today is snowballing, and most software implementations
    rely on ready-made open source frameworks, software libraries, and third-party
    software that don’t come with a guarantee or liability of any kind. While the
    open source ecosystem is building the technological world like never before, it
    does have its own share of vulnerabilities, which you don’t want to insert within
    your software through no fault of your own. Vulnerability scanning is crucial,
    as scans can discover any third-party dependency with vulnerabilities and alert
    you at the initial stage.
  prefs: []
  type: TYPE_NORMAL
- en: Automate security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Security should not hinder the speed of your DevOps teams; therefore, to keep
    up with the fast pace of DevOps, you should look at embedding security within
    your CI/CD processes. You can do code analysis, vulnerability scanning, configuration
    management, and infrastructure scanning with policy as code and binary authorization
    to allow only tested and secure software to be deployed. Automation helps identify
    potential vulnerabilities early on in the software development life cycle, thereby
    bringing down the cost of software development and rework.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, QA is the backbone of software delivery, and modern DevSecOps heavily
    emphasizes automating it. Here are some tips you can follow to implement a modern
    testing approach.
  prefs: []
  type: TYPE_NORMAL
- en: Test automation within your CI/CD pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automating testing across the board is key. This means encompassing a wide spectrum,
    from unit and integration testing to functional, security, and performance testing.
    The goal is to seamlessly embed these tests within your CI/CD pipeline, ensuring
    a constant stream of validation. In this journey, creating isolated and reproducible
    test environments becomes crucial to thwart any interference among tests. Here,
    methods such as containerization and virtualization are valuable tools for environment
    isolation.
  prefs: []
  type: TYPE_NORMAL
- en: Manage your test data effectively
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Test data management is another pivotal aspect. It’s imperative to handle your
    test data effectively, not only ensuring its consistency but also safeguarding
    data privacy. Leveraging data generation tools can be a game-changer in this regard,
    allowing you to create relevant datasets for your testing needs. Moreover, when
    dealing with sensitive information, the consideration of data anonymization is
    prudent. This ensures that you maintain the highest standards of data protection
    while still benefiting from comprehensive testing procedures.
  prefs: []
  type: TYPE_NORMAL
- en: Test all aspects of your application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CI is all about keeping the development process flowing smoothly. This involves
    frequently merging code and running tests automatically, ensuring the code base
    remains stable. When tests fail, immediate attention is crucial to rectify the
    issues promptly.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end testing is your compass to ensure the entire application workflow
    functions as expected. Automation frameworks play a pivotal role in replicating
    real user interactions, making it possible to assess your application thoroughly.
  prefs: []
  type: TYPE_NORMAL
- en: Load testing is an essential part of the process, as it evaluates how your application
    performs under varying loads, providing insights into its robustness and capacity.
    Additionally, scalability testing ensures that the system is well-equipped to
    handle growth, an important factor for the long-term health of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Implement chaos engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Incorporating chaos engineering practices is a proactive strategy to uncover
    and address potential system weaknesses. By conducting controlled experiments,
    you can gauge the resilience of your system and better prepare it for unexpected
    challenges. These experiments involve intentionally introducing chaos into your
    environment to observe how your system responds. This not only helps you identify
    weaknesses but also provides valuable insights into how to make your system more
    robust and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: Monitor and observe your application when it is being tested
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Setting up robust monitoring and observability tools is crucial for gaining
    deep insights into your system’s performance and behavior. These tools allow you
    to collect essential metrics, logs, and traces, providing a comprehensive view
    of your application’s health and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Effective testing in production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implementing feature flags and canary releases is a prudent strategy for testing
    new functionality in a real production environment while minimizing risks. Feature
    flags allow you to enable or disable certain features at runtime, giving you control
    over their activation. Canary releases involve rolling out new features to a small
    subset of users, allowing you to monitor their impact before a full-scale release.
  prefs: []
  type: TYPE_NORMAL
- en: By utilizing feature flags, you can introduce new features to a limited audience
    without affecting the entire user base. This controlled approach lets you observe
    user interactions, collect feedback, and assess the feature’s performance in a
    real-world scenario. Simultaneously, canary releases enable you to deploy these
    features to a small, representative group of users, allowing you to monitor their
    behavior, collect performance metrics, and identify potential issues.
  prefs: []
  type: TYPE_NORMAL
- en: Crucially, continuous monitoring is essential during this process. By closely
    observing the impact of the new functionality, you can quickly detect any issues
    that may arise. If problems occur, you have the flexibility to roll back the changes
    by simply turning off the feature flags or reverting to the previous version.
    This iterative and cautious approach minimizes the impact of potential problems,
    ensuring a smoother user experience and maintaining the stability of your production
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation and knowledge sharing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Documenting testing procedures, test cases, and best practices is essential
    for ensuring consistency and reliability within the development and testing processes.
    Comprehensive documentation serves as a reference for team members, providing
    clear guidelines on how to conduct tests, the expected outcomes, and the best
    practices to follow. This documentation acts as a valuable resource for both new
    and existing team members, fostering a shared understanding of the testing procedures.
  prefs: []
  type: TYPE_NORMAL
- en: Encouraging knowledge sharing among team members further enhances the collective
    expertise of the team. By promoting open communication and sharing experiences,
    team members can learn from one another, gain insights into different testing
    scenarios, and discover innovative solutions to common challenges. This collaborative
    environment promotes continuous learning and ensures that the team stays updated
    on the latest developments and techniques in the field of software testing.
  prefs: []
  type: TYPE_NORMAL
- en: By adhering to these best practices, teams can enhance the security and reliability
    of their CI/CD pipelines. Properly documented procedures and test cases enable
    consistent testing, reducing the likelihood of introducing errors into the code
    base. Knowledge sharing ensures that the team benefits from the collective wisdom
    and experiences of its members, leading to more informed decision-making and efficient
    problem-solving.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, managing security risks effectively becomes possible through well-documented
    testing procedures and disseminating best practices. Teams can identify potential
    security vulnerabilities early in the development process, enabling them to address
    these issues before they escalate into significant threats. Regular knowledge-sharing
    sessions can also include discussions about security best practices, ensuring
    that team members are aware of the latest security threats and countermeasures.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, these best practices contribute to a robust testing and development
    culture. They empower teams to deliver software faster and with confidence, knowing
    that their CI/CD pipelines are secure, reliable, and capable of handling the challenges
    of modern software development.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has covered CI/CD pipeline security and testing, and we have understood
    various tools, techniques, and best practices surrounding it. We looked at a secure
    CI/CD workflow for reference. We then understood, using hands-on exercises, the
    aspects that made it secure, such as secret management, container vulnerability
    scanning, and binary authorization.
  prefs: []
  type: TYPE_NORMAL
- en: Using the skills learned in this chapter, you can now appropriately secure your
    CI/CD pipelines and make your application more secure.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore the operational elements along with key
    performance indicators for running our application in production.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Which of these is the recommended place for storing secrets?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Private Git repository
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Public Git repository
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Docker image
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Secret management system
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which one of the following is an open source secret management system?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Secret Manager
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. HashiCorp Vault
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Anchore Grype
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is it a good practice to download a secret within your CD pipeline’s filesystem?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which base image is generally considered more secure and consists of the fewest
    vulnerabilities?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Alpine
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Slim
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Buster
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Default
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which of the following answers are true about binary authorization? (Choose
    two)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. It scans your images for vulnerabilities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. It allows only attested images to be deployed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. It prevents people from bypassing your CI/CD pipeline.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: B
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'No'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: B and C
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Part 5:Operating Applications in Production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part provides a comprehensive guide to managing containers in production.
    We will start by covering key performance indicators and reliability principles
    and then explore Istio for advanced security, traffic management, and observability.
    This section will equip you with crucial skills to optimize container-based applications
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 14*](B19877_14.xhtml#_idTextAnchor1812), *Understanding Key Performance
    Indicators (KPIs) for Your Production Service*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 15*](B19877_15.xhtml#_idTextAnchor1834), *Operating Containers in
    Production with Istio*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
