- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containerization with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we talked about source code management with Git, where
    we took a crash course on Git and then discussed GitOps and how it shapes modern
    DevOps practices.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll get hands-on and explore **Docker** – the de facto container
    runtime. By the end of this chapter, you should be able to install and configure
    Docker, run your first container, and then monitor it. This chapter will also
    form the basis for the following chapters, as we will use the same setup for the
    demos later.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Docker storage drivers and volumes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running your first container
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker logging and logging drivers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker monitoring with Prometheus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Declarative container management with Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, you will need a Linux machine running Ubuntu 18.04 Bionic
    LTS or later with sudo access. We will be using Ubuntu 22.04 Jammy Jellyfish for
    the entirety of this book, but feel free to use any OS of your choice. I will
    post links to alternative installation instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also need to clone the following GitHub repository for some of the
    exercises: [https://github.com/PacktPublishing/Modern-DevOps-Practices-2e](https://github.com/PacktPublishing/Modern-DevOps-Practices-2e).'
  prefs: []
  type: TYPE_NORMAL
- en: We discussed Git extensively in the previous chapter; therefore, you can easily
    clone the repository using that knowledge. Now, let’s move on to installing Docker
    on your machine.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be installing Docker in an Ubuntu system. For other OSs, please refer
    to [https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/).
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Docker, we need to install supporting tools to allow the `apt` package
    manager to download Docker through HTTPS. Let’s do so using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Download the Docker gpg key and add it to the apt package manager:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you need to add the Docker repository to your `apt` configuration so
    that you can download packages from there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, install the Docker engine by using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify whether Docker has been installed successfully, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You should expect a similar output to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The next thing you should do is allow regular users to use Docker. You want
    your users to act as something other than root for building and running containers.
    To do that, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: To apply the changes to your profile, log out from your virtual machine and
    log back in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that Docker has been fully set up on your machine, let’s run a `hello-world`
    container to see this for ourselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You will also receive the following message, which tells you what happened
    behind the scenes to print the `Hello from Docker!` message on your screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: All this helpful information is self-explanatory. To explain Docker Hub a bit,
    it is a public Docker container registry that hosts many Docker images for people
    like you and me to consume.
  prefs: []
  type: TYPE_NORMAL
- en: As Docker works on a layered architecture, most Docker images are derived from
    one or more base images hosted on Docker Hub. So, please create a Docker Hub account
    for yourself to host your containers and share them with the rest of the world.
  prefs: []
  type: TYPE_NORMAL
- en: Most organizations might want to keep their images private, so you have the
    option of creating private repositories within Docker Hub. You can also host your
    own internal Docker registry using a SaaS service such as **Google Container Registry**
    (**GCR**), or installing an artifact repository such as **Sonatype Nexus** or
    **JFrog Artifactory**. Whatever your choice of tool, the mechanism and how it
    works always remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Docker storage drivers and volumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker containers are ephemeral workloads. Whatever data you store on your container
    filesystem gets wiped out once the container is gone. The data lives on a disk
    during the container’s life cycle but does not persist beyond it. Pragmatically
    speaking, most applications in the real world are stateful. They need to store
    data beyond the container life cycle and want it to persist.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do we go along with that? Docker provides several ways you can store
    data. By default, all data is stored on the writable container layer, which is
    ephemeral. The writable container layer interacts with the host filesystem via
    a storage driver. Because of the abstraction, writing files to the container layer
    is slower than writing directly to the host filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: To solve that problem and also provide persistent storage, Docker provides volumes,
    bind mounts, and `tmpfs`. With them, you can interact directly with the host filesystem
    (and memory in the case of `tmpfs`) and save a ton of **I/O operations per second**
    (**IOPS**), improving performance. While this section focuses on storage drivers
    that cater to the container filesystem, it is worth discussing multiple data storage
    options within Docker to provide a background.
  prefs: []
  type: TYPE_NORMAL
- en: Docker data storage options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every option has a use case and trade-off. Let’s look at each option and where
    you should use which.
  prefs: []
  type: TYPE_NORMAL
- en: Volumes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Docker volumes store the data directly in the host’s filesystem. They do not
    use the storage driver layer in between, so writing to volumes is faster. They
    are the best way to persist data. Docker stores volumes in `/var/lib/docker/volumes`
    and assumes that no one apart from the Docker daemon can modify the data on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result, volumes provide the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Provide some isolation with the host filesystems. If you don’t want other processes
    to interact with the data, then a volume should be your choice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can share a volume with multiple containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Volumes can either be named or anonymous. Docker stores anonymous volumes in
    a directory with a unique random name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Volumes enable you to store data remotely or in a cloud provider using volume
    drivers. This helps a lot if multiple containers share the same volume to provide
    a multi-instance active-active configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data in the volume persists even when the containers are deleted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s look at another storage option – bind mounts.
  prefs: []
  type: TYPE_NORMAL
- en: Bind mounts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Bind mounts are very similar to volumes but with a significant difference:
    they allow you to mount an existing host directory as a filesystem on the container.
    This lets you share important files with the Docker container, such as `/etc/resolv.conf`.'
  prefs: []
  type: TYPE_NORMAL
- en: Bind mounts also allow multiple processes to modify data along with Docker.
    So, if you are sharing your container data with another application that is not
    running in Docker, bind mounts are the way to go.
  prefs: []
  type: TYPE_NORMAL
- en: tmpfs mounts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`tmpfs` mounts store data in memory. They do not store any data on disk – neither
    the container nor the host filesystem. You can use them to store sensitive information
    and the non-persistent state during the lifetime of your container.'
  prefs: []
  type: TYPE_NORMAL
- en: Mounting volumes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you mount a host directory that already contains files to an empty volume
    of the container, the container can see the files stored in the host. This is
    an excellent way to pre-populate files for your container(s) to use. However,
    if the directory does not exist in the host filesystem, Docker will create the
    directory automatically. If the volume is non-empty and the host filesystem already
    contains files, Docker will obscure the mount. This means that while you won’t
    see the original files while the Docker volume is mounted to it, the files are
    not deleted, and you can recover them by unmounting the Docker volume.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll look at Docker storage drivers in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Docker storage drivers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are numerous storage driver types. Some of the most popular ones are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`overlay2`: This is a production-ready driver and is the preferred storage
    choice for Docker. It works in most environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`devicemapper`: This was the preferred driver for devices running RHEL and
    CentOS 7 and below that did not support `overlay2`. You can use this driver if
    you have write-intensive activities in your containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`btrfs` and `zfs`: These drivers are write-intensive and provide many features,
    such as allowing snapshots, and can only be used if you are using `btrfs` or `zfs`
    filesystems within your host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vfs`: This storage driver should be used only if no copy-on-write filesystem
    is available. It is extremely slow, and you should refrain from using it in production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s concentrate on two of the most popular ones – `overlay2` and `devicemapper`.
  prefs: []
  type: TYPE_NORMAL
- en: overlay2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`overlay2` is the default and recommended storage driver in most operating
    systems except RHEL 7 and CentOS 7 and older. They use file-based storage and
    perform best when subject to more reads than writes.'
  prefs: []
  type: TYPE_NORMAL
- en: devicemapper
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`devicemapper` is block-based storage and performs the best when subject to
    more writes than reads. Though it is compatible and the default with CentOS 7,
    RHEL 7, and below, as they don’t support `overlay2`, it is currently not recommended
    in the newer versions of these operating systems that do support `overlay2`.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Use `overlay2` where possible, but if you have a specific use case for not using
    it (such as too many write-intensive containers), `devicemapper` is a better choice.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a storage driver
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this discussion, we will configure `overlay2` as the storage driver. Although
    it is configured by default, and you can skip the steps if you are following this
    book, it is worth a read in case you want to change it to something else.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s list the existing storage driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the existing storage driver is already `overlay2`. Let’s learn
    how to change it to `devicemapper` if we had to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `/etc/docker/daemon.json` file using an editor of your choice. If
    you’re using `vim`, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the `storage-driver` entry to the `daemon.json` configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, restart the Docker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the status of the Docker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, rerun `docker info` to see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see the `devicemapper` storage driver. We can also see several
    warnings with it that say that the `devicemapper` storage driver is deprecated
    and will be removed in a future version.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we should stick with the defaults unless we have a particular requirement.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s roll back our changes and set the storage driver to `overlay2` again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify the `storage-driver` entry in the `daemon.json` configuration file to
    `overlay2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, restart the Docker service and check its status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If you rerun `docker info`, you will see the storage driver as `overlay2`,
    and all the warnings will disappear:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Changing the storage driver will wipe out existing containers from the disk,
    so exercise caution when you do so and take appropriate downtimes if you’re doing
    this in production. You will also need to pull images again since local images
    will fail to exist.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have installed Docker on our machine and configured the right storage
    driver, it’s time to run our first container.
  prefs: []
  type: TYPE_NORMAL
- en: Running your first container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can create Docker containers out of Docker container images. While we will
    discuss container images and their architecture in the following chapters, an
    excellent way to visualize them is as a copy of all files, application libraries,
    and dependencies comprising your application environment, similar to a virtual
    machine image.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run a Docker container, we can use the `docker run` command, which has the
    following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Let’s look at the `docker run` command and its variations using working examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'In its simplest form, you can use `docker run` by simply typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you may recall, we used this command when we installed Docker. Here, I have
    purposefully omitted `tag`, `options`, `command`, and `arguments`. We will cover
    it with multiple examples to show its actual use cases.
  prefs: []
  type: TYPE_NORMAL
- en: As we didn’t supply `tag`, Docker automatically assumed the `tag` as `latest`,
    so if you look at the command output, you will see that Docker is pulling the
    `hello-world:latest` image from Docker Hub.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at an example with a specific version tag.
  prefs: []
  type: TYPE_NORMAL
- en: Running containers from versioned images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can run `nginx:1.18.0` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the prompt will be stuck after this. There is a reason for this:
    `nginx` is a long-running process, also known as a daemon. Since NGINX is a web
    server that needs to listen to HTTP requests continuously, it should never stop.
    In the case of the `hello-world` application, its only job was to print the message
    and exit. NGINX has a different purpose altogether.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, no one would keep a Bash session open for a web server to run, so there
    has to be some way to run it in the background. You can run containers in the
    detached mode for that. We’ll have a look at this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Running Docker containers in the background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To run a Docker container in the background as a daemon, you can use `docker
    run` in detached mode using the `-``d` flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it just prints a random ID and provides control back to the
    shell.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To see what’s going on within the container, you can use the `docker logs` command.
    But before using that, we need to know the container’s ID or name to see the container’s
    logs.
  prefs: []
  type: TYPE_NORMAL
- en: To get a list of containers running within the host, run the following command
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command lists the NGINX container that we just started. Unless
    you specify a particular name for your container, Docker allocates a random name
    to it. In this case, it has called it `fervent_shockley`. It also assigns every
    container a unique container ID, such as `beb5dfd529c9`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the container ID or the container name to interact with the container
    to list the logs. Let’s use the container ID this time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it prints a similar log output as it did when we ran it in the
    foreground.
  prefs: []
  type: TYPE_NORMAL
- en: Practically speaking, you will use `docker logs` 90% of the time unless you
    need to debug something with BusyBox. BusyBox is a lightweight shell container
    that can help you troubleshoot and debug issues with your container – mostly network
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make BusyBox echo `Hello World!` for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, Docker pulls the latest `busybox` image from Docker Hub and runs
    the `echo 'Hello` `World'` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use BusyBox in interactive mode by using the `-it` flag, which
    will help you run a series of commands on the BusyBox shell. It is also a good
    idea to add an `--rm` flag to it to tell Docker to clean up the containers once
    we have exited from the shell, something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon listing all the containers, we do not see the `busybox` container in there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: There are various other flags that you can use with your containers, each serving
    a specific purpose. Let’s look at a few common ones.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The best setting for a highly available NGINX container should be something
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a look at this in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-d`: Run as a daemon in detached mode.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--name nginx`: Give the name `nginx`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--restart unless-stopped`: Always automatically restart on failures unless
    explicitly stopped manually, and also start automatically on Docker daemon startup.
    Other options include `no`, `on_failure`, and `always`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-p 80:80`: Forward traffic from host port `80` to container port `80`. This
    allows you to expose your container to your host network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--memory 1000M`: Limit the container memory consumption to `1000M`. If the
    memory exceeds this limit, the container stops and acts according to the `--``restart`
    flag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--memory-reservation 250M`: Allocate a soft limit of `250M` memory to the
    container if the server runs out of memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will look into other flags in the subsequent sections as we get more hands-on.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Consider using `unless-stopped` instead of `always` as it allows you to stop
    the container manually if you want to do some maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s list the containers and see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: If you look carefully, you’ll see a container called `nginx` and a port forward
    from `0.0.0.0:80 ->` `80`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s `curl` on `localhost:80` on the host to see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the NGINX welcome message. This means NGINX is running successfully,
    and we can access it from the machine. If you have exposed your machine’s port
    `80` to the external world, you can also access this using your browser as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – The NGINX welcome page](img/B19877_Figure_3.01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – The NGINX welcome page
  prefs: []
  type: TYPE_NORMAL
- en: You also might want to restart or remove your container occasionally. We’ll
    look at ways to do that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Restarting and removing containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To restart your containers, you must stop them first and then start them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To stop your container, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'To start your container, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to get rid of your container completely, you need to stop your
    container first and then remove it, using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use the following command to do it in one go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s look at how we can monitor our containers with tools such as `journald`
    and Splunk.
  prefs: []
  type: TYPE_NORMAL
- en: Docker logging and logging drivers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker not only changed how applications are deployed but also the workflow
    for log management. Instead of writing logs to files, containers write logs to
    the console (`stdout`/`stderr`). Docker then uses a logging driver to export container
    logs to the specified destinations.
  prefs: []
  type: TYPE_NORMAL
- en: Container log management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Log management is an essential function within Docker, as with any application.
    However, due to the transient nature of Docker workloads, it becomes more critical
    as we lose the filesystem and potentially logs when the container is deleted or
    faces any issue. So, we should use log drivers to export the logs into a particular
    place and store and persist it. If you have a log analytics solution, the best
    place for your logs to be is within it. Docker supports multiple log targets via
    logging drivers. Let’s have a look.
  prefs: []
  type: TYPE_NORMAL
- en: Logging drivers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At the time of writing, the following logging drivers are available:'
  prefs: []
  type: TYPE_NORMAL
- en: '`none`: No logs are available for the container, and therefore they are not
    stored anywhere.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`local`: Logs are stored locally in a custom format, which minimizes overhead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`json-file`: The log files are stored in JSON format. This is the default Docker
    logging driver.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`syslog`: This driver uses `syslog` for storing the Docker logs as well. This
    option makes sense when you use `syslog` as your default logging mechanism.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`journald`: Uses `journald` to store Docker logs. You can use the `journald`
    command line to browse the container and the Docker daemon logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gelf`: Sends logs to a **Graylog Extended Log Format** (**GELF**) endpoint
    such as Graylog or Logstash.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fluentd`: Sends logs to Fluentd.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`awslogs`: Sends logs to AWS CloudWatch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`splunk`: Sends logs to Splunk using the HTTP Event Collector.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`etwlogs`: Sends logs to **Event Tracing for Windows** (**ETW**) events. You
    can only use it on Windows platforms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcplogs`: Sends logs to Google Cloud Logging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`logentries`: Sends logs to Rapid7 Logentries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While all these are viable options, we will look at `journald` and Splunk. While
    `journald` is a native operating system service monitoring option, Splunk is one
    of the most famous log analytics and monitoring tools. Now, let’s understand how
    to configure a logging driver.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring logging drivers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start by finding the current logging driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Currently, the default logging driver is set to `json-file`. If we want to use
    `journald` or Splunk as the default logging driver, we must configure the default
    logging driver in the `daemon.json` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `/etc/docker/daemon.json` file using an editor of your choice. If
    you’re using `vim`, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the `log-driver` entry to the `daemon.json` configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, restart the Docker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the status of the Docker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, rerun `docker info` to see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that `journald` is the default logging driver, let’s launch a new NGINX
    container and visualize the logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s look at the `journald` logs to see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: We can see the logs in the journal.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we can configure the Splunk logging driver to send data to Splunk
    for analytics and visualization. Let’s have a look.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `/etc/docker/daemon.json` file using an editor of your choice. If
    you’re using `vim`, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the log-driver entry to the `daemon.json` configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, restart the Docker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the status of the Docker service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, rerun `docker info` to see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Since Splunk is now the default logging driver, let’s launch a new NGINX container
    and visualize the logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Log in to your Splunk instance; you will see the Docker logs streaming. You
    can then analyze the logs and create visualizations out of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also have different logging drivers for different containers, and you
    can do so by overriding the defaults by passing the `log-driver` and `log-opts`
    flags from the command line. As our current configuration is Splunk, and we want
    to export data to a JSON file, we can specify `log-driver` as `json-file` while
    running the container. Let’s have a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: To visualize JSON logs, we need to look into the JSON log directory – that is,
    `/var/lib/docker/containers/<container_id>/<container_id>-json.log`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the `nginx-json-file` container, we can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the logs are now streaming to the JSON file instead of Splunk.
    That is how we override the default log driver.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, it is best to stick with one default logging driver so that you
    have one place to analyze and visualize your logs.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s understand some of the challenges and best practices associated with
    Docker logging.
  prefs: []
  type: TYPE_NORMAL
- en: Typical challenges and best practices to address these challenges with Docker
    logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker allows you to run multiple applications in a single machine or a cluster
    of machines. Most organizations run a mix of virtual machines and containers,
    and they have their logging and monitoring stack configured to support virtual
    machines.
  prefs: []
  type: TYPE_NORMAL
- en: Most teams struggle to make Docker logging behave the way virtual machine logging
    works. So, most teams will send logs to the host filesystem, and the log analytics
    solution then consumes the data from there. This is not ideal, and you should
    avoid making this mistake. It might work if your container is static, but it becomes
    an issue if you have a cluster of servers, each running Docker, and you can schedule
    your container in any virtual machine you like.
  prefs: []
  type: TYPE_NORMAL
- en: So, treating a container as an application running on a virtual machine is a
    mistake from a logging point of view. Instead, you should visualize the container
    as an entity – just like a virtual machine. It would be best if you never associated
    containers with a virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: One solution is to use the logging driver to forward the logs to a log analytics
    solution directly. But then, the logging becomes heavily dependent on the availability
    of the log analytics solution. So, it might not be the best thing to do. People
    faced issues when their services running on Docker went down because the log analytics
    solution was unavailable or there were network issues.
  prefs: []
  type: TYPE_NORMAL
- en: Well, the best way to approach this problem is to use JSON files to store the
    logs temporarily in your virtual machine and use another container to push the
    logs to your chosen log analytics solution the old-fashioned way. That way, you
    decouple from the dependency on an external service to run your application.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the logging driver to export logs directly to your log analytics
    solution within the log forwarder container. There are many logging drivers available
    that support many log targets. Always mark the logs in such a way that the containers
    appear as their own entities. This will disassociate containers from virtual machines,
    and you can then make the best use of a distributed container-based architecture.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve looked at the logging aspects of containers, but one of the essential
    elements of a DevOps engineer’s role is monitoring. We’ll have a look at this
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Docker monitoring with Prometheus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring Docker nodes and containers is an essential part of managing Docker.
    There are various tools available for monitoring Docker. While you can use traditional
    tools such as Nagios, Prometheus is gaining ground in cloud-native monitoring
    because of its simplicity and pluggable architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus is a free, open source monitoring tool that provides a dimensional
    data model, efficient and straightforward querying using the **Prometheus query
    language** (**PromQL**), efficient time series databases, and modern alerting
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: It has several exporters available for exporting data from various sources and
    supports both virtual machines and containers. Before we delve into the details,
    let’s look at some of the challenges with container monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges with container monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From a conceptual point of view, there is no difference between container monitoring
    and the traditional method. You still need metrics, logs, health checks, and service
    discovery. These aren’t things that are unknown or haven’t been explored before.
    The problem with containers is the abstraction that they bring with them; let’s
    look at some of the issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Containers behave like mini virtual machines; however, in reality, they are
    processes running on a server. However, they still have everything to monitor
    that we would in a virtual machine. A container process will have many metrics,
    very similar to virtual machines, to be treated as separate entities altogether.
    When dealing with containers, most people make this mistake when they map containers
    to a particular virtual machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers are temporary, and most people don’t realize that. When you have
    a container and it is recreated, it has a new IP. This can confuse traditional
    monitoring systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers running on clusters can move from one node (server) to another. This
    adds another layer of complexity as your monitoring tool needs to know where your
    containers are to scrape metrics from them. This should not matter with the more
    modern, container-optimized tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prometheus helps us address these challenges as it is built from a distributed
    application’s point of view. To understand this, we’ll look at a hands-on example.
    However, before that, let’s install Prometheus on a separate Ubuntu 22.04 Linux
    machine.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Prometheus
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Installing Prometheus consists of several steps, and for simplicity, I’ve created
    a Bash script for installing and setting up Prometheus on an Ubuntu machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following commands on a separate machine where you want to set up Prometheus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'To check whether Prometheus is installed and running, check the status of the
    Prometheus service using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: As the service is `Active`, we can conclude that Prometheus has been installed
    and is running successfully. The next step is configuring the Docker server to
    enable Prometheus to collect logs from it.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring cAdvisor and the node exporter to expose metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we’ll launch a cAdvisor container on the machine running Docker to expose
    the metrics of the Docker containers. cAdvisor is a metrics collector that scrapes
    metrics from containers. To launch the container, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that cAdvisor is running, we need to configure the node exporter to export
    node metrics on the Docker machine. To do so, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Now that the node exporter is running, let’s configure Prometheus to connect
    to cAdvisor and the node exporter and scrape metrics from there.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Prometheus to scrape metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now configure Prometheus on the Prometheus machine so that it can scrape
    the metrics from cAdvisor. To do so, modify the `/etc/prometheus/prometheus.yml`
    file so that it includes the following within the server running Prometheus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'After changing this configuration, we need to restart the Prometheus service.
    Use the following command to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s launch a sample web application that we will monitor using Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: Launching a sample container application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s run an NGINX container called `web` that runs on port `8081` on
    the Docker machine. To do so, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we’ve set up the Docker container, let’s go ahead and open the Prometheus
    UI by visiting `https://<PROMETHEUS_SERVER_EXTERNAL_IP>:9090` and then running
    the following query by typing it in the textbox:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'It should show something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Prometheus – container_memory_usage_bytes](img/B19877_Figure_3.02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – Prometheus – container_memory_usage_bytes
  prefs: []
  type: TYPE_NORMAL
- en: We can also view the time series of this metric by clicking on the **Graph**
    tab. However, before doing so, let’s load our NGINX service using the Apache Bench
    tool. Apache Bench is a load-testing tool that helps us fire HTTP requests to
    the NGINX endpoint using the command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'On your Docker server, run the following command to start a load test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'It will hit the endpoint with 100,000 requests, which means it provides a fair
    amount of load to do a memory spike. Now, if you open the **Graph** tab, you should
    see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Prometheus – container_memory_usage_bytes – Graph](img/B19877_Figure_3.03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – Prometheus – container_memory_usage_bytes – Graph
  prefs: []
  type: TYPE_NORMAL
- en: 'To visualize node metrics, we can use the following PromQL statement to get
    the `node_cpu` value of the Docker host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the following screenshot, it will provide us with the `node_cpu`
    metrics for multiple modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Prometheus – node_cpu](img/B19877_Figure_3.04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – Prometheus – node_cpu
  prefs: []
  type: TYPE_NORMAL
- en: There are a variety of other metrics that Prometheus gives you to visualize.
    Let’s understand some of the metrics you can monitor.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics to monitor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring metrics is a complex subject, and it would depend mostly on your
    use case. However, the following are some guidelines on what metrics you want
    to monitor.
  prefs: []
  type: TYPE_NORMAL
- en: Host metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You need to monitor your host metrics as your containers run on them. Some
    of the metrics that you can watch are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Host CPU**: It’s good to know whether your host has sufficient CPU to run
    your containers. If not, it might terminate some of your containers to account
    for that. So, to ensure reliability, you need to keep this in check.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Host memory**: Like the host CPU, you need to watch the host memory to detect
    issues such as memory leaks and runaway memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Host disk space**: As Docker containers use the host filesystem to store
    transient and persistent files, you need to monitor it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker container metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Docker container metrics are the next thing to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Container CPU**: This metric will provide the amount of CPU used by the Docker
    container. You should monitor it to understand the usability pattern and decide
    where to place your container effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throttled CPU time**: This metric allows us to understand the total time
    when the CPU was throttled for a container. This lets us know whether a particular
    container needs more CPU time than others, and you can adjust the CPU share constraint
    accordingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container memory fail counters**: This metric provides the number of times
    the container requested more than the allocated memory. It will help you understand
    what containers require more than the allocated memory, and you can plan to run
    those containers accordingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container memory usage**: This metric will provide the amount of memory used
    by the Docker container. You can set memory limits according to the usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container swap**: This metric will tell you what containers were using swap
    instead of RAM. It helps us identify memory-hungry containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container disk I/O**: This is an important metric and will help us understand
    containers’ disk profiles. Spikes can indicate a disk bottleneck or suggest that
    you might want to revisit your storage driver configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container network metrics**: This metric will tell us how much network bandwidth
    the containers use and help us understand traffic patterns. You can use these
    to detect an unexpected network spike or a denial-of-service attack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important tip
  prefs: []
  type: TYPE_NORMAL
- en: Profiling your application during the performance testing phase in the non-production
    environment will give you a rough idea of how the system will behave in production.
    The actual fine-tuning of your application begins when you deploy them to production.
    Therefore, monitoring is critical, and fine-tuning is a continuous process.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have been running commands to do most of our work. That is the imperative
    way of doing this. But what if I told you that instead of typing commands, you
    could declare what you want, and something could run all the required commands
    on your behalf? That is known as the declarative method of managing an application.
    Docker Compose is one of the popular tools to achieve this. We’ll have a look
    at this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Declarative container management with Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Compose helps you manage multiple containers in a declarative way. You
    can create a YAML file and specify what you want to build, what containers you
    want to run, and how the containers interact with each other. You can define mounts,
    networks, port mapping, and many different configurations in the YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: After that, you can simply run `docker compose up` to run your entire containerized
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Declarative management is quickly gaining ground because of its power and simplicity.
    Now, sysadmins don’t need to remember what commands they had run or write lengthy
    scripts or playbooks to manage containers. Instead, they can simply declare what
    they want in a YAML file, and `docker compose` or other tools can help them achieve
    that state. We installed Docker Compose when we installed Docker, so let’s see
    it in action with a sample application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a sample application with Docker Compose
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have a Python Flask application that listens on port `5000`, which we will
    eventually map to host port `80`. The application will connect to the Redis database
    as a backend service on its default port, `6379`, and fetch the page’s last visit
    time. We will not expose that port to the host system. This means the database
    is entirely out of bounds for any external party with access to the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the application architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Sample application](img/B19877_Figure_3.05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – Sample application
  prefs: []
  type: TYPE_NORMAL
- en: 'The necessary files are available in this book’s GitHub repository. Run the
    following command to locate the files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The `app.py` file looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The `requirements.txt` file looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: I’ve already built the application for you, and the image is available on Docker
    Hub. The next chapter will cover how to build a Docker image in detail. For now,
    let’s have a look at the `docker-compose` file.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the docker-compose file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next step in the process is to create a `docker-compose` file. A `docker-compose`
    file is a YAML file that contains a list of services, networks, volumes, and other
    associated configurations. Let’s look at the following example `docker-compose.yaml`
    file to understand it better:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The YAML file describes two services – `flask` and `redis`.
  prefs: []
  type: TYPE_NORMAL
- en: The `flask` service uses the `python-flask-redis:latest` image – the image we
    built with the preceding code. It also maps host port `80` to container port `5000`,
    exposing this application to your host machine on port `80`, and you can access
    it via `http://localhost`.
  prefs: []
  type: TYPE_NORMAL
- en: The `redis` service uses the official `redis:alpine` image and does not expose
    any port, as we don’t want this service outside the container network’s confines.
    However, it declares a persistent volume, `redis-data`, that comprises the `/data`
    directory. We can mount this volume on the host filesystem for persistence beyond
    the container life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: There is also a `flask-app-net` network that uses the bridge driver, and both
    services share the same network. This means the services can call each other by
    using their service names. If you look at the `app.py` code, you will see that
    we established a Redis service connection using the `redis` hostname.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply the configuration, simply run `docker-compose` `up -d`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s list the Docker containers to see how we fare:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: We can see that two containers are running for both services. We can also see
    host port `80` forwarding connections to container port `5000` on the `flask`
    service.
  prefs: []
  type: TYPE_NORMAL
- en: The `redis` service is internal and therefore, there is no port mapping.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run `curl localhost` and see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Here, we get the last visited page from the Redis cache according to the sample
    Flask application code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run this a few times and see whether the time changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the last visited time changes every time we `curl`. Since the
    volume is persistent, we should get similar last visited times even after a container
    restarts.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s `curl` and get the last visited time and also the current date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the next time we `curl`, we should get a date-time similar to `2023-06-01,
    06:55:50`. But before that, let’s restart the container and see whether the data
    persists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that Redis has been restarted, let’s run `curl` again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, we get the correct last visited time, even after restarting the
    `redis` service. This means that data persistence works correctly, and the volume
    is adequately mounted.
  prefs: []
  type: TYPE_NORMAL
- en: You can do many other configurations on `docker compose` that you can readily
    get from the official documentation. However, you should now have a general idea
    about using `docker compose` and its benefits. Now, let’s look at some of the
    best practices associated with Docker Compose.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Compose best practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker Compose provides a declarative way of managing Docker container configuration.
    This enables GitOps for your Docker workloads. While Docker Compose is primarily
    used in development environments, you can use it in production very effectively,
    especially when Docker runs in production and does not use another container orchestrator
    such as Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Always use docker-compose.yml files alongside code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The YAML file defines how to run your containers. So, it becomes a valuable
    tool for declaratively building and deploying your containers from a single space.
    You can add all dependencies to your application and run related applications
    in a single network.
  prefs: []
  type: TYPE_NORMAL
- en: Separate multiple environment YAMLs using overrides
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Docker Compose YAML files allow us to both build and deploy Docker images. Docker
    has enabled the *build once, run anywhere* concept. This means we build once in
    the development environment and then use the created image in subsequent environments.
    So, the question arises of how we can achieve that. Docker Compose allows us to
    apply multiple YAML files in a sequence where the next configuration overrides
    the last. That way, we can have separate override files for various environments
    and manage multiple environments using a set of these files.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, say we have the following base `docker-compose.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'We only have to build the Flask application container image in the development
    environment so that we can create an override file for the development environment
    – that is, `docker-compose.override.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Here, we added a `build` parameter within the web service. This means the Python
    Flask application will be rebuilt and then deployed. We also set the `DEBUG` environment
    variable within the `web` service and exposed the `redis` port to the host filesystem.
    This makes sense in the development environment, as we might want to debug Redis
    from the development machine directly. Still, we would not want something of that
    sort in the production environment. Therefore, the default `docker-compose.yaml`
    file will work in the production environment, as we saw in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: Use an .env file to store sensitive variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You might not want to store sensitive content such as passwords and secrets
    in version control. Instead, you can use an `.env` file that contains a list of
    variable names and values and keep it in a secret management system such as HashiCorp
    Vault.
  prefs: []
  type: TYPE_NORMAL
- en: Be mindful of dependencies in production
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you change a particular container and want to redeploy it, `docker-compose`
    also redeploys any dependencies. Now, this might not be something that you wish
    to do, so you can override this behavior by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Treat docker-compose files as code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Always version control your `docker-compose` files and keep them alongside the
    code. This will allow you to track their versions and use gating and Git features
    such as pull requests.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was designed to cater to both beginners and experienced individuals.
    We started by covering the foundational concepts of Docker and gradually delved
    into more advanced topics and real-world use cases. This chapter began with installing
    Docker, running our first Docker container, understanding various modes of running
    a container, and understanding Docker volumes and storage drivers. We also learned
    how to select the right storage driver, volume options, and some best practices.
    All these skills will help you easily set up a production-ready Docker server.
    We also discussed the logging agent and how to quickly ship Docker logs to multiple
    destinations, such as **journald**, **Splunk**, and JSON files, to help you monitor
    your containers. We looked at managing Docker containers declaratively using **Docker
    Compose** and deployed a complete composite container application. Please try
    out all the commands mentioned in this chapter for a more hands-on experience
    – practice is vital to achieving something worthwhile and learning something new.
  prefs: []
  type: TYPE_NORMAL
- en: As a next step, in the following chapter, we will look at Docker images, creating
    and managing them, and some best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Answer the following questions to test your knowledge of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: You should use `overlay2` for CentOS and RHEL 7 and below. (True/False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following statements is true? (Choose four)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Volumes increase IOPS.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Volumes decrease IOPS.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. `tmpfs` mounts use system memory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. You can use bind mounts to mount host files to containers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: E. You can use volume mounts for a multi-instance active-active configuration.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Changing the storage driver removes existing containers from the host. (True/False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`devicemapper` is a better option than `overlay2` for write-intensive containers.
    (True/False)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following logging drivers are supported by Docker? (Choose four)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. `journald`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Splunk
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. JSON files
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Syslog
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: E. Logstash
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Docker Compose is an imperative approach to managing containers. (True/False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following `docker run` configurations are correct? (Choose three)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. `docker` `run nginx`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. `docker run --name` `nginx nginx:1.17.3`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. `docker run -d --name` `nginx nginx`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. `docker run -d --name nginx nginx --``restart never`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the answers to this chapter’s questions:'
  prefs: []
  type: TYPE_NORMAL
- en: False – You should use `devicemapper` for CentOS and RHEL 7 and below as they
    do not support `overlay2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: B, C, D, E.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A, B, C, D.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False – Docker Compose is a declarative approach to container management.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A, B, C.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
