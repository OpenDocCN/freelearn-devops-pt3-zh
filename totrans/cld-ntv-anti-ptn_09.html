<html><head></head><body>
<div epub:type="chapter" id="_idContainer070">
<h1 class="chapter-number" id="_idParaDest-250"><a id="_idTextAnchor250"/><span class="koboSpan" id="kobo.1.1">9</span></h1>
<h1 id="_idParaDest-251"><a id="_idTextAnchor251"/><span class="koboSpan" id="kobo.2.1">Connecting It All</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In cloud native environments, networking plays a critical role in ensuring the performance, scalability, and security of applications. </span><span class="koboSpan" id="kobo.3.2">However, as organizations embrace the cloud, they often encounter challenges stemming from misaligned strategies and outdated practices. </span><span class="koboSpan" id="kobo.3.3">These challenges manifest as anti-patterns—recurring issues that undermine the effectiveness of cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">native solutions.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">This chapter delves into some of the most common cloud native networking anti-patterns, examining their impact and providing actionable insights to avoid them. </span><span class="koboSpan" id="kobo.5.2">By understanding and addressing these pitfalls, organizations can design resilient, efficient, and secure network architectures tailored for </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">the cloud.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">The anti-patterns covered in this chapter include </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.9.1">Ignoring latency </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">and bandwidth</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Lack of </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">DNS strategy</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.13.1">Monolithic connectivity</span></span></li>
<li><span class="koboSpan" id="kobo.14.1">Ignoring cloud native </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">networking features</span></span></li>
<li><span class="koboSpan" id="kobo.16.1">Zero Trust </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">application patterns</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.18.1">By exploring these topics, this chapter equips you with the knowledge to recognize and mitigate these anti-patterns, fostering robust cloud native </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">networking practices.</span></span></p>
<h1 id="_idParaDest-252"><a id="_idTextAnchor252"/><span class="koboSpan" id="kobo.20.1">Ignoring latency and bandwidth</span></h1>
<p><span class="koboSpan" id="kobo.21.1">When organizations transition to the cloud, the role of networking undergoes a significant shift. </span><span class="koboSpan" id="kobo.21.2">In traditional on-premises setups, network engineers and administrators manage physical hardware, switches, routers, and the meticulous planning necessary to ensure low latency, redundancy, and security. </span><span class="koboSpan" id="kobo.21.3">This careful orchestration is crucial for optimal performance. </span><span class="koboSpan" id="kobo.21.4">However, as companies move to the cloud, the focus of networking shifts from physical infrastructure management to virtualized infrastructure. </span><span class="koboSpan" id="kobo.21.5">This shift can lead to the misconception that networking becomes a secondary concern, but in reality, it remains just as critical in cloud native environments, albeit in a different form. </span><span class="koboSpan" id="kobo.21.6">This is where the common cloud native anti-pattern of ignoring latency and </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">bandwidth emerges.</span></span></p>
<p><span class="koboSpan" id="kobo.23.1">The focus shifts from physical hardware to virtualized infrastructure, requiring engineers to manage components such</span><a id="_idIndexMarker964"/><span class="koboSpan" id="kobo.24.1"> as </span><strong class="bold"><span class="koboSpan" id="kobo.25.1">virtual private clouds</span></strong><span class="koboSpan" id="kobo.26.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.27.1">VPCs</span></strong><span class="koboSpan" id="kobo.28.1">), subnets, security groups, load balancers, and inter-service communication. </span><span class="koboSpan" id="kobo.28.2">While physical constraints are reduced, the complexity of managing efficient, secure, and redundant communication across distributed systems persists. </span><span class="koboSpan" id="kobo.28.3">Latency and bandwidth issues can be exacerbated, especially in applications built from numerous microservices, which must communicate seamlessly across </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">distributed environments.</span></span></p>
<p><span class="koboSpan" id="kobo.30.1">In the following sections, we will examine how to plan and manage connectivity to the internet effectively, on-premises systems, and third-party services. </span><span class="koboSpan" id="kobo.30.2">This will include insights into designing robust, secure network architectures that facilitate seamless integration and reliable communication, whether connecting cloud resources to legacy infrastructure, external partners, or the broader </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">public internet.</span></span></p>
<h2 id="_idParaDest-253"><a id="_idTextAnchor253"/><span class="koboSpan" id="kobo.32.1">Cloud native latency</span></h2>
<p><span class="koboSpan" id="kobo.33.1">In cloud</span><a id="_idIndexMarker965"/><span class="koboSpan" id="kobo.34.1"> environments such </span><a id="_idIndexMarker966"/><span class="koboSpan" id="kobo.35.1">as Azure, AWS, and </span><strong class="bold"><span class="koboSpan" id="kobo.36.1">Google Cloud Platform</span></strong><span class="koboSpan" id="kobo.37.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.38.1">GCP</span></strong><span class="koboSpan" id="kobo.39.1">), network latency refers to the time a data request takes to travel from one point </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">to another.</span></span></p>
<p><span class="koboSpan" id="kobo.41.1">For example, suppose your application hosted on AWS needs to retrieve data from an S3 bucket. </span><span class="koboSpan" id="kobo.41.2">In that case, network latency is the delay incurred as the request traverses the network, is processed, and the response is returned. </span><span class="koboSpan" id="kobo.41.3">Similarly, in Azure, if your services span multiple regions, say from East US to West Europe, network latency will influence the time it takes for data to travel across these regions. </span><span class="koboSpan" id="kobo.41.4">Let us focus on the S3 example, as the S3 latency is something we recently encountered in an engagement. </span><span class="koboSpan" id="kobo.41.5">Let us use the following </span><a id="_idIndexMarker967"/><span class="koboSpan" id="kobo.42.1">diagram as a reference point for </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">the scenario:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<span class="koboSpan" id="kobo.44.1"><img alt="" role="presentation" src="image/B22364_09_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.45.1">Figure 9.1 - AWS networking diagram</span></p>
<h3><span class="koboSpan" id="kobo.46.1">Cloud native latency with services</span></h3>
<p><span class="koboSpan" id="kobo.47.1">During a</span><a id="_idIndexMarker968"/><span class="koboSpan" id="kobo.48.1"> consulting engagement, a mid-sized e-commerce company had recently migrated a significant portion of its operations to the cloud. </span><span class="koboSpan" id="kobo.48.2">As part of their architecture, they stored vast amounts of product images, user-generated content, and transactional data in Amazon S3. </span><span class="koboSpan" id="kobo.48.3">However, instead of using S3 gateway endpoints to access their storage directly within the VPC, they routed all S3 traffic through an egress VPC hosted in a separate account. </span><span class="koboSpan" id="kobo.48.4">An S3 endpoint is a private connection within a VPC that allows direct, secure access to Amazon S3 without traversing the public internet, reducing latency and </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">improving security.</span></span></p>
<p><span class="koboSpan" id="kobo.50.1">Initially, everything worked fine. </span><span class="koboSpan" id="kobo.50.2">Their network team was familiar with egress VPCs from their on-premises days, where routing traffic through specific network exits provided centralized control and monitoring. </span><span class="koboSpan" id="kobo.50.3">They assumed a similar setup would be beneficial in the cloud, ensuring tighter control over internet-bound traffic. </span><span class="koboSpan" id="kobo.50.4">However, over time, they began noticing performance degradation. </span><span class="koboSpan" id="kobo.50.5">The following list goes into the details of what said </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">issues were:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.52.1">Latency issues became apparent, particularly during peak </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">traffic hours</span></span></li>
<li><span class="koboSpan" id="kobo.54.1">Users experienced delays while browsing extensive collections of </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">product images</span></span></li>
<li><span class="koboSpan" id="kobo.56.1">High volumes of data uploads further exacerbated the response </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">time issues</span></span></li>
<li><span class="koboSpan" id="kobo.58.1">Customers faced slow image loads and transaction </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">processing delays</span></span></li>
<li><span class="koboSpan" id="kobo.60.1">The team hadn’t accounted for the cost of additional network hops between their application VPC and the </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">egress VPC</span></span></li>
<li><span class="koboSpan" id="kobo.62.1">Every request to S3 had to traverse between the two VPCs, adding </span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">unnecessary latency</span></span></li>
<li><span class="koboSpan" id="kobo.64.1">Data routing through multiple network layers before reaching S3 contributed to </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">the delay</span></span></li>
<li><span class="koboSpan" id="kobo.66.1">API calls made to AWS services such as S3 were directed to the internet due to the absence of a </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">gateway option</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.68.1">Without S3 gateway</span><a id="_idIndexMarker969"/><span class="koboSpan" id="kobo.69.1"> endpoints, which would have allowed for a direct, high-speed connection to S3 within the VPC itself, every request took the long way around. </span><span class="koboSpan" id="kobo.69.2">The solution was simple but impactful. </span><span class="koboSpan" id="kobo.69.3">By enabling S3 gateway endpoints within their application VPC, they could establish a direct path to S3, eliminating the cross-VPC traffic, and the traffic would stay within the AWS account rather than reaching out to the internet. </span><span class="koboSpan" id="kobo.69.4">Almost immediately, latency dropped and the performance issues disappeared. </span><span class="koboSpan" id="kobo.69.5">Their customers enjoyed a smoother, faster experience, and the engineering team learned an important lesson about the intricacies of cloud native networking. </span><span class="koboSpan" id="kobo.69.6">The following figure shows the usage of </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">gateway endpoints:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer062">
<span class="koboSpan" id="kobo.71.1"><img alt="" role="presentation" src="image/B22364_09_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.72.1">Figure 9.2 - S3 gateway endpoint and DynamoDB</span></p>
<p><span class="koboSpan" id="kobo.73.1">It was a costly oversight that could have been avoided had they considered the native tools available </span><a id="_idIndexMarker970"/><span class="koboSpan" id="kobo.74.1">within the cloud environment. </span><span class="koboSpan" id="kobo.74.2">Instead, they had unknowingly introduced an anti-pattern by relying on outdated network practices from their </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">on-premises days.</span></span></p>
<h3><span class="koboSpan" id="kobo.76.1">Cross-zone latency</span></h3>
<p><span class="koboSpan" id="kobo.77.1">A typical pattern </span><a id="_idIndexMarker971"/><span class="koboSpan" id="kobo.78.1">in the move to cloud native is found when connecting resources across multiple cloud environments </span><a id="_idIndexMarker972"/><span class="koboSpan" id="kobo.79.1">or </span><strong class="bold"><span class="koboSpan" id="kobo.80.1">availability zones</span></strong><span class="koboSpan" id="kobo.81.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.82.1">AZs</span></strong><span class="koboSpan" id="kobo.83.1">) within the same cloud provider, such as AWS, Azure regions, or GCP zones. </span><span class="koboSpan" id="kobo.83.2">While cloud platforms offer distributed infrastructure and the promise of high availability, organizations often underestimate the latency and bandwidth challenges that arise when resources are spread geographically. </span><span class="koboSpan" id="kobo.83.3">Note that geographical spread also means across zones within a </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">specific region.</span></span></p>
<p><span class="koboSpan" id="kobo.85.1">Take, for example, a typical region in AWS. </span><span class="koboSpan" id="kobo.85.2">You may have 3–5 distinct AZs, each of which is a grouping of data centers across different diverse locations. </span><span class="koboSpan" id="kobo.85.3">This allows for better fault tolerance, but latency between these zones is higher than between services/apps in the </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">same zone.</span></span></p>
<p><span class="koboSpan" id="kobo.87.1">Furthermore, data transfer costs can escalate rapidly when services communicate across regions or zones, leading to unexpected financial overhead. </span><span class="koboSpan" id="kobo.87.2">This anti-pattern reflects a fundamental oversight in cloud native architecture, where organizations focus on multi-zone redundancy or cross-cloud integrations without considering the performance and cost implications </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">of networking.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<span class="koboSpan" id="kobo.89.1"><img alt="" role="presentation" src="image/B22364_09_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.90.1">Figure 9.3 - Example of AWS AZs</span></p>
<p><span class="koboSpan" id="kobo.91.1">It is crucial to</span><a id="_idIndexMarker973"/><span class="koboSpan" id="kobo.92.1"> factor in bandwidth limitations and optimize for low-latency interactions, mainly when designing architectures that span multiple zones or regions. </span><span class="koboSpan" id="kobo.92.2">In-region networking is optimized logically to ensure efficiency and performance, but due to the geographic separation designed to support localized high availability, it will always face inherent physical limitations. </span><span class="koboSpan" id="kobo.92.3">You can do the following to </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">resolve this:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.94.1">Build your private, data, and public network layers across the same redundancy planes. </span><span class="koboSpan" id="kobo.94.2">If data resources are in AZ A, so should the other layers </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">that interact.</span></span></li>
<li><span class="koboSpan" id="kobo.96.1">Account </span><a id="_idIndexMarker974"/><span class="koboSpan" id="kobo.97.1">for cross-zone latency when building </span><a id="_idIndexMarker975"/><span class="koboSpan" id="kobo.98.1">with </span><strong class="bold"><span class="koboSpan" id="kobo.99.1">high availability</span></strong><span class="koboSpan" id="kobo.100.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.101.1">HA</span></strong><span class="koboSpan" id="kobo.102.1">) </span><span class="No-Break"><span class="koboSpan" id="kobo.103.1">in mind.</span></span></li>
<li><span class="koboSpan" id="kobo.104.1">Consider latency tradeoffs for high-performance computing, as </span><em class="italic"><span class="koboSpan" id="kobo.105.1">highly available</span></em><span class="koboSpan" id="kobo.106.1"> does not mean </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">highly performant.</span></span></li>
</ul>
<h2 id="_idParaDest-254"><a id="_idTextAnchor254"/><span class="koboSpan" id="kobo.108.1">Cloud native bandwidth</span></h2>
<p><span class="koboSpan" id="kobo.109.1">In cloud native</span><a id="_idIndexMarker976"/><span class="koboSpan" id="kobo.110.1"> environments, bandwidth limitations can significantly impact application performance, particularly as services are scaled or distributed across regions. </span><span class="koboSpan" id="kobo.110.2">Although the cloud abstracts much of the underlying infrastructure, bandwidth constraints still persist. </span><span class="koboSpan" id="kobo.110.3">Overlooking these limitations can lead to performance bottlenecks, especially in high-traffic or </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">data-intensive scenarios.</span></span></p>
<p><span class="koboSpan" id="kobo.112.1">Bandwidth limitations must be carefully addressed when scaling applications or managing large amounts of data. </span><span class="koboSpan" id="kobo.112.2">For instance, with the big three hyperscalers (AWS, GCP, and Azure), services like EC2 and RDS have bandwidth constraints based on instance types. </span><span class="koboSpan" id="kobo.112.3">Smaller EC2 instances, such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.113.1">t2.micro</span></strong><span class="koboSpan" id="kobo.114.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.115.1">t3.small</span></strong><span class="koboSpan" id="kobo.116.1">, offer significantly lower network bandwidth compared to larger instances like </span><strong class="source-inline"><span class="koboSpan" id="kobo.117.1">m6a.large</span></strong><span class="koboSpan" id="kobo.118.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.119.1">c6a.xlarge</span></strong><span class="koboSpan" id="kobo.120.1">. </span><span class="koboSpan" id="kobo.120.2">Data transfers between regions or even across AZs can exacerbate latency and introduce further </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1">bandwidth bottlenecks.</span></span></p>
<p><span class="koboSpan" id="kobo.122.1">Similar bandwidth constraints exist within Azure </span><span class="No-Break"><span class="koboSpan" id="kobo.123.1">and GCP.</span></span></p>
<h3><span class="koboSpan" id="kobo.124.1">Ambiguity – a cause of latency and bandwidth issues</span></h3>
<p><span class="koboSpan" id="kobo.125.1">As we </span><a id="_idIndexMarker977"/><span class="koboSpan" id="kobo.126.1">explored earlier, the choice of instance types in cloud environments has become far more critical than it ever was in traditional on-premises settings. </span><span class="koboSpan" id="kobo.126.2">The flexibility and sheer variety of options available in the cloud are both a blessing and a challenge. </span><span class="koboSpan" id="kobo.126.3">Consider, for example, the task of selecting an instance type in AWS for a Kubernetes node that requires four cores and eight gigabytes of RAM. </span><span class="koboSpan" id="kobo.126.4">At first glance, it seems we are spoiled </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">for choice.</span></span></p>
<p><span class="koboSpan" id="kobo.128.1">A quick look at AWS Pricing Calculator reveals a list of at least 10 potential instance types, each offering different combinations of network speeds, memory allocations, and pricing. </span><span class="koboSpan" id="kobo.128.2">The </span><a id="_idIndexMarker978"/><span class="koboSpan" id="kobo.129.1">following is an example </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">of this:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer064">
<span class="koboSpan" id="kobo.131.1"><img alt="" role="presentation" src="image/B22364_09_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.132.1">Figure 9.4 - Extract from AWS Pricing Calculator</span></p>
<p><span class="koboSpan" id="kobo.133.1">However, the real challenge lies in determining which instance best suits your specific use case. </span><span class="koboSpan" id="kobo.133.2">Do you choose </span><strong class="source-inline"><span class="koboSpan" id="kobo.134.1">c6g.xlarge</span></strong><span class="koboSpan" id="kobo.135.1">, which is cost-effective and still provides up to 10 gigabits of network throughput? </span><span class="koboSpan" id="kobo.135.2">Or do you opt for the more powerful </span><strong class="source-inline"><span class="koboSpan" id="kobo.136.1">c7g.xlarge</span></strong><span class="koboSpan" id="kobo.137.1">? </span><span class="koboSpan" id="kobo.137.2">It’s not simply a matter of weighing performance against cost. </span><span class="koboSpan" id="kobo.137.3">A deeper consideration is whether your application can even run on ARM processors, both of which leverage AWS’s Graviton ARM chips, which, while offering impressive performance gains, may not be compatible with </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">all workloads.</span></span></p>
<p><span class="koboSpan" id="kobo.139.1">Beyond processor compatibility, other technical specifications, such as network bandwidth and CPU architecture, require thoughtful consideration. </span><span class="koboSpan" id="kobo.139.2">These details aren’t just abstract numbers; they directly impact your application’s performance </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">and scalability.</span></span></p>
<p><span class="koboSpan" id="kobo.141.1">As we migrate from on-premises infrastructure to the cloud, the art of selecting the right instance type becomes paramount, and this choice in compute extends out to other </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">cloud services.</span></span></p>
<h3><span class="koboSpan" id="kobo.143.1">Beyond VMs – bandwidth limitations for containers and serverless</span></h3>
<p><span class="koboSpan" id="kobo.144.1">It is </span><a id="_idIndexMarker979"/><span class="koboSpan" id="kobo.145.1">essential to recognize that bandwidth limitations are not confined to VMs alone. </span><span class="koboSpan" id="kobo.145.2">Containerized services and serverless architectures can also suffer from bandwidth bottlenecks, seriously impacting application performance in cloud native environments. </span><span class="koboSpan" id="kobo.145.3">While abstracting infrastructure management, services such as AWS Fargate and Google Cloud Run still impose network bandwidth constraints that developers must consider when designing scalable, </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">distributed systems.</span></span></p>
<p><span class="koboSpan" id="kobo.147.1">For instance, AWS Lambda, a serverless computing service, also experiences bandwidth limitations that can affect applications. </span><span class="koboSpan" id="kobo.147.2">While Lambda abstracts server infrastructure, its network still faces throughput restrictions, especially when handling high-volume data transfers between services like S3, DynamoDB, or external APIs. </span><span class="koboSpan" id="kobo.147.3">Ignoring these limitations can lead to performance degradation in serverless applications, which rely heavily on fast, seamless communication across services. </span><span class="koboSpan" id="kobo.147.4">Some specific points to consider include </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.149.1">VPC networking in Lambda</span></strong><span class="koboSpan" id="kobo.150.1">: When a Lambda function is configured to run inside a VPC, it may experience added latency and bandwidth constraints due to the VPC’s network configuration and throughput limits. </span><span class="koboSpan" id="kobo.150.2">Lambda is unique in that the higher the memory allocation, the higher the background CPU count and network bandwidth. </span><span class="koboSpan" id="kobo.150.3">Specifically, the more CPU is available, the more accessible the full bandwidth of the elastic </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">network interface.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.152.1">Cold start delays</span></strong><span class="koboSpan" id="kobo.153.1">: While not directly bandwidth-related, Lambda cold starts can indirectly affect how quickly an application can process requests, especially under high loads, exacerbating bandwidth bottlenecks during </span><span class="No-Break"><span class="koboSpan" id="kobo.154.1">initial invocations.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.155.1">S3 and Lambda data transfers</span></strong><span class="koboSpan" id="kobo.156.1">: Large-scale data transfers between S3 and Lambda can hit bandwidth limits, especially when dealing with large files or high concurrency, leading to slower execution times or throttling. </span><span class="koboSpan" id="kobo.156.2">Note also the serverless limitations of Lambda, via 6 MB sync and 20 MB response </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">size limits.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.158.1">Outbound bandwidth to external APIs</span></strong><span class="koboSpan" id="kobo.159.1">: When Lambda functions interact with external APIs or services outside the AWS ecosystem, bandwidth constraints can increase response times or lead to timeouts if data transfer rates </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">exceed limits.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.161.1">As </span><a id="_idIndexMarker980"/><span class="koboSpan" id="kobo.162.1">cloud native architectures become more complex and distributed, bandwidth considerations must not be overlooked. </span><span class="koboSpan" id="kobo.162.2">From VMs to containers and serverless functions, all layers of cloud infrastructure face bandwidth limitations that can introduce unexpected bottlenecks. </span><span class="koboSpan" id="kobo.162.3">Ignoring these limits is a common anti-pattern that can significantly degrade performance and lead to unforeseen costs, especially in high-traffic environments or applications that process large volumes of data. </span><span class="koboSpan" id="kobo.162.4">By proactively addressing bandwidth constraints and designing architectures with these limits, organizations can ensure their cloud native solutions are optimized for performance </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">and scalability.</span></span></p>
<p><span class="koboSpan" id="kobo.164.1">Across the big three cloud providers, applications designed without accounting for these limitations may suffer from high latency, data bottlenecks, and increased costs. </span><span class="koboSpan" id="kobo.164.2">Cloud native architecture must consider these factors to avoid common anti-patterns related to bandwidth and latency. </span><span class="koboSpan" id="kobo.164.3">The following section will show us how we can avoid the pitfalls of latency and bandwidth being overlooked. </span><span class="koboSpan" id="kobo.164.4">Our next section will dig into the lack of </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">DNS strategy.</span></span></p>
<h1 id="_idParaDest-255"><a id="_idTextAnchor255"/><span class="koboSpan" id="kobo.166.1">Lack of DNS strategy</span></h1>
<p class="author-quote"><span class="koboSpan" id="kobo.167.1">“</span><em class="italic"><span class="koboSpan" id="kobo.168.1">It’s not DNS,</span></em></p>
<p class="author-quote"><em class="italic"><span class="koboSpan" id="kobo.169.1">There’s no way it’s DNS,</span></em></p>
<p class="author-quote"><em class="italic"><span class="koboSpan" id="kobo.170.1">It was DNS</span></em><span class="koboSpan" id="kobo.171.1">.”</span></p>
<p><span class="koboSpan" id="kobo.172.1">This now-famous haiku perfectly captures the frustration and irony of one of the most overlooked aspects of modern networking: DNS. </span><span class="koboSpan" id="kobo.172.2">Often dismissed as a straightforward service, DNS is one of those critical components that only garners attention when things go wrong. </span><span class="koboSpan" id="kobo.172.3">In cloud native environments, where services, systems, and applications rely heavily on dynamic and distributed architectures, DNS issues can quickly spiral into significant outages, performance bottlenecks, or security vulnerabilities. </span><span class="koboSpan" id="kobo.172.4">And yet, many organizations treat DNS as </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">an afterthought.</span></span></p>
<p><span class="koboSpan" id="kobo.174.1">The anti-pattern of inconsistent DNS management is a silent disruptor. </span><span class="koboSpan" id="kobo.174.2">Organizations moving toward cloud native architectures often inherit a fragmented approach to DNS. </span><span class="koboSpan" id="kobo.174.3">With legacy systems, hybrid environments, and third-party services all in play, DNS strategies become disjointed and poorly aligned. </span><span class="koboSpan" id="kobo.174.4">This leads to unpredictable issues: slow resolution times, increased latency, and intermittent failures as systems struggle to connect across </span><span class="No-Break"><span class="koboSpan" id="kobo.175.1">varied infrastructures.</span></span></p>
<p><span class="koboSpan" id="kobo.176.1">In the cloud native space, this is a recipe for disaster. </span><span class="koboSpan" id="kobo.176.2">Whether services are hosted on-premises or in the cloud, a lack of cohesive DNS strategy can destabilize even the most well-designed applications. </span><span class="koboSpan" id="kobo.176.3">The challenge is compounded when external services are involved, creating a tangled web of DNS resolution paths that can delay communication, introduce security risks, or lead to outright </span><span class="No-Break"><span class="koboSpan" id="kobo.177.1">service failure.</span></span></p>
<p><span class="koboSpan" id="kobo.178.1">This section explores the causes and consequences of lacking DNS strategy and provides a guide for creating a unified, resilient DNS strategy. </span><span class="koboSpan" id="kobo.178.2">We’ll cover </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.180.1">Cloud native </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">DNS management</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.182.1">Hybrid environments</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.183.1">Third-party integrations</span></span></li>
<li><span class="koboSpan" id="kobo.184.1">Undermining traffic </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">segregation (QoS)</span></span></li>
<li><span class="koboSpan" id="kobo.186.1">Configuring low-performance backup links for high-performance primary links: considerations of QoS over </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">backup links</span></span></li>
</ul>
<h2 id="_idParaDest-256"><a id="_idTextAnchor256"/><span class="koboSpan" id="kobo.188.1">Cloud native DNS management</span></h2>
<p><span class="koboSpan" id="kobo.189.1">In cloud</span><a id="_idIndexMarker981"/><span class="koboSpan" id="kobo.190.1"> native architectures, DNS is no longer just simply mapping domain names to IP addresses. </span><span class="koboSpan" id="kobo.190.2">It becomes critical to how services discover one another, how traffic is routed efficiently, and how resilience is built into the network. </span><span class="koboSpan" id="kobo.190.3">However, the complexity of cloud native environments and the ease of spinning new services can quickly turn DNS into a tangled mess if not </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">managed properly.</span></span></p>
<p><span class="koboSpan" id="kobo.192.1">In cloud native environments, services such as Amazon Route 53, Azure DNS, and GCP Cloud DNS provide highly scalable DNS services designed specifically for cloud native use cases. </span><span class="koboSpan" id="kobo.192.2">These services enable fast, reliable routing to VM instances, load balancers, API gateways, and external endpoints. </span><span class="koboSpan" id="kobo.192.3">When appropriately managed, they ensure low-latency access to services, seamless failover, and redundancy across regions. </span><span class="koboSpan" id="kobo.192.4">However, when DNS configurations are fragmented, even in cloud native environments, it can lead to severe performance and connectivity issues. </span><span class="koboSpan" id="kobo.192.5">These issues and their eventual solution are discussed in the example </span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">that follows.</span></span></p>
<h3><span class="koboSpan" id="kobo.194.1">Cloud native and on-premises DNS</span></h3>
<p><span class="koboSpan" id="kobo.195.1">We </span><a id="_idIndexMarker982"/><span class="koboSpan" id="kobo.196.1">encountered a similar situation with a fintech client that used Amazon Route 53 to manage DNS for their cloud native microservices. </span><span class="koboSpan" id="kobo.196.2">Initially, everything worked smoothly, but as their infrastructure expanded, they began integrating services that required coordination between their cloud environment and on-premises systems. </span><span class="koboSpan" id="kobo.196.3">The fintech organization implemented separate DNS zones to manage internal domains, with Route 53 handling cloud native services and </span><strong class="bold"><span class="koboSpan" id="kobo.197.1">Active Directory</span></strong><span class="koboSpan" id="kobo.198.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.199.1">AD</span></strong><span class="koboSpan" id="kobo.200.1">) DNS managing their on-premises resources. </span><span class="koboSpan" id="kobo.200.2">However, there was no unified DNS strategy in place, resulting in inconsistent DNS records between the </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">two systems.</span></span></p>
<p><span class="koboSpan" id="kobo.202.1">As traffic increased, these clashing DNS configurations became a problem. </span><span class="koboSpan" id="kobo.202.2">Services began to fail, not due to application issues but because the conflicting DNS setups couldn’t handle proper traffic routing between the cloud and on-premises environments. </span><span class="koboSpan" id="kobo.202.3">The lack of a centralized DNS strategy led to delays in resolving internal services, causing timeouts and degrading the user experience. </span><span class="koboSpan" id="kobo.202.4">The fragmented approach to DNS management resulted in misrouted traffic and unnecessary latency, affecting critical </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">financial operations.</span></span></p>
<p><span class="koboSpan" id="kobo.204.1">The fragmented </span><a id="_idIndexMarker983"/><span class="koboSpan" id="kobo.205.1">DNS management between AD and Route 53 led to delayed lookups, inconsistent routing, and broken connections. </span><span class="koboSpan" id="kobo.205.2">Services slowed down, causing latency spikes and interruptions that took significant troubleshooting time. </span><span class="koboSpan" id="kobo.205.3">The root of the issue? </span><span class="koboSpan" id="kobo.205.4">The erratic and uncoordinated DNS setup </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">across environments.</span></span></p>
<h3><span class="koboSpan" id="kobo.207.1">Overcoming clashing DNS</span></h3>
<p><span class="koboSpan" id="kobo.208.1">The</span><a id="_idIndexMarker984"/><span class="koboSpan" id="kobo.209.1"> organization eventually resolved this issue with </span><a id="_idIndexMarker985"/><span class="koboSpan" id="kobo.210.1">the help of </span><strong class="bold"><span class="koboSpan" id="kobo.211.1">Route 53 Resolver</span></strong><span class="koboSpan" id="kobo.212.1">, a service designed to bridge on-premises and cloud native DNS environments. </span><span class="koboSpan" id="kobo.212.2">Route 53 Resolver allowed them to forward DNS queries between their AWS environment and their on-premises AD DNS servers. </span><span class="koboSpan" id="kobo.212.3">DNS forwarding rules created a seamless flow of DNS queries between the two systems, allowing cloud services to resolve on-premises domains, and vice versa. </span><span class="koboSpan" id="kobo.212.4">This approach eliminated the need for parallel DNS systems, centralizing DNS resolution under a single, </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1">cohesive architecture.</span></span></p>
<p><span class="koboSpan" id="kobo.214.1">The introduction of Route 53 Resolver transformed their DNS setup into a unified system, leveraging a proper hybrid model. </span><span class="koboSpan" id="kobo.214.2">Internal applications could now resolve both cloud native and on-premises domain names without the delays or conflicts caused by fragmented management. </span><span class="koboSpan" id="kobo.214.3">By consolidating their DNS strategy, integrating AWS Directory Service with Route 53, and leveraging Route 53 Resolver, they ensured that DNS resolution was consistent, fast, and reliable across all environments. </span><span class="koboSpan" id="kobo.214.4">A simplified version of the solution can be </span><span class="No-Break"><span class="koboSpan" id="kobo.215.1">found here:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer065">
<span class="koboSpan" id="kobo.216.1"><img alt="" role="presentation" src="image/B22364_09_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.217.1">Figure 9.5 - Hybrid DNS Resolver</span></p>
<p><span class="koboSpan" id="kobo.218.1">The next section will expand on this as we look at hybrid environments </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">and QoS.</span></span></p>
<h2 id="_idParaDest-257"><a id="_idTextAnchor257"/><span class="koboSpan" id="kobo.220.1">Undermining traffic segregation (QoS) based on application/data criticality</span></h2>
<p><span class="koboSpan" id="kobo.221.1">One of the</span><a id="_idIndexMarker986"/><span class="koboSpan" id="kobo.222.1"> most overlooked aspects of cloud native architecture is the importance of traffic segregation based on application and data criticality. </span><span class="koboSpan" id="kobo.222.2">Not all traffic in a system is equal; some workloads require high-priority, low-latency communication, while others can tolerate slower processing times. </span><span class="koboSpan" id="kobo.222.3">This concept is fundamental to </span><strong class="bold"><span class="koboSpan" id="kobo.223.1">quality of service</span></strong><span class="koboSpan" id="kobo.224.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.225.1">QoS</span></strong><span class="koboSpan" id="kobo.226.1">), which</span><a id="_idIndexMarker987"/><span class="koboSpan" id="kobo.227.1"> prioritizes traffic based on its importance to business operations. </span><span class="koboSpan" id="kobo.227.2">Unfortunately, a common anti-pattern in cloud native deployments is the</span><a id="_idIndexMarker988"/><span class="koboSpan" id="kobo.228.1"> failure to implement adequate traffic segregation, resulting in performance degradation, missed </span><strong class="bold"><span class="koboSpan" id="kobo.229.1">service-level agreements</span></strong><span class="koboSpan" id="kobo.230.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.231.1">SLAs</span></strong><span class="koboSpan" id="kobo.232.1">), and unnecessary </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">resource consumption.</span></span></p>
<p><span class="koboSpan" id="kobo.234.1">In traditional networking, QoS policies often prioritize traffic based on its type and importance. </span><span class="koboSpan" id="kobo.234.2">Critical applications, for example, real-time financial transactions, video conferencing, or database replication are prioritized. </span><span class="koboSpan" id="kobo.234.3">At the same time, non-critical tasks like backups, bulk file transfers, or routine updates are assigned lower priority. </span><span class="koboSpan" id="kobo.234.4">However, in cloud native environments, this approach is often neglected. </span><span class="koboSpan" id="kobo.234.5">Without proper QoS implementation, all traffic is treated equally, leading to significant issues when high-priority services must compete with less critical ones for bandwidth and </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">compute resources.</span></span></p>
<h3><span class="koboSpan" id="kobo.236.1">The cost of ignoring traffic segregation – a fintech case study</span></h3>
<p><span class="koboSpan" id="kobo.237.1">During a</span><a id="_idIndexMarker989"/><span class="koboSpan" id="kobo.238.1"> consulting engagement with a large fintech company, we encountered a classic example of the pitfalls of failing to implement proper traffic segregation in a cloud environment. </span><span class="koboSpan" id="kobo.238.2">The company ran real-time transaction processing alongside nightly data backups, which operated in the same shared cloud infrastructure. </span><span class="koboSpan" id="kobo.238.3">Initially, everything seemed to work fine, but as transaction volumes grew, so did the strain on </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">the network.</span></span></p>
<p><span class="koboSpan" id="kobo.240.1">The lack of a </span><a id="_idIndexMarker990"/><span class="koboSpan" id="kobo.241.1">structured traffic prioritization strategy meant that their backup operations, scheduled during peak hours, consumed a significant portion of the available bandwidth. </span><span class="koboSpan" id="kobo.241.2">This interference caused delays in real-time financial transactions, leading to missed SLAs and customer dissatisfaction. </span><span class="koboSpan" id="kobo.241.3">This is where the need for a robust QoS strategy became evident. </span><span class="koboSpan" id="kobo.241.4">With proper traffic segregation and prioritization, we ensured that critical services, for example, real-time transaction processing, were always given priority over less urgent tasks such as nightly backups. </span><span class="koboSpan" id="kobo.241.5">By isolating bandwidth-heavy operations and allocating resources based on service criticality, we helped them avoid these </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">delays altogether.</span></span></p>
<h3><span class="koboSpan" id="kobo.243.1">The risks of failing to segregate traffic based on criticality</span></h3>
<p><span class="koboSpan" id="kobo.244.1">When traffic</span><a id="_idIndexMarker991"/><span class="koboSpan" id="kobo.245.1"> segregation based on application or data criticality is ignored, organizations are exposed to several risks, including </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.247.1">Degraded performance for critical applications</span></strong><span class="koboSpan" id="kobo.248.1">: Business-critical applications, like real-time financial transactions or sensitive data transfers, may experience latency or delays if forced to compete for bandwidth with </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">non-essential traffic.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.250.1">Missed SLAs</span></strong><span class="koboSpan" id="kobo.251.1">: In environments where uptime, speed, and reliability are key performance indicators, the failure to segregate traffic can lead to missed SLAs, resulting in penalties or </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">reputational damage.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.253.1">Resource contention</span></strong><span class="koboSpan" id="kobo.254.1">: Equal treatment of all traffic can cause resource contention, where essential processes are starved for bandwidth or compute power, while less important tasks consume </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">unnecessary resources.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.256.1">Security risks</span></strong><span class="koboSpan" id="kobo.257.1">: Some data flows, such as those involving sensitive financial or personal information, should be segregated not just for performance reasons but also for security. </span><span class="koboSpan" id="kobo.257.2">Failure</span><a id="_idIndexMarker992"/><span class="koboSpan" id="kobo.258.1"> to isolate this traffic can expose critical data </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">to vulnerabilities.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.260.1">Best practices for traffic segregation and QoS</span></h3>
<p><span class="koboSpan" id="kobo.261.1">To </span><a id="_idIndexMarker993"/><span class="koboSpan" id="kobo.262.1">avoid the anti-pattern of undermining traffic segregation, organizations should implement a structured QoS strategy tailored to their cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">native infrastructure:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-4">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.264.1">Best Practice</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.265.1">Description</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.266.1">Prioritize traffic based </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">on criticality</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.268.1">Define and categorize traffic based on its importance to business operations. </span><span class="koboSpan" id="kobo.268.2">Latency-sensitive or critical tasks should have higher priority over </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">non-urgent processes.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.270.1">Use network </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">segmentation</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.272.1">Implement virtual network segmentation (e.g., VPCs or subnets) to separate traffic by priority, ensuring high-priority traffic does not compete with </span><span class="No-Break"><span class="koboSpan" id="kobo.273.1">lower-priority flows.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.274.1">Leverage cloud native </span><span class="No-Break"><span class="koboSpan" id="kobo.275.1">QoS tools</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.276.1">Utilize cloud provider tools such as Amazon Traffic Mirroring, bandwidth control, Azure Traffic Manager, and Google Cloud Network Service Tiers to manage and optimize </span><span class="No-Break"><span class="koboSpan" id="kobo.277.1">traffic flow.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.278.1">Monitor and adjust </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">QoS policies</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.280.1">Regularly monitor the performance of QoS policies and make adjustments as workloads change to maintain </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">optimal performance.</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.282.1">Account for multi-cloud and </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">hybrid setups</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.284.1">Ensure consistent QoS policies across multi-cloud or hybrid environments to prevent bottlenecks and maintain performance between on-premises and </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">cloud infrastructures.</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.286.1">Table 9.1 - QoS best practices</span></p>
<p><span class="koboSpan" id="kobo.287.1">A common </span><a id="_idIndexMarker994"/><span class="koboSpan" id="kobo.288.1">anti-pattern in cloud native architectures is relying on low-performance backup links to support high-performance primary links without considering how QoS will function during failover. </span><span class="koboSpan" id="kobo.288.2">Backup links are implemented in many setups as a cost-saving measure, typically designed with lower bandwidth and </span><span class="No-Break"><span class="koboSpan" id="kobo.289.1">reduced capabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.290.1">However, if a primary high-performance link fails, critical applications and data flows are forced onto these slower links, potentially causing severe performance degradation, increased latency, and service outages. </span><span class="koboSpan" id="kobo.290.2">Failing to configure appropriate QoS policies for these backup links can exacerbate the issue, as critical traffic may not be prioritized during the failover, further degrading the </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1">user experience.</span></span></p>
<h3><span class="koboSpan" id="kobo.292.1">Key considerations for backup link QoS</span></h3>
<p><span class="koboSpan" id="kobo.293.1">To mitigate</span><a id="_idIndexMarker995"/><span class="koboSpan" id="kobo.294.1"> these risks, it’s essential to plan for the backup links as carefully as the primary links, ensuring that they can handle the most critical traffic if a failover occurs. </span><span class="koboSpan" id="kobo.294.2">Properly configured QoS can help ensure that essential services maintain priority during periods of reduced capacity and operate with minimal disruption. </span><span class="koboSpan" id="kobo.294.3">To ensure consistency, regular checks and testing applications via backup links are critical. </span><span class="koboSpan" id="kobo.294.4">Untested backups should be treated as inactive until tested in some cadence. </span><span class="koboSpan" id="kobo.294.5">The following points highlight how to approach </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">backup links:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.296.1">Prioritize critical traffic during failover</span></strong><span class="koboSpan" id="kobo.297.1">: Implement QoS policies to ensure that high-priority traffic, such as transactional data or real-time services, is prioritized over less critical traffic on </span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">backup links.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.299.1">Test backup link capacity regularly</span></strong><span class="koboSpan" id="kobo.300.1">: Regularly test the performance of backup links to ensure they can handle the critical traffic load during a failover scenario without </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">significant degradation.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.302.1">Scale backup links based on needs</span></strong><span class="koboSpan" id="kobo.303.1">: Ensure that backup links are appropriately scaled to handle the most critical workloads, even if they can’t match the full capacity of </span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">primary links.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.305.1">Monitor link performance</span></strong><span class="koboSpan" id="kobo.306.1">: Continuously monitor both primary and backup links to ensure that QoS policies are functioning as intended and traffic is routed efficiently during </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">failover events.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.308.1">Evaluate cost vs. </span><span class="koboSpan" id="kobo.308.2">performance trade-offs</span></strong><span class="koboSpan" id="kobo.309.1">: Balance cost savings with critical application performance requirements. </span><span class="koboSpan" id="kobo.309.2">Under-provisioned backup links may reduce costs, but they can introduce unacceptable risks to business continuity </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">during outages.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.311.1">Proper planning</span><a id="_idIndexMarker996"/><span class="koboSpan" id="kobo.312.1"> and careful configuration of backup links with QoS policies can help ensure smooth transitions during failover, preserving the performance of critical applications and maintaining </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">business continuity.</span></span></p>
<p><span class="koboSpan" id="kobo.314.1">In cloud native environments, failing to implement traffic segregation based on application and data criticality is a serious anti-pattern that can erode system performance, increase latency, and jeopardize the reliability of critical services. </span><span class="koboSpan" id="kobo.314.2">By establishing a robust QoS strategy that prioritizes high-value workloads, organizations can ensure that their cloud native applications are resilient, responsive, and capable of meeting even the most demanding </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">business requirements.</span></span></p>
<h2 id="_idParaDest-258"><a id="_idTextAnchor258"/><span class="koboSpan" id="kobo.316.1">Monolithic connectivity</span></h2>
<p><span class="koboSpan" id="kobo.317.1">We briefly</span><a id="_idIndexMarker997"/><span class="koboSpan" id="kobo.318.1"> touched on the role of network engineers and systems admins in managing on-premises hardware such as switches, routers, and the like; with that mindset came a traditional data center way of planning networking. </span><span class="koboSpan" id="kobo.318.2">The individual hardware components became a single point of failure for the entire network, whereas if a core switch were to fail, the whole network stack would also crumble. </span><span class="koboSpan" id="kobo.318.3">The cloud native</span><a id="_idIndexMarker998"/><span class="koboSpan" id="kobo.319.1"> model has a very different networking setup from that of a data center of a conventional organization; a traditional data center model may set its subnets and network layers across </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.321.1">Core</span></strong><span class="koboSpan" id="kobo.322.1">: The backbone of the network for </span><span class="No-Break"><span class="koboSpan" id="kobo.323.1">core switches</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.324.1">Distribution</span></strong><span class="koboSpan" id="kobo.325.1">: This sits between the cores and handles </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">networking policies/security</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.327.1">Access</span></strong><span class="koboSpan" id="kobo.328.1">: The access layer for servers, storage arrays, and the typical network we see from an </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">admin perspective</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.330.1">The accompanying diagram offers a more detailed illustration to provide a clearer understanding of </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">this concept.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer066">
<span class="koboSpan" id="kobo.332.1"><img alt="" role="presentation" src="image/B22364_09_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.333.1">Figure 9.6 - Three-tier traditional network</span></p>
<p><span class="koboSpan" id="kobo.334.1">Subnetting is managed</span><a id="_idIndexMarker999"/><span class="koboSpan" id="kobo.335.1"> differently across the three network layers. </span><span class="koboSpan" id="kobo.335.2">The following table </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">details this:</span></span></p>
<table class="No-Table-Style" id="table002-2">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.337.1">Network Layer</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.338.1">Subnetting Approach</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.339.1">Function </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.340.1">and Focus</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.341.1">Core layer</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.342.1">Minimal subnetting</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.343.1">Acts as a high-speed interconnect between other layers, prioritizing performance </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">over segmentation</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.345.1">Distribution layer</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.346.1">Extensive subnetting to support </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">diverse needs</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.348.1">Handles fiber channels, firewalls, and traffic monitoring between layers, requiring flexibility </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">and control</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.350.1">Access layer</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.351.1">Traditional </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">subnetting practices</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.353.1">Supports everyday network setups, tailoring subnetting to user </span><span class="No-Break"><span class="koboSpan" id="kobo.354.1">and device</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.355.1">Table 9.2 - Subnetting across network layers</span></p>
<h3><span class="koboSpan" id="kobo.356.1">Monolithic friction with cloud native</span></h3>
<p><span class="koboSpan" id="kobo.357.1">While </span><a id="_idIndexMarker1000"/><span class="koboSpan" id="kobo.358.1">still focused on high-speed interconnectivity, the core layer may leverage virtualized networking solutions that reduce the need for physical infrastructure, making subnetting even more minimal and flexible. </span><span class="koboSpan" id="kobo.358.2">The distribution layer becomes highly dynamic in a cloud native context, with subnetting used to manage VPCs, security groups, and service meshes to control traffic flow between services, storage, and firewalls across multiple regions or AZs. </span><span class="koboSpan" id="kobo.358.3">Meanwhile, the access layer shifts toward integrating scalable resources like containerized workloads, where traditional subnetting practices give way to automated, software-defined networking solutions that dynamically adjust to </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">workload demands.</span></span></p>
<p><span class="koboSpan" id="kobo.360.1">In an ideal world, organizations transitioning to cloud native environments would leave behind the constraints of their old data centers. </span><span class="koboSpan" id="kobo.360.2">However, what often happens instead is that traditional networking models are simply lifted and shifted into the cloud. </span><span class="koboSpan" id="kobo.360.3">This creates a common anti-pattern we’ve encountered frequently, where outdated practices are applied to modern architectures. </span><span class="koboSpan" id="kobo.360.4">The result is a system weighed down by limitations, restricting the true potential of cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">native infrastructure.</span></span></p>
<p><span class="koboSpan" id="kobo.362.1">This section</span><a id="_idIndexMarker1001"/><span class="koboSpan" id="kobo.363.1"> will explore how cloud native environments transition from monolithic connectivity patterns to layered failover strategies across OSI layers. </span><span class="koboSpan" id="kobo.363.2">We’ll focus on the challenges of synchronous versus asynchronous traffic, mitigating single points of failure and configuring packet inspection to meet the unique demands of cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">native architectures.</span></span></p>
<h2 id="_idParaDest-259"><a id="_idTextAnchor259"/><span class="koboSpan" id="kobo.365.1">Monolith to layered networking</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.366.1">Monolithic connectivity</span></strong><span class="koboSpan" id="kobo.367.1">, a common</span><a id="_idIndexMarker1002"/><span class="koboSpan" id="kobo.368.1"> anti-pattern in legacy systems, relies on tightly coupled, single-tiered network designs where all application components communicate internally, often without clear separation or segmentation. </span><span class="koboSpan" id="kobo.368.2">While this model may have worked for smaller, self-contained applications, it struggles to meet the demands of modern cloud native environments, which prioritize scalability, flexibility, </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">and resilience.</span></span></p>
<p><span class="koboSpan" id="kobo.370.1">Organizations transitioning to cloud native architectures adopt layered networking models that separate services and components. </span><span class="koboSpan" id="kobo.370.2">This approach aligns closely with microservices, where each service operates independently and communicates through well-defined network layers. </span><span class="koboSpan" id="kobo.370.3">Organizations can address common issues such as lack of scalability, difficulty isolating failures, and security vulnerabilities by moving away from monolithic connectivity to a more modular, layered structure. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.371.1">Figure 9</span></em></span><em class="italic"><span class="koboSpan" id="kobo.372.1">.1</span></em><span class="koboSpan" id="kobo.373.1"> shows a perfect example of a modular layered network structure, with multiple private subnets segregated within </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">a VPC.</span></span></p>
<h3><span class="koboSpan" id="kobo.375.1">Layered networking</span></h3>
<p><span class="koboSpan" id="kobo.376.1">Layered networking in </span><a id="_idIndexMarker1003"/><span class="koboSpan" id="kobo.377.1">cloud native environments introduces distinct layers, each with a specific purpose. </span><span class="koboSpan" id="kobo.377.2">This segmentation enhances control, isolating services based on their function, priority, or security requirements. </span><span class="koboSpan" id="kobo.377.3">For example, frontend services can be placed in one network layer, while backend services, for example, databases or internal APIs, reside in another. </span><span class="koboSpan" id="kobo.377.4">This layered approach improves scalability</span><a id="_idIndexMarker1004"/><span class="koboSpan" id="kobo.378.1"> and security by limiting direct access to critical services. </span><span class="koboSpan" id="kobo.378.2">By applying network policies, organizations can ensure that only authorized services can communicate across layers, reducing the risk of lateral movement in case of a </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">security breach.</span></span></p>
<p><span class="koboSpan" id="kobo.380.1">Moreover, layered networking </span><a id="_idIndexMarker1005"/><span class="koboSpan" id="kobo.381.1">supports the independent scaling of services. </span><span class="koboSpan" id="kobo.381.2">In monolithic architectures, scaling often meant replicating the entire application, which can be resource-intensive and inefficient. </span><span class="koboSpan" id="kobo.381.3">In contrast, layered architectures enable individual services to scale as needed, depending on traffic and performance demands. </span><span class="koboSpan" id="kobo.381.4">This flexibility ensures that resources are used efficiently and allows organizations to adapt quickly to changing workloads. </span><span class="koboSpan" id="kobo.381.5">The following table details the benefits of the layered </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">networking approach:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table003-2">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.383.1">Aspect</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.384.1">Monolithic Connectivity</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.385.1">Layered Networking (</span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.386.1">Cloud native)</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.387.1">Scalability</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.388.1">Scaling requires replicating the entire </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">monolithic application</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.390.1">Independent services can be scaled individually, reducing </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">resource use</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.392.1">Security</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.393.1">All components communicate freely within the same network tier, posing potential </span><span class="No-Break"><span class="koboSpan" id="kobo.394.1">security risks</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.395.1">There is a clear separation of services, enabling better security policies </span><span class="No-Break"><span class="koboSpan" id="kobo.396.1">and isolation</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.397.1">Resilience</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.398.1">A failure in one system part can bring down the </span><span class="No-Break"><span class="koboSpan" id="kobo.399.1">entire application</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.400.1">Isolated services reduce the blast radius of failures, </span><span class="No-Break"><span class="koboSpan" id="kobo.401.1">enhancing resilience</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.402.1">Flexibility</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.403.1">It is difficult to modify or add services without impacting the </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">entire system</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.405.1">Services can be added, modified, or replaced without affecting the </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">whole architecture</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.407.1">Network </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.408.1">Traffic Control</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.409.1">There is no clear traffic segmentation; all traffic flows freely </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1">between components</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.411.1">Traffic is segmented based on service layers, allowing for better traffic management </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">and monitoring</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.413.1">Development </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.414.1">Speed</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.415.1">Changes require complete application testing </span><span class="No-Break"><span class="koboSpan" id="kobo.416.1">and deployment</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.417.1">Individual services can be updated and </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">deployed independently</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.419.1">Table 9.3 - Benefits of layered networking</span></p>
<h3><span class="koboSpan" id="kobo.420.1">Monolith to microservice – networking-focused example</span></h3>
<p><span class="koboSpan" id="kobo.421.1">During a</span><a id="_idIndexMarker1006"/><span class="koboSpan" id="kobo.422.1"> consulting engagement with a government client, we were tasked with addressing significant network challenges as part of their</span><a id="_idIndexMarker1007"/><span class="koboSpan" id="kobo.423.1"> transition from a monolithic architecture to a cloud native environment. </span><span class="koboSpan" id="kobo.423.2">The company’s original network design lacked segmentation, with all services, frontend applications, databases, and internal APIs residing in a single flat network. </span><span class="koboSpan" id="kobo.423.3">This setup led to numerous issues, including inefficiencies in traffic flow, security vulnerabilities, and scaling challenges, particularly with IP allocation due to a small </span><span class="No-Break"><span class="koboSpan" id="kobo.424.1">subnet range.</span></span></p>
<p><span class="koboSpan" id="kobo.425.1">Their monolithic network architecture made isolating services based on function or security requirements difficult. </span><span class="koboSpan" id="kobo.425.2">All traffic flowed through the same network, exposing critical backend services, such as databases, to unnecessary risk. </span><span class="koboSpan" id="kobo.425.3">Without proper network segmentation, any breach in the system could quickly spread laterally, potentially compromising sensitive data. </span><span class="koboSpan" id="kobo.425.4">Moreover, as traffic to their platform grew, scaling required replicating the entire system, including components that didn’t need to be scaled. </span><span class="koboSpan" id="kobo.425.5">This approach was resource-intensive </span><span class="No-Break"><span class="koboSpan" id="kobo.426.1">and inefficient.</span></span></p>
<h3><span class="koboSpan" id="kobo.427.1">The approach – three-tier network</span></h3>
<p><span class="koboSpan" id="kobo.428.1">We introduced a</span><a id="_idIndexMarker1008"/><span class="koboSpan" id="kobo.429.1"> layered networking model on AWS, following three-tier capabilities to bring order and control to their cloud native infrastructure. </span><span class="koboSpan" id="kobo.429.2">This model was deployed </span><span class="No-Break"><span class="koboSpan" id="kobo.430.1">as follows:</span></span></p>
<ol>
<li><strong class="bold"><span class="koboSpan" id="kobo.431.1">Presentation </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.432.1">layer (frontend)</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.433.1">:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.434.1">Purpose</span></strong><span class="koboSpan" id="kobo.435.1">: Handles user requests and public traffic, primarily on user-facing components like web servers </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1">or APIs.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.437.1">Implementation</span></strong><span class="koboSpan" id="kobo.438.1">: Place frontend services in a public subnet within the AWS VPC, accessible from </span><span class="No-Break"><span class="koboSpan" id="kobo.439.1">the internet.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.440.1">Security</span></strong><span class="koboSpan" id="kobo.441.1">: Use security groups and </span><strong class="bold"><span class="koboSpan" id="kobo.442.1">web application firewalls</span></strong><span class="koboSpan" id="kobo.443.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.444.1">WAFs</span></strong><span class="koboSpan" id="kobo.445.1">) to protect against external threats while allowing incoming web traffic or load </span><span class="No-Break"><span class="koboSpan" id="kobo.446.1">balancer traffic.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.447.1">Application layer (</span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.448.1">business logic)</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.450.1">Purpose</span></strong><span class="koboSpan" id="kobo.451.1">: Processes business logic, communicating between the frontend and the backend. </span><span class="koboSpan" id="kobo.451.2">This layer hosts the internal services, APIs, </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">or microservices.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.453.1">Implementation</span></strong><span class="koboSpan" id="kobo.454.1">: Deploy application services in a private subnet to isolate them from direct internet access while allowing them to communicate with both the frontend and </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">backend layers.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.456.1">Security</span></strong><span class="koboSpan" id="kobo.457.1">: Use security groups to control which frontend services can communicate with the application layer, ensuring only authorized traffic flows between these layers. </span><span class="koboSpan" id="kobo.457.2">Access between Kubernetes Pods was limited using security group references, eliminating IP spoofing as an </span><span class="No-Break"><span class="koboSpan" id="kobo.458.1">attack vector.</span></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.459.1">Data </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.460.1">layer (backend)</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.461.1">:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.462.1">Purpose</span></strong><span class="koboSpan" id="kobo.463.1">: Stores and manages data, like databases and internal APIs, which must be secure </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1">and isolated.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.465.1">Implementation</span></strong><span class="koboSpan" id="kobo.466.1">: Place databases and other backend services in a separate private subnet with strict access controls to ensure that only the application layer can </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">access it.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.468.1">Security</span></strong><span class="koboSpan" id="kobo.469.1">: Implement a VPC gateway endpoint to restrict access and configure </span><strong class="bold"><span class="koboSpan" id="kobo.470.1">network access control lists</span></strong><span class="koboSpan" id="kobo.471.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.472.1">NACLs</span></strong><span class="koboSpan" id="kobo.473.1">) to further restrict any unauthorized access from </span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">other subnets.</span></span></li></ul></li>
</ol>
<p><span class="koboSpan" id="kobo.475.1">On top of the </span><a id="_idIndexMarker1009"/><span class="koboSpan" id="kobo.476.1">three-tier approach here, we had distributed all three tiers across multiple AZs; the architecture was significantly more resilient and scalable, allowing the application to continue functioning even if an entire zone went offline. </span><span class="koboSpan" id="kobo.476.2">When an AZ was created, the application would scale to other zones, and traffic would automatically be directed to the new nodes. </span><span class="koboSpan" id="kobo.476.3">AZs are isolated data center locations (per zone) within an AWS region, each with independent power, networking, and cooling. </span><span class="koboSpan" id="kobo.476.4">They offer much greater resilience than two traditional data centers because they are geographically separate yet closely interconnected; this also consists of fully redundant dedicated fiber lines. </span><span class="koboSpan" id="kobo.476.5">This ensures that even if one zone fails due to a localized issue, the others remain fully operational without impacting performance. </span><span class="koboSpan" id="kobo.476.6">Where this multiple AZ design was leveraged best was when addressing synchronous and </span><span class="No-Break"><span class="koboSpan" id="kobo.477.1">asynchronous traffic.</span></span></p>
<h2 id="_idParaDest-260"><a id="_idTextAnchor260"/><span class="koboSpan" id="kobo.478.1">Synchronous versus synchronous traffic</span></h2>
<p><span class="koboSpan" id="kobo.479.1">Cloud </span><a id="_idIndexMarker1010"/><span class="koboSpan" id="kobo.480.1">native </span><a id="_idIndexMarker1011"/><span class="koboSpan" id="kobo.481.1">architecture fundamentally shifts how traffic and communication between services are handled. </span><span class="koboSpan" id="kobo.481.2">One of the most significant challenges in traditional environments is managing synchronous versus asynchronous traffic, which can become a bottleneck as systems grow in complexity and demand. </span><span class="koboSpan" id="kobo.481.3">Traditional organizations’ services often rely on synchronous communication, meaning that one service must wait for a response from another before continuing. </span><span class="koboSpan" id="kobo.481.4">This approach can lead to inefficiencies, higher latency, and potential points of failure, particularly in distributed environments where network issues or service delays can halt </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1">entire processes.</span></span></p>
<p><span class="koboSpan" id="kobo.483.1">Comparatively, cloud </span><a id="_idIndexMarker1012"/><span class="koboSpan" id="kobo.484.1">native architectures </span><a id="_idIndexMarker1013"/><span class="koboSpan" id="kobo.485.1">are designed to embrace asynchronous communication. </span><span class="koboSpan" id="kobo.485.2">This shift resolves a major anti-pattern often seen in traditional setups, where systems are tightly coupled and dependent on real-time, synchronous responses. </span><span class="koboSpan" id="kobo.485.3">These traditional systems struggle under high load or when services experience delays, leading to timeouts, failures, and decreased resilience. </span><span class="koboSpan" id="kobo.485.4">Let’s look at the benefits of asynchronous traffic in a cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.486.1">native environment.</span></span></p>
<h3><span class="koboSpan" id="kobo.487.1">Key benefits of asynchronous traffic in cloud native</span></h3>
<p><span class="koboSpan" id="kobo.488.1">The following</span><a id="_idIndexMarker1014"/><span class="koboSpan" id="kobo.489.1"> benefits highlight why asynchronous traffic is essential for cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.490.1">native applications:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.491.1">Increased resilience</span></strong><span class="koboSpan" id="kobo.492.1">: Services can continue functioning even if one part of the system is delayed </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">or unavailable</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.494.1">Improved scalability</span></strong><span class="koboSpan" id="kobo.495.1">: Asynchronous systems can handle higher loads because they don’t require immediate responses, reducing the strain on services during </span><span class="No-Break"><span class="koboSpan" id="kobo.496.1">peak traffic</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.497.1">Decoupled services</span></strong><span class="koboSpan" id="kobo.498.1">: Cloud native systems encourage loose coupling, where services operate independently, reducing the risk of </span><span class="No-Break"><span class="koboSpan" id="kobo.499.1">cascading failures</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.500.1">Fault tolerance</span></strong><span class="koboSpan" id="kobo.501.1">: By using queues and event-driven models, systems can automatically retry failed operations without blocking </span><span class="No-Break"><span class="koboSpan" id="kobo.502.1">other processes</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.503.1">From strong consistency to eventual consistency</span></h3>
<p><span class="koboSpan" id="kobo.504.1">A key aspect of this transition is the shift from </span><em class="italic"><span class="koboSpan" id="kobo.505.1">strongly consistent</span></em><span class="koboSpan" id="kobo.506.1"> to </span><em class="italic"><span class="koboSpan" id="kobo.507.1">eventually consistent</span></em><span class="koboSpan" id="kobo.508.1"> systems, which</span><a id="_idIndexMarker1015"/><span class="koboSpan" id="kobo.509.1"> allows cloud native applications to prioritize availability and fault tolerance over immediate consistency. </span><span class="koboSpan" id="kobo.509.2">By adopting eventual consistency, cloud native systems can handle large-scale, distributed workloads more effectively, as they no longer rely on the entire system being perfectly synchronized. </span><span class="koboSpan" id="kobo.509.3">This approach increases scalability and resilience, enabling systems to operate smoothly even when components are temporarily out of sync – an essential trade-off in high-traffic, globally </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1">distributed environments.</span></span></p>
<p><span class="koboSpan" id="kobo.511.1">Cloud native architectures resolve this challenge by leveraging asynchronous communication models, such as message queues, event-driven architectures, and serverless components. </span><span class="koboSpan" id="kobo.511.2">In these systems, services publish events or send messages without waiting for an immediate response. </span><span class="koboSpan" id="kobo.511.3">For example, when a user places an order on an e-commerce platform, the order might be processed asynchronously through a message queue (e.g., Amazon SQS or Kafka), allowing the frontend to continue interacting with the user while the backend processes the order in the background. </span><span class="koboSpan" id="kobo.511.4">This decoupling improves the application’s resilience, as the failure or delay of one service does not impact the overall system’s ability to respond to users or </span><span class="No-Break"><span class="koboSpan" id="kobo.512.1">continue functioning.</span></span></p>
<h3><span class="koboSpan" id="kobo.513.1">Addressing monolithic connectivity</span></h3>
<p><span class="koboSpan" id="kobo.514.1">In </span><a id="_idIndexMarker1016"/><span class="koboSpan" id="kobo.515.1">traditional systems, the reliance on synchronous communication creates an anti-pattern of tight coupling, where services are overly dependent on each other and must be available in real time for the system to function properly. </span><span class="koboSpan" id="kobo.515.2">This introduces fragility, as any delay or failure in one component can ripple through the </span><span class="No-Break"><span class="koboSpan" id="kobo.516.1">entire system.</span></span></p>
<p><span class="koboSpan" id="kobo.517.1">Cloud native architectures resolve this by promoting asynchronous communication, where services interact without waiting for immediate responses. </span><span class="koboSpan" id="kobo.517.2">In doing so, the anti-pattern is broken, and systems become more resilient, scalable, and adaptable to change. </span><span class="koboSpan" id="kobo.517.3">As organizations move to cloud native, they benefit from the flexibility of being able to scale individual services independently, handle failures gracefully, and process high volumes of traffic more efficiently. </span><span class="koboSpan" id="kobo.517.4">This shift not only improves the system’s overall performance but also lays the foundation for a more agile, adaptable infrastructure that can evolve with the </span><span class="No-Break"><span class="koboSpan" id="kobo.518.1">business’s needs.</span></span></p>
<p><span class="koboSpan" id="kobo.519.1">In moving </span><a id="_idIndexMarker1017"/><span class="koboSpan" id="kobo.520.1">from monolithic connectivity to layered networking, cloud native architectures significantly improve scalability, security, and resilience. </span><span class="koboSpan" id="kobo.520.2">By adopting layered models, organizations can break away from tightly coupled, synchronous systems prone to single points of failure. </span><span class="koboSpan" id="kobo.520.3">Instead, services are isolated and scalable, allowing greater flexibility and control. </span><span class="koboSpan" id="kobo.520.4">With proper segmentation, even the most complex infrastructures can maintain high availability, and the risk of lateral movement during a security breach is minimized. </span><span class="koboSpan" id="kobo.520.5">These benefits make cloud native approaches far superior to traditional models, ensuring they remain robust and efficient as </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">applications scale.</span></span></p>
<p><span class="koboSpan" id="kobo.522.1">Next, we’ll explore another critically overlooked anti-pattern: ignoring cloud native networking features. </span><span class="koboSpan" id="kobo.522.2">We’ll examine how failing to leverage built-in cloud features can limit performance and security and how properly utilizing these features can maximize the benefits of a cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.523.1">native infrastructure.</span></span></p>
<h1 id="_idParaDest-261"><a id="_idTextAnchor261"/><span class="koboSpan" id="kobo.524.1">Ignoring cloud native networking features</span></h1>
<p><span class="koboSpan" id="kobo.525.1">One of the most common pitfalls when transitioning to cloud native architectures is overlooking the powerful networking features inherently built into cloud platforms. </span><span class="koboSpan" id="kobo.525.2">In traditional on-premises environments, networking is often hardware-centric, relying on physical switches, routers, and firewalls. </span><span class="koboSpan" id="kobo.525.3">This leads to misconceptions and misaligned expectations when dealing with the more dynamic, software-driven nature of cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">native networking.</span></span></p>
<p><span class="koboSpan" id="kobo.527.1">This section will explore how failing to fully embrace </span><strong class="bold"><span class="koboSpan" id="kobo.528.1">software-defined networking</span></strong><span class="koboSpan" id="kobo.529.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.530.1">SDN</span></strong><span class="koboSpan" id="kobo.531.1">) in the</span><a id="_idIndexMarker1018"/><span class="koboSpan" id="kobo.532.1"> cloud can lead to performance and resilience issues. </span><span class="koboSpan" id="kobo.532.2">We will also stress the importance of treating network configuration as code </span><a id="_idIndexMarker1019"/><span class="koboSpan" id="kobo.533.1">through </span><strong class="bold"><span class="koboSpan" id="kobo.534.1">infrastructure as code</span></strong><span class="koboSpan" id="kobo.535.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.536.1">IaC</span></strong><span class="koboSpan" id="kobo.537.1">), a practice crucial for successfully implementing cloud native networking. </span><span class="koboSpan" id="kobo.537.2">The risks associated with inadequate network boundary guardrails, especially when managing access between environments such as production and non-production are </span><span class="No-Break"><span class="koboSpan" id="kobo.538.1">also discussed.</span></span></p>
<p><span class="koboSpan" id="kobo.539.1">Each of these areas presents unique challenges, and a failure to address them can limit the potential of cloud native infrastructures, leaving organizations vulnerable to security breaches and </span><span class="No-Break"><span class="koboSpan" id="kobo.540.1">operational inefficiencies.</span></span></p>
<h2 id="_idParaDest-262"><a id="_idTextAnchor262"/><span class="koboSpan" id="kobo.541.1">SDN in the cloud – the risks from on-premises</span></h2>
<p><span class="koboSpan" id="kobo.542.1">SDN is </span><a id="_idIndexMarker1020"/><span class="koboSpan" id="kobo.543.1">not a concept that is limited to just the cloud native environment; the idea has been around for some time. </span><span class="koboSpan" id="kobo.543.2">Popularizing this concept</span><a id="_idIndexMarker1021"/><span class="koboSpan" id="kobo.544.1"> arguably has been companies such as VMware with their VMware NSX product, released in 2013 – an early example of SDN that allows virtualization of network infrastructure, enabling the creation, management, and automation of complex networks through software rather than traditional hardware. </span><span class="koboSpan" id="kobo.544.2">Rather than setting up entire server racks worth of hardware from scratch, SDN tools like VMware NSX gave admins a much quicker way to deploy and extend their networks to new hardware; cloud vendors adopted this concept to do the same without needing the hardware components. </span><span class="koboSpan" id="kobo.544.3">SDN in traditional environments still requires hardware to deploy; it just makes templating a </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">lot easier.</span></span></p>
<p><span class="koboSpan" id="kobo.546.1">SDN thrives in the cloud, shifting control from physical hardware to software-based solutions. </span><span class="koboSpan" id="kobo.546.2">This transformation allows cloud providers such as AWS, Azure, and GCP to offer flexible, scalable, and dynamic networking solutions that adapt to the needs of modern applications. </span><span class="koboSpan" id="kobo.546.3">Here</span><a id="_idIndexMarker1022"/><span class="koboSpan" id="kobo.547.1"> are some key examples of how SDN is applied across </span><span class="No-Break"><span class="koboSpan" id="kobo.548.1">these platforms:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.549.1">AWS</span></strong><span class="koboSpan" id="kobo.550.1">: Amazon VPC enables isolated networks with control over routing, firewalls, </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">and access</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.552.1">Azure</span></strong><span class="koboSpan" id="kobo.553.1">: Azure VNet uses SDN with tools like NSGs and Azure Firewall for traffic segmentation and network </span><span class="No-Break"><span class="koboSpan" id="kobo.554.1">policy automation</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.555.1">GCP</span></strong><span class="koboSpan" id="kobo.556.1">: Google Cloud VPC uses SDN for customizable IP ranges, firewall rules, and routing, with tools</span><a id="_idIndexMarker1023"/><span class="koboSpan" id="kobo.557.1"> such as Cloud Armor and VPC peering for security </span><span class="No-Break"><span class="koboSpan" id="kobo.558.1">and connectivity</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.559.1">Across all three platforms, SDN provides the flexibility to scale, automate, and manage network infrastructure programmatically, allowing users to build secure, optimized cloud environments without the limitations of </span><span class="No-Break"><span class="koboSpan" id="kobo.560.1">traditional hardware.</span></span></p>
<h3><span class="koboSpan" id="kobo.561.1">Networking mindset changes with cloud native</span></h3>
<p><span class="koboSpan" id="kobo.562.1">One of the</span><a id="_idIndexMarker1024"/><span class="koboSpan" id="kobo.563.1"> most common cloud native anti-patterns is the lack of understanding of SDN in cloud environments compared to traditional on-premises hardware setups. </span><span class="koboSpan" id="kobo.563.2">This gap in understanding often leads to unrealistic expectations around performance, resilience, and overall network behavior, resulting in misconfigurations that compromise both system reliability </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1">and scalability.</span></span></p>
<p><span class="koboSpan" id="kobo.565.1">With the cloud vendors, a common misunderstanding arises when users expect cloud networking to behave like traditional hardware-based infrastructure, where dedicated physical devices dictate network performance and capacity. </span><span class="koboSpan" id="kobo.565.2">Network reliability is tied directly to hardware robustness, such as switches and routers in an on-premises environment. </span><span class="koboSpan" id="kobo.565.3">However, AWS networking, like Amazon VPC, is entirely virtualized. </span><span class="koboSpan" id="kobo.565.4">Performance and resilience depend on how well subnets, security groups, and multi-AZ setups are configured. </span><span class="koboSpan" id="kobo.565.5">Misconfigurations in this virtual environment can lead to poor fault tolerance and performance bottlenecks, starkly contrasting the expectations of physical </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">hardware environments.</span></span></p>
<h3><span class="koboSpan" id="kobo.567.1">Legacy brought to the cloud native networking – a case study</span></h3>
<p><span class="koboSpan" id="kobo.568.1">We </span><a id="_idIndexMarker1025"/><span class="koboSpan" id="kobo.569.1">encountered a common example of a poorly configured AWS networking setup during a network uplift engagement with a banking client. </span><span class="koboSpan" id="kobo.569.2">However, when we refer to “poorly configured,” it’s essential to recognize that what was once considered best practice can, with the passage of time and advancements in technology, evolve into a suboptimal solution. </span><span class="koboSpan" id="kobo.569.3">This client transitioned from an on-premises infrastructure to AWS over 3–4 years. </span><span class="koboSpan" id="kobo.569.4">Initially, their network architects viewed the three-tier AWS network design as too simplistic and believed it introduced too much overhead for cross-domain communication and </span><span class="No-Break"><span class="koboSpan" id="kobo.570.1">change management.</span></span></p>
<p><span class="koboSpan" id="kobo.571.1">Instead of designing separate VPCs for each environment or workload, the architects implemented a</span><a id="_idIndexMarker1026"/><span class="koboSpan" id="kobo.572.1"> design that centralized networking into a single VPC shared across multiple accounts. </span><span class="koboSpan" id="kobo.572.2">In this design, subnets were shared between different accounts, which seemed logical from a traditional networking perspective. </span><span class="koboSpan" id="kobo.572.3">It mirrored the idea of a centralized core network sharing access layers across various AWS accounts. </span><span class="koboSpan" id="kobo.572.4">However, rather than solving overhead issues, this approach introduced significant complexity. </span><span class="koboSpan" id="kobo.572.5">When a change or flexibility was required, any alteration to the VPC structure or route table rules affected all accounts within the shared network. </span><span class="koboSpan" id="kobo.572.6">Instead of building a fault-tolerant, layered cloud network, they had inadvertently created a single point of failure disguised as simplicity. </span><span class="koboSpan" id="kobo.572.7">This design was similar to </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">the following:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer067">
<span class="koboSpan" id="kobo.574.1"><img alt="" role="presentation" src="image/B22364_09_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.575.1">Figure 9.7 - Shared VPC design</span></p>
<p><span class="koboSpan" id="kobo.576.1">In a risk-averse industry such as banking, this design flaw was compounded by the fact that even minor changes were heavily scrutinized during change advisory board meetings. </span><span class="koboSpan" id="kobo.576.2">The result was a rigid, fragile network architecture that stifled agility and introduced </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">considerable risk.</span></span></p>
<p><span class="koboSpan" id="kobo.578.1">Our solution was </span><a id="_idIndexMarker1027"/><span class="koboSpan" id="kobo.579.1">transitioning from shared subnets to individual VPCs for each account, interconnected through AWS Transit Gateway. </span><span class="koboSpan" id="kobo.579.2">To preserve the benefits of the shared subnet setup, we restructured the network, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.580.1">Figure 9</span></em></span><em class="italic"><span class="koboSpan" id="kobo.581.1">.1</span></em><span class="koboSpan" id="kobo.582.1">. </span><span class="koboSpan" id="kobo.582.2">All outbound traffic, such as internet and third-party requests, was routed through an egress VPC, where a security appliance such as a FortiGate firewall scanned all outbound traffic. </span><span class="koboSpan" id="kobo.582.3">This eliminated the need for multiple NAT gateways or instances. </span><span class="koboSpan" id="kobo.582.4">Each VPC was configured with specific subnets, allowing cloud native features to be enabled or restricted based on the use case. </span><span class="koboSpan" id="kobo.582.5">For example, data/private subnets were limited to accessing only DynamoDB gateway endpoints, ensuring tighter security and minimizing unnecessary </span><span class="No-Break"><span class="koboSpan" id="kobo.583.1">service access.</span></span></p>
<p><span class="koboSpan" id="kobo.584.1">The added benefit of this rearchitected solution was a more resilient, dispersed network design. </span><span class="koboSpan" id="kobo.584.2">Changes were now account-specific, significantly reducing the blast radius of any failed modifications. </span><span class="koboSpan" id="kobo.584.3">This modular design ensured that any impact was limited to individual environments, enhancing agility and </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">fault tolerance.</span></span></p>
<p><span class="koboSpan" id="kobo.586.1">As we have touched on changes, this leads us to the next section on inadequate network access reviews and missing </span><span class="No-Break"><span class="koboSpan" id="kobo.587.1">boundary guardrails.</span></span></p>
<h2 id="_idParaDest-263"><a id="_idTextAnchor263"/><span class="koboSpan" id="kobo.588.1">Inadequate network access reviews and missing boundary guardrails</span></h2>
<p><span class="koboSpan" id="kobo.589.1">With</span><a id="_idIndexMarker1028"/><span class="koboSpan" id="kobo.590.1"> traditional data centers, where physical boundaries naturally limit access, cloud infrastructure is</span><a id="_idIndexMarker1029"/><span class="koboSpan" id="kobo.591.1"> dynamic, allowing for easier and potentially dangerous access escalation. </span><span class="koboSpan" id="kobo.591.2">Without regular, thorough reviews of access privileges, users or systems may gain unintended access to critical production environments from non-production or development systems. </span><span class="koboSpan" id="kobo.591.3">This lack of oversight leaves organizations vulnerable to unauthorized lateral movement, exposing sensitive data and core systems to </span><span class="No-Break"><span class="koboSpan" id="kobo.592.1">significant threats.</span></span></p>
<p><span class="koboSpan" id="kobo.593.1">The absence of solid network boundary guardrails further exacerbates these risks. </span><span class="koboSpan" id="kobo.593.2">Guardrails, such as security groups, firewall rules, and routing table policies, are essential for keeping access within the intended environment. </span><span class="koboSpan" id="kobo.593.3">Without these controls, the network becomes flat, allowing unrestricted movement across environments, which increases the</span><a id="_idIndexMarker1030"/><span class="koboSpan" id="kobo.594.1"> risk of breaches</span><a id="_idIndexMarker1031"/><span class="koboSpan" id="kobo.595.1"> and non-compliance with industry regulations. </span><span class="koboSpan" id="kobo.595.2">To secure cloud native environments effectively, organizations must implement rigorous access reviews and enforce strict boundary controls to prevent unauthorized access and escalation. </span><span class="koboSpan" id="kobo.595.3">A common sense approach would be to segregate resources within their groupings between environments (i.e., for AWS), having a production account containing only production networking resources and no connections to non-production or testing environments via any means. </span><span class="koboSpan" id="kobo.595.4">The following table outlines the risks </span><span class="No-Break"><span class="koboSpan" id="kobo.596.1">typically found:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table004-2">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.597.1">Risk</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.598.1">Description</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.599.1">Access </span><span class="No-Break"><span class="koboSpan" id="kobo.600.1">escalation</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.601.1">Users gain unauthorized access to production systems from </span><span class="No-Break"><span class="koboSpan" id="kobo.602.1">non-production environments</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.603.1">Weak security </span><span class="No-Break"><span class="koboSpan" id="kobo.604.1">posture</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.605.1">The lack of boundary guardrails results in flat network structures, allowing unauthorized movement </span><span class="No-Break"><span class="koboSpan" id="kobo.606.1">between environments</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.607.1">Increased </span><span class="No-Break"><span class="koboSpan" id="kobo.608.1">attack surface</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.609.1">Poorly defined boundaries create vulnerabilities, enabling attackers to move laterally within </span><span class="No-Break"><span class="koboSpan" id="kobo.610.1">the network</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.611.1">Compliance </span><span class="No-Break"><span class="koboSpan" id="kobo.612.1">violations</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.613.1">Inadequate control and oversight can lead to non-compliance with security and </span><span class="No-Break"><span class="koboSpan" id="kobo.614.1">regulatory standards</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.615.1">Operational </span><span class="No-Break"><span class="koboSpan" id="kobo.616.1">risks</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.617.1">Overlapping or misconfigured access can cause outages, service disruptions, and, importantly, break </span><span class="No-Break"><span class="koboSpan" id="kobo.618.1">compliance measures</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.619.1">Table 9.4 - Key risks of inadequate network access reviews and missing guardrails</span></p>
<p><span class="koboSpan" id="kobo.620.1">Organizations</span><a id="_idIndexMarker1032"/><span class="koboSpan" id="kobo.621.1"> can </span><a id="_idIndexMarker1033"/><span class="koboSpan" id="kobo.622.1">better protect their cloud infrastructure by addressing these issues through consistent access reviews and robust boundary guardrails, ensuring secure and compliant operations. </span><span class="koboSpan" id="kobo.622.2">To better deliver the previously mentioned IaC and automation, they </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">are key.</span></span></p>
<h2 id="_idParaDest-264"><a id="_idTextAnchor264"/><span class="koboSpan" id="kobo.624.1">IaC and automation – the networking perspective</span></h2>
<p><span class="koboSpan" id="kobo.625.1">At the </span><a id="_idIndexMarker1034"/><span class="koboSpan" id="kobo.626.1">heart of every cloud native organization is IaC. </span><span class="koboSpan" id="kobo.626.2">The specific tool you choose (Terraform, CloudFormation, or Azure Resource Manager) matters less than how you design and implement it. </span><span class="koboSpan" id="kobo.626.3">Every IaC tool is both terrible and terrific, but what truly defines a successful approach is the architecture and best practices behind its use. </span><span class="koboSpan" id="kobo.626.4">Standardization is critical to efficient infrastructure deployment across cloud native environments. </span><span class="koboSpan" id="kobo.626.5">This is especially true for cloud networking, where consistency is crucial for managing multiple environments, such as development, testing, </span><span class="No-Break"><span class="koboSpan" id="kobo.627.1">and production.</span></span></p>
<p><span class="koboSpan" id="kobo.628.1">Without proper standardization and best practices, cloud infrastructure can quickly become chaotic. </span><span class="koboSpan" id="kobo.628.2">Different teams may deploy similar resources in various ways, leading to inefficiencies, inconsistencies, and unnecessary complexity. </span><span class="koboSpan" id="kobo.628.3">The result is a system that becomes difficult to manage and prone to errors. </span><span class="koboSpan" id="kobo.628.4">Standardization is not just about keeping things tidy; it’s about ensuring that every deployment follows a predictable, efficient pattern that can be repeated and scaled. </span><span class="koboSpan" id="kobo.628.5">So, what does effective standardization and best practice look like? </span><span class="koboSpan" id="kobo.628.6">Consider the following </span><span class="No-Break"><span class="koboSpan" id="kobo.629.1">best practices:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.630.1">Defined naming standards</span></strong><span class="koboSpan" id="kobo.631.1">: Create clear naming conventions to ensure consistency across environments. </span><span class="koboSpan" id="kobo.631.2">For example, using a pattern such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.632.1">{environment}-{app}-{resource}-{name}</span></strong><span class="koboSpan" id="kobo.633.1"> – for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.634.1">prod-banking-aks-node</span></strong><span class="koboSpan" id="kobo.635.1"> – helps maintain clarity and </span><span class="No-Break"><span class="koboSpan" id="kobo.636.1">avoids confusion.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.637.1">Repeatable patterns</span></strong><span class="koboSpan" id="kobo.638.1">: For repeated deployments, such as setting up a VNet in Azure across multiple environments, use reusable modules (e.g., Terraform modules or CDK functions). </span><span class="koboSpan" id="kobo.638.2">This ensures consistency in how infrastructure is deployed and makes </span><span class="No-Break"><span class="koboSpan" id="kobo.639.1">management easier.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.640.1">Plan before you deploy</span></strong><span class="koboSpan" id="kobo.641.1">: Especially with networking resources, ensure that infrastructure changes can be made without disrupting running environments. </span><span class="koboSpan" id="kobo.641.2">Some changes, such as renaming resources, can trigger replacements that may bring down critical systems during change windows, and idempotency safeguards against </span><span class="No-Break"><span class="koboSpan" id="kobo.642.1">such risks.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.643.1">Version control</span></strong><span class="koboSpan" id="kobo.644.1">: Use Git to store and manage your IaC. </span><span class="koboSpan" id="kobo.644.2">Version control allows for easy tracking of changes and rollbacks and better collaboration across teams, ensuring that infrastructure deployments remain consistent </span><span class="No-Break"><span class="koboSpan" id="kobo.645.1">and traceable.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.646.1">Automated deployment pipelines</span></strong><span class="koboSpan" id="kobo.647.1">: Implement CI/CD pipelines for infrastructure deployment rather than relying on manual, localized processes. </span><span class="koboSpan" id="kobo.647.2">This reduces human error, ensures consistency, and allows for better integration with version control systems for </span><span class="No-Break"><span class="koboSpan" id="kobo.648.1">streamlined management.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.649.1">By</span><a id="_idIndexMarker1035"/><span class="koboSpan" id="kobo.650.1"> adhering to these principles, organizations can bring order to the complexities of cloud deployments, ensuring that infrastructure is scalable, maintainable, and efficient. </span><span class="koboSpan" id="kobo.650.2">Standardization isn’t just a best practice; it’s the foundation for long-term success in the cloud. </span><span class="koboSpan" id="kobo.650.3">The following figure provides a simple example of what an automated and standardized pipeline looks like when deploying </span><span class="No-Break"><span class="koboSpan" id="kobo.651.1">with CI/CD:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer068">
<span class="koboSpan" id="kobo.652.1"><img alt="" role="presentation" src="image/B22364_09_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.653.1">Figure 9.8 - Simple IaC change, check, and deployment pipeline</span></p>
<p><span class="koboSpan" id="kobo.654.1">In a</span><a id="_idIndexMarker1036"/><span class="koboSpan" id="kobo.655.1"> well-automated, IaC-driven, cloud native network, changes to routing rules or security policies are scripted, version-controlled, and deployed uniformly across environments. </span><span class="koboSpan" id="kobo.655.2">This ensures that every environment, whether development, testing, or production, has consistent network configurations, reducing the risk of miscommunication between services and ensuring tight security controls. </span><span class="koboSpan" id="kobo.655.3">Conversely, in environments where networking is managed manually, any change is subject to human error, creating discrepancies across environments that can lead to outages or </span><span class="No-Break"><span class="koboSpan" id="kobo.656.1">data breaches.</span></span></p>
<p><span class="koboSpan" id="kobo.657.1">Beyond the risk of misconfiguration, neglecting automation in networking slows down an organization’s ability to scale. </span><span class="koboSpan" id="kobo.657.2">Cloud native environments demand agility, and without automated network deployments, provisioning new environments or scaling existing ones becomes a time-consuming, error-prone task. </span><span class="koboSpan" id="kobo.657.3">Teams are forced to replicate network configurations manually, often introducing inconsistencies that can cause </span><span class="No-Break"><span class="koboSpan" id="kobo.658.1">service disruptions.</span></span></p>
<h1 id="_idParaDest-265"><a id="_idTextAnchor265"/><span class="koboSpan" id="kobo.659.1">Zero Trust application patterns</span></h1>
<p><span class="koboSpan" id="kobo.660.1">As organizations</span><a id="_idIndexMarker1037"/><span class="koboSpan" id="kobo.661.1"> transition from on-premises environments to cloud native architectures, the </span><strong class="bold"><span class="koboSpan" id="kobo.662.1">Zero Trust</span></strong><span class="koboSpan" id="kobo.663.1"> model is one of the most crucial security shifts they must adopt. </span><span class="koboSpan" id="kobo.663.2">In traditional on-premises environments, security often hinged on perimeter defenses; if you were inside the network, you were trusted. </span><span class="koboSpan" id="kobo.663.3">However, cloud native applications operate in a more dynamic, distributed, and potentially exposed environment. </span><span class="koboSpan" id="kobo.663.4">The concept of a transparent network boundary dissolves in the cloud, where services span regions, multiple VPCs, and often different cloud providers. </span><span class="koboSpan" id="kobo.663.5">This is where Zero Trust emerges as an essential security framework, built on the premise of “</span><em class="italic"><span class="koboSpan" id="kobo.664.1">never trust, </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.665.1">always verify</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.666.1">.”</span></span></p>
<p><span class="koboSpan" id="kobo.667.1">In its simplest terms, Zero Trust rejects the notion of implicit trust based on location or ownership of a network. </span><span class="koboSpan" id="kobo.667.2">Instead, it assumes that every user, device, and application must continuously prove its legitimacy before accessing resources. </span><span class="koboSpan" id="kobo.667.3">The core principles of Zero Trust dictate that security should not only focus on external threats but also on monitoring and controlling access within the network, preventing unauthorized lateral movement, and reducing the attack surface. </span><span class="koboSpan" id="kobo.667.4">This is particularly relevant in cloud native environments, where the dynamic nature of workloads and users necessitates constant verification at every </span><span class="No-Break"><span class="koboSpan" id="kobo.668.1">access point.</span></span></p>
<h2 id="_idParaDest-266"><a id="_idTextAnchor266"/><span class="koboSpan" id="kobo.669.1">Zero Trust in cloud native versus on-premises environments</span></h2>
<p><span class="koboSpan" id="kobo.670.1">In traditional, on-premises setups, applications</span><a id="_idIndexMarker1038"/><span class="koboSpan" id="kobo.671.1"> typically relied on network segmentation and firewalls to define security zones, sometimes called DMZs. </span><span class="koboSpan" id="kobo.671.2">If an application or user was inside the corporate network, they were often granted broad access to resources with little scrutiny. </span><span class="koboSpan" id="kobo.671.3">This approach, known</span><a id="_idIndexMarker1039"/><span class="koboSpan" id="kobo.672.1"> as </span><strong class="bold"><span class="koboSpan" id="kobo.673.1">implicit trust</span></strong><span class="koboSpan" id="kobo.674.1">, leaves significant room for error. </span><span class="koboSpan" id="kobo.674.2">Once an attacker gains access to the network, they can move laterally between systems without facing substantial barriers. </span><span class="koboSpan" id="kobo.674.3">On-premises security models have often prioritized keeping threats out rather than scrutinizing every </span><span class="No-Break"><span class="koboSpan" id="kobo.675.1">internal interaction.</span></span></p>
<p><span class="koboSpan" id="kobo.676.1">In contrast, cloud native environments treat every component as an untrusted entity, whether it’s an internal microservice, user, or external client. </span><span class="koboSpan" id="kobo.676.2">For cloud native applications, the Zero Trust model aligns more naturally with the distributed nature of cloud services, where there are no well-defined internal and external perimeters. </span><span class="koboSpan" id="kobo.676.3">Applications must verify every request, whether it’s between internal microservices, API calls, or </span><span class="No-Break"><span class="koboSpan" id="kobo.677.1">user access.</span></span></p>
<p><span class="koboSpan" id="kobo.678.1">Consider AWS and its implementation of the principle of least privilege. </span><span class="koboSpan" id="kobo.678.2">At its core, this principle aligns with Zero Trust by ensuring that users and services are granted only the permissions they need to perform their tasks and nothing more. </span><span class="koboSpan" id="kobo.678.3">This means leveraging services such as </span><a id="_idIndexMarker1040"/><span class="koboSpan" id="kobo.679.1">AWS </span><strong class="bold"><span class="koboSpan" id="kobo.680.1">Identity and Access Management</span></strong><span class="koboSpan" id="kobo.681.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.682.1">IAM</span></strong><span class="koboSpan" id="kobo.683.1">), where tightly scoped policies control every action. </span><span class="koboSpan" id="kobo.683.2">No service or user is inherently trusted within a single account or VPC. </span><span class="koboSpan" id="kobo.683.3">Each action must be authenticated and authorized, minimizing the risk of privilege escalation </span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">or misuse.</span></span></p>
<p><span class="koboSpan" id="kobo.685.1">In Azure, Conditional Access </span><a id="_idIndexMarker1041"/><span class="koboSpan" id="kobo.686.1">policies and </span><strong class="bold"><span class="koboSpan" id="kobo.687.1">Azure Active Directory</span></strong><span class="koboSpan" id="kobo.688.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.689.1">AAD</span></strong><span class="koboSpan" id="kobo.690.1">) take on a similar role, verifying each access request based on dynamic conditions, such as user location, device health, and behavioral analytics. </span><span class="koboSpan" id="kobo.690.2">Access is granted only when these factors align with predefined security policies. </span><span class="koboSpan" id="kobo.690.3">Meanwhile, Azure VNet </span><a id="_idIndexMarker1042"/><span class="koboSpan" id="kobo.691.1">and </span><strong class="bold"><span class="koboSpan" id="kobo.692.1">network security groups</span></strong><span class="koboSpan" id="kobo.693.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.694.1">NSGs</span></strong><span class="koboSpan" id="kobo.695.1">) enable granular segmentation of traffic, ensuring that applications and services are isolated and access is controlled based on tightly defined </span><span class="No-Break"><span class="koboSpan" id="kobo.696.1">security rules.</span></span></p>
<p><span class="koboSpan" id="kobo.697.1">In GCP, the </span><a id="_idIndexMarker1043"/><span class="koboSpan" id="kobo.698.1">BeyondCorp model operationalizes Zero Trust by completely removing implicit trust from the equation. </span><span class="koboSpan" id="kobo.698.2">Google Cloud’s </span><strong class="bold"><span class="koboSpan" id="kobo.699.1">Identity-Aware Proxy</span></strong><span class="koboSpan" id="kobo.700.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.701.1">IAP</span></strong><span class="koboSpan" id="kobo.702.1">) ensures that each request to </span><a id="_idIndexMarker1044"/><span class="koboSpan" id="kobo.703.1">an application is authenticated, authorized, and encrypted based on user and device identity. </span><span class="koboSpan" id="kobo.703.2">No traffic is assumed trustworthy simply because it </span><a id="_idIndexMarker1045"/><span class="koboSpan" id="kobo.704.1">originates from a particular part of </span><span class="No-Break"><span class="koboSpan" id="kobo.705.1">the network.</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table005-2">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.706.1">Principle</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.707.1">Description</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.708.1">Cloud native </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.709.1">Application Example</span></strong></span></p>
</td>
</tr>
</thead>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.710.1">Never trust, </span><span class="No-Break"><span class="koboSpan" id="kobo.711.1">always verify</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.712.1">Every request must be authenticated, authorized, and encrypted, regardless of origin. </span><span class="koboSpan" id="kobo.712.2">No part of the network is trusted by default, and access is </span><span class="No-Break"><span class="koboSpan" id="kobo.713.1">continuously verified.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.714.1">Validating API requests, user logins, and inter-service communication using AWS IAM policies and AWS Secrets Manager for </span><span class="No-Break"><span class="koboSpan" id="kobo.715.1">secure communication</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.716.1">Least privilege</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.717.1">Enforces minimal access, granting users and services only the permissions needed to perform their tasks, and nothing more. </span><span class="koboSpan" id="kobo.717.2">This limits the potential damage from a compromised account </span><span class="No-Break"><span class="koboSpan" id="kobo.718.1">or service.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.719.1">Azure </span><strong class="bold"><span class="koboSpan" id="kobo.720.1">Role-Based Access </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.721.1">Control</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.722.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.723.1">RBAC</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.724.1">)</span></span></p>
<p><span class="koboSpan" id="kobo.725.1">ensures least privilege access for cloud native applications, keeping internal </span><span class="No-Break"><span class="koboSpan" id="kobo.726.1">systems isolated</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.727.1">Microsegmentation</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.728.1">It breaks down networks into secure segments to limit </span><a id="_idIndexMarker1046"/><span class="koboSpan" id="kobo.729.1">lateral movement. </span><span class="koboSpan" id="kobo.729.2">In cloud native environments, this is achieved with virtual network constructs, which isolate workloads </span><span class="No-Break"><span class="koboSpan" id="kobo.730.1">by default.</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.731.1">AWS VPCs, Azure VNets, and Google Cloud VPCs isolate resources, while security groups and NSGs control </span><span class="No-Break"><span class="koboSpan" id="kobo.732.1">authorized traffic</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.733.1">Continuous monitoring and </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">auditing</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.735.1">Monitors and audits all interactions within the environment in real time to detect anomalies, respond </span><span class="No-Break"><span class="koboSpan" id="kobo.736.1">to threats</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.737.1">AWS CloudTrail, Azure Monitor, and Google Cloud Operations Suite provide real-time insights into </span><span class="No-Break"><span class="koboSpan" id="kobo.738.1">access patterns</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.739.1">Table 9.5 - Key principles of Zero Trust</span></p>
<h2 id="_idParaDest-267"><a id="_idTextAnchor267"/><span class="koboSpan" id="kobo.740.1">Zero Trust in practice – a cloud native example</span></h2>
<p><span class="koboSpan" id="kobo.741.1">During a</span><a id="_idIndexMarker1047"/><span class="koboSpan" id="kobo.742.1"> consulting engagement with a financial services company, we were tasked with implementing a Zero Trust architecture for a cloud native microservice-based application deployed across multiple AWS AZs. </span><span class="koboSpan" id="kobo.742.2">Each microservice was deployed as an AWS Lambda function, with API Gateway serving as the communication layer between services. </span><span class="koboSpan" id="kobo.742.3">To ensure robust security, we implemented IAM-based authorization for each service call using AWS Signature Version 4 signing, which adds authentication details to HTTP requests. </span><span class="koboSpan" id="kobo.742.4">This method ensured that access to each API was tightly controlled, limiting communication strictly to authorized </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">IAM roles.</span></span></p>
<p><span class="koboSpan" id="kobo.744.1">We leveraged Amazon Cognito to enforce identity verification for user access, applying fine-grained permissions to regulate access to specific data and application functions. </span><span class="koboSpan" id="kobo.744.2">Additionally, network traffic between the production and staging environments was isolated using separate VPCs, preventing direct communication without explicit authorization. </span><span class="koboSpan" id="kobo.744.3">Real-time monitoring through CloudWatch Logs and VPC Flow Logs allowed us to track network activity and quickly flag any unauthorized access attempts. </span><span class="koboSpan" id="kobo.744.4">Finally, to ensure microsegmentation, we used PrivateLink and VPC gateway endpoints for client access. </span><span class="koboSpan" id="kobo.744.5">This</span><a id="_idIndexMarker1048"/><span class="koboSpan" id="kobo.745.1"> comprehensive approach ensured that all interactions within the system were authenticated, authorized, and monitored, adhering to the Zero Trust principles that are critical in cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.746.1">native architectures.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer069">
<span class="koboSpan" id="kobo.747.1"><img alt="" role="presentation" src="image/B22364_09_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.748.1">Figure 9.9 - Example of Zero Trust application in AWS</span></p>
<p><span class="koboSpan" id="kobo.749.1">In this Zero Trust framework, the application is not only secure but also adaptable and able to scale or deploy new services without compromising its security posture. </span><span class="koboSpan" id="kobo.749.2">This approach contrasts sharply with on-premises models, where trust is often assumed within the network, creating vulnerabilities once an attacker breaches </span><span class="No-Break"><span class="koboSpan" id="kobo.750.1">the perimeter.</span></span></p>
<p><span class="koboSpan" id="kobo.751.1">As cloud native architectures grow in complexity and scale, adopting a Zero Trust application pattern is no longer optional, it’s a necessity. </span><span class="koboSpan" id="kobo.751.2">By ensuring that no user, service, or device is trusted by default and that every interaction is authenticated and authorized, organizations can safeguard their cloud infrastructure against evolving threats. </span><span class="koboSpan" id="kobo.751.3">The Zero Trust model, supported by cloud native tools across AWS, Azure, and GCP, helps protect the distributed and dynamic nature of modern applications, ensuring security without compromising the agility and innovation that the cloud offers. </span><span class="koboSpan" id="kobo.751.4">The next section goes beyond Zero Trust and looks at balancing the trade-offs within </span><span class="No-Break"><span class="koboSpan" id="kobo.752.1">cloud native.</span></span></p>
<h2 id="_idParaDest-268"><a id="_idTextAnchor268"/><span class="koboSpan" id="kobo.753.1">Network defense in depth versus flat networks – balancing security and operability</span></h2>
<p><span class="koboSpan" id="kobo.754.1">The debate </span><a id="_idIndexMarker1049"/><span class="koboSpan" id="kobo.755.1">between network defense in depth and flat networks is critical. </span><span class="koboSpan" id="kobo.755.2">When trade-offs are not adequately weighed, they often reveal an anti-pattern in architectural design. </span><span class="koboSpan" id="kobo.755.3">On the one hand, defense in depth (a layered approach to security) prioritizes protecting resources at multiple levels, from firewalls and network segmentation to access controls and encryption. </span><span class="koboSpan" id="kobo.755.4">On the other hand, flat networks, which offer minimal segmentation and simpler connectivity, can enhance operability by reducing complexity and streamlining communication </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">between services.</span></span></p>
<p><span class="koboSpan" id="kobo.757.1">Defense in depth is a tried-and-true security model that applies multiple layers of protection to cloud native environments. </span><span class="koboSpan" id="kobo.757.2">By segmenting workloads across VPCs in AWS, Azure </span><strong class="bold"><span class="koboSpan" id="kobo.758.1">virtual networks</span></strong><span class="koboSpan" id="kobo.759.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.760.1">VNets</span></strong><span class="koboSpan" id="kobo.761.1">), or</span><a id="_idIndexMarker1050"/><span class="koboSpan" id="kobo.762.1"> Google Cloud VPCs, services are logically separated and protected by strict security groups, firewalls, and access control policies. </span><span class="koboSpan" id="kobo.762.2">This model ensures that even if an attacker breaches one layer, additional barriers, such as Azure NSGs, Google Cloud firewall rules, or AWS security groups, can prevent lateral movement and further compromise. </span><span class="koboSpan" id="kobo.762.3">While this layered approach strengthens security, it also increases operational overhead. </span><span class="koboSpan" id="kobo.762.4">However, the trade-off comes in the form of increased complexity. </span><span class="koboSpan" id="kobo.762.5">More segmentation means more configuration, potential points of failure, and a more significant operational overhead when managing policies across </span><span class="No-Break"><span class="koboSpan" id="kobo.763.1">various layers.</span></span></p>
<p><span class="koboSpan" id="kobo.764.1">Conversely, flat networks, which provide minimal segmentation between services, simplify the operational burden. </span><span class="koboSpan" id="kobo.764.2">In a flat network, communication is less restricted, making deploying and scaling services easier. </span><span class="koboSpan" id="kobo.764.3">The ease of connectivity reduces friction during development and deployment cycles, as developers do not need to navigate a web of security layers and access rules. </span><span class="koboSpan" id="kobo.764.4">However, while flat networks may enhance speed and flexibility, they sacrifice security. </span><span class="koboSpan" id="kobo.764.5">With fewer barriers between services, an attacker who gains access to any part of the network may move laterally with minimal resistance, potentially compromising the </span><span class="No-Break"><span class="koboSpan" id="kobo.765.1">entire system.</span></span></p>
<p><span class="koboSpan" id="kobo.766.1">The key to choosing between network defense in depth and flat networks lies in evaluating the organization’s specific needs and the criticality of the data and services being managed. </span><span class="koboSpan" id="kobo.766.2">Security versus operability is not a binary decision but a balancing act. </span><span class="koboSpan" id="kobo.766.3">Critical applications may benefit from more stringent security measures in some cases, while less sensitive services may tolerate flatter, more operationally </span><span class="No-Break"><span class="koboSpan" id="kobo.767.1">efficient architectures.</span></span></p>
<p><span class="koboSpan" id="kobo.768.1">For example, when</span><a id="_idIndexMarker1051"/><span class="koboSpan" id="kobo.769.1"> we were tasked with building microservices across an EKS cluster in a cloud native environment handling financial transactions, defense in depth was likely the best approach, ensuring that each microservice handling sensitive data was tightly secured and isolated. </span><span class="koboSpan" id="kobo.769.2">Beyond just the regular AWS tooling, to ensure each call was secure, we implemented a service mesh for Mutual TLS and Open Policy Agent to refine-grained access policies. </span><span class="koboSpan" id="kobo.769.3">Again, the trade-offs between security and operability must always be considered, with the understanding that flexibility in cloud native environments should never come at the expense of security where it truly matters. </span><span class="koboSpan" id="kobo.769.4">As any company that handles financial transactions needs to comply with PCI-DSS and other compliance standards, we ensured that, at all layers of the implementation, best practices have </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">been applied.</span></span></p>
<h1 id="_idParaDest-269"><a id="_idTextAnchor269"/><span class="koboSpan" id="kobo.771.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.772.1">Ignoring fundamental aspects such as latency and bandwidth can lead to significant performance bottlenecks, while a lack of a DNS strategy introduces operational inefficiencies and inconsistency in service discovery. </span><span class="koboSpan" id="kobo.772.2">Relying on monolithic connectivity creates a fragile network structure that is difficult to scale and secure, whereas ignoring cloud native networking features overlooks the built-in capabilities designed to optimize and secure modern infrastructures. </span><span class="koboSpan" id="kobo.772.3">Finally, failing to adopt Zero Trust application patterns leaves cloud environments vulnerable, as traditional perimeter-based security is insufficient for the dynamic, distributed nature of cloud native systems. </span><span class="koboSpan" id="kobo.772.4">To build resilient, scalable, and secure cloud native applications, it is essential to address these anti-patterns head-on, ensuring that network architectures are designed with the unique demands of the cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.773.1">in mind.</span></span></p>
<p><span class="koboSpan" id="kobo.774.1">The next chapter will go over how to approach observability within the cloud </span><span class="No-Break"><span class="koboSpan" id="kobo.775.1">native space.</span></span></p>
</div>
</body></html>