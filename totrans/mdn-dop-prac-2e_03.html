<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer037">
			<h1 id="_idParaDest-72" class="chapter-number"><a id="_idTextAnchor220"/>3</h1>
			<h1 id="_idParaDest-73"><a id="_idTextAnchor221"/>Containerization with Docker</h1>
			<p>In the previous chapter, we talked about source code management with Git, where we took a crash course on Git and then discussed GitOps and how it shapes modern <span class="No-Break">DevOps practices.</span></p>
			<p>In this chapter, we’ll get hands-on and explore <strong class="bold">Docker</strong> – the de facto container runtime. By the end of this chapter, you should<a id="_idIndexMarker250"/> be able to install and configure Docker, run your first container, and then monitor it. This chapter will also form the basis for the following chapters, as we will use the same setup for the <span class="No-Break">demos later.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li><span class="No-Break">Installing tools</span></li>
				<li><span class="No-Break">Installing Docker</span></li>
				<li>Introducing Docker storage drivers <span class="No-Break">and volumes</span></li>
				<li>Running your <span class="No-Break">first container</span></li>
				<li>Docker logging and <span class="No-Break">logging drivers</span></li>
				<li>Docker monitoring <span class="No-Break">with Prometheus</span></li>
				<li>Declarative container management with <span class="No-Break">Docker Compose</span><a id="_idTextAnchor222"/><a id="_idTextAnchor223"/></li>
			</ul>
			<h1 id="_idParaDest-74"><a id="_idTextAnchor224"/>Technical requirements</h1>
			<p>For this chapter, you will need a Linux machine running Ubuntu 18.04 Bionic LTS or later with sudo access. We will be using Ubuntu 22.04 Jammy Jellyfish for the entirety of this book, but feel free to use any OS of your choice. I will post links to alternative <span class="No-Break">installation instructions.</span></p>
			<p>You will also need to clone the following GitHub repository for some of the <span class="No-Break">exercises: </span><a href="https://github.com/PacktPublishing/Modern-DevOps-Practices-2e"><span class="No-Break">https://github.com/PacktPublishing/Modern-DevOps-Practices-2e</span></a><span class="No-Break">.</span><a id="_idTextAnchor225"/></p>
			<p>We discussed Git extensively in the previous chapter; therefore, you can easily clone the repository using that knowledge. Now, let’s move on to installing Docker on <span class="No-Break">your machine.</span><a id="_idTextAnchor226"/><a id="_idTextAnchor227"/></p>
			<h1 id="_idParaDest-75"><a id="_idTextAnchor228"/>Installing Docker</h1>
			<p>We will be installing <a id="_idIndexMarker251"/>Docker in an Ubuntu system. For other OSs, please refer <span class="No-Break">to </span><a href="https://docs.docker.com/engine/install/"><span class="No-Break">https://docs.docker.com/engine/install/</span></a><span class="No-Break">.</span></p>
			<p>To install Docker, we need to install supporting tools to allow the <strong class="source-inline">apt</strong> package manager to download Docker through HTTPS. Let’s do so using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ sudo apt-get update
$ sudo apt-get install -y ca-certificates curl gnupg</pre>			<p>Download the Docker gpg key and add it to the apt <span class="No-Break">package manager:</span></p>
			<pre class="console">
$ sudo install -m 0755 -d /etc/apt/keyrings
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
$ sudo chmod a+r /etc/apt/keyrings/docker.gpg</pre>			<p>Then, you need to add the Docker repository to your <strong class="source-inline">apt</strong> configuration so that you can download packages <span class="No-Break">from there:</span></p>
			<pre class="console">
$ echo \
  "deb [arch="$(dpkg --print-architecture)" \
signed-by=/etc/apt/keyrings/docker.gpg] \
https://download.docker.com/linux/ubuntu \
"$(. /etc/os-release &amp;&amp; echo "$VERSION_CODENAME")" \
stable" | sudo tee /etc/apt/sources.list.d/docker.list \
&gt; /dev/null</pre>			<p>Finally, install the Docker engine by using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ sudo apt-get update
$ sudo apt-get -y install docker-ce docker-ce-cli \
containerd.io docker-buildx-plugin docker-compose-plugin</pre>			<p>To verify whether Docker has been installe<a id="_idTextAnchor229"/>d successfully, run <span class="No-Break">the following:</span></p>
			<pre class="console">
$ sudo docker --version</pre>			<p>You should expect a similar output to <span class="No-Break">the following:</span></p>
			<pre class="console">
Docker version 24.0.2, build cb74dfc</pre>			<p>The next thing you should do is allow regular users to use Docker. You want your users to act as something other than root for building and running containers. To do that, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ sudo usermod -a -G docker &lt;username&gt;</pre>			<p>To apply the changes to your profile, log out from your virtual machine and log <span class="No-Break">back in.</span></p>
			<p>Now that<a id="_idIndexMarker252"/> Docker has been fully set up on your machine, let’s run a <strong class="source-inline">hello-world</strong> container to see this <span class="No-Break">for ourselves:</span></p>
			<pre class="console">
$ docker run hello-world</pre>			<p>You should see the <span class="No-Break">following output:</span></p>
			<pre class="console">
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
719385e32844: Pull complete
Digest: sha256:fc6cf906cbfa013e80938cdf0bb199fbdbb86d6e3e013783e5a766f50f5dbce0
Status: Downloaded newer image for hello-world:latest
Hello from Docker!</pre>			<p>You will also receive the following message, which tells you what happened behind t<a id="_idTextAnchor230"/>he scenes to print the <strong class="source-inline">Hello from Docker!</strong> message on <span class="No-Break">your screen:</span></p>
			<pre class="console">
This message shows that your installation appears to be working correctly.
To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the hello-world image from Docker Hub.(amd64).
 3. The Docker daemon created a new container from that image that runs the executable 
that produces the output you are currently reading.
4. The Docker daemon streamed that output to the Docker client, which sent it to your 
Terminal:
To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash
Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/
For more examples and ideas, visit:
 https://docs.docker.com/get-started/</pre>			<p>All this <a id="_idIndexMarker253"/>helpful information is self-explanatory. To explain Docker Hub a bit, it is a public Docker container registry that hosts many Docker images for people like you and me <span class="No-Break">to consume.</span></p>
			<p>As Docker works on a layered architecture, most Docker images are derived from one or more base images hosted on Docker Hub. So, please create a Docker Hub account for yourself to host your containers and share them with the rest of <span class="No-Break">the world.</span></p>
			<p>Most organizations might want to keep their images private, so you have the option of creating private repositories within Docker Hub. You can also host your own internal Docker registry using a <a id="_idTextAnchor231"/>SaaS service such <a id="_idIndexMarker254"/>as <strong class="bold">Google Container Registry</strong> (<strong class="bold">GCR</strong>), or installing an <a id="_idIndexMarker255"/>artifact repository<a id="_idIndexMarker256"/> such as <strong class="bold">Sonatype Nexus</strong> or <strong class="bold">JFrog Artifactory</strong>. Whatev<a id="_idTextAnchor232"/>er your choice of tool, the mechanism and how it works<a id="_idTextAnchor233"/> always remain <span class="No-Break">the<a id="_idTextAnchor234"/><a id="_idTextAnchor235"/> same.</span></p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor236"/>Introducing Docker storage drivers and volumes</h1>
			<p>Docker containe<a id="_idTextAnchor237"/>rs<a id="_idIndexMarker257"/> are ephemeral workloads. Whatever data you store on your container filesystem gets wiped out once the container is gone. The data lives on a disk during the container’s life cycle but does not persist beyond it. Pragmatically speaking, most applications in the real world are stateful. They need to store data beyond the container life cycle and want it <span class="No-Break">to persist.</span></p>
			<p>So, how do we go along with that? Docker provides several ways you can store data. By default, all data is stored on the writable container layer, which is ephemeral. The writable container layer interacts with the host filesystem via a storage driver. Because of the abstraction, writing files to the container layer is slower than writing directly to the <span class="No-Break">host filesystem.</span></p>
			<p>To solve that problem and also provide persistent storage, Docker provides volumes, bind mounts, and <strong class="source-inline">tmpfs</strong>. With them, you can interact directly with the host filesystem (and memory in the case of <strong class="source-inline">tmpfs</strong>) and save a<a id="_idIndexMarker258"/> ton of <strong class="bold">I/O operations per second</strong> (<strong class="bold">IOPS</strong>), improving performance. While this section focuses on storage drivers that cater to the container filesystem, it is worth discussing multiple data storage options within Docker to provide <span class="No-Break">a bac<a id="_idTextAnchor238"/><a id="_idTextAnchor239"/>kground.</span></p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor240"/>Docker data storage options</h2>
			<p>Every option<a id="_idIndexMarker259"/> has a use case and trade-off. Let’s look at each option and where you should <span class="No-Break">use which.</span></p>
			<h3>Volumes</h3>
			<p>Docker vol<a id="_idTextAnchor241"/>umes <a id="_idIndexMarker260"/>store the data directly in the host’s filesystem. They <a id="_idIndexMarker261"/>do not use the storage driver layer in between, so writing to volumes is faster. They are the best way to persist data. Docker stores volumes in <strong class="source-inline">/var/lib/docker/volumes</strong> and assumes that no one apart from the Docker daemon can modify the data <span class="No-Break">on them.</span></p>
			<p>As a result, volumes provide the <span class="No-Break">following features:</span></p>
			<ul>
				<li>Provide<a id="_idIndexMarker262"/> some isolation with the host <a id="_idIndexMarker263"/>filesystems. If you don’t want other processes to interact with the data, then a volume should be <span class="No-Break">your choice.</span></li>
				<li>You can share a volume with <span class="No-Break">multiple containers.</span></li>
				<li>Volumes can either be named or anonymous. Docker stores anonymous volumes in a directory with a unique <span class="No-Break">random name.</span></li>
				<li>Volumes enable you to store data remotely or in a cloud provider using volume drivers. This helps a lot if multiple containers share the same volume to provide a multi-instance <span class="No-Break">active-active configuration.</span></li>
				<li>The data in the<a id="_idIndexMarker264"/> volume persists even when the <a id="_idIndexMarker265"/>containers <span class="No-Break">are deleted.</span></li>
			</ul>
			<p>Now, let’s look at another storage option – <span class="No-Break">bind mounts.</span></p>
			<h3>Bind mounts</h3>
			<p><a id="_idTextAnchor242"/>Bind mounts<a id="_idIndexMarker266"/> are very similar to volumes but with a significant difference: they allow you to<a id="_idIndexMarker267"/> mount an existing host directory as a filesystem on the container. This lets you share important files with the Docker container, such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">/etc/resolv.conf</strong></span><span class="No-Break">.</span></p>
			<p>Bind mounts also allow multiple processes to modify data along with Docker. So, if you are sharing your container data with another application that is not running in Docker, bind mounts are the way <span class="No-Break">to go.</span></p>
			<h3>tmpfs mounts</h3>
			<p><strong class="source-inline"><a id="_idTextAnchor243"/>tmpfs</strong> mounts <a id="_idIndexMarker268"/>store data in memory. They do not store any data on disk – neither the <a id="_idIndexMarker269"/>container nor the host filesystem. You can use them to store sensitive information and the non-persistent state during the lifetime<a id="_idTextAnchor244"/><a id="_idTextAnchor245"/> of <span class="No-Break">your container.</span></p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor246"/>Mounting volumes</h2>
			<p>If you mount a<a id="_idIndexMarker270"/> host directory that already contains files to an empty volume of the container, the container can see the files stored in the host. This is an excellent way to pre-populate files for your container(s) to use. However, if the directory does not exist in the host filesystem, Docker will create the directory automatically. If the volume is non-empty and the host filesystem already contains files, Docker will obscure the mount. This means that while you won’t see the original files while the Docker volume is mounted to it, the files are not deleted, and you can recover them by unmounting the <span class="No-Break">Docker volume.</span></p>
			<p>We’ll look at Docker storage drivers <a id="_idTextAnchor247"/><a id="_idTextAnchor248"/>in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor249"/>Docker storage drivers</h2>
			<p>There are numerous <a id="_idIndexMarker271"/>storage <a id="_idTextAnchor250"/>driver types. Some of the most popular ones are <span class="No-Break">as follow<a id="_idTextAnchor251"/>s:</span></p>
			<ul>
				<li><strong class="source-inline">overlay2</strong>: This is a <a id="_idIndexMarker272"/>production-ready driver and is the preferred<a id="_idIndexMarker273"/> storage choice for Docker. It works in <span class="No-Break">most environments.</span></li>
				<li><strong class="source-inline">devicemapper</strong>: This was <a id="_idIndexMarker274"/>the preferred driver for devices<a id="_idIndexMarker275"/> running RHEL and CentOS 7 and below that did not support <strong class="source-inline">overlay2</strong>. You can use this driver if you have write-intensive activities in <span class="No-Break">your containers.</span></li>
				<li><strong class="source-inline">btrfs</strong> and <strong class="source-inline">zfs</strong>: These <a id="_idIndexMarker276"/>drivers are write-intensive and provide<a id="_idIndexMarker277"/> many features, such as allowing snapshots, and <a id="_idIndexMarker278"/>can only be used if you are using <strong class="source-inline">btrfs</strong> or <strong class="source-inline">zfs</strong> filesystems within<a id="_idTextAnchor252"/> <a id="_idIndexMarker279"/><span class="No-Break">your host.</span></li>
				<li><strong class="source-inline">vfs</strong>: This <a id="_idIndexMarker280"/>storage driver should be used only if no copy-on-write <a id="_idIndexMarker281"/>filesystem is available. It is extremely slow, and you should refrain from using it <span class="No-Break">in production.</span></li>
			</ul>
			<p>Let’s concentrate on two of the most popular ones – <strong class="source-inline">overlay2</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">devicemapper</strong></span><span class="No-Break">.</span></p>
			<h3>over<a id="_idTextAnchor253"/>lay2</h3>
			<p><strong class="source-inline">overlay2</strong> is the <a id="_idIndexMarker282"/>default and<a id="_idIndexMarker283"/> recommended storage driver in most operating systems except RHEL 7 and CentOS 7 and older. They use file-based storage and perform best when subject to more reads <span class="No-Break">than writes.</span></p>
			<h3>device<a id="_idTextAnchor254"/>mapper</h3>
			<p><strong class="source-inline">devicemapper</strong> is <a id="_idIndexMarker284"/>block-based <a id="_idIndexMarker285"/>storage and performs the best when subject to more writes than reads. Though it is compatible and the default with CentOS 7, RHEL 7, and below, as they don’t support <strong class="source-inline">overlay2</strong>, it is currently not recommended in the newer versions of these operating systems that do <span class="No-Break">support </span><span class="No-Break"><strong class="source-inline">overlay2</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Use <strong class="source-inline">overlay2</strong> where possible, but if you have a specific use case for not using it (such as too many write-intensive containers<a id="_idTextAnchor255"/><a id="_idTextAnchor256"/>), <strong class="source-inline">devicemapper</strong> is a <span class="No-Break">better choice.</span></p>
			<h2 id="_idParaDest-80">C<a id="_idTextAnchor257"/>onfiguring a storage driver</h2>
			<p>For this discussion, we will <a id="_idIndexMarker286"/>configure <strong class="source-inline">overlay2</strong> as the storage driver. Although it is configured by default, and you can skip the steps if you are following this <a id="_idIndexMarker287"/>book, it is worth a read in case you want to change it to <span class="No-Break">something else.</span></p>
			<p>First, let’s list the existing <span class="No-Break">storage driver:</span></p>
			<pre class="console">
$ docker info | grep 'Storage Driver'
Storage Driver: overlay2</pre>			<p>We can see that the existing storage driver is already <strong class="source-inline">overlay2</strong>. Let’s learn how to change it to <strong class="source-inline">devicemapper</strong> if we <span class="No-Break">had to.</span></p>
			<p>Edit the <strong class="source-inline">/etc/docker/daemon.json</strong> file using an editor of your choice. If you’re using <strong class="source-inline">vim</strong>, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ sudo vim /etc/docker/daemon.json</pre>			<p>Add the <strong class="source-inline">storage-driver</strong> entry to the <strong class="source-inline">daemon.json</strong> <span class="No-Break">configuration file:</span></p>
			<pre class="console">
{
  "storage-driver": "devicemapper"
}</pre>			<p>Then, restart the <span class="No-Break">Docker service:</span></p>
			<pre class="console">
$ sudo systemctl r<a id="_idTextAnchor258"/>estart docker</pre>			<p>Check the status of the <span class="No-Break">Docker service:</span></p>
			<pre class="console">
$ sudo systemctl status docker</pre>			<p>Now, rerun <strong class="source-inline">docker info</strong> to<a id="_idIndexMarker288"/> see <a id="_idIndexMarker289"/>what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker info | grep 'Storage Driver'
Storage Driver: devicemapper
WARNING: The devicemapper storage-driver is deprecated, and will be removed in a future 
release.
         Refer to the documentation for more information: https://docs.docker.com/go/
storage-driver/
WARNING: devicemapper: usage of loopback devices is strongly discouraged for production 
use.
         Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.</pre>			<p>Here, we can see the <strong class="source-inline">devicemapper</strong> storage driver. We can also see several warnings with it that say that the <strong class="source-inline">devicemapper</strong> storage driver is deprecated and will be removed in a <span class="No-Break">future version.</span></p>
			<p>Therefore, we should stick with the defaults unless we have a <span class="No-Break">particular requirement.</span></p>
			<p>So, let’s roll back our changes and set the storage driver to <span class="No-Break"><strong class="source-inline">overlay2</strong></span><span class="No-Break"> again:</span></p>
			<pre class="console">
$ sudo vim /etc/docker/daemon.json</pre>			<p>Modify the <strong class="source-inline">storage-driver</strong> entry in the <strong class="source-inline">daemon.json</strong> configuration file <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">overlay2</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
{
  "storage-driver": "overlay2"
}</pre>			<p>Then, restart the Docker service and check <span class="No-Break">its status:</span></p>
			<pre class="console">
$ sudo systemctl restart docker
$ sudo systemctl status do<a id="_idTextAnchor259"/>cker</pre>			<p>If you<a id="_idIndexMarker290"/> rerun <strong class="source-inline">docker info</strong>, you will see the storage driver as <strong class="source-inline">overlay2</strong>, and all the <a id="_idIndexMarker291"/>warnings <span class="No-Break">will disappear:</span></p>
			<pre class="console">
$ docker info | grep 'Storage Driver'
Storage Driver: overlay2</pre>			<p class="callout-heading">Tip</p>
			<p class="callout">Changing the storage driver will wipe out existing containers from the disk, so exercise caution when you do so and take appropriate downtimes if you’re doing this in production. You will also need to pull images again since local images will fail <span class="No-Break">to exist.</span></p>
			<p>Now that we have installed Docker on our machine and configured the right storage driv<a id="_idTextAnchor260"/><a id="_idTextAnchor261"/>er, it’s time to run our <span class="No-Break">first container.</span></p>
			<h1 id="_idParaDest-81">Running <a id="_idTextAnchor262"/>your first container</h1>
			<p>You can create Docker <a id="_idIndexMarker292"/>containers out of Docker container images. While we will discuss container images and their architecture in the following chapters, an excellent way to visualize them is as a copy of all files, application libraries, and dependencies comprising your application environment, similar to a virtual <span class="No-Break">machine image.</span></p>
			<p>To run a Docker container, we can use<a id="_idIndexMarker293"/> the <strong class="source-inline">docker run</strong> command, which has the <span class="No-Break">following structure:</span></p>
			<pre class="console">
$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]</pre>			<p>Let’s look at the <strong class="source-inline">docker run</strong> command <a id="_idIndexMarker294"/>and its variations using <span class="No-Break">working examples.</span></p>
			<p>In its simplest form, you can<a id="_idIndexMarker295"/> use <strong class="source-inline">docker run</strong> by simply typing <span class="No-Break">the following:</span></p>
			<pre class="console">
$ docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
0e03bdcc26d7: Pull complete
Digest: sha256:e7c70bb24b462baa86c102610182e3efcb12a04854e8c582
838d92970a09f323
Status: Downloaded newer image for hello-world:latest<a id="_idTextAnchor263"/>
Hello from Docker!
...</pre>			<p>As you may recall, we used this command when we installed Docker. Here, I have purposefully omitted <strong class="source-inline">tag</strong>, <strong class="source-inline">options</strong>, <strong class="source-inline">command</strong>, and <strong class="source-inline">arguments</strong>. We will cover it with multiple examples to show its actual <span class="No-Break">use cases.</span></p>
			<p>As we didn’t supply <strong class="source-inline">tag</strong>, Docker automatically assumed the <strong class="source-inline">tag</strong> as <strong class="source-inline">latest</strong>, so if you look at the command <a id="_idIndexMarker296"/>output, you will see that Docker is pulling the <strong class="source-inline">hello-world:latest</strong> image from <span class="No-Break">Docker Hub.</span></p>
			<p>Now, let’s l<a id="_idTextAnchor264"/><a id="_idTextAnchor265"/>ook at an example with a specific <span class="No-Break">version tag.</span></p>
			<h2 id="_idParaDest-82">Running containers from vers<a id="_idTextAnchor266"/>ioned images</h2>
			<p>We can <a id="_idIndexMarker297"/>run <strong class="source-inline">nginx:1.18.0</strong> using the <span class="No-Break">following</span><span class="No-Break"><a id="_idIndexMarker298"/></span><span class="No-Break"> command:</span></p>
			<pre class="console">
$ docker run nginx:1.18.0
Unable to find image 'nginx:1.18.0' locally
1.18.0: Pulling from library/nginx
852e50cd189d: Pull complete
48b8657f2521: Pull complete
b4f4d57f1a55: Pull complete
d8fbe49a7d55: Pull complete
04e4a40fabc9: Pull complete
Digest: sha256:2104430ec73de095df553d0c7c2593813e01716a48d66f
85a3dc439e050919b3
Status: Downloaded newer image for nginx:1.18.0
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform
configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-
listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-
envsubst-on-templates.sh
/docker-entrypoint.sh: Configuration complete<a id="_idTextAnchor267"/>; ready for
start up</pre>			<p>Note<a id="_idIndexMarker299"/> that the prompt will be stuck after this. There is a<a id="_idIndexMarker300"/> reason for this: <strong class="source-inline">nginx</strong> is a long-running process, also known as a<a id="_idIndexMarker301"/> daemon. Since NGINX is a web server that needs to listen to HTTP requests continuously, it should never stop. In the case of the <strong class="source-inline">hello-world</strong> application, its<a id="_idIndexMarker302"/> only <a id="_idIndexMarker303"/>job was to print the message and exit. NGINX has a different <span class="No-Break">purpose altogether.</span></p>
			<p>Now, no one would keep a Bash session open for a web server to run, so there has to be some way to run it in the background. You can run <a id="_idTextAnchor268"/>containers in the detached mode for<a id="_idTextAnchor269"/><a id="_idTextAnchor270"/> that. We’ll have a look at this in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor271"/>Running Docker containers in the background</h2>
			<p>To run a Docker container<a id="_idIndexMarker304"/> in the background as a daemon, you can use <strong class="source-inline">docker run</strong> in detached mode using the <strong class="source-inline">-</strong><span class="No-Break"><strong class="source-inline">d</strong></span><span class="No-Break"> flag:</span></p>
			<pre class="console">
$ docker run -d nginx:1.18.0
beb5dfd529c9f001539c555a18e7b76ad5d73b95dc48e8a35aecd7471ea938fc</pre>			<p>As you can see, it just prin<a id="_idTextAnchor272"/><a id="_idTextAnchor273"/>ts a random ID and provides control back to <span class="No-Break">th<a id="_idTextAnchor274"/>e shell.</span></p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor275"/>Troubleshooting containers</h2>
			<p>To see what’s going on within the <a id="_idIndexMarker305"/>container, you can use the <strong class="source-inline">docker logs</strong> command. But before using that, we need to know the container’s ID or name to see the <span class="No-Break">container’s logs.</span></p>
			<p>To get a list of containers running within the host, run the <span class="No-Break">following command</span></p>
			<pre class="console">
$ docker ps
CONTAINER ID  IMAGE         COMMAND        CREATED        STATUS        PORTS   NAMES
beb5dfd529c9  nginx:1.18.0  "/docker-      2 minutes ago  Up 2 minutes  80/tcp  fervent_
                            entrypoint.…"                                       shockley</pre>			<p>The preceding command lists the NGINX container that we just started. Unless you specify a particular name for your container, Docker allocates a random name to it. In this case, it has called it <strong class="source-inline">fervent_shockley</strong>. It also assigns every container a unique container ID, such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">beb5dfd529c9</strong></span><span class="No-Break">.</span></p>
			<p>You can use the <a id="_idIndexMarker306"/>container ID or the container name to interact with the container to list the logs. Let’s use the container ID <span class="No-Break">this time:</span></p>
			<pre class="console">
$ docker logs beb5dfd529c9
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform 
configuration
...
/docker-entrypoint.sh: Configuration complete; ready for start up</pre>			<p>As you can see, it prints a similar log output as it did when we ran it in <span class="No-Break">the foreground.</span></p>
			<p>Practically speaking, you will use <strong class="source-inline">docker logs</strong> 90% of the time unless you need to debug something with BusyBox. Bu<a id="_idTextAnchor276"/>syBox is a lightweight shell container that can help you troubleshoot and debug issues with your container – mostly <span class="No-Break">network issues.</span></p>
			<p>Let’s make BusyBox echo <strong class="source-inline">Hello World!</strong> <span class="No-Break">for us:</span></p>
			<pre class="console">
$ docker run busybox echo 'Hello World!'
Unable to find image 'busybox:latest' locally
latest: Pulling from library/busybox
325d69979d33: Pull complete
Digest: sha256:560af6915bfc8d7630e50e212e08242d37b63bd5c1ccf9bd4acccf116e262d5b
Status: Downloaded newer image for busybox:latest
Hello World!</pre>			<p>As we can see, Docker pulls the latest <strong class="source-inline">busybox</strong> image from Docker Hub and runs the <strong class="source-inline">echo 'Hello </strong><span class="No-Break"><strong class="source-inline">World'</strong></span><span class="No-Break"> command.</span></p>
			<p>You can also use BusyBox in interactive mode by using the <strong class="source-inline">-it</strong> flag, which will help you run a series of commands on the BusyBox shell. It is also a good idea to add an <strong class="source-inline">--rm</strong> flag to it to tell <a id="_idIndexMarker307"/>Docker to clean up the containers once we have exited from the shell, something <span class="No-Break">like this:</span></p>
			<pre class="console">
$ docker run -it --rm busybox /bin/sh
/ # echo 'Hello world!'
Hello world!
/ # wget http://example.com
Connecting to example.com (93.184.216.34:80)
saving to 'index.html'
index.html           100% |***********************************
****|  1256  0:00:00 ETA
'inde<a id="_idTextAnchor277"/>x.html' saved
/ # exit</pre>			<p>Upon listing all the containers, we do not see the <strong class="source-inline">busybox</strong> container <span class="No-Break">in there:</span></p>
			<pre class="console">
$ docker ps -a
CONTAINER ID  IMAGE   COMMAND        CREATED     STATUS    PORTS   NAMES
beb5dfd529c9  nginx:  "/docker-      17 minutes  Up 17     80/tcp  fervent_
              1.18.0  entrypoint.…"  ago         minutes           shockley</pre>			<p>There are various other flags that you can use with your containers, each ser<a id="_idTextAnchor278"/><a id="_idTextAnchor279"/>ving a specific purpose. Let’s look at a few <a id="_idIndexMarker308"/><a id="_idTextAnchor280"/><span class="No-Break">common ones.</span></p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor281"/>Putting it all together</h2>
			<p>The best setting<a id="_idIndexMarker309"/> for a highly available NGINX container should be something like <span class="No-Break">the following</span><span class="No-Break">:</span></p>
			<pre class="console">
$ docker run -d --name nginx --restart unless-stopped \
-p 80:80 --memory 1000M --memory-reservation 250M nginx:1.18.0</pre>			<p>Let’s take a look at this in <span class="No-Break">more detail:</span></p>
			<ul>
				<li><strong class="source-inline">-d</strong>: Run as a daemon in <span class="No-Break">detached mode.</span></li>
				<li><strong class="source-inline">--name nginx</strong>: Give the <span class="No-Break">name </span><span class="No-Break"><strong class="source-inline">nginx</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">--restart unless-stopped</strong>: Always automatically restart on failures unless explicitly stopped manually, and also start automatically on Docker daemon startup. Other options include <strong class="source-inline">no</strong>, <strong class="source-inline">on_failure</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">always</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">-p 80:80</strong>: Forward traffic from host port <strong class="source-inline">80</strong> to container port <strong class="source-inline">80</strong>. This allows you to expose yo<a id="_idTextAnchor282"/>ur container to your <span class="No-Break">host network.</span></li>
				<li><strong class="source-inline">--memory 1000M</strong>: Limit the container memory consumption to <strong class="source-inline">1000M</strong>. If the memory exceeds this limit, the container stops and acts according to the <strong class="source-inline">--</strong><span class="No-Break"><strong class="source-inline">restart</strong></span><span class="No-Break"> flag.</span></li>
				<li><strong class="source-inline">--memory-reservation 250M</strong>: Allocate a soft limit of <strong class="source-inline">250M</strong> memory to the container if the server runs out <span class="No-Break">of memory.</span></li>
			</ul>
			<p>We will look into other flags in the subsequent sections as we get <span class="No-Break">more hands-on.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Consider using <strong class="source-inline">unless-stopped</strong> instead of <strong class="source-inline">always</strong> as it allows you to stop the container manually if you want to do <span class="No-Break">some maintenance.</span></p>
			<p>Now, let’s list the containers and see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker ps -a
CONTAINER ID  IMAGE   COMMAND         CREATED     STATUS   PORTS       NAMES
06fc749371b7  nginx   "/docker-       17 seconds  Up 16    0.0.0.0:    nginx   
                      entrypoint.…"   ago         seconds  80-&gt;80/tcp  
beb5dfd529c9  nginx:  "/docker-       22 minutes  Up 22    80/tcp      fervent_shockley
              1.18.0  entrypoint.…"   ago         minutes</pre>			<p>If you look carefully, you’ll see a container called <strong class="source-inline">nginx</strong> and a port forward from <strong class="source-inline">0.0.0.0:80 -&gt; </strong><span class="No-Break"><strong class="source-inline">80</strong></span><span class="No-Break">.</span></p>
			<p>Now, let’s <strong class="source-inline">curl</strong> on <strong class="source-inline">localhost:80</strong> on the <a id="_idIndexMarker310"/>host to see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ curl localhost:80
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;We<a id="_idTextAnchor283"/>lcome to nginx!&lt;/title&gt;
...
&lt;/html&gt;</pre>			<p>We get the NGINX welcome message. This means NGINX is running successfully, and we can access it from the machine. If you have exposed your machine’s port <strong class="source-inline">80</strong> to the external wor<a id="_idTextAnchor284"/>ld, you can also access this using your browser <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B19877_Figure_3.01.jpg" alt="Figure 3.1 – The NGINX welcome page" width="646" height="270"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – The NGINX welcome page</p>
			<p>You also might want to restart or remove your container occas<a id="_idTextAnchor285"/><a id="_idTextAnchor286"/>ionally. We’ll look at ways to do that in the<a id="_idTextAnchor287"/> <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor288"/>Restarting and removing containers</h2>
			<p>To <a id="_idIndexMarker311"/>restart your containers<a id="_idTextAnchor289"/>, you must stop them first and then <span class="No-Break">start them.</span></p>
			<p>To stop your <a id="_idIndexMarker312"/>container, run <span class="No-Break">the following:</span></p>
			<pre class="console">
$ docker stop nginx</pre>			<p>To start your container, run <span class="No-Break">the following:</span></p>
			<pre class="console">
$ docker start nginx</pre>			<p>If you want to get rid of your container completely, you need to stop your container first and then remove it, using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker stop nginx &amp;&amp; docker rm nginx</pre>			<p>Alternatively, you can use the following command to do it in <span class="No-Break">one go:</span></p>
			<pre class="console">
$ docker rm -f nginx</pre>			<p>Now, let’s look at how we can m<a id="_idTextAnchor290"/><a id="_idTextAnchor291"/>onitor our containers with tools such as <strong class="source-inline">journald</strong> <span class="No-Break">and Splunk.</span></p>
			<h1 id="_idParaDest-87">D<a id="_idTextAnchor292"/>ocker logging and logging drivers</h1>
			<p>Docker not only changed how applications are <a id="_idTextAnchor293"/>deployed but also the workflow for log management. Instead of writing logs to files, containers write logs to the<a id="_idTextAnchor294"/> console (<strong class="source-inline">stdout</strong>/<strong class="source-inline">stderr</strong>). Docker then uses a lo<a id="_idTextAnchor295"/><a id="_idTextAnchor296"/>gging driver<a id="_idIndexMarker313"/> to export container logs to the <span class="No-Break">specified</span><span class="No-Break"> destinations.</span></p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor297"/>Container log management</h2>
			<p>Log management is an essential function <a id="_idIndexMarker314"/>within Docke<a id="_idTextAnchor298"/>r, as with <a id="_idIndexMarker315"/>any application. However, due to the transient nature of Docker workloads, it becomes more critical as we lose the filesystem and potentially logs when the container is deleted or faces any issue. So, we should use log drivers to export the logs into a particular place and store and persist it. If you have a log analytics solution, the best place for your logs to be is within it. Docker suppo<a id="_idTextAnchor299"/><a id="_idTextAnchor300"/>rts multiple log targets via logging drivers<a id="_idTextAnchor301"/>. Let’s have <span class="No-Break">a look.</span></p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor302"/>Logging drivers</h2>
			<p>At the time of writing, the following logging drivers <span class="No-Break">are available:</span></p>
			<ul>
				<li><strong class="source-inline">none</strong>: No logs <a id="_idIndexMarker316"/>are available for the container, and therefore they are not <span class="No-Break">stored anywhere.</span></li>
				<li><strong class="source-inline">local</strong>: Logs are stored locally in a custom format, which <span class="No-Break">minimizes overhead.</span></li>
				<li><strong class="source-inline">json-file</strong>: The log files are stored in JSON format. This is the default Docker <span class="No-Break">logging driver.</span></li>
				<li><strong class="source-inline">syslog</strong>: This driver uses <strong class="source-inline">syslog</strong> for storing the Docker logs as well. This option makes sense when you use <strong class="source-inline">syslog</strong> as your default <span class="No-Break">logging mechanism.</span></li>
				<li><strong class="source-inline">journald</strong>: Uses <strong class="source-inline">journald</strong> to stor<a id="_idTextAnchor303"/>e Docker logs. You can use the <strong class="source-inline">journald</strong> command line to browse the container and the Docker <span class="No-Break">daemon logs.</span></li>
				<li><strong class="source-inline">gelf</strong>: Sends logs to<a id="_idIndexMarker317"/> a <strong class="bold">Graylog Extended Log Format</strong> (<strong class="bold">GELF</strong>) endpoint such as Graylog <span class="No-Break">or Logstash.</span></li>
				<li><strong class="source-inline">fluentd</strong>: Sends logs <span class="No-Break">to Fluentd.</span></li>
				<li><strong class="source-inline">awslogs</strong>: Sends logs to <span class="No-Break">AWS CloudWatch.</span></li>
				<li><strong class="source-inline">splunk</strong>: <a id="_idTextAnchor304"/>Sends logs to Splunk using the HTTP <span class="No-Break">Event Collector.</span></li>
				<li><strong class="source-inline">etwlogs</strong>: Sends logs <a id="_idIndexMarker318"/>to <strong class="bold">Event Tracing for Windows</strong> (<strong class="bold">ETW</strong>) events. You can only use it on <span class="No-Break">Windows platforms.</span></li>
				<li><strong class="source-inline">gcplogs</strong>: Sends logs to Google <span class="No-Break">Cloud Logging.</span></li>
				<li><strong class="source-inline">logentries</strong>: Sends<a id="_idIndexMarker319"/> logs to <span class="No-Break">Rapid7 Logentries.</span></li>
			</ul>
			<p>While all these are viable options, we will look at <strong class="source-inline">journald</strong> and Splunk. While <strong class="source-inline">journald</strong> is a native operating system service monitoring option, Splunk is one of the most famous log analytics and monito<a id="_idTextAnchor305"/><a id="_idTextAnchor306"/>ring tools. Now, let’s understand how to configure a <span class="No-Break">l<a id="_idTextAnchor307"/>ogging driver.</span></p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor308"/>Configuring logging drivers</h2>
			<p>Let’s start by<a id="_idIndexMarker320"/> finding the current <span class="No-Break">logging driver:</span></p>
			<pre class="console">
$ docker info | grep "Logging Driver"
Logging Driver: json-file</pre>			<p>Currently, the default logging driver is set to <strong class="source-inline">json-file</strong>. If we want to use <strong class="source-inline">journald</strong> or Splunk as the default logging driver, we must configure the default logging driver in the <span class="No-Break"><strong class="source-inline">daemon.json</strong></span><span class="No-Break"> file.</span></p>
			<p>Edit the <strong class="source-inline">/etc/docker/daemon.json</strong> file using an editor of your choice. If you’re using <strong class="source-inline">vim</strong>, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ sudo vim /etc/docker/daemon.json</pre>			<p>Add the <strong class="source-inline">log-driver</strong> entry to the <strong class="source-inline">daemon.json</strong> <span class="No-Break">configuration file:</span></p>
			<pre class="console">
{
  "log-driver": "journald"
}</pre>			<p>Then, restart the <span class="No-Break">Docker service:</span></p>
			<pre class="console">
$ sudo systemctl restart docker</pre>			<p>Check the status of the <span class="No-Break">Docker service:</span></p>
			<pre class="console">
$ sudo systemctl status docker</pre>			<p>Now, rerun <strong class="source-inline">docker info</strong> to see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker info | grep "Logging Driver"
Logging Driver: journald</pre>			<p>Now that <strong class="source-inline">journald</strong> is the <a id="_idIndexMarker321"/>default logging driver, let’s launch a new NGINX container and visualize <span class="No-Break">the logs:</span></p>
			<pre class="console">
$ docker run --name nginx-journald -d nginx
66d50cc11178b0dcdb66b114ccf4aa2186b510eb1fdb1e19d563566d2e96140c</pre>			<p>Now, let’s look at the <strong class="source-inline">journald</strong> logs to see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ sudo journalctl CONTAINER_NAME=nginx-journald
...
Jun 01 06:11:13 99374c32101c fb8294aece02[10826]: 10-listen-on-ipv6-by-default.sh: info: 
Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
...
Jun 01 06:11:13 99374c32101c fb8294aece02[10826]: 2023/06/01 06:11:13 [notice<a id="_idTextAnchor309"/>] 1#1: start 
worker process 30
...</pre>			<p>We can see the logs in <span class="No-Break">the journal.</span></p>
			<p>Similarly, we can configure the<a id="_idIndexMarker322"/> Splunk logging driver to send data to Splunk for analytics and visualization. Let’s have <span class="No-Break">a look.</span></p>
			<p>Edit the <strong class="source-inline">/etc/docker/daemon.json</strong> file using an editor of your choice. If you’re using <strong class="source-inline">vim</strong>, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ vim /etc/docker/daemon.json</pre>			<p>Add the log-driver entry to the <strong class="source-inline">daemon.json</strong> <span class="No-Break">configuration file:</span></p>
			<pre class="console">
{
  "log-driver": "splunk",
  "log-opts": {
    "splunk-token": "&lt;Splunk HTTP Event Collector token&gt;",
    "splunk-url": "&lt;Splunk HTTP(S) url&gt;"
  }
}</pre>			<p>Then, restart the <span class="No-Break">Docker service:</span></p>
			<pre class="console">
$ sudo systemctl restart docker</pre>			<p>Check the status of the <span class="No-Break">Docker service:</span></p>
			<pre class="console">
$ sudo systemctl status docker</pre>			<p>Now, rerun <strong class="source-inline">docker info</strong> to see<a id="_idIndexMarker323"/> what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker info | grep "Logging Driver"
Logging Driver: splunk</pre>			<p>Since Splunk is now the default logging driver, let’s launch a new NGINX container and visualize <span class="No-Break">the logs:</span></p>
			<pre class="console">
$ docker run --name nginx-splunk -d nginx
dedde062feba33f64efd89ef9102c7c93afa854473cda3033745d35d9065c9e5</pre>			<p>Log in to your Splunk instance; you will see the Docker logs streaming. You can then analyze the<a id="_idTextAnchor310"/> logs and create visualizations out <span class="No-Break">of them.</span></p>
			<p>You can also have different logging drivers for different containers, and you can do so by overriding the defaults by passing the <strong class="source-inline">log-driver</strong> and <strong class="source-inline">log-opts</strong> flags from the command line. As our current configuration is Splunk, and we want to export data to a JSON file, we can specify <strong class="source-inline">log-driver</strong> as <strong class="source-inline">json-file</strong> while running the container. Let’s have <span class="No-Break">a look:</span></p>
			<pre class="console">
$ docker run --name nginx-json-file --log-driver json-file -d nginx
379eb8d0162d98614d53ae1c81ea1ad154745f9edbd2f64cffc2279772198bb2</pre>			<p>To visualize JSON logs, we need to look into the JSON log directory – that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">/var/lib/docker/containers/&lt;container_id&gt;/&lt;container_id&gt;-json.log</strong></span><span class="No-Break">.</span></p>
			<p>For the <strong class="source-inline">nginx-json-file</strong> container, we<a id="_idIndexMarker324"/> can do <span class="No-Break">the following:</span></p>
			<pre class="console">
$ cat /var/lib/docker/containers\
/379eb8d0162d98614d53ae1c81ea1ad154745f9edbd2f64cffc2279772198bb2\
/379eb8d0162d98614d53ae1c81ea1ad154745f9edbd2f64cffc2279772198bb2-json.log
{"log":"/docker-entrypoint.sh: /docker-entrypoint.d/ is not
empty, will attempt to perform configuration\n","stream":"
stdout","time":"2022-06-01T06:27:05.922950436Z"}
...
{"log":"/docker-entrypoint.sh: Configuration complete; ready
for start up\n","stream":"<a id="_idTextAnchor311"/>stdout","time":"2023-06-01T06:27:
05.937629749Z"}</pre>			<p>We can see that the logs are now streaming to the JSON file instead of Splunk. That is how we override the default <span class="No-Break">log driver.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">In most cases, it is best to stick with one default logging driver so that you have one place to analyze and visualize <span class="No-Break">your logs.</span></p>
			<p>Now, let’s understand <a id="_idTextAnchor312"/><a id="_idTextAnchor313"/>some of the challenges and best practices associated with <span class="No-Break">Docker logging.</span></p>
			<h2 id="_idParaDest-91">Typical challenges and best practices<a id="_idTextAnchor314"/> to address these challenges with Docker logging</h2>
			<p>Docker allows <a id="_idIndexMarker325"/>you to run multiple applications in a single machine or a cluster of machines. Most organizations run a mix of virtual machines and containers, and they have their logging and monitoring stack configured to support <span class="No-Break">virtual machines.</span></p>
			<p>Most teams struggle to make Docker logging behave the way virtual machine logging works. So, most teams will send logs to the host filesystem, and the log analytics solution then consumes the data from there. This is not ideal, and you should avoid making this mistake. It might work if your container is static, but it becomes an issue if you have a cluster of servers, each running Docker, and you can schedule your container in any virtual machine <span class="No-Break">you like.</span></p>
			<p>So, treating a container as an application running on a virtual machine is a mistake from a logging point of view. Instead, you should visualize the container as an entity – just like a virtual machine. It would be best if you never associated containers with a <span class="No-Break">virtual machine.</span></p>
			<p>One solution is to use the logging driver to forward the logs to a log analytics solution directly. But then, the logging becomes heavily dependent on the availability of the log analytics solution. So, it might not be the best thing to do. People faced issues when their services running on Docker went down because the log analytics solution was unavailable or there were <span class="No-Break">network issues.</span></p>
			<p>Well, the best way to approach this problem is to use JSON files to store the logs temporarily in your virtual machine and use another container to push the logs to your chosen log analytics solution the old-fashioned way. That way, you decouple<a id="_idTextAnchor315"/> from the dependency on an external service to run <span class="No-Break">your application.</span></p>
			<p>You can use the logging driver to export logs directly to your log analytics solution within the log forwarder container. There are many logging drivers available that support many log targets. Always<a id="_idIndexMarker326"/> mark the logs in such a way that the containers appear as their own entities. This will disassociate containers from virtual machines, and you can then make the best use of a distributed <span class="No-Break">container-based architecture.</span></p>
			<p>So far, we’ve looked at the logging aspects of containers, but one of the essential elements of a DevOps en<a id="_idTextAnchor316"/><a id="_idTextAnchor317"/>gineer’s role is monitoring. We’ll have a look at th<a id="_idTextAnchor318"/>is in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor319"/>Docker monitoring with Prometheus</h1>
			<p>Monitoring Docker <a id="_idIndexMarker327"/>nodes and containers is an essential part of managin<a id="_idTextAnchor320"/>g Docker. There<a id="_idIndexMarker328"/> are various tools available for monitoring Docker. While you can use traditional tools such as Nagios, Prometheus is gaining ground in cloud-native monitoring because of its simplicity and <span class="No-Break">pluggable architecture.</span></p>
			<p>Prometheus<a id="_idIndexMarker329"/> is a free, open source monitoring tool that provides a dimensional data model, efficient and s<a id="_idTextAnchor321"/>traightforward querying using the <strong class="bold">Prometheus query language</strong> (<strong class="bold">PromQL</strong>), efficient<a id="_idIndexMarker330"/> time series databases, and modern <span class="No-Break">alerting capabilities.</span></p>
			<p>It has several exporters available for exporting data from various sources and supports both virtual machines and containers. Before we delve in<a id="_idTextAnchor322"/><a id="_idTextAnchor323"/>to the details, let’s look at some of the challenges with <span class="No-Break">container monitoring.</span><a id="_idTextAnchor324"/></p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor325"/>Challenges with container monitoring</h2>
			<p>From a conceptual point of view, there<a id="_idIndexMarker331"/> is no difference between container monitoring and the traditional method. You still need metrics, logs, health checks, and service discovery. These aren’t things that are unknown or haven’t been explored before. The problem with containers is the abstraction that they bring with them; let’s look at some of <span class="No-Break">the issues:</span></p>
			<ul>
				<li>Containers behave like mini virtual machines; however, in reality, they are processes running on a server. However, they still have everything to monitor that we would in a virtual machine. A container process will have many metrics, very similar to virtual machines, to be treated as separate entities altogether. When dealing with containers, most people make this mistake when they map containers to a particular <span class="No-Break">virtual machine.</span></li>
				<li>Containers are temporary, and most people don’t realize that. When you have a container and it is recreated, it has a new IP. This can confuse traditional <span class="No-Break">monitoring systems.</span></li>
				<li>Containers running on clusters can move from one node (server) to another. This adds another layer of complexity as your monitoring tool needs to know where your containers are to scrape metrics from them. This should not matter with the more <a id="_idIndexMarker332"/>modern, <span class="No-Break">container-optimized tools.</span></li>
			</ul>
			<p>Prometheus helps us address these challenges as it is built from a distributed application’s point of view. To understand this, we’ll look at a hands-on example. However<a id="_idTextAnchor326"/><a id="_idTextAnchor327"/>, before that, let’s install Prometheus on <a id="_idTextAnchor328"/>a separate Ubuntu 22.04 <span class="No-Break">Linux machine.</span></p>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor329"/>Installing Prometheus</h2>
			<p>Installing Prometheus consists <a id="_idIndexMarker333"/>of several steps, and for simplicity, I’ve created a Bash script for installing and setting up Prometheus on an <span class="No-Break">Ubuntu machine.</span></p>
			<p>Use the following commands on a separate machine where you want to set <span class="No-Break">up Prometheus:</span></p>
			<pre class="console">
$ git clone https://github.com/PacktPublishing/Modern-DevOps-Practices-2e.git \
modern-devops
$ cd modern-devops/ch3/prometheus/
$ sudo bash prometheus_setup.sh</pre>			<p>To check whether Prometheus is installed and running, check the status of the Prometheus service using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ sudo systemctl status prometheus
prometheus.service – Prometheus
   Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: 
enabled)
   Active: active (running<a id="_idTextAnchor330"/>) since Tue 2023-06-01 09:26:57 UTC; 1min 22s ago</pre>			<p>As the service <a id="_idIndexMarker334"/>is <strong class="source-inline">Active</strong>, we can conclude that Prometheus has been installed and is running successfully. The next <a id="_idTextAnchor331"/><a id="_idTextAnchor332"/>step is configuring the Docker server to enable Prometheus to collect logs <span class="No-Break">from it.</span></p>
			<h2 id="_idParaDest-95">Config<a id="_idTextAnchor333"/>uring cAdvisor and the node exporter to expose metrics</h2>
			<p>Now, we’ll launch a <a id="_idIndexMarker335"/>cAdvisor container on the machine running Docker to expose the metrics of the Docker <a id="_idTextAnchor334"/>containers. cAdvisor is a metrics collector that scrapes metrics from containers. To launch the container, use the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker run -d --restart always --name cadvisor -p 8080:8080 \
-v "/:/rootfs:ro" -v "/var/run:/var/run:rw" -v "/sys:/sys:ro" \
-v "/var/lib/docker/:/var/lib/docker:ro" google/cadvisor:latest</pre>			<p>Now that cAdvisor is running, we need to configure the node exporter to export node metrics on the Docker machine. To do so, run the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cd ~/modern-devops/ch3/prometheus/
$ sudo bash node_exporter_setup.sh</pre>			<p>Now that the node exporter<a id="_idIndexMarker336"/> is running, let’s configure P<a id="_idTextAnchor335"/><a id="_idTextAnchor336"/>rometheus to connect to cAdvisor and the node exporte<a id="_idTextAnchor337"/>r and scrape metrics <span class="No-Break">from there.</span></p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor338"/>Configuring Prometheus to scrape metrics</h2>
			<p>We will now configure <a id="_idIndexMarker337"/>Prometheus on the Prometheus machine so that it can scrape the metrics from cAdvisor. To do so, modify the <strong class="source-inline">/etc/prometheus/prometheus.yml</strong> file so that it includes the following within the<a id="_idIndexMarker338"/> server <span class="No-Break">running Prometheus:</span></p>
			<pre class="console">
$ sudo vim /etc/prometheus/prometheus.yml
  ...
  - job_name: 'node_exporter'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:9100', '&lt;Docker_IP&gt;:9100']
  - job_name: 'Docker Containers'
    static_configs:
      - targets: ['&lt;Docker_IP&gt;:8080']</pre>			<p>After changing this <a id="_idIndexMarker339"/>configuration, we need to restart the Prometheus service. Use the following command to <span class="No-Break">do so:</span></p>
			<pre class="console">
$ sudo systemctl restart prom<a id="_idTextAnchor339"/><a id="_idTextAnchor340"/>etheus</pre>			<p>Now, let’s launch a sample web application that we w<a id="_idTextAnchor341"/>ill monitor <span class="No-Break">using Prometheus.</span></p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor342"/>Launching a sample container application</h2>
			<p>Now, let’s run an NGINX<a id="_idIndexMarker340"/> container called <strong class="source-inline">web</strong> that runs on port <strong class="source-inline">8081</strong> on the Docker machine. To do so, use the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker run -d --name web -p 8081:80 nginx
f9b613d6bdf3d6aee0cb3a08cb55c99a7c4821341b058d8757579b52cabbb0f5</pre>			<p>Now that we’ve set up the Docker container, let’s go ahead and open the Prometheus UI by visiting <strong class="source-inline">https://&lt;PROMETHEUS_SERVER_EXTERNAL_IP&gt;:9090</strong> and then running the following qu<a id="_idTextAnchor343"/>ery by typing it in <span class="No-Break">the textbox<a id="_idTextAnchor344"/>:</span></p>
			<pre class="console">
container_memory_usage_bytes{name=~"web"}</pre>			<p>It should show something like <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B19877_Figure_3.02.jpg" alt="Figure 3.2 – Prometheus – container_memory_usage_bytes" width="1028" height="369"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.2 – Prometheus – container_memory_usage_bytes</p>
			<p>We can also view the <a id="_idIndexMarker341"/>time series of this metric by clicking on the <strong class="bold">Graph</strong> tab. However, before doing so, let’s load our NGINX service using the Apache Bench tool. Apache Bench is a load-testing tool that helps us fire HTTP requests to the NGINX endpoint using the <span class="No-Break">command line.</span></p>
			<p>On your Docker server, run the following command to start a <span class="No-Break">load test:</span></p>
			<pre class="console">
$ ab -n 100000 http://localhost:8081/</pre>			<p>It will hit the endpoint with 100,000 requests, which means it provides a fair amount of load to do a me<a id="_idTextAnchor345"/>mory spike. Now, if you open the <strong class="bold">Graph</strong> tab, you should see something like <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B19877_Figure_3.03.jpg" alt="Figure 3.3 – Prometheus – container_memory_usage_bytes – Graph" width="1634" height="794"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Fig<a id="_idTextAnchor346"/>ure 3.3 – Prometheus – container_memory_usage_bytes – Graph</p>
			<p>To visualize node metrics, we <a id="_idIndexMarker342"/>can use the following PromQL statement to get the <strong class="source-inline">node_cpu</strong> value of the <span class="No-Break">Docker host:</span></p>
			<pre class="console">
node_cpu{instance="&lt;Docker_IP&gt;:9100",job="node_exporter"}</pre>			<p>As shown in th<a id="_idTextAnchor347"/>e following screenshot, it will provide us with the <strong class="source-inline">node<a id="_idTextAnchor348"/>_cpu</strong> metrics for <span class="No-Break">multiple modes:</span></p>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="image/B19877_Figure_3.04.jpg" alt="Figure 3.4 – Prometheus – node_cpu" width="793" height="935"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.4 – Prometheus – node_cpu</p>
			<p>There are a variety<a id="_idIndexMarker343"/> of other metrics that<a id="_idTextAnchor349"/><a id="_idTextAnchor350"/> Prometheus gives you to visualize. Let’s<a id="_idTextAnchor351"/> understand some of the metrics you <span class="No-Break">can monitor.</span></p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor352"/>Metrics to monitor</h2>
			<p>Monitoring metrics is a complex subject, and it would depend mostly on your use case. However, the following are some g<a id="_idTextAnchor353"/>uidelines on what metrics you want <span class="No-Break">to monitor.</span></p>
			<h3>Host metrics</h3>
			<p>You need to monitor your host metrics as your containers run o<a id="_idTextAnchor354"/>n them. Some of the metrics that you can watch are <span class="No-Break">as </span><span class="No-Break"><a id="_idIndexMarker344"/></span><span class="No-Break">follows:</span></p>
			<ul>
				<li><strong class="bold">Host CPU</strong>: It’s good to know whether your host has sufficient CPU to run your containers. If not, it might terminate some of your containers to account for that. So,<a id="_idTextAnchor355"/> to ensure reliability, you need to keep this <span class="No-Break">in check.</span></li>
				<li><strong class="bold">Host memory</strong>: Like the host CPU, you need to watch the host memory to d<a id="_idTextAnchor356"/>etect issues such as memory<a id="_idTextAnchor357"/> leaks and <span class="No-Break">runaway memory.</span></li>
				<li><strong class="bold">Host disk space</strong>: As Docker<a id="_idIndexMarker345"/> containers use the host filesystem to store transient and per<a id="_idTextAnchor358"/>sistent files, you need to <span class="No-Break">monitor it.</span></li>
			</ul>
			<h3>Docker container metri<a id="_idTextAnchor359"/>cs</h3>
			<p>Docker container metrics are the<a id="_idIndexMarker346"/> next thing <span class="No-Break">to consider:</span></p>
			<ul>
				<li><strong class="bold">Container CPU</strong>: This metric will provide the amount of CPU used by the Docker container. You should monitor it to understand the usability <a id="_idTextAnchor360"/>pattern and decide where to place your <span class="No-Break">container effectively.</span></li>
				<li><strong class="bold">Throttled CPU time</strong>: This metric allows us to understand the total time when the CPU was throttled for a container. This lets us know whether a particular container needs more CPU time than others, and you can adjust the CPU share <span class="No-Break">constraint accordingly.</span></li>
				<li><strong class="bold">Containe<a id="_idTextAnchor361"/>r memory fail counters</strong>: This metric provides the number of times the container requested more than the allocated memory. It will help you understand what containers require more than the allocated memor<a id="_idTextAnchor362"/>y, and you can plan to run those <span class="No-Break">containers accordingly.</span></li>
				<li><strong class="bold">Container memory usage</strong>: This metric will provide the amount of memory used by the Do<a id="_idTextAnchor363"/>cker container. You can set memory limits according to <span class="No-Break">the usage.</span></li>
				<li><strong class="bold">Container swap</strong>: This metric will tell you what containers were using swap <a id="_idTextAnchor364"/>instead of RAM. It helps us identify <span class="No-Break">memory-hungry containers.</span></li>
				<li><strong class="bold">Container disk I/O</strong>: This is an important metric and will help us understand containers’ disk profiles. Spikes can indicate a disk bottleneck or suggest that you might want to revisit your storage <span class="No-Break">driver configuration.</span></li>
				<li><strong class="bold">Container network metrics</strong>: This metric will tell us how much network bandwidth the containers use and help us understand traffic patterns. You can use these to detect an<a id="_idIndexMarker347"/> unexpected network spike or a <span class="No-Break">denia</span><span class="No-Break">l-of-s</span><span class="No-Break">ervice attack.</span></li>
			</ul>
			<p class="callout-heading">Important tip</p>
			<p class="callout">Profiling your application during the performance testing phase in the non-production environment will give you a rough idea of how the system will behave in production. The actual fine-tuning of your application begins when you deploy them to production. Therefore, monitoring is critical, and fine-tuning is a <span class="No-Break">continuous process.</span></p>
			<p>So far, we have been running commands to do most of our work. That is the imperative way of doing this. But what if I told you that instead of typing commands, you could declare what you want, and something could run all the required commands on your behalf? That is known as the declarative method of managing an application. Docker Compos<a id="_idTextAnchor365"/><a id="_idTextAnchor366"/>e is one of the popular tools to achieve this. We’ll have a look at this <a id="_idTextAnchor367"/>in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor368"/>Declarative container management with Docker Compose</h1>
			<p>Docker Compose helps you <a id="_idIndexMarker348"/>manage multiple containers in a declarative way. You can create a YAML file and specify what you want to build, what containers you want to run, and how the containers interact with each other. You can define mounts, networks, port mapping, and many different configurations in the <span class="No-Break">YAML file.</span></p>
			<p>After that, you can simply run <strong class="source-inline">docker compose up</strong> to run your entire <span class="No-Break">containerized application.</span></p>
			<p>Declarative management is quickly gaining ground because of its power and simplicity. Now, sysadmins don’t need to remember what commands they had run or write lengthy scripts or playbooks to manage containers. Instead, they can simply declare wha<a id="_idTextAnchor369"/>t they want in a YAML file, and <strong class="source-inline">docker compose</strong> or other tools can help them achieve that state. We installed<a id="_idTextAnchor370"/><a id="_idTextAnchor371"/> Docker Compose when we installed Docker, so let’s see it in<a id="_idTextAnchor372"/> action with a <span class="No-Break">sample application.</span></p>
			<h2 id="_idParaDest-100"><a id="_idTextAnchor373"/>Deploying a sample application with Docker Compose</h2>
			<p>We <a id="_idIndexMarker349"/>have a Python Flask application that <a id="_idIndexMarker350"/>listens on port <strong class="source-inline">5000</strong>, which we will eventually map to host port <strong class="source-inline">80</strong>. The application will connect to the Redis database as a backend service on its default port, <strong class="source-inline">6379</strong>, and fetch the page’s last visit time. We will not expose that port to the host system. This means the database is entirely out of bounds for any external party with access to <span class="No-Break">the application.</span></p>
			<p>The following diagram depicts the <span class="No-Break">application architecture:</span></p>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B19877_Figure_3.05.jpg" alt="Figure 3.5 – Sample application" width="1586" height="753"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.5 – Sample application</p>
			<p>The necessary<a id="_idIndexMarker351"/> files are available in this book’s <a id="_idIndexMarker352"/>GitHub repository. Run the following command to locate <span class="No-Break">the files:</span></p>
			<pre class="console">
$ git clone https://github.com/PacktPublishing/Modern-DevOps-Practices-2e.git \
modern-devops 
$ cd modern-devops/ch3/docker-compose
$ ls -l
total 16
-rw-r--r-- 1 root root 681 Nov 25 06:11 app.py
-rw-r--r-- 1 root root 389 Nov 25 06:45 docker-compose.yaml
-rw-r--r-- 1 root root 238 Nov 25 05:27 Dockerfile
-rw-r--r-- 1 root root  12 Nov 25 05:26 requirements.txt</pre>			<p>The <strong class="source-inline">app.py</strong> file looks <span class="No-Break">as follows:</span></p>
			<pre class="console">
import time
import redis
from flask import Flask
from datetime import datetime
app = Flask(__name__)
cache = redis.Redis(host='redis', port=6379)
def get_last_visited():
    try:
        last_visited = cache.getset('last_visited',str(datetime.now().strftime("%Y-%m-%d, 
%H:%M:%S")))
        if last_visited is None:
            return cache.getset('last_visited',str(datetime.now().strftime("%Y-%m-%d, 
%H:%M:%S")))
        return last_visited
    except redis.exceptions.ConnectionError as e:
        raise e
@app.route('/')
def index():
    last_visited = str(get_last_visited().decode('utf-8'))
    return 'Hi there! This page was last visited on {}.\n'.format(last_visit<a id="_idTextAnchor374"/>ed)</pre>			<p>The <strong class="source-inline">requirements.txt</strong> file looks <span class="No-Break">as follows:</span></p>
			<pre class="console">
flask
redis</pre>			<p>I’ve already built the <a id="_idIndexMarker353"/>application for you, and<a id="_idIndexMarker354"/> the image is available on Docker Hub. The next chapter will <a id="_idTextAnchor375"/><a id="_idTextAnchor376"/>cover how to build a Docker image in detail. For now,<a id="_idTextAnchor377"/> let’s have a look at the <span class="No-Break"><strong class="source-inline">docker-compose</strong></span><span class="No-Break"> file.</span></p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor378"/>Creating the docker-compose file</h2>
			<p>The next step in the <a id="_idIndexMarker355"/>process is to create a <strong class="source-inline">docker-compose</strong> file. A <strong class="source-inline">docker-compose</strong> file is a YAML file that contains a list of services, networks, volumes, and other associated configurations. Let’s look at the following example <strong class="source-inline">docker-compose.yaml</strong> file to understand <span class="No-Break">it better:</span></p>
			<pre class="console">
version: "2.4"
services:
  flask:
    image: "bharamicrosystems/python-flask-redis:latest"
    ports:
      - "80:5000"
    networks:
      - flask-app-net
  redis:
    image: "redis:alpine"
    networks:
      - flask-app-net
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data:/data
networks:
  flask-app-net:
    driver: bridge
volumes:
  redis-data:</pre>			<p>The YAML file describes two services – <strong class="source-inline">flask</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">redis</strong></span><span class="No-Break">.</span></p>
			<p>The <strong class="source-inline">flask</strong> service uses the <strong class="source-inline">python-flask-redis:latest</strong> image – the image we built with the preceding code. It also maps host port <strong class="source-inline">80</strong> to container port <strong class="source-inline">5000</strong>, exposing this application to<a id="_idTextAnchor379"/> your host machine on port <strong class="source-inline">80</strong>, and you can access it <span class="No-Break">via </span><span class="No-Break"><strong class="source-inline">http://localhost</strong></span><span class="No-Break">.</span></p>
			<p>The <strong class="source-inline">redis</strong> service uses the official <strong class="source-inline">redis:alpine</strong> image and does not expose any port, as we don’t want this service outside the container network’s confines. However, it declares a persistent volume, <strong class="source-inline">redis-data</strong>, that comprises the <strong class="source-inline">/data</strong> directory. We can mount this volume on the host filesystem for persistence beyond the container <span class="No-Break">life cycle.</span></p>
			<p>There is also a <strong class="source-inline">flask-app-net</strong> network that uses the bridge driver, and both services share the same network. This means the services can call each other by using their service names. If you look at the <strong class="source-inline">app.py</strong> code, you will see that we established a Redis service connection<a id="_idIndexMarker356"/> using the <span class="No-Break"><strong class="source-inline">redis</strong></span><span class="No-Break"> hostname.</span></p>
			<p>To apply the configuration, simply run <strong class="source-inline">docker-compose </strong><span class="No-Break"><strong class="source-inline">up -d</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
$ docker compose up -d
[+] Running 17/17
flask 9 layers []      0B/0B      Pulled 10.3s
redis 6 layers []      0B/0B      Pulled 9.1s
[+] Building 0.0s (0/0)
[+] Running 4/4
Network docker-compose_flask-app-net  Created 0.1s
Volume "docker-compose_redis-data"    Created 0.0s
Container docker-comp<a id="_idTextAnchor380"/>ose-flask-1      Started 3.8s
Container docker-compose-redis-1      Stated</pre>			<p>Now, let’s list the Docker containers to see how <span class="No-Break">we fare:</span></p>
			<pre class="console">
$ docker ps
CONTAINER ID  IMAGE              COMMAND         CREATED    STATUS   PORTS             NAMES
9151e72f5d66  redis:             "docker-        3 minutes  Up 3     6379/tcp          docker-compose
              alphone            entrypoint.s…"  ago        minutes                    -redis-1
9332c2aaf2c4  bharamicrosystems  "flask run"     3 minutes  Up 3     0.0.0.0:80-&gt;      docker-compose
              /python-flask-                     ago        minutes  5000/tcp,         -flask-1
              redis:latest                                           :::80-&gt;5000/tcp</pre>			<p>We can see that two containers are running for both services. We can also see host port <strong class="source-inline">80</strong> forwarding connections to container port <strong class="source-inline">5000</strong> on the <span class="No-Break"><strong class="source-inline">flask</strong></span><span class="No-Break"> service.</span></p>
			<p>The <strong class="source-inline">redis</strong> service is internal and therefore, there is no <span class="No-Break">port mapping.</span></p>
			<p>Let’s run <strong class="source-inline">curl localhost</strong> and see what <span class="No-Break">we get<a id="_idTextAnchor381"/>:</span></p>
			<pre class="console">
$ curl localhost
Hi there! This page was last visited on 2023-06-01, 06:54:27.</pre>			<p>Here, we get the last visited page from the Redis cache according to the sample Flask <span class="No-Break">application code.</span></p>
			<p>Let’s run this a few times <a id="_idIndexMarker357"/>and see whether the <span class="No-Break">time changes:</span></p>
			<pre class="console">
$ curl localhost
Hi there! This page was last visited on 2023-06-01, 06:54:28.
$ curl localhost
Hi there! This page was last visited on 2023-06-01, 06:54:51.
$ curl localhost
Hi there! This page was last visited on 2023-06-01, 06:54:52.</pre>			<p>We can see that the last visited time changes every time we <strong class="source-inline">curl</strong>. Since the volume is persistent, we should get similar last visited times even after a <span class="No-Break">container restarts.</span></p>
			<p>First, let’s <strong class="source-inline">curl</strong> and get the last visited time and also the <span class="No-Break">current date:</span></p>
			<pre class="console">
$ curl localhost &amp;&amp; date
Hi there! This page was last visited on 2023-06-01, 06:54:53.
Thu Jun  1 06:55:50 UTC 2023</pre>			<p>Now, the next time we <strong class="source-inline">curl</strong>, we should get a date-time similar to <strong class="source-inline">2023-06-01, 06:55:50</strong>. But before that, let’s restart the container and see whether the <span class="No-Break">data persists:</span></p>
			<pre class="console">
$ docker compose restart redis
[+] Restarting 1/1
Container docker-compose-redis-1  Started</pre>			<p>Now that Redis has been restarted, let’s run <span class="No-Break"><strong class="source-inline">curl</strong></span><span class="No-Break"> again:</span></p>
			<pre class="console">
$ <a id="_idTextAnchor382"/>curl localhost
Hi there! This page was last visited on 2023-06-01, 06:55:50.</pre>			<p>As we can see, we get the correct last visited time, even after restarting the <strong class="source-inline">redis</strong> service. This means that data persistence works correctly, and the volume is <span class="No-Break">adequately mounted.</span></p>
			<p>You can do many other<a id="_idIndexMarker358"/> configurations on <strong class="source-inline">docker compose</strong> that you can readily get from the official documentation. However, you should now have a general idea about using <strong class="source-inline">docker <a id="_idTextAnchor383"/><a id="_idTextAnchor384"/>compose</strong> and its benefits. Now, let’s look at <a id="_idTextAnchor385"/>some of the best practices associated with <span class="No-Break">Docker Compose.</span></p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor386"/>Docker Compose best practices</h2>
			<p>Docker Compose provides a <a id="_idIndexMarker359"/>declarative way of managing Docker container <a id="_idIndexMarker360"/>configuration. This enables GitOps for your Docker workloads. While Docker Compose is primarily used in development environments, you can use it in production very effectively, especially when Docker runs in production and does not use another container orchestrator such <span class="No-Break">as Kubernetes.</span></p>
			<h3>Always use docker-compose.yml files alongside code</h3>
			<p>The YAML file defines how to run your containers. So, it becomes a valuable tool for declaratively building and deploying your containers from a single space. You can add all dependencies to your application and run related applications in a <span class="No-Break">single network.</span></p>
			<h3>Separate multiple environment YAMLs using overrides</h3>
			<p>Docker Compose YAML files allow us to both build and deploy Docker images. Docker has enabled the <em class="italic">build once, run anywhere</em> concept. This means we build once in the development environment and then use the created image in subsequent environments. So, the question arises of how we can achieve that. Docker Compose allows us to apply multiple YAML files in a sequence where the next configuration over<a id="_idTextAnchor387"/>rides the last. That way, we <a id="_idIndexMarker361"/>can have separate override files for various environments and manage<a id="_idIndexMarker362"/> multiple environments using a set of <span class="No-Break">these files.</span></p>
			<p>For example, say we have the following base <span class="No-Break"><strong class="source-inline">docker-compose.yaml</strong></span><span class="No-Break"> file:</span></p>
			<pre class="console">
version: "2.4"
services:
  flask:
    image: "bharamicrosystems/python-flask-redis:latest"
    ports:
      - "80:5000"
    networks:
      - flask-app-net
  redis:
    image: "redis:alpine"
    networks:
      - flask-app-net
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data:/data
networks:
  flask-app-net:
    driver: bridge
volumes:
  redis-data:</pre>			<p>We only <a id="_idIndexMarker363"/>have to build the Flask application container<a id="_idIndexMarker364"/> image in the development environment so that we can create an override file for the development environment – that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">docker-compose.override.yaml</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
web:
  build: .
  environment:
    DEBUG: 'true'
redis:
  ports:
    - 6379:6379</pre>			<p>Here, we added a <strong class="source-inline">build</strong> parameter within the web service. This means the Python Flask application will be rebuilt and then deployed. We also set the <strong class="source-inline">DEBUG</strong> environment variable within the <strong class="source-inline">web</strong> service and exposed the <strong class="source-inline">redis</strong> port to the host filesystem. This makes sense in the development environment, as we might want to debug Redis from the development machine directly. Still, we would not wa<a id="_idTextAnchor388"/>nt something of that sort in the production environment. Therefore, the default <strong class="source-inline">docker-compose.yaml</strong> file will work in the production environment, as we saw in the <span class="No-Break">previous section.</span></p>
			<h3>Use an .env file to store sensitive variables</h3>
			<p>You might not <a id="_idIndexMarker365"/>want to store sensitive content such as passwords<a id="_idIndexMarker366"/> and secrets in version control. Instead, you can use an <strong class="source-inline">.env</strong> file that contains a list of variable names and values and keep it in a secret management system such as <span class="No-Break">HashiCorp Vault.</span></p>
			<h3>Be mindful of dependencies in production</h3>
			<p>When you change a particular container and want to redeploy it, <strong class="source-inline">d<a id="_idTextAnchor389"/>ocker-compose</strong> also redeploys any dependencies. Now, this might not be something that you wish to do, so you can override this behavior by using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker-compose up --no-deps -d &lt;container_service_name&gt;</pre>			<h3>Treat docker-compose files as code</h3>
			<p>Always<a id="_idIndexMarker367"/> version control your <strong class="source-inline">docker-compose</strong> files and<a id="_idIndexMarker368"/> keep them a<a id="_idTextAnchor390"/><a id="_idTextAnchor391"/>longside the code. This will allow you to track their versions and use gating and Git features such as <span class="No-Break">pull requests.</span></p>
			<h1 id="_idParaDest-103"><a id="_idTextAnchor392"/>Summary</h1>
			<p>This chapter was designed to cater to both beginners and experienced individuals. We started by covering the foundational concepts of Docker and gradually delved into more advanced topics and real-world use cases. This chapter began with installing Docker, running our first Docker container, understanding various modes of running a container, and understanding Docker volumes and storage drivers. We also learned how to select the right storage driver, volume options, and some best practices. All these skills will help you easily set up a production-ready Docker server. We also discussed the logging agent and how to quickly ship Docker logs to multiple destinations, such as <strong class="bold">journald</strong>, <strong class="bold">Splunk</strong>, and JSON files, to help you monitor your containers. We looked at managing Docker containers declaratively using <strong class="bold">Docker Compose</strong> and deployed a complete composite container application. Please try out all the commands mentioned in this chapter for a more hands-on experience – practice is vital to achieving something worthwhile and learning <span class="No-Break">something new.</span></p>
			<p>As a next st<a id="_idTextAnchor393"/><a id="_idTextAnchor394"/>ep, in the following chapter, we will look at Docker images, creating and managing them, and some <span class="No-Break">best practices.</span></p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor395"/>Questions</h1>
			<p>Answer the following questions to test your knowledge of <span class="No-Break">this chapter:</span></p>
			<ol>
				<li>You should use <strong class="source-inline">overlay2</strong> for CentOS and RHEL 7 and <span class="No-Break">below. </span><span class="No-Break">(True/False)</span></li>
				<li>Which of the following statements is true? (<span class="No-Break">Choose four)</span><p class="list-inset">A. Volumes <span class="No-Break">increase IOPS.</span></p><p class="list-inset">B. Volumes <span class="No-Break">decrease IOPS.</span></p><p class="list-inset">C. <strong class="source-inline">tmpfs</strong> mounts use <span class="No-Break">system memory.</span></p><p class="list-inset">D. You can use bind mounts to mount host files <span class="No-Break">to containers.</span></p><p class="list-inset">E. You can use volume mounts for a multi-instance <span class="No-Break">active-active configuration.</span></p></li>
				<li>Changing the storage driver removes existing containers from the <span class="No-Break">host. </span><span class="No-Break">(True/False)</span></li>
				<li><strong class="source-inline">devicemapper</strong> is a better option than <strong class="source-inline">overlay2</strong> for write-intensive <span class="No-Break">containers. </span><span class="No-Break">(True/False)</span></li>
				<li>Which of the following logging drivers are supported by Docker? (<span class="No-Break">Choose four)</span><p class="list-inset"><span class="No-Break">A. </span><span class="No-Break"><strong class="source-inline">journald</strong></span></p><p class="list-inset"><span class="No-Break">B. Splunk</span></p><p class="list-inset">C. <span class="No-Break">JSON files</span></p><p class="list-inset"><span class="No-Break">D. Syslog</span></p><p class="list-inset"><span class="No-Break">E. Logstash</span></p></li>
				<li>Docker Compose is an imperative approach to managing <span class="No-Break">containers. </span><span class="No-Break">(True/False)</span></li>
				<li>Which of the following <strong class="source-inline">docker run</strong> configurations are correct? (<span class="No-Break">Choose three)</span><p class="list-inset">A. <strong class="source-inline">docker </strong><span class="No-Break"><strong class="source-inline">run nginx</strong></span></p><p class="list-inset">B. <strong class="source-inline">docker run <a id="_idTextAnchor396"/><a id="_idTextAnchor397"/>--name </strong><span class="No-Break"><strong class="source-inline">nginx nginx:1.17.3</strong></span></p><p class="list-inset">C. <strong class="source-inline">docker run -d --name </strong><span class="No-Break"><strong class="source-inline">nginx nginx</strong></span></p><p class="list-inset">D. <strong class="source-inline">docker run -d --name nginx nginx --</strong><span class="No-Break"><strong class="source-inline">restart never</strong></span></p></li>
			</ol>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor398"/>Answers</h1>
			<p>The following are the answers to this <span class="No-Break">chapter’s questions:</span></p>
			<ol>
				<li>False – You should use <strong class="source-inline">devicemapper</strong> for CentOS and RHEL 7 and below as they do not <span class="No-Break">support </span><span class="No-Break"><strong class="source-inline">overlay2</strong></span><span class="No-Break">.</span></li>
				<li>B, C, <span class="No-Break">D, E</span><span class="No-Break">.</span></li>
				<li><span class="No-Break">True.</span></li>
				<li><span class="No-Break">True.</span></li>
				<li>A, B, <span class="No-Break">C, D.</span></li>
				<li>False – Docker Compose is a declarative approach to <span class="No-Break">container management.</span></li>
				<li>A, <span class="No-Break">B, C.</span></li>
			</ol>
		</div>
	</div>
</div>
</body></html>