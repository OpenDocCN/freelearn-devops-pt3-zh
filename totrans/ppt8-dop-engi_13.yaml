- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Taking Puppet Server Further
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will look at how you can monitor, tune, and integrate your Puppet
    infrastructure with third-party sources. You will understand how to find the logs
    of the various services we have discussed in previous chapters and how to find
    the current status APIs. You will then learn how these logs and statuses can be
    integrated into services such as **logstash** to provide greater visibility and
    alerting options. Then, we’ll review the metrics provided by Puppet, along with
    how these can be integrated with dashboarding tools such as Splunk and Grafana
    to provide **monitoring** and **observability** for Puppet’s infrastructure. We
    will set up a lab for both **Splunk** and **Grafana** as part of the Puppet Operational
    Dashboard to show these dashboards. Using these metrics, you will learn how the
    various components of Puppet’s infrastructure can be tuned and scaled to deal
    with common issues and problems as Puppet grows. After, you’ll learn how the external
    provider pattern can allow for facts, classification, and Hiera data to be fed
    from external data sources into Puppet and to allow Puppet platform teams to provide
    self-service with Puppet data without requiring full knowledge of Puppet or the
    environment release procedures. Various third-party implementations, including
    **ServiceNow** and **1Password**, will be shown. The **Puppet Data Service** (**PDS**)
    will be implemented in this chapter’s lab to demonstrate this pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Logging and status
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics, tuning, and scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying and avoiding common issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: External data sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Clone the control repository from [https://github.com/puppetlabs/control-repo](https://github.com/puppetlabs/control-repo
    ) to your GitHub account (`controlrepo-chapter13`) and update the following files
    in this repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Puppetfile` with [https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/Puppetfile](https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/Puppetfile)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hiera.yaml` with [https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/hiera.yaml](https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/hiera.yaml)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`manifests/site.pp` with [https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/site.pp](https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/site.pp)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Build a large cluster with three compilers and three clients by downloading
    the `params.json` file from [https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/params.json](https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/params.json)
    and update it with the location of your control repository and your SSH key for
    the control repository. Then, run the following command from your `pecdm` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: First, we will look at where to find the logs and current status of the Puppet
    services and infrastructure. This will be fundamental to how you will need to
    tune and troubleshoot Puppet.
  prefs: []
  type: TYPE_NORMAL
- en: Logging and status
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we discussed different Puppet components previously in this book, we listed
    logging directories, but it is useful to have a single reference point for these
    logs.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring log locations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section provides a list of these logs, titled with the core function,
    the containing directory, and the list of logs in that directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/var/log/puppetlabs/puppetserver/`: The primary server logging directory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`puppetserver.log`: The primary server which logs its activity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`puppetserver-access.log`: Requests to access endpoints'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`puppetserver-daemon.log`: Crash reports and fatal errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`puppetserver-status.log`: Debug status logging for the service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/var/log/puppetlabs/postgresql/<version>`: PostgreSQL logging directory*   `pgstartup.log`:
    Start-up logs*   `postgresql-<Mon – Sun>.log`: Daily debugging logs*   `/var/log/puppetlabs/puppetdb/`:
    PuppetDB logging directory*   `puppetdb.log`: The PuppetDB service activity log*   `puppetdb-access.log`:
    Requests to access endpoints*   `puppetdb-status.log`: Debug status logging for
    the service*   `/var/log/puppetlabs/puppetserver/`: The primary server logging
    directory*   `code-manager-access.log`: Requests to access endpoints of the code
    manager*   `file-sync-access.log`: Requests to access endpoints of file sync*   `pcp-broker.log`:
    Puppet Communications Protocol brokers on compilers*   `/var/log/puppetlabs/console-services/`:
    Puppet Enterprise console service logging directory*   `console-services.log`:
    Console service activity logs*   `console-services-api-access.log`: Requests to
    access the console service API endpoints*   `console-services-access.log`: Requests
    to access the console service endpoint*   `console-services-daemon.log`: Crash
    reports and fatal errors logged*   `/var/log/puppetlabs/nginx/`: nginx logging
    directory*   `access.log`: Requests to nginx endpoints*   `error.log`: nginx errors
    and general console errors*   **Agent logs:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The agent output that you see on your screen when you run Puppet manually is
    logged to a location based on the `logdest` and `logdir` settings in the `puppet.conf`
    file. The `logdest` parameter can be set to `syslog` (to be sent to the POSIX
    syslog service), `eventlog` (to be sent to the Windows event log), `console` (for
    logs to be sent to the console), or a filename so that they’re outputted to a
    file of this name in the location set by `logdest`. `syslog` is the default for
    Unix-based systems, while `eventlog` is the default for Windows. The defaults
    for `logdest` are `/var/log/puppetlabs/puppet` for Unix and `C:\ProgramData\PuppetLabs\puppet\var\log`
    for Windows.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to turn on server profiling, which can generate detailed catalog
    logging information. This can then be graphed to show in-depth debugging information
    about the catalog compilation. It is beyond the scope of this book to dive into
    this. More information can be found in Puppet’s documentation at [https://github.com/puppetlabs/puppet/blob/main/docs/profiling.md](https://github.com/puppetlabs/puppet/blob/main/docs/profiling.md).
  prefs: []
  type: TYPE_NORMAL
- en: Having examined the various locations of logging, it becomes clear that it would
    be useful to forward these server logs to specialized tools so that they can be
    indexed and processed.
  prefs: []
  type: TYPE_NORMAL
- en: Forwarding server logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the number of Puppet clients grows, the log tracking exercise, which we completed
    in [*Chapter 10*](B18492_10.xhtml#_idTextAnchor252), simply becomes impractical.
    In this scenario, more specialized `logback.xml`, which can be sent to a logging
    backend such as Elastic’s Logstash or Grafana’s Loki. The `logback.xml` file contains
    `appender` definitions, which are the Logback components for writing logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'By observing the `appender` configuration for `puppetserver.log`, we will see
    the current configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see how it appends to the log, the filename pattern it will use,
    along with dates for rolling the log, and that the file size will not exceed 200
    MB per file, no more than 1 GB, and that logs will not be retained for more than
    90 days. The encoder shows how the log entries should be formed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add a JSON version of the log, we could make a similar entry that consists
    of just 5 days of logging. Here, the encoder is the Logstash encoder to output
    in JSON. Here’s the code for this `appender`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To enable this `appender` toward the bottom of the `logback.xml` file, add
    the following definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Adding `<appender-ref ref="server_JSON"/>` within this root section would enable
    our JSON `appender`. Restarting the `puppetserver` service would enable the new
    `appender`.
  prefs: []
  type: TYPE_NORMAL
- en: To set up `server-access.log`, you can use the code at [https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/appender_example.xml](https://github.com/PacktPublishing/Puppet-8-for-DevOps-Engineers/blob/main/ch13/appender_example.xml),
    which will add an `appender` that will configure the JSON output with an appropriate
    pattern.
  prefs: []
  type: TYPE_NORMAL
- en: You will need to consider disk space in such cases. It’s possible to run this
    with JSON logging. Logback is a powerful library, but it’s beyond the scope of
    this book to go through the full options. These can be reviewed at [http://logback.qos.ch/manual/configuration.html](http://logback.qos.ch/manual/configuration.html)
    and [https://logback.qos.ch/manual/appenders.html](https://logback.qos.ch/manual/appenders.html).
  prefs: []
  type: TYPE_NORMAL
- en: Now that logfiles exist in JSON, a tool such as Grafana’s **Promtail** or Elastic’s
    **Filebeat** could be configured to forward the log files to a service such as
    Elastic’s Logstash or Grafana’s Loki. The Ruby logs managed by **Logrotate** can
    also be gathered, but it would require more work to put suitable patterns on them
    to be processed.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Puppet Enterprise services, `console-services`, PuppetDB, and orchestration
    services all use Logback and can have their logs forwarded like this.
  prefs: []
  type: TYPE_NORMAL
- en: Having reviewed how logs can be sent to external services to be processed, we
    will now see how the reports that are generated from applying Puppet catalogs
    can also be sent to external tools using report processors.
  prefs: []
  type: TYPE_NORMAL
- en: Report processors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As well as server logging, as shown in [*Chapter 10*](B18492_10.xhtml#_idTextAnchor252),
    every catalog run generates reports. In [*Chapter 10*](B18492_10.xhtml#_idTextAnchor252),
    you saw how this was configured by `peadm` to be stored in `puppetdb` using `reports
    = puppetdb` in the `master/server` section of `puppet.conf`. Setting this `reports`
    value told the server to use a report processor, which is a Ruby script that’s
    run when Puppet Server receives a report. The script then performs actions to
    pass it on to a target. In the case of PuppetDB, this is to send reports to be
    stored in PuppetDB. There are three built-in report processors: `http`, `log`,and
    `store`. `http, which` sends the report to an HTTP address set by the `reporturl`
    setting in `puppet.conf` in YAML format. `log` sends the report output to the
    logging file specified in `logdest` and `logdir` in `puppet.conf`, and `store`
    puts the report’s output into files specified by the `reportdir` setting that’s
    set in `puppet.conf`. Other custom report processors are available in Puppet Forge,
    including the Splunk integration module, as described at [https://forge.puppet.com/modules/puppetlabs/splunk_hec](https://forge.puppet.com/modules/puppetlabs/splunk_hec),
    and the Datadog agent module, as described at [https://forge.puppet.com/modules/datadog/datadog_agent](https://forge.puppet.com/modules/datadog/datadog_agent),
    which allows report data to be viewed in those third-party services. The instructions
    vary, depending on the module, but normally, the minimum actions required to add
    a report processor is for Puppet Server to have the module deployed in an environment
    and for the reports to have the name of the forwarder set. Writing custom report
    processors is beyond the scope of this book but details can be found at [https://puppet.com/docs/puppet/latest/reporting_write_processors.html.](https://puppet.com/docs/puppet/latest/reporting_write_processors.html'
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: In addition to logs and reports, we can see what condition the current Puppet
    Infrastructure is by calling the status APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing status APIs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Puppet provides a status endpoint that can be called at `GET /status/v1/services`.
    This endpoint returns the status of all known services on the server. This access
    is controlled by `auth.conf` and can be accessed locally via the Puppet CA certificates,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The final pipe to JQ (a command-line JSON processor) is optional but makes
    the output more readable. Here’s an example of the output Puppet Server’s status
    would provide:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to target an individual service by adding the service name to
    the URL – for example, `GET/status/v1/services/server`. For PE installations that
    have additional services, the specific port for each service should also be called.
    PE services will be discussed in [*Chapter 14*](B18492_14.xhtml#_idTextAnchor340).
  prefs: []
  type: TYPE_NORMAL
- en: The return code from these calls will be `200` for all services running, `404`
    when a service is not found, or `503` when a service state is in any state other
    than running.
  prefs: []
  type: TYPE_NORMAL
- en: The server state can be `running` when all services are running, `error` if
    any service reports an error, `starting` or `stopping` if any services are in
    those states, and `unknown` if any service reports an unknown state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Puppet Enterprise has an extra command-line option to call APIs via the `puppet
    infrastructure status` command, which produces an output similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the web console, you can find the Puppet Service’s status by clicking the
    **Puppet Services status** button, as per the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – Puppet Services status in the web console](img/B18492_13_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – Puppet Services status in the web console
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The `puppet status` command, which was depreciated in Puppet 5, was removed
    in Puppet 7\. It didn’t use API endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: The logs, reports, and statuses we have viewed so far allow us to observe what
    the Puppet infrastructure and clients are doing, but they don’t tell us about
    the overall performance of the infrastructure and its clients. Next, we will look
    at the metrics that Puppet supplies and how they can be used to monitor the performance
    and capacity of infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics, tuning, and scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To provide more detailed data on the performance and health of Puppet services
    via the services status API, the `level` flag can be set to `debug`; this will
    return metrics. For example, to return the metrics for Puppet Server and filter
    them using JQ, the following commands can be run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This would output data such as the following metric for the `puppet-v3-catalog`
    endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This gives us a `count` of how many calls have been made to the endpoint since
    the service last restarted. `mean` is the average response time over 5 minutes,
    while `aggregate` is the total time spent since the service started.
  prefs: []
  type: TYPE_NORMAL
- en: There are many metrics across all the different services. To find the definitions
    of these metrics, the API services can be viewed in the documentation (for example,
    [https://puppet.com/docs/pe/2021.7/status_api.html](https://puppet.com/docs/pe/2021.7/status_api.html)).
    However, overall, they are poorly documented and may take some exploration or
    you asking questions on Puppet’s Slack channels and support channels if you have
    a contract. Do not be concerned by most of the metrics having *experimental* in
    their title – most of the metrics have been available for years; they just haven’t
    had the experimental tag removed by Puppet.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In-depth details explaining how the underlying metrics library works for Puppet
    are available at [https://www.youtube.com/watch?v=czes-oa0yik&t=0s](https://www.youtube.com/watch?v=czes-oa0yik&t=0s),
    provided by the author of the metrics library.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s take a look at the dashboards that are used to display metrics data.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring metrics dashboards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Puppet provides three implementations that automate the process of gathering
    and displaying metrics data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Puppet Operational Dashboards**, available at [https://forge.puppet.com/modules/puppetlabs/puppet_operational_dashboards](https://forge.puppet.com/modules/puppetlabs/puppet_operational_dashboards),
    is a supported Puppet module from Puppet Forge that implements Telegraf, InfluxDB,
    and Grafana to provide mechanisms to send the API metric data, store it in a time
    series database, and visualize the data in preconfigured dashboards. Operational
    Dashboards supports both Puppet Enterprise and open source Puppet. An example
    of such a dashboard can be seen in the following figure:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 13.2 – Grafana Puppetserver performance dashboard](img/B18492_13_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – Grafana Puppetserver performance dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Splunk Plugin**, an app on the Splunk store, available at [https://splunkbase.splunk.com/app/4413/#/overview](https://splunkbase.splunk.com/app/4413/#/overview),
    can be added to your Splunk setup to provide preconfigured dashboards. The Splunk
    **HTTP event collector** (**HEC**) module can be found at [https://forge.puppet.com/modules/puppetlabs/splunk_hec](https://forge.puppet.com/modules/puppetlabs/splunk_hec).
    [https://forge.puppet.com/modules/puppetlabs/pe_event_forwarding](https://forge.puppet.com/modules/puppetlabs/pe_event_forwarding)
    can be combined with this module to send the metrics over HTTP to the HEC module.
    An example of a Splunk dashboard is shown in the following figure, with Puppet
    Server Memory graphed:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Splunk Puppet Server Memory dashboard](img/B18492_13_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Splunk Puppet Server Memory dashboard
  prefs: []
  type: TYPE_NORMAL
- en: Puppet teams work together to keep the Splunk and Grafana dashboards consistent.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Puppet Enterprise, there is also the `/opt/puppetlabs/puppet-metrics-collector`
    directory. These JSON files can then be searched using commands such as `grep`
    or `JQ` (assuming the terminal was in the metric collector directory). Two common
    queries, which will be explained in detail in the `average-free-jrubies` and `queue_depth`.
    These can be added like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: To make it easier to share this data, it can be archived by running the `/opt/puppetlabs/puppet-metrics-collector/scripts/create-metrics-archive`
    command, which will produce a `–r` flag if you wish to archive a set number of
    days.
  prefs: []
  type: TYPE_NORMAL
- en: Having looked at how to gather and display metrics, we will now discuss some
    common performance and capacity issues and how to manage them using metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying and avoiding common issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having set up logging, statuses, and metrics, we need to consider what to look
    for and how to examine our Puppet infrastructure. Normal monitoring of CPU, memory,
    and disk usage should be in place but there are some key functional areas to focus
    on. We will discuss these in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Catalog compilation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In [*Chapter 10*](B18492_10.xhtml#_idTextAnchor252), we learned how each **catalog
    compilation** required a JRuby instance to compile a catalog for each Puppet request
    and that the Puppet Primary or Compiler Servers provided this JRuby capacity.
    To calculate the necessary number of JRuby instances to handle the load for infrastructure,
    we can take the **run interval** (how often servers will check in) and divide
    this by the average length of compilation. This will sum up how many JRuby instances
    are required per server. We can take the number of Puppet Clients we expect the
    infrastructure to have and divide this by the previous figure to provide an estimate
    of the total required JRuby instances:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add this here: *Total JRuby Instances = Number of Puppet clients / ( run interval
    / average* *compilation length*'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the sizing for your infrastructure can be complicated. The number of
    JRuby instances on a primary server or compiler can be set by running `max-active-instances`
    in the `puppetserver.conf` file; this defaults to the number of CPUs – 1 for a
    range of 1 to 4\. Each JRuby instance will require memory in the JVM stack. For
    Puppet Enterprise, this file is controlled by setting the `hiera` value to `puppet_enterprise::master::puppetserver::jruby_max_active_instances:`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The total JVM stack memory is allocated by the Puppet Server startup script,
    which depending on the operating system, will be at `/etc/sysconfig/puppetserver`
    or `/etc/defaults/puppetserver`. This is set by the `xmx` argument, which can
    be calculated as each JRuby instance requiring 512 MB of memory by default and
    leaving 512 MB of headroom for other Java tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add this here: *Total stack heap size required = 512mb + maximum active instances
    ** *512MB*'
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended that you never exceed 32 GB of stack size for JVM. As seen
    from various field experiments, the maximum effective number of JRuby instances
    appears to be between 11 and 13\. These maximum figures tend to be for much larger
    estates and concern should be given to allow for compiler failures. In this case,
    it would be unwise to focus entirely on horizontal scaling; instead, it should
    be balanced with **vertical scaling** (having more compiler servers).
  prefs: []
  type: TYPE_NORMAL
- en: Sizing recommendations can be difficult when you’re just starting – it can be
    very unclear what your average compilation time will be and seconds in compilation
    can have a big impact, so it is wise to monitor both JRuby usage and catalog compilation
    time as the estate grows and look for outliers as they appear. Puppet has some
    guidelines for Puppet Enterprise sizing at [https://puppet.com/docs/pe/2021.7/tuning_infrastructure.html](https://puppet.com/docs/pe/2021.7/tuning_infrastructure.html).
  prefs: []
  type: TYPE_NORMAL
- en: When monitoring catalog performance, we have some key concerns. The `jruby.num-jrubies`
    and `jruby.num-free-jrubies` metrics show how many JRuby instances are on a server
    and how many are free. When looking at these metrics, the average used capacity
    of the infrastructure should be calculated. It is recommended that you avoid going
    beyond 80% usage as performance tends not to scale beyond this. You should also
    confirm that there are no issues with load balancers and that the free JRuby instance
    usage is even across compilers. One issue that can occur is known as **Thundering
    Herd**, where many servers request catalog compilations at the same time. This
    can be seen in the metrics as large spikes in JRuby instance usage. If you experience
    this, you can use the **puppet run scheduler** module at [https://forge.puppet.com/modules/reidmv/puppet_run_scheduler](https://forge.puppet.com/modules/reidmv/puppet_run_scheduler)
    to distribute the scheduling of Puppet agent runs.
  prefs: []
  type: TYPE_NORMAL
- en: If the capacity of the JRuby pool is exceeded, then requests will queue and
    timeout after a default of 10 seconds. The `borrow-timeout-count` metric provides
    a count of the number of requests that have timed out while waiting for a JRuby
    instance to become available.
  prefs: []
  type: TYPE_NORMAL
- en: Catalog runtimes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As highlighted previously, the catalog’s runtime has a huge impact on the number
    of JRuby instances that are required in the infrastructure. Looking at the `metrics-time-total`
    metric, which shows the compile time for report events sent, we can look at the
    average time to compile to help with our capacity calculations. We can also look
    at the distribution of these figures to see if we have any extreme outliers we
    would want to investigate in that catalog and its Puppet code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some key areas to check can be seen in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Metric Definition** | **Metric Name** |'
  prefs: []
  type: TYPE_TB
- en: '| Catalog compilation time | `Metrics-time-config_retrieval` |'
  prefs: []
  type: TYPE_TB
- en: '| Time to apply the catalog | `Metrics-time.catalog_application` |'
  prefs: []
  type: TYPE_TB
- en: '| Number of resources in the catalog | `Metrics-resources-total` |'
  prefs: []
  type: TYPE_TB
- en: '| Time to generate facts | `Metrics-changes-total` |'
  prefs: []
  type: TYPE_TB
- en: Table 12.1 – Catalog metrics
  prefs: []
  type: TYPE_NORMAL
- en: Within each of these measures, you should ensure that there was a reason for
    it to be an outlier. If the code or fact is complex or any particular resource
    is known to be slow, this may be normal, or it may be inefficient code that can
    be reviewed before it is applied to more servers, thus saving infrastructure capacity.
  prefs: []
  type: TYPE_NORMAL
- en: PuppetDB and PostgreSQL tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For PuppetD, the best metrics to monitor are `jvm-metrics.heap-memory.committed`
    and `jvm-metrics.heap-memory.used`. If the used memory’s size is regularly approaching
    the committed memory’s size, then it’s best to increase the stack’s size. Similar
    to compilers, this involves updating the `puppetdb` or `pe-puppetdb` config file
    at `/etc/sysconfig/` or `/etc/default/puppetdb`, respectively, depending on your
    operating system, and updating the `JAVA_ARGS` argument. For example, if you found
    that `jvm-metrics.heap-memory.committed` was set to 512 MB but `jvm-metrics.heap-memory.used`
    was approaching this limit regularly, the maximum heap size could be updated to
    `JAVA_ARGS ="-Xmx512m"` to `JAVA_ARGS="-Xmx1g"` in the config file. After doing
    this, you would need to restart the PuppetDB service. However, note that all jobs
    that have been queued due to them running out of memory would just continue after
    a restart. For Puppet Enterprise, this file can be controlled by setting the `hiera`
    value to `puppet_enterprise::profile::puppetdb::java_args:`.
  prefs: []
  type: TYPE_NORMAL
- en: Another good indication of performance is the queue depth, which is represented
    by the `puppetdb-status.status.queue_depth` metric. If this is high and there
    are free CPUs, it would be beneficial to increase the number of CPU threads available
    to PuppetDB. This can be done in the PuppetDB configuration file at `/etc/puppetlabs/puppetdb/conf.d`.
    If PuppetDB has been installed by a package in the `[command-processing]` section
    with the `threads` key or if the Puppet PuppetDB module has been used, as will
    be the case in Puppet Enterprise, the class should be adjusted using the module’s
    settings. In Puppet Enterprise, this can be done in the **node groups** section
    in the web console. Any changes that are made to threads will require you to restart
    the PuppetDB service.
  prefs: []
  type: TYPE_NORMAL
- en: The reverse scenario, where CPU usage is high and throttling but the PuppetDB
    queue is low, should allow threads to be released to improve the throughput of
    other services.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning sizing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To assist in getting the right server settings based on available hardware,
    Puppet Enterprise has the `puppet infrastructure` `tune` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'This calculates the optimal settings to apply for your servers. The following
    example output extracts only the suggested Hiera settings printed by the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This extracted data could be put in a Hiera file and classified against the
    primary server. Note that if the RAM is high enough, it will recommend configurations
    for heap sizes above 32 GB. This is sub-optimal, as we discussed when we looked
    at compilation sizing and issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is general advice:'
  prefs: []
  type: TYPE_NORMAL
- en: It may seem difficult to process the number of metrics, especially given the
    lack of clear definitions, but if the Splunk plugin or Operational dashboard is
    used, this can give you a view that’s consistent with what Puppet Support teams
    use and monitor. Learning how your estate normally behaves in these values and
    looking for spikes in the graph and relating them to others can go some way to
    finding issues.
  prefs: []
  type: TYPE_NORMAL
- en: Using Puppet’s knowledge base, which has been open to any user since April 2021,
    can help you search for issues. Looking at collections of articles such as [https://support.puppet.com/hc/en-us/sections/360000926413-Performance-tuning](https://support.puppet.com/hc/en-us/sections/360000926413-Performance-tuning)
    can assist you in gaining a deeper understanding of any issues that you experience.
  prefs: []
  type: TYPE_NORMAL
- en: Lab – configuring metric dashboards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having discussed metrics and Puppet’s two options for viewing them, we can configure
    the Splunk dashboard and the Puppet Operational dashboard to see the dashboards
    provided. Using the issues that were described in the previous section around
    PuppetDB and compiler capacity, find the graphs that would assist in your investigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure the Puppet operational dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: Choose one of your nodes to host the Puppet Operational dashboard and classify
    `puppet_operational_dashboards` on the web console as a node group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the node group’s PE Infrastructure Agent, add `puppet_operational_dashboards::enterprise_infrastructure`
    to the list of classes on the **Classes** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run `puppet` on all the nodes until the servers are showing clean.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in at `https://<public_ip_of_operational_dashboard_node>:3000` `user=admin
    password=admin`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Configure Splunk:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign up for a Splunk account at [https://www.splunk.com/en_us/sign-up.html?301=/page/sign_up](https://www.splunk.com/en_us/sign-up.html?301=/page/sign_up)
    (this is free).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose a different node to host Splunk Enterprise by classifying `splunk::enterprise`
    as a node group on the web console and pinning the chosen node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install the Puppet report viewer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in and download [https://splunkbase.splunk.com/app/4413/](https://splunkbase.splunk.com/app/4413/).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in to `https://<public_ip_of_splunk_server>:8000` `username`=`admin` and
    `password`=`changeme`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the cog to the top left of the **Apps** bar.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: On the next screen, select **upload app from file** at the top right.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the license to free in Splunk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Settings** at the top right.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the dropdown under system, select **Licensing**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **change** **license group**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **free license** and click **Save**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create an HEC token in Splunk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to **Settings** | **Data Input** in your Splunk console.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new HTTP Event Collector with a name of your choice.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure **Indexer acknowledgement** is not enabled.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next** and set **source type** to **Automatic**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure **App Context** is set to **Puppet** **Report Viewer**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the main index.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Set **Default Index** to **main**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Review** and then **Submit**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Classify `puppet_metrics_collector` with the `metrics_server_type` parameter
    set to `splunk_hec` on the PE Infrastructure node group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Classify `splunk_hec` on the `enable_reports` set to `true`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`events_reporting_enabled` set to `true`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`manage_routes` set to `true`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`token` set to `<token number of generated in` `step 5>`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`url` set to `https://<public_ip_of_splunk_server>:8088/services/collector`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in at `https://<public_ip_of_splunk_server>:8000` and run `index=* sourcetype=puppet:summary`
    to ensure data is being gathered (it may take some time to start).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that both the Puppet operational dashboard and Splunk have been configured,
    tour the various graphs and panels to find the graphs that are relevant to catalog
    capacity and PuppetDB performance.
  prefs: []
  type: TYPE_NORMAL
- en: If possible, leave Splunk set up for the next section as the inventory and inventory
    trend views are the dashboard views of the Facter terminus output.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know how to integrate Puppet’s status, logging, and metrics, we
    can look at a pattern that allows us to integrate Puppet with other services and
    provide self-service to Puppet users.
  prefs: []
  type: TYPE_NORMAL
- en: External data provider pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Puppet will not be the only source of configuration and information in your
    estate. There are likely to be numerous sources for **Configuration Management
    Databases** (**CMDBs**) such as ServiceNow or internally developed systems that
    are used by application teams to store their information. Several of your colleagues
    and internal customers will want to be able to create exceptions and customizations
    without having to understand Puppet code and the workflow for deployment. There
    will also be demands to be able to feed Puppet data back into external systems.
    The external data provider pattern allows this to happen by allowing you to do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Make changes in the classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add and change trusted facts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feed existing data in as a fact or Hiera data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Send Facter data to external sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having introduced the core concept of the external data provider pattern, we
    will now look at each of the technical components used within it.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding external data provider components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The underlying components of this pattern are shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – Core components of the external data provider pattern](img/B18492_13_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – Core components of the external data provider pattern
  prefs: []
  type: TYPE_NORMAL
- en: 'We will run through each to show how this pattern works. It is beyond the scope
    of this book to show you how to write each of these components, but we will detail
    where documentation exists for this. In the following section, sample implementations
    will be referenced:'
  prefs: []
  type: TYPE_NORMAL
- en: A **backend storage service** (**BSS**) allows you to store data for consumption.
    The technical solution for the BSS is not important, but it must be resilient
    and provide high throughput on reads.
  prefs: []
  type: TYPE_NORMAL
- en: This throughput can be calculated at *2 + <number of Hiera levels>* reads per
    Puppet agent run. To show how this would be calculated if an estate of 10,000
    servers used the default agent run time of 30 minutes and had a 5-level Hiera
    setup, this would be calculated as *(2+5) * 10,000 / 1,800 = 39 queries per second*
    (rounded up).
  prefs: []
  type: TYPE_NORMAL
- en: Tools such as CMDB or internal applications can be directly queried and act
    as the BSS, but the tool can deal with the workload.
  prefs: []
  type: TYPE_NORMAL
- en: The `trusted` external command, which was introduced in Puppet 6.11 and 7.0,
    allows a script to be run during Puppet runs and gather facts and classification
    information from external sources. This script should take the `certname` property
    of the client as its argument, return a JSON hash of facts, and exit with an error
    code for any unknown `certname`. This script can be configured by using the `trusted_external_command`
    setting in the `master/server` section of `puppet.conf` on each primary and compiler
    server. The facts that are returned by this command will be contained under `trusted.external.basename`,
    where `basename` is the name of the script. Since Puppet 6.17 and 7.0, it is also
    possible to use multiple trusted external commands by setting `trusted_external_command`
    to be a directory containing multiple scripts. This can be useful for querying
    multiple sources. Each source would then get a different base name. In the external
    data provider pattern, it is used to query the BSS.
  prefs: []
  type: TYPE_NORMAL
- en: The Hiera backend uses functions written in Ruby or Puppet to query APIs or
    other sources when Hiera lookups are performed. In the external data provider
    pattern, the backend queries the BSS for values. Documentation on this is available
    at [https://puppet.com/docs/puppet/latest/hiera_custom_backends.html](https://puppet.com/docs/puppet/latest/hiera_custom_backends.html).
  prefs: []
  type: TYPE_NORMAL
- en: Puppet allows pluggable backends known as **termini** and uses indirectors,
    as discussed in [*Chapter 10*](B18492_10.xhtml#_idTextAnchor252), to allow Ruby
    scripts to access key-value pairs at endpoints. Fact termini are Ruby scripts
    that access the fact endpoints and allow the data to be sent on to other external
    systems. Further details on this are available at [https://puppet.com/docs/puppet/latest/indirection.html](https://puppet.com/docs/puppet/latest/indirection.html)
    and [https://puppet.com/docs/puppet/latest/man/facts.html](https://puppet.com/docs/puppet/latest/man/facts.html).
  prefs: []
  type: TYPE_NORMAL
- en: External data provider implementations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the time of writing, no single implementation of the external data provider
    pattern implements all parts, but they can be used together to integrate multiple
    systems and purposes. The list of examples in this section is not meant to be
    exhaustive but should show the breadth of integrations that can be investigated.
    We will also provide documentation examples, which can be expanded on if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Satellite
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Red Hat Satellite can receive reports from Puppet Server through a report processor
    while using the module available at [https://forge.puppet.com/modules/puppetlabs/satellite_pe_tools](https://forge.puppet.com/modules/puppetlabs/satellite_pe_tools).
    However, it is also possible to use the `puppetserver_foreman` module to configure
    a trusted external command to gather the various configuration data from Satellite,
    such as smart parameters and organization as facts. With Puppet being removed
    as the default configuration management choice and instead used as an optional
    plugin, and Puppet versions not keeping up with development in the Satellite platform,
    as per [https://www.redhat.com/en/blog/upcoming-changes-puppet-functionality-red-hat-satellite](https://www.redhat.com/en/blog/upcoming-changes-puppet-functionality-red-hat-satellite),
    the use of this trusted external command allows Puppet Server’s functionality
    to be migrated as a separate Puppet infrastructure while the configuration is
    maintained in the Foreman component of Satellite. See the files/Satellite at [https://github.com/theforeman/puppet-puppetserver_foreman](https://github.com/theforeman/puppet-puppetserver_foreman)
    to see the trusted external command.
  prefs: []
  type: TYPE_NORMAL
- en: ServiceNow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several ServiceNow integrations have been developed for use with Puppet; the
    CMDB integration allows a trusted command provided by the module available at
    [https://forge.puppet.com/modules/puppetlabs/servicenow_cmdb_integration](https://forge.puppet.com/modules/puppetlabs/servicenow_cmdb_integration).
  prefs: []
  type: TYPE_NORMAL
- en: ServiceNow should only be used with BSS on a smaller scale since using a large
    number of nodes could overwhelm ServiceNow with queries. It provides a useful
    example of using the trusted command.
  prefs: []
  type: TYPE_NORMAL
- en: 'A better approach has been developed to ensure scaling where the ServiceNow
    graph connector connects to the Puppet API and gathers the necessary data: [https://store.servicenow.com/sn_appstore_store.do#!/store/application/42ae987a1b832c10fa34a8233a4bcb0b](https://store.servicenow.com/sn_appstore_store.do#!/store/application/42ae987a1b832c10fa34a8233a4bcb0b).'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Key Vault
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Key Vault’s integration is a function that calls `azure_key_vault::secret`
    in Puppet code. This can be used with a Hiera backend to access Azure Key Vault
    secrets. It is an approved module ([https://forge.puppet.com/modules/tragiccode/azure_key_vault](https://forge.puppet.com/modules/tragiccode/azure_key_vault)).
  prefs: []
  type: TYPE_NORMAL
- en: 1Password
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The 1Password integration is a Hiera backend that allows lookup calls to be
    made for secrets in the 1Password setup: [https://forge.puppet.com/modules/bryxxit/onepassword_lookup](https://forge.puppet.com/modules/bryxxit/onepassword_lookup).'
  prefs: []
  type: TYPE_NORMAL
- en: Vault
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The two Vault solutions (server-side and client-side) were discussed and demonstrated
    in [*Chapter 9*](B18492_09.xhtml#_idTextAnchor233), but to recap, it is the server-side
    Vault lookup that implements a Hiera backend lookup function called `hiera_vault`
    in the module. As discussed at [https://forge.puppet.com/modules/petems/hiera_vault](https://forge.puppet.com/modules/petems/hiera_vault),
    this allows secrets from Vault to be called via Hiera and compiled into code.
  prefs: []
  type: TYPE_NORMAL
- en: Puppet Data Service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Puppet Data Service** (**PDS**) provides one of the most complete implementations
    of the external data provider pattern, except it implements a fact terminus. The
    following components are a part of PDS:'
  prefs: []
  type: TYPE_NORMAL
- en: A REST API and CLI that allow user and application interaction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pluggable backend database to provide a BSS (at the time of writing, only
    PostgreSQL is supported)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Hiera backend to query the BSS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A trusted external command to query the BSS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PDS was designed to be less focused on a particular set of integrations and
    allow Puppet platform teams to leverage the external data provider pattern to
    provide self-service and reduce operational burdens. PDS has an install module
    ([https://github.com/puppetlabs/puppetlabs-puppet_data_service](https://github.com/puppetlabs/puppetlabs-puppet_data_service)).
    The code that makes up the application and API ([https://github.com/puppetlabs/puppet-data-service](https://github.com/puppetlabs/puppet-data-service))
    is packaged in `deb` and `rpm`, which are used by the `install` module. At the
    time of writing, both modules are only designed for a Puppet Enterprise installation,
    but nothing within the underlying setup limits the application to Puppet Enterprise,
    which means it can be adapted to open source Puppet.
  prefs: []
  type: TYPE_NORMAL
- en: Splunk
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the *Logging and status* section of this chapter, we discussed and demonstrated
    how the `splunk_hec` module provided communication from Puppet Server to the Splunk
    Hec URL on a Splunk server using the same modules fact terminus ([https://github.com/puppetlabs/puppetlabs-splunk_hec/blob/main/lib/puppet/indirector/facts/splunk_hec.rb](https://github.com/puppetlabs/puppetlabs-splunk_hec/blob/main/lib/puppet/indirector/facts/splunk_hec.rb)).
  prefs: []
  type: TYPE_NORMAL
- en: Facts from Puppet runs can be sent to Splunk, which can then be viewed in the
    Splunk app ([https://splunkbase.splunk.com/app/4413/](https://splunkbase.splunk.com/app/4413/))
    in terms of inventory and inventory trends.
  prefs: []
  type: TYPE_NORMAL
- en: Lab – hands-on with Splunk and Puppet Data Service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having discussed several integrations, if you left the Splunk installation or
    reinstallation as per the previous lab, you can log into Splunk and view the **inventory**
    and **inventory trend** tabs. Here, you will see the Facter terminus output and
    can experiment with viewing the data from your nodes.
  prefs: []
  type: TYPE_NORMAL
- en: In this part of the lab, you will see how PDS can be used to classify nodes,
    update Hiera data, and add trusted facts.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install PDS, you will need to perform the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Observe the `hiera.yaml` and `site.pp` file in the control repository you cloned
    and see how PDS will use them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the two required application roles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For the database server, do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a new node group from the PE console:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Add the `puppet_data_service::database` class to the PDS database group you
    created in the previous step.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Add your existing primary server to the group using the Rules tab node before
    following these steps.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Commit your changes.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For the PDS API servers, do the following
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `puppet_data_service::server` class
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Include the `database_host: <FQDN of your primary` `server>` parameter'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `sensitive pds_token` parameter. You can use [https://www.uuidgenerator.net/](https://www.uuidgenerator.net/)
    to generate a token
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Commit your changes.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run Puppet on all nodes until reports show unchanged.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an SSH session to the primary server and one of the nodes in separate
    terminal windows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the primary server, run the `pds-cli node upsert <fqdn_of_node> -c motd -e`
    `production` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the node, run `puppet agent –t`. In the output of the command, you will see
    that `motd` has been applied with default settings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the primary server, run `pds-cli hiera upsert nodes/<fqdn_of_node> motd::content
    -v '"Hello world` `its PDS\n"'`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the node, run `puppet agent –t`. In the output of the command, you will see
    that `motd` has been applied with the Hiera override we set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the primary, run `pds-cli node upsert <fqdn_of_node> -c motd -d ''{"status":
    "Testing"}'' -e production` and `pds-cli hiera upsert nodes/<fqdn_of_name> motd::content
    -v ''"Hello world, I am a PDS %{``trusted.external.pds.data.status} Server\n"''`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the node, run `puppet agent –t`. Observe that it applies the new `motd` with
    the Hiera override and value `testing` set for the trusted fact.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log into the console and look at the node and its facts to see if it has a trusted
    fact, `pds.data.status`, set to testing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we summarized the various log locations and showed you how
    logs could be turned into JSON and exported so that they can be handled in logging
    toolsets such as Elastic or Grafana, which can better index them for viewing and
    analysis. We learned how report processors can be used on Puppet Server to allow
    the reports to be generated by applying catalogs on clients. This allows them
    to be sent to tools such as Splunk and allows for advanced visualizations and
    searches. The available status APIs were discussed, indicating how an API call
    could be made to find the status of all running services or a particular service.
    Puppet Enterprise was shown to have a command line (`Puppet Infrastructure status`)
    and web console option to call this API. Using these mechanisms, you learned how
    to access critical logging and metrics to understand the current state of the
    system.
  prefs: []
  type: TYPE_NORMAL
- en: To use this information and understand the performance of the services in depth,
    you learned how Puppet metrics become available upon using the `debug` flag of
    the status API and how tools such as the Puppet Operational Dashboard and the
    Puppet plugin for Splunk could be used to gather this data and visualize it. Puppet
    Enterprise was noted as having the Metrics Collector module, which gathers metrics
    locally in JSON files, which can be viewed manually or exported.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand how these metrics and dashboards can be used, we reviewed
    some common issues, looking at how to size the infrastructure for catalog compilation
    and avoid issues such as Thundering Herd as servers squeeze demand and how PuppetDB
    could be adjusted as demand increases or decreases. Various infrastructure tuning
    tools were shown to be an option in PE to optimize settings for deployed hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we covered the external data provider pattern, which provides mechanisms
    for self-service and access to Puppet data on external services so that it can
    be integrated better. The core components of a backend storage service were shown
    to provide a store for data that could cope with the level of queries Puppet would
    make while trusted external commands and the Hiera backend were shown as ways
    to query that data. Fact termini were shown to be ways to export data from the
    BSS to external services.
  prefs: []
  type: TYPE_NORMAL
- en: Various implementations of these components were shown when using various Hiera
    backends, with 1Password, Azure Key Vault, and Vault being shown as ways to access
    external secret managers, while Satellite and ServiceNow were shown to have trusted
    commands that allowed data within those applications to be fed into Puppet code.
  prefs: []
  type: TYPE_NORMAL
- en: Puppet Data Service was shown to be one of the most complete implementations
    of the pattern and provides a solid design to allow for self-service of internal
    customers who would be able to access suitably exposed Puppet options without
    requiring full knowledge of the Git flow and Puppet language.
  prefs: []
  type: TYPE_NORMAL
- en: This coverage of the external data provider pattern showed you how powerful
    integrations can be made with Puppet Enterprise to feed data into and out of different
    tools and work toward building a platform with Puppet as a vital component.
  prefs: []
  type: TYPE_NORMAL
- en: Having covered the components of Puppet Server how to monitor performance at
    scale and integrate it, the next chapter will look at Puppet Enterprise-specific
    services and their components. It will describe what Puppet Enterprise is, how
    it differs from the open source version, what extra services it provides, and
    the reference architectures provided by Puppet to allow for easier scaling and
    tooling to automate a deployment and its status. Projects and integrations specifically
    for Puppet Enterprise will also be discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Part 4 – Puppet Enterprise and Approaches to the Adoption of Puppet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part will look at Puppet Enterprise and how it differs from open source.
    It will review some Puppet-related products that can extend Puppet Enterprise
    and some specific integrations for Puppet Enterprise. We will then discuss approaches
    that can help organizations successfully adopt Puppet. We will look at correctly
    scoping use cases to benefit from regular delivery, and how Puppet can work within
    platform engineering as well as with heritage estates, and even in highly regulated,
    change-managed estates.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 14*](B18492_14.xhtml#_idTextAnchor340), *A Brief Overview of Puppet
    Enterprise*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 15*](B18492_15.xhtml#_idTextAnchor359), *Approaches to Adoption*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
