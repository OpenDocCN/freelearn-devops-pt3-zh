["```\nconst (\n    kubectl = \"kubectl\"\n    git = \"git\"\n)\n_, err := exec.LookPath(kubectl)\nif err != nil {\n    return fmt.Errorf(\"cannot find kubectl in our PATH\")\n}\n_, err := exec.LookPath(git)\nif err != nil {\n    return fmt.Errorf(\"cannot find git in our PATH\")\n}\n```", "```\ncmd := exec.CommandContext(ctx, kubectl, \"apply\", \"-f\", config)\n```", "```\nfunc hostAlive(ctx context.Context, host net.IP) bool {\n        cmd := exec.CommandContext(ctx, ping, \"-c\", \"1\", \"-t\", \"2\", host.String())\n        if err := cmd.Run(); err != nil {\n            return false\n        }\n        return true\n}\n```", "```\nfunc runUname(ctx context.Context, host net.IP, user string) \n(string, error) {\n        if _, ok := ctx.Deadline(); !ok {\n                var cancel context.CancelFunc\n                ctx, cancel = context.WithTimeout(ctx, 5*time.Second)\n                defer cancel()\n        }\n        login := fmt.Sprintf(\"%s@%s\", user, host)\n        cmd := exec.CommandContext(\n                ctx,\n                ssh,\n                \"-o StrictHostKeyChecking=no\",\n                \"-o BatchMode=yes\",\n                login,\n                \"uname -a\",\n        )\n        out, err := cmd.CombinedOutput()\n        if err != nil {\n                return \"\", err\n        }\n        return string(out), nil\n}\n```", "```\ntype record struct{\n    Host net.IP\n    Reachable bool\n    LoginSSH bool\n    Uname string\n}\n```", "```\nfunc scanPrefixes(ipCh chan net.IP) chan record {\n        ch := make(chan record, 1)\n        go func() {\n                defer close(ch)\n                limit := make(chan struct{}, 100)\n                wg := sync.WaitGroup{}\n                for ip := range ipCh {\n                        limit <- struct{}{}\n                        wg.Add(1)\n                        go func(ip net.IP) {\n                                defer func() { <-limit }()\n                                defer wg.Done()\n                                ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second))\n                                defer cancel()\n                                rec := record{Host: ip}\n                                if hostAlive(ctx, ip) {\n                                        rec.Reachable = true\n                                }\n                                ch <- rec\n                        }(ip)\n                }\n                wg.Wait()\n        }()\n        return ch\n}\n```", "```\nfunc unamePrefixes(user string, recs chan record) chan record\n```", "```\nfunc main() {\n    _, err := exec.LookPath(ping)\n    if err != nil {\n        log.Fatal(\"cannot find ping in our PATH\")\n    }\n    _, err := exec.LookPath(ssh)\n    if err != nil {\n        log.Fatal(\"cannot find ssh in our PATH\")\n    }\n    if len(os.Args) != 2 {\n        log.Fatal(\"error: only one argument allowed, the network CIDR to scan\")\n    }\n    ipCh, err := hosts(os.Args[1])\n    if err != nil {\n            log.Fatalf(\"error: CIDR address did not parse: %s\", err)\n    }\n    u, err := user.Current()\n    if err != nil {\n        log.Fatal(err)\n    }\n```", "```\n    scanResults := scanPrefixes(ipCh)\n    unameResults := unamePrefixes(u.Username, scanResults)\n    for rec := range unameResults {\n        b, _ := json.Marshal(rec)\n        fmt.Printf(\"%s\\n\", b)\n    }\n}\n```", "```\nauth := ssh.Password(\"password\")\n```", "```\nfunc publicKey(privateKeyFile string) (ssh.AuthMethod, error) {\n    k, err := os.ReadFile(privateKeyFile)\n    if err != nil {\n            return nil, err\n    }\n    signer, err := ssh.ParsePrivateKey(k)\n    if err != nil {\n            return nil, err\n    }\n    return ssh.PublicKeys(signer), nil\n}\n```", "```\nconfig := &ssh.ClientConfig {\n    User: user,\n    Auth: []ssh.AuthMethod{auth},\n    HostKeyCallback: ssh.InsecureIgnoreHostKey(),\n    Timeout: 5 * time.Second,\n}\n```", "```\nconn, err := ssh.Dial(\"tcp\", host, config)\nif err != nil {\n    fmt.Println(\"Error: could not dial host: \", err)\n    os.Exit(1)\n}\ndefer conn.Close()\n```", "```\nfunc combinedOutput(conn *ssh.Client, cmd string) (string, error) {\n    sess, err := conn.NewSession()\n    if err != nil {\n            return \"\", err\n    }\n    defer sess.Close()\n    b, err := sess.Output(cmd)\n    if err != nil {\n            return \"\", err\n    }\n    return string(b), nil\n}\n```", "```\nconfig := &ssh.ClientConfig {\n    User:            user,\n    Auth:            []ssh.AuthMethod{auth},\n    HostKeyCallback: ssh.InsecureIgnoreHostKey(),\n}\nconn, err := ssh.Dial(\"tcp\", host, config)\nif err != nil {\n    return err\n}\ne, _, err := expect.SpawnSSH(conn, 5 * time.Second)\nif err != nil {\n    return err\n}\ndefer e.Close()\n```", "```\nvar (\n    promptRE = regexp.MustCompile(`\\$ `)\n    aptCont = regexp.MustCompile(`Do you want to continue\\? \\[Y/n\\] `)\n    aptAtNewest = regexp.MustCompile(`is already the newest`)\n)\n_, _, err = e.Expect(promptRE, 10*time.Second)\nif err != nil {\n        return fmt.Errorf(\"did not get shell prompt\")\n}\n```", "```\nif err := e.Send(\"sudo apt-get install expect\\n\"); err != nil {\n        return fmt.Errorf(\"error on send command: %s\", err)\n}\n```", "```\nf _, _, ecase, err := e.ExpectSwitchCase(\n    []expect.Caser{\n            &expect.Case{\n                    R: aptCont,\n                    T: expect.OK(),\n            },\n            &expect.Case{\n                    R: aptAtNewest,\n                    T: expect.OK(),\n            },\n    },\n    10*time.Second,\n)\nif err != nil {\n        return fmt.Errorf(\"apt-get install did not send what we expected\")\n}\n```", "```\nswitch ecase{\ncase 0:\n        if err := e.Send(\"Y\\n\"); err != nil {\n                return err\n        }\n}\n```", "```\n_, _, err = e.Expect(promptRE, 10*time.Second)\nif err != nil {\n        return fmt.Errorf(\"did not get shell prompt\")\n}\nreturn nil\n```", "```\ntype stateFn func(ctx context.Context) (stateFn, error)\ntype actions struct {\n    ... // Some set of attributes\n}\nfunc (s *actions) run(ctx context.Context) (err error) {\n    fn := s.rmBackend\n    if s.failedState != nil {\n        fn = s.failedState\n    }\n    s.started = true\n    for {\n        if ctx.Err() != nil {\n            s.err = ctx.Err()\n            return ctx.Err()\n        }\n        fn, err = fn(ctx)\n        if err != nil {\n            s.failedState = fn\n            s.err = err\n            return err\n        }\n        if fn == nil {\n            return nil\n        }\n    }\n}\nfunc (a *actions) rmBackend(ctx context.Context) (stateFn, error) {...}\nfunc (a *actions) jobKill(ctx context.Context) (stateFn, error) {...}\nfunc (a *actions) cp(ctx context.Context) (stateFn, error) {...}\nfunc (a *actions) jobStart(ctx context.Context) (stateFn, error) {...}\nfunc (a *actions) reachable(ctx context.Context) (stateFn, error) {...}\nfunc (a *actions) addBackend(ctx context.Context) (stateFn, error) {...}\n```", "```\nfunc (a *actions) rmBackend(ctx context.Context) (stateFn, error) {\n    err := a.lb.RemoveBackend(ctx, a.config.Pattern, a.backend)\n    if err != nil {\n        return nil, fmt.Errorf(\"problem removing backend from pool: %w\", err)\n    }\n    return a.jobKill, nil\n}\n```", "```\nfunc (a *actions) jobKill(ctx context.Context) (stateFn, error) {\n    pids, err := a.findPIDs(ctx)\n    if err != nil {\n        return nil, fmt.Errorf(\"problem finding existing PIDs: %w\", err)\n    }\n    if len(pids) == 0 {\n        return a.cp, nil\n    }\n    if err := a.killPIDs(ctx, pids, 15); err != nil {\n        return nil, fmt.Errorf(\"failed to kill existing PIDs: %w\", err)\n    }\n    if err := a.waitForDeath(ctx, pids, 30*time.Second); err != nil {\n        if err := a.killPIDs(ctx, pids, 9); err != nil {\n            return nil, fmt.Errorf(\"failed to kill existing PIDs: %w\", err)\n        }\n        if err := a.waitForDeath(ctx, pids, 10*time.Second); err != nil {\n            return nil, fmt.Errorf(\"failed to kill existing PIDs after -9: %w\", err)\n        }\n        return a.cp, nil\n    }\n    return a.cp, nil\n}\n```", "```\ntype workflow struct {\n    config *config\n    lb     *client.Client\n    failures int32\n    endState endState\n    actions []*actions\n}\n```", "```\nfunc (w *workflow) run(ctx context.Context) error {\n    preCtx, cancel := context.WithTimeout(ctx, 30*time.Second)\n    if err := w.checkLBState(preCtx); err != nil {\n        w.endState = esPreconditionFailure\n        return fmt.Errorf(\"checkLBState precondition fail: %s\", err)\n    }\n    cancel()\n```", "```\nfor i := 0; i < len(w.actions) && \nint32(i) < w.config.CanaryNum; i++ {\n    color.Green(\"Running canary on: %s\", w.actions[i].endpoint)\n    ctx, cancel := context.WithTimeout(ctx, 10*time.Minute)\n    err := w.actions[i].run(ctx)\n    cancel()\n    if err != nil {\n        w.endState = esCanaryFailure\n        return fmt.Errorf(\"canary failure on endpoint(%s): %w\\n\", w.actions[i].endpoint, err)\n    }\n    color.Yellow(\"Sleeping after canary for 1 minutes\")\n    time.Sleep(1 * time.Minute)\n}\n```", "```\nlimit := make(chan struct{}, w.config.Concurrency)\nwg := sync.WaitGroup{}\nfor i := w.config.CanaryNum; int(i) < len(w.actions); i++ {\n    i := i\n    limit <- struct{}{}\n    if atomic.LoadInt32(&w.failures) > w.config.MaxFailures {\n        break\n    }\n    wg.Add(1)\n    go func() {\n        defer func(){<-limit}()\n        defer wg.Done()\n        ctx, cancel := context.WithTimeout(ctx, 10*time.Minute)\n        color.Green(\"Upgrading endpoint: %s\", \nw.actions[i]. endpoint)\n        err := w.actions[i].run(ctx)\n        cancel()\n        if err != nil {\n            color.Red(\"Endpoint(%s) had upgrade error: %s\", w.actions[i].endpoint, err)\n            atomic.AddInt32(&w.failures, 1)\n        }\n    }()\n}\nwg.Wait()\n```", "```\n{\n    \"Concurrency\": 2,\n    \"CanaryNum\": 1,\n    \"MaxFailures\": 2,\n    \"Src\": \"/home/[user]/rollout/webserver\",\n    \"Dst\": \"/home/[user]/webserver\",\n    \"LB\": \"10.0.0.4:8081\",\n    \"Pattern\": \"/\",\n    \"Backends\": [\n            \"10.0.0.5\",\n            \"10.0.0.6\",\n            \"10.0.0.7\",\n            \"10.0.0.8\",\n            \"10.0.0.9\"\n    ],\n    \"BackendUser\": \"azureuser\",\n    \"BinaryPort\": 8082\n}\n```", "```\n{\n    \"cmdline\": [\"/tmp/go-build7781/c0021/exe/main\"],\n    \"cpu\": \"8\",\n    \"goroutines\": \"16\",\n}\n```", "```\nsyntax = \"proto3\";\npackage system.agent;\noption go_package = \"github.com/[repo]/proto/agent\";\nmessage InstallReq {\n    string name = 1;\n    bytes package = 2;\n    string binary = 3;\n    repeated string args = 4;\n}\nmessage InstallResp {}\nmessage CPUPerfs {\n    int32 resolutionSecs = 1;\n    int64 unix_time_nano = 2;\n    repeated CPUPerf cpu = 3;\n}\nmessage CPUPerf {\n    string id = 1;\n    int32 user = 2;\n    int32 system = 3;\n    int32 idle = 4;\n    int32 io_wait = 5;\n    int32 irq = 6;\n}\nmessage MemPerf {\n    int32 resolutionSecs = 1;\n    int64 unix_time_nano = 2;\n    int32 total = 3;\n    int32 free = 4;\n    int32 avail = 5;\n}\nservice Agent {\n   rpc Install(InstallReq) returns (InstallResp) {};\n}\n```", "```\nfunc (a *Agent) Install(ctx context.Context, req \n*pb.InstallReq) (*pb.InstallResp, error) {\n    if err := req.Validate(); err != nil {\n        return nil, status.Error(codes.InvalidArgument, \nerr.Error())\n    }\n    a.lock(req.Name)\n    defer a.unlock(req.Name, false)\n    loc, err := a.unpack(req.Name, req.Package)\n    if err != nil {\n        return nil, err\n    }\n    if err := a.migrate(req, loc); err != nil {\n        return nil, err\n    }\n    if err := a.startProgram(ctx, req.Name); err != nil {\n        return nil, err\n    }\n    return &pb.InstallResp{}, nil\n}\n```", "```\nfunc (a *Agent) collectCPU(resolution int) error {\n    stat, err := linuxproc.ReadStat(\"/proc/stat\")\n    if err != nil {\n        return err\n    }\n    v := &pb.CPUPerfs{\n        ResolutionSecs: resolution,\n        UnixTimeNano:   time.Now().UnixNano(),\n    }\n    for _, p := range stat.CPUStats {\n        c := &pb.CPUPerf{\n            Id:     p.Id,\n            User:   int32(p.User),\n            System: int32(p.System),\n            Idle:   int32(p.Idle),\n            IoWait: int32(p.IOWait),\n            Irq:    int32(p.IRQ),\n        }\n        v.Cpu = append(v.Cpu, c)\n    }\n    a.cpuData.Store(v)\n    return nil\n}\n```", "```\nfunc (a *Agent) perfLoop() error {\n    const resolutionSecs = 10\n    if err := a.collectCPU(resolutionSecs); err != nil {\n        return err\n    }\n    expvar.Publish(\n        \"system-cpu\",\n        expvar.Func(\n            func() interface{} {\n                return a.cpuData.Load().(*pb.CPUPerfs)\n            },\n        ),\n    )\n    go func() {\n        for {\n            time.Sleep(resolutionSecs * time.Second)\n            if err := a.collectCPU(resolutionSecs); err != nil {\n                log.Println(err)\n            }\n        }\n    }()\n        return nil\n}\n```", "```\n\"system-cpu\": {\"resolutionSecs\":10,\"unixTimeNano\":\"1635015190106788056\",\"cpu\":[{\"id\":\"cpu0\",\"user\":13637,\"system\":10706,\"idle\":17557545,\"ioWait\":6663},{\"id\":\"cpu1\",\"user\":12881,\"system\":22465,\"idle\":17539705,\"ioWait\":2997}]},\n\"system-mem\": {\"resolutionSecs\":10,\"unixTimeNano\":\"163501519010 6904757\",\"total\":8152984,\"free\":6594776,\"avail\":7576540}\n```"]