- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Measuring the Process and Solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We measure to see how far our efforts have progressed. This measurement has
    multiple dimensions. We examine whether we are achieving Lean flow and delivering
    work properly. Following that, we deploy the work to see if the changes work in
    the environment and whether the environment is safe. Finally, we gauge whether
    the changes created add value and are worthy of continued development.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at the measurements used to answer the questions
    posed above. We will look at metrics to determine the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Whether we are on track to deliver the solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The health of our environments before and after our solution is delivered
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether our solution is delivering on hypothesized value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring solution delivery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 4*](B18756_04.xhtml#_idTextAnchor086), *Leveraging* *Lean Flow
    to Keep the Work Moving*, we looked at practices to establish and maintain Lean
    flow. We need metrics to evaluate whether we have achieved that Lean flow and
    whether we can be predictable in our commitments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Common metrics to evaluate Lean flow are outlined in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: Cycle time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WIP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blockers or bottlenecks in the process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A useful tool to obtain these metrics is a cumulative flow diagram. We will
    take a close look at a cumulative flow diagram to find these metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Cycle time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a value stream, cycle time is the time it takes for a piece of work to be
    delivered after it has been accepted and goes through the entire development process.
  prefs: []
  type: TYPE_NORMAL
- en: We saw in [*Chapter 4*](B18756_04.xhtml#_idTextAnchor086), *Leveraging* *Lean
    Flow to Keep the Work Moving*, the many factors that can affect cycle time. These
    factors included too much WIP, large batch sizes, high utilization, and variability.
  prefs: []
  type: TYPE_NORMAL
- en: Another factor that can affect cycle time is if there is waste in the development
    process. This waste may come in the form of delays or *wait times* as work gets
    handed off from one phase to the next.
  prefs: []
  type: TYPE_NORMAL
- en: Regular measurement of cycle time allows us to see how long it takes for a value
    stream to deliver work. Increases in cycle time can allow us to determine if the
    root cause is one of the factors mentioned. Once determined, corrective steps
    can be taken to put cycle time back to its previous length of time.
  prefs: []
  type: TYPE_NORMAL
- en: Lead time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Lead time and cycle time are frequently confused with each other. The big difference
    between them is the perspective: while lead time is from the customer’s perspective,
    cycle time is from the perspective of the value stream and is an internal metric.'
  prefs: []
  type: TYPE_NORMAL
- en: Lead time is the length of time a customer waits for delivery of an item of
    work after a request for that work. As shown in the following diagram, lead time
    is made up of cycle time as well as any *wait time* for the value stream to accept
    and start the work.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Illustration of cycle time and lead time](img/B18756_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Illustration of cycle time and lead time
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding illustration, we can improve two times to improve the lead
    time. We could improve the wait time or we could improve the cycle time. Most
    organizations strive to improve cycle times with the added benefit of improving
    the lead time.
  prefs: []
  type: TYPE_NORMAL
- en: WIP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By now, we should be familiar with **WIP** or **Work in Progress/Process** as
    the work that a value stream has started but not finished. We have seen the ill
    effects and consequences of too much WIP.
  prefs: []
  type: TYPE_NORMAL
- en: WIP is visible on the Kanban board shown in the following illustration.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Kanban board with WIP highlighted](img/B18756_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Kanban board with WIP highlighted
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we can count the items and determine our WIP is six.
  prefs: []
  type: TYPE_NORMAL
- en: Throughput
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Up to this point, we have looked at metrics that are units, either of time or
    quantity. Throughput is the only metric we look at that is basically a rate. In
    other words, how much work is accomplished in a given unit of time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughput is basically the number of units of work completed in a set period
    of time. Scrum practitioners know of this metric as velocity: the sum total of
    story points for stories completed in a sprint (a fixed period of time; often
    two weeks). Other Agile methodologies look at other units of work (stories, features,
    etc.) delivered per standard unit of time (week, month).'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that cycle time has an inverse relationship with throughput for a
    value stream. The greater the throughput, the shorter the cycle time.
  prefs: []
  type: TYPE_NORMAL
- en: Blockers and bottlenecks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To ensure Lean flow, we need to find and resolve those impediments that are
    preventing that flow from occurring. These may be temporary or systemic blocks
    preventing one or more pieces of work from progressing through the process.
  prefs: []
  type: TYPE_NORMAL
- en: Vigilance on these blockers may require daily checks to see if the blockage
    is still occurring and escalation if resolving the block has not occurred for
    several days.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring with cumulative flow diagrams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A cumulative flow diagram is an easy way to examine cycle time, lead time, throughput,
    and WIP. You can also inspect and find bottlenecks in your process.
  prefs: []
  type: TYPE_NORMAL
- en: The cumulative flow diagram is a graph of the history of work that the value
    stream works through over time. The *x* axis of the cumulative flow diagram refers
    to time. The *y* axis refers to the count of work. Each band in the cumulative
    flow diagram refers to a step in the workflow that is derived from columns on
    a Kanban board. An example cumulative flow diagram follows.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Cumulative flow diagram](img/B18756_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Cumulative flow diagram
  prefs: []
  type: TYPE_NORMAL
- en: In general, we should see the bands move upward and grow from left to right.
    The entrance and exit lines for a band that represents a process step in the workflow
    should be roughly parallel in a situation where flow occurs. If the entrance and
    exit lines grow apart, creating a large growing area, that’s an indicator that
    a bottleneck exists in that part of the process. We can see such a bottleneck
    in the following diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Annotation of bottleneck in cumulative flow diagram](img/B18756_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Annotation of bottleneck in cumulative flow diagram
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at how we can use the cumulative flow diagram to measure cycle
    time, WIP, and throughput.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring WIP with the cumulative flow diagram
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To measure the WIP that a value stream has at a given point in time, do the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Start at the point where the boundary between the band corresponding to the
    Backlog or **To Do** column and the band corresponding to the first **In Progress**
    column resides. In our example, this is the boundary between the **To Do** band
    and the **In Progress** band. We want to look at only the work that has started
    and, thus, beyond the **To** **Do** state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make a note of how many units of work that is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw a vertical line down through the other bands until you reach the boundary
    between the band representing the last **In Progress** column and the band representing
    the **Done** column. In our example, we draw the line through the **In Progress**
    band and the **IN REVIEW** band. Make a note of how many units of work that is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subtract the second number from the first number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following diagram illustrates the method described.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Calculation of WIP](img/B18756_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Calculation of WIP
  prefs: []
  type: TYPE_NORMAL
- en: Note that you can use the same method on a smaller scale to find the number
    of **In Progress** issues in a single column at a point in time by looking at
    the two lines that form the band for the column of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring cycle time with the cumulative flow diagram
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To measure cycle time, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Find and mark a spot when an issue has moved from the band representing the
    **To Do** or Backlog column and note its date.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw a horizontal line until you reach the spot where it touches the band representing
    the **Done** column. Mark the second date.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Subtract the first date from the second, and you will get a measure of the cycle
    time for one issue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Cycle time calculation](img/B18756_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – Cycle time calculation
  prefs: []
  type: TYPE_NORMAL
- en: The steps are illustrated in the preceding diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring throughput with the cumulative flow diagram
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Throughput on a cumulative flow diagram is done by finding a line and determining
    its slope:'
  prefs: []
  type: TYPE_NORMAL
- en: Mark one point of the line and make a note of the date and number of issues.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On a higher point on the line, make a note of the date and number of issues.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The numerator will be the number of issues on the second point minus the number
    of issues on the first point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The denominator will be the period of time between the two points.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An example of this calculation is shown in the following example.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Throughput calculation](img/B18756_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – Throughput calculation
  prefs: []
  type: TYPE_NORMAL
- en: Note that areas of no throughput will appear as horizontal lines.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, for our examples, we have found the following measurements:'
  prefs: []
  type: TYPE_NORMAL
- en: On January 22, our WIP was six issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our cycle time for one issue was one month
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our throughput for issues moving from **IN REVIEW** to **Done** was 0.06/day
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having evaluated the measurements taken to ensure Lean flow and timely delivery
    of solutions, we need to take a closer look at ensuring that quality is present
    during deployment and before release. To do this, let’s look at the important
    measurements to capture from the staging and production environments.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at full stack telemetry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now turn our attention from the process of developing the product to the
    product itself. Throughout the development process, we ran testing in our CI/CD
    pipeline. The passing of those tests is an indication that the product is working
    as intended. Now, as the product is deployed in multiple environments, we want
    to ensure proper operation. To do this, we monitor performance in those environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Monitoring is the act of measuring our environment. We measure or capture the
    following three key types of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Logs**: Logs are an indication that a notable event has occurred. These events
    may be classified to determine their severity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traces**: Traces show the path inside an application and the messages sent
    by the application for a given business transaction. Timing information may also
    be included. The information from traces helps determine the correct function
    and performance when troubleshooting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics**: Metrics are indicators of the current state of the system and
    its components. Periodic measurements are taken to determine good or bad trends
    over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We collect these types of data artifacts through monitoring to answer the following
    questions about the environment that contains the system and its components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Security**: Are security vulnerabilities present? Has the system been hacked?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance**: Is the system performing properly? Are transactions following
    the expected paths?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliability**: Is the system up and performing well?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To answer these questions, monitoring takes measurements from multiple perspectives.
    A few of the key perspectives follow:'
  prefs: []
  type: TYPE_NORMAL
- en: Application performance monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Infrastructure monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a closer look at these elements of full stack telemetry.
  prefs: []
  type: TYPE_NORMAL
- en: Application performance monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When looking to see if an application is performing adequately in an environment,
    there are usually two perspectives that are taken into account:'
  prefs: []
  type: TYPE_NORMAL
- en: How do users perceive the performance of the application? This may be seen as
    user load or response times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much of our resources (e.g., allocated memory) is the application using?
    This is typically measured as a change in capacity from a previous state or configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In 2010, Gartner looked at expanding these sets of measures into five dimensions
    called the APM Conceptual Framework. These dimensions are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: End user experience (e.g., response times)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runtime application architecture (e.g., garbage collection events)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Middleware components (e.g., database reads and writes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many of the applications that have their performance measured by application
    performance monitoring are web-based applications with a web browser or mobile
    app user interface. The reason for this is the easy collection of metrics that
    span the five dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Many monitoring tools, especially ones detailed in [*Chapter 3*](B18756_03.xhtml#_idTextAnchor066),
    *Automation for Efficiency and Quality*, have features that touch all five of
    these dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: With the growing popularity of containers and microservices, application performance
    monitoring has had to look at creating accurate measurements of performance within
    a container or microservice. Because of this, there is some overlap between application
    performance monitoring and infrastructure monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Infrastructure monitoring is used to measure the resources of the entire system
    or environment. This is usually identified in terms of the following utilizations:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory (RAM) utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage availability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Historically, infrastructure monitoring was important for on-premises equipment,
    such as *bare-metal* servers. With the growth of cloud environments, infrastructure
    monitoring tools need to measure dynamically allocated resources that will be
    instantaneously created and destroyed depending on need.
  prefs: []
  type: TYPE_NORMAL
- en: Network monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Network monitoring measures the performance of the organization’s network to
    discover slow performance or outage situations. Generally, network monitoring
    systems keep track of the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Availability of network resources (e.g., connection uptime, connection speed)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Networking hardware status
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network interface state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A growing area for network monitoring is ensuring that security in terms of
    integrity, accessibility, and privacy is maintained. Some network defenses to
    ensure security include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Network Access** **Control** (**NAC**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firewalls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Antivirus/anti-malware software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Virtual Private** **Networks** (**VPNs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Email security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All the tools that perform monitoring will create logs of all activities and
    measurements, from critical alerts to informational notices. Log management collects
    these events as well as performing the following activities:'
  prefs: []
  type: TYPE_NORMAL
- en: Aggregation into a central location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log rotation and disposal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search and reporting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Properly managed logs are needed both during the development process and afterward
    for several purposes. These include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Determining whether tests pass
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting application and environment failures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating customer feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While collecting the logs, traces, and metrics is important, the ability to
    sift through all that data when something goes wrong is also important. For that,
    we turn to observability. Let’s discuss what to do with that monitoring information.
  prefs: []
  type: TYPE_NORMAL
- en: Observability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The mountain of data created by collecting logs, traces, and metrics through
    monitoring now introduces the following new questions:'
  prefs: []
  type: TYPE_NORMAL
- en: When something wrong occurs, can I quickly find the data in the logs, traces,
    and metrics to understand the root cause and find a solution?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can I use the data I’ve collected in logs, traces, and metrics to predict when
    problems may occur and try to prevent them from occurring?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Observability looks to answer these questions by shifting from collecting the
    data to understanding the data itself to identify its current state. Doing so
    moves beyond just monitoring to include the following activities:'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis of logs, traces, and metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking for correlation between the logs, traces, metrics, and specific events,
    such as outages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualization and exploration of data through dashboards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerts and notifications when problems occur
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observability helps enforce a higher level of systems thinking by allowing teams
    to understand the cause and effect the changes have on the environment. By understanding
    what causes changes beneficial to the environment, teams can incorporate the correct
    changes for better outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having ensured that the solution is of sufficient quality, we come upon the
    greater test: does the solution developed provide sufficient value to our customers
    to the point that they will love it? To evaluate this, we need to take measurements
    of outcome-based metrics. This is the topic of the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the value proposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s difficult to apply an objective measurement to a subjective quality such
    as value. What we can do is measure actions taken by our customer or feedback
    that our customer has given in terms of survey responses or thoughts during specific
    events such as reviews.
  prefs: []
  type: TYPE_NORMAL
- en: When looking at the measurements for value, some metrics may be collected too
    late to allow a value stream to know when to pivot. Examples of this include **Profit
    & Loss** (**P&L**) or **Return on Investment** (**RoI**). So, other metrics that
    can act as leading indicators are needed. The practice of collecting leading indicators
    to allow pivots or continued development is called *innovation accounting* by
    Eric Ries in his book, *The* *Lean Startup*.
  prefs: []
  type: TYPE_NORMAL
- en: The Innovation Accounting framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ries describes the method of hypothesizing and learning as the **Innovation
    Accounting** framework. In this framework, teams work to establish hypotheses
    of what the customer wants, develop those hypotheses, and then measure and determine
    further actions. This is done in a three-phase cycle in which the following is
    done:'
  prefs: []
  type: TYPE_NORMAL
- en: Look at the present situation and establish a baseline hypothesis through a
    **Minimum Viable Product** (**MVP**) or development of *just enough* of a product
    or its features to bring to a customer and obtain feedback as validation of the
    hypothesis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on metrics, make small adjustments to the MVP.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the metrics indicate success, continue the refinement of the MVP. If metrics
    tell you otherwise, pivot to something new.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the Innovation Accounting framework, the metrics gathered must be carefully
    chosen, so they don’t end up being **vanity metrics**. Vanity metrics tell a good
    story but provide no meaningful insights. To avoid a metric from falling into
    the vanity metric category, Ries recommends they have the following three qualities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Actionable**: Does the metric show clear cause and effect? In other words,
    could you replicate the results by performing the same actions?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accessible**: Does everyone on the value stream have access to the same data,
    and is that data understood by all?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auditable**: Is there credibility to the report?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics that work with Innovation Accounting will depend on the end product
    developed by the value stream and customer interaction with the product. We will
    look at a few of the leading metric collections used to measure value.
  prefs: []
  type: TYPE_NORMAL
- en: Pirate metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For many products available and sold to end user customers, such as **Software
    as a Service** (**SaaS**) or web-based products, *pirate* metrics offer the best
    guidance on whether development and marketing efforts are bearing fruit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pirate metrics were devised by Dave McClure in 2007\. They get their name from
    the acronym formed when we look at the first letter of the five phases (**AARRR**),
    which sounds like the noise a pirate makes. These phases are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Acquisition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Activation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retention
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Referral
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revenue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a close look at each phase.
  prefs: []
  type: TYPE_NORMAL
- en: Acquisition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this phase, metrics look to determine the number of new visitors to the product.
    The metrics here are used to capture the effectiveness of the following methods
    to attract new users.
  prefs: []
  type: TYPE_NORMAL
- en: '**Search Engine** **Optimization** (**SEO**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social media
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advertising
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marketing campaigns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Activation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the activation phase, we look to see how many new users want to become more
    engaged after first encountering the product or website. Metrics here look at
    the following user actions as indications that new users are beyond the acquisition
    phase and into this phase:'
  prefs: []
  type: TYPE_NORMAL
- en: Visiting additional pages after the landing page
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at or playing with additional product features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spending more time on the website
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signing up for the newsletter/email list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signing up for a free trial
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results of tests recording user behavior, such as A/B tests, are used to create
    these types of metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Retention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this phase, we look to see how long we can keep users after their first
    encounter. We want to measure whether the following things occur:'
  prefs: []
  type: TYPE_NORMAL
- en: Return visits to the website
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Opening email newsletters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeated use of the product over a given period of time (often the first month)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, these metrics measure the effectiveness of marketing emails and campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: Referral
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This phase looks to see if the established customer spreads the word to friends
    or coworkers. The metrics to determine entry into this phase include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of referrals who enter the acquisition phase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of referrals who enter the activation phase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revenue
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, this phase looks at those customers that have reached a higher level
    and purchased enhanced product features or website content. We look to see which
    customers do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Pay the minimum revenue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pay enough revenue for marketing efforts to *break even* throughout all phases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Google HEART framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The HEART framework was devised by Kerry Rodden, Hilary Hutchinson, and Xin
    Fu at Google. It was developed to gauge the effectiveness of **User Experience**
    (**UX**) design for the large-scale web applications offered by Google.
  prefs: []
  type: TYPE_NORMAL
- en: 'The framework has team members evaluate the following dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Happiness**: These are typically subjective measures such as user satisfaction,
    perceived ease of use, and likelihood to recommend.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Engagement**: This tracks how involved the user is with the product and its
    features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adoption**: This tracks the number of new users in a given time period.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retention**: This tracks how many users in a given time period are still
    engaged at a later time period.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Task success**: This measures the overall usability of the product or individual
    feature in question. Can a user accomplish the desired outcome using the product
    or feature?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each dimension, the team looks at setting three qualities. These qualities
    are outlined in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Goals or objectives**: What is the goal for the product or feature?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Signals**: How do we know that we achieved the goal or objective?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics**: What metrics can we collect to get the signals we want?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Teams will often take the dimensions and qualities and arrange them in a table.
    An example of this is in the following diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Goals** | **Signals** | **Metrics** |'
  prefs: []
  type: TYPE_TB
- en: '| Happiness |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Engagement |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Adoption |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Retention |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Task success |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: Table 5.1 – Google HEART framework
  prefs: []
  type: TYPE_NORMAL
- en: The next metrics framework looks for alignment between customer desires and
    organization efforts. Let’s look at this framework now.
  prefs: []
  type: TYPE_NORMAL
- en: Fit for Purpose metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In *Fit for Purpose: How Modern Businesses Find, Satisfy, & Keep Customers*,
    authors David J. Anderson and Alexei Zheglov describe the **Fit for Purpose**
    (**F4P**) framework, a way of aligning customer needs (*purpose*) with the products
    and solutions an organization may offer (*fit*).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Anderson and Zheglov identify four classifications of metrics that organizations
    typically collect and show where they fit in the framework. The classifications
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Fitness criteria
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: General health indicators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improvement drivers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vanity metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at each category now.
  prefs: []
  type: TYPE_NORMAL
- en: Fitness criteria
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Fitness criteria describe the metrics your customer will use to determine whether
    your product or solution fits their needs or purpose. These fitness criteria will
    be based on the following dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: Design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service delivery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customers will evaluate fitness criteria using thresholds. The first is a minimum
    acceptance level, below which they will decide the product or service does not
    meet their need. The second threshold is for exceptional service or for situations
    where the product in all three dimensions exceeds expectations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many organizations start with these metrics as fitness criteria until they
    find out more about the customer or market segment:'
  prefs: []
  type: TYPE_NORMAL
- en: Lead time and its predictability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quality and its predictability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Safety, including compliance with necessary laws and standards if in a regulated
    industry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Price. Note that this is often not an independent variable. In other words,
    the price may be sacrificed for higher expectations of the other fitness criteria.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer input into their fitness criteria is often acquired through F4P surveys,
    which ask customers what three purposes they were seeking, how well the product
    or service met those purposes, and any other notes.
  prefs: []
  type: TYPE_NORMAL
- en: General health indicators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: General health indicators are metrics internal to the organization. They can
    be used to determine suitability to improve one or more of the dimensions (design,
    implementation, service journey) that customers use to align an organization’s
    fit to their purpose. Although these are important metrics and should be collected
    and analyzed, they are secondary to fitness criteria in determining whether value
    has been created to the point that customers will select the product.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of general health indicators include cycle time for a value stream,
    velocity for a Scrum team, and mean time to restore/recover for an operations
    team.
  prefs: []
  type: TYPE_NORMAL
- en: Improvement drivers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Improvement drivers are metrics used by organizations for the purpose of improvement.
    They are the measurement that an organization is adopting a specific behavior.
    There is usually a target associated with them, and when that target is achieved,
    that metric should be changed to a general health indicator.
  prefs: []
  type: TYPE_NORMAL
- en: An example of an improvement driver could be the number of tests automated.
    This metric would be there to encourage an emphasis on test automation.
  prefs: []
  type: TYPE_NORMAL
- en: Vanity metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve discussed vanity metrics before when talking about Innovation Accounting.
    Many organizations do collect vanity metrics, and they do provide an emotional
    boost. But like sugary snacks or junk food with their *empty calories*, these
    metrics offer no real insight into whether an organization’s actions are bringing
    the true value that a customer wants.
  prefs: []
  type: TYPE_NORMAL
- en: An example of this is the total number of website visits that an organization’s
    website generates. Without diving deeper into details, this is a number that will
    always go up and doesn’t relate to any efforts the organization is making in marketing
    or SEO.
  prefs: []
  type: TYPE_NORMAL
- en: Net promoter score
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Net promoter score is a common metric used in customer support. This usually
    takes the form of a single survey question: how likely are you to recommend the
    product or service to a friend or colleague? This question is accompanied by a
    range of responses from 1-10\. The users then divide the respondents into the
    following categories based on their response:'
  prefs: []
  type: TYPE_NORMAL
- en: Promoters (9-10)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Passives (7-8)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detractors (1-6)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The score is then calculated by looking at the percentage of promoters and detractors
    and subtracting the percentage of detractors from the percentage of promoters.
    This percentage is then expressed as an integer.
  prefs: []
  type: TYPE_NORMAL
- en: We have now completed our exploration of popular metrics frameworks used to
    measure the value we deliver to our customers. Most of these involve direct contact
    with the customer and it is beneficial if this contact is made on a frequent basis.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at the measurements we make during both the development
    process and afterward. We found that we had to make measurements in three areas
    to determine whether our value stream was optimized and working toward value.
  prefs: []
  type: TYPE_NORMAL
- en: The first area examined using measurement was the teams and value stream to
    see if they were working toward optimizing flow. Measurements such as cycle time,
    lead time, WIP, and throughput were defined and determined using a cumulative
    flow diagram.
  prefs: []
  type: TYPE_NORMAL
- en: The second area measured the environments where the applications reside. Tools
    are available to ensure the proper functioning of the application and the environmental
    resources, such as the infrastructure, including storage and networks.
  prefs: []
  type: TYPE_NORMAL
- en: The third area measured the value provided by the solution. Metric frameworks,
    such as pirate metrics (AARRR), the Google HEART framework, and F4P metrics, look
    at the customer actions and thoughts to determine whether the solution developed
    works with customer expectations to provide value.
  prefs: []
  type: TYPE_NORMAL
- en: In our next chapter, we’ll finish our examination of CALMR by taking a look
    at *Recovery*. We will look at the methods value streams will use to mitigate
    the risk of a failure in production and the methods they use to quickly resolve
    issues in production if they happen.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Test your knowledge of the concepts in this chapter by answering these questions.
  prefs: []
  type: TYPE_NORMAL
- en: Lead time measures wait time and ________________?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: throughput
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: blockers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: cycle time
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: WIP
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When measuring throughput and cycle time, if cycle time decreases, what happens
    to throughput?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Throughput goes up
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Throughput goes down
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Throughput stays the same
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Throughput goes up, then down
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How does WIP present itself on a cumulative flow diagram?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Horizontal line
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Vertical line
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Upward slope
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Downward slope
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What measurements are taken for infrastructure monitoring (pick 2)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Garbage collection rate
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CPU utilization
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Response rate
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Storage availability
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Network availability
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which type of metric is valued by customers in the Fit for Purpose framework?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fitness criteria
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: General health indicators
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Improvement drivers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Vanity metrics
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[http://www.gartner.com/DisplayDocument?id=1436734&ref=g_sitelink](http://www.gartner.com/DisplayDocument?id=1436734&ref=g_sitelink)
    – A Gartner report that describes the APM Conceptual Framework.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://500hats.typepad.com/500blogs/2007/09/startup-metrics.html](https://500hats.typepad.com/500blogs/2007/09/startup-metrics.html)
    – Blog page of Dave McClure where he describes pirate metrics (AARRR).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://research.google/pubs/pub36299/](https://research.google/pubs/pub36299/)
    – Paper submitted by Kerry Rodden, Hilary Hutchinson, and Xin Fu outlining Google’s
    HEART framework.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Lean Startup* by Eric Ries – An examination of the Lean Startup Cycle.
    Part of the cycle includes a discussion of Innovation Accounting and what metrics
    are truly beneficial and not vanity metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Fit for Purpose: How Modern Businesses Find, Satisfy, & Keep Customers* by
    David J. Anderson and Alexei Zheglov – An examination of the Fit for Purpose Metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
