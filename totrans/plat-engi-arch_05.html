<html><head></head><body>
		<div id="_idContainer089">
			<h1 id="_idParaDest-107" class="chapter-number"><a id="_idTextAnchor255"/><st c="0">5</st></h1>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor256"/><st c="2">Integration, Delivery, and Deployment – Automation is Ubiquitous</st></h1>
			<p><a href="B31164_02.xhtml#_idTextAnchor055"><span class="No-Break"><em class="italic"><st c="66">Chapter 2</st></em></span></a><st c="76"> included a reference architecture of a platform highlighting layers such as </st><em class="italic"><st c="153">Developer Experience</st></em><st c="173">, </st><em class="italic"><st c="175">Automation and Orchestration</st></em><st c="203">, and </st><em class="italic"><st c="209">Observability Plane</st></em><st c="228">. </st><a href="B31164_03.xhtml#_idTextAnchor133"><span class="No-Break"><em class="italic"><st c="230">Chapter 3</st></em></span></a><st c="239"> ended with a different perspective on this reference architecture using a top-down approach from </st><em class="italic"><st c="337">Purpose</st></em><st c="344">, </st><em class="italic"><st c="346">User Interface</st></em><st c="360">, </st><em class="italic"><st c="362">Core Platform Components</st></em><st c="386">, </st><em class="italic"><st c="388">Platform as a Product</st></em><st c="409">, and </st><span class="No-Break"><em class="italic"><st c="415">Success KPIs</st></em></span><span class="No-Break"><st c="427">.</st></span></p>
			<p><st c="428">Most platforms are built with the purpose of making it easier for development teams to ship software without having to deal with all the complexity around building, deploying, testing, validating, securing, operating, releasing, or scaling software. </st><st c="679">In this chapter, we will dive into those layers and components of our platform so we understand how we can centralize and automate the expertise it takes to ship software and provide it as </st><span class="No-Break"><st c="868">a self-service.</st></span></p>
			<p><st c="883">By the end of this chapter, we will have learned how to define an end-to-end release process for software artifacts, align the </st><strong class="bold"><st c="1011">continuous integration / continuous deployment</st></strong><st c="1057"> (</st><strong class="bold"><st c="1059">CI/CD</st></strong><st c="1064">) process with the artifact life cycle phases, automate the phases using tools for CI, CD, and continuous release, integrate those tools into your existing process, observe the automation, and scale through </st><span class="No-Break"><st c="1272">an IDP.</st></span></p>
			<p><st c="1279">As such, we will cover the following main topics in </st><span class="No-Break"><st c="1332">the chapter:</st></span></p>
			<ul>
				<li><st c="1344">An introduction to </st><span class="No-Break"><st c="1364">Continuous X</st></span></li>
				<li><st c="1376">GitOps: Moving from pushing to pulling the </st><span class="No-Break"><st c="1420">desired state</st></span></li>
				<li><st c="1433">Understanding the importance of container and artifact registries as </st><span class="No-Break"><st c="1503">entry points</st></span></li>
				<li><st c="1515">Defining the release process </st><span class="No-Break"><st c="1545">and management</st></span></li>
				<li><st c="1559">Achieving sustainable CI/CD for DevOps – application life </st><span class="No-Break"><st c="1618">cycle orchestration</st></span></li>
				<li><strong class="bold"><st c="1637">Internal Developer Platforms</st></strong><st c="1666"> (</st><strong class="bold"><st c="1668">IDPs</st></strong><st c="1672">) – the automation Kraken in </st><span class="No-Break"><st c="1702">the platform</st></span></li>
			</ul>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor257"/><st c="1714">An introduction to Continuous X</st></h1>
			<p><st c="1746">If this is the first time you are hearing </st><a id="_idIndexMarker429"/><st c="1789">about </st><strong class="bold"><st c="1795">Continuous Integration</st></strong><st c="1817"> (</st><strong class="bold"><st c="1819">CI</st></strong><st c="1821">) or </st><strong class="bold"><st c="1827">Continuous Delivery</st></strong><st c="1846"> (</st><strong class="bold"><st c="1848">CD</st></strong><st c="1850">), then we suggest checking out some of the great literature that</st><a id="_idIndexMarker430"/><st c="1916"> exists on these basic concepts. </st><em class="italic"><st c="1949">Jez Humble</st></em><st c="1959"> is the maintainer of </st><a href="https://continuousdelivery.com/"><st c="1981">https://continuousdelivery.com/</st></a><st c="2012"> and has co-authored the original </st><em class="italic"><st c="2046">Continuous Delivery</st></em><st c="2065"> book with </st><em class="italic"><st c="2076">Dave Farley</st></em><st c="2087">. If you need a crash course on this topic, then please have a look at their material. </st><st c="2174">There are also several recorded talks that give a great overview, such as the one titled </st><em class="italic"><st c="2263">Continuous Delivery Sounds Great But It Won’t Work </st></em><span class="No-Break"><em class="italic"><st c="2314">Here</st></em></span><span class="No-Break"><st c="2318">: </st></span><a href="https://vimeo.com/193849732"><span class="No-Break"><st c="2321">https://vimeo.com/193849732</st></span></a><span class="No-Break"><st c="2348">.</st></span></p>
			<p><st c="2349">So that we all have the same common understanding, let us quickly recap what the building blocks are and why this is important in </st><span class="No-Break"><st c="2480">software delivery</st><a id="_idTextAnchor258"/><st c="2497">.</st></span></p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor259"/><st c="2498">High-level definition of Continuous X</st></h2>
			<p><st c="2536">The</st><a id="_idIndexMarker431"/><st c="2540"> basic foundation of automating software delivery is to have proper </st><em class="italic"><st c="2608">configuration management</st></em><st c="2632"> of all assets required to build, deploy, validate, operate, and scale our systems: code, tests, deployment and infrastructure definitions, dependencies, observability, ownership, and more. </st><st c="2822">Putting all those assets into version control allows us to generate repeatable and reliable output, gives us auditability, allows us to revert breaking changes, and gives us disaster </st><span class="No-Break"><st c="3005">recovery capabilities.</st></span></p>
			<p><st c="3027">Git, or any</st><a id="_idIndexMarker432"/><st c="3039"> type of Git flavor, is most likely what can be found today in software organizations for version control. </st><st c="3146">Depending on the Git solution you use, you will see additional built-in capabilities such as cross-team collaboration (issue tracking, resolving merge conflicts, etc.), automation (commit checks, delivery pipelines, etc.), or reporting (efficiency or </st><span class="No-Break"><st c="3397">DORA metrics).</st></span></p>
			<p><st c="3411">Now that we have established the foundation, let’s dive into </st><span class="No-Break"><st c="3473">Continuous</st><a id="_idTextAnchor260"/><st c="3483"> X.</st></span></p>
			<h3><st c="3486">CI</st></h3>
			<p><strong class="bold"><st c="3489">CI</st></strong><st c="3492"> is the</st><a id="_idIndexMarker433"/><st c="3499"> practice that emphasizes frequent and automated integration of code changes into a shared repository. </st><st c="3602">When multiple developers work on the same code base, it’s important to bring those changes together frequently to validate that the code integrates well and produces an artifact (a container image, a binary) that can be deployed into an environment. </st><st c="3852">Key aspects of CI include </st><span class="No-Break"><st c="3878">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="3892">Automated builds</st></strong><st c="3909">: Code</st><a id="_idIndexMarker434"/><st c="3916"> commits in version</st><a id="_idIndexMarker435"/><st c="3935"> control trigger an automated build process that compiles, runs tests, and </st><span class="No-Break"><st c="4010">generates artifacts</st></span></li>
				<li><strong class="bold"><st c="4029">Test automation</st></strong><st c="4045">: Unit tests, integration tests, and other checks are executed during the build </st><a id="_idIndexMarker436"/><st c="4126">process </st><a id="_idIndexMarker437"/><st c="4134">marking the build broken if any tests </st><span class="No-Break"><st c="4172">should fail</st></span></li>
				<li><strong class="bold"><st c="4183">Feedback loop</st></strong><st c="4197">: This provides </st><a id="_idIndexMarker438"/><st c="4214">rapid feedback to </st><a id="_idIndexMarker439"/><st c="4232">developers to quickly fix issues, leading to overall higher code quality </st><span class="No-Break"><st c="4305">and</st><a id="_idTextAnchor261"/><st c="4308"> stability</st></span></li>
			</ul>
			<h3><st c="4318">Continuous testing and validation of observability</st></h3>
			<p><st c="4369">While CI already highlights the</st><a id="_idIndexMarker440"/><st c="4401"> importance of automated unit and integration tests, we want to stress the fact that more automated testing and validation early in the life cycle will result in better quality and stability. </st><st c="4593">Assuming the built software provides REST APIs or a UI, basic validation against those interfaces should be done to validate the accurate functionality (e.g, do APIs return proper responses, are the correct HTTP status codes used when testing with invalidated parameters, are there any timeouts in API calls, or are any HTTP </st><span class="No-Break"><st c="4918">errors returned?).</st></span></p>
			<p><strong class="bold"><st c="4936">Observability</st></strong><st c="4950"> is essential </st><a id="_idIndexMarker441"/><st c="4964">to validate if systems are healthy and provides the data to troubleshoot problems faster. </st><st c="5054">As part of the continuous validation</st><a id="_idIndexMarker442"/><st c="5090"> process, we must validate that the tested build is producing valid and expected observability data. </st><st c="5191">We should validate that all expected metrics, logs, or traces are produced and that there is no obvious anomaly or outlier present after running those basic unit, integration, or </st><span class="No-Break"><st c="5370">API tests.</st></span></p>
			<p><st c="5380">We have been stressing that </st><a id="_idIndexMarker443"/><st c="5409">observability has to be a non-functional requirement of modern software. </st><st c="5482">This is why the CI should already validate if the expected data is produced. </st><st c="5559">If not, then this is just like a failing unit or integration test and you should mark the build </st><span class="No-Break"><st c="5655">as broken!</st></span></p>
			<p><st c="5665">For Financial One ACME and its critical financial services, we should validate </st><span class="No-Break"><st c="5745">the following:</st></span></p>
			<ul>
				<li><st c="5759">Will the API properly validate the access control of the caller (e.g., not be able to query financial data from </st><span class="No-Break"><st c="5872">other users)?</st></span></li>
				<li><st c="5885">Will the API not log any confidential data, such as credit card numbers, usernames, </st><span class="No-Break"><st c="5970">or tokens?</st></span></li>
				<li><st c="5980">Will the API properly generate metrics for failed attempts so this can be used in production to alert on potential</st><a id="_idTextAnchor262"/> <span class="No-Break"><st c="6095">hack attacks?</st></span></li>
			</ul>
			<h3><st c="6109">Continuous delivery</st></h3>
			<p><st c="6129">As defined on the continuous delivery site (</st><a href="https://continuousdelivery.com/"><st c="6174">https://continuousdelivery.com/</st></a><st c="6206">), “</st><em class="italic"><st c="6211">Continuous Delivery is the ability to get changes of all types—including new features, configuration changes, bug fixes and experiments—into production, or into the hands of users, safely and quickly in a sustainable way</st></em><st c="6432">.” The goal is to take the fear of failure out of </st><a id="_idIndexMarker444"/><st c="6482">deployments. </st><st c="6495">Instead of infrequent big bang releases, deployments should become routine as they continuously happen. </st><st c="6599">Additionally, applying new deployment patterns such as blue/green, canary, or feature flagging allows us to reduce the risk even further. </st><st c="6737">These will be discussed further in the section about deployments </st><span class="No-Break"><st c="6802">versus releases!</st></span></p>
			<p><st c="6818">Some aspects of continuous delivery are </st><span class="No-Break"><st c="6859">as follows:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="6870">Automated deployments</st></strong><st c="6892">: New </st><a id="_idIndexMarker445"/><st c="6899">artifacts that come</st><a id="_idIndexMarker446"/><st c="6918"> out of CI are bundled with other changes and get automatically deployed. </st><st c="6992">Deployment definitions are declarative and version-controlled and therefore allow a more predictable, repeatable, and low-risk way of updating in </st><span class="No-Break"><st c="7138">any environment.</st></span></li>
				<li><strong class="bold"><st c="7154">Deployment pipelines</st></strong><st c="7175">: Pipelines </st><a id="_idIndexMarker447"/><st c="7188">allow higher-level testing and deployment validation as compared to CI. </st><st c="7260">Here</st><a id="_idIndexMarker448"/><st c="7264"> is where performance, security, scalability, resiliency, and user experience tests get executed. </st><st c="7362">This validates not just a single artifact but the full deployment </st><span class="No-Break"><st c="7428">change set!</st></span></li>
				<li><strong class="bold"><st c="7439">Quality gates and promotion</st></strong><st c="7467">: At the end of a deployment pipeline, all test results act as a quality gate</st><a id="_idIndexMarker449"/><st c="7545"> before promoting</st><a id="_idIndexMarker450"/><st c="7562"> that change into the next environment: from development</st><a id="_idIndexMarker451"/><st c="7618"> to </st><strong class="bold"><st c="7622">Quality Assurance</st></strong><st c="7639"> (</st><strong class="bold"><st c="7641">QA</st></strong><st c="7643">,) from QA to staging, from staging </st><span class="No-Break"><st c="7679">to production.</st></span></li>
				<li><strong class="bold"><st c="7693">Rolling back versus rolling forward</st></strong><st c="7729">: If the quality gate fails in production, a rollback</st><a id="_idIndexMarker452"/><st c="7783"> can be triggered by reverting back to the previous version-controlled deployment</st><a id="_idIndexMarker453"/><st c="7864"> configuration. </st><st c="7880">Another strategy is rolling forward, which means that problems</st><a id="_idIndexMarker454"/><st c="7942"> are fixed, and thanks to automated deployments, the fix can be deployed quickly to avoid</st><a id="_idTextAnchor263"/><st c="8031"> the need for </st><span class="No-Break"><st c="8045">a rollback.</st></span></li>
			</ul>
			<h3><st c="8056">Continuous deployments – decoupling deployments from releases</st></h3>
			<p><st c="8118">CD deploys changes in an automated and fast way. </st><st c="8168">However, there is still a risk that a change results in a failure, requiring either rolling backward or rolling forward, as </st><span class="No-Break"><st c="8292">explained earlier.</st></span></p>
			<p><st c="8310">Continuous deployments </st><a id="_idIndexMarker455"/><st c="8334">go a step further and embrace new deployment patterns that favor the separation of the deployment of a change and releasing the new feature set to the end users. </st><st c="8496">The current well-established patterns are </st><span class="No-Break"><st c="8538">as follows:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="8549">Blue/green deployments</st></strong><st c="8572">: The new </st><a id="_idIndexMarker456"/><st c="8583">deployment (commonly labeled </st><em class="italic"><st c="8612">blue</st></em><st c="8616">) will be done </st><a id="_idIndexMarker457"/><st c="8632">in parallel to the existing deployment (commonly labeled </st><em class="italic"><st c="8689">green</st></em><st c="8694">). </st><st c="8698">Through a load balancer, traffic can be switched to blue. </st><st c="8756">If there is a problem with blue, traffic can be switched back to the still-running instance, therefore eliminating the need for a rollback while minimizing the impact on the</st><a id="_idIndexMarker458"/><st c="8929"> end user. </st><st c="8940">If all goes well, green becomes blue until the next deployment </st><a id="_idIndexMarker459"/><span class="No-Break"><st c="9003">comes along.</st></span></li>
				<li><strong class="bold"><st c="9015">Canary deployments</st></strong><st c="9034">: Similar to blue/green deployments but on a more granular level. </st><st c="9101">It’s the practice </st><a id="_idIndexMarker460"/><st c="9119">of a staged deployment of the new version besides the old version. </st><st c="9186">First, it is deployed to a small subset of users or a </st><a id="_idIndexMarker461"/><st c="9240">percentage of the traffic. </st><st c="9267">If everything is good, the staged rollout continues until all user traffic has the new version. </st><st c="9363">If a problem occurs during the stages, the old version will receive </st><span class="No-Break"><st c="9431">the traffic.</st></span></li>
				<li><strong class="bold"><st c="9443">Feature flagging</st></strong><st c="9460">: Instead of load-balanced side-by-side deployments of the old and new versions, feature flagging</st><a id="_idIndexMarker462"/><st c="9558"> allows developers to “hide” new code</st><a id="_idIndexMarker463"/><st c="9595"> behind a switch/toggle. </st><st c="9620">During a deployment, the new version gets deployed over the old one without executing the new hidden code. </st><st c="9727">Through fine-grained configuration, features can be turned on for individual users, user types, geographical regions, or any other attribute of a consumer of a service. </st><st c="9896">If a feature has a problem, it only takes a runtime configuration change and that code becomes </st><span class="No-Break"><st c="9991">inactive again.</st></span></li>
			</ul>
			<p><st c="10006">Decoupling deployments from releases allows teams to better control the rollout of new features of their software and with that, minimize risk. </st><st c="10151">There is more to explain about implementation details as well as challenges but that’s beyond the scope of this book. </st><st c="10269">If you are interested in learning more, look into </st><em class="italic"><st c="10319">OpenFeature</st></em> <em class="italic"><st c="10330">[1]</st></em><st c="10334">, a </st><strong class="bold"><st c="10338">Cloud Native Computing Foundation</st></strong><st c="10371"> (</st><strong class="bold"><st c="10373">CNCF</st></strong><st c="10377">) incubating project. </st><st c="10400">OpenFeature provides a standard, feature-flag </st><a id="_idIndexMarker464"/><st c="10446">management, vendor-agnostic way for developers to implement feature flags. </st><st c="10521">The community around it also has a lot of best practices around progressive delivery, which includes all</st><a id="_idTextAnchor264"/><st c="10625"> the patterns </st><span class="No-Break"><st c="10639">discussed previously.</st></span></p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor265"/><st c="10660">Continuous X for infrastructure</st></h2>
			<p><st c="10692">Continuous X</st><a id="_idIndexMarker465"/><st c="10705"> is not only relevant for application code or configuration. </st><st c="10766">The same concepts should be applied to any infrastructure definition. </st><st c="10836">As a platform, we will need certain infrastructure components. </st><st c="10899">Whether that’s virtual machines, Kubernetes nodes, load </st><a id="_idIndexMarker466"/><st c="10955">balancers, </st><strong class="bold"><st c="10966">Domain Name System</st></strong><st c="10984"> (</st><strong class="bold"><st c="10986">DNS</st></strong><st c="10989">), file storage, databases, virtual networks, serverless, or any other component that allows us to run our core platform as well as the applications that will be deployed, operated, and managed through our </st><span class="No-Break"><st c="11196">platform self-services.</st></span></p>
			<p><st c="11219">Just like with application code, we want to configure our infrastructure requirements as code, version control them, and apply the same CI and continuous testing, validation, </st><span class="No-Break"><st c="11395">and delivery.</st></span></p>
			<p><strong class="bold"><st c="11408">GitOps</st></strong><st c="11415"> is also</st><a id="_idIndexMarker467"/><st c="11423"> a term that emerged over the past years and it focuses on automating the process of provisioning infrastructure from a desired state defined declaratively and version-controlled in Git. </st><st c="11610">We will cover GitOps in more detail in a later section of this chapter. </st><st c="11682">First, let’s </st><a id="_idIndexMarker468"/><st c="11695">discuss the basics by star</st><a id="_idTextAnchor266"/><st c="11721">ting with </st><strong class="bold"><st c="11732">infrastructure as </st></strong><span class="No-Break"><strong class="bold"><st c="11750">code</st></strong></span><span class="No-Break"><st c="11754"> (</st></span><span class="No-Break"><strong class="bold"><st c="11756">IaC</st></strong></span><span class="No-Break"><st c="11759">).</st></span></p>
			<h3><st c="11762">IaC</st></h3>
			<p><st c="11766">There are </st><a id="_idIndexMarker469"/><st c="11777">many different tools that enable </st><strong class="bold"><st c="11810">IaC</st></strong><st c="11813"> and most likely, you already have one or several </st><a id="_idIndexMarker470"/><st c="11863">in your organization: Terraform, Ansible, Puppet, Chef, CloudFormation, and </st><strong class="bold"><st c="11939">AWS</st></strong> <strong class="bold"><st c="11942">Cloud Development Kit</st></strong><st c="11964"> (</st><strong class="bold"><st c="11966">CDK</st></strong><st c="11969">) just to name </st><span class="No-Break"><st c="11985">a few.</st></span></p>
			<p><st c="11991">Here is a very simple Terraform snippet that would create an EC2 instance of </st><span class="No-Break"><st c="12069">type </st></span><span class="No-Break"><strong class="source-inline"><st c="12074">c5.large</st></strong></span><span class="No-Break"><st c="12082">:</st></span></p>
			<pre class="source-code"><st c="12084">
resource "aws_instance" "finoneacme_demoserver" {
  ami           = "ami-01e815680a0bbe597"
  instance_type = "c5.large"
  tags = {
    Name = "IaCTFExample"
  }
}</st></pre>
			<p><st c="12226">Here is one more example of creating an AWS S3 bucket </st><span class="No-Break"><st c="12281">using Ansible:</st></span></p>
			<pre class="source-code"><st c="12295">
- name: provisioning S3 Bucket using Ansible playbook
   hosts: localhost
   connection: local
   gather_facts: false
   tags: provisioning
   tasks:
     - name: create S3 bucket
       S3_bucket:
         name: finoneacme_bucket_dev
         region: us-east-1
         versioning: yes
         tags:
           name: bucketenv
           type: dev</st></pre>
			<p><st c="12560">IaC </st><a id="_idIndexMarker471"/><st c="12565">enables us to define the desired state of our IaC. </st><st c="12616">This is code that can be version-controlled, such as application code, and once deployed, it results in the desired infrastructure being provisioned. </st><st c="12766">Like with application code, we can use </st><span class="No-Break"><st c="12805">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="12819">CI</st></strong><st c="12822">: Use this to validate that all our IaC is valid. </st><st c="12873">IaC tools typically have features to “dry run” and validate that there is no mistake and that all config files have no conflict or </st><span class="No-Break"><st c="13004">dependency issues.</st></span></li>
				<li><strong class="bold"><st c="13022">Testing and deployment validation</st></strong><st c="13056">: After IaC is deployed, we can validate that we really got our desired state (e.g., ensuring that the EC2 instance is really up and running, that the S3 buckets are </st><span class="No-Break"><st c="13223">accessible, etc.).</st></span></li>
				<li><strong class="bold"><st c="13241">Rollback or revert</st></strong><st c="13260">: IaC gives us the option to roll back changes or revert to a previous version because everything </st><span class="No-Break"><st c="13359">is version-controlled!</st></span></li>
			</ul>
			<p><st c="13381">For more details on</st><a id="_idIndexMarker472"/><st c="13401"> IaC, including version control strategies (where IaC lives), the authors recommend looking i</st><a id="_idTextAnchor267"/><st c="13494">nto existing books and blogs on </st><span class="No-Break"><st c="13527">that topic.</st></span></p>
			<h3><st c="13538">Crossplane – IaC for platform and applications</st></h3>
			<p><st c="13585">IaC is not limited to the </st><a id="_idIndexMarker473"/><st c="13612">core platform services but is also relevant for the applications that we allow our development teams to deploy through our platform self-services. </st><st c="13759">A new application may need file storage, a database, and a public DNS, or need to deploy a third-party solution; it depends on its own virtual machine, which is accessible from the deployed app that may reside </st><span class="No-Break"><st c="13969">on K8s.</st></span></p>
			<p><st c="13976">You can provide templates for Terraform, Ansible, and CDK, which your developers can add to their own code repositories, and which are then applied as part of the Continuous X of </st><span class="No-Break"><st c="14156">their application.</st></span></p>
			<p><st c="14174">One tool that has emerged in the cloud native space to cover both application and infrastructure orchestration is the </st><strong class="bold"><st c="14293">CNCF project Crossplane</st></strong> <em class="italic"><st c="14316">[2]</st></em><st c="14320">. Besides coming with a lot of different </st><a id="_idIndexMarker474"/><st c="14361">providers for all major cloud vendors or even Terraform, it comes with Compositions. </st><strong class="bold"><st c="14446">Compositions</st></strong><st c="14458"> are a template for creating multiple managed resources as a single object. </st><st c="14534">This allows the platform team to define such templates for common application architectures and then have the application team simply use that template to instantiate the correct infrastructure and deploy </st><span class="No-Break"><st c="14739">the application.</st></span></p>
			<p><st c="14755">One of our self-service use cases discussed in </st><a href="B31164_02.xhtml#_idTextAnchor055"><span class="No-Break"><em class="italic"><st c="14803">Chapter 2</st></em></span></a><st c="14812"> was the automated provisioning of a performance test environment. </st><st c="14879">We could define a composition that would be as easy to use by the development teams as the one shown in </st><span class="No-Break"><st c="14983">this example:</st></span></p>
			<pre class="source-code"><st c="14996">
apiVersion: composites.financialone.acme/v1alpha1
kind: PerformanceTestCluster
metadata:
  name: ptest-devteam1
spec:
  clusterSize: "medium"
  targetApp:
    repoUrl: "https://financialone.acme/our-app-repo"
    targetRevision: "2.5.1"
    chart: "ourapp"
  loadProfile: "spike-load"
  observability: true
  notifySlackOnReady: "#devteam1"
  leaseTime: "12h"</st></pre>
			<p><st c="15330">The Composition </st><a id="_idIndexMarker475"/><st c="15347">definition of </st><strong class="source-inline"><st c="15361">PerformanceTestCluster</st></strong><st c="15383"> would have been created by the platform engineering team in combination with those experts who know how to install the load testing and observability tools. </st><st c="15541">In the preceding example, a new medium-sized K8s cluster would be provisioned, the requested app would be installed using the referenced Helm chart, observability data would be captured (e.g., Prometheus and log scraping configured) and the load testing tool would be deployed to be able to run spike load scenarios. </st><st c="15858">Once everything is ready, a Slack notification with the environment details will be sent to the team. </st><st c="15960">Last but not least, the environment would also be shut down after 12 hours as specified in the mandatory </st><span class="No-Break"><strong class="source-inline"><st c="16065">leaseTime</st></strong></span><span class="No-Break"><st c="16074"> field.</st></span></p>
			<p><st c="16081">The preceding example already shows the power of IaC when i</st><a id="_idTextAnchor268"/><st c="16141">ntegrating this into our Continuous </st><span class="No-Break"><st c="16178">X efforts!</st></span></p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor269"/><st c="16188">Continuous X as a system-critical component in our platform</st></h2>
			<p><st c="16248">There are many different tools we can </st><a id="_idIndexMarker476"/><st c="16287">choose from to implement Continuous X: Jenkins, GitLab, Tekton, Argo CD, Flux, Keptn, Crossplane, Selenium, and </st><strong class="source-inline"><st c="16399">k6</st></strong><st c="16401">, to just name a few. </st><st c="16423">Whatever tools we choose, those tools need to be available, resilient, and secure all of the time, as they are the backbone of our platform. </st><st c="16564">Those tools are as business-critical as any software that powers the business we are in. </st><st c="16653">Think about Financial One ACME. </st><st c="16685">If the developers need to push out a fix to a critical production issue on their financial software, they need Continuous X to </st><span class="No-Break"><st c="16812">work perfectly.</st></span></p>
			<p><st c="16827">To ensure that those components are available when they are needed, we need to apply the same best practices as we put on our </st><span class="No-Break"><st c="16954">business-critical apps:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="16977">Secure by default</st></strong><st c="16995">: If attackers find their way into our Continuous X toolkit, they have open doors to enter any system that is managed by our platform. </st><st c="17131">Because of this criticality, </st><a href="B31164_07.xhtml#_idTextAnchor381"><span class="No-Break"><em class="italic"><st c="17160">Chapter 7</st></em></span></a><st c="17169"> is fully dedicated to building secure and </st><span class="No-Break"><st c="17212">compliant products.</st></span></li>
				<li><strong class="bold"><st c="17231">Test every change we make</st></strong><st c="17257">: Let’s assume we use GitLab as one of our tools for Git and CI. </st><st c="17323">We must version control the deployment configuration of GitLab and run it through the same Continuous X process to validate every new version or configuration change. </st><st c="17490">If necessary, we will roll back or roll forward in case an update is </st><span class="No-Break"><st c="17559">causing issues!</st></span></li>
				<li><strong class="bold"><st c="17574">Deploy highly available</st></strong><st c="17598">: Follow the deployment guidelines for those tools for high availability. </st><st c="17673">If we have globally distributed teams, we want to make sure to deploy certain components as close as possible to our end users. </st><st c="17801">Also, look into zero-downtime upgrade options and </st><span class="No-Break"><st c="17851">follow them.</st></span></li>
				<li><strong class="bold"><st c="17863">Observe each component</st></strong><st c="17886">: Every tool provides some type of telemetry data that indicates health. </st><st c="17960">Argo CD, for instance, exposes Prometheus metrics for work queue length, Git requests, and sync activity. </st><st c="18066">Those give an indication of whether Argo CD is still able to do its job. </st><st c="18139">A constantly increasing work queue depth is a sign that Argo CD can’t keep up with all requests, which needs to be </st><span class="No-Break"><st c="18254">looked into.</st></span></li>
				<li><strong class="bold"><st c="18266">Service-level agreements (SLAs) and alerting on problems</st></strong><st c="18323">: We – the platform team – must know that something is wrong before our end users report it to us. </st><st c="18423">That’s why we need to set up</st><a id="_idIndexMarker477"/><st c="18451"> SLAs for each component and configure proper alerting in case systems are not working as expected. </st><st c="18551">The simplest way to do this is to set up synthetic checks against the key API endpoints of each tool (e.g., validate that Jenkins UI is responsive</st><a id="_idIndexMarker478"/><st c="18697"> with a synthetic check that runs every five minutes; this gives us an early warning signal in case Jenkins starts having problems before anyone else </st><span class="No-Break"><st c="18847">notices it).</st></span></li>
			</ul>
			<p><st c="18859">The following is an example dashboard highlighting key health indicators of tools, such as Argo CD. </st><st c="18960">The</st><a id="_idIndexMarker479"/><st c="18963"> same must be applied to all other tools that make up our core </st><span class="No-Break"><st c="19026">platform capabilities!</st></span></p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B31164_05_01.jpg" alt="Figure 5.1: Monitor and observe every tool part of the platform"/><st c="19048"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="19787">Figure 5.1: Monitor and observe every tool part of the platform</st></p>
			<p class="callout-heading"><st c="19850">Platform Components are as business-critical as your critical apps</st></p>
			<p class="callout"><st c="19917">The core of the platform will revolve around deploying changes into various environments. </st><st c="20008">All tools that support those use cases – especially those for Continuous X – need to be highly available, resilient, and secure. </st><st c="20137">Make sure to apply the same engineering best practices to all components of </st><span class="No-Break"><st c="20213">the platform!</st></span></p>
			<p><st c="20226">Now that we have recapped the core concepts of Continuous X (integration, testing, validation, delivery, deployment, and release) and discussed that all configurations (code, deployment config, infrastructure, observability, etc.) must follow the same principles, it’s time to have a look into how these concepts can be used to provide self-service autonom</st><a id="_idTextAnchor270"/><st c="20583">y to teams that leverage this through </st><span class="No-Break"><st c="20622">a platform.</st></span></p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor271"/><st c="20633">GitOps – Moving from pushing to pulling the desired state</st></h1>
			<p><strong class="bold"><st c="20691">CI/CD</st></strong><st c="20697"> has</st><a id="_idIndexMarker480"/><st c="20701"> been around for many years. </st><st c="20730">The </st><em class="italic"><st c="20734">Continuous Delivery</st></em><st c="20753"> book was initially released back in 2010 – years before the emergence of containers (made popular through Docker, starting in 2013) and container orchestration platforms (such as Kubernetes, starting </st><span class="No-Break"><st c="20954">in 2014).</st></span></p>
			<p><st c="20963">Fast forward to 2024 when this book was initially published; we live in a world where the following is </st><span class="No-Break"><st c="21067">the case:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="21076">Git</st></strong><st c="21080"> is the source </st><a id="_idIndexMarker481"/><st c="21095">of truth. </st><st c="21105">It contains everything as code: source code, tests, infrastructure and deployment definitions, observability, ownership, and </st><span class="No-Break"><st c="21230">so on.</st></span></li>
				<li><strong class="bold"><st c="21236">CI/CD</st></strong><st c="21242"> is building, testing, and</st><a id="_idIndexMarker482"/><st c="21268"> packaging container / </st><strong class="bold"><st c="21291">Open Container Initiative</st></strong><st c="21316"> (</st><strong class="bold"><st c="21318">OCI</st></strong><st c="21321">) images </st><a id="_idIndexMarker483"/><st c="21331">from a source code Git repository and publishing them to an artifact registry (</st><span class="No-Break"><st c="21410">e.g., Harbor).</st></span></li>
				<li><strong class="bold"><st c="21425">GitOps</st></strong><st c="21432"> continuously attempts to apply the latest desired state as declared in a deployment </st><a id="_idIndexMarker484"/><st c="21517">Git repository (e.g., Helm Charts) on the target Kubernetes environment and pushes any additional configuration (e.g., observability to the </st><span class="No-Break"><st c="21657">respective tools).</st></span></li>
			</ul>
			<p><st c="21675">The preceding description is not a one-size-fits-all model. </st><st c="21736">GitOps will be implemented slightly differently in every organization. </st><st c="21807">If you search for </st><strong class="source-inline"><st c="21825">What is GitOps?</st></strong><st c="21840">, you will find many different variations, such as </st><span class="No-Break"><st c="21891">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="21905">Separate CI and CD</st></strong><st c="21924">: CI publishing containers and CD publishing packaged artifacts, such as </st><span class="No-Break"><st c="21998">Helm charts</st></span></li>
				<li><strong class="bold"><st c="22009">Single Git</st></strong><st c="22020">: Everything as code (source, test, deployment, observability, etc.) in a single </st><span class="No-Break"><st c="22102">Git repository</st></span></li>
				<li><strong class="bold"><st c="22116">Push GitOps</st></strong><st c="22128">: Pushing</st><a id="_idIndexMarker485"/><st c="22138"> the desired state through pipelines or workflows versus pulling changes into the target environment through </st><span class="No-Break"><st c="22247">GitOps operators</st></span></li>
			</ul>
			<p><st c="22263">In the following section, we will shine the light on one flavor of GitOps that favors the </st><strong class="bold"><st c="22354">pull</st></strong><st c="22358"> (</st><em class="italic"><st c="22360">pulling</st></em><st c="22367"> a configuration into the target environment) model over the </st><strong class="bold"><st c="22428">push</st></strong><st c="22432"> (</st><em class="italic"><st c="22434">pushing</st></em><st c="22441"> a configuration from an external tool into the target environment) model, which can be implemented with CNCF tools, such as Flux or Argo CD, as shown in the following illustration taken from Codefresh’s Learning Center on </st><span class="No-Break"><st c="22664">GitOps: </st></span><a href="https://codefresh.io/learn/gitops/"><span class="No-Break"><st c="22672">https://codefresh.io/learn/gitops/</st></span></a><span class="No-Break"><st c="22706">.</st></span></p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B31164_05_02.jpg" alt="Figure 5.2: Basic GitOps flow as promoted by GitOps tools such as Argo CD or Flux"/><st c="22707"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="22940">Figure 5.2: Basic GitOps flow as promoted by GitOps tools such as Argo CD or Flux</st></p>
			<p><st c="23021">It’s your choice as to whether you favor the Push model using automated pipelines or workflows to push changes into your target Kubernetes environments! </st><st c="23175">To make the decision easier, let’s dig into more detail on the individual phases and learn about </st><a id="_idTextAnchor272"/><st c="23272">some best practices that should happen in </st><span class="No-Break"><st c="23314">every phase!</st></span></p>
			<h2 id="_idParaDest-114"><a id="_idTextAnchor273"/><st c="23326">Phase 1 – from source code to container image</st></h2>
			<p><st c="23372">Moving to GitOps doesn’t </st><a id="_idIndexMarker486"/><st c="23398">change anything about how we are building our applications from source code that is version-controlled in Git. </st><st c="23509">Before building new artifacts, a good practice is to automate dependency checks and updates. </st><st c="23602">Tools, such as </st><strong class="bold"><st c="23617">Renovate Bot</st></strong> <em class="italic"><st c="23629">[3]</st></em><st c="23633">, integrate with </st><a id="_idIndexMarker487"/><st c="23650">Git and create Pull Requests in case outdated dependencies, third-party libraries, or other dependencies </st><span class="No-Break"><st c="23755">are found.</st></span></p>
			<p><st c="23765">Once we have our up-to-date code in Git, </st><strong class="bold"><st c="23807">CI</st></strong><st c="23809"> has the</st><a id="_idIndexMarker488"/><st c="23817"> same job as it always had: it creates an artifact, most likely a container image, that gets pushed to a container registry! </st><st c="23942">That CI can be triggered on demand, on commits to certain branches, on Pull Requests, or on any other trigger that makes sense for </st><span class="No-Break"><st c="24073">the organization!</st></span></p>
			<p><st c="24090">There are many different tools available that can do the job: Jenkins, GitLab, Azure DevOps, GitHub Actions, Bitbucket Pipelines, and many more. </st><st c="24236">There are also various container registry options. </st><st c="24287">We will talk about container registries and the importance of them a bit later in this book as they are – like all the components of our platform – critical to the success of our </st><span class="No-Break"><st c="24466">future platform!</st></span></p>
			<p><st c="24482">Once the CI </st><a id="_idIndexMarker489"/><st c="24495">has successfully compiled the source code, executed unit tests, and run any additional quality checks on the code, it’s time to package the binary into a container image. </st><st c="24666">There are many best practices out there for building container images; from just packaging a single service into a container, being careful to use public base images, to building the smallest image possible. </st><st c="24874">Following all those rules will lead to a higher rate of success as the container image moves from CI all the way into production. </st><st c="25004">Here are two obvious but very important practices that we want to mention in this chapter (for more information, please refer to the books </st><span class="No-Break"><st c="25143">previously mentioned):</st></span></p>
			<ul>
				<li><strong class="bold"><st c="25165">Properly and consistently tag your images</st></strong><st c="25207">: Images are generally identified by two components: their name and their tag (e.g., </st><strong class="source-inline"><st c="25293">finoneacme/fund-transfer:2.34.3</st></strong><st c="25324">, where </st><strong class="source-inline"><st c="25332">finoneacme/fund-transfer</st></strong><st c="25356"> is the name and </st><strong class="source-inline"><st c="25373">2.34.3</st></strong><st c="25379"> is the tag). </st><st c="25393">When you build an image, it’s up to you to tag it properly but you should follow a consistent policy. </st><st c="25495">There are two common ways to do this that are used in </st><span class="No-Break"><st c="25549">the industry:</st></span><ul><li><strong class="bold"><st c="25562">Semantic versioning</st></strong><st c="25582">: A common way is using a version number. </st><st c="25625">The </st><strong class="bold"><st c="25629">Semantic Versioning Specification</st></strong> <em class="italic"><st c="25662">[4]</st></em><st c="25666"> provides an easy-to-follow guideline with a three-part</st><a id="_idIndexMarker490"/><st c="25721"> version number: </st><strong class="source-inline"><st c="25738">MAJOR.MINOR.PATCH</st></strong><st c="25755">. Every minor or patch version number must be for a backward-compatible change. </st><st c="25835">In combination with the version name </st><strong class="source-inline"><st c="25872">latest</st></strong><st c="25878">, which is the default to point to the latest available version, you can provide easy access to a specific image (e.g., </st><strong class="source-inline"><st c="25998">X.Y.Z</st></strong><st c="26003">). </st><st c="26007">It also allows for the selection of the latest patch release for a specific minor release (e.g., </st><strong class="source-inline"><st c="26104">X.Y</st></strong><st c="26107">) or the latest minor and patch version for a major release (</st><span class="No-Break"><st c="26169">e.g., </st></span><span class="No-Break"><strong class="source-inline"><st c="26176">X</st></strong></span><span class="No-Break"><st c="26177">).</st></span></li><li><strong class="bold"><st c="26179">Tagging using Git commit hash</st></strong><st c="26209">: When Git commits are triggering a CI build, it is best to directly use the </st><strong class="source-inline"><st c="26287">git commit</st></strong><st c="26297"> hash as version instead of keeping track of semantic versioning. </st><st c="26363">The commit hash</st><a id="_idIndexMarker491"/><st c="26378"> on the image also immediately tells us which source code commit was responsible for producing this container image. </st><st c="26495">For our image, this could mean it’s tagged like </st><span class="No-Break"><st c="26543">this: </st></span><span class="No-Break"><strong class="source-inline"><st c="26549">financeoneacme/fund-transfer:d85aaef</st></strong></span><span class="No-Break"><st c="26585">.</st></span></li></ul></li>
				<li><strong class="bold"><st c="26586">Scan your images for known vulnerabilities</st></strong><st c="26629">: Images that are built by your CI must be scanned for known vulnerabilities. </st><st c="26708">This can be done as part of an extra step in CI (e.g., call a scanning tool before uploading the image to the registry). </st><st c="26829">It can also be handled by the container registry itself. </st><st c="26886">Depending on the registry used, the image can be scanned during upload and blocked or quarantined if vulnerabilities are found. </st><st c="27014">This stops known vulnerabilities at the time of creating the container image. </st><st c="27092">Be aware that this does not stop vulnerabilities that are identified at a later time, such as the well-known </st><strong class="source-inline"><st c="27201">log4j</st></strong><st c="27206"> vulnerability. </st><st c="27222">This is why security must go beyond the static checks in the CI process and continue throughout the life cycle of an artifact. </st><st c="27349">This will be</st><a id="_idIndexMarker492"/><st c="27361"> explored more in </st><a href="B31164_07.xhtml#_idTextAnchor381"><span class="No-Break"><em class="italic"><st c="27379">Chapter 7</st></em></span></a><st c="27388">, which dives deeper into building and operating </st><span class="No-Break"><st c="27437">secure products.</st></span></li>
			</ul>
			<p><st c="27453">Now that we have a container image uploaded to our </st><a id="_idTextAnchor274"/><st c="27505">container registry, we can use it in a </st><span class="No-Break"><st c="27544">deployment definition.</st></span></p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor275"/><st c="27566">Phase 2 – from container image to metadata-enriched deployment artifact</st></h2>
			<p><st c="27638">The container image now needs to find its way into a deployment definition. </st><st c="27715">Looking at Kubernetes, we would need a manifest file that defines our deployment definition, which we can later apply to our </st><span class="No-Break"><st c="27840">K8s cluster.</st></span></p>
			<p><st c="27852">In </st><a href="B31164_03.xhtml#_idTextAnchor133"><span class="No-Break"><em class="italic"><st c="27856">Chapter 3</st></em></span></a><st c="27865">, we highlighted that adding </st><a id="_idIndexMarker493"/><st c="27894">metadata (ownership, observability level, notifications) to our deployment file will benefit lots of the self-service use cases, such as the </st><em class="italic"><st c="28035">Requesting Logs as Self-Service</st></em><st c="28066"> use case. </st><st c="28077">Besides our source code, we therefore also need to version control our deployment definition and should enforce a minimum set of metadata. </st><st c="28216">This enables our platform self-service use cases (e.g., who has deployed which services belong to which application) as well as following general infrastructure best </st><a id="_idIndexMarker494"/><st c="28382">practices (e.g., defining request and resource limits), as you can see in the </st><span class="No-Break"><st c="28460">following manifest:</st></span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US"><st c="28479">mainfest.yaml (Kubernetes Deployment)</st></p>
			<pre class="source-code"><st c="28517">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fund-transfer-service
spec:
  …
  template:
    metadata:
      annotations:
        # team ownership
        owner.team: dev-team-backend
        app.kubernetes.io/name: fund-transfer-service
        # app-context
        app.kubernetes.io/part-of: backend-services
        app.kubernetes.io/version: d85aaef
        # log level
        observability.logs.level: info
        # log source
        observability.logs.location: stdout
    …
    spec:
      containers:
      - name: fund-transfer
        image: "financeoneacme/fund-transfer:d85aaef"
        imagePullPolicy: IfNotPresent
        resources:
          # specify limits
          limits:
            memory: "200Mi"
            cpu: "2"
          requests:
            memory: "100Mi"
            cpu: "2"
    …</st></pre>
			<p><st c="29126">The deployment definition can be a manifest or a set of manifest files, as we likely also need additional K8s resources, such as a service or Ingress definition. </st><st c="29289">Instead of plain manifest files that we organize in a subfolder next to the source code of our service, there are options to leverage templating or</st><a id="_idIndexMarker495"/><st c="29436"> packaging frameworks and tools, such</st><a id="_idIndexMarker496"/><st c="29473"> as </st><strong class="bold"><st c="29477">Kustomize</st></strong> <em class="italic"><st c="29486">[5]</st></em><st c="29490"> or </st><span class="No-Break"><strong class="bold"><st c="29494">Helm</st></strong></span><span class="No-Break"> </span><span class="No-Break"><em class="italic"><st c="29498">[6]</st></em></span><span class="No-Break"><st c="29502">.</st></span></p>
			<p><st c="29503">It is important to consider how to organize and version control all of our everything as code files. </st><st c="29605">There are several strategies with pros and cons that are well documented. </st><st c="29679">To learn more, the authors suggest reading up on the different patterns for repositories and directory structures. </st><st c="29794">The following section is just a quick overview of wha</st><a id="_idTextAnchor276"/><st c="29847">t you must know to continue your in-depth research on </st><span class="No-Break"><st c="29902">this topic!</st></span></p>
			<h3><st c="29913">Monorepo versus polyrepo</st></h3>
			<p><st c="29938">When designing your git repository structure, you have two general options which the industry refers to as monorepo</st><a id="_idIndexMarker497"/><st c="30054"> or polyrepo; a single Git repository or multiple repositories split by teams</st><a id="_idIndexMarker498"/> <span class="No-Break"><st c="30131">or functions:</st></span></p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B31164_05_03.jpg" alt="Figure 5.3: Mono versus polyrepo – pros and cons for both patterns"/><st c="30145"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="30266">Figure 5.3: Mono versus polyrepo – pros and cons for both patterns</st></p>
			<ul>
				<li><strong class="bold"><st c="30332">Monorepo</st></strong><st c="30341">: In the</st><a id="_idIndexMarker499"/><st c="30350"> monorepo pattern, all configuration files (code, infrastructure, observability, etc.) are stored in a single Git repository. </st><st c="30476">This pattern applies to every potential environment (dev, testing, staging, production)—meaning every configuration is in a single Git repo, separated </st><span class="No-Break"><st c="30627">by folders.</st></span><p class="list-inset"><st c="30638">The benefit of a</st><a id="_idIndexMarker500"/><st c="30655"> monorepo is that everything is in one place. </st><st c="30701">The downside is that this repo will eventually become very large, resulting in potential performance issues when tools like ArgoCD or Flux need to constantly scan the entire repo for changes. </st><st c="30893">It also makes it harder to separate the concerns between application and </st><span class="No-Break"><st c="30966">infrastructure owners.</st></span></p></li>
				<li><strong class="bold"><st c="30988">Polyrepo</st></strong><st c="30997">: In the </st><a id="_idIndexMarker501"/><st c="31007">polyrepo pattern, we have multiple repositories, which makes it easier to separate concerns. </st><st c="31100">These can be repositories per team (app team A, B, C), per environment (dev, staging, prod, etc.), per tenant (in multi-tenancy systems), or per organizational boundary (app teams, platform </st><span class="No-Break"><st c="31290">teams, etc.).</st></span><p class="list-inset"><st c="31303">The </st><a id="_idIndexMarker502"/><st c="31308">benefit is a better separation of concerns. </st><st c="31352">The downside is that we eventually end up managing a large number of Git repositories, which makes it harder to ensure consistency and overall validity across all configuratio</st><a id="_idTextAnchor277"/><st c="31527">ns spread across multiple repos that make up the </st><span class="No-Break"><st c="31577">entire configuration.</st></span></p></li>
			</ul>
			<h3><st c="31598">Directory structure – follow the DRY principle</st></h3>
			<p><st c="31645">Whether mono or polyrepo, the individual</st><a id="_idIndexMarker503"/><st c="31686"> Git repository will need to have a good directory structure. </st><st c="31748">Typically, we see it reflecting the organizational structure separating the development teams from the teams that manage the underlying infrastructure or platform. </st><st c="31912">A good practice is to follow </st><a id="_idIndexMarker504"/><st c="31941">the </st><strong class="bold"><st c="31945">don’t repeat yourself</st></strong><st c="31966"> (</st><strong class="bold"><st c="31968">DRY</st></strong><st c="31971">) </st><em class="italic"><st c="31974">[7]</st></em><st c="31977">  principle. </st><st c="31989">The idea is to find the best structure to avoid copying/pasting common YAML settings in different places. </st><st c="32095">This is where tools such as Helm and </st><span class="No-Break"><st c="32132">Kustomize help.</st></span></p>
			<p><st c="32147">The following structure example was inspired by a GitOps blog</st><a id="_idIndexMarker505"/><st c="32209"> from </st><strong class="bold"><st c="32215">Red Hat</st></strong> <em class="italic"><st c="32222">[8]</st></em><st c="32226"> and shows the configuration for the platform administrator and the configuration for an application team using a templating tool such </st><a id="_idIndexMarker506"/><st c="32361">as Kustomize. </st><st c="32375">This structure could either be used in a single monorepo separated by a folder, or it could be put into individual repos following the </st><span class="No-Break"><st c="32510">polyrepo pattern.</st></span></p>
			<table id="table001-4" class="T---Table _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="T---Table">
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="32527">Platform Team</st></strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="32541">Development Team</st></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><strong class="source-inline"><st c="32558">├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32563">bootstrap</st></strong></span></p>
							<p><strong class="source-inline"><st c="32572">│   ├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32579">base</st></strong></span></p>
							<p><strong class="source-inline"><st c="32583">│   └── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32590">overlays</st></strong></span></p>
							<p><strong class="source-inline"><st c="32598">│       └── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32605">default</st></strong></span></p>
							<p><strong class="source-inline"><st c="32612">├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32617">cluster-config</st></strong></span></p>
							<p><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="32631">│</st></strong><strong class="source-inline"/><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="32633">├── </st></strong><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="32637">gitops-controller</st></strong></span></p>
							<p><strong class="source-inline"><st c="32654">│   ├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32661">identity-provider</st></strong></span></p>
							<p><strong class="source-inline"><st c="32678">│   └── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32685">image-scanner</st></strong></span></p>
							<p><strong class="source-inline"><st c="32698">└── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32703">components</st></strong></span></p>
							<p><strong class="source-inline"/><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="32713">├── </st></strong><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="32718">applicationsets</st></strong></span></p>
							<p><strong class="source-inline"><st c="32733">    ├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32738">applications</st></strong></span></p>
							<p><strong class="source-inline"/><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="32750">└── </st></strong><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="32755">argocdproj</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><strong class="source-inline"><st c="32765">└── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32770">deploy</st></strong></span></p>
							<p><strong class="source-inline"><st c="32776">    ├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32781">base</st></strong></span></p>
							<p><strong class="source-inline"><st c="32785">    └── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32790">overlays</st></strong></span></p>
							<p><strong class="source-inline"><st c="32798">        ├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32803">dev</st></strong></span></p>
							<p><strong class="source-inline"><st c="32806">        ├── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32811">prod</st></strong></span></p>
							<p><strong class="source-inline"><st c="32815">        └── </st></strong><span class="No-Break"><strong class="source-inline"><st c="32820">stage</st></strong></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="32825">Table 5.1: One possible directory structure used by tools such as Kustomize</st></p>
			<p><st c="32901">Now that we have learned about the different ways to organize our repositories and directory structures, we need to learn how the new container image in </st><em class="italic"><st c="33055">Phase 1</st></em><st c="33062"> makes it to our deployment definition in </st><span class="No-Break"><st c="33104">our repositories!</st></span></p>
			<h3><a id="_idTextAnchor278"/><st c="33121">Updating manifest with new container image version</st></h3>
			<p><st c="33172">The last piece to </st><em class="italic"><st c="33191">Phase 2</st></em><st c="33198"> is to promote a</st><a id="_idIndexMarker507"/><st c="33214"> new image version that came out of CI into our deployment files. </st><st c="33280">This could be updating the deployment manifest, as shown in the preceding example, or updating a </st><strong class="source-inline"><st c="33377">values.yaml</st></strong><st c="33388"> file when using </st><span class="No-Break"><st c="33405">Helm charts.</st></span></p>
			<p><st c="33417">As those configuration files are version-controlled in a Git repository (mono or poly, it doesn’t matter), we should follow the regular Git workflow and create a Pull Request to promote the update of that image. </st><st c="33630">We can automate the creation of that Pull Request in </st><span class="No-Break"><st c="33683">two ways:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="33692">Step in CI pipeline</st></strong><st c="33712">: As the last step in CI, a Pull Request</st><a id="_idIndexMarker508"/><st c="33753"> can be opened, promoting the new image tag to the respective deployment definition repo and the right directory structure (for example, updating the values in the development overlay directory if this is a newly </st><span class="No-Break"><st c="33966">built image)</st></span></li>
				<li><strong class="bold"><st c="33978">Webhook in a container registry</st></strong><st c="34010">: When the registry receives a new image from CI, it can trigger a webhook, which allows </st><a id="_idIndexMarker509"/><st c="34100">us to create that same Pull Request in our deployment </st><span class="No-Break"><st c="34154">Git repository</st></span></li>
			</ul>
			<p><st c="34168">The following shows the updated version information of the </st><em class="italic"><st c="34228">Kubernetes Deployment</st></em><st c="34249">  that we have seen in the earlier example. </st><st c="34292">You can compare this with the values of the </st><span class="No-Break"><st c="34336">previous example:</st></span></p>
			<pre class="source-code"><st c="34353">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fund-transfer-service
spec:
  …
  template:
    metadata:
      annotations:
        owner.team: dev-team-backend
        app.kubernetes.io/name: fund-transfer-service
        app.kubernetes.io/part-of: backend-services
        app.kubernetes.io/version: a3456bc
        observability.logs.level: info
        observability.logs.location: stdout
    …
    spec:
      containers:
      - name: fund-transfer
        image: "financeoneacme/fund-transfer:a3456bc"
    …</st></pre>
			<p><st c="34780">Now, we know how a new image that is built by CI makes it into the deployment definition in our respective repositories. </st><st c="34902">We already saw the GitOps operator in an image earlier in this chapter. </st><st c="34974">Now, it’s time to dive into what the GitOps operator really does to apply our desired state from Git to our </st><span class="No-Break"><st c="35082">target cluster</st><a id="_idTextAnchor279"/><st c="35096">s!</st></span></p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor280"/><st c="35099">Phase 3 – GitOps – keeping your desired deployment state</st></h2>
			<p><st c="35156">Now that we have everything as code in Git, it’s time to talk about how to apply that configuration to our target environments. </st><st c="35285">One way is to use the same push model as we use for CI. </st><st c="35341">We could have delivery pipelines get triggered on changes in our Git repository and then have the latest version of the manifests or helm charts applied to the target environment. </st><st c="35521">In this chapter, we, however, focus on and favor the Pull model, which is implemented by GitOps operators or GitOps agents, such as Argo CD, Flux, and some </st><span class="No-Break"><st c="35677">commercial offering</st><a id="_idTextAnchor281"/><st c="35696">s.</st></span></p>
			<h3><st c="35699">GitOps operators in a nutshell – sync Git to K8s</st></h3>
			<p><st c="35748">GitOps operators</st><a id="_idIndexMarker510"/><st c="35765"> continuously reconcile and ensure that the desired state declared in our repositories matches the actual state running in our target environments. </st><st c="35913">The operator detects an </st><em class="italic"><st c="35937">out-of-sync</st></em><st c="35948"> if the state in Git does not match the one on the target environment. </st><st c="36019">This could happen if the Git configuration was changed (e.g., a new image is available and causes a manifest update). </st><st c="36137">It can also happen if somebody changes the configuration in K8s (e.g., through a manual update or a different automation tooling). </st><st c="36268">The following is a high-level overview showing the role of the </st><span class="No-Break"><st c="36331">GitOps operator:</st></span></p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B31164_05_04.jpg" alt="Figure 5.4: GitOps operator synchronizes the desired state in Git with the actual state in K8s"/><st c="36347"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="36448">Figure 5.4: GitOps operator synchronizes the desired state in Git with the actual state in K8s</st></p>
			<p><st c="36542">Depending on the GitOps operator tool, there will be different configuration options in the reconciliation process. </st><st c="36659">It’s worth checking out the documentation of the two prominent tools in the cloud native </st><a id="_idIndexMarker511"/><st c="36748">ecosystem: </st><strong class="bold"><st c="36759">Argo CD</st></strong> <em class="italic"><st c="36766">[9]</st></em><st c="36770"> and </st><strong class="bold"><st c="36775">Flux</st></strong> <em class="italic"><st c="36779">[10]</st></em><st c="36784">. Also, make </st><a id="_idIndexMarker512"/><st c="36797">yourself familiar with the configuration elements, as some tools have a concept of projects and applications, whereas others just have a concept of </st><span class="No-Break"><st c="36945">a sou</st><a id="_idTextAnchor282"/><st c="36950">rce.</st></span></p>
			<h3><st c="36955">Understanding reconciliation – keeping K8s in sync with Git</st></h3>
			<p><st c="37015">Essentially, the GitOps operator will fetch the desired state for a project or application from a source (Git repository, a folder in the Git repository, the OCI repository, S3 buckets, etc.) and compare it with the current state running on the target K8s cluster. </st><st c="37281">The two states can either be </st><em class="italic"><st c="37310">synced</st></em><st c="37316"> or </st><em class="italic"><st c="37320">out-of-sync</st></em><st c="37331">. When the state is </st><em class="italic"><st c="37351">out-of-sync</st></em><st c="37362">, there are different options for the GitOps operator to synchronize the states – meaning: bring the current state to match the </st><span class="No-Break"><st c="37490">desired state:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="37504">Manual sync</st></strong><st c="37516">: Either via</st><a id="_idIndexMarker513"/><st c="37529"> a </st><strong class="bold"><st c="37532">command-line interface</st></strong><st c="37554"> (</st><strong class="bold"><st c="37556">CLI</st></strong><st c="37559">) or a</st><a id="_idIndexMarker514"/><st c="37566"> UI, one can trigger the GitOps operator to synchronize the </st><span class="No-Break"><st c="37626">two states.</st></span></li>
				<li><strong class="bold"><st c="37637">Auto sync</st></strong><st c="37647">: Once a </st><a id="_idIndexMarker515"/><st c="37657">system is out-of-sync, the GitOps operator tries to </st><span class="No-Break"><st c="37709">automatically synchronize.</st></span></li>
				<li><strong class="bold"><st c="37735">Sync schedules/windows</st></strong><st c="37758">: There might</st><a id="_idIndexMarker516"/><st c="37772"> be times when you want or don’t want syncs to happen. </st><st c="37827">This is where sync schedules or sync windows come in, which either block or allow syncs </st><span class="No-Break"><st c="37915">to happen.</st></span></li>
				<li><strong class="bold"><st c="37925">Sync failed</st></strong><st c="37937">: It can happen </st><a id="_idIndexMarker517"/><st c="37954">that the GitOps operator can’t apply the desired state. </st><st c="38010">This could be because of configuration file mistakes (e.g., referencing an invalid image). </st><st c="38101">It could be because of an infrastructure issue (e.g., K8s doesn’t have enough resources). </st><st c="38191">It could also be because of competing tools (e.g., auto-scaling tools, such as HPA/KEDA, changing replicas or resource limits). </st><st c="38319">It’s important to be aware of this state and handle it correctly. </st><st c="38385">See the section on best practices for some </st><span class="No-Break"><st c="38428">additional input!</st></span></li>
			</ul>
			<p><st c="38445">Now that we are aware of the synchronization basics, let’s have a look at different GitOps operator </st><span class="No-Break"><st c="38546">deployment </st><a id="_idTextAnchor283"/><st c="38557">patterns!</st></span></p>
			<h3><st c="38566">GitOps operator patterns – single, hub and spoke, and many-to-many</st></h3>
			<p><st c="38633">The simplest version – and</st><a id="_idIndexMarker518"/><st c="38660"> probably the model that many start with – is the monorepo approach with GitOps operators pulling into a single target environment, as we have seen in </st><span class="No-Break"><em class="italic"><st c="38811">Figure 5</st></em></span><em class="italic"><st c="38819">.3</st></em><st c="38821"> for both patterns. </st><st c="38841">While the single target is a common pattern, especially as you are getting started with GitOps, we have other patterns that we want to </st><span class="No-Break"><st c="38976">quickly highlight.</st></span></p>
			<p><st c="38994">GitOps can also be set up where we have a central GitOps operator that keeps the desired state as declared in Git and synchronizes with several target environments by pushing out those changes. </st><st c="39189">This is called</st><a id="_idIndexMarker519"/><st c="39203"> the </st><strong class="bold"><st c="39208">hub-and-spoke model</st></strong><st c="39227">. Another option is the </st><strong class="bold"><st c="39251">many-to-many model</st></strong><st c="39269">, where each target environment has its own GitOps </st><a id="_idIndexMarker520"/><st c="39320">operator that continuously synchronizes the desired state with the state on its own cluster, as shown in the </st><span class="No-Break"><st c="39429">following figure:</st></span></p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B31164_05_05.jpg" alt="Figure 5.5: Hub-and-spoke and many-to-many GitOps operator pattern"/><st c="39446"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="39503">Figure 5.5: Hub-and-spoke and many-to-many GitOps operator pattern</st></p>
			<p><st c="39569">Now that we have discussed the major phases in GitOps, let’s recap and have a quick look into some </st><span class="No-Break"><st c="39669">best</st><a id="_idTextAnchor284"/><st c="39673"> practices.</st></span></p>
			<h3><st c="39684">GitOps best practices</st></h3>
			<p><st c="39706">This list is not complete but should </st><a id="_idIndexMarker521"/><st c="39744">give you a good starting point when defining your</st><a id="_idIndexMarker522"/> <span class="No-Break"><st c="39793">GitOps process:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="39809">Separate config from source code repositories/folders</st></strong><st c="39863">: It’s recommended to separate the actual source code from the deployment definitions. </st><st c="39951">Either in separate repositories or, within the repo, in separate folders. </st><st c="40025">Why is that? </st><st c="40038">It’s a clean separation of concerns and access. </st><st c="40086">It makes Git-triggered actions easier as a change in a deployment config file should trigger different actions than in the source code files. </st><st c="40228">It avoids a potentially infinite loop of change if CI changes the same repository! </st><st c="40311">The smaller the repository, the less work for GitOps tools to scan all files to determine the </st><span class="No-Break"><st c="40405">desired state.</st></span></li>
				<li><strong class="bold"><st c="40419">Proper sync settings – poll versus webhook</st></strong><st c="40462">: GitOps tools provide different sync settings for both scanning the source systems (e.g., Git) and scheduling the triggering of synchronizations. </st><st c="40610">For scanning, make yourself familiar with the default poll frequency (e.g., Argo CD, by default, pulls all Git repos every three minutes). </st><st c="40749">Both Argo CD and Flux can also be changed to receive webhooks from the Git system, which replaces the pull into a push mechanism! </st><st c="40879">This is very important to understand, as with an increase in the number of source systems (Git, artifact repositories, S3 buckets, etc.), the number of API calls from your GitOps tool to those systems increases. </st><st c="41091">It’s a good practice to monitor the number of calls made from the GitOps tool to those external systems to get alerted in case the behavior drastically changes. </st><st c="41252">A change in behavior could be caused by an accidental configuration change of default settings. </st><st c="41348">Most tools provide Prometheus or OpenTelemetry metrics that can be observed by your </st><span class="No-Break"><st c="41432">observability tool!</st></span><p class="list-inset"><st c="41451">The authors have seen configurations that ended in API rate limits and even crashing Git systems due to too much load produced by the GitOps tools during </st><span class="No-Break"><st c="41606">a sync!</st></span></p></li>
				<li><strong class="bold"><st c="41613">Not every config must be in a manifest</st></strong><st c="41652">: As GitOps keeps track of desired versus actual state, it’s important to leave some configuration out of your manifest that might be managed by different tools. </st><st c="41815">Take replicas as an example. </st><st c="41844">If you are using tools such as HPA or KEDA to auto-scale your pods, you do not want a static replicas count in your manifest. </st><st c="41970">This would lead the GitOps tool to detect out-of-syncs for any change that HPA/KEDA does. </st><st c="42060">This, therefore, results in two automation tools competing with </st><span class="No-Break"><st c="42124">each other.</st></span></li>
				<li><strong class="bold"><st c="42135">GitOps notifications to handle sync states</st></strong><st c="42178">: GitOps tools provide notifications when sync status changes. </st><st c="42242">This would be when GitOps detects an out-of-sync, when it finishes a sync, or when there is an issue and a sync fails. </st><st c="42361">In all those cases, it’s important to get notified as you want to make sure that you handle sync failures or send information back to the development </st><a id="_idIndexMarker523"/><st c="42511">team when the latest update has successfully </st><span class="No-Break"><st c="42556">been</st></span><span class="No-Break"><a id="_idIndexMarker524"/></span><span class="No-Break"><st c="42560"> synced.</st></span></li>
			</ul>
			<p><st c="42568">To get notified, GitOps tools will create Kubernetes events that you can ingest into your observability solution and then react/alert on them. </st><st c="42712">GitOps tools also typically provide some type of native notification feature where an external tool can be triggered in the case of a special event. </st><st c="42861">Flux, for instance, provides Alerts, whereas Argo CD provides a concept of notifications. </st><st c="42951">Both allow you to, for example, send Slack messages or trigger other external tools in the case of certain events that </st><span class="No-Break"><st c="43070">need attention!</st></span></p>
			<p class="callout-heading"><st c="43085">GitOps – changing from push to pull</st></p>
			<p class="callout"><st c="43121">GitOps expands the power of Git from application code to everything as code. </st><st c="43199">While CI/CD still focuses on building artifacts, GitOps provides an elegant way to pull the desired deployment state into any target environment along the software development life cycle. </st><st c="43387">Changes to a system can only be done through Git with the benefit of traceability of changes, revertability to a previous version, and enforcing review processes through </st><span class="No-Break"><st c="43557">Pull Requests.</st></span></p>
			<p><st c="43571">Now that we have covered the basics of GitOps, we should see how this can benefit us in building modern platforms. </st><st c="43687">As platform teams, we can centrally enforce best practices (version control, policies, etc.) by using automation in CI/CD and the container registry to reduce the chance of a bad change request. </st><st c="43882">With Git, every change and deployment is traceable back to a Git commit, making troubleshooting much easier, and it also provides an additional level of self-service (e.g., notify development teams when their change has been synchronized to the target environment or notify them when their latest version (via the </st><strong class="source-inline"><st c="44196">git commit</st></strong><st c="44206"> hash) has </st><span class="No-Break"><st c="44217">any issues).</st></span></p>
			<p><st c="44229">Now, let’s go on and spend some time on container registries as, without them, we wouldn’t be able to publish or distribute any of the images that are being produced by the development teams that leverage the platform as </st><a id="_idTextAnchor285"/><span class="No-Break"><st c="44451">a self-service.</st></span></p>
			<h1 id="_idParaDest-117"><a id="_idTextAnchor286"/><st c="44466">Understanding the importance of container and artifact registries as entry points</st></h1>
			<p><st c="44548">Container and artifact registries deserve their own chapter as they are one of the core building blocks of modern cloud-native platforms. </st><st c="44687">However, we will try to provide the relevant knowledge that should help you follow along with what’s to come in the later chapters of </st><span class="No-Break"><st c="44821">this book.</st></span></p>
			<p><st c="44831">We differentiate between public and </st><span class="No-Break"><st c="44868">private registries:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="44887">Public registries</st></strong><st c="44905"> are commonly </st><a id="_idIndexMarker525"/><st c="44919">used by individuals or small teams that want to get up and running with their registries as quickly as possible. </st><st c="45032">However, at some point, it’s worth looking at </st><span class="No-Break"><st c="45078">private registries.</st></span></li>
				<li><strong class="bold"><st c="45097">Private registries</st></strong><st c="45116"> provide</st><a id="_idIndexMarker526"/><st c="45124"> several critical capabilities, such as efficient storage of images, scanning for vulnerabilities, replicating images to other registries, enforcing access control when images get pulled, and notifying other tools about updates, with the ultimate goal of making images fast and easily accessible to those environments that need to </st><span class="No-Break"><st c="45455">deploy them.</st></span></li>
			</ul>
			<p><st c="45467">While private container registries are typically only accessed internally to push new builds and have them pulled by our GitOps tools, we can also open the registry to the</st><em class="italic"><st c="45639"> public</st></em><st c="45646">. With the </st><em class="italic"><st c="45657">public</st></em><st c="45663">, we mean</st><a id="_idIndexMarker527"/><st c="45672"> allowing third-party vendors the option to push their latest images or deployment artifacts. </st><st c="45766">As organizations rely on third-party software – think about any off-the-shelf software product you deploy yourself – we can leverage the same process of vulnerability scanning, replication, and access control before that software gets deployed on the internal systems. </st><st c="46035">Financial One ACME, for instance, could allow their third-party vendors for a Development Ticketing System to push new versions to that public endpoint. </st><st c="46188">Once scanned and validated, it can be deployed to the internal K8s clusters that run all the </st><span class="No-Break"><st c="46281">development tooling.</st></span></p>
			<p><st c="46301">The following illustration is a very high-level overview of how container registries integrate into the end-to-end delivery process that starts with pushing a new artifact (third-party or CI/CD) until that new artifact gets deployed to the </st><span class="No-Break"><st c="46542">target environments:</st></span></p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B31164_05_06.jpg" alt="Figure 5.6: Container registries – the heartbeat of our platform"/><st c="46562"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="46750">Figure 5.6: Container registries – the heartbeat of our platform</st></p>
			<p><st c="46814">While there is a lot of in-depth information available from the different open source and commercial registry vendors, we want to give a quick overview of how registries fit into our platform engineering architecture, why certain concepts are important, and how we can best make container registries available to our end users as an easy to </st><a id="_idTextAnchor287"/><span class="No-Break"><st c="47156">use self-service!</st></span></p>
			<h2 id="_idParaDest-118"><a id="_idTextAnchor288"/><st c="47173">From container to artifact registry</st></h2>
			<p><st c="47209">Before diving into the </st><a id="_idIndexMarker528"/><st c="47233">process, we need to quickly highlight that container registries – while the name implies it – are not limited to container images. </st><st c="47364">Most container registries typically support the OCI </st><em class="italic"><st c="47416">[11]</st></em><st c="47420"> image standard. </st><st c="47437">Over the past years, container registries expanded to support non-container artifacts such as Helm Charts, zipped versions of Manifests, or Kustomize-based templates. </st><st c="47604">That expansion also came with a name change for artifact registries as those tools manage artifacts in general and not just </st><span class="No-Break"><st c="47728">container images.</st></span></p>
			<p><st c="47745">But that is not all. </st><st c="47767">Artifact registries, open source, or </st><strong class="bold"><st c="47804">SaaS</st></strong><st c="47808"> (short for </st><strong class="bold"><st c="47820">Software as a Service</st></strong><st c="47841">) services, often come </st><a id="_idIndexMarker529"/><st c="47865">with additional features, such as access control, regional replication, audit logging, policy enforcement, security scanning, notificatio</st><a id="_idTextAnchor289"/><st c="48002">ns, and </st><span class="No-Break"><st c="48011">even more.</st></span></p>
			<h2 id="_idParaDest-119"><a id="_idTextAnchor290"/><st c="48021">Building and pushing artifacts to the registry</st></h2>
			<p><em class="italic"><st c="48068">Uploading</st></em><st c="48078"> (</st><em class="italic"><st c="48080">pushing</st></em><st c="48087">) and </st><em class="italic"><st c="48094">downloading</st></em><st c="48105"> (</st><em class="italic"><st c="48107">pulling</st></em><st c="48114">) images can be done </st><a id="_idIndexMarker530"/><st c="48136">using Docker (or other tools, such as Podman) commands. </st><st c="48192">Before doing so, you need to authenticate against the registry (your private or public registry, such as Docker Hub). </st><st c="48310">Once authenticated, it’s easy to push and pull, as shown in the </st><span class="No-Break"><st c="48374">following code:</st></span></p>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US"><st c="48389">Interacting with the container registry via docker commands</st></p>
			<pre class="source-code"><st c="48449">
export REGISTRY=registry.finone.acme
# Authenticate
docker login -u YOURUSER -p YOURPASSWORD $REGISTRY
# Build an image
docker build -t $REGISTRY/financeoneacme/fund-transfer:1.2.3 .
</st><st c="48633"># Push an image
docker push $REGISTRY/financeoneacme/fund-transfer:1.2.3
# Pull an image
docker pull $REGISTRY/financeoneacme/fund-transfer:1.2.3</st></pre>
			<p><st c="48778">When building new images as part of the CI process, it’s important to follow best practices around image labels and metadata. </st><st c="48905">The OCI therefore also has a list of suggested annotations </st><em class="italic"><st c="48964">[12]</st></em><st c="48968"> as part of their image spec that should be used, such as </st><strong class="source-inline"><st c="49026">created</st></strong><st c="49033">, </st><strong class="source-inline"><st c="49035">authors</st></strong><st c="49042">, </st><strong class="source-inline"><st c="49044">url</st></strong><st c="49047">, and </st><strong class="source-inline"><st c="49053">documentation</st></strong><st c="49066"> (all prefixed </st><span class="No-Break"><st c="49081">with </st></span><span class="No-Break"><strong class="source-inline"><st c="49086">org.opencontainers.image.</st></strong></span><span class="No-Break"><st c="49111">).</st></span></p>
			<p><st c="49114">Next to an API interface, registries typically also provide</st><a id="_idIndexMarker531"/><st c="49174"> a </st><strong class="bold"><st c="49177">user interface</st></strong><st c="49191"> (</st><strong class="bold"><st c="49193">UI</st></strong><st c="49195">) that makes it easier to see what images are uploaded, how much space they consume, and – depending on the management features of the registry – also provides the configurational aspects of all those capabilities (e.g., creating projects, managing users, specifying policies, configu</st><a id="_idTextAnchor291"/><st c="49480">ring </st><span class="No-Break"><st c="49486">webhooks, etc.).</st></span></p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor292"/><st c="49502">Managing uploaded artifacts</st></h2>
			<p><st c="49530">Registries typically</st><a id="_idIndexMarker532"/><st c="49551"> manage artifacts in projects. </st><st c="49582">Projects can be private or public within the registry, meaning that artifacts in a public project can be accessed by anyone who can reach the registry, while private projects can only be reached by authorized users. </st><st c="49798">That brings us to user management and access controls, which can be defined on a project level, and can also feed into access logs. </st><st c="49930">Registries will create logs for every push and pull to have a good audit trail. </st><st c="50010">The CNCF Harbor</st><a id="_idIndexMarker533"/><st c="50025"> is a very popular container registry that also provides good documentation about all those features. </st><st c="50127">Instead of going into detail here, we suggest you read up on the publicly available documentation </st><em class="italic"><st c="50225">[13]</st></em><st c="50229"> for all those features. </st><st c="50254">What is important to remember is how to organize your images into projects and who you give access to. </st><st c="50357">If we also want to allow external third parties to push their images to our registries, you can create specific users for them that allow them to upload to the respect</st><a id="_idTextAnchor293"/><st c="50524">ive </st><span class="No-Break"><st c="50529">container projects!</st></span></p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor294"/><st c="50548">Vulnerability scanning</st></h2>
			<p><a href="B31164_07.xhtml#_idTextAnchor381"><span class="No-Break"><em class="italic"><st c="50571">Chapter 7</st></em></span></a><st c="50581"> focuses on security in more detail but it’s important to mention here that a central component, such as an artifact registry where every artifact has to pass through, is a perfect place for static vulnerability checking. </st><st c="50803">Registries often provide out-of-the-box</st><a id="_idIndexMarker534"/><st c="50842"> scanning capabilities or allow the integration of additional tools depending on the artifact type. </st><st c="50942">Those tools would then be called either during the upload of a new image to get scanned as images arrive or on a schedule to make sure that images get scanned and rescanne</st><a id="_idTextAnchor295"/><st c="51113">d on a </st><span class="No-Break"><st c="51121">continuous basis.</st></span></p>
			<h2 id="_idParaDest-122"><a id="_idTextAnchor296"/><st c="51138">Subscribing to the life cycle events of an artifact in the registry</st></h2>
			<p><st c="51206">An artifact typically runs</st><a id="_idIndexMarker535"/><st c="51233"> through different life cycle stages from the initial upload (push), security scan, replication to other repositories, and downloads (pull) until an artifact is deleted as it is no longer needed. </st><st c="51429">Looking at Harbor as an example registry, we can also subscribe to all of those life cycle stages using webhooks. </st><st c="51543">This enables a lot of interesting use cases, such as </st><span class="No-Break"><st c="51596">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="51610">Security</st></strong><st c="51619">: Notify security team on </st><span class="No-Break"><st c="51646">new vulnerabilities</st></span></li>
				<li><strong class="bold"><st c="51665">Storage</st></strong><st c="51673">: Clean up old images in case storage quotas </st><span class="No-Break"><st c="51719">are reached</st></span></li>
				<li><strong class="bold"><st c="51730">Deploy</st></strong><st c="51737">: New images uploaded from CI/CD or </st><span class="No-Break"><st c="51774">third-party vendors</st></span></li>
				<li><strong class="bold"><st c="51793">Audit</st></strong><st c="51799">: Keep track of who is pulling </st><span class="No-Break"><st c="51831">which artifacts</st></span></li>
			</ul>
			<p><st c="51846">For reference, here is the full list of available life cycle events that can be used with webhooks: </st><strong class="source-inline"><st c="51947">artifact deleted</st></strong><st c="51963">, </st><strong class="source-inline"><st c="51965">artifact pulled</st></strong><st c="51980">, </st><strong class="source-inline"><st c="51982">artifact pushed</st></strong><st c="51997">, </st><strong class="source-inline"><st c="51999">chart deleted</st></strong><st c="52012">, </st><strong class="source-inline"><st c="52014">chart downloaded</st></strong><st c="52030">, </st><strong class="source-inline"><st c="52032">chart uploaded</st></strong><st c="52046">, </st><strong class="source-inline"><st c="52048">quota exceeded</st></strong><st c="52062">, </st><strong class="source-inline"><st c="52064">quote near threshold</st></strong><st c="52084">, </st><strong class="source-inline"><st c="52086">replication finished</st></strong><st c="52106">, </st><strong class="source-inline"><st c="52108">scanning faile</st><a id="_idTextAnchor297"/><st c="52122">d</st></strong><st c="52124">, and </st><span class="No-Break"><strong class="source-inline"><st c="52130">scanning finished</st></strong></span><span class="No-Break"><st c="52147">.</st></span></p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor298"/><st c="52148">Retention and immutability</st></h2>
			<p><st c="52175">Repositories can grow really </st><a id="_idIndexMarker536"/><st c="52205">quickly – potentially</st><a id="_idIndexMarker537"/><st c="52226"> leading to high storage costs if you don’t have a good cleanup strategy. </st><st c="52300">This is why it is advisable to clean old images that are no longer needed. </st><st c="52375">Some registries, therefore, provide out-of-the-box retention policies where you can define the images that match certain rules that will be retained and for how long. </st><st c="52542">Once images fall out of the retention period, they will </st><span class="No-Break"><st c="52598">be deleted.</st></span></p>
			<p><st c="52609">Another use case is that, by</st><a id="_idIndexMarker538"/><st c="52638"> default, everyone can upload a new image with the same</st><a id="_idIndexMarker539"/><st c="52693"> image tag, leaving the previous image version tagless. </st><st c="52749">To prevent this, some registries provide immutability rules, which prevent tags from being </st><a id="_idTextAnchor299"/><st c="52840">removed from </st><span class="No-Break"><st c="52853">existing images!</st></span></p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor300"/><st c="52869">Monitoring our registries</st></h2>
			<p><st c="52895">As registries are the heartbeat</st><a id="_idIndexMarker540"/><st c="52927"> of our platform, we need to make sure they stay healthy. </st><st c="52985">If registries stop processing push or pull requests, can’t execute vulnerability checks, and can’t replicate to other registries or send out notifications, then we have a problem! </st><st c="53165">It means that critical updates won’t make it into the target environments fast enough. </st><st c="53252">This could mean that a security vulnerability – while fixed through a new image – can’t be remediated as the new image can’t be delivered to the infected environment. </st><st c="53419">It can also mean that we can’t ship new features in the time </st><span class="No-Break"><st c="53480">we promised.</st></span></p>
			<p><st c="53492">To observe the health of our registries, we can monitor their various health metrics. </st><st c="53579">In self-hosted registries, those metrics are often exposed via Prometheus or a custom REST API. </st><st c="53675">In SaaS-hosted registries, those metrics are typically exposed via the vendor’s monitoring service API, such as </st><span class="No-Break"><st c="53787">AWS CloudWatch.</st></span></p>
			<p><st c="53802">A good reference is Harbor, the CNCF project we mentioned earlier. </st><st c="53870">It exposes lots of important metrics </st><a id="_idIndexMarker541"/><st c="53907">via </st><strong class="bold"><st c="53911">Prometheus</st></strong> <em class="italic"><st c="53921">[14]</st></em><st c="53926">, including the number of projects and repositories within a project, storage used, number of tasks executed and queued as well as performance metrics on the Harbor APIs (e.g., how long it takes to push or </st><span class="No-Break"><st c="54132">pull artifacts).</st></span></p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B31164_05_07.jpg" alt="Figure 5.7: Monitoring our registry to identify potential problems early"/><st c="54148"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="54225">Figure 5.7: Monitoring our registry to identify potential problems early</st></p>
			<p><st c="54297">Harbor</st><a id="_idIndexMarker542"/><st c="54304"> is also an early adopter of OpenTelemetry, the CNCF project that initially introduced a standard for distributed tracing to the cloud-native community. </st><st c="54457">Harbor provides </st><a id="_idIndexMarker543"/><st c="54473">an </st><strong class="bold"><st c="54476">OpenTelemetry exporter</st></strong> <em class="italic"><st c="54498">[15]</st></em><st c="54503">, generating traces with even more detailed information that can be used for both health monitoring as well </st><span class="No-Break"><st c="54611">as troubleshooting!</st></span></p>
			<p class="callout-heading"><st c="54630">Registries – the central hub for all our artifacts</st></p>
			<p class="callout"><strong class="bold"><st c="54681">Container or artifact registries</st></strong><st c="54714"> are the central </st><a id="_idIndexMarker544"/><st c="54731">hub of all software that gets built and deployed. </st><st c="54781">It</st><a id="_idIndexMarker545"/><st c="54783"> provides a central way to manage, scan, distribute, and enforce access to all software before it gets deployed. </st><st c="54896">It must, therefore, be treated as a highly critical component that must be observed to ensure availability and resiliency, and must be secure </st><span class="No-Break"><st c="55038">in itself!</st></span></p>
			<p><st c="55048">Now that we have talked about the importance of our artifact registry, let’s continue to see how all of those components integrate</st><a id="_idTextAnchor301"/><st c="55179"> with our </st><span class="No-Break"><st c="55189">end-to-release process.</st></span></p>
			<h1 id="_idParaDest-125"><a id="_idTextAnchor302"/><st c="55212">Defining the release process and management</st></h1>
			<p><st c="55256">We have covered all of the building blocks it takes to build and deploy software. </st><st c="55339">CI builds new container images or artifacts and pushes them to a registry. </st><st c="55414">We know that registries have the power to scan for vulnerabilities, replicate to other registries, notify other tools about any activity, and enforce </st><span class="No-Break"><st c="55564">access control.</st></span></p>
			<p><st c="55579">We also learned about GitOps and its pull approach of ensuring the desired deployment state (manifest files, Helm charts, Kustomize, etc.), as defined in a Git repository on the </st><span class="No-Break"><st c="55758">target environment.</st></span></p>
			<p><st c="55777">What we are discussing now is how to define and enforce a full end-to-end release process and how to manage the life cycle of artifacts from the initial creation, initial deployment, promotion into other stages, and updates to new versions until a potential retirement when the software is no </st><span class="No-Break"><st c="56071">longer required!</st></span></p>
			<p><st c="56087">The following illustration highlights that pushing a new image and replicating it to other registries is just one piece of the puzzle. </st><st c="56223">The new version of the image also needs to be referenced in the deployment definition that is managed in mono or poly Git repositories. </st><st c="56359">When having multiple stages (development, QA, production) and having multiple regions or clusters in a stage, we also need to promote that new version between each stage and </st><span class="No-Break"><st c="56533">each region/cluster!</st></span></p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B31164_05_08.jpg" alt="Figure 5.8: Release process – from initial push to deploy and promote, from stage to stage"/><st c="56553"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="56764">Figure 5.8: Release process – from initial push to deploy and promote, from stage to stage</st></p>
			<p><st c="56854">In the preceding figure, </st><strong class="source-inline"><st c="56880">values.yaml</st></strong><st c="56891"> represents the values for a Helm chart. </st><st c="56932">It is, of course, simplified as there would be many more of the values that we discussed earlier (e.g., ownership, application context, log level, </st><strong class="source-inline"><st c="57079">git commit</st></strong><st c="57089"> hash, container </st><span class="No-Break"><st c="57106">registry, etc.).</st></span></p>
			<p><st c="57122">Now, let’s have a look into how those deployment updates can be done, what should happen between the stages, what rollout options we have, and how to best keep track of a live inventory to know what is d</st><a id="_idTextAnchor303"/><st c="57326">eployed where, when, and </st><span class="No-Break"><st c="57352">by whom!</st></span></p>
			<h2 id="_idParaDest-126"><a id="_idTextAnchor304"/><st c="57360">Updating deployment to a new version</st></h2>
			<p><st c="57397">There are </st><a id="_idIndexMarker546"/><st c="57408">different ways that </st><strong class="source-inline"><st c="57428">values.yaml</st></strong><st c="57439"> can be updated for the initial development stage and how it then gets promoted to the next stages. </st><st c="57539">Depending on the tooling and the level of maturity or processes that organizations have in place, this can be implemented in various ways. </st><st c="57678">The options would be </st><span class="No-Break"><st c="57699">as follows:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="57710">Updated as part of the CI</st></strong><st c="57736">: Once the CI publishes a new image to the registry, it could open a Pull Request to update the version in the repository for the </st><span class="No-Break"><st c="57867">first stage.</st></span></li>
				<li><strong class="bold"><st c="57879">Updated through a registry webhook</st></strong><st c="57914">: When a new image is uploaded to the registry, a webhook can be used to open a Pull Request. </st><st c="58009">This approach is similar to having the CI do it. </st><st c="58058">However, it decouples the process. </st><st c="58093">This also works independently of which tool (e.g., CI) or creator (e.g., third-party vendor) pushes a new </st><span class="No-Break"><st c="58199">image version.</st></span></li>
				<li><strong class="bold"><st c="58213">Scheduled updates</st></strong><st c="58231">: Every hour, every day at 8 a.m., or any other schedule can be used to create a Pull Request with the latest version information from the registry. </st><st c="58381">This provides continuous updates as well as batch changes on </st><span class="No-Break"><st c="58442">a schedule.</st></span></li>
				<li><strong class="bold"><st c="58453">Manual Pull Requests</st></strong><st c="58474">: As a precursor to automating the Pull Requests, or to enforce</st><a id="_idIndexMarker547"/><st c="58538"> mandatory manual approval, the versio</st><a id="_idTextAnchor305"/><st c="58576">n update can also be </st><span class="No-Break"><st c="58598">done manually.</st></span></li>
			</ul>
			<h2 id="_idParaDest-127"><a id="_idTextAnchor306"/><st c="58612">Batching changes to combat dependencies</st></h2>
			<p><st c="58652">When dealing with simple applications or microservices that can be deployed independently, a single file update might be enough. </st><st c="58782">Often, we have to combine multiple changes into a single change request. </st><st c="58855">This is when changes have dependencies on changes in other components. </st><st c="58926">An example for our Finance One ACME could be that the new version of the </st><strong class="source-inline"><st c="58999">fund-transfer</st></strong><st c="59012"> service also requires a new version of the </st><strong class="source-inline"><st c="59056">account-info</st></strong><st c="59068"> service, which requires an infrastructure change. </st><st c="59119">You can see that it can easily become complex and it becomes harder to </st><span class="No-Break"><st c="59190">fully automate.</st></span></p>
			<p><st c="59205">Those changes are hard to automate and often fall back to some release management team that resolves those </st><span class="No-Break"><st c="59313">dependencies manually.</st></span></p>
			<p><st c="59335">There are other ways of solving this. </st><st c="59374">One approach is using package managers, such as Helm, where a Helm chart can </st><a id="_idIndexMarker548"/><st c="59451">contain all configurations needed to deploy a full app. </st><st c="59507">Helm charts</st><a id="_idIndexMarker549"/><st c="59518"> can then also become artifacts uploaded to </st><span class="No-Break"><st c="59562">a registry.</st></span></p>
			<p><st c="59573">Another approach that we have seen in an earlier section is using tools such as Crossplane, which </st><a id="_idIndexMarker550"/><st c="59672">provides IaC and application as code. </st><st c="59710">The following is an example of using a composition for an application that contains several components, such as the business logic, a cache, an ingress, and </st><span class="No-Break"><st c="59867">a database:</st></span></p>
			<pre class="source-code"><st c="59878">
apiVersion: composites.financialone.acme/v1alpha1
kind: FinancialBackend
metadata:
  name: tenantABC-eu-west
spec:
  service-versions:
    fund-transfer: 2.34.3
    account-info: 1.17.0
  redis-cache:
    version: 7.4.2
    name: transfer-cache
    size: medium
  database:
    size: large
    name: accounts-db
  region: "eu-west"
  ingress:
    url: "https://tenantABC-eu-west.financialone.acme"</st></pre>
			<p><st c="60232">As we can see, there are different ways to solve this application </st><span class="No-Break"><st c="60299">dependency problem.</st></span></p>
			<p><st c="60318">Where this becomes trickier is when we have cross-application dependencies or dependencies to shared services that are independently deployed and updated. </st><st c="60474">Following best practices to define good and clear APIs between those services and ensuring backward compatibility between major versions will make this easier. </st><st c="60634">To learn more, have a look at existing literature or the work the CNCF </st><strong class="bold"><st c="60705">TAG App Delivery</st></strong> <em class="italic"><st c="60721">[16]</st></em><st c="60726"> does on </st><a id="_idIndexMarker551"/><st c="60735">managing a</st><a id="_idTextAnchor307"/><st c="60745">pplication and </st><span class="No-Break"><st c="60761">deployment dependencies.</st></span></p>
			<h2 id="_idParaDest-128"><a id="_idTextAnchor308"/><st c="60785">Pre- and post-deployment checks</st></h2>
			<p><st c="60817">Once we have all our deployment configuration changes ready and committed to Git, we will be ready to deploy into the target cluster. </st><st c="60952">As explained earlier in this chapter, we can either use a Push model (e.g., a delivery pipeline deploys our changes) or a Pull model (e.g., a GitOps operator synchronizes the latest version in Git to the </st><span class="No-Break"><st c="61156">target cluster).</st></span></p>
			<p><st c="61172">With both approaches, we want to do some pre- and post-deployment checks to answer questions, such as </st><span class="No-Break"><st c="61275">the following:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="61289">Pre-deployment: Are we ready to deploy </st></strong><span class="No-Break"><strong class="bold"><st c="61329">that change?</st></strong></span><ul><li><st c="61341">Are all </st><a id="_idIndexMarker552"/><st c="61350">external</st><a id="_idIndexMarker553"/> <span class="No-Break"><st c="61358">dependencies ready?</st></span></li><li><st c="61378">Have all new images been successfully scanned and have </st><span class="No-Break"><st c="61434">no vulnerabilities?</st></span></li><li><st c="61453">Is there no ongoing maintenance or deployment quarantine in the </st><span class="No-Break"><st c="61518">target environment?</st></span></li><li><st c="61537">Has everyone that needs to approve a deployment </st><span class="No-Break"><st c="61586">approved it?</st></span></li></ul></li>
				<li><strong class="bold"><st c="61598">Post-deployment: Was the </st></strong><span class="No-Break"><strong class="bold"><st c="61624">deployment successful?</st></strong></span><ul><li><st c="61646">Are</st><a id="_idIndexMarker554"/><st c="61650"> updated services available and successfully </st><a id="_idIndexMarker555"/><span class="No-Break"><st c="61695">handling requests?</st></span></li><li><st c="61713">Does the system meet all functional and </st><span class="No-Break"><st c="61754">non-functional requirements?</st></span></li><li><st c="61782">Do all services meet their SLAs </st><a id="_idIndexMarker556"/><st c="61815">and </st><strong class="bold"><st c="61819">service-level </st></strong><span class="No-Break"><strong class="bold"><st c="61833">objectives</st></strong></span><span class="No-Break"><st c="61843"> (</st></span><span class="No-Break"><strong class="bold"><st c="61845">SLOs</st></strong></span><span class="No-Break"><st c="61849">)?</st></span></li><li><st c="61852">Was everyone notified about </st><span class="No-Break"><st c="61881">the deployment?</st></span></li><li><st c="61896">Can the deployment be promoted to the </st><span class="No-Break"><st c="61935">next stage?</st></span></li></ul></li>
			</ul>
			<p><st c="61946">The pre-deployment checks can be implemented in various ways. </st><st c="62009">Some can be implemented as part of the Pull Request flow (e.g., Pull Requests cannot be merged when not all pre-deployment checks are fulfilled). </st><st c="62155">They can also be validated within a deployment pipeline or implemented as a pre-sync hook in </st><span class="No-Break"><st c="62248">GitOps tools.</st></span></p>
			<p><st c="62261">The post-deployment checks can be implemented after the deployment is done from the deployment pipeline as well as through post-sync hooks in </st><span class="No-Break"><st c="62404">GitOps tools.</st></span></p>
			<p><st c="62417">One tool that enables pre- and post-deployment checks on Kubernetes independent of how the deployment is done is the CNCF project, Keptn. </st><strong class="bold"><st c="62556">Keptn</st></strong><st c="62561"> can stop Kubernetes deployments if the pre-deployment </st><a id="_idIndexMarker557"/><st c="62616">checks are not successful. </st><st c="62643">Keptn can also execute post-deployment checks, such as executing tests, evaluating SLOs, or </st><span class="No-Break"><st c="62735">notifying teams.</st></span></p>
			<p><st c="62751">To learn mo</st><a id="_idTextAnchor309"/><st c="62763">re about Keptn, check the </st><span class="No-Break"><st c="62790">documentation </st></span><span class="No-Break"><em class="italic"><st c="62804">[17]</st></em></span><span class="No-Break"><st c="62808">.</st></span></p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor310"/><st c="62809">Deployment notifications</st></h2>
			<p><st c="62834">Once we are aware of a new</st><a id="_idIndexMarker558"/><st c="62861"> deployment that has either succeeded or failed the post-deployment check, we can use this information and notify those people or tools that can benefit from this information. </st><st c="63037">Whether using tools such as Keptn, the notifications of the GitOps tools, or doing this from the pipeline, here are some examples of where to send </st><span class="No-Break"><st c="63184">this information:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="63201">A chat</st></strong><st c="63208">: Notify development teams in their Slack channel that their latest deployment is either ready or has failed </st><span class="No-Break"><st c="63318">the checks</st></span></li>
				<li><strong class="bold"><st c="63328">A ticket</st></strong><st c="63337">: Update the Pull Request or a Jira ticket with the information about the </st><span class="No-Break"><st c="63412">deployment status</st></span></li>
				<li><strong class="bold"><st c="63429">A status page</st></strong><st c="63443">: Keep a deployment status page with version, environment, and health information up </st><span class="No-Break"><st c="63529">to date</st></span></li>
				<li><strong class="bold"><st c="63536">An observability backend</st></strong><st c="63561">: Send a deployment event to your </st><span class="No-Break"><st c="63596">observability backend</st></span></li>
			</ul>
			<p class="callout-heading"><st c="63617">Deployment events to observability backend</st></p>
			<p class="callout"><st c="63660">Observability tools not only track metrics, logs, and traces, but they can also track events such as</st><a id="_idIndexMarker559"/><st c="63761"> deployment or</st><a id="_idIndexMarker560"/><st c="63775"> configuration change events. </st><st c="63805">Many observability tools (</st><strong class="bold"><st c="63831">Dynatrace</st></strong><st c="63841">, </st><strong class="bold"><st c="63843">Datadog</st></strong><st c="63850">, </st><strong class="bold"><st c="63852">New Relic</st></strong><st c="63861">, etc.) can use those events and correlate them</st><a id="_idIndexMarker561"/><st c="63908"> with a change in the app’s behavior. </st><st c="63946">This can significantly improve incident response as it can</st><a id="_idTextAnchor311"/><st c="64004"> be correlated with a specific </st><span class="No-Break"><st c="64035">deployment change.</st></span></p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor312"/><st c="64053">Promotions between stages</st></h2>
			<p><st c="64079">Assuming we have a new</st><a id="_idIndexMarker562"/><st c="64102"> release in development that successfully passed all post-deployment checks, how do those changes get promoted from development to QA and then into production? </st><st c="64262">Does every change have to get promoted all the way into production or not? </st><st c="64337">Do new releases get rolled out to all production environments at once or are there better strategies </st><span class="No-Break"><st c="64438">for it?</st></span></p>
			<p><st c="64445">Here are some strategies that we have seen in organizations we have worked with in the past. </st><st c="64539">For all those strategies, it means that a Pull Request is created to promote the new deployment definition from the Git location of the lower stage to the Git location of the </st><span class="No-Break"><st c="64714">higher stage:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="64727">Automated</st></strong><st c="64737">: Often seen between development and QA environments. </st><st c="64792">Every time the post-deployment checks are successful, it can trigger an automated Pull Request. </st><st c="64888">This ensures that all development changes that have made it through the basic checks are quickly promoted to an environment used for more </st><span class="No-Break"><st c="65026">thorough testing.</st></span></li>
				<li><strong class="bold"><st c="65043">Scheduled</st></strong><st c="65053">: For instance, once a day, promote the latest version from development or QA into a special test environment (e.g., a performance testing environment). </st><st c="65207">This ensures that the team gets daily feedback on performance behavior changes of their updates from the previous </st><span class="No-Break"><st c="65321">24 hours.</st></span></li>
				<li><strong class="bold"><st c="65330">Controlled/manual</st></strong><st c="65348">: This typically happens the closer you get into production. </st><st c="65410">Changes that made it successfully through QA and performance testing are marked to be safe to promote into higher-level environments. </st><st c="65544">The actual promotion typically happens manually while the Pull Request itself might already be automatically created (but not auto-approved) from those versions that successfully made it through, for example, the performance </st><span class="No-Break"><st c="65769">testing phase!</st></span></li>
				<li><strong class="bold"><st c="65783">Multi-stage in production</st></strong><st c="65809">: When having multiple production clusters, it is common practice to roll out the changes into one cluster first. </st><st c="65924">Then, validate if everything works and keep rolling out the rest. </st><st c="65990">This first cluster could be for internal usage only or for users who know that they receive updates first (e.g., friends and family or members of an early access group). </st><st c="66160">When deploying into multiple regions or multiple SaaS vendors, it is also advisable to define a</st><a id="_idIndexMarker563"/><st c="66255"> clear sequence (e.g., start in Europe first and then roll out to </st><span class="No-Break"><st c="66321">the US).</st></span></li>
			</ul>
			<p><st c="66329">Using multiple quality gated stages and a staged rollout strategy in our various production environments has</st><a id="_idTextAnchor313"/><st c="66438"> one goal: reducing the risk of </st><span class="No-Break"><st c="66470">failed deployments!</st></span></p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor314"/><st c="66489">Blue/green, canary, and feature flagging</st></h2>
			<p><st c="66530">While using multiple </st><a id="_idIndexMarker564"/><st c="66552">stages with pre- and</st><a id="_idIndexMarker565"/><st c="66572"> post-deployment checks already </st><a id="_idIndexMarker566"/><st c="66604">reduces risk, there is more we can do for each individual deployment: </st><strong class="bold"><st c="66674">progressive delivery</st></strong><st c="66694"> strategies, such as </st><a id="_idIndexMarker567"/><st c="66715">blue/green, canary, or feature flags. </st><st c="66753">We have already discussed what those things are in more detail in the </st><em class="italic"><st c="66823">Continuous deployment – decoupling deployments from </st></em><span class="No-Break"><em class="italic"><st c="66875">releases</st></em></span><span class="No-Break"><st c="66883"> section.</st></span></p>
			<p><st c="66892">In the context of the release process, this is an important topic, as there are several </st><span class="No-Break"><st c="66981">open questions:</st></span></p>
			<ul>
				<li><st c="66996">Who is receiving the new version? </st><st c="67031">Is it a certain percentage of users or a </st><span class="No-Break"><st c="67072">specific group?</st></span></li>
				<li><st c="67087">How do you measure and validate whether the rollout </st><span class="No-Break"><st c="67140">was successful?</st></span></li>
				<li><st c="67155">Who is responsible for making the roll-forward or </st><span class="No-Break"><st c="67206">rollback decision?</st></span></li>
			</ul>
			<p><st c="67224">Just like validating a deployment through post-deployment checks, we can do the same with progressive delivery. </st><st c="67337">Open </st><a id="_idIndexMarker568"/><st c="67342">source tools, such </st><a id="_idIndexMarker569"/><st c="67361">as </st><strong class="bold"><st c="67364">Argo Rollouts</st></strong> <em class="italic"><st c="67377">[18]</st></em><st c="67382"> and </st><strong class="bold"><st c="67387">Flagger</st></strong> <em class="italic"><st c="67394">[19]</st></em><st c="67399">, or commercial tools provide automated analysis between the progressive rollout phases. </st><st c="67488">This usually works by querying data from the observability platform; for example, Prometheus, to validate if the new version doesn’t differ from the existing version for key service-level indicators, such as request failure rate, response time, memory, and CPU consumption. </st><st c="67762">For more details, it’s recommended to check the documentation of the </st><a id="_idTextAnchor315"/><st c="67831">respective tooling that is used for </st><span class="No-Break"><st c="67867">progressive rollouts.</st></span></p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor316"/><st c="67888">Release inventory</st></h2>
			<p><st c="67906">The value proposition of automating the deployment and release process is that engineering teams can release updates more frequently into the various target environments. </st><st c="68078">The easier we make this automation available through our platform, the more teams will end up deploying </st><span class="No-Break"><st c="68182">more releases.</st></span></p>
			<p><st c="68196">Release inventories allow </st><a id="_idIndexMarker570"/><st c="68223">us to keep track of which versions are currently released in which environments by which teams. </st><st c="68319">From a platform engineering perspective, we can enforce a consistent definition of exactly that information: version, environment, and ownership. </st><st c="68465">If everything is configured as code, it means that this information is available in Git. </st><st c="68554">When using Kubernetes as the target platform, we can also add this information as annotations on our Kubernetes objects (Deployments, </st><span class="No-Break"><st c="68688">Pods, Ingress).</st></span></p>
			<p><st c="68703">In previous examples, we already highlighted some of the standard K8s annotations. </st><st c="68787">Here is a snippet of a </st><span class="No-Break"><st c="68810">deployment definition:</st></span></p>
			<pre class="source-code"><st c="68832">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fund-transfer-service
spec:
  …
  template:
    metadata:
      annotations:
        owner.team: team-us
        app.kubernetes.io/name: fund-transfer
        app.kubernetes.io/part-of: backend-tenant-2
        app.kubernetes.io/version: 1.5.1</st></pre>
			<p><st c="69083">With this information in K8s, we </st><a id="_idIndexMarker571"/><st c="69117">can simply query the K8s API of each K8s cluster to get an overview of all deployments by those labels. </st><st c="69221">We could then get an overview </st><span class="No-Break"><st c="69251">like this:</st></span></p>
			<table id="table002-3" class="T---Table _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="T---Table">
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="69261">Cluster</st></strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="69269">Release</st></strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="69277">Part-Of</st></strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="69285">Owner</st></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69291">dev</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69295">fund-transfer:1.5.1</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69315">backend</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69323">team-at</st></strong></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69331">dev</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69335">account-info:1.17.2</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69355">backend</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69363">team-ae</st></strong></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="69371">qa</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69374">fund-transfer:1.4.9</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69394">backend</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69402">team-at</st></strong></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="69410">qa</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69413">account-info:1.17.1</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69433">backend</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69441">team-ae</st></strong></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="69449">prod-eu</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69457">fund-transfer:1.4.7</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69477">backend-tenant-1</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69494">team-de</st></strong></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="69502">prod-eu</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69510">account-info:1.17.1</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69530">backend-tenant-1</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69547">team-de</st></strong></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69555">prod-us</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69563">fund-transfer:1.4.6</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69583">backend-tenant-2</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69600">team-us</st></strong></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69608">prod-us</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69616">account-info:1.17.0</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69636">backend-tenant-2</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="source-inline"><st c="69653">team-us</st></strong></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="69661">Table 5.2: Release inventory based on metadata on deployed artifacts</st></p>
			<p><st c="69730">Observability tools often provide this feature as they already pull the K8s APIs to observe cluster health, events, and objects including </st><span class="No-Break"><st c="69869">this metadata.</st></span></p>
			<p><st c="69883">Another approach is to parse this information directly from Git. </st><st c="69949">Tools such as Backstage do exactly this and with that information, provide an easy-to-search </st><span class="No-Break"><st c="70042">software catalog.</st></span></p>
			<h2 id="_idParaDest-133"><a id="_idTextAnchor317"/><st c="70059">Release management – from launch to mission control</st></h2>
			<p><st c="70111">For many organizations, the release </st><a id="_idIndexMarker572"/><st c="70148">process ends with the actual deployment of a new release into production when operations teams take over all aspects of keeping the software running. </st><st c="70298">These two phases are also often called </st><strong class="bold"><st c="70337">launch</st></strong><st c="70343"> and </st><strong class="bold"><st c="70348">mission control</st></strong><st c="70363">, borrowed from how NASA manages their </st><span class="No-Break"><st c="70402">space missions.</st></span></p>
			<p><st c="70417">Many years ago, the DevOps movement was fueled by prominent examples, such as the AWS platform, which promoted the </st><em class="italic"><st c="70533">you built it, you run it!</st></em><st c="70558"> approach. </st><st c="70569">This meant that the responsibility of developers didn’t end with building an artifact and then throwing it over the so-called “Ops Wall.” Developers had to take full responsibility and ownership of their code from development all the way into production. </st><st c="70824">They had to handle incidents and updates until their code eventually </st><span class="No-Break"><st c="70893">got retired.</st></span></p>
			<p><st c="70905">When looking at today’s complex environments, it is very hard to own every aspect (code and infrastructure). </st><st c="71015">With platform engineering, we try to bring the promise of DevOps back by providing self-services to reduce the complexity and giving teams the chance to own more of the end-to-end life cycle of </st><span class="No-Break"><st c="71209">their software.</st></span></p>
			<p><st c="71224">When building future platforms, our focus must be to provide self-services to orchestrate the whole life cycle of an artifact. </st><st c="71352">In fact, orchestrating the whole life cycle of an application as a single artifact is typically just a fraction of an application. </st><strong class="bold"><st c="71483">Life cycle orchestration</st></strong><st c="71507"> includes</st><a id="_idIndexMarker573"/><st c="71516"> building, deploying, and releasing, but also all use cases needed for production support. </st><st c="71607">This includes resiliency through scaling, incident management, access to the right observability data for troubleshooting, and automated delivery to push fixes </st><span class="No-Break"><st c="71767">and updates.</st></span></p>
			<p><st c="71779">In the next section, we dive into life cycle orchestration, how to increase transparency by making our life cycles observable, and how an event-driven model can help reduce the complexity of pipeline and </st><span class="No-Break"><st c="71984">orchestration code</st><a id="_idTextAnchor318"/><st c="72002">.</st></span></p>
			<h1 id="_idParaDest-134"><a id="_idTextAnchor319"/><st c="72003">Achieving sustainable CI/CD for DevOps – application life cycle orchestration</st></h1>
			<p><st c="72081">From building, to publishing, to promoting, to deploying, to releasing, to fixing. </st><st c="72165">That’s a lot of tasks that have to be automated to orchestrate the whole life cycle of our artifacts and applications. </st><st c="72284">The challenge that we have seen with teams that take end-to-end responsibility is that the majority of those scripts deal with </st><span class="No-Break"><st c="72411">the following:</st></span></p>
			<ul>
				<li><st c="72425">Triggering a certain (</st><span class="No-Break"><st c="72448">hardcoded) tool</st></span></li>
				<li><st c="72464">Doing so in a certain (</st><span class="No-Break"><st c="72488">hardcoded) environment</st></span></li>
				<li><st c="72511">Then, waiting for the tool to complete </st><span class="No-Break"><st c="72551">its job</st></span></li>
				<li><st c="72558">Parsing the specific </st><span class="No-Break"><st c="72580">result format</st></span></li>
				<li><st c="72593">Based on the parsing result, deciding what to do </st><span class="No-Break"><st c="72643">next (hardcoded)</st></span></li>
			</ul>
			<p><st c="72659">That script code then often gets copied and pasted between different projects, slightly modified, and adapted. </st><st c="72771">Fixes or adaptations to a single script are hard to promote to all the other variations as there is no easy tracking of all those scripts. </st><st c="72910">This leads to high effort in maintenance, makes it inflexible to change the process or tools used in those scripts, and takes away time from engineers doing their </st><span class="No-Break"><st c="73073">regular jobs.</st></span></p>
			<p><st c="73086">There is nothing wrong with using the power of pipeline scripting. </st><st c="73154">Many of the pipeline automation tools also provide abstractions, code reuse through libraries, and other features to reduce code duplication and increase reusability. </st><st c="73321">So, depending on the tools you use, make sure to follow those </st><span class="No-Break"><st c="73383">best practices!</st></span></p>
			<p><st c="73398">There exists a different approach that fits in the event-driven nature of modern cloud-native applications and</st><a id="_idIndexMarker574"/><st c="73509"> cloud-native environments: </st><strong class="bold"><st c="73537">life cycle </st></strong><span class="No-Break"><strong class="bold"><st c="73548">event-driven orchestration</st></strong></span><span class="No-Break"><st c="73574">!</st></span></p>
			<p><st c="73575">In the next section, we will dive into this approach as it provides a lot of flexibility and centralized observability and will lead to a more sustainable way to automate CI/CD </st><span class="No-Break"><st c="73752">and operation</st><a id="_idTextAnchor320"/><st c="73765">s!</st></span></p>
			<h2 id="_idParaDest-135"><a id="_idTextAnchor321"/><st c="73768">Artifact life cycle event observability</st></h2>
			<p><st c="73808">The basics for event-driven </st><a id="_idIndexMarker575"/><st c="73837">orchestration are life cycle events, such as those discussed in </st><a href="B31164_03.xhtml#_idTextAnchor133"><span class="No-Break"><em class="italic"><st c="73901">Chapter 3</st></em></span></a><st c="73910">. It’s about observing the full life cycle of an artifact: from the initial Git commit of code, the building and pushing of container images to a registry, to the releasing into every stage until the artifact gets updated or retired, including all the steps </st><span class="No-Break"><st c="74168">in between.</st></span></p>
			<p><st c="74179">So far in this chapter, we discussed many of those life cycle steps and also highlighted how to extract some of those life </st><span class="No-Break"><st c="74303">cycle events:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="74316">CI/CD pipelines</st></strong><st c="74332"> can emit events when they </st><em class="italic"><st c="74359">build</st></em> <span class="No-Break"><st c="74364">or </st></span><span class="No-Break"><em class="italic"><st c="74368">deploy</st></em></span></li>
				<li><strong class="bold"><st c="74374">Artifact registries</st></strong><st c="74394"> provide webhooks when containers get </st><em class="italic"><st c="74432">pushed</st></em><st c="74438">, </st><em class="italic"><st c="74440">pulled</st></em><st c="74446">, </st><span class="No-Break"><st c="74448">or </st></span><span class="No-Break"><em class="italic"><st c="74451">scanned</st></em></span></li>
				<li><strong class="bold"><st c="74458">GitOps</st></strong><st c="74465"> tools can send notifications for </st><strong class="source-inline"><st c="74499">PreSync</st></strong><st c="74506">, </st><strong class="source-inline"><st c="74508">Sync</st></strong><st c="74512">, </st><strong class="source-inline"><st c="74514">PostSync</st></strong><st c="74522">, </st><span class="No-Break"><st c="74524">and </st></span><span class="No-Break"><strong class="source-inline"><st c="74528">SyncFailed</st></strong></span></li>
				<li><strong class="bold"><st c="74538">Git</st></strong><st c="74542"> workflows can be used to send events when code </st><em class="italic"><st c="74590">changes</st></em><st c="74597"> or </st><span class="No-Break"><st c="74601">gets </st></span><span class="No-Break"><em class="italic"><st c="74606">promoted</st></em></span></li>
				<li><st c="74614">Tools such as </st><strong class="bold"><st c="74629">Keptn</st></strong><st c="74634"> provide</st><a id="_idIndexMarker576"/><st c="74642"> pre- and post-deployment events for individual deployments as well as </st><span class="No-Break"><st c="74713">complex applications</st></span></li>
				<li><strong class="bold"><st c="74733">Container</st></strong><st c="74743"> platforms, such as Kubernetes, expose events about </st><span class="No-Break"><em class="italic"><st c="74795">deployment health</st></em></span></li>
			</ul>
			<p><strong class="bold"><st c="74812">CDEvents</st></strong> <em class="italic"><st c="74821">[20]</st></em><st c="74826">, a project</st><a id="_idIndexMarker577"/><st c="74837"> from the Continuous Delivery Foundation, extends the CloudEvents specification, which is already a graduated CNCF project with wide ecosystem adoption. </st><st c="74990">CDEvents was initially started to standardize events for all life cycle phases for building, testing, and deploying. </st><st c="75107">It has recently expanded to also cover the life cycle phases of deployments in operations such as </st><span class="No-Break"><st c="75205">production incidents.</st></span></p>
			<p><st c="75226">The idea is that tools that adhere to those event standards are easier to integrate with all other tools in the ecosystem. </st><st c="75350">Instead of having to manage and maintain hard code integrations between tools, those tools communicate via open standard APIs and Events. </st><st c="75488">Tools can emit those events; for example, Jenkins has created a new artifact and other tools can subscribe to them (e.g., GitLab can subscribe and trigger a workflow to scan and publish the container). </st><st c="75690">That life cycle phase would also generate a </st><span class="No-Break"><st c="75734">standardized event.</st></span></p>
			<p><st c="75753">All events have a minimum set of properties to identify the phase, the artifact, and the tool that was involved, as well as the additional properties that are mandatory (e.g., initial </st><strong class="source-inline"><st c="75938">git commit</st></strong><st c="75948">, version, environment, and </st><span class="No-Break"><st c="75976">responsible team).</st></span></p>
			<p><st c="75994">When all those events are sent to a central event hub, it enables a fully event-driven orchestration of the life cycle </st><span class="No-Break"><st c="76114">of artifacts.</st></span></p>
			<p><st c="76127">For example, if you decide to notify development teams about new deployments in their Slack, you can easily subscribe to the deployment events and forward that event to Slack. </st><st c="76304">If you change the chat tool to something else, simply change that event subscription. </st><st c="76390">No need to find all code in all pipelines that currently send notifications as this happens through a simple event </st><span class="No-Break"><st c="76505">subscription change.</st></span></p>
			<p><st c="76525">To sum it up, using a well-defined set of life cycle events across all tools and phases enables many capabilities in our platform </st><span class="No-Break"><st c="76656">engineering approach:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="76677">Traceability</st></strong><st c="76690">: We can trace every artifact from its initial creation until its end of the life cycle. </st><st c="76780">This allows us to see where artifacts are (release inventory), where they are stuck, and who is responsible for letting an artifact into a </st><span class="No-Break"><st c="76919">certain environment.</st></span></li>
				<li><strong class="bold"><st c="76939">Measurement</st></strong><st c="76951">: We can measure how many artifacts flow through the life cycle and how long it takes. </st><st c="77039">This is the basis for reporting the DORA </st><span class="No-Break"><st c="77080">Efficiency metrics!</st></span></li>
				<li><strong class="bold"><st c="77099">Interoperability</st></strong><st c="77116">: We can easily integrate new tools or replace them if they all adhere to the same standards (e.g., switching from one notification tool to another is just a matter of changing an </st><span class="No-Break"><st c="77297">event subscription).</st></span></li>
				<li><strong class="bold"><st c="77317">Flexibility</st></strong><st c="77329">: Like</st><a id="_idIndexMarker578"/><st c="77336"> replacing tools, we can easily adapt our delivery processes by having additional tools add work on certain events (e.g., adding an additional mandatory security scan for deployments in certain environments can be done by an event subscription of a security </st><span class="No-Break"><st c="77594">scan tool).</st></span></li>
			</ul>
			<p><st c="77605">Let’s have a quick overview of the building blocks of such an event-driven system as compared to having to create and maintain lengthy complex automation scripts to include a lot of </st><span class="No-Break"><st c="77788">process </st><a id="_idTextAnchor322"/><st c="77796">logic.</st></span></p>
			<h2 id="_idParaDest-136"><a id="_idTextAnchor323"/><st c="77802">Working with events</st></h2>
			<p><st c="77822">The first step is that the tools we </st><a id="_idIndexMarker579"/><st c="77859">use along the artifact life cycle emit those events. </st><st c="77912">Looking at </st><a id="_idIndexMarker580"/><st c="77923">CDEvents (which extends CloudEvents), there are several tools in the ecosystem that already provide out-of-the-box support for them, such as Jenkins, Tekton, Keptn, Tracetest, Spinnaker, </st><span class="No-Break"><st c="78110">and others.</st></span></p>
			<p><st c="78121">Those tools that are not integrated yet can easily emit those events using the available SDKs. </st><st c="78217">The following is a code example using Python, which creates a Pipeline Run Finished Event (</st><strong class="source-inline"><st c="78308">cdevents.new_pipelinerun_finished</st></strong><st c="78342">_event) with metadata, identifying the pipeline, artifact, </st><span class="No-Break"><st c="78402">or owner:</st></span></p>
			<pre class="source-code"><st c="78411">
import cdevents
event = cdevents.new_pipelinerun_finished_event(
  context_id="git-abcdef1231",
  context_source="jenkins",
  context_timestamp=datetime.datetime.now(),
  subject_id="pipeline_job123",
  custom_data={
    "owner": "dev-team-backend",
    "part-of": "backend-services",
    "name" : "fund-transfer-service"
  },
  subject_source="build",
  custom_data_content_type="application/json",
  pipeline_name="backendBuildPipeline",
  url="https://finone.acme/ci/job123",
)
# Create a CloudEvent from the CDEvent
cloudevent = cdevents.to_cloudevent(event)
# Creates the HTTP request representation of the CloudEvent in structured content mode
headers, body = to_structured(event)
# POST it to the event bus, data store
requests.post("&lt;some-url&gt;", data=body, headers=headers)</st></pre>
			<p><st c="79161">The preceding Python code example creates a new </st><strong class="source-inline"><st c="79210">pipelinerun_finished_event</st></strong><st c="79236">, which indicates the finished execution of a pipeline. </st><st c="79292">The additional context data indicates which pipeline and when it was built, and it allows us to provide additional metadata, such as ownership, artifact, or which application this pipeline </st><span class="No-Break"><st c="79481">belongs to.</st></span></p>
			<p><st c="79492">Whether you use the </st><a id="_idIndexMarker581"/><st c="79513">CDEvents standard proposal or send your own life cycle events, it is a </st><a id="_idIndexMarker582"/><st c="79584">good idea to base it on CloudEvents as that project already has a lot of industry integrations that can either emit or consume CloudEvents, with Knative as </st><span class="No-Break"><st c="79740">on</st><a id="_idTextAnchor324"/><st c="79742">e example!</st></span></p>
			<h2 id="_idParaDest-137"><a id="_idTextAnchor325"/><st c="79753">Subscribing to events to orchestrate</st></h2>
			<p><st c="79790">Once all our tools are </st><a id="_idIndexMarker583"/><st c="79814">emitting standardized events, we can more easily orchestrate our artifact life cycle process by having tools we want to participate in the process subscribe to those events they want to </st><span class="No-Break"><st c="80000">act upon.</st></span></p>
			<p><st c="80009">We discussed the same concept earlier in this chapter when we talked about using the webhook capabilities of tools such as Argo CD or Harbor to act upon when a new artifact is available or when a new deployment was </st><span class="No-Break"><st c="80225">successfully synced.</st></span></p>
			<p><st c="80245">The benefit of a standard event model is that tools no longer need to subscribe to a specific webhook of a specific tool (e.g., Argo CD webhooks). </st><st c="80393">Instead, we can subscribe to a central event hub that receives all standardized life cycle events from all involved tools, as </st><span class="No-Break"><st c="80519">visualized here:</st></span></p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B31164_05_09.jpg" alt="Figure 5.9: All tools emit and subscribe to standardized life cycle events"/><st c="80535"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="80607">Figure 5.9: All tools emit and subscribe to standardized life cycle events</st></p>
			<p><st c="80681">Having everything </st><a id="_idIndexMarker584"/><st c="80700">based on an event standard eliminates the need for point-to-point tool integrations or hardcoded tool integrations in pipeline scripts. </st><st c="80836">As an example, instead of sending a notification to Slack or Mattermost from every pipeline that deploys a new build, we can simply subscribe to the </st><strong class="source-inline"><st c="80985">dev.cdevents.service.published</st></strong><st c="81015"> event and have the details about that service forwarded to our </st><span class="No-Break"><st c="81079">chat tool.</st></span></p>
			<p><st c="81089">If that tool is Slack today, and at a later time, we decide to move to another tool, we simply change </st><span class="No-Break"><st c="81192">that subscription.</st></span></p>
			<p><st c="81210">Another use case is to have different tools as part of the process active in different environments. </st><st c="81312">As those standardized events contain a lot of metadata (e.g., which environment a service gets deployed into), we can subscribe to events for a certain environment. </st><st c="81477">The following is a table that shows </st><span class="No-Break"><st c="81513">some examples:</st></span></p>
			<table id="table003-3" class="T---Table _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="T---Table">
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="81527">Source Tool</st></strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="81539">Event Properties</st></strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="81556">Subscribed By</st></strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p><span class="No-Break"><strong class="bold"><st c="81570">Action</st></strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><span class="No-Break"><st c="81577">Argo</st></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><strong class="bold"><st c="81582">Type</st></strong></span><span class="No-Break" lang="en-US" xml:lang="en-US"><st c="81587">: </st></span><span class="No-Break"><strong class="source-inline" lang="en-US" xml:lang="en-US"><st c="81590">service.deployed</st></strong></span></p>
							<p><span class="No-Break"><strong class="bold"><st c="81606">Environment</st></strong></span><span class="No-Break"><st c="81618">: </st></span><span class="No-Break"><strong class="source-inline"><st c="81621">staging</st></strong></span></p>
							<p><span class="No-Break"><strong class="bold"><st c="81628">Artifact</st></strong></span><span class="No-Break"><st c="81637">: </st></span><span class="No-Break"><strong class="source-inline"><st c="81640">fund-transfer:2.3</st></strong></span></p>
							<p><span class="No-Break"><strong class="bold"><st c="81657">Owner</st></strong></span><span class="No-Break"><st c="81663">: </st></span><span class="No-Break"><strong class="source-inline"><st c="81666">team-backend</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><st c="81678">K6 when </st><strong class="source-inline"><st c="81687">environment == "</st></strong><span class="No-Break"><strong class="source-inline"><st c="81703">staging"</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><st c="81712">Execute </st><span class="No-Break"><st c="81721">simple load</st></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p><st c="81732">.</st></p>
						</td>
						<td class="T---Table T---Body"/>
						<td class="T---Table T---Body">
							<p><span class="No-Break"><st c="81733">Slack when</st></span>
<strong class="source-inline"><st c="81744">Owner == </st></strong><span class="No-Break"><strong class="source-inline"><st c="81754">team-backend</st></strong></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><st c="81766">Send a notification to the team’s backend </st><span class="No-Break"><st c="81809">Slack channel</st></span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body"/>
						<td class="T---Table T---Body"/>
						<td class="T---Table T---Body">
							<p><span class="No-Break" lang="en-US" xml:lang="en-US"><st c="81822">OTel Collector</st></span></p>
						</td>
						<td class="T---Table T---Body">
							<p><span lang="en-US" xml:lang="en-US"><st c="81837">Collecting all events to forward to the </st></span><span class="No-Break" lang="en-US" xml:lang="en-US"><st c="81878">observability backend</st></span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="81899">Table 5.3: The same event from Argo can be subscribed by various tools for various actions</st></p>
			<p><st c="81990">Some tools already provide </st><a id="_idIndexMarker585"/><st c="82018">out-of-the-box support for CloudEvents where they can either subscribe to a CloudEvent source or provide an API endpoint that can consume CloudEvents. </st><st c="82169">For others, it will be necessary to build a slim integration layer where one subscribes to those events and then forwards them to the target tool. </st><st c="82316">It’s also possible to implement this using event bus systems that </st><span class="No-Break"><st c="82382">support CloudEvents.</st></span><a id="_idTextAnchor326"/></p>
			<h2 id="_idParaDest-138"><a id="_idTextAnchor327"/><st c="82402">Analyzing events</st></h2>
			<p><st c="82419">Now that we know how events are </st><a id="_idIndexMarker586"/><st c="82452">sent and how they can be subscribed by other tools, we can discuss how we can leverage them to analyze how well our life cycle processes </st><span class="No-Break"><st c="82589">actually work.</st></span></p>
			<p><st c="82603">Well-defined </st><a id="_idIndexMarker587"/><st c="82617">events that have a timestamp, a life cycle phase definition (</st><strong class="source-inline"><st c="82678">=event type</st></strong><st c="82690">), and some context (artifact, environment, owner) can be analyzed to answer questions, such as </st><span class="No-Break"><st c="82787">the following:</st></span></p>
			<ul>
				<li><st c="82801">How many deployments happen in a </st><span class="No-Break"><st c="82835">given environment?</st></span></li>
				<li><st c="82853">How many deployments are done for a particular application </st><span class="No-Break"><st c="82913">or tenant?</st></span></li>
				<li><st c="82923">How active is a team based on the </st><span class="No-Break"><st c="82958">ownership information?</st></span></li>
				<li><st c="82980">How many artifacts make it from development </st><span class="No-Break"><st c="83025">to production?</st></span></li>
				<li><st c="83039">Which artifacts take a long time and where are they blocked on the way </st><span class="No-Break"><st c="83111">to production?</st></span></li>
				<li><st c="83125">Are there certain artifacts that cause more security vulnerabilities or production problems </st><span class="No-Break"><st c="83218">than others?</st></span></li>
				<li><st c="83230">Which tools involved in the process are consuming most of </st><span class="No-Break"><st c="83289">the time?</st></span></li>
				<li><st c="83298">Are there tools that are most often the reason for a slow </st><span class="No-Break"><st c="83357">end-to-end process?</st></span></li>
			</ul>
			<p><st c="83376">There are probably many more questions that we can all answer by analyzing </st><span class="No-Break"><st c="83452">those events.</st></span></p>
			<p><st c="83465">How can we analyze them? </st><st c="83491">You can stream all those events to a database or your observability platform. </st><st c="83569">In </st><span class="No-Break"><em class="italic"><st c="83572">Figure 5</st></em></span><em class="italic"><st c="83580">.9</st></em><st c="83582">, we included OpenTelemetry, as events can just be ingested and forwarded to your observability backend and </st><span class="No-Break"><st c="83690">analyzed there.</st></span></p>
			<p class="callout-heading"><st c="83705">Bringing transparency into CI/CD through event observability</st></p>
			<p class="callout"><st c="83766">Having all events in a single spot with all that metadata and clearly defined types that represent the life cycle stages allows us to get a lot of transparency into the integration, delivery, and operations processes. </st><st c="83985">This data allows us to optimize our processes, which will result in </st><span class="No-Break"><st c="84053">more sustainability.</st></span></p>
			<p><st c="84073">Building automation for CI/CD and operations typically results in a lot of customized code that needs to be maintained across all projects it was copied to. </st><st c="84231">What we learned in this section is that moving to an event-driven approach for artifact life cycle management can address a lot of the complexity problems that are otherwise hidden in custom scripts or hardcoded </st><span class="No-Break"><st c="84443">tool-to-tool integrations.</st></span></p>
			<p><st c="84469">In </st><a href="B31164_09.xhtml#_idTextAnchor479"><span class="No-Break"><em class="italic"><st c="84473">Chapter 9</st></em></span></a><st c="84482">, we will cover additional aspects of how to reduce technical debt in all our platform components by making the right </st><span class="No-Break"><st c="84600">architectural decision</st><a id="_idTextAnchor328"/><st c="84622">s.</st></span></p>
			<h1 id="_idParaDest-139"><a id="_idTextAnchor329"/><st c="84625">IDPs – the automation Kraken in the platform</st></h1>
			<p><st c="84670">In this chapter so</st><a id="_idIndexMarker588"/><st c="84689"> far, we have learned a lot about the basic building blocks to automate the end-to-end build, delivery, deployment, and release process. </st><st c="84826">We have talked about new approaches to deploying the desired state with GitOps where the desired state is pulled from within the target environment versus pushed from an external tool, such as </st><span class="No-Break"><st c="85019">a pipeline.</st></span></p>
			<p><st c="85030">We discussed the end-to-end release processes on what happens from the first commit until releasing software to the end users. </st><st c="85158">Finally, we talked about applying an event-driven approach to orchestrating our artifact life cycle, which provides a centralized event hub to make everything that happens more transparent and observable. </st><st c="85363">It also gives us more flexibility as we can remove the complexity of tool integrations and process definitions from pipeline or bash scripts into event subscriptions and </st><span class="No-Break"><st c="85533">event-driven workflows.</st></span></p>
			<p><st c="85556">In this last section, we want to have a brief look into which of those concepts can be implemented with existing tools that you may already have, which new approaches exist to solve some of the challenges we discussed, and where you may want to look as some new tools have emerged over the last years – both open source and commercial – that take some of that work off </st><span class="No-Break"><st c="85926">our shoulders.</st></span></p>
			<p><st c="85940">We will do so by putting ourselves into the shoes of our users, our developers, or our development teams, as they are the ones who will need to apply to a new way </st><span class="No-Break"><st c="86104">of worki</st><a id="_idTextAnchor330"/><st c="86112">ng.</st></span></p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor331"/><st c="86116">Providing templates as Golden Paths for easier starts!</st></h2>
			<p><st c="86171">We try to enforce a lot of new practices, such as ensuring the right metadata on the deployments (version, application context, ownership, etc.) or having security vulnerability checks as part of every build pipeline. </st><st c="86390">In the platform engineering community, those are also referred to </st><a id="_idIndexMarker589"/><st c="86456">as </st><em class="italic"><st c="86459">Golden Paths</st></em><st c="86471">. To ensure that those practices can easily be followed by teams that start new projects, we need to make them easily accessible </st><span class="No-Break"><st c="86600">and adoptable!</st></span></p>
			<p><st c="86614">The easiest and most impactful approach is to provide software or repository templates. </st><st c="86703">These are templates in the forms of manifest files, pipelines, automation scripts, and so on that developers can find in a template repository, which they can then take and apply to </st><span class="No-Break"><st c="86885">their projects.</st></span></p>
			<p><st c="86900">While this approach works, it doesn’t force engineers to really use those templates; plus, it’s an additional manual step that can also lead </st><span class="No-Break"><st c="87042">to mistakes.</st></span></p>
			<p><st c="87054">One way to make this easier and automated is to either provide a CLI or a UI to initialize new or update existing git repositories with best-practice templates. </st><st c="87216">This can either be custom-built or we can look into existing solutions, such as </st><strong class="bold"><st c="87296">Backstage</st></strong><st c="87305">, a CNCF</st><a id="_idIndexMarker590"/><st c="87313"> project that was donated </st><span class="No-Break"><st c="87339">by Spotify.</st></span></p>
			<p><st c="87350">Backstage’s </st><strong class="bold"><st c="87363">Software Templates</st></strong><st c="87381"> feature </st><a id="_idIndexMarker591"/><st c="87390">was built to make Golden Path templates the entry point for every developer’s journey as they are building new software components. </st><st c="87522">Templates can be defined by subject matter experts who know how to properly configure pipelines, enable automated testing and deployment, and enforce </st><span class="No-Break"><st c="87672">security checks.</st></span></p>
			<p><st c="87688">Once templates are defined, they are available through an easy-to-use wizard that prompts the developer for some critical input data, such as what type of service they implement, ownership information, the requirements on observability or security, and so on – all of that input will then impact the creation of a new repository or the update of an existing one with the files and configurations from </st><span class="No-Break"><st c="88090">the template.</st></span></p>
			<p><st c="88103">To learn more about templating, check out the detailed documentation and examples on the </st><strong class="bold"><st c="88193">Backstage </st></strong><span class="No-Break"><strong class="bold"><st c="88203">website</st><a id="_idTextAnchor332"/></strong></span><span class="No-Break"> </span><span class="No-Break"><em class="italic"><st c="88210">[21]</st></em></span><span class="No-Break"><st c="88215">.</st></span></p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor333"/><st c="88216">Abstractions through Crossplane</st></h2>
			<p><st c="88248">Another simplification and way to enforce best practices is to provide an additional layer of abstraction when defining your </st><a id="_idIndexMarker592"/><st c="88374">application or services. </st><st c="88399">In K8s, we have to define our deployments, services, Ingress, </st><strong class="bold"><st c="88461">Persistent Volume Claims</st></strong><st c="88485"> (</st><strong class="bold"><st c="88487">PVCs</st></strong><st c="88491">), and even more when we need to deploy dependent services, such as a database, a cache, or any other required </st><span class="No-Break"><st c="88603">software components.</st></span></p>
			<p><st c="88623">In the earlier section on IaC, we introduced the CNCF project, Crossplane. </st><strong class="bold"><st c="88699">Crossplane</st></strong><st c="88709"> orchestrates </st><a id="_idIndexMarker593"/><st c="88723">both infrastructure and application deployment through code and provides a concept of </st><a id="_idIndexMarker594"/><st c="88809">so-called </st><strong class="bold"><st c="88819">composites</st></strong><st c="88829">. We will not spend more time here on this as we already provided several examples earlier on how to use composites to provision a performance test environment as well as one to define a financial backend type of application where the developer only needs to specify the versions of services that will then be deployed together. </st><st c="89158">The following are just the first two lines of that composite definition. </st><st c="89231">See the rest in the </st><em class="italic"><st c="89251">Crossplane – IaC for platform and </st></em><span class="No-Break"><em class="italic"><st c="89285">applications</st></em></span><span class="No-Break"><st c="89297"> section:</st></span></p>
			<pre class="source-code"><st c="89306">
apiVersion: composites.financialone.acme/v1alpha1
kind: FinancialBackend</st></pre>
			<p><st c="89379">When providing abstractions, it is important to make them known to developers. </st><st c="89459">This can be done by providing educational material or simply providing them through the same templating approach, as discussed earlier, using a tool such </st><span class="No-Break"><st c="89613">as B</st><a id="_idTextAnchor334"/><st c="89617">ackstage.</st></span></p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor335"/><st c="89627">Everything Git-flow-driven</st></h2>
			<p><st c="89654">Well, it should be no surprise that Git</st><a id="_idIndexMarker595"/><st c="89694"> is our source of truth – we have established this early in the chapter. </st><st c="89767">However, most Git solutions provide additional capabilities that we can use to also enforce standards and processes (e.g., GitHub workflows). </st><st c="89909">Workflows can be triggered on a schedule or as part of many different events that can happen in the end to end flow of a Git driven process (e.g., </st><em class="italic"><st c="90056">push</st></em><st c="90060">, </st><em class="italic"><st c="90062">pull </st></em><span class="No-Break"><em class="italic"><st c="90067">requests</st></em></span><span class="No-Break"><st c="90075">, </st></span><span class="No-Break"><em class="italic"><st c="90077">release</st></em></span><span class="No-Break"><st c="90084">).</st></span></p>
			<p><st c="90087">This allows us to enforce our standards as well before artifacts get built and pushed; for instance, validating mandatory metadata files we expect for every deployment (e.g., ownership information). </st><st c="90287">We can also use this to automatically do code scans and generate scorecards or we can use it to validate that all dependencies are safe and don’t have any known </st><span class="No-Break"><st c="90448">security vulnerabilities.</st></span></p>
			<p><st c="90473">Depending on the Git tool that is chosen, you will typically find a marketplace or best practice catalog of workflows and actions that can and should be executed for certain types of projects. </st><st c="90667">Make sure you make yourself familiar with all that is possible based on your </st><span class="No-Break"><st c="90744">to</st><a id="_idTextAnchor336"/><st c="90746">ol choice.</st></span></p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor337"/><st c="90757">Software catalog</st></h2>
			<p><st c="90774">Once we enable developers to build more software that follows all our processes, we will hopefully see the result in a lot of new services being developed. </st><st c="90931">Those are services that other developers also need to know about so that we avoid the problem of development teams building duplicated services and encouraging developers to build more capabilities on top of existing services </st><span class="No-Break"><st c="91157">and APIs.</st></span></p>
			<p><st c="91166">A </st><strong class="bold"><st c="91169">software catalog</st></strong><st c="91185"> that</st><a id="_idIndexMarker596"/><st c="91190"> gives an overview of all available services and APIs and ideally also provides some documentation is what we are </st><span class="No-Break"><st c="91304">aiming for.</st></span></p>
			<p><st c="91315">As </st><a id="_idIndexMarker597"/><st c="91319">Git is the source of truth, we can extract most of this information straight from Git. </st><st c="91406">Depending on which Git solution we choose, a software catalog might already be part of the offering. </st><st c="91507">However, there are more services and APIs that are part of the software catalog that an organization owns and can develop against (e.g., external APIs or third-party software </st><span class="No-Break"><st c="91682">deployed on-premises).</st></span></p>
			<p><st c="91704">Backstage, the tool that</st><a id="_idIndexMarker598"/><st c="91729"> also provides the templating feature discussed earlier, also comes with a software catalog. </st><st c="91822">It gets its data from parsing specific metadata files in Git repositories but also allows external data sources to provide entity information. </st><st c="91965">The following illustration is taken from the Backstage blog and shows what Spotify’s software catalog in Backstage </st><span class="No-Break"><st c="92080">looks like:</st></span></p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B31164_05_10.jpg" alt="Figure 5.10: Software catalog extracted from entity metadata in Git"/><st c="92091"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="93405">Figure 5.10: Software catalog extracted from entity metadata in Git</st></p>
			<p><st c="93472">As we can see from the preceding screenshot, software catalogs are a powerful way to understand what software components are available within an organization, what type of software it is, who owns it, where to find the source code, and </st><span class="No-Break"><st c="93709">additional information.</st></span></p>
			<p><st c="93732">Tools such as Backstage</st><a id="_idIndexMarker599"/><st c="93756"> are not the full IDP; however, they represent a portal – a graphical UI – into all the data relevant for the majority of the users of </st><span class="No-Break"><st c="93891">an IDP.</st></span></p>
			<p><st c="93898">While Backstage is one option, there are many other options out there. </st><st c="93970">Everything from homegrown to other open source or commercial tools, such as Cortex, Humanitec, Por</st><a id="_idTextAnchor338"/><st c="94068">t, </st><span class="No-Break"><st c="94072">or Kratix.</st></span></p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor339"/><st c="94082">Summary</st></h1>
			<p><st c="94090">In this chapter, we learned a lot about the underlying automation and processes to get an artifact from the initial creation all the way into production. </st><st c="94245">For modern platforms, a GitOps approach where we pull versus push changes should be a key consideration. </st><st c="94350">We learned about Git as the source of truth and artifacts (container or OCI-compliant images) as of our business logic into our </st><span class="No-Break"><st c="94478">target environments.</st></span></p>
			<p><st c="94498">As an organization grows, it’s important to enforce good processes and best practices. </st><st c="94586">For enforcement to work, it needs to be easily accessible and should be available end-to-end as a self-service to not impact the flow of creativity </st><span class="No-Break"><st c="94734">of engineers.</st></span></p>
			<p><st c="94747">This also brings us to the topic of the next chapter. </st><st c="94802">In </st><a href="B31164_06.xhtml#_idTextAnchor341"><span class="No-Break"><em class="italic"><st c="94805">Chapter 6</st></em></span></a><st c="94814">, we dive into the importance of focusing on self-service capabilities that really address the needs of our target users: our developers. </st><st c="94952">We will discuss how to bring those Golden Paths’ best practices into our platform to significantly improve the way developers can get their </st><span class="No-Break"><st c="95092">work done.</st></span></p>
			<h1 id="_idParaDest-145"><a id="_idTextAnchor340"/><st c="95102">Further reading</st></h1>
			<ul>
				<li><st c="95118">[1] OpenFeature – </st><a href="https://openfeature.dev/"><span class="No-Break"><st c="95137">https://openfeature.dev/</st></span></a></li>
				<li><st c="95161">[2] Crossplane – </st><a href="https://www.crossplane.io/"><span class="No-Break"><st c="95179">https://www.crossplane.io/</st></span></a></li>
				<li><st c="95205">[3] Renovate Bot – </st><a href="https://github.com/renovatebot/renovate"><span class="No-Break"><st c="95225">https://github.com/renovatebot/renovate</st></span></a></li>
				<li><st c="95264">[4] Semantic Versioning – </st><a href="https://semver.org/"><span class="No-Break"><st c="95291">https://semver.org/</st></span></a></li>
				<li><st c="95310">[5] Kustomize – </st><a href="https://kustomize.io/"><span class="No-Break"><st c="95327">https://kustomize.io/</st></span></a></li>
				<li><st c="95348">[6] Helm – </st><a href="https://helm.sh/"><span class="No-Break"><st c="95360">https://helm.sh/</st></span></a></li>
				<li><st c="95376">[7] </st><em class="italic"><st c="95381">The Pragmatic Programmer</st></em><st c="95405"> – the DRY principle – </st><a href="https://media.pragprog.com/titles/tpp20/dry.pdf"><span class="No-Break"><st c="95428">https://media.pragprog.com/titles/tpp20/dry.pdf</st></span></a></li>
				<li><st c="95475">[8] </st><em class="italic"><st c="95480">How to set up GitOps directory structure</st></em><st c="95520"> – </st><a href="https://developers.redhat.com/articles/2022/09/07/how-set-your-gitops-directory-structure#directory_structures"><span class="No-Break"><st c="95523">https://developers.redhat.com/articles/2022/09/07/how-set-your-gitops-directory-structure#directory_structures</st></span></a></li>
				<li><st c="95633">[9] Argo CD – </st><a href="https://argo-cd.readthedocs.io/en/stable/"><span class="No-Break"><st c="95648">https://argo-cd.readthedocs.io/en/stable/</st></span></a></li>
				<li><st c="95689">[10] Flux – </st><a href="https://fluxcd.io/flux/"><span class="No-Break"><st c="95702">https://fluxcd.io/flux/</st></span></a></li>
				<li><st c="95725">[11] Open Container Initiative – </st><a href="https://opencontainers.org/"><span class="No-Break"><st c="95759">https://opencontainers.org/</st></span></a></li>
				<li><st c="95786">[12] Suggested container annotations – </st><a href="https://github.com/opencontainers/image-spec/blob/main/annotations.md"><span class="No-Break"><st c="95826">https://github.com/opencontainers/image-spec/blob/main/annotations.md</st></span></a></li>
				<li><st c="95895">[13] Harbor – </st><a href="https://goharbor.io/"><span class="No-Break"><st c="95910">https://goharbor.io/</st></span></a></li>
				<li><st c="95930">[14] Harbor Prometheus metrics – </st><a href="https://goharbor.io/docs/2.10.0/administration/metrics/"><span class="No-Break"><st c="95964">https://goharbor.io/docs/2.10.0/administration/metrics/</st></span></a></li>
				<li><st c="96019">[15] Harbor distributed tracing – </st><a href="https://goharbor.io/docs/2.10.0/administration/distributed-tracing/"><span class="No-Break"><st c="96054">https://goharbor.io/docs/2.10.0/administration/distributed-tracing/</st></span></a></li>
				<li><st c="96121">[16] </st><em class="italic"><st c="96127">CNCF TAG App Delivery</st></em><st c="96148"> – </st><a href="https://tag-app-delivery.cncf.io/"><span class="No-Break"><st c="96151">https://tag-app-delivery.cncf.io/</st></span></a></li>
				<li><st c="96184">[17] Keptn – </st><a href="https://keptn.sh/"><span class="No-Break"><st c="96198">https://keptn.sh/</st></span></a></li>
				<li><st c="96215">[18] </st><em class="italic"><st c="96221">Argo Rollouts</st></em><st c="96234"> – </st><a href="https://argoproj.github.io/rollouts/"><span class="No-Break"><st c="96237">https://argoproj.github.io/rollouts/</st></span></a></li>
				<li><st c="96273">[19] Flagger – </st><a href="https://flagger.app/"><span class="No-Break"><st c="96289">https://flagger.app/</st></span></a></li>
				<li><st c="96309">[20] CDEvents –  </st><a href="https://github.com/cdevents"><span class="No-Break"><st c="96326">https://github.com/cdevents</st></span></a></li>
				<li><st c="96353">[21] Backstage – </st><a href="https://backstage.io/"><span class="No-Break"><st c="96371">https://backstage.io/</st></span></a></li>
			</ul>
		</div>
	<div id="charCountTotal" value="96392"/></body></html>