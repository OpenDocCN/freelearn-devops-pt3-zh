<html><head></head><body>
		<div id="_idContainer035">
			<h1 id="_idParaDest-67" class="chapter-number"><a id="_idTextAnchor066"/>3</h1>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor067"/>Automation for Efficiency and Quality</h1>
			<p>Of the factors in the CALMR (Culture, Automation, Lean Flow, Measuring, Recovery) approach, automation is the one most associated with the DevOps approach. A great deal of energy is devoted by DevOps practitioners to keeping current on trends in technology for environments and tooling. These tools, with different functions, are tied together to form a toolchain or pipeline. </p>
			<p>We start our look at different types of tools in our pipeline by looking at the foundational tool types every pipeline needs. This includes Agile project management, version control systems, and <span class="No-Break">review/documentation tools.</span></p>
			<p><strong class="bold">Continuous Integration</strong> (<strong class="bold">CI</strong>) tools stem from build management utilities. We will examine tools that create builds and other types of tools that run when a build is executed. These include automated testing tools, packaging tools, and <span class="No-Break">artifact repositories.</span></p>
			<p>An extension of CI is the deployment of build packages to staging and production environments. We will examine the tool types used in <strong class="bold">Continuous Deployment</strong> (<strong class="bold">CD</strong>), including configuration management, <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>), and vulnerability <span class="No-Break">scanning tools.</span></p>
			<p>Automation still relies on people. We will have a look at the ways development teams and operations teams can align to create the necessary automation and environments using <span class="No-Break">DevOps topologies.</span></p>
			<p>Finally, we’ll see how people create the automation for the Continuous Delivery Pipeline in SAFe® by examining what the system team does in the <strong class="bold">Agile Release </strong><span class="No-Break"><strong class="bold">Train</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ART</strong></span><span class="No-Break">).</span></p>
			<p>In a nutshell, the following topics will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Pipelines <span class="No-Break">and toolchains</span></li>
				<li><span class="No-Break">Continuous integration</span></li>
				<li><span class="No-Break">Continuous deployment</span></li>
				<li><span class="No-Break">DevOps topologies</span></li>
				<li>The <span class="No-Break">system team</span></li>
			</ul>
			<h1 id="_idParaDest-69"><a id="_idTextAnchor068"/>Pipelines and toolchains</h1>
			<p>A toolchain is the set<a id="_idIndexMarker179"/> of tools <a id="_idIndexMarker180"/>used in DevOps practices in the product development life cycle. The classic representation of the toolchain used in DevOps is an infinity loop, broken up into a number of functions. Each function or stage is enhanced by automation. A representation of this infinity loop, created by Kharnagy, and licensed under the Creative Commons Attribution ShareAlike license, is shown in the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B18756_03_01.jpg" alt="Figure 3.1 – DevOps toolchain "/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – DevOps toolchain </p>
			<p>If we separate the ends of this infinity loop, we see the basis of our pipeline. The pipeline orchestrates the operation of all the stages with the exception of the monitoring stage. This begins our look at each pipeline stage, as shown in the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B18756_03_02.jpg" alt="Figure 3.2 – DevOps pipeline"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.2 – DevOps pipeline</p>
			<p>We begin our examination of the pipeline by looking at the activities whose artifacts set the pipeline in motion: plan and create. These foundational steps are illustrated in <span class="No-Break"><em class="italic">Figure 3</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B18756_03_03.jpg" alt="Figure 3.3 – Pipeline foundations"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.3 – Pipeline foundations</p>
			<p>Let’s start our examination of the CI/CD pipeline by looking at foundational tools. We will look at tools that can assist with planning in our value stream and monitoring the progress of<a id="_idIndexMarker181"/> the <a id="_idIndexMarker182"/>overall development process. We’ll also examine the tools that act as repositories for the code, tests, configuration scripts, <span class="No-Break">and documentation.</span></p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor069"/>Planning with Agile project management tools</h2>
			<p>To look at <a id="_idIndexMarker183"/>where we<a id="_idIndexMarker184"/> are from request to release, we need to find a way to understand what we must do, and what the progress is of those steps. There are a large variety of methods to achieve this, from physical Kanban boards to Excel spreadsheets. As teams deal with remote and geographically distributed ways of working, Agile project management tools are a popular method for <span class="No-Break">doing this.</span></p>
			<p>Agile project management tools allow for the creation and update of work items. Progress on the work items is displayed on either a Kanban board or a list of issues. Recording the work items and their progress allows for easy collection of progress metrics, such as <span class="No-Break">lead time.</span></p>
			<p>In addition, work items can be linked to branches in version control and executions in a CI/CD pipeline tool. This allows for a trail of when a change was released throughout the <span class="No-Break">entire pipeline.</span></p>
			<p>Leading Agile project management tools include Jira and Trello, both by Atlassian, Azure DevOps by Microsoft, Digital.ai Agility (formerly known as VersionOne), IBM Engineering Work Management (formerly known as IBM Team Concert), and Broadcom Rally. In addition, many version control tools such as GitHub and GitLab include Agile project <span class="No-Break">management</span><span class="No-Break"><a id="_idIndexMarker185"/></span><span class="No-Break"> functions.</span></p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor070"/>Creating code and documentation</h2>
			<p>Version control<a id="_idIndexMarker186"/> has been an important part of software development since the 1990s. With version control, multiple developers can work on the same code base without fear of deleting each other’s changes. To accomplish this, developers create a branch that contains their changes. When the time comes to share these changes, they merge the changes back into a shared branch where any differences are resolved. Merges can also be effective points for other developers to review any code changes going to the <span class="No-Break">shared branch.</span></p>
			<p>These days, code is not the only artifact kept in version control. Testing scripts used for automated testing can be kept in version control. Text files that are used for configuring staging and production environments are also kept in version control. In short, anything that is text that refers to any change or release is kept in version control. As we saw in <a href="B18756_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introducing SAFe® and DevOps</em>, when looking at Flickr, a common version control system between Dev and Ops <span class="No-Break">is best.</span></p>
			<p>The most prevalent version control system for code is Git, invented by Linus Torvalds, which was used as the repository for the Linux operating system. Git is a distributed version control system that allows copies of the entire repository to be easily replicated, even to developers. Even with the ease of replication, there are Git hosting solutions available that allow organizations to centralize the repositories to an <em class="italic">origin</em>. The most popular Git hosting products include Bitbucket by Atlassian, GitHub, GitLab, and <span class="No-Break">Azure DevOps.</span></p>
			<p>Documentation is another important artifact created for product development. <strong class="bold">Non-Functional Requirements</strong> (<strong class="bold">NFRs</strong>) may<a id="_idIndexMarker187"/> be detailed in specifications, architecture may be specified in <a id="_idIndexMarker188"/>terms of models and diagrams, and <strong class="bold">user interface/user experience</strong> (<strong class="bold">UI/UX</strong>) guidelines may be depicted as wireframes and sketches. These initial designs may start from planning and continue in the iterative <span class="No-Break">learning cycles.</span></p>
			<p>Document repositories and wiki software are used to store requirements specifications, architectural models, UI wireframes, and product and user documentation. Popular repositories include Confluence from Atlassian and <span class="No-Break">GitLab Pages.</span></p>
			<p>Once changes have been added to the repository in version control, the work of the CI/CD pipeline can <a id="_idIndexMarker189"/>begin. Let’s take a look at the activities that make up <span class="No-Break">continuous integration.</span></p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor071"/>Continuous integration</h1>
			<p>When code <a id="_idIndexMarker190"/>changes are ready, automation can begin building the necessary packages for use in staging and production environments. As part of the build process, tests can be run to determine the correct function as well as security. When testing indicates correct and secure functionality, a package is created and stored in artifact repositories based on the <span class="No-Break">technology used.</span></p>
			<p>This part of the pipeline is illustrated in the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B18756_03_04.jpg" alt="Figure 3.4 – Pipeline: Continuous integration"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.4 – Pipeline: Continuous integration</p>
			<p>Let’s look at how the CI portion of the pipeline manages a build, executes the initial-level testing, and packages the build. We will begin with a definition of continuous integration, continuous delivery, and <span class="No-Break">continuous deployment.</span></p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor072"/>Continuous integration versus continuous delivery versus continuous deployment</h2>
			<p>We will<a id="_idIndexMarker191"/> see that continuous integration <a id="_idIndexMarker192"/>captures the activities that can be automatically run once a change has been committed to the version control system. Code, including any changes, can be compiled or packaged to a form computers can use. Tests are run after the build step to ensure no bugs or security vulnerabilities have been introduced. Notifications can be created upon success or failure. Upon success, the code changes can be merged with the existing code base. We will examine these steps in detail when we look at the continuous integration stage of the Continuous Delivery Pipeline in <a href="B18756_11.xhtml#_idTextAnchor244"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Continuous Integration of </em><span class="No-Break"><em class="italic">Solution Development</em></span><span class="No-Break">.</span></p>
			<p>Continuous delivery takes the continuous integration steps further by allowing the newly-merged changes to be packaged and delivered to a staging environment, a test environment that is as similar to production as possible, or to production. Once delivered to the environment, further tests can be run to verify the correctness of new features or to perform a deeper security scan. The success of these tests allows the organization to release the changes when they’re ready. Detailed steps outlining continuous delivery (labeled as continuous deployment) will be listed in <a href="B18756_12.xhtml#_idTextAnchor268"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>, <em class="italic">Continuous Deployment </em><span class="No-Break"><em class="italic">to Production</em></span><span class="No-Break">.</span></p>
			<p>Continuous deployment is continuous delivery with one further step: when the tests are complete in the production environment, the new features are automatically released to allow customers to use <span class="No-Break">them immediately.</span></p>
			<p>Regardless of whether your final stop in automation is continuous integration, continuous <a id="_idIndexMarker193"/>delivery, or you completely <a id="_idIndexMarker194"/>automate a release through continuous deployment, you will typically use the same tool to establish your pipeline. Let’s look at that category of <span class="No-Break">tools now.</span></p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor073"/>Orchestrating the change</h2>
			<p>Pipeline<a id="_idIndexMarker195"/> orchestration tools (commonly referred to as CI/CD tools) begin as build management tools. These tools execute build scripts and perform additional actions when triggered manually or automatically when a commit occurs in the version control system. </p>
			<p>Earlier versions of CI/CD tools maintained the jobs to be done as part of the UI. CI/CD tools today allow jobs to be defined through a text file using YAML or other formats. </p>
			<p>The power of the CI/CD tools lies in their flexibility. Easy integration with other tools to perform other functions, such as automated testing and deployment, has enabled overall success in the DevOps movement. Scalability in execution through the incorporation of agent software in worker nodes is another important factor, allowing jobs to be created in <span class="No-Break">any environment.</span></p>
			<p>CI/CD tools can be set up in <em class="italic">on-premises</em> environments, on private clouds, or as <strong class="bold">Software-as-a-Service </strong>(<strong class="bold">SaaS</strong>) products. The most popular CI/CD tool for on-premises or private cloud environments continues to be Jenkins, an open source project that started as Hudson. Other popular tools include CircleCI and Bamboo from Atlassian. Many Git hosting products have rolled out CI/CD pipeline extensions as part of their system, including GitLab, GitHub <a id="_idIndexMarker196"/>Actions on GitHub, Azure DevOps, and Bitbucket Pipelines on <span class="No-Break">Bitbucket Cloud.</span></p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor074"/>Verifying quality</h2>
			<p>By far, one of the<a id="_idIndexMarker197"/> most important functions a pipeline can do is set up and execute automated testing. Automated testing is gaining attention due to the <em class="italic">shift-left</em> philosophy with the realization that the earlier and more often you do testing, the better the quality of the finished product. The DevSecOps movement advocates for earlier and more frequent automated testing as a way of establishing <em class="italic">continuous security</em>. Early testing can be done without requiring the code to be executed in an environment either through simulated inputs and evaluating outputs or through an examination of <span class="No-Break">the code.</span></p>
			<p>These <em class="italic">first-level</em> tests are known as unit tests and static analyses. Let’s take a detailed look at <span class="No-Break">them now.</span></p>
			<h3>Unit tests (test-driven development)</h3>
			<p>Unit tests are <a id="_idIndexMarker198"/>scripts written to verify that functions in code produce the desired output when given simulated input. Unit test frameworks such as JUnit and NUnit are specific to the language used to create the code. Unit tests can run directly from the pipeline as a defined stage. </p>
			<p>Test management software can also be used to execute unit tests. Each unit test is saved as a test case in the test management software, and the results are recorded. Test management software can also set up an integration to Agile project management tools to record defects when <span class="No-Break">tests fail.</span></p>
			<p>Popular test management software includes Engineering Test Management from IBM, XRay from XBlend, and Zephyr <span class="No-Break">from SmartBear.</span></p>
			<h3>Static analysis</h3>
			<p>Static <a id="_idIndexMarker199"/>analysis is the examination of code without executing it. Typically, tools are used to analyze and audit the code. Static analysis has other names depending on the <span class="No-Break">expected outputs:</span></p>
			<ul>
				<li>Linting is a static analysis done with a specific tool (lint). Linting examines code looking for possible code errors and can be used to enforce <span class="No-Break">coding standards.</span></li>
				<li><strong class="bold">Static application security testing</strong> (<strong class="bold">SAST</strong>) is static analysis applied to searching for possible security vulnerabilities <span class="No-Break">in code.</span></li>
				<li>Dependency scanning looks at the dependencies of libraries called by code to review whether known security vulnerabilities exist. </li>
				<li>License scanning looks at the dependencies called by code to review the type of open source licensing the libraries use. This helps keep the organization compliant with the types of open source licenses used and if attribution and distribution of changes <span class="No-Break">are required.</span></li>
			</ul>
			<p>Tooling that can perform the analysis described, including SAST, includes SonarQube from SonarSource, Snyk, Coverity from Synopsys, mend.io (formerly WhiteSource), Klocwork<a id="_idIndexMarker200"/> offered by Perforce, as well <span class="No-Break">as GitLab.</span></p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor075"/>Packaging for deployment</h2>
			<p>After the first<a id="_idIndexMarker201"/> level of the tests pass, the pipeline can then prepare the code changes. Packaging the changes is dependent upon several factors, including the language and the technology used <span class="No-Break">for deployment.</span></p>
			<p>Artifact repository tools allow for version control of large package images. These may pose problems with storage on the version control software mentioned previously because these artifacts are large binary files. These binary images may range from standard packages such as WAR files in Java or NPM images in Node.js, to <strong class="bold">virtual machine </strong>(<strong class="bold">VM</strong>) images. The popularity of Docker as a deployment technology has created a need to identify and version control Docker images in private repositories, resulting in additional capabilities for artifact <span class="No-Break">repository tools.</span></p>
			<p>Popular artifact repository tools include Artifactory by JFrog and Nexus by Sonatype. In addition, GitLab and Azure DevOps include the ability to act as an artifact repository for binary images. </p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor076"/>Continuous deployment</h1>
			<p>During the <a id="_idIndexMarker202"/>continuous integration phase of the pipeline, we saw the last step as the packaging of changes into a binary image. Continuous deployment continues from that step to the application of that image into testing and production environments. </p>
			<p>Automation may play a role in adding or updating resources in these environments. IaC tools allow the configuration of <span class="No-Break">these resources.</span></p>
			<p>Now that code changes are in an environment, testing can be done in further detail to find problems with quality and security. Here, the tests may also look at how changes affect the performance and validation of the <span class="No-Break">desired changes.</span></p>
			<p>As changes are added to environments, we need to be aware of the effects of these changes. To that end, we will measure the performance of the overall environment including the storage and analysis <span class="No-Break">of logs.</span></p>
			<p>The continuous deployment stage is illustrated in the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B18756_03_05.jpg" alt="Figure 3.5 – Pipeline: Continuous deployment"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.5 – Pipeline: Continuous deployment</p>
			<p>Let’s look at these activities carried out in the environments. We may need to configure the environment to set up new features. Then comes the actual deployment of changes into the environment. Finally, more and deeper testing can be performed in the environment to ensure the correct function, security, <span class="No-Break">and value.</span></p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor077"/>Configuring environments with IaC </h2>
			<p>Often, changes <a id="_idIndexMarker203"/>may <a id="_idIndexMarker204"/>involve creating new resources in an environment. Part of the configurations in configuration management tools may invoke other tools that allow the automatic creation of resources. The creation of these resources is guided by a script, often in YAML format. Due to the reliance on these scripts, the tools are described <span class="No-Break">as IaC.</span></p>
			<p>The emergence of public cloud environments, such as <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), Azure <a id="_idIndexMarker205"/>from Microsoft, and Google Cloud Platform, has introduced tools associated with each cloud environment. The most notable of these is CloudFormation, which works <span class="No-Break">with AWS.</span></p>
			<p>Other vendors offer IaC tools that are more flexible, working in a variety of physical servers, private cloud, and public cloud environments. The most notable <a id="_idIndexMarker206"/>of these is Terraform <a id="_idIndexMarker207"/>by Hashicorp. </p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor078"/>Releasing with configuration management and feature flags</h2>
			<p>Configuration<a id="_idIndexMarker208"/> management<a id="_idIndexMarker209"/> tools are responsible <a id="_idIndexMarker210"/>for <a id="_idIndexMarker211"/>identifying and setting the configuration of development and production environments. A pipeline can invoke the configuration management tool to introduce a build package that has passed the continuous <span class="No-Break">integration stage.</span></p>
			<p>Originally, configuration management tools specified the configuration for physical (bare metal) servers or VM images. They have grown to include Docker containers and <span class="No-Break">Kubernetes clusters.</span></p>
			<p>Descriptions of configurations are often specified in terms of the desired configuration state but do not elaborate on the necessary steps to achieve the desired state. This helps to achieve idempotence in <span class="No-Break">the system.</span></p>
			<p>Popular configuration management tools include Chef by Progress Chef, Puppet, and Ansible by Red Hat. Ansible has an advantage over both Chef and Puppet in that it connects to the environment resources <a id="_idIndexMarker212"/>through <strong class="bold">Secure Shell</strong> (<strong class="bold">SSH</strong>), which removes the need to install agent software on <span class="No-Break">the resource.</span></p>
			<h3>Release visibility with feature flags</h3>
			<p>Even as code <a id="_idIndexMarker213"/>changes make their way into production environments, those changes may not be visible to the end users or affect existing functionality. This may be due to code switches or <em class="italic">feature flags</em> that prevent the visibility of the code changes. This allows for a gradual rollout of changes, such as canary deployments. This also allows for a quick reversion to the previous state by deactivating the applicable <span class="No-Break">feature flags.</span></p>
			<p>Popular feature <a id="_idIndexMarker214"/>flag tools include LaunchDarkly, Flagsmith, and CloudBees <span class="No-Break">Feature Management.</span></p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor079"/>Additional verification through advanced testing in the environment</h2>
			<p>Now that<a id="_idIndexMarker215"/> changes are built, packaged, and placed in environments, testing can work on deeper levels. Test inputs can be placed in the environment to determine whether the code works as expected, whether any vulnerabilities are introduced, and whether the system behaves as expected. </p>
			<p>These types of tests that measure correct functionality, security, and acceptance are described <span class="No-Break">as follows.</span></p>
			<h3>Functional and UI testing</h3>
			<p>Functional <a id="_idIndexMarker216"/>testing is most concerned <a id="_idIndexMarker217"/>with code correctness. It exists primarily <a id="_idIndexMarker218"/>to see whether the coding works and meets the base<a id="_idIndexMarker219"/> requirements. Typically, functional tests go beyond the individual code functions, which would have been tested during unit testing. Specific types of functional testing are used in the <span class="No-Break">following </span><span class="No-Break"><a id="_idIndexMarker220"/></span><span class="No-Break">scenarios:</span></p>
			<ul>
				<li><strong class="bold">Sanity testing</strong> is running<a id="_idIndexMarker221"/> a small set of functional tests to verify <span class="No-Break">code features</span></li>
				<li><strong class="bold">Smoke testing</strong> usually <a id="_idIndexMarker222"/>involves running short, high-level functional tests to gain confidence in a new build or a <span class="No-Break">new deployment</span></li>
				<li><strong class="bold">Regression testing</strong> is a more <a id="_idIndexMarker223"/>extensive execution of functional tests to verify that new code features work with the existing <span class="No-Break">system functionality</span></li>
			</ul>
			<p>Automated tools for functional testing depend upon the language the coding features are written in, the environment the code will be deployed in, and the technology platform (web versus mobile versus other). A cross-section of popular tools includes UFT by Micro Focus, Worksoft Certify, and <span class="No-Break">Tricentis Tosca.</span></p>
			<p>UI testing is functional testing for graphical UIs. This ensures that elements such as buttons and fields on a web page connect to the correct underlying code functions and ensures the correctness of those code functions. </p>
			<p>Many popular UI testing tools are based on Selenium, a platform that captures actions performed on<a id="_idIndexMarker224"/> a web page in scripts that can<a id="_idIndexMarker225"/> be repeated by automation. Such <a id="_idIndexMarker226"/>tools include TestComplete and CrossBrowserTesting by<a id="_idIndexMarker227"/> SmartBear and <span class="No-Break">Sauce Labs.</span></p>
			<h3>Load/performance testing</h3>
			<p>Performance<a id="_idIndexMarker228"/> testing, such as<a id="_idIndexMarker229"/> load testing, is not designed to measure correct functionality. Rather, the goal of performance testing is to verify any NFRs such as reliability and scalability. We want to see how the system, including any new code changes, can handle increased demand for its resources by flooding the system with a large number of system requests, such as logins and <span class="No-Break">form evaluations.</span></p>
			<p>Popular tools for performance testing include LoadRunner from Micro Focus and JMeter for traditional applications and Sauce Performance from Sauce Labs for web and mobile application <span class="No-Break">performance testing.</span></p>
			<h3>Dynamic application security testing </h3>
			<p><strong class="bold">Dynamic application security testing</strong> (<strong class="bold">DAST</strong>) continues<a id="_idIndexMarker230"/> the<a id="_idIndexMarker231"/> emphasis on security in DevSecOps. With DAST, automated tests continue security scanning by performing simulated attacks on the environment for web applications to find vulnerabilities. </p>
			<p>A leading DAST scanner is OWASP Zed Attack Proxy, which is used by GitLab to provide DAST scanning functionality on <span class="No-Break">its pipeline.</span></p>
			<h3>IaC scanning</h3>
			<p>Additional<a id="_idIndexMarker232"/> tests for DevSecOps <a id="_idIndexMarker233"/>continue with the ability to scan the IaC files to discover whether there are any misconfigurations or security vulnerabilities. </p>
			<p>Leading tools such as Snyk and GitLab can scan for multiple IaC tools, including Ansible, Terraform, Dockerfiles, and configuration services for public clouds, such as CloudFormation, Google <a id="_idIndexMarker234"/>Deployment<a id="_idIndexMarker235"/> Manager, and <strong class="bold">Azure Resource </strong><span class="No-Break"><strong class="bold">Manager</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ARM</strong></span><span class="No-Break">).</span></p>
			<h3>Container scanning</h3>
			<p>Containers <a id="_idIndexMarker236"/>are a technology where an application and any needed libraries are encapsulated as a virtual image. This virtual image can be an extension of base resources that represent the functions provided by an <span class="No-Break">operating system.</span></p>
			<p>Docker is the technology used to implement containers. Developers define the application and libraries in Docker images. The image can be placed in a repository where it can be pulled and executed in any environment by <span class="No-Break">Docker Engine.</span></p>
			<p>Container scanning allows the Docker image and dependent images to be scanned to look for security vulnerabilities. Tools that can implement container scanning include GitLab <span class="No-Break">and Snyk.</span></p>
			<h3>Acceptance tests (behavior-driven development)</h3>
			<p>Acceptance <a id="_idIndexMarker237"/>tests are test scripts written in a business-readable language called Gherkin. Each test is composed of three main clauses, each starting with <span class="No-Break">a keyword:</span></p>
			<ul>
				<li><strong class="bold">Given</strong>: This clause<a id="_idIndexMarker238"/> describes the <span class="No-Break">initial conditions</span></li>
				<li><strong class="bold">When</strong>: This clause <a id="_idIndexMarker239"/>describes the input for <span class="No-Break">the test</span></li>
				<li><strong class="bold">Then</strong>: This clause<a id="_idIndexMarker240"/> describes the <span class="No-Break">desired behavior</span></li>
			</ul>
			<p>Cucumber is the tool that executes Gherkin tests. Cucumber is available in an open source version and paid versions are available in CucumberStudio and Cucumber for Jira. All versions are supported <span class="No-Break">by SmartBear.</span></p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor080"/>Monitoring the environment</h2>
			<p>We now leave<a id="_idIndexMarker241"/> tools that are part of the pipeline to tools that are run continuously. Ongoing evaluation of staging and production environments is done by tools independent of the pipeline. These tools perform the <span class="No-Break">following functions:</span></p>
			<h3>Performance monitoring/reporting</h3>
			<p>Stability is <a id="_idIndexMarker242"/>the key goal for operations. To that end, they will monitor the health of the environment by collecting metrics that can indicate the health of key components. This may include the <span class="No-Break">following metrics:</span></p>
			<ul>
				<li><span class="No-Break">CPU utilization</span></li>
				<li><span class="No-Break">Memory utilization</span></li>
				<li><span class="No-Break">Storage utilization</span></li>
				<li>The number <span class="No-Break">of processes</span></li>
				<li><span class="No-Break">Network statistics</span></li>
				<li><span class="No-Break">Application state</span></li>
			</ul>
			<p>Popular tools for monitoring include Prometheus for collecting metrics and Grafana for displaying the metrics on a dashboard. If the environment is on a public cloud, CloudWatch is <a id="_idIndexMarker243"/>available on AWS, and Azure Monitor is available on Azure. Cloud-based <strong class="bold">monitoring-as-a-service</strong> (<strong class="bold">MaaS</strong>) products can consolidate monitoring from multiple environments and sources. Such products include Datadog and <span class="No-Break">New Relic.</span></p>
			<h3>Log collection</h3>
			<p>Another <a id="_idIndexMarker244"/>aspect of monitoring comes from collecting log messages created by the system and applications. The messages may provide context for issues when problems arise in the environment. </p>
			<p>Logs from different systems, different system components, and different applications are collected into one source using log aggregation tools. These tools include a search capability to filter by an important keyword <span class="No-Break">when necessary.</span></p>
			<p>Log aggregation tools can be a software application that resides on-premises or in a private cloud, a feature available <a id="_idIndexMarker245"/>on public clouds, or a <strong class="bold">SaaS</strong> product. Popular log aggregation tools include the combination of Elasticsearch, Logstash, and Kibana (an ELK stack) for collection and analytics in on-premises/private cloud environments. Log collection is part of the AWS CloudWatch service. Splunk and Datadog are <a id="_idIndexMarker246"/>popular SaaS-based products that perform <span class="No-Break">log aggregation.</span></p>
			<h3>Alerting</h3>
			<p>When problems <a id="_idIndexMarker247"/>arise, it is important to notify the key people in a timely fashion. Alert tools can provide multiple channels for notification, including emails, SMS messages, and IM chat messages. They may also provide a tolerance mechanism to prevent too many alert messages to operations personnel and <em class="italic">alert fatigue</em> from occurring. These tools can also create issues for incident <a id="_idIndexMarker248"/>management so that <strong class="bold">IT service management</strong> (<strong class="bold">ITSM</strong>) processes <span class="No-Break">are followed.</span></p>
			<p>Leading alerting tools include PagerDuty and Opsgenie <span class="No-Break">by Atlassian.</span></p>
			<p>At this point, we’ve talked about the technology involved in creating the automation that is part of DevOps. Let’s focus our attention now on people, in terms of who can be responsible for installing and configuring such automation as the <span class="No-Break">CI/CD pipeline.</span></p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor081"/>DevOps topologies</h1>
			<p>With the growing<a id="_idIndexMarker249"/> list of tools and technologies available to Dev and Ops, it may be difficult to figure out where the responsibilities lie in moving toward a DevOps approach. Who is responsible for creating the CI/CD pipeline? What do we consider databases? How do we deploy <span class="No-Break">into production?</span></p>
			<p>In 2013, Matthew Skelton initially described three team <em class="italic">anti-types</em> to avoid and five possible team structures. Additional contributions have increased the number of anti-types to eight and the number of beneficial team structures to nine. The following list shows the anti-types and they are elaborated here <span class="No-Break">at </span><a href="https://web.devopstopologies.com"><span class="No-Break">https://web.devopstopologies.com</span></a><span class="No-Break">:</span></p>
			<ul>
				<li>Dev and <span class="No-Break">Ops Silos</span></li>
				<li>Permanent DevOps <span class="No-Break">Team Silo</span></li>
				<li>Dev Doesn’t <span class="No-Break">Need Ops</span></li>
				<li>DevOps as the Dev <span class="No-Break">Tools Team</span></li>
				<li><span class="No-Break">Rebranded Sysadmins</span></li>
				<li>Ops Embedded in <span class="No-Break">Dev Team</span></li>
				<li>Dev and <span class="No-Break">DBA Silos</span></li>
				<li><span class="No-Break">Fake SRE</span></li>
			</ul>
			<p>The 9 DevOps<a id="_idIndexMarker250"/> topologies from that site are <span class="No-Break">as follows.</span></p>
			<h3>Dev and Ops collaboration</h3>
			<p>This structure<a id="_idIndexMarker251"/> is considered the ideal DevOps approach, where Dev and Ops are working together and have smooth collaboration. Implementing this structure likely requires a large organizational culture change toward a <span class="No-Break">generative culture.</span></p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B18756_03_06.jpg" alt="Figure 3.6 – Dev and Ops collaboration (﻿diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.6 – Dev and Ops collaboration (diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>Fully shared Ops responsibilities</h3>
			<p>Some <a id="_idIndexMarker252"/>organizations with a single web-based product, such as Netflix or Facebook, may be able to take the Dev and Ops collaboration model shown previously and integrate Ops more fully. In this model, there is very little separation between Dev and Ops. Because of this, everyone is focused on <span class="No-Break">the mission.</span></p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/B18756_03_07.jpg" alt="Figure 3.7 – Fully shared Ops responsibilities (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.7 – Fully shared Ops responsibilities (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>Ops as infrastructure as a service</h3>
			<p>There may <a id="_idIndexMarker253"/>be some organizations that have a more traditional Ops department. Also, some organizations may deploy applications to public cloud environments such as AWS or Azure. In either case, a small subset of the Dev department may treat operations <em class="italic">as a service</em> and set up tooling for deployment, metrics, provisioning, and monitoring of those resources. In this model, there is no direct collaboration <span class="No-Break">with Operations.</span></p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B18756_03_08.jpg" alt="Figure 3.8 – Ops as infrastructure as a service (﻿diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.8 – Ops as infrastructure as a service (diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>DevOps as an external service</h3>
			<p>Some smaller<a id="_idIndexMarker254"/> teams and organizations may not have the manpower or experience to move toward a DevOps approach. In that case, they may contract an external vendor to create the test environments and automation and configure the monitoring. The DevOps vendors may also train Dev and Ops to move to a different model, such as Dev and <span class="No-Break">Ops collaboration.</span></p>
			<p class="IMG---Figure"><img src="image/B18756_03_09.png" alt="Figure 3.9 – DevOps as an external service (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.9 – DevOps as an external service (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>DevOps team (with expiration date)</h3>
			<p>There may <a id="_idIndexMarker255"/>be situations where having a dedicated DevOps team works. The idea is that the DevOps team can act as a <em class="italic">bridge</em> for both Dev and Ops teams. The DevOps team can instruct developers on working with infrastructure and can instruct operations personnel on Agile development. At some point, the DevOps team will disband, allowing Dev and Ops to collaborate in the Dev and Ops <span class="No-Break">collaboration model.</span></p>
			<p>The danger exists when the DevOps team does not disband, instead forming a separate silo. This is actually one of the identified anti-types (DevOps Team Silo) mentioned on the DevOps <span class="No-Break">topologies website.</span></p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B18756_03_10.jpg" alt="Figure 3.10 – DevOps team with expiration date (﻿diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.10 – DevOps team with expiration date (diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>DevOps advocacy team</h3>
			<p>A DevOps advocacy <a id="_idIndexMarker256"/>team acts as a facilitator between Dev and Ops if the two departments tend to drift apart. Unlike the DevOps team with an expiration date, this DevOps team is kept on an ongoing basis, ensuring both Dev and Ops follow current <span class="No-Break">DevOps practices.</span></p>
			<p>Like the DevOps team with an expiration date, a DevOps advocacy team runs the risk of turning into a DevOps <span class="No-Break">Team Silo.</span></p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B18756_03_11.jpg" alt="Figure 3.11 – DevOps advocacy team (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.11 – DevOps advocacy team (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>SRE team</h3>
			<p>As far back <a id="_idIndexMarker257"/>as 2004, Google has used its software engineers as operations<a id="_idIndexMarker258"/> personnel. These <strong class="bold">site reliability engineers</strong> (<strong class="bold">SREs</strong>) handle the support of production environments, mostly by developing software to keep the resources and services running. SREs accept the application from Dev, but only if Dev provides enough evidence in the form of logs and metrics that it meets a quality threshold. If the<a id="_idIndexMarker259"/> code<a id="_idIndexMarker260"/> does not meet this standard, SREs can reject <span class="No-Break">the deployment.</span></p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B18756_03_12.jpg" alt="Figure 3.12– SRE team (﻿diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.12– SRE team (diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>Container-driven collaboration</h3>
			<p>Because<a id="_idIndexMarker261"/> containers abstract many of the infrastructure details, most collaboration between Dev and Ops is not necessary. In this case, a container-based deployment may be accepted by Ops most of the time if there is a sound engineering culture. If not monitored closely, there is a risk of changing to an anti-type where Ops is expected to deploy anything from Dev <span class="No-Break">without question.</span></p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B18756_03_13.jpg" alt="Figure 3.13 – Container-driven collaboration (﻿diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.13 – Container-driven collaboration (diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<h3>Dev and DBA collaboration</h3>
			<p>If the <a id="_idIndexMarker262"/>applications an organization develops rely<a id="_idIndexMarker263"/> on one or more central databases, the collaboration between developers and the <strong class="bold">database administrators</strong> (<strong class="bold">DBAs</strong>) may be crucial. To enable that collaboration, the database developers in Dev work closely with the DBAs <span class="No-Break">in operations.</span></p>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B18756_03_14.jpg" alt="Figure 3.14 – Dev and DBA collaboration (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.14 – Dev and DBA collaboration (Diagram based on work at devopstopologies.com – licensed under CC BY-SA)</p>
			<p>Now that we have seen possible configurations for organizing the team responsible for the CI/CD pipeline, let’s take a close look at such a team on the ART: the <span class="No-Break">system team.</span></p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor082"/>The system team</h1>
			<p>The system<a id="_idIndexMarker264"/> team is the team on the ART that is responsible for the tooling and automation of the Continuous Delivery Pipeline. They work with the other teams on the ART to help in delivering valuable solutions. </p>
			<p>The system team may follow one of several DevOps topologies. The system team may be set up as a DevOps team with an expiration date. They will set up the Continuous Delivery Pipeline and instruct the Dev and Ops personnel on its use before disbanding. Another model for the system team may be being set up as a DevOps <span class="No-Break">advocacy team.</span></p>
			<p>As custodians of the automation and development process, they have deep responsibilities to the other teams on the ART. These responsibilities are described <span class="No-Break">as follows.</span></p>
			<h3>Building infrastructure for solution development</h3>
			<p>The system <a id="_idIndexMarker265"/>team will often be responsible for setting up the pre-build, continuous integration, and continuous deployment portions of the CI/CD pipeline and integrating the technology so it’s a seamless part of the Continuous Delivery Pipeline. They strive to apply automation as much as possible. This may also involve close collaboration with other teams, so they may visit other <span class="No-Break">teams’ events.</span></p>
			<h3>Spearheading solution integration</h3>
			<p>As part of <a id="_idIndexMarker266"/>maintaining the CI phase, the system team may be involved in determining the build process after a change has been committed to version control. They will maintain the proper build scripts and CI configuration files. If build automation is not yet available, they may be the team performing build and <span class="No-Break">integration activities.</span></p>
			<h3>Setting up end-to-end testing</h3>
			<p>To support the <a id="_idIndexMarker267"/>other teams, the system team may help the testers with the creation and optimization of automated tests. They may also work with the other teams to aggregate separate tests into well-defined test suites for different types of testing, such as smoke testing. </p>
			<h3>Assisting with demos</h3>
			<p>The ART integrates<a id="_idIndexMarker268"/> the work from all its teams and demonstrates the working state of the solution at a given point in time. This integration and demonstration is called the <em class="italic">system demo</em> and happens at a <span class="No-Break">regular cadence.</span></p>
			<p>As maintainers of the Continuous Delivery Pipeline, the system team is there to ensure that technical environments work for all teams so that the system demo <span class="No-Break">is seamless.</span></p>
			<h3>Facilitating the release</h3>
			<p>Because<a id="_idIndexMarker269"/> the system team has a holistic view of the process, they may be called upon to verify that deployments to production and final release <span class="No-Break">are valid.</span></p>
			<p>The system team can be considered the <em class="italic">DevOps</em> team for the ART. It may follow one of the DevOps topologies as a way of collaborating with the other Agile teams. Its responsibilities primarily involve configuring the automation, but it may assist the Agile teams in <a id="_idIndexMarker270"/>other ways as the entire ART endeavors to <span class="No-Break">deliver value.</span></p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor083"/>Summary</h1>
			<p>Automation plays a key role in DevOps. We looked at the important tools that make up a DevOps toolchain, especially those parts of the toolchain that are orchestrated from building and testing to deployment, creating the CI/CD pipeline or <span class="No-Break"><em class="italic">the pipeline</em></span><span class="No-Break">.</span></p>
			<p>CI typically includes activities that happen to code changes after they have been committed to version control. This may include preliminary testing, and upon passing, they may be built together and packaged into an artifact based on language <span class="No-Break">and technology.</span></p>
			<p>CD continues from where CI leaves off by taking the build artifacts and applying them to testing or production environments. Here, environments will be reconfigured, possibly with new resources. Additional testing will be performed to ensure security, correctness, and validation of <span class="No-Break">anticipated value.</span></p>
			<p>DevOps topologies outline possible models of collaboration between Dev and Ops teams with the possible inclusion of people specializing in DevOps. Some of the topologies are not long-lasting, lest they turn into <em class="italic">anti-types</em> that <span class="No-Break">stifle collaboration.</span></p>
			<p>In SAFe, the system team performs as the DevOps team on the ART. That team is responsible for constructing and maintaining the Continuous Delivery Pipeline for the other teams on <span class="No-Break">the ART.</span></p>
			<p>Automation does allow the ART or any DevOps team to deliver faster, but not if the development process is not optimized for Lean flow. In the next chapter, we will examine the practices from the Lean thinking movement that <span class="No-Break">enable flow.</span></p>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor084"/>Questions</h1>
			<p>Test your knowledge of the concepts in this chapter by answering <span class="No-Break">these questions.</span></p>
			<ol>
				<li>What tests are examples of static analysis (<span class="No-Break">pick two)?</span><ol><li><span class="No-Break">Unit tests</span></li><li><span class="No-Break">Linting</span></li><li><span class="No-Break">DAST</span></li><li><span class="No-Break">Dependency scanning</span></li><li><span class="No-Break">Acceptance tests</span></li></ol></li>
				<li>What allows code changes to be hidden in production until <span class="No-Break"><em class="italic">turned on</em></span><span class="No-Break">?</span><ol><li><span class="No-Break">Version control</span></li><li><span class="No-Break">Continuous integration</span></li><li><span class="No-Break">Feature flags</span></li><li><span class="No-Break">Continuous deployment</span></li></ol></li>
				<li>Monitoring includes activities such as performance monitoring, alerting, <span class="No-Break">and what?</span><ol><li><span class="No-Break">Load testing</span></li><li><span class="No-Break">Version control</span></li><li><span class="No-Break">Log collection</span></li><li><span class="No-Break">Unit testing</span></li></ol></li>
			</ol>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor085"/>Further reading</h1>
			<ul>
				<li>The original formulation of DevOps topologies, including three anti-types and five <span class="No-Break">types: </span><a href="https://blog.matthewskelton.net/2013/10/22/what-team-structure-is-right-for-devops-to-flourish/&#13;"><span class="No-Break">https://blog.matthewskelton.net/2013/10/22/what-team-structure-is-right-for-devops-to-flourish/</span></a></li>
				<li>The updated formulation of DevOps <span class="No-Break">topologies: </span><a href="https://web.devopstopologies.com&#13;"><span class="No-Break">https://web.devopstopologies.com</span></a></li>
				<li><em class="italic">Team Topologies: Organizing Business and Technology Teams for Fast Flow</em> by Matthew Skelton and Manuel Pais – the evolution of DevOps topologies to look at topologies for all kinds <span class="No-Break">of teams.</span></li>
			</ul>
		</div>
	</body></html>