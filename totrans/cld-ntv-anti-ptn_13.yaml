- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: How Do You Know It All Works?
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你怎么知道一切都能正常工作？
- en: Testing our code is how we ensure that our changes are both fit for purpose
    and that they don’t regress any existing functionality. In a cloud native environment,
    our complexity increasingly lives in areas beyond the scope of our code, so testing
    our application in a meaningful way can become complex. Let’s explore how we can
    test cloud native code in ways that are both time-efficient and meaningful while
    avoiding some common anti-patterns.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 测试我们的代码是确保我们的更改既符合预期功能，又不会回归已有功能的方式。在云原生环境中，我们的复杂性越来越多地存在于超出我们代码范围的区域，因此以有意义的方式测试我们的应用程序变得复杂。让我们探讨如何以既高效又有意义的方式测试云原生代码，同时避免一些常见的反模式。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要内容：
- en: General testing anti-patterns
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的测试反模式
- en: Lack of contract testing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏契约测试
- en: Manual testing
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动测试
- en: Trying to recreate the cloud
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 试图重现云环境
- en: Poorly structured code
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构不良的代码
- en: General testing anti-patterns
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的测试反模式
- en: Before we explore the types of tests commonly used in cloud native applications,
    we must first explore some general testing anti-patterns that we must avoid. These
    anti-patterns typically result from the evolution of the application’s testing
    strategy as it is migrated to the cloud. While most of these anti-patterns apply
    to unit tests, it’s essential to be mindful of them when testing other patterns
    as well.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨云原生应用程序中常用的测试类型之前，我们首先需要了解一些我们必须避免的常见测试反模式。这些反模式通常是由于应用程序的测试策略在迁移到云端时演变而来。虽然大多数这些反模式适用于单元测试，但在测试其他模式时，也需要注意它们。
- en: 'First, we will look at some testing anti-patterns and how they surface in a
    cloud native environment. The specific anti-patterns we will explore are the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将看看一些测试反模式，以及它们如何在云原生环境中显现。我们将探讨的具体反模式如下：
- en: Tests that have never failed
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从未失败的测试
- en: Coverage badge tests
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 覆盖率徽章测试
- en: Testing implementation details
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试实现细节
- en: Tests that intermittently fail
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 间歇性失败的测试
- en: Tests with side effects or coupled tests
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有副作用的测试或耦合测试
- en: Multi-stage tests
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多阶段测试
- en: Tests that have never failed
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从未失败的测试
- en: When we think about testing, we might think that a test that has never failed
    is good. That means our code and changes have always complied with our expected
    behavior, right? Without the test failing, how can we be sure that the test fails
    when its contract is breached?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑测试时，可能会认为从未失败的测试是好的。这意味着我们的代码和更改一直符合我们的预期行为，对吧？如果没有失败的测试，我们怎么能确保当合同被违反时，测试会失败呢？
- en: To illustrate this situation, I will use my experience with some of our teams
    in a previous role. The teams had just finished writing their functionality and
    were in the process of writing tests. They were working with an asynchronous code
    base in Node.js, and a quirk of asynchronous programming in Node.js is that when
    an asynchronous function is called and it contains asynchronous code, without
    a top-level await on the function call in the test, the test will exit before
    the asynchronous code executes. This means any assertions in the asynchronous
    code would only throw errors after the test, and because no assertions were thrown
    during test execution, the test passes. From an untrained perspective, the test
    appears to test the functionality expected. However, in practice, the test is
    useless. Unsurprisingly, many tests started failing when we sprinkled in some
    `async` and `await` syntactic sugar.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这种情况，我将用我在之前角色中与一些团队的经验。那些团队刚刚完成了功能的编写，并且正在编写测试。他们在一个基于 Node.js 的异步代码库中工作，而
    Node.js 中异步编程的一个特点是，当调用一个异步函数并且其中包含异步代码时，如果在测试中的函数调用上没有顶层的 `await`，测试将在异步代码执行之前退出。这意味着异步代码中的任何断言都只会在测试后抛出错误，因为在测试执行过程中没有抛出断言，所以测试通过。从一个未经训练的角度看，测试似乎验证了预期的功能。然而，实际上，测试是无效的。毫不奇怪，当我们加入了一些
    `async` 和 `await` 的语法糖后，许多测试开始失败。
- en: In this example, a lack of understanding of asynchronous programming principles
    contributed to functionally useless tests that gave the impression everything
    was okay.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，缺乏对异步编程原则的理解导致了功能上无用的测试，这些测试给人一种一切正常的假象。
- en: 'This anti-pattern is an easy trap to fall into in cloud computing. As systems
    become asynchronous, decoupled, and eventually consistent, our testing strategy
    must match the system’s complexity. You will notice that the entire situation
    could have been avoided had the team followed **test-driven development** (**TDD**).
    The common TDD approach I like to utilize is *Red*, *Green*, and *Refactor*:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种反模式在云计算中很容易陷入。随着系统变得异步、解耦并最终一致，我们的测试策略必须与系统的复杂性相匹配。你会注意到，如果团队遵循了**测试驱动开发**（**TDD**），整个情况是可以避免的。我喜欢使用的常见
    TDD 方法是*红色*、*绿色*和*重构*：
- en: '**Red**: First, create the minimum structure required to support your test.
    This might be an empty function block, method, or object. Second, write a test
    (or tests) that you believe tests your expected behavior. When you run your tests,
    they should fail, showing red.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**红色**：首先，创建支持你测试所需的最小结构。这可能是一个空的函数块、方法或对象。其次，编写你认为能够测试期望行为的测试（或多个测试）。当你运行测试时，它们应该失败，显示为红色。'
- en: '**Green**: Fill out your empty placeholder with the logic to make your test
    pass, showing green.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**绿色**：用逻辑填充你的空占位符，使你的测试通过，显示为绿色。'
- en: '**Refactor**: Create new tests and functionality to handle edge cases. In these
    scenarios, it is best to create positive and negative test cases and purposefully
    break the test a few times to ensure it behaves as expected.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重构**：创建新的测试和功能来处理边缘情况。在这些情况下，最好创建正面和负面测试用例，并故意打破测试几次，以确保它按预期行为。'
- en: In the cloud native world, typically, these tests would form part of our automated
    integration pipeline, such as in AWS CodePipeline, GCP Cloud Build, or Azure DevOps
    Pipelines.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在云原生世界中，这些测试通常是我们自动化集成管道的一部分，例如 AWS CodePipeline、GCP Cloud Build 或 Azure DevOps
    Pipelines。
- en: Coverage badge tests
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖率徽章测试
- en: Another anti-pattern that often comes up is `200` status code might give you
    good test coverage, but is it a good test? What about the semantic structure of
    the data? Does the output match the expected input? The behavior of the endpoint
    is completely untested in this scenario. We haven’t guaranteed that any future
    changes won’t result in unexpected behaviors, just that they will return a status
    code of `200`.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的反模式是，`200` 状态码可能给你带来很好的测试覆盖率，但这算是一个好的测试吗？数据的语义结构呢？输出是否与预期输入匹配？在这种情况下，端点的行为完全没有经过测试。我们没有确保任何未来的更改不会导致意外的行为，只保证它们会返回
    `200` 状态码。
- en: Incentivizing code coverage in isolation will not give you greater certainty
    of the emergent behaviors of your application. Instead, you must incentivize writing
    proper tests that have been peer-reviewed to describe the expected behavior of
    the system. A simple litmus test for good testing practice is whether the test
    ensures that the emergent behavior of the system more closely aligns with the
    behavior in our mental model of the system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 激励孤立的代码覆盖率并不会增加你对应用程序突现行为的确定性。相反，你必须激励编写经过同行评审的适当测试，以描述系统的预期行为。一个简单的测试标准是，测试是否确保系统的突现行为与我们对系统的心理模型更为一致。
- en: Testing implementation details
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试实现细节
- en: 'Requiring developers to hit a code coverage threshold set too high can also
    lead to another anti-pattern: testing implementation details. This anti-pattern
    can be particularly insidious in the cloud native domain as we are more concerned
    with the result and emergent system behaviors than the method used to achieve
    them, as implementation details can be very fluid as we leverage new architectural
    and technological patterns. For example, if we need to sort an array, we might
    first check that the input is an array of numbers, then call a bubble sort function
    if it is. Let’s say we write two tests here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要求开发人员达到过高的代码覆盖率阈值，也可能导致另一个反模式：测试实现细节。在云原生领域，这种反模式尤其隐蔽，因为我们更关注结果和系统的突现行为，而不是实现这些行为的方法。随着我们利用新的架构和技术模式，实施细节可能非常流动。例如，如果我们需要对一个数组进行排序，我们可能首先检查输入是否为数字数组，如果是，则调用冒泡排序函数。假设我们在这里编写了两个测试：
- en: Check that the bubble sort function is not called when the array is not an array
    of numbers and the result is an error
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查当数组不是数字数组时，冒泡排序函数不会被调用，并且结果是一个错误
- en: Check that the bubble sort function is called when the array is an array of
    numbers and the result is a sorted array
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查当数组是数字数组时，冒泡排序函数会被调用，并且结果是一个排序后的数组
- en: 'Later, someone removes the initial check to see whether the array is an array
    of numbers and replaces the bubble sort with a merge sort function that already
    has built-in type checking. This is what happens to our test:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，有人移除了最初的检查，来判断数组是否为数字数组，并将冒泡排序替换为已经内建类型检查的归并排序函数。我们的测试发生了如下变化：
- en: Our first test passes, even though we now call the sort function on every execution
    because our merge sort function differs from our bubble sort function
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的第一个测试通过了，尽管我们现在在每次执行时都会调用排序函数，因为我们的归并排序函数与冒泡排序函数不同
- en: Our second test fails because we did not call the bubble sort function
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的第二个测试失败了，因为我们没有调用冒泡排序函数
- en: 'In this case, we have not changed the emergent behavior of the system; we have
    only changed the implementation details. Instead, we could design our test to
    look like this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们并没有改变系统的突现行为；我们只是更改了实现细节。相反，我们可以将测试设计成如下方式：
- en: Check that we get an error on anything other than an array of numbers
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查我们是否会在除数字数组以外的任何情况中出现错误
- en: Check that we correctly sort an array of numbers
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查我们是否正确地对数字数组进行排序
- en: These tests check solely the exhibited behavior, not how we achieved it. Under
    this new testing framework, both tests will pass when we perform our refactor.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试仅检查所展示的行为，而不是我们是如何实现的。在这个新的测试框架下，当我们进行重构时，两个测试都会通过。
- en: Intermittently failing tests
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 间歇性失败的测试
- en: I have often asked clients about a failing test pipeline only to be told, “*Yeah,
    it does that sometimes. Just rerun it.*” Intermittently failing tests breed ambiguity.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我常常询问客户有关失败的测试管道，结果常常得到这样的回答：“*是的，它有时会这样。只要重新运行就行了。*” 间歇性失败的测试会引发模糊性。
- en: When a test pipeline fails, our first instinct is to rerun it. This ambiguity
    means that our mean time to identify failures in our pipeline goes through the
    roof, as we don’t know whether the culprit is a failing test or whether the pipeline
    is just acting up. It is essential to be not only confident in the success of
    your passing tests but also in your failing tests.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当测试管道失败时，我们的第一反应是重新运行它。这种模糊性意味着，我们识别管道失败的平均时间急剧增加，因为我们不知道问题是出在一个失败的测试，还是管道本身出了问题。我们不仅要对通过的测试充满信心，对失败的测试同样也要有信心。
- en: Let us imagine a hypothetical intermittently failing series of tests. These
    tests would block production deployments, PR reviews, and local testing. It always
    seems to sort itself by the next run, it only happens a few times a year, and
    it’s an infrequently updated micro-frontend, so why bother fixing it?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设有一系列间歇性失败的测试。这些测试将阻碍生产部署、PR审查和本地测试。它总是通过下次运行自行修复，每年只发生几次，且它是一个更新不频繁的微前端，那么为什么还要费力去修复呢？
- en: 'After triaging the issue, we found the culprit pretty quickly: someone asserted
    in a test that the current UTC minute of the hour was less than 59 instead of
    less than or equal to. This change, in line with probability, was pushed and merged
    successfully. The expectation was buried deep in a block that prevented a precursory
    glance from diagnosing the problem from the test output. This also creates a compelling
    argument for verbose and well-formatted test outputs. As you can imagine, someone’s
    pipeline failed after working locally; they decided to rerun it, and it passed.
    It became known that that particular pipeline was flaky and we could fix it with
    a rerun. What effect do you think that has on developers?'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在对问题进行初步诊断后，我们很快找到了罪魁祸首：有人在测试中断言当前的UTC分钟数小于59，而不是小于或等于59。这个符合概率的更改已经被成功推送并合并。这个期望深藏在一个代码块中，阻止了初步检查从测试输出中诊断出问题。这也为冗长且格式良好的测试输出提供了有力的论据。正如你可以想象的那样，有人在本地运行正常的情况下，某个管道失败了；他们决定重新运行，结果通过了。大家知道这个特定的管道是易出问题的，我们可以通过重新运行来修复它。你觉得这对开发人员有什么影响？
- en: When I ran into this situation in my work, we found that the number of failed
    reruns significantly outpaced the actual number of *flaky* runs due to a lack
    of confidence in the failures of the underlying pipeline. Cloud native delivery
    allows us to push incremental changes to our code base rapidly. This process means
    that a high-performing team will run these pipelines multiple times daily.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在工作中遇到这种情况时，我们发现，由于对基础管道失败的信心不足，失败的重新运行次数大大超过了*不稳定*的实际运行次数。云原生交付使我们能够快速推送代码库的增量更改。这一过程意味着，高效的团队每天会多次运行这些管道。
- en: Therefore, in a cloud native environment, having faith in your pipelines, both
    in success and failure, is imperative. Another common way that tests become flaky
    is by relying on test side effects or coupled tests.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在云原生环境中，对你的管道保持信任，无论成功或失败，都是至关重要的。测试变得不稳定的另一种常见方式是依赖于测试副作用或耦合测试。
- en: Tests with side effects or coupled tests
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 具有副作用或耦合的测试
- en: Relying on side effects or coupling tests is an easy trap, especially as we
    refactor code and add existing tests, as other tests may already cause side effects
    that our new tests may unknowingly come to depend on.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖副作用或耦合测试是一个容易陷入的陷阱，特别是在我们重构代码并添加现有测试时，因为其他测试可能已经引起副作用，而我们的新测试可能会不知不觉地依赖于这些副作用。
- en: 'For illustrative purposes, let us consider tests that ensure user behavior.
    We have two endpoints: one to create users and one to delete users. We have one
    test that generates a random email, creates a user with that email, and saves
    it as a global variable in the test file. Then, another test reads the global
    variable and deletes the user, checking whether the user is deleted correctly.
    We have broken both rules here. Not only do we have a side effect by modifying
    the global state but we have also coupled two tests through that side effect.
    It’s essential to understand what we have lost here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明，让我们考虑确保用户行为的测试。我们有两个端点：一个用于创建用户，另一个用于删除用户。我们有一个测试，它生成一个随机的电子邮件，使用该电子邮件创建一个用户，并将其作为全局变量保存在测试文件中。然后，另一个测试读取该全局变量并删除该用户，检查用户是否正确删除。我们在这里违反了两个规则。我们不仅通过修改全局状态产生了副作用，而且还通过这个副作用耦合了两个测试。理解我们在这里失去了什么是至关重要的：
- en: '**Isolated testing**: Because of the coupling, if we want to run only the *user
    delete* test, it will always fail because it needs to be run in concert with the
    *user create* test. We can now only run the entire test file.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隔离测试**：由于耦合问题，如果我们只想运行*用户删除*测试，它总是会失败，因为它需要与*用户创建*测试一起运行。现在我们只能运行整个测试文件。'
- en: '**Ability to refactor**: If we move the tests to different files or change
    their execution order, they will fail. This makes refactoring harder, as we now
    need to understand its coupled tests to refactor the test for the functionality
    we are interested in.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重构能力**：如果我们将测试移动到不同的文件或改变其执行顺序，它们将失败。这使得重构变得更加困难，因为我们现在需要理解它的耦合测试，以便重构我们感兴趣的功能的测试。'
- en: '**Parallel execution**: As our test base grows, it becomes apparent that we
    need to optimize our pipeline execution. The first tool people will usually reach
    for is parallel execution. When we couple tests, parallel execution can cause
    you to lose the deterministic execution of your test suite. This lack of determinism
    means that your tests may intermittently fail, contributing to “flaky” pipelines
    as the tests may or may not execute in the correct order.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行执行**：随着我们的测试基础逐渐增长，优化管道执行变得愈加明显。人们通常首先会选择并行执行工具。当我们耦合测试时，并行执行可能导致失去测试套件的确定性执行。这种缺乏确定性意味着测试可能会间歇性地失败，从而导致管道变得“不稳定”，因为测试可能会或可能不会按照正确的顺序执行。'
- en: How can we remove the coupling and side effects from our example? A simple indicator
    for a single test is to run our test in isolation and check that it still passes.
    This check ensures that our test has no upstream coupling; it does not test for
    side effects or downstream coupling.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何去除示例中的耦合和副作用？对于单个测试，一个简单的指示器是将测试单独运行，并检查它是否仍然通过。这个检查确保我们的测试没有上游耦合；它不会测试副作用或下游耦合。
- en: The next step is to refactor our test files. Ideally, there should be no global
    variables. This concept can be controversial as many test implementations will
    have static data in global variables. Still, strictly controlled generated data
    will always beat static data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是重构我们的测试文件。理想情况下，应该没有全局变量。这个概念可能会引起争议，因为许多测试实现会在全局变量中有静态数据。然而，严格控制的生成数据总是比静态数据更好。
- en: 'The driving force behind this is simple: having generated data means that you
    are testing the bounds of your system to a greater extent. It can contribute to
    intermittently failing test pipelines, but if you hit an intermittent failure,
    take it as a blessing, not a curse. Hitting an intermittent failure means the
    data you generated to match your expected production data does not behave as expected!
    If you had used static data, you would never have found this edge case before
    production.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其背后的驱动因素很简单：生成数据意味着你在更大程度上测试了系统的边界。这可能会导致测试管道间歇性地失败，但如果你遇到间歇性失败，请将其视为一种祝福，而非诅咒。出现间歇性失败意味着你生成的数据与预期的生产数据不符！如果你使用静态数据，就永远无法在生产环境之前发现这个边缘案例。
- en: The other issue with static data is that teams tend to get lazy. The usual culprit
    is UUIDs. I’ve seen production systems go down because someone had used the same
    UUID to index two different values and then created a correlation in code where
    no correlation existed in the production data. The cause was that rather than
    generate a new UUID, a developer saw a UUID generated for a different entity and
    decided to copy the already compliant UUID to save about 20 seconds of development
    effort. As you can imagine, saving those 20 seconds was massively outweighed by
    the impacts of the eventual downtime.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用静态数据的另一个问题是团队往往会变得懒惰。常见的罪魁祸首是UUID。我见过生产系统崩溃的案例，原因是有人用了相同的UUID去索引两个不同的值，并在代码中创建了一个在生产数据中并不存在的关联。问题在于，开发者并没有生成一个新的UUID，而是看到另一个实体的UUID已经生成，决定复制这个已经合规的UUID，从而节省了大约20秒的开发时间。正如你所想，节省这20秒的时间远不及最终停机带来的影响。
- en: Most testing libraries have pre-test and post-test hooks to set up your data
    and application components. A level of granularity is also usually provided. You
    can run before and after *all* tests or before and after *each* test. The deciding
    factor on when to use them is based on the application component.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数测试库都提供了预测试和后测试的钩子，用于设置数据和应用组件。通常也会提供一定的粒度，你可以在*所有*测试之前和之后运行，或者在*每个*测试之前和之后运行。决定何时使用它们的因素通常取决于应用组件。
- en: If the component has an internal state modified by tests, then that component
    should be created and disposed of before and after each test. Examples include
    local caches and persistence layers. If the component does not have an internal
    state, it is probably safe to optimize by setting it up once for all tests and
    tearing it down when all tests have finished.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果组件有一个由测试修改的内部状态，那么该组件应在每个测试之前和之后创建和销毁。例如，局部缓存和持久化层。如果组件没有内部状态，通常可以通过为所有测试设置一次并在所有测试完成后销毁来进行优化。
- en: 'Examples might include authentication layers (unless you’re storing sessions
    in this layer!), request routing layers, or utility components. When we look at
    avoiding side effects and ordering in tests, we might think of putting our entire
    flow in a single test. Then, we’re not breaking the boundaries between our tests!
    However, this leads us to our next non-functional antipattern: multistage tests.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 示例可能包括认证层（除非你在该层存储会话！）、请求路由层或实用组件。当我们考虑避免副作用和测试顺序时，我们可能会想到将整个流程放入一个单一的测试中。这样，我们就没有打破测试之间的边界！然而，这会引出下一个非功能性反模式：多阶段测试。
- en: Multistage tests
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多阶段测试
- en: '**Multistage tests** often come about because we see actions as being related.
    However, we need to keep in mind that the purpose of testing is usually to test
    a unit of behavior, even in integration tests, albeit with a broader definition
    of our unit of behavior. To understand why this is an anti-pattern, we need to
    look at our failure modes. When we have many atomic tests, we can easily see which
    functionality is broken. With a smaller number of multistage tests, we might cover
    the same amount of behavior, but we lose fidelity in our reporting.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**多阶段测试**往往是因为我们将动作视为相关的。然而，我们需要记住，测试的目的是通常是测试一个行为单元，即使在集成测试中，我们也有一个更广泛的行为单元定义。为了理解为什么这是一个反模式，我们需要看看我们的失败模式。当我们有许多原子测试时，我们可以轻松看到哪个功能被破坏了。通过更少的多阶段测试，我们可能覆盖了相同的行为，但我们失去了报告的精确性。'
- en: 'Early errors in a multistage test can also cause the test to fail early, masking
    errors from later in the multistage test. It might be a logical fallacy, but if
    we replaced all our tests with one large multistage test, we would have either
    a pass or fail for the entire system, which makes the search area on failure very
    broad. At the other extreme, where we make our tests as atomic as possible, we
    get extremely high fidelity and know precisely which units of behavior are broken.
    A pattern to follow in this area is to use **arrange, act, and** **assert** (**AAA**):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 多阶段测试中的早期错误也可能导致测试提前失败，从而掩盖后期多阶段测试中的错误。这可能是一个逻辑谬误，但如果我们用一个大型的多阶段测试替代所有的测试，我们就只能得到整个系统的通过或失败，这样一旦失败，问题的范围就非常广泛。在另一个极端情况下，如果我们将测试做到尽可能原子化，就能获得极高的精度，准确知道哪个行为单元出现了问题。这个领域中的一个模式是使用**安排、操作和**
    **断言**（**AAA**）：
- en: '**Arrange**: Set up everything required for the test to run (data, authentication,
    application instances, etc.).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安排**：设置测试运行所需的所有内容（数据、认证、应用实例等）。'
- en: '**Act**: Perform the behavior under test. This action might be calling an endpoint
    or method, or performing an integration flow.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作**：执行待测试的行为。这一操作可能是调用某个端点或方法，或者执行集成流程。'
- en: '**Assert**: Check that the results of your behavior match what you expect.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**断言**：检查行为的结果是否符合预期。'
- en: 'The key here is that this pattern should only occur in order once in a test.
    For example, a test that does not follow this pattern might go like this: arrange,
    act, assert, act, assert, act, assert. Failures in higher asserts mask all actions
    after the first assert. Therefore, our tests should have the correct level of
    atomicity to provide as much detail as possible.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于，这个模式在一个测试中应该只出现一次。例如，未遵循这个模式的测试可能是这样：安排、操作、断言、操作、断言、操作、断言。后续断言的失败会掩盖第一次断言之后的所有操作。因此，我们的测试应该具有正确的原子性，以提供尽可能多的细节。
- en: 'So far, we have mainly focussed on unit testing, but we should not unit test
    to the exclusion of all else. Next, we will look at another critical type of testing
    to ensure semantic correctness: contract testing.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们主要关注了单元测试，但我们不应当仅仅进行单元测试，忽略其他所有测试。接下来，我们将讨论另一个关键的测试类型，来确保语义正确性：契约测试。
- en: Lack of contract testing
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺少契约测试
- en: In a cloud native environment, we often have loose coupling between components,
    with functionality exposed through a combination of APIs and events while consumed
    by other microservices, user interfaces, third parties, and every combination
    and permutation. When developing system components, worrying about the immediate
    application is no longer enough. Instead, we need to provide confidence about
    the communications between our services. This is where contract testing comes
    into play.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在云原生环境中，我们通常会看到组件之间的松耦合，功能通过API和事件的组合进行暴露，并由其他微服务、用户界面、第三方及各种组合和排列来消费。在开发系统组件时，单单关注应用程序的即时需求已经不够了。我们需要为服务之间的通信提供信心。这就是契约测试发挥作用的地方。
- en: Contract testing
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 契约测试
- en: At the core of **contract testing** is the concept of a contract. A **contract**
    is a specification that explains precisely how data will be shared between services
    and its format, and it may even make some assurances around non-functional requirements.
    This contract may exist as an OpenAPI specification, JSON Schema, Protobuf definition,
    Smithy interface, or similarly in any **interface definition** **language** (**IDL**).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**契约测试**的核心概念是契约。**契约**是一种规范，明确解释数据如何在服务之间共享及其格式，甚至可能对非功能性需求做出一些保证。这个契约可以以OpenAPI规范、JSON
    Schema、Protobuf定义、Smithy接口或任何类似的**接口定义语言**（**IDL**）的形式存在。'
- en: The other piece of the data contract puzzle is that it should also give the
    semantic meaning of the data being transferred. The key is providing consumers
    with a clear definition of what to expect. Now that we have a contract, we can
    examine our application’s output and ensure it agrees with our published schema.
    In other words, we test our application against the contract.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 数据契约的另一部分是它应该传达被传输数据的语义含义。关键在于为消费者提供清晰的定义，告诉他们预期会得到什么。现在我们已经有了契约，可以检查应用程序的输出，并确保它与已发布的架构一致。换句话说，我们是根据契约来测试我们的应用程序。
- en: We can now decouple the development of different parts of our application. By
    defining our communication patterns in advance and defining tests that allow us
    to check our compliance with that pattern, we can build multiple parts of the
    application if we agree on the contracts we align to. As teams grow and functionality
    development grows beyond the scope of one developer, these types of tests become
    increasingly important. If one developer is working on a vertical slice of application
    functionality, they might iteratively design the communication patterns between
    the application components as they progress. This allows for agile development;
    however, it falls over when that developer needs to collaborate on that functionality
    with other parties. The iterative changes they are keeping in their head suddenly
    become impediments to the system’s progress as a whole, as these frequent changes
    need to be communicated.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以解耦应用程序的不同部分开发。通过提前定义我们的通信模式，并定义测试来检查我们是否遵守该模式，我们可以在达成合同一致的前提下，构建应用程序的多个部分。随着团队的扩展以及功能开发超出单个开发者的范围，这类测试变得越来越重要。如果一个开发者在处理应用功能的垂直切片时，可能会根据进度逐步设计组件间的通信模式。这允许敏捷开发；然而，当该开发者需要与其他方协作时，问题就出现了。他们在头脑中保持的迭代变化，突然成为系统整体进展的障碍，因为这些频繁的变化需要进行沟通。
- en: While it may sound slightly waterfall-like to define your communication patterns
    up front, it’s important to note that the level of upfront planning is minimal.
    We’re operating at atomic units of functionality here, one or two API endpoints
    at a time, not a monolithic definition of a system. Putting in the time up front
    to build a shared understanding of the communication model will pay dividends
    in the future, as rather than iterative, rapid changes to data exchange models,
    we are now only making changes to the model as functionally required by and agreed
    upon by both parties.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提前定义通信模式可能听起来有些像瀑布式开发，但需要注意的是，前期规划的程度是最小的。我们在这里操作的是功能的最小单元，一次处理一两个 API 端点，而不是系统的整体定义。提前投入时间建立共享的通信模型理解，将在未来带来回报，因为与其进行数据交换模型的迭代性快速变更，我们现在只会根据双方的功能需求和协议对模型进行必要的修改。
- en: Beyond the initial contract
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超越初步合同
- en: As we build out these contracts for data exchange methods, we can start publishing
    these artifacts for other parties to consume. By ensuring that we remain faithful
    to our data contracts through contract testing, we ensure that our current and
    future consumers can enjoy the continued operation of their dependencies. New
    users can easily onboard as consumers of the system as it is documented.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们为数据交换方法构建这些合同时，我们可以开始发布这些文档供其他方使用。通过合同测试确保我们始终遵循数据合同，我们确保当前和未来的消费者可以继续享受其依赖项的稳定运行。新用户可以轻松地作为系统的消费者加入，因为系统已经有了文档说明。
- en: The question then becomes, what happens when we need to change a contract? This
    is where two other anti-patterns present themselves. The first anti-pattern is
    not maintaining a service dependency map. A service dependency map tells us exactly
    which services consume functionality from the service we have built to the contract
    specification.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 那么问题来了，当我们需要更改合同时，会发生什么？这时，另外两种反模式就会出现。第一个反模式是没有维护服务依赖图。服务依赖图准确地告诉我们哪些服务从我们构建的服务中消费功能，并遵循合同规范。
- en: This allows us to assess the blast radius of the service we are making a contract
    change to and ensure that any changes we make to the contract are compatible with
    other services that consume it. Many cloud service providers will have distributed
    traceability of transactions through inbuilt observability tooling, or we may
    be able to build one through any of the third-party tools that offer a similar
    service. Without a service dependency map, we don’t have any visibility into the
    blast radius of changes we plan on making. Let’s look at an example of a simple
    service diagram.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够评估我们正在对其进行合同更改的服务的影响范围，并确保我们对合同所做的任何更改与其他使用该服务的服务兼容。许多云服务提供商通过内置的可观察工具提供分布式事务追踪，或者我们可以通过任何提供类似服务的第三方工具来构建一个。如果没有服务依赖图，我们就无法了解我们计划做出的更改的影响范围。让我们来看一个简单的服务图示例。
- en: '![](img/B22364_13_1.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22364_13_1.jpg)'
- en: Figure 13.1 - A simple example of a user service, exposed through an API gateway,
    called by two upstream services
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1 - 一个简单的用户服务示例，通过 API 网关暴露，并被两个上游服务调用
- en: In this example, we have a user endpoint called by both the messaging service
    and the backend for frontend services.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们有一个用户端点，同时被消息服务和前端后端服务调用。
- en: From the preceding example, we can see that a change to the contract of `/user`
    on the user service will impact two upstream services that may also have to be
    updated to ensure continuity of service. When we define the new contract, we can
    use it to test the upstream services and, if they all pass, safely make the change.
    How can we make contracts that don’t break upstream services when we change them?
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的例子中，我们可以看到，用户服务的`/user`契约的更改将影响到两个上游服务，它们可能也需要更新，以确保服务的连续性。当我们定义新的契约时，可以用它来测试上游服务，如果它们都通过了，就可以安全地进行更改。那么，当我们更改契约时，如何避免破坏上游服务呢？
- en: This brings us to our second anti-pattern, which directly manipulates the existing
    data contract. We can extend the data contract to include new functionality instead
    of modifying the semantic meaning of existing fields or functionality. Consider
    an object used by the preceding messaging service that returns a `name` field
    from the `/user` endpoint. Our data contract specifies that this field is the
    first name of the person, for example, `Alice`. The messaging service might also
    want to provide a salutation, for example, `Ms. Alice`. With no changes to the
    messaging service, we could change the semantic meaning of the `/user` endpoint
    data contract so that *name* now means *salutation plus name*. However, this might
    have unexpected effects on other consumers of the service. Let’s say the **backend
    for frontend** (**BFF**) service gets information about multiple users and sorts
    their names alphabetically. Now, we sort by salutation instead of name. We have
    unintentionally modified behavior by changing the semantic meaning.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了我们的第二个反模式，它直接操作现有的数据契约。我们可以扩展数据契约来包括新的功能，而不是修改现有字段或功能的语义含义。考虑一个由前述消息服务使用的对象，该对象从`/user`端点返回一个`name`字段。我们的数据契约规定该字段表示人的名字，例如`Alice`。消息服务可能还想提供一个称呼，例如`Ms.
    Alice`。在不修改消息服务的情况下，我们可以改变`/user`端点数据契约的语义，使得*name*现在表示*称呼加名字*。然而，这可能会对服务的其他消费者产生意想不到的影响。假设**前端后端**（**BFF**）服务获取多个用户的信息并按字母顺序排序他们的名字。现在，我们按称呼排序，而不是按名字排序。通过改变语义含义，我们无意中修改了行为。
- en: 'This contrived example may seem easy to avoid; however, even simple changes
    to data contracts can have unintended consequences. There are two options here:
    either we change the data contract and deal with the fallout (usually hard to
    predict, discover, and rectify), or we extend our data contract. When we extend
    our data contract, we rely on services not involved in the change to ignore the
    extensions. For example, rather than changing the semantic meaning of the `name`
    field, we add a new field called `salutation`. The messaging service can consume
    this field to provide the required functionality, and the BFF service can continue
    using the `name` field as expected, ignoring the `salutation` field.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个牵强的例子看起来似乎很容易避免；然而，即使是对数据契约的小变动，也可能会带来意想不到的后果。这里有两种选择：要么我们修改数据契约并处理后果（通常很难预测、发现和修复），要么我们扩展数据契约。当我们扩展数据契约时，我们依赖那些未参与变更的服务忽略这些扩展。例如，我们可以不改变`name`字段的语义含义，而是新增一个叫做`salutation`的字段。消息服务可以使用这个字段来提供所需的功能，而BFF服务则可以继续使用`name`字段，忽略`salutation`字段。
- en: If we really must change the underlying semantics of the data contract, then
    we can still follow our principle of not modifying the behavior expected by other
    systems. This may seem counter-intuitive. However, by utilizing API versioning,
    we can fundamentally change the structure and semantics of our data contract by
    adding a v2 of our API. This preserves the data contract between our old systems
    while allowing us to make considerable changes to support new functionality. We
    can retroactively update the dependent services by aligning them with the new
    data contract by utilizing contract testing. Eventually deprecating the original
    endpoint without any material impact, we have essentially decoupled the modification
    of data contracts from the adoption of the new data contracts, which, in turn,
    changes a highly synchronous deployment exercise and likely downtime into an asynchronous
    process that can be undertaken as the business needs arise.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们真的必须改变数据契约的底层语义，我们仍然可以遵循不修改其他系统期望行为的原则。这可能看起来不符合直觉。然而，通过利用API版本控制，我们可以通过增加API的v2版本，根本性地改变数据契约的结构和语义。这保留了我们旧系统之间的数据契约，同时允许我们做出显著更改以支持新功能。我们可以通过契约测试使依赖服务与新数据契约对齐，从而追溯更新它们。最终，我们可以在没有实质性影响的情况下废弃原始端点，这样我们就基本上将数据契约的修改与新数据契约的采用解耦，从而将一个高度同步的部署过程和可能的停机时间，转变为一个可以根据业务需求异步进行的过程。
- en: Contract enforcement
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 契约执行
- en: It’s all good to define the data contract we use between services, but the next
    stage is contract enforcement. It is not enough to define the contracts that our
    services communicate in. Ideally, at both ends, we should check that the data
    we transfer aligns with our understanding of the contract. An important aspect
    here is to validate what we know and discard what we don’t; this leaves us the
    option of contract expansion, as we discussed earlier. Contract validation at
    runtime can save us from unexpected data behaviors and alert us to mismatches
    between contracts.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 定义我们在服务之间使用的数据契约是好的，但下一步是契约执行。仅仅定义我们服务之间传递的契约是不够的。理想情况下，在两个端点，我们应该检查我们传输的数据是否与我们对契约的理解一致。这里的一个重要方面是验证我们知道的内容并丢弃我们不知道的内容；这给我们提供了扩展契约的选项，正如我们之前讨论的那样。运行时的契约验证可以帮助我们避免意外的数据行为，并提醒我们契约之间的匹配问题。
- en: A good practice here is to complement our contract testing with fuzzing, injecting
    corrupted or invalid data to ensure our application rejects it. In the cloud environment,
    rejecting the wrong data is just as important as accepting the right data!
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的实践是将我们的契约测试与模糊测试结合，注入损坏或无效的数据，以确保我们的应用程序能够拒绝这些数据。在云环境中，拒绝错误的数据与接受正确的数据同样重要！
- en: To provide a good user experience, enforcing our data contract at the application
    layer is often useful before sending it to our services. Not only does this provide
    faster feedback to the users but every error we catch in the application is a
    request we don’t need to serve, reducing the load on the underlying resources.
    The cheapest computer you can use is usually at the closest edge to the user.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供良好的用户体验，在将数据发送到我们的服务之前，在应用层强制执行数据契约通常是有用的。这样不仅能为用户提供更快的反馈，而且每个我们在应用程序中捕获的错误，都是我们不需要处理的请求，从而减少了底层资源的负载。你能用的最便宜的计算机通常是离用户最近的边缘设备。
- en: On the flip side, though, we want to validate our data when we receive it for
    both correctness and security purposes. Anyone could send anything they want to
    our endpoints, and it is our responsibility to work out what to do with it. If
    we enforce contracts on both the backend and frontend, though, we require our
    data contract to be portable.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，另一方面，我们希望在接收到数据时进行验证，以确保其正确性和安全性。任何人都可以向我们的端点发送任何数据，我们有责任处理它。如果我们在后端和前端都执行契约，我们的数据契约就需要是可移植的。
- en: Portability
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可移植性
- en: In these scenarios, it should go without saying that the format of your data
    contracts should aim to be as technology-agnostic as possible. Framework- and
    language-specific libraries often have valuable features. However, locking us
    into a framework can make it challenging to operate across technologies. In like-for-like
    execution environments, say a frontend in React and a backend in Node.js, both
    run JavaScript under the hood, so it might be tempting to use a specialized solution.
    However, what if your company acquires a product with a code base in C#? How will
    they access contracts and ensure data integrity? Hence, the requirements for portability,
    which are a feature of all formats mentioned earlier in the chapter, should always
    be at the forefront of the mind.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些场景中，不言而喻，数据契约的格式应尽量保持技术中立。框架和语言特定的库往往具有有价值的功能。然而，将我们锁定在某个框架中可能会使得跨技术操作变得困难。在类似的执行环境中，比如前端使用
    React，后端使用 Node.js，它们都在底层运行 JavaScript，因此可能会有诱惑去使用专门的解决方案。但是，如果你的公司收购了一个代码库为 C#
    的产品呢？他们将如何访问契约并确保数据完整性？因此，前面章节提到的所有格式的可移植性要求应始终牢记于心。
- en: A mature standard (if you are using JSON, which feels like the de facto cloud
    native standard, except for perhaps Protobuf in GCP!) is JSON Schema. It is maintained
    through the **Internet Engineering Task Force** (**ITEF**), and any precursory
    web search will reveal them as the stewards of many standards we take for granted
    today. You can typically find very mature libraries to generate, validate, and
    test JSON schemas in the language and framework of your choice. It also allows
    for clear delineation between the data schema to test against (JSON Schema) and
    the interface definition through a standard such as OpenAPI or AsyncAPI. If the
    schema is the definition of the data, the interface definition is the metastructure
    that defines the relationships between our schemas and service endpoints.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一个成熟的标准（如果你使用 JSON，这几乎是事实上的云原生标准，除了 GCP 中的 Protobuf！）是 JSON Schema。它由**互联网工程任务组**（**IETF**）维护，通过简单的网络搜索，你会发现他们是我们今天理所当然接受的许多标准的管理者。你通常可以找到非常成熟的库来生成、验证和测试
    JSON 架构，支持你选择的语言和框架。它还允许通过标准如 OpenAPI 或 AsyncAPI，明确区分用于测试的数据架构（JSON Schema）和接口定义。如果架构是数据的定义，接口定义则是定义我们架构与服务端点之间关系的元结构。
- en: Code generation
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码生成
- en: 'If we have both our schemas and our interface definitions predefined, then
    there exist multiple open source projects that allow for this information to be
    used to generate code. Typically, this code generation consists of three discrete
    components:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们已经预定义了架构和接口定义，那么有多个开源项目可以利用这些信息来生成代码。通常，这种代码生成包括三个独立的组件：
- en: '**Type generation**: Generating types from our schemas for consumption in our
    code. This generation is typically a prerequisite for the other two types.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类型生成**：从我们的架构中生成类型，以供代码中使用。这种生成通常是其他两种类型的先决条件。'
- en: '**Client generation**: From our interface definitions and our generated types,
    we can automatically build SDKs to interact with our services, without having
    to worry about needing to make API requests, marshal and unmarshal data, and so
    on.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端生成**：根据我们的接口定义和生成的类型，我们可以自动构建 SDK 来与我们的服务进行交互，无需担心需要进行 API 请求、编组和解组数据等问题。'
- en: '**Server stub generation**: From our interface definition, we can generate
    server stubs that allow us to conform to our interface definition, only requiring
    us to build out the business logic.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务器存根生成**：根据我们的接口定义，我们可以生成服务器存根，使我们能够遵循接口定义，只需要构建业务逻辑。'
- en: When we look at the big three cloud providers, they use this methodology to
    maintain the SDKs that they provide for such a wide range of languages. AWS uses
    the Smithy IDL 2.0, which was custom-made for defining interfaces and code generation
    for AWS but is open source. Azure uses OpenAPI specifications, which we have discussed
    in depth already. Finally, GCP uses Protobuf definitions for all its services,
    which can encode in both JSON or a custom and compact binary format. By using
    code generation, they can make a change to the underlying contract and apply it
    across all their subsequent client SDKs by regenerating them.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们看三大云服务提供商时，他们使用这种方法来维护他们为各种语言提供的 SDK。AWS 使用 Smithy IDL 2.0，这是专门为 AWS 定义接口和代码生成而定制的，但它是开源的。Azure
    使用 OpenAPI 规范，这是我们已经深入讨论过的内容。最后，GCP 使用 Protobuf 定义其所有服务，可以以 JSON 或自定义的紧凑二进制格式进行编码。通过使用代码生成，他们可以对底层契约进行更改，并通过重新生成所有后续客户端
    SDK 来应用这些更改。
- en: 'So, contract testing ensures we don’t break functionality and semantics for
    upstream services and ensures we have confidence in calling our downstream services.
    But how do we ensure continuity in our user interface? This is where an anti-pattern
    is so prevalent that it deserves its own section: manual testing.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，契约测试确保我们不会破坏上游服务的功能和语义，并确保我们在调用下游服务时有信心。但我们如何确保用户界面的连续性呢？这就是一个反模式如此普遍，以至于值得单独开一节来讲解：手动测试。
- en: Manual testing
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动测试
- en: 'When beginning this section, a quote of disputed origin springs to mind: “*I
    didn’t have time to write you a short letter, so I wrote you a long one.*” As
    counter-intuitive as this may seem, people often have the same mentality about
    manual testing. They are so caught up in the process of testing the long way that
    they do not pause to consider the possibilities of automation. This anti-pattern
    is typically heavily ingrained in organizations right down to the team structure.
    This section will look at the case for transitioning to test automation in a cloud
    native environment and the practices you can use to migrate your manual testing
    processes to automated tests.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这一部分时，一个出处争议的名言浮现在脑海：“*我没有时间给你写一封简短的信，所以我写了封长信。*” 虽然这看起来有些反直觉，但人们通常对手动测试持有相同的心态。他们常常沉迷于手动测试的过程，以至于没有停下来考虑自动化的可能性。这种反模式通常深深根植于组织结构中，直到团队层级。本部分将探讨在云原生环境中转向测试自动化的理由，以及你可以使用的实践，将手动测试流程迁移到自动化测试。
- en: Typical company testing archetypes
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 典型的公司测试类型
- en: Usually, companies are convinced that unit testing will provide tangible benefits
    and agree that these can be automated. If you are a company that manually performs
    unit testing, your engineers must have unlimited patience.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，公司会确信单元测试能够提供实际的好处，并同意这些测试可以自动化。如果你是一个手动执行单元测试的公司，那么你的工程师必须具备无限的耐心。
- en: Integration tests form the middle ground, and companies approach this differently.
    Some companies believe that integration tests are optional if they write enough
    unit tests (more on that in the next section). Some companies have some integration
    tests, but they don’t form part of the deployment pipeline or are only run manually
    once in a blue moon.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试处于中间地带，公司对此有不同的处理方式。有些公司认为，如果他们编写足够的单元测试，那么集成测试是可选的（下一部分会详细讨论这个问题）。有些公司进行一些集成测试，但这些测试并不成为部署流水线的一部分，或者只是偶尔手动运行一次。
- en: Finally, we have the companies that have integration tests, have them automated,
    and they form part of the deployment pipeline. There are other approaches/levels
    of maturity, but these are some common integration testing archetypes we see.
    At the final tier, we have our end-to-end tests, which may be automated and form
    part of the deployment process; if this is the case in your company, this section
    may be preaching to the choir. However, these tests are much more likely to exist
    in the form of a dedicated QA function, clicking through user interfaces, following
    steps in a spreadsheet or document, and then reporting back on the result, either
    pre- or post-deployment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有那些已经进行集成测试、将其自动化并将其纳入部署流水线的公司。还有其他的处理方法和成熟度层次，但这些是我们常见的集成测试类型。在最后的层级，我们有端到端测试，这些测试可能是自动化的，并成为部署过程的一部分；如果你的公司就是这种情况，那么这一部分可能已经是在对合唱团宣讲。然而，这些测试更有可能以专门的质量保证（QA）职能的形式存在，点击用户界面，按照电子表格或文档中的步骤操作，然后反馈结果，无论是在部署前还是部署后。
- en: 'So, at the crux, we are looking at three separate kinds of tests:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，关键在于，我们在观察三种不同类型的测试：
- en: '**Unit tests**: Testing atomic units of functionality within a single service
    or component'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单元测试**：测试单个服务或组件中的原子功能单元'
- en: '**Integration tests**: Testing the interactions between components'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成测试**：测试组件之间的交互'
- en: '**End-to-end tests**: Testing the system’s functionality from the end user’s
    context'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端到端测试**：从最终用户的角度测试系统的功能'
- en: The case for test automation
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试自动化的理由
- en: 'With these three forms of test in mind, I would also like to call back to the
    top of your working memory the DORA metrics:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑这三种测试形式时，我还想回顾一下你工作记忆中的DORA指标：
- en: Deployment frequency
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署频率
- en: Lead time for changes
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变更的交付时间
- en: Change failure rate
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变更失败率
- en: Time to restore service
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复服务时间
- en: 'Tests involve optimizing one metric: *change failure rate*. The more testing
    we do before we deploy a change, the lower our change failure rate. Note that
    this eliminates an entire swath of the testing archetypes we discussed earlier
    in this subsection.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 测试涉及优化一个指标：*变更失败率*。我们在部署变更之前进行的测试越多，变更失败率就越低。需要注意的是，这消除了我们在本小节早些时候讨论过的所有测试类型。
- en: If your testing does not occur on your deployment path, you are not protecting
    your change failure rate! You might have a faster time to restore service as you
    may uncover errors or their source earlier with post-deployment tests, but this
    is an entirely different area of expertise (see Chapter 10 for observing your
    deployed architecture). So, we have established the requirement that for tests
    to have a meaningful impact on the performance of your software teams, they need
    to be on the critical path for deployment to production.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的测试没有在部署路径上进行，那么你就没有保护你的变更失败率！虽然通过部署后测试，你可能会更早发现错误或其来源，从而可能有更快的恢复服务时间，但这实际上属于完全不同的专业领域（请参见第10章，关于观察已部署架构的内容）。因此，我们已经设定了一个要求：为了让测试对软件团队的性能产生有意义的影响，测试必须是部署到生产环境的关键路径上的一部分。
- en: When we have manual processes, we end up batching together our changes so that
    they can keep up with the pace of change in our code bases. This protects the
    change failure rate. However, in reality, batching changes together increases
    our change failure rate because the chances of any of the changes we have batched
    together negatively impacting the application significantly increased compared
    to if we deploy those changes individually.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用手动流程时，我们最终会将变更批量处理，以便跟上代码库中的变更节奏。这有助于保护变更失败率。然而，实际上，将变更批量处理会增加我们的变更失败率，因为我们将这些变更合并在一起的情况下，任何单一变更对应用程序产生重大负面影响的概率比我们单独部署这些变更时要大得多。
- en: Let’s say 5 of our changes fail if we deploy 100 changes individually. Then,
    we have a 5% change failure rate. If we deploy batches of 10 changes 10 times,
    we might get lucky, and those 5 failures across those 100 changes are all batched
    into 1 segment, but that’s still a 10% change failure rate. More than likely,
    those 5 failures spread throughout those 10 segments, and now, up to half of those
    segments fail, resulting in a change failure rate of up to 50%. If we just do
    one significant change, then what ends up happening is every change has a failure.
    It’s just a matter of magnitude, so batching things together, even though tests
    are on our critical path, can still cause issues with our change failure rate.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在单独部署100个变更时，5个变更失败。那么，我们的变更失败率是5%。如果我们将这些变更分成10组，每组10个，进行10次部署，可能会运气好，把那5个失败分布在100个变更中，并且都集中在1个组内，但这仍然是10%的变更失败率。更有可能的是，这5个失败分散在10个组中，导致多达一半的组失败，变更失败率高达50%。如果我们只做一次重大变更，那么最终结果就是每个变更都会失败。这只不过是规模的问题，因此，即使测试在我们的关键路径上，批量处理变更仍然可能导致变更失败率的问题。
- en: 'So, we have established that batches are bad for our change failure rate. Let’s
    now look at our other metrics: our deployment frequency and lead time for changes.
    Both of these functions depend on our total pipeline time. Introducing manual
    stages into our pipeline significantly increases the time it takes to complete.
    Longer pipeline cycle times mean developers are less likely to deploy small incremental
    changes; instead, they are more likely to batch together changes, leading to the
    same problem we discussed before batching together changes for testing. This impacts
    our deployment frequency.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们已经确定批量操作对我们的变更失败率有不良影响。现在让我们看看其他指标：我们的部署频率和变更的交付时间。这两个功能都依赖于我们整个流水线的时间。向流水线中引入手动阶段会显著增加完成所需的时间。较长的流水线周期意味着开发人员不太可能部署小的增量变更；相反，他们更有可能将变更批量处理，导致我们之前讨论的将变更批量测试的问题。这会影响我们的部署频率。
- en: Our other metric, lead time for changes, is a function of all the linear steps
    that must occur before a change Is deployed to production. By increasing the pipeline
    time, even if we kept our changes atomic and deployed frequently, the lead time
    for changes would still be more significant because one of its components takes
    a long time to complete. So, manual testing is destructive for our change failure
    rate and affects our other metrics, lead time for changes, and deployment frequency.
    We discussed earlier on in the book that introducing stages on the deployment
    path that have long cycle times or increase the times that deployment also means
    that we are unlikely to perform the same checks when the service is heavily impacted,
    so changes that are hotfixes or are intended to be fixes for urgent issues in
    production tend not to be as rigorously tested as of the code that initially caused
    the problem in the first place.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的另一个指标，变更交付时间，是指在变更部署到生产环境之前，必须完成的所有线性步骤的总和。通过增加流水线时间，即使我们保持变更原子化并频繁部署，变更交付时间仍然会变得更长，因为其中某个环节需要较长时间才能完成。所以，手动测试对我们的变更失败率有破坏性，也影响我们的其他指标，变更交付时间和部署频率。我们在本书早些时候讨论过，部署路径中引入具有长周期时间的阶段或增加部署时间，意味着我们不太可能在服务受到严重影响时执行相同的检查，因此那些紧急修复或旨在解决生产中紧急问题的变更，通常没有像最初导致问题的代码那样经过严格测试。
- en: So, if we follow our process to the letter, we will see that we negatively impact
    our time to restore services as well. We can improve our time to restore service
    only through workarounds and avenues outside of our standard operating procedures.
    This negates any benefit that might be achieved through the earlier detection
    of issues through testing production or outside the critical deployment path.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果我们严格按照流程操作，我们会发现恢复服务的时间也会受到负面影响。我们只能通过变通方法和标准操作程序之外的途径来改善恢复服务的时间。这也抵消了通过在生产环境中测试或在关键部署路径之外早期发现问题所可能带来的任何好处。
- en: As soon as we introduce humans into our process, we introduce variability. Humans
    are very good at taking the unknown, applying their knowledge and heuristics,
    and solving problems they have not encountered before. Testing is the exact opposite
    of this process. We know the issues we want to test for and how to test for them.
    Therefore, humans are poorly suited to the task of manual testing. We can accelerate
    this process significantly through automation. As soon as we take humans out of
    the equation and introduce automated over manual processes, the function of how
    much testing we can perform does not become a question of *human* resources but
    of *compute* resources. With the advent of the cloud, on-demand compute resources
    can quickly be provisioned and deprovisioned as needed to perform testing. This
    process accelerates our feedback cycle, allowing us not only to have certainty
    that the changes we are applying will not cause failures but also to have all
    of our developers empowered to perform adequate testing on all of the code they
    push into a production environment.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将人类引入我们的流程中，就会引入变数。人类非常擅长处理未知的问题，运用他们的知识和启发式方法，解决他们之前没有遇到过的问题。测试恰恰与这个过程相反。我们知道我们要测试的问题以及如何进行测试。因此，人类并不适合从事手动测试工作。通过自动化，我们可以显著加速这个过程。一旦我们将人类从方程式中移除，并引入自动化而非手动流程，我们能够进行多少测试的问题就不再是*人力*资源的问题，而是*计算*资源的问题。随着云计算的出现，可以根据需要快速配置和释放按需计算资源来执行测试。这个过程加速了我们的反馈周期，不仅使我们有信心确保所做的更改不会导致失败，还使所有开发人员能够在将代码推送到生产环境时，充分测试所有代码。
- en: 'Now, this may sound like humans don’t add value to the testing process in any
    way; however, I would like to postulate that humans add unique value in how they
    can define and envision test suites rather than the execution of those test suites.
    The definition and creation of test suites is a unique skill; they are variable
    and nuanced, and humans are great at that task. A great joke goes like this: a
    developer walks into a bar and orders 1 beer; a tester walks into a bar and orders
    1 beer, 10,000 beers, negative 1 beers, a sofa, and so on. Still, the part of
    testing that we value is the creative side, understanding the problem space, and
    coming up with unique edge cases to ensure consistency in behavior. The actual
    execution of these tests is something that testers are wasted on. This section
    won’t tell you to make your entire testing team redundant. This section tells
    you to put your testing team to the best use possible by allowing them to exercise
    their creativity.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这听起来好像人类在测试过程中没有任何价值；然而，我想提出一个假设：人类在定义和构想测试套件方面可以提供独特的价值，而不仅仅是执行这些测试套件。测试套件的定义和创建是一项独特的技能；它们是可变且微妙的，而人类在这方面非常擅长。一个很棒的笑话是这样的：一位开发者走进酒吧点了一杯啤酒；一位测试人员走进酒吧点了一杯啤酒、10,000杯啤酒、负1杯啤酒、一张沙发，等等。尽管如此，我们重视的测试部分是创造性方面，理解问题空间，并提出独特的边界情况来确保行为一致性。实际上，执行这些测试是测试人员不应承担的任务。本节内容并不会告诉你让整个测试团队冗余。本节的目的是通过允许测试团队发挥创造力，最大限度地发挥他们的作用。
- en: Migrating manual testing processes
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移手动测试流程
- en: 'As discussed, manual testing processes typically exist in the end-to-end space.
    The migration process for manual integration tests puts them on the critical path,
    as they likely already exist as code-driven tests. If they don’t, then the integration
    tests can be created using the existing skill set of your development teams. Manual
    end-to-end tests, on the other hand, can seem like a much more daunting task to
    migrate. Our testing function may not have coding skills. However, that does not
    mean we must revamp our entire testing department. Instead, we can perform three
    key actions:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，手动测试流程通常存在于端到端的过程中。手动集成测试的迁移过程将其置于关键路径上，因为它们可能已经作为代码驱动的测试存在。如果没有，它们可以利用开发团队现有的技能集来创建集成测试。另一方面，手动端到端测试可能看起来是一个更加艰巨的迁移任务。我们的测试团队可能没有编码技能。然而，这并不意味着我们必须重构整个测试部门。相反，我们可以采取三个关键行动：
- en: Lean on our development function
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 倚赖我们的开发职能
- en: Utilize tooling to accelerate the migration
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用工具加速迁移
- en: Upskill our testing teams
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升我们测试团队的技能
- en: As I said before, humans can deal with variability. Our development function
    may have exploited this not maliciously but inadvertently by relying on visual
    cues to the tester performing the manual testing. When we migrate to automated
    testing, typically, we must depend on properties in our user interface that are
    invisible to the tester but visible to our testing framework. For example, when
    we change a button in our interface to a hyperlink but keep the same styling,
    the tester is unlikely to register a change. Still, this is a significant change
    for an automated test suite looking for a button element.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前所说，人类能够应对变化。我们的开发团队可能并非恶意地利用这一点，而是无意中依赖视觉提示来引导进行手动测试。当我们迁移到自动化测试时，通常必须依赖用户界面中对测试人员不可见但对测试框架可见的属性。例如，当我们将界面中的按钮改为超链接但保持相同的样式时，测试人员不太可能察觉到变化。然而，对于一个寻找按钮元素的自动化测试套件来说，这却是一个重大的变化。
- en: Therefore, our development function needs to improve its working methods to
    ensure that the artifacts it produces are testable. In the web world, this may
    look like leveraging ARIA labels to provide meaning to specific elements. In this
    way, a hyperlink and a button that share an ARIA label can be treated similarly.
    Regarding aria labels, not only will your testers thank you for making your UI
    more testable but suitable aria labels also make your site more accessible. Hence,
    it’s something you should be doing anyway. Our development function is already
    likely well versed in adding tests to the pipeline to production. So, we can lean
    on our development teams to help integrate this new test suite into the path to
    production, removing the requirement for this capability within our testing teams.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的开发团队需要改进工作方法，以确保其产生的工件是可测试的。在 Web 世界中，这可能表现为利用 ARIA 标签为特定元素提供意义。通过这种方式，共享
    ARIA 标签的超链接和按钮可以被类似对待。关于 ARIA 标签，不仅测试人员会感谢你让 UI 更具可测试性，适当的 ARIA 标签还会使你的网站更具可访问性。因此，这是你应该做的事情。我们的开发团队已经很熟练地将测试集成到生产流程中。所以，我们可以依赖开发团队帮助将这套新的测试套件集成到生产路径中，从而免去测试团队对这项能力的需求。
- en: We still need help writing the tests. However, it’s unlikely that our development
    teams will want to go through all of the documentation produced in the past by
    a manual testing team and convert them into automated tests. This is also not
    future-proof; any new test we want to add will depend on the development team.
    This is where we can utilize tooling to accelerate the migration. Many testing
    suites we would use for end-to-end testing include functionality allowing us to
    record tests directly from the browser. Using this functionality, we can do one
    last manual run of our tests, record them, and then save them for use in our automated
    testing framework.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然需要帮助编写测试。然而，开发团队不太可能愿意逐一查看过去手动测试团队所产生的所有文档，并将其转换为自动化测试。这也无法适应未来；我们想要添加的任何新测试都将依赖于开发团队。这时我们可以利用工具来加速迁移。许多用于端到端测试的测试套件都包括允许我们直接从浏览器录制测试的功能。使用这个功能，我们可以最后一次手动执行测试，录制下来，然后保存到我们的自动化测试框架中使用。
- en: Our source of truth is no longer copious pieces of documentation but codified
    tests with no ambiguity. This process gets us significantly closer to automated
    end-to-end testing without involving the development team. For this initial migration,
    interfacing with the development team may be beneficial in getting the project
    off the ground. However, in the long run, the testing team must complete this
    process autonomously.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的真实依据不再是大量的文档，而是没有歧义的编码化测试。这个过程使我们大大接近于实现无需开发团队参与的自动化端到端测试。对于这次初始迁移，可能需要与开发团队进行接口对接，帮助项目启动。然而，从长远来看，测试团队必须独立完成这一过程。
- en: We must upskill our testing teams in the framework that we use for creating
    tests. This does not mean that every tester needs to become a developer. However,
    every tester needs the capability to define, record, and integrate tests into
    the test suite autonomously. This process is a much smaller ask, but utilizing
    tooling and leaning on our development function prevents us from needing to change
    the structure of our teams. The one case in which I recommend changing the structure
    of your teams is to shift toward the structure we mentioned earlier in the book
    that allows teams to be self-sufficient.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须提升测试团队在创建测试时使用的框架技能。这并不意味着每个测试员都需要成为开发人员。然而，每个测试员都需要具备独立定义、记录和将测试集成到测试套件中的能力。这个过程要求较小，但通过利用工具并依赖开发功能，我们可以避免改变团队结构。我推荐唯一改变团队结构的情况是朝着书中早些时候提到的结构转型，使团队能够自给自足。
- en: If your testing function is a standalone unit of your business, consider integrating
    them into your delivery teams to enable them to be fully autonomous. Not only
    will this break down the adversarial nature between a standalone testing function
    and a development function but it will also allow end-to-end ownership of the
    delivery of the team’s outcomes. This closer alignment means that testers can
    lean upon the development resources within their teams as they upskill to become
    fully self-sufficient.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的测试功能是你业务中的独立单元，考虑将它们融入到交付团队中，使其能够完全自主。这不仅会打破独立测试功能和开发功能之间的对立关系，还会让团队能够完全拥有交付结果的端到端责任。这种更紧密的对齐意味着测试员可以依赖他们团队中的开发资源，在提升技能以实现完全自给自足的过程中获得支持。
- en: Trying to recreate the cloud
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试重建云环境
- en: In the previous section, we discussed the overuse of unit tests to compensate
    for the lack of integration tests. Good coding practices drive good testing. Our
    business logic, the part of our code that drives value, should be unit-tested.
    However, unit testing for this part of our code should not involve extensive mocking
    of the environment in which it runs. The anti-pattern we typically see in this
    space is that people try to recreate the cloud on their local environment through
    third-party tooling, extensive mocking, or some other method.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了通过过度使用单元测试来弥补集成测试的缺乏。良好的编码实践能推动良好的测试。我们的业务逻辑，即驱动价值的代码部分，应该进行单元测试。然而，对这部分代码进行单元测试时，不应涉及过多模拟其运行环境。我们在这一领域中常见的反模式是，人们尝试通过第三方工具、广泛模拟或其他方法在本地环境中重建云环境。
- en: To dissect this anti-pattern, we will look at the traditional testing paradigm,
    what testing looks like in a cloud native world, and how we can best leverage
    cloud services to test our code. Previously, we focused on end-to-end, contract,
    and unit tests, so it should be no surprise that this section will focus heavily
    on integration tests.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了剖析这种反模式，我们将审视传统的测试范式、云原生世界中的测试样式，以及我们如何最好地利用云服务来测试我们的代码。之前，我们集中讨论了端到端测试、契约测试和单元测试，因此这一节将重点讨论集成测试。
- en: The traditional testing paradigm
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统的测试范式
- en: The traditional testing paradigm typically consists of a large number of unit
    tests because they’re cheap, a few integration tests because they’re a little
    bit harder to write and a little bit harder to run, and just a couple of end-to-end
    tests because, as discussed previously, this is often a manual function. This
    typically gives us a pattern referred to as the testing pyramid.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的测试范式通常包含大量的单元测试，因为它们成本低，少量集成测试，因为它们编写起来稍微有点难度，执行起来也有些难度，只有少数几个端到端测试，因为如前所述，这通常是一个手动功能。这通常为我们提供了一个被称为测试金字塔的模式。
- en: '![](img/B22364_13_2.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22364_13_2.jpg)'
- en: Figure 13.2 - The testing pyramid
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 - 测试金字塔
- en: 'In the initial premise for this section, I mentioned that our unit test should
    focus on testing the parts of our code that are unique to our business: our business
    logic. In the cloud world, resources are cheap, and much of the complexity that
    used to live inside our application can now be farmed out to the cloud service
    provider itself. This presents an interesting problem: if our logic is pushed
    out to the cloud service provider, less and less of our functionality becomes
    testable through unit tests. Typically, we see developers start relying on extensive
    mocking in this scenario. It’s not uncommon to enter a code base at a client and
    see eight or more cloud services mocked out to test a piece of business logic.
    Third-party tools have also sprung up and promise to provide cloud-like functionality
    inside your test pipelines or local environment.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的初始前提中，我提到我们的单元测试应该专注于测试那些与我们业务相关的代码部分：我们的业务逻辑。在云端环境中，资源便宜，许多以前存在于应用程序中的复杂性现在可以委托给云服务提供商本身。这就提出了一个有趣的问题：如果我们的逻辑被推送到云服务提供商，那么通过单元测试能够测试的功能将越来越少。通常情况下，我们看到开发者在这种情况下开始依赖大量的模拟。进入客户的代码库时，看到为测试一段业务逻辑而模拟了八个或更多云服务并不罕见。第三方工具也应运而生，并承诺在你的测试流水线或本地环境中提供类似云的功能。
- en: 'If we continue in our traditional mindset of unit tests first, then these all
    look like attractive propositions. When we look at the testing pyramid, it may
    feel that resorting to an integration test is a failure on behalf of the developer:
    “*I wasn’t good enough to write a unit test for this.*” We may feel that integration
    tests are reserved explicitly for very complex cross-service behaviors, but this
    leads us to integrated test territory, not integration test territory. Much like
    the producers of a popular nature documentary, we want to observe the behavior
    of our system in its natural habitat. In our case, its natural habitat just happens
    to be the cloud.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们继续以传统的单元测试优先思维方式，这些看起来都是很有吸引力的提议。当我们看到测试金字塔时，可能会觉得依赖集成测试是开发者的失败：“*我没有足够好，无法为此编写单元测试*。”我们可能认为集成测试仅仅用于非常复杂的跨服务行为，但这会将我们带入集成测试的领域，而非集成测试的领域。就像一部受欢迎的自然纪录片的制作人一样，我们希望观察系统在其自然栖息地中的行为。在我们的例子中，它的自然栖息地恰好是云端。
- en: The testing honeycomb
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试蜂巢模型
- en: '*Spotify R&D* published an excellent article in 2018 examining the testing
    honeycomb ([https://engineering.atspotify.com/2018/01/testing-of-microservices/](https://engineering.atspotify.com/2018/01/testing-of-microservices/)).
    In this honeycomb, we remove our overdependence on unit tests as the base level
    of testing and rely instead on integration or service tests. Spotify specifically
    talks about the removal of integrated tests, which are tests that span multiple
    services. However, we believe that end-to-end tests can still produce value even
    if they span numerous services. They should not be taken as an indication of an
    individual service’s health but as an overall system health check before deployment.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*Spotify研发*在2018年发布了一篇优秀的文章，探讨了测试的蜂巢模型（[https://engineering.atspotify.com/2018/01/testing-of-microservices/](https://engineering.atspotify.com/2018/01/testing-of-microservices/)）。在这个蜂巢模型中，我们减少了对单元测试的过度依赖，作为测试的基础层，转而依赖集成测试或服务测试。Spotify特别提到了集成测试的移除，即跨多个服务的测试。然而，我们认为，即使跨越多个服务，端到端的测试仍然可以产生价值。它们不应该作为单个服务健康状况的指示，而应该作为部署前的整体系统健康检查。'
- en: '![](img/B22364_13_3.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22364_13_3.jpg)'
- en: Figure 13.3 - The testing honeycomb
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 - 测试蜂巢模型
- en: Using integration tests, we more accurately represent the real-world deployed
    environment than in unit tests. Instead of testing against a simulacrum of the
    cloud, we deploy our services to the cloud and then test them in their natural
    habitat. This was fine in the traditional model, where a large amount of our functionality
    existed within the context of our application.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 使用集成测试，我们比单元测试更准确地代表了实际部署环境。我们不是对云的模拟进行测试，而是将我们的服务部署到云端，然后在它们的自然栖息地中进行测试。在传统模型中，这种方式是可行的，因为我们的功能大部分存在于应用程序的上下文中。
- en: However, as we have said, more of the common parts of our application are being
    outsourced to managed services in the cloud. Therefore, it can be easy to produce
    tight coupling between cloud services and the logic we want to test. In the next
    section, we will go into more detail on structuring our code, but for now, let’s
    focus on integration testing.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如我们所说，我们应用程序中越来越多的常见部分正被外包到云端托管服务中。因此，很容易在云服务和我们想要测试的逻辑之间产生紧密耦合。在接下来的部分中，我们将更详细地讨论如何构建我们的代码，但现在，让我们专注于集成测试。
- en: Testing in the cloud versus testing for the cloud
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在云中测试与为云测试
- en: Earlier in this book, we discussed development in ephemeral environments. The
    same concept can be used in our testing pipeline. Using the structure of the testing
    honeycomb, we have many integration tests that specify how our application interacts
    with the cloud environment. These tests can be run in a temporary cloud environment.
    This allows us to test our code in the cloud, using actual cloud services rather
    than mocking them. When we mock out services in the cloud, we are testing our
    code against our mental model of the cloud. When we use actual cloud services,
    there is no transitive mental model that our code needs to pass through to be
    tested.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的早些章节中，我们讨论了在短暂环境中的开发。相同的概念可以用于我们的测试管道。利用测试蜂窝的结构，我们有许多集成测试来指定我们的应用程序如何与云环境交互。这些测试可以在临时的云环境中运行。这使我们能够在云中测试代码，使用真实的云服务而不是模拟它们。当我们模拟云服务时，我们是在将代码与我们脑海中对云的模型进行测试。而当我们使用实际的云服务时，代码不需要通过任何过渡的心智模型来进行测试。
- en: 'There are some core concepts that we need to have implemented to be able to
    test our code in ephemeral environments:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些核心概念，我们需要实现这些概念才能在短暂环境中测试我们的代码：
- en: We must have solid **infrastructure as code** (**IaC**) foundations to spin
    up and tear down environments as required
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们必须拥有坚实的**基础设施即代码**（**IaC**）基础，以便根据需要快速启动和销毁环境。
- en: We need to understand which parts of our infrastructure take longer to provision
    and supply pre-provisioned resources for testing purposes to keep cycle times
    low
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要了解我们基础设施中哪些部分需要更长时间来配置，并为测试目的提供预配置资源，以保持较低的周期时间。
- en: Our testing pipeline must have access to a cloud environment
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的测试管道必须能够访问云环境。
- en: When discussing solid IaC foundations, we mean following good practices when
    implementing IaC. To test our applications effectively, we need to pull up just
    the part of our infrastructure required for testing instead of our entire application.
    Typically, we need firm domain boundaries between different application areas
    to test our system effectively with the cloud in isolation from other application
    components. For more information on providing firm boundaries between application
    components and strong cohesion within application components, we recommend reviewing
    the *Tight coupling, low* *cohesion* section.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论坚实的IaC基础时，我们指的是在实现IaC时遵循良好的实践。为了有效地测试我们的应用程序，我们只需启动测试所需的基础设施部分，而不是整个应用程序。通常，我们需要在不同应用领域之间设置明确的域边界，以便有效地在与其他应用组件隔离的云中测试我们的系统。有关提供应用组件之间坚实边界以及应用组件内部强凝聚力的更多信息，我们建议查阅*紧密耦合，低*
    *内聚性*部分。
- en: The other interesting part of IaC that is typically exposed through this practice
    is the solidification and codification of specific IaC properties. When we need
    to deploy multiple copies of our application to run tests, sometimes numerous
    copies simultaneously, we can quickly highlight any areas of our infrastructure
    that have solidified around a single deployment. Hence, testing this way can also
    highlight gaps in our resiliency plan and ability to bring up new application
    instances.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: IaC（基础设施即代码）中另一个通常通过这一实践暴露出的有趣部分是具体IaC属性的固化和编码。当我们需要部署多个副本来运行测试时，有时需要同时运行多个副本，我们可以迅速发现基础设施中那些围绕单一部署固化的区域。因此，这种测试方式还可以突出我们弹性计划中的漏洞，以及我们启动新应用实例的能力。
- en: Some parts of IaC configurations can be provisioned very quickly. Things such
    as serverless functions or API gateways can be provisioned in minimal time. On
    the other hand, more traditional resources such as relational database instances
    or virtual machines may require more time to be created. Typically, we can use
    common resources between our test environments and partition them by namespaces
    or any other supported partitioning method. For example, suppose we had a relational
    database service. In that case, each test environment might use the same database
    instance, which takes a long time to provision. However, create a separate database
    within that instance to perform its test and then delete it upon completion. An
    in-memory key store might use a single instance with keys prefixed with namespaces
    unique to the test suite execution. This process ensures that we keep our cycle
    times low and provide fast feedback to our developers while also allowing us to
    maintain a high deployment frequency and low lead time for changes.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一些基础设施即代码（IaC）配置的某些部分可以非常快速地进行配置。例如，无服务器函数或API网关可以在最短的时间内进行配置。另一方面，更传统的资源，如关系型数据库实例或虚拟机，可能需要更多的时间来创建。通常，我们可以在测试环境之间使用共享资源，并通过命名空间或任何其他支持的分区方法进行划分。例如，假设我们有一个关系型数据库服务。在这种情况下，每个测试环境可能使用相同的数据库实例，这需要较长的时间来配置。然而，可以在该实例内创建一个单独的数据库来执行测试，然后在完成后将其删除。内存中的键存储可能使用一个实例，并且每个键的前缀使用测试套件执行时独特的命名空间。这个过程确保我们保持较低的周期时间，能够为开发人员提供快速反馈，同时还允许我们维持高频率的部署和较短的更改前置时间。
- en: Fundamental to all of this is that our testing environment needs to be a real
    cloud environment. This requirement might mean linking our testing pipeline with
    cloud credentials, infrastructure pipelines, and CI/CD processes. This increases
    complexity; however, the benefit is increased certainty in our deployments. Applying
    the same best cloud practices described elsewhere in this book to the cloud environment
    used for testing is also essential. We can still apply the practices of good cloud
    governance, FinOps, DevSecOps, and platform engineering to make this cloud environment
    a first-class citizen in our cloud estate. By practicing good hygiene in this
    cloud environment, we not only make it easier for the developers who need to run
    tests in this environment but also gain increased certainty in the tests we run,
    avoiding the issues of flaky pipelines, long pipeline runtimes, and long lead
    times for changes.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些的基础是，我们的测试环境需要是真实的云环境。这个要求可能意味着将我们的测试管道与云凭证、基础设施管道和CI/CD流程连接起来。这增加了复杂性；然而，它的好处是增加了部署的确定性。将书中描述的其他最佳云实践应用到用于测试的云环境中也是至关重要的。我们仍然可以应用良好的云治理、FinOps、DevSecOps和平台工程的实践，使这个云环境在我们的云资产中成为一等公民。通过在这个云环境中保持良好的操作习惯，我们不仅能让需要在该环境中运行测试的开发人员更加轻松，也能提高我们所运行测试的确定性，避免管道不稳定、长时间管道运行和较长的更改前置时间等问题。
- en: Testing non-functional requirements
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试非功能性需求
- en: 'Now that we are testing in a real cloud environment and have mature integration
    tests, we can also test for properties that were previously unfeasible. Some of
    the key properties that are great to test for in this space include the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在真实的云环境中进行测试，并且已经拥有成熟的集成测试，我们还可以测试以前无法测试的属性。在这个领域中，以下是一些非常重要的测试属性：
- en: '**Latency**: This ensures our requests are completed in a reasonable amount
    of time'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：这确保我们的请求能够在合理的时间内完成'
- en: '**Consistency**: Many cloud systems operate on the principle of eventual consistency,
    but we might have non-functional requirements regarding time to consistency'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性**：许多云系统遵循最终一致性的原则，但我们可能对一致性时间有非功能性需求'
- en: '**Scalability**: We might want to perform load testing to ensure that our services
    can handle the expected traffic shapes'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：我们可能希望进行负载测试，以确保我们的服务能够处理预期的流量模式'
- en: '**Resilience**: Assuming we have resiliency strategies, we will want to test
    them based on the reasons we discussed earlier in the book'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性**：假设我们已经有了弹性策略，我们将根据书中早期讨论的原因进行测试'
- en: At this point, you need to apply your judgment. Previously, we talked about
    testing needing to be on the critical path to be useful. Testing non-functional
    requirements is not always feasible to perform on the critical path and often
    deals with slowly changing properties of our application. Therefore, running this
    sort of testing on a schedule can occasionally be better due to its complex nature.
    Typically, these tests are used to test for regression from previous executions.
    We can also apply the same rigor of checking for regressions of non-functional
    requirements on our other tests.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你需要发挥自己的判断力。之前我们讨论过，测试需要在关键路径上进行，才有意义。对非功能性需求进行测试并不总是能在关键路径上进行，通常这类测试涉及到我们应用程序的缓慢变化特性。因此，出于其复杂性，定期执行这类测试有时可能会更好。通常，这些测试用于检查先前执行中的回归。我们也可以将同样的严谨性应用于检查其他测试中的非功能性需求回归。
- en: We can certainly check test execution times for regressions on the critical
    path. In a recent case, a manually discovered regression uncovered a vulnerability
    in XZ, a popular compression utility. A developer noticed regressions in SSH execution
    times, which, in the subsequent investigation, revealed a complex multi-year-long
    plot to backdoor the utility. The full story sounds like the plot of a spy movie
    and is worth additional research by any interested readers.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以检查关键路径上的回归测试执行时间。在最近的一例中，一次手动发现的回归揭示了XZ（一个流行的压缩工具）中的一个漏洞。一位开发人员注意到SSH执行时间的回归，随后通过调查发现了一个持续了多年的复杂阴谋，旨在为该工具留下后门。整个故事听起来像是一部间谍电影，任何感兴趣的读者都值得进一步研究。
- en: Even though these were manually discovered regressions, had they not been found,
    they could have had potentially catastrophic effects for many projects built on
    these tools.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些回归是手动发现的，但如果没有被发现，它们可能会对许多基于这些工具构建的项目造成灾难性的影响。
- en: Poorly structured code
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构不良的代码
- en: One of the key anti-patterns we see in writing cloud native software is a false
    equivalency between 100% code coverage and code quality. It’s important to remember
    that high code quality and good coding practices should naturally result in sufficient
    code coverage to guarantee the behavior we want to test. As professionals, we
    must ensure that we adhere to these practices. One of the main impediments to
    writing good tests is poorly structured code, or, to put it another way, low-quality
    code. Therefore, in this section, we will explore some common anti-patterns that
    can arise when writing cloud native software and how that impacts our ability
    to test.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在编写云原生软件时常见的一个关键反模式是将100%代码覆盖率与代码质量等同起来。重要的是要记住，高质量的代码和良好的编码实践应当自然地产生足够的代码覆盖率，以保证我们想要测试的行为。作为专业人士，我们必须确保遵循这些实践。编写良好测试的主要障碍之一是结构不良的代码，换句话说，就是低质量的代码。因此，在本节中，我们将探讨在编写云原生软件时可能出现的一些常见反模式，以及它们如何影响我们进行测试的能力。
- en: Key terms
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关键术语
- en: 'Before we discuss code structure, we need to define some key terms to understand
    the topic at hand:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论代码结构之前，我们需要定义一些关键术语，以便理解当前话题：
- en: '**Business logic** is anything our application does that transforms the information
    between our user and the persistence layer. Business logic might consist of evaluating
    custom rules to determine whether a customer is eligible for a product or assigning
    inventory to a new order that has just entered a purchasing system. Fundamentally,
    business logic is the part of our application that presents our unique business
    proposition. If we connect the user directly to the persistence layer, are we
    adding any value for the customer? Other non-business logic areas of the company
    still derive value by providing things such as a good user experience, reliability,
    and fulfillment. But, in a software sense, the codifying and repeatability of
    processes through business logic is usually one of the core elements through which
    we derive value.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**业务逻辑**是指我们应用程序中将用户与持久化层之间的信息进行转换的所有操作。业务逻辑可能包括评估自定义规则，以确定客户是否有资格购买某个产品，或者将库存分配给刚刚进入采购系统的新订单。从根本上说，业务逻辑是我们应用程序中呈现我们独特商业主张的部分。如果我们将用户直接连接到持久化层，那么我们为客户增加了什么价值呢？公司中的其他非业务逻辑领域仍然通过提供良好的用户体验、可靠性和履行等内容而产生价值。但从软件的角度看，通过业务逻辑对过程进行编码和重复性的执行，通常是我们获得价值的核心元素之一。'
- en: '**Side effects** are anything our application does that affects other parts
    of the system and relies on behavior outside the defined function. For example,
    a side effect might be creating a new record in the database or sending a notification
    to a user’s phone. Anything that our function does other than returning a value
    based on its arguments is a side effect. Side effects are not inherently wrong.
    Instead, they are an essential part of our application, allowing us to perform
    actions such as persistence, evolution, and eventing.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**副作用**是指我们的应用程序执行的任何影响系统其他部分并依赖于定义函数之外行为的操作。例如，副作用可能是创建数据库中的新记录或向用户的手机发送通知。任何我们的函数执行的操作，除了根据其参数返回一个值，都是副作用。副作用本身并不是错误的。相反，它们是我们应用程序的一个重要组成部分，使我们能够执行诸如持久化、演变和事件处理等操作。'
- en: The monolith
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单体架构
- en: Just because we escaped the monolithic application through microservices or
    serverless functions does not mean we’ve escaped the conceptual idea of the monolith
    within our code. I defined the previous two terms because they represent two significant
    but very different actions an application must perform. The critical difference
    is that a pure function can typically represent our business logic. This function
    has no side effects and relies solely on its arguments to produce a return value.
    To maintain the results of this function, we must rely on side effects to communicate
    with other parts of our system, such as our database.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅因为我们通过微服务或无服务器函数逃离了单体应用程序，并不意味着我们在代码中已经逃离了单体的概念。我定义了前面两个术语，因为它们代表了应用程序必须执行的两个重要但非常不同的操作。关键的区别是，纯函数通常可以代表我们的业务逻辑。这个函数没有副作用，仅仅依赖其参数来生成返回值。为了保持这个函数的结果，我们必须依赖副作用与系统的其他部分进行通信，例如我们的数据库。
- en: This is where we can once again fall into the monolithic trap. It can be tempting
    to intersperse our business logic with side effects as we require them. This makes
    sense from a logical perspective, and from structuring our code, we add effects
    as we need them where we need them. However, this leads us down the path of high
    coupling and low cohesion, which we had previously in the monolithic structure.
    Instead, what we should look to do is separate our concerns from our business
    logic. The rules that define how we operate should be written as pure functions.
    They shouldn’t have any side effects, making our company’s unique value proposition
    directly testable.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们再次可能陷入单体陷阱的地方。将业务逻辑与副作用交织在一起以满足需求是很有诱惑力的。从逻辑角度来看，这似乎很合理，在构建代码时，我们在需要的地方添加副作用。但这将导致高耦合和低内聚性，正如我们在单体结构中曾经遇到的那样。相反，我们应该做的是将关注点从业务逻辑中分离出来。定义我们如何操作的规则应该写成纯函数。它们不应有任何副作用，使得我们公司的独特价值主张可以直接进行测试。
- en: When we start introducing side effects directly alongside our business logic,
    we suddenly run into the requirement to provide mocking that mimics these side
    effects simply to test the rules by which we run our business. This can turn the
    practice of testing our business logic from a 10-minute exercise testing a pure
    function into a multi-hour exercise where most of our time is spent setting up
    the environment to run our tests by mocking out the side effects. Recalling the
    testing honeycomb from the previous section, we can test our side effects through
    a different type of test. In that case, we should use integration tests and test
    our code in the cloud rather than extensive mocking and unit tests. The logical
    extension of this is writing our business logic as a pure function and testing
    only our business logic to ensure correctness against our business rules and expectations.
    Then, when we want to test our system’s side effects, we can begin integration
    testing against the deployed service.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始将副作用直接与业务逻辑放在一起时，我们突然需要提供模拟这些副作用的功能，仅仅为了测试我们运行业务的规则。这可能将测试业务逻辑的过程从一个测试纯函数的10分钟练习，变成一个多小时的练习，其中大部分时间都用来设置环境，模拟副作用以便运行测试。回想上一节的测试蜂巢，我们可以通过另一种类型的测试来测试副作用。在这种情况下，我们应该使用集成测试，在云中测试我们的代码，而不是大量的模拟和单元测试。这一逻辑的延伸是将业务逻辑编写为纯函数，并只测试业务逻辑，以确保其符合我们的业务规则和期望。然后，当我们想测试系统的副作用时，我们可以开始对已部署的服务进行集成测试。
- en: So, now we’ve managed to separate the concerns of our business logic from the
    side effects required to make it useful. A lot of functional glue still binds
    our business logic with our side effects. While this could be tested through integration
    testing, other alternatives allow us to increase our code coverage without replicating
    the cloud in our unit tests. This is advantageous because unit tests have lower
    complexity, faster execution, and faster feedback cycles than integration tests.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在我们已经成功地将业务逻辑与实现其有用性的副作用分离开来。尽管如此，仍然有许多功能性代码将业务逻辑与副作用绑定在一起。虽然这可以通过集成测试进行验证，但其他替代方案使我们能够在不在单元测试中复制云环境的情况下提高代码覆盖率。这是有利的，因为单元测试的复杂度较低，执行速度更快，反馈周期也比集成测试更短。
- en: Hexagonal architecture
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 六边形架构
- en: In 2005, Alistair Cockburn introduced the concept of hexagonal architecture.
    Broadly speaking, hexagonal architecture provides a methodology for decoupling
    the implementation of our side effects from their usage. I’ll provide a diagram
    for hexagonal architecture and then we can go into it in more detail.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 2005年，阿里斯泰尔·科克本（Alistair Cockburn）提出了六边形架构的概念。广义上来说，六边形架构为我们提供了一种方法论，用于将副作用的实现与其使用解耦。我将提供一张六边形架构的示意图，之后我们可以更详细地讨论。
- en: '![](img/B22364_13_4.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22364_13_4.jpg)'
- en: Figure 13.4 - Conceptual diagram of the hexagonal architecture model
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 - 六边形架构模型的概念图
- en: At the core of our application, we have our application code that glues our
    side effects and business logic together; this bundle is our entity. The side
    effects are exposed through standard interfaces referred to as **ports**. For
    example, we might have a persistence port or a notification port. What’s important
    is that the entity is agnostic of the implementation of these ports. All it knows
    is the interface by which this functionality is exposed. Adapters implement these
    interfaces or ports. The adapter contains all the knowledge to interact with the
    external system. For example, our database port may connect to an adapter that
    provides a database through a PostgreSQL-compatible service. Our entity is unaware
    of Postgres; it could be DynamoDB, SQL Server, MySQL, or any other database engine.
    What’s important is that it exposes the functionality expected by the entity and
    defined in the port. Likewise, our notification port could use SMS email push
    notifications or carrier pigeons; it doesn’t matter to the entity.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们应用的核心中，我们有将副作用和业务逻辑结合在一起的应用代码；这个组合就是我们的实体。副作用通过标准接口暴露，这些接口被称为**端口**。例如，我们可能有持久化端口或通知端口。重要的是，实体对这些端口的实现是透明的。它只知道通过何种接口暴露这些功能。适配器实现这些接口或端口。适配器包含与外部系统交互所需的所有知识。例如，我们的数据库端口可能连接到一个提供PostgreSQL兼容服务的适配器。我们的实体并不知道Postgres；它可以是DynamoDB、SQL
    Server、MySQL或任何其他数据库引擎。重要的是，它暴露了实体所期望的功能，并且这些功能在端口中有定义。同样，我们的通知端口可以使用SMS、电子邮件推送通知或信鸽；这对实体来说并不重要。
- en: 'Similarly, we have ports driven by external adapters for incoming traffic to
    our entity. Whether our entity is triggered by an event from an event queue or
    by a direct HTTP request, we have ports that represent the interface of the request
    and then adapters that connect those ports to our entity. This is a crucial distinction:
    we have driving ports, external forces that act upon our entity, and driven ports,
    which our entity uses to act on external systems.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们有由外部适配器驱动的端口，用于接收来自外部的流量。无论我们的实体是由事件队列中的事件触发，还是由直接的HTTP请求触发，我们都有端口代表请求的接口，然后通过适配器将这些端口连接到我们的实体。这是一个至关重要的区别：我们有驱动端口，它们是作用于实体的外部力量；还有被驱动端口，这是我们的实体用于作用于外部系统的端口。
- en: This might seem unrelated to testing; however, one of the key benefits of this
    architecture pattern is that it makes our entities, our application code, agnostic
    of where it’s being run. The complexity of actually interacting with actual services
    is hidden away in the adapters. Mocking our side effects becomes much easier through
    the simplified interface presented through our ports, as we can produce a new
    adapter that implements the expected behavior rather than trying to mock out cloud
    native services. This also prevents us from tying our unit testing and application
    code to specific libraries or SDKs, as all of that is taken care of in our adapters
    and will eventually be tested through our integration tests.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来与测试无关；然而，这种架构模式的一个关键好处是，它使我们的实体和应用代码与运行环境无关。与实际服务进行交互的复杂性被隐藏在适配器中。通过我们端口提供的简化接口，模拟副作用变得更加容易，因为我们可以创建一个新的适配器来实现预期的行为，而不是尝试模拟云原生服务。这也防止了我们将单元测试和应用代码与特定的库或
    SDK 绑定，因为所有这些都在适配器中处理，并最终通过我们的集成测试进行测试。
- en: 'So, here, we not only get a benefit in the testability of our code but we also
    gain portability of our code if we need to change an integration with an external
    system; it is a simple matter of writing a new adapter that agrees with the interface
    for the existing port. This negates one of the key arguments against writing cloud
    native software: it will cause vendor lock-in. By utilizing hexagonal architecture,
    we can ensure the code we are writing is agnostic of where it’s being run, increasing
    the portion of our code base that will be utilized if we decide to migrate cloud
    providers.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这里，我们不仅能获得代码可测试性的好处，还能在需要更改与外部系统的集成时获得代码的可移植性；这只是编写一个新的适配器来匹配现有端口的接口问题。这样就消除了反对编写云原生软件的一个关键论点：它会导致供应商锁定。通过利用六边形架构，我们可以确保我们编写的代码与运行环境无关，从而增加了如果我们决定迁移云提供商时代码库中可用的部分。
- en: Structuring your code correctly from day one
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从第一天开始就正确构建你的代码结构
- en: We have covered test-driven development in a few sections of this chapter, but
    I want to discuss it in a different context. When we talk about structuring our
    code to be testable and about good structure in general, TDD can help us achieve
    this outcome. If the first thing we write in our code base for new functionality
    is a test, then, by default, the code we write to fulfill this test will be testable
    implicitly.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的几个部分已经涵盖了测试驱动开发（TDD），但我想从不同的角度来讨论它。当我们谈论如何构建可测试的代码以及良好的结构时，TDD 可以帮助我们实现这个目标。如果我们在代码库中为新功能编写的第一件事是一个测试，那么，默认情况下，我们为实现这个测试而编写的代码将会是隐式可测试的。
- en: I will use Java to paint a picture of testable versus untestable code, as it
    has some insidious anti-patterns. Let’s assume we’re testing some business logic,
    and we have a class that contains everything we need for our feature to run. We
    might be tempted to implement our business logic as a private method in this class
    to call it from within our application logic that is exposed to the outside world
    as a public method. If we’re already following some of the practices in this section,
    we might also mark our private business logic method as static to indicate that
    it doesn’t rely on this class’s internal state.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用 Java 来描述可测试代码与不可测试代码的区别，因为它有一些隐蔽的反模式。假设我们正在测试一些业务逻辑，并且我们有一个类，其中包含了运行我们功能所需的一切。我们可能会被诱导将业务逻辑实现为这个类中的一个私有方法，并从对外公开的应用逻辑的公共方法中调用它。如果我们已经遵循了本节中的一些实践，我们可能还会将我们的私有业务逻辑方法标记为静态，以表示它不依赖于该类的内部状态。
- en: Now, it comes time to test our code; of course, the main function we want to
    test is our business logic to ensure that the business rules we are solidifying
    in the code are correctly implemented. However, due to the structure of our class,
    this is one of the least testable parts of our code because it’s private and only
    exposed to our class’s internals.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，到了测试我们的代码的时候；当然，我们想要测试的主要功能是我们的业务逻辑，以确保我们在代码中固化的业务规则得到了正确实现。然而，由于我们类的结构，这部分代码是最难测试的，因为它是私有的，只能在类的内部暴露。
- en: 'What can happen in this scenario is that the developer can be tempted to do
    one of the following:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，开发人员可能会被诱导去做以下事情之一：
- en: Make the method public
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使方法成为公共方法
- en: Test the application code in a way that tests all bounds of business logic
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以一种测试所有业务逻辑边界的方式测试应用代码
- en: The first method is not preferable because we’re changing the visibility of
    class internals specifically for testing purposes. Other people relying on this
    business logic may call it directly from this class, which is not its primary
    purpose, violating the single responsibility principle.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个方法不太可取，因为我们为了测试目的而改变了类内部的可见性。其他依赖该业务逻辑的人可能会直接从这个类中调用它，而这并不是它的主要目的，从而违反了单一职责原则。
- en: The second is not preferable because we are testing the code through a proxy,
    which makes the test brittle to application changes. It also causes us more work
    on the testing side as we have to mock out everything required for the application
    code to run.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个方法也不太可取，因为我们通过代理测试代码，这使得测试对应用程序的变更非常脆弱。它还增加了测试方面的工作量，因为我们必须模拟应用程序代码运行所需的所有内容。
- en: Now, consider if we had written a test that expected a method that would implement
    our business logic. What might our code look like in this scenario? We’re free
    from the constraints of the application so it’s unlikely that we would try to
    test it through the application code. We could make a public method, but it’s
    also likely our application code doesn’t exist yet because we want to refine the
    business logic. So, rather than add it to the class for the application code,
    we instead produce a static class that solely implements our business logic, is
    directly testable, has a single responsibility, and is consumable within our application
    code.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑一下如果我们编写了一个测试，期望某个方法能够实现我们的业务逻辑，那么在这种情况下我们的代码可能会是什么样的呢？我们摆脱了应用程序的约束，因此不太可能通过应用程序代码来测试它。我们可以创建一个公共方法，但也很可能我们的应用程序代码还不存在，因为我们希望完善业务逻辑。所以，我们不将它添加到应用程序代码中的类里，而是创建一个仅实现我们业务逻辑的静态类，该类是直接可测试的，具有单一责任，并且可以在应用程序代码中使用。
- en: Therefore, TDD is not only a tool for writing productive tests but also for
    helping drive well-structured code. This doesn’t mean you need to write every
    test before starting to write code, just that you define the core behavior that
    you want to achieve in advance.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，TDD不仅仅是编写高效测试的工具，它还帮助我们推动代码的良好结构化。这并不意味着你需要在开始编写代码之前编写每个测试，而是提前定义你希望实现的核心行为。
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Testing is one of the greatest tools we have in the cloud native toolbox. It
    prevents regressions, ensures compatibility, and allows us to have more confidence
    that the behavior of our system closely matches the behavior of our mental model.
    Hopefully, you have picked up some tips on how to build meaningful tests without
    blowing your development timelines. Good testing practices are critical to scaling
    cloud native applications, and by avoiding the anti-patterns in this chapter,
    you will be well on your way to deploying quickly and with confidence. We have
    covered a lot so far. Next up, we will look at how to get started on your cloud
    native journey.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 测试是我们在云原生工具箱中最强大的工具之一。它防止回归，确保兼容性，并让我们更有信心地认为系统的行为与我们心中的模型一致。希望你已经获得了一些关于如何在不拖延开发进度的情况下构建有意义测试的技巧。良好的测试实践对于扩展云原生应用至关重要，通过避免本章中的反模式，你将能更快、更有信心地部署应用。到目前为止，我们已经覆盖了很多内容。接下来，我们将探讨如何开始你的云原生之旅。
