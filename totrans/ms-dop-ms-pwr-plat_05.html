<html><head></head><body>
		<div id="_idContainer065">
			<h1 id="_idParaDest-86" class="chapter-number"><a id="_idTextAnchor089"/><st c="0">5</st></h1>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor090"/><st c="2">Streamlining Power Platform Development with DevOps Tooling</st></h1>
			<p><st c="61">In the previous chapter, we created our first Power Platform pipeline using a service principal to deploy our solution from one environment to another. </st><st c="214">This chapter covers the pro-dev DevOps tools that can help us streamline our development process in Power Platform. </st><st c="330">The first tool is </st><strong class="bold"><st c="348">Git</st></strong><st c="351">, a </st><a id="_idIndexMarker501"/><st c="355">distributed version control system that is widely used around the world. </st><st c="428">We will learn about Git repositories, commonly used </st><strong class="bold"><st c="480">Git CLI</st></strong><st c="487"> commands</st><a id="_idIndexMarker502"/><st c="496"> such as </st><strong class="source-inline"><st c="505">clone</st></strong><st c="510">, </st><strong class="source-inline"><st c="512">push</st></strong><st c="516">, </st><strong class="source-inline"><st c="518">pull</st></strong><st c="522">, </st><strong class="source-inline"><st c="524">checkout</st></strong><st c="532">, and more. </st><st c="544">We will also explore how we can manage Power Platform solution plain files and folders in a Git repository and how pull requests and merges are performed even from command lines. </st><st c="723">We then learn about how Power Platform pipelines can be connected to these Git repos. </st><st c="809">We will spend some time on </st><strong class="bold"><st c="836">Power Platform CLI</st></strong><st c="854"> (</st><strong class="bold"><st c="856">PAC CLI</st></strong><st c="863">), which</st><a id="_idIndexMarker503"/><st c="872"> allows us to interact with Power Platform solutions in any script language. </st><st c="949">We will also learn how to create Azure DevOps Services pipelines in </st><strong class="bold"><st c="1017">YAML</st></strong><st c="1021"> (short for </st><strong class="bold"><st c="1033">Yet Another Markup Language</st></strong><st c="1060">) format, and </st><a id="_idIndexMarker504"/><st c="1075">understand the YAML specification itself and relevant methods, such as variables, parameters, and tasks. </st><st c="1180">We will also understand the build tasks provided by Microsoft for Power Platform solutions. </st><st c="1272">Finally, we will learn</st><a id="_idIndexMarker505"/><st c="1294"> how to use </st><strong class="bold"><st c="1306">GitHub Copilot</st></strong><st c="1320">, an AI-powered code completion tool that can help us write code </st><span class="No-Break"><st c="1385">more efficiently.</st></span></p>
			<p><st c="1402">By the end of this chapter, we will have a solid understanding of, and hands-on skills in, how to set up end-to-end CI/CD pipelines with the help of pro-dev DevOps tools such as Azure DevOps pipelines and GitHub Actions, which deliver our solutions to different Power </st><span class="No-Break"><st c="1671">Platform environments.</st></span></p>
			<p><st c="1693">In this chapter, we’re going to cover the following </st><span class="No-Break"><st c="1746">main topics:</st></span></p>
			<ul>
				<li><st c="1758">Git – the single source </st><span class="No-Break"><st c="1783">of truth</st></span></li>
				<li><st c="1791">Power </st><span class="No-Break"><st c="1798">Platform CLI</st></span></li>
				<li><st c="1810">Power Platform build tools for </st><span class="No-Break"><st c="1842">Azure DevOps</st></span></li>
				<li><st c="1854">GitHub Actions for </st><span class="No-Break"><st c="1874">Power Platform</st></span></li>
				<li><st c="1888">Managed pipelines – source </st><span class="No-Break"><st c="1916">control integration</st></span></li>
				<li><st c="1935">Copilots in Power Platform </st><span class="No-Break"><st c="1963">pipeline development</st></span></li>
			</ul>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor091"/><st c="1983">Technical requirements</st></h1>
			<p><st c="2006">To create our first CI/CD pipelines by using pro-dev DevOps tools, we need to have </st><span class="No-Break"><st c="2090">the following:</st></span></p>
			<ul>
				<li><st c="2104">A Power Platform subscription. </st><st c="2136">We can sign up for a Power Apps Developer Plan (</st><a href="https://www.microsoft.com/en-us/power-platform/products/power-apps/free"><st c="2184">https://www.microsoft.com/en-us/power-platform/products/power-apps/free</st></a><st c="2256">) if we already have a Microsoft Entra ID work account. </st><st c="2313">Or, we can join the Microsoft 365 Developer </st><span class="No-Break"><st c="2357">Program (</st></span><a href="https://developer.microsoft.com/en-us/microsoft-365/dev-program"><span class="No-Break"><st c="2366">https://developer.microsoft.com/en-us/microsoft-365/dev-program</st></span></a><span class="No-Break"><span class="P---URL"><st c="2430">)</st></span></span><span class="No-Break"><st c="2432">.</st></span></li>
				<li><st c="2433">An Azure DevOps Services organization: we can create a DevOps organization any time </st><em class="italic"><st c="2518">for free</st></em><st c="2526"> (</st><a href="https://learn.microsoft.com/en-us/azure/devops/user-guide/sign-up-invite-teammates"><st c="2528">https://learn.microsoft.com/en-us/azure/devops/user-guide/sign-up-invite-teammates</st></a><st c="2610">). </st><st c="2614">If we create a public project in Azure DevOps, we get multiple free pipelines and free access to every feature of the service – see the </st><strong class="bold"><st c="2750">Azure DevOps for Open </st></strong><span class="No-Break"><strong class="bold"><st c="2772">Source</st></strong></span><span class="No-Break"><st c="2778"> offering.</st></span></li>
				<li><st c="2788">A GitHub handle and public repository (</st><a href="https://github.com/signup"><st c="2828">https://github.com/signup</st></a><st c="2854">), which is also </st><em class="italic"><st c="2872">free</st></em><st c="2876"> for </st><span class="No-Break"><st c="2881">public repositories.</st></span></li>
				<li><st c="2901">A GitHub Copilot free trial (</st><a href="https://github.com/login?return_to=%2Fgithub-copilot%2Fsignup"><st c="2931">https://github.com/login?return_to=%2Fgithub-copilot%2Fsignup</st></a><st c="2993">) or access to Microsoft </st><span class="No-Break"><st c="3019">Copilot (</st></span><a href="https://copilot.microsoft.com"><span class="No-Break"><st c="3028">https://copilot.microsoft.com</st></span></a><span class="No-Break"><st c="3058">).</st></span></li>
				<li><st c="3061">Visual Studio Code – it is highly recommended to use this free code editor to create, edit, and update the YAML files in this chapter. </st><st c="3197">We can download Visual Studio Code on any platform via </st><a href="https://code.visualstudio.com/download"><st c="3252">https://code.visualstudio.com/download</st></a><st c="3290">, and with the help of the VS Code extensions for Power Platform, Git, Azure DevOps pipelines, and GitHub workflows, we can carry out a syntax highlight and a semantic check on our changes. </st><st c="3480">With the Git extension, we can manage our Git repository, too. </st><st c="3543">See the </st><em class="italic"><st c="3551">Further reading</st></em><st c="3566"> section to learn more about Visual Studio Code. </st><st c="3615">As an alternative, we can directly visit </st><a href="https://vscode.dev"><st c="3656">https://vscode.dev</st></a><st c="3674"> to use the Visual Studio Code editor online in our favorite browser to edit any files and to open a </st><span class="No-Break"><st c="3775">remote repository.</st></span></li>
				<li><st c="3793">The code files for this chapter can be downloaded from our GitHub repo </st><span class="No-Break"><st c="3865">at </st></span><a href="https://github.com/PacktPublishing/Mastering-DevOps-on-Microsoft-Power-Platform/tree/main/Chapter05"><span class="No-Break"><st c="3868">https://github.com/PacktPublishing/Mastering-DevOps-on-Microsoft-Power-Platform/tree/main/Chapter05</st></span></a><span class="No-Break"><st c="3967">.</st></span></li>
			</ul>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor092"/><st c="3968">Git – the single source of truth</st></h1>
			<p><st c="4001">In custom development projects, the source code is maintained in </st><strong class="bold"><st c="4067">version control systems</st></strong><st c="4090">. These</st><a id="_idIndexMarker506"/><st c="4097"> systems let developers work together on the same code base so that they can constantly introduce new features and/or fix bugs without conflicting with the changes of others. </st><st c="4272">One of the reasons we use such code repositories (version control systems) is to provide end-to-end forward and backward traceability between code in production (the running application) and source code changes that have been made before pushing a version to production. </st><st c="4543">In modern DevOps tools, in the project management part, the work items that need to be developed are directly linked to code changes that are made by developers. </st><st c="4705">Version control systems provide a history of items and support transaction-like changes that span over multiple files and folders in repositories. </st><st c="4852">These are very</st><a id="_idIndexMarker507"/><st c="4866"> often represented</st><a id="_idIndexMarker508"/><st c="4884"> as </st><strong class="bold"><st c="4888">version or </st></strong><span class="No-Break"><strong class="bold"><st c="4899">history trees</st></strong></span><span class="No-Break"><st c="4912">.</st></span></p>
			<p><st c="4913">For developers to work in the most effective and efficient way </st><em class="italic"><st c="4977">in parallel</st></em><st c="4988">, version control systems provide branching capabilities. </st><st c="5046">A </st><strong class="bold"><st c="5048">branch</st></strong><st c="5054">, as its name suggests, is a snapshot of a line of code – a fork that then</st><a id="_idIndexMarker509"/><st c="5128"> manages its own history. </st><st c="5154">Changes that we commit (play back) to this branch are not visible from the branch from which our branch was created. </st><st c="5271">The mainline or root – the main branch itself – is presented as a branch in this approach as well. </st><st c="5370">After completing our backlog item in the child branch, we </st><strong class="bold"><st c="5428">merge</st></strong><st c="5433"> back the changes to the parent branch. </st><st c="5473">Branches can be created at any depth, but, in general, we recommend keeping the depth of the branch hierarchy as flat as possible to avoid integration debt later. </st><st c="5636">Branches separate the work in progress from stable and </st><span class="No-Break"><st c="5691">tested code.</st></span></p>
			<p><st c="5703">To maintain and control a healthy development environment, we need to define our branch strategy. </st><st c="5802">A </st><strong class="bold"><st c="5804">branch strategy</st></strong><st c="5819"> is a set of guidelines and best practices for managing branches in a version control system. </st><st c="5913">It helps teams to organize their code base, streamline their development process, and minimize conflicts when merging code. </st><st c="6037">There are several popular branch strategies. </st><st c="6082">It is important for teams to choose a branch strategy that fits their development process and to follow it consistently to ensure smooth collaboration and efficient code management. </st><st c="6264">Let us have a look at the two most popular </st><span class="No-Break"><st c="6307">branch strategies:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="6325">Trunk-based development</st></strong><st c="6349"> is a</st><a id="_idIndexMarker510"/><st c="6354"> version control management practice where developers merge small, frequent updates to a core branch </st><a id="_idIndexMarker511"/><st c="6455">called </st><strong class="bold"><st c="6462">trunk</st></strong><st c="6467"> or </st><strong class="bold"><st c="6471">main</st></strong><st c="6475">. The main characteristic of this approach is that the only long-lived branch is the main branch, which is always deployable. </st><st c="6601">Developers can’t commit changes directly to the main branch, but instead, they work on short-lived branches and merge their changes to the main </st><span class="No-Break"><st c="6745">branch frequently.</st></span></li>
				<li><strong class="bold"><st c="6763">Git Flow / GitHub flow</st></strong><st c="6786"> was originally </st><strong class="bold"><st c="6802">Git Flow</st></strong><st c="6810"> that </st><a id="_idIndexMarker512"/><st c="6816">defined several long-living branches, like </st><a id="_idIndexMarker513"/><st c="6859">release-, hotfix- and patch branches next to the main branch. </st><st c="6921">In the last decade, the software industry has evolved a lot and software development teams usually maintain only one version of software – the latest version. </st><st c="7080">This means that there is no need to maintain such a complex branch hierarchy and this was the reason to move from Git Flow to GitHub flow. </st><strong class="bold"><st c="7219">GitHub flow</st></strong><st c="7230"> is a </st><a id="_idIndexMarker514"/><st c="7236">lightweight, branch-based workflow that supports teams and projects where deployments are made regularly. </st><st c="7342">This workflow is very popular among developers because it allows them to work on new features, bug fixes, or experiments without affecting the main code base. </st><st c="7501">Once the work on a branch is complete, it can be merged back into the main code base through a pull request. </st><st c="7610">GitHub flow is very similar to trunk-based development but contains GitHub-specific capabilities, like </st><span class="No-Break"><st c="7713">pull requests.</st></span></li>
			</ul>
			<p><strong class="bold"><st c="7727">Git</st></strong><st c="7731"> is </st><a id="_idIndexMarker515"/><st c="7735">the most widely used version control system. </st><st c="7780">It is a </st><strong class="bold"><st c="7788">distributed version control system</st></strong><st c="7822">, which</st><a id="_idIndexMarker516"/><st c="7829"> means we can download a repository to our own development machines and, without internet connectivity, we can work on the repo by branching and making changes. </st><st c="7990">Of course, if we would like to propagate our changes back to the team, we need to get connected and then </st><em class="italic"><st c="8095">upload</st></em><st c="8101"> our changes. </st><st c="8115">There are</st><a id="_idIndexMarker517"/><st c="8124"> also </st><strong class="bold"><st c="8130">centralized version control systems</st></strong><st c="8165"> on the market. </st><st c="8181">These require continuous internet connectivity, which slows down the interaction with such repositories </st><span class="No-Break"><st c="8285">in general.</st></span></p>
			<p><st c="8296">Git, a </st><a id="_idIndexMarker518"/><st c="8304">fast, scalable, distributed revision control system is open source. </st><st c="8372">There are many DevOps tools in which the open source Git engine is available, such as GitHub Enterprise, Azure DevOps Services, and GitLab. </st><st c="8512">Of course, these engines are customized in a way that service providers can realize</st><a id="_idIndexMarker519"/><st c="8595"> their own operational approaches and offer Git as a </st><strong class="bold"><st c="8648">Software-as-a-Service</st></strong><st c="8669"> (</st><strong class="bold"><st c="8671">SaaS</st></strong><st c="8675">) offering, but the client APIs are compatible with any of </st><span class="No-Break"><st c="8735">these distributions.</st></span></p>
			<p><st c="8755">In general, version control systems</st><a id="_idIndexMarker520"/><st c="8791"> manage plain text files because these are the files that can be merged by developers in case of conflict resolution (conflicts are readable). </st><st c="8934">Over the course of software history, more and more binary files, such as images, videos, sound files, 3D objects, and media files have become part of software solutions. </st><st c="9104">In the early days of software development, these files were maintained parallel with the code base, although they were also part of the version that was modified/branched by developers. </st><st c="9290">Git already supports large binary</st><a id="_idIndexMarker521"/><st c="9323"> files (</st><strong class="bold"><st c="9331">Git Large File Storage</st></strong><st c="9354">) and large monolith repositories to ease the migration from other version </st><span class="No-Break"><st c="9430">control systems.</st></span></p>
			<p class="callout-heading"><st c="9446">Monolith large repositories</st></p>
			<p class="callout"><st c="9474">Among others, the code base of Microsoft Windows, with its 250 GB, is maintained in one large monolith Git repository in an Azure DevOps </st><span class="No-Break"><st c="9612">Services project.</st></span></p>
			<p><st c="9629">The </st><strong class="bold"><st c="9634">Git command-line interface</st></strong><st c="9660"> (</st><strong class="bold"><st c="9662">CLI</st></strong><st c="9665">) is a</st><a id="_idIndexMarker522"/><st c="9672"> powerful tool that allows developers to interact with Git repositories using a command-line terminal. </st><st c="9775">The Git CLI is available on all major operating systems, including Windows, macOS, and Linux. </st><st c="9869">Some very often used Git commands are </st><span class="No-Break"><st c="9907">the following:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="9921">git clone</st></strong><st c="9931">: This </st><a id="_idIndexMarker523"/><st c="9939">command </st><a id="_idIndexMarker524"/><st c="9947">is used to create a copy of a remote repository on your </st><span class="No-Break"><st c="10003">local machine.</st></span></li>
				<li><strong class="source-inline"><st c="10017">git pull</st></strong><st c="10026">: This</st><a id="_idIndexMarker525"/><st c="10033"> command is used to fetch and merge changes from the remote repository into your </st><span class="No-Break"><st c="10114">local repository.</st></span></li>
				<li><strong class="source-inline"><st c="10131">git push</st></strong><st c="10140">: This </st><a id="_idIndexMarker526"/><st c="10148">command is used to upload your local repository changes (commits and branches) to the </st><span class="No-Break"><st c="10234">remote repository.</st></span></li>
				<li><strong class="source-inline"><st c="10252">git commit</st></strong><st c="10263">: This </st><a id="_idIndexMarker527"/><st c="10271">command is used to save changes to your local repository. </st><st c="10329">It creates a new </st><strong class="source-inline"><st c="10346">commit</st></strong><st c="10352"> object in the repository history with the current state of </st><span class="No-Break"><st c="10412">the repository.</st></span></li>
				<li><strong class="source-inline"><st c="10427">git branch</st></strong><st c="10438">: This </st><a id="_idIndexMarker528"/><st c="10446">command is used to manage branches in a Git repository. </st><st c="10502">It can be used to list, create, delete, and </st><span class="No-Break"><st c="10546">rename branches.</st></span></li>
				<li><strong class="source-inline"><st c="10562">git checkout</st></strong><st c="10575">: This </st><a id="_idIndexMarker529"/><st c="10583">command is used to switch between branches or to restore files in your working directory from </st><span class="No-Break"><st c="10677">the repository.</st></span></li>
				<li><strong class="source-inline"><st c="10692">git merge</st></strong><st c="10702">: This</st><a id="_idIndexMarker530"/><st c="10709"> command is used to merge changes from one branch into another. </st><st c="10773">It integrates changes from the named commits into the</st><a id="_idIndexMarker531"/> <span class="No-Break"><st c="10826">current branch.</st></span></li>
			</ul>
			<p><st c="10842">Normally, we clone a repo, create a local branch, commit our changes, push our branch back to the remote origin, and finally, merge the changes back to the parent branch. </st><st c="11014">This last operation is a special one that is sometimes referred to as a pull request depending on the Git distro, like GitHub or GitLab. </st><st c="11151">We can merge branches without pull </st><span class="No-Break"><st c="11186">requests, too.</st></span></p>
			<p><st c="11200">The </st><strong class="bold"><st c="11205">pull request</st></strong><st c="11217"> is a </st><a id="_idIndexMarker532"/><st c="11223">mechanism for developers to notify team members that they have completed a feature. </st><st c="11307">Once their feature branch is ready, the developer files a pull request via their online repository. </st><st c="11407">The rest of the team then reviews the code and can make comments and suggestions. </st><st c="11489">Once the team agrees that the code is ready, it can be merged into the main code base. </st><st c="11576">Pull requests are a way to </st><em class="italic"><st c="11603">foster code reviews</st></em><st c="11622"> and collaboration within a </st><span class="No-Break"><st c="11650">development team.</st></span></p>
			<p class="callout-heading"><st c="11667">Pull requests</st></p>
			<p class="callout"><st c="11681">Pull requests are</st><a id="_idIndexMarker533"/><st c="11699"> more than just a </st><strong class="source-inline"><st c="11717">git merge</st></strong><st c="11726"> operation. </st><st c="11738">DevOps tools such as GitHub or Azure DevOps Services provide web UI support and their own CLI tools to initiate pull requests </st><span class="No-Break"><st c="11864">on branches.</st></span></p>
			<p><st c="11876">Having understood the key concepts of Git, let us see how it fits with our Power Platform solutions. </st><st c="11978">As we discussed earlier, in </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="12006">Chapter 4</st></em></span></a><st c="12015">, Power Platform solutions</st><a id="_idIndexMarker534"/><st c="12041"> are available in managed and unmanaged formats. </st><st c="12090">Depending on a solution’s content, the difference between managed and unmanaged solutions can vary significantly. </st><st c="12204">For instance, if a solution contains PowerApps application, then a managed one will contain a few files and one of them will be the </st><strong class="source-inline"><st c="12336">msapp</st></strong><st c="12341"> document, which includes every asset of the PowerApps canvas app in compressed format. </st><st c="12429">On the other hand, an unmanaged solution will consist of XML and JSON files in a well-defined folder structure describing the solution with all its assets, such as apps, flows, bots, connection references, and so on, in plain </st><span class="No-Break"><st c="12655">text format.</st></span></p>
			<p><st c="12667">And this is the exact place where version control systems a play significant role, as the following </st><span class="No-Break"><st c="12768">figure illustrates:</st></span></p>
			<div>
				<div id="_idContainer056" class="IMG---Figure">
					<img src="image/B22208_05_1.jpg" alt="Figure 5.1 – Developer environments with corresponding child branches"/><st c="12787"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="12871">Figure 5.1 – Developer environments with corresponding child branches</st></p>
			<p><st c="12940">App makers and developers (</st><strong class="bold"><st c="12968">DevA</st></strong><st c="12973"> and </st><strong class="bold"><st c="12978">DevB</st></strong><st c="12982"> in our case) use dedicated developer environments to craft a solution(s). </st><st c="13057">When the first version of their application is created, they commit both the managed and unmanaged </st><a id="_idIndexMarker535"/><st c="13156">Power Platform solutions – the latter one as unpacked – to their own child branches, created from the main branch. </st><st c="13271">After that, they work on these branches, and respectively in the corresponding environments, by constantly synchronizing the changes between environment and branch. </st><st c="13436">When they are ready, they submit a pull request to merge back the changes from the child branch to the main branch. </st><st c="13552">In an ideal case, there is no merge conflict and the changes are integrated into the main branch smoothly. </st><strong class="bold"><st c="13659">Merge conflicts</st></strong><st c="13674"> are </st><a id="_idIndexMarker536"/><st c="13679">conflicting changes – that is, when the same file in the same position is changed on both parent and child branches. </st><st c="13796">If a merge conflict occurs, then the pull request is refused, and the developer needs to merge the changes back from the main branch to the developer branch and resolve the conflicts there. </st><st c="13986">In the case of Power Platform, it doesn’t mean just resolving conflicts at the code level, but also loading the unmanaged solution back to the developer environment to check everything works as expected and then publishing the changes. </st><st c="14222">After that, we need to export the solution back to the developer branch and resubmit the </st><span class="No-Break"><st c="14311">pull request.</st></span></p>
			<p><st c="14324">Overall, branching and child branches allow developers to work parallelly even on the same Power Platform solution, but we need to pay careful attention and let developers work on different assets </st><span class="No-Break"><st c="14522">in solutions.</st></span></p>
			<p><st c="14535">After getting to know the Git features, let us learn about the tool that we can use to export and import solutions in </st><span class="No-Break"><st c="14654">Power Platform.</st></span></p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor093"/><st c="14669">Power Platform CLI</st></h1>
			<p><st c="14688">We have already seen some of the</st><a id="_idIndexMarker537"/><st c="14721"> PAC CLI commands in the previous chapters, such as signing in to the different environments or installing the Power Platform pipeline as a Dynamics 365 application in our environment. </st><st c="14906">Besides these commands, PAC CLI supports many more commands and features that we can authenticate on behalf of service principals and manage our solutions, environments, deployments, pipelines, and more. </st><st c="15110">One of the biggest advantages of PAC CLI is that it runs on any platform, and can be integrated into any </st><span class="No-Break"><st c="15215">DevOps tool.</st></span></p>
			<p><st c="15227">Some of the most often-used commands of PAC CLI are </st><span class="No-Break"><st c="15280">the following:</st></span></p>
			<ul>
				<li><st c="15294">The </st><strong class="source-inline"><st c="15299">pac admin</st></strong><st c="15308"> command</st><a id="_idIndexMarker538"/><st c="15316"> group provides a set of commands to work with your Power Platform admin account, such as creating an environment, creating service </st><a id="_idIndexMarker539"/><st c="15448">principals, assigning Microsoft Entra ID groups to environments, and </st><span class="No-Break"><st c="15517">so on.</st></span></li>
				<li><st c="15523">The </st><strong class="source-inline"><st c="15528">pac application</st></strong><st c="15543"> command</st><a id="_idIndexMarker540"/><st c="15551"> group is for listing and installing available Dataverse applications from AppSource. </st><st c="15637">We used </st><strong class="source-inline"><st c="15645">pac application install</st></strong><st c="15668"> to deploy Power Platform pipelines as a Dynamics 365 application in our production environment in </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="15767">Chapter 4</st></em></span></a><span class="No-Break"><st c="15776">.</st></span></li>
				<li><st c="15777">The </st><strong class="source-inline"><st c="15782">pac auth</st></strong><st c="15790"> command</st><a id="_idIndexMarker541"/><st c="15798"> group provides a set of commands to authenticate in different services, such as environments or whole tenants. </st><st c="15910">We can use service accounts as well as service principals. </st><st c="15969">Our credentials are stored locally </st><span class="No-Break"><st c="16004">if needed.</st></span></li>
				<li><st c="16014">The </st><strong class="source-inline"><st c="16019">pac canvas</st></strong><st c="16029"> commands </st><a id="_idIndexMarker542"/><st c="16039">work with Power Apps </st><strong class="source-inline"><st c="16060">.msapp</st></strong><st c="16066"> files. </st><st c="16074">These files are created when we export canvas apps from Power Apps Studio directly or as part of our Power </st><span class="No-Break"><st c="16181">Platform solutions.</st></span></li>
				<li><st c="16200">The </st><strong class="source-inline"><st c="16205">pac catalog</st></strong><st c="16216"> command</st><a id="_idIndexMarker543"/><st c="16224"> group provides commands for managing the </st><strong class="bold"><st c="16266">Power Platform catalog</st></strong><st c="16288">, which is a repository for sharing and reusing code and </st><a id="_idIndexMarker544"/><st c="16345">components. </st><st c="16357">Some of the commands available in the </st><strong class="source-inline"><st c="16395">pac catalog</st></strong><st c="16406"> command group include </st><strong class="source-inline"><st c="16429">pac catalog install</st></strong><st c="16448">, which installs a catalog item in the target environment, and </st><strong class="source-inline"><st c="16511">pac catalog list</st></strong><st c="16527">, which lists all published catalog items from the current </st><span class="No-Break"><st c="16586">Dataverse organization.</st></span></li>
				<li><st c="16609">The </st><strong class="source-inline"><st c="16614">pac copilot</st></strong><st c="16625"> command</st><a id="_idIndexMarker545"/><st c="16633"> group provides commands for managing chatbots and AI Builder models (among others, new large language models). </st><st c="16745">Some of the commands available include </st><strong class="source-inline"><st c="16784">pac copilot predict</st></strong><st c="16803">, which sends text or prompts to an AI model, </st><strong class="source-inline"><st c="16849">pac copilot create</st></strong><st c="16867"> for creating a new bot using an existing template file as the reference, and </st><strong class="source-inline"><st c="16945">pac copilot list</st></strong><st c="16961"> for listing virtual agents in the current or target </st><span class="No-Break"><st c="17014">Dataverse environment.</st></span></li>
				<li><st c="17036">The </st><strong class="source-inline"><st c="17041">pac package</st></strong><st c="17052"> command</st><a id="_idIndexMarker546"/><st c="17060"> group is a set of tools and utilities for </st><a id="_idIndexMarker547"/><st c="17103">managing packages. </st><st c="17122">It includes commands such as </st><strong class="source-inline"><st c="17151">pac package add-external-package</st></strong><st c="17183"> for adding a package that is external to the Dataverse solution system to</st><a id="_idIndexMarker548"/><st c="17257"> a </st><strong class="bold"><st c="17260">Package Deployer</st></strong><st c="17276"> project, </st><strong class="source-inline"><st c="17286">pac package add-reference</st></strong><st c="17311"> for adding a reference to a Dataverse solution project, and </st><strong class="source-inline"><st c="17372">pac package add-solution</st></strong><st c="17396"> for adding a prebuilt Dataverse solution file to a Package Deployer project. </st><st c="17474">Please note that, in </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="17495">Chapter 4</st></em></span></a><st c="17504">, we discussed the Package Deployer in the context of Power Platform Enterprise </st><span class="No-Break"><st c="17584">templates, too.</st></span></li>
				<li><st c="17599">The </st><strong class="source-inline"><st c="17604">pac pcf</st></strong><st c="17611"> command group</st><a id="_idIndexMarker549"/><st c="17625"> is used for </st><a id="_idIndexMarker550"/><st c="17638">managing and working with </st><strong class="bold"><st c="17664">Power Apps component framework</st></strong><st c="17694"> (</st><strong class="bold"><st c="17696">PCF</st></strong><st c="17699">) projects. </st><st c="17712">It includes commands such as </st><strong class="source-inline"><st c="17741">pac pcf init</st></strong><st c="17753"> for initializing a new Power Apps component framework project in the current directory, and </st><strong class="source-inline"><st c="17846">pac pcf push</st></strong><st c="17858"> for pushing the component to the Power Apps component framework </st><span class="No-Break"><st c="17923">developer environment.</st></span></li>
				<li><st c="17945">The </st><strong class="source-inline"><st c="17950">pac pipeline</st></strong><st c="17962"> command</st><a id="_idIndexMarker551"/><st c="17970"> group is used to work with Power Platform pipelines. </st><st c="18024">For example, </st><strong class="source-inline"><st c="18037">pac pipeline deploy</st></strong><st c="18056"> is used to start pipeline deployment, while </st><strong class="source-inline"><st c="18101">pac pipeline list</st></strong><st c="18118"> is used to list pipelines in the given environment. </st><st c="18171">This command group provides the option for administrators and ops teams to start deployments in a fully automated way, as we discussed in </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="18309">Chapter 4</st></em></span></a><span class="No-Break"><st c="18318">.</st></span></li>
				<li><st c="18319">The </st><strong class="source-inline"><st c="18324">pac plugin</st></strong><st c="18334"> command</st><a id="_idIndexMarker552"/><st c="18342"> group is used to work with </st><strong class="bold"><st c="18370">Dataverse plug-in</st></strong><st c="18387"> class libraries</st><a id="_idIndexMarker553"/><st c="18403"> in Microsoft Power Platform. </st><st c="18433">For example, </st><strong class="source-inline"><st c="18446">pac plugin init</st></strong><st c="18461"> is used to initialize a directory with a new Dataverse plugin class library, while </st><strong class="source-inline"><st c="18545">pac plugin push</st></strong><st c="18560"> is used to import a plugin into Dataverse. </st><st c="18604">We can use .NET Framework-based plugins to react to Dataverse events on the server side running in the context of the </st><span class="No-Break"><st c="18722">Dataverse engine.</st></span></li>
				<li><st c="18739">The </st><strong class="source-inline"><st c="18744">pac powerpages</st></strong><st c="18758"> command group</st><a id="_idIndexMarker554"/><st c="18772"> is for </st><a id="_idIndexMarker555"/><st c="18780">managing </st><strong class="bold"><st c="18789">Power Pages websites</st></strong><st c="18809"> in the Power Platform tenant. </st><st c="18840">For example, </st><strong class="source-inline"><st c="18853">pac powerpages list</st></strong><st c="18872"> is used to list all </st><a id="_idIndexMarker556"/><st c="18893">Power Pages websites from the current Dataverse environment, while </st><strong class="source-inline"><st c="18960">pac powerpages download</st></strong><st c="18983"> is used to download Power Pages website content from the current Dataverse environment to move it to another environment with </st><strong class="source-inline"><st c="19110">pac </st></strong><span class="No-Break"><strong class="source-inline"><st c="19114">powerpages upload</st></strong></span><span class="No-Break"><st c="19131">.</st></span></li>
				<li><st c="19132">The </st><strong class="source-inline"><st c="19137">pac solution</st></strong><st c="19149"> command group</st><a id="_idIndexMarker557"/><st c="19163"> is used to work</st><a id="_idIndexMarker558"/><st c="19179"> with </st><strong class="bold"><st c="19185">Power Platform solutions</st></strong><st c="19209">. Some of the commands available in the </st><strong class="source-inline"><st c="19249">pac solution</st></strong><st c="19261"> command group include </st><strong class="source-inline"><st c="19284">pac solution init</st></strong><st c="19301">, which initializes an MSBuild-based </st><strong class="source-inline"><st c="19338">cdsproj</st></strong><st c="19345"> file for component framework components; </st><strong class="source-inline"><st c="19387">pac solution add-reference</st></strong><st c="19413">, which adds a reference from the project in the current directory to the project at the specified path; and </st><strong class="source-inline"><st c="19522">pac solution add-solution-component</st></strong><st c="19557">, which adds one or more solution components to the target unmanaged solution in Dataverse. </st><st c="19649">Imports and exports of solutions are also supported by the equivalent </st><strong class="source-inline"><st c="19719">pac </st></strong><span class="No-Break"><strong class="source-inline"><st c="19723">solution</st></strong></span><span class="No-Break"><st c="19731"> commands.</st></span></li>
			</ul>
			<p class="callout-heading"><st c="19741">PAC CLI and Power Platform PowerShell modules</st></p>
			<p class="callout"><st c="19787">PAC CLI is the next-generation command-line tool for Power Platform, which runs on any OS platform. </st><st c="19888">PowerShell admin capabilities are continuously migrated to PAC CLI to reach feature parity in the future. </st><st c="19994">PAC CLI and PowerShell modules are wrappers around the underlying REST API endpoints of </st><span class="No-Break"><st c="20082">Power Platform.</st></span></p>
			<p><st c="20097">To install PAC CLI, we need to have .NET Core 3.1 or later (.NET 6 is recommended) already deployed to our machine. </st><st c="20214">After that, we can execute the following command in our favorite terminal (CMD on Windows, Bash on Linux, or Terminal </st><span class="No-Break"><st c="20332">on macOS):</st></span></p>
			<pre class="console"><st c="20342">
dotnet tool install --global Microsoft.PowerApps.CLI.Tool</st></pre>			<p><st c="20400">Now that we have learned about the breadth and depth of the commands available in PAC CLI, in the next sections, we will understand how this CLI tool is utilized by Azure DevOps Services and </st><span class="No-Break"><st c="20592">GitHub Enterprise.</st></span></p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor094"/><st c="20610">Power Platform build tools for Azure DevOps</st></h1>
			<p><strong class="bold"><st c="20654">Azure Pipelines</st></strong><st c="20670"> stands </st><a id="_idIndexMarker559"/><st c="20678">out as a robust feature within Azure DevOps Services, offering a</st><a id="_idIndexMarker560"/><st c="20742"> comprehensive </st><strong class="bold"><st c="20757">continuous integration</st></strong><st c="20779"> (</st><strong class="bold"><st c="20781">CI</st></strong><st c="20783">) and </st><strong class="bold"><st c="20790">continuous delivery</st></strong><st c="20809"> (</st><strong class="bold"><st c="20811">CD</st></strong><st c="20813">) service. </st><st c="20825">Compatible with your Git provider of choice (GitHub or</st><a id="_idIndexMarker561"/><st c="20879"> Azure DevOps), it enables deployments across various major cloud providers, including Microsoft Azure. </st><st c="20983">This service streamlines the process of building, testing, and deploying your code base. </st><st c="21072">It supports an</st><a id="_idIndexMarker562"/><st c="21086"> extensive array of programming </st><a id="_idIndexMarker563"/><st c="21118">languages and platforms, such as .NET, Java, Node.js, Android, Xcode, and C++, and allows for a variety of testing frameworks and services to be utilized. </st><st c="21273">Additionally, Azure Pipelines enables the execution of scripts in the command line, PowerShell, Bash, or Shell within your </st><span class="No-Break"><st c="21396">automation workflows.</st></span></p>
			<p><st c="21417">Azure Pipelines also provides the infrastructure in which our scripts and pipeline tasks can run. </st><strong class="bold"><st c="21516">Azure Pipelines agents</st></strong><st c="21538"> are</st><a id="_idIndexMarker564"/><st c="21542"> containers (virtual machines in a virtual machine scale set) that execute our jobs (pipeline tasks). </st><st c="21644">Agents are installed in these machines, and they use HTTP outbound connectivity to Azure DevOps endpoints to pull the activities they need </st><span class="No-Break"><st c="21783">to run.</st></span></p>
			<p><st c="21790">There are different types of agents, including Microsoft-hosted agents, self-hosted agents, and Azure Virtual Machine Scale </st><span class="No-Break"><st c="21915">Set agents:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="21926">Microsoft-hosted agents</st></strong><st c="21950"> provide a</st><a id="_idIndexMarker565"/><st c="21960"> hassle-free solution for executing your jobs. </st><st c="22007">These agents are fully managed by Microsoft, ensuring that they are always up to date with the latest virtual machine image specified in your YAML pipeline, without requiring any maintenance or upgrades on </st><span class="No-Break"><st c="22213">our part.</st></span></li>
				<li><strong class="bold"><st c="22222">Self-hosted agents</st></strong><st c="22241"> are those</st><a id="_idIndexMarker566"/><st c="22251"> that we set up and maintain on our own virtual machines. </st><st c="22309">This option provides us with greater control over the machine specifications and the operating system images utilized by </st><span class="No-Break"><st c="22430">the agents.</st></span></li>
				<li><strong class="bold"><st c="22441">Azure Virtual Machine Scale Set agents</st></strong><st c="22480"> are </st><a id="_idIndexMarker567"/><st c="22485">a kind of self-hosted agent that embraces the Virtual Machine Sale Set’s autoscaling features heavily. </st><st c="22588">Azure DevOps scales out and scales in VMs based on the size of </st><span class="No-Break"><st c="22651">pipeline queues.</st></span></li>
			</ul>
			<p><st c="22667">In Azure Pipelines, a </st><strong class="bold"><st c="22690">job</st></strong><st c="22693"> is </st><a id="_idIndexMarker568"/><st c="22697">a series of steps that run sequentially as a unit. </st><st c="22748">Every pipeline has at least one job, and a job is the smallest unit of work that can be scheduled to run. </st><st c="22854">Jobs can be organized into stages, and you can specify conditions and dependencies to control when jobs run. </st><st c="22963">Jobs can run on Microsoft-hosted agents, self-hosted agents, or Azure Virtual Machine Scale Set agents, and can be run directly on the host machine of the agent or in a container. </st><st c="23143">Azure Pipelines supports running jobs in parallel on Linux, macOS, and Windows. </st><st c="23223">You can create and configure pipelines in the Azure DevOps web portal with the classic user interface editor as well as with the latest YAML-based script editor. </st><st c="23385">We prefer the latter because the version control management of these YAML files is also available in </st><span class="No-Break"><st c="23486">that case.</st></span></p>
			<p><st c="23496">The advanced capabilities of </st><a id="_idIndexMarker569"/><st c="23526">Azure Pipelines, like the infrastructure and </st><a id="_idIndexMarker570"/><st c="23571">topology of Microsoft-hosted and self-hosted build agents, are beyond this book, but you can find further information and learning modules in the </st><em class="italic"><st c="23717">Further </st></em><span class="No-Break"><em class="italic"><st c="23725">reading</st></em></span><span class="No-Break"><st c="23732"> section.</st></span></p>
			<p><st c="23741">On top of Azure </st><a id="_idIndexMarker571"/><st c="23758">Pipelines, </st><strong class="bold"><st c="23769">Microsoft Build Tools for Power Platform (Microsoft Power Platform Build Tools for Azure DevOps)</st></strong><st c="23865"> provides additional tasks in Azure DevOps that can be used to automate common build and deployment tasks related to solutions built on Microsoft Power Platform. </st><st c="24027">Some of the available tasks include the </st><strong class="bold"><st c="24067">Power Platform Tool Installer</st></strong><st c="24096">, which installs </st><a id="_idIndexMarker572"/><st c="24113">Power Platform tools (among others, the PAC CLI in the agent). </st><st c="24176">This build task is a mandatory step at the beginning of every build and release pipeline in which we would like to use other Power Platform build tasks. </st><st c="24329">The build tools work for canvas- and model-driven apps, Microsoft Copilot Studio, cloud and desktop flows, Power Pages websites, AI Builder models, custom connectors, and dataflows, for everything that can be added to </st><span class="No-Break"><st c="24547">a solution.</st></span></p>
			<p><st c="24558">Every build task uses PAC CLI under the hood and the Power Platform wrapper provides a common interface for Azure DevOps Pipelines and </st><span class="No-Break"><st c="24694">GitHub Actions:</st></span></p>
			<div>
				<div id="_idContainer057" class="IMG---Figure">
					<img src="image/B22208_05_2.jpg" alt="Figure 5.2 – Power Platform build tools and GitHub Actions architecture"/><st c="24709"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="24793">Figure 5.2 – Power Platform build tools and GitHub Actions architecture</st></p>
			<p><st c="24864">This means that when we </st><a id="_idIndexMarker573"/><st c="24889">use a task such as </st><strong class="source-inline"><st c="24908">PowerPlatformExportSolution@2</st></strong><st c="24937">, then this pipeline task executes the corresponding PAC CLI</st><a id="_idIndexMarker574"/><st c="24997"> command through the wrapper with the appropriate parameters. </st><st c="25059">Let us have a look at a pipeline that exports a managed solution, unpacks it, and publishes it to the build artifacts (see </st><strong class="source-inline"><st c="25182">.pipelines/powerlatform-exportsolution.yml</st></strong><st c="25224"> in the </st><strong class="source-inline"><st c="25232">Chapter05</st></strong><st c="25241"> folder of the </st><span class="No-Break"><st c="25256">GitHub repo):</st></span></p>
			<pre class="source-code"><st c="25269">
trigger:
- none
pool:
  vmImage: ubuntu-latest
steps:
</st><strong class="bold"><st c="25322">- task: PowerPlatformToolInstaller@2</st></strong><st c="25358">
  inputs:
    DefaultVersion: true
</st><strong class="bold"><st c="25388">- task: PowerPlatformExportSolution@2</st></strong><st c="25425">
  inputs:
    authenticationType: 'PowerPlatformSPN'
</st><strong class="bold"><st c="25473">    PowerPlatformSPN: '[Service_Connection_Name]'</st></strong><st c="25518">
    SolutionName: '[Our_Solution_Name]'
    SolutionOutputFile: '$(Build.ArtifactStagingDirectory)/Solution/[Our_Solution_Name].zip'
    Managed: true
    AsyncOperation: false
    MaxAsyncWaitTime: '60'
</st><strong class="bold"><st c="25703">- task: PowerPlatformUnpackSolution@2</st></strong><st c="25740">
  inputs:
    SolutionInputFile: '$(Build.ArtifactStagingDirectory)/Solution/TranslatorSolution.zip'
    SolutionTargetFolder: '$(Build.ArtifactStagingDirectory)/Solution/out'
    SolutionType: 'Managed'
- task: PowerPlatformChecker@2
  inputs:
    </st><strong class="bold"><st c="25970">PowerPlatformSPN: [Service_Connection_Name]'</st></strong><st c="26014">
    FilesToAnalyze: '$(Build.ArtifactStagingDirectory)/Solution/*.zip'
    RuleSet: '0ad12346-e108-40b8-a956-9a8f95ea18c9'
- task: PublishBuildArtifacts@1
  enabled: true
  inputs:
    PathtoPublish: '$(Build.ArtifactStagingDirectory)'
    ArtifactName: 'Translator'
    publishLocation: 'Container'</st></pre>			<p><st c="26290">The </st><strong class="source-inline"><st c="26295">PowerPlatformExportSolution@2</st></strong><st c="26324"> uses a service connection (</st><strong class="source-inline"><st c="26352">PowerPlatformSPN: 'PowerPlatformE5-Default'</st></strong><st c="26396">) to connect to the Dataverse. </st><strong class="bold"><st c="26428">Service connections</st></strong><st c="26447"> allow </st><a id="_idIndexMarker575"/><st c="26454">you to connect to external and remote services to execute tasks in</st><a id="_idIndexMarker576"/><st c="26520"> your pipelines. </st><st c="26537">They provide a way to authenticate and authorize Azure DevOps with external services</st><a id="_idIndexMarker577"/><st c="26621"> so that Azure DevOps can access resources and perform operations on your behalf, or on behalf of service principals. </st><st c="26739">There is a dedicated service connection for </st><span class="No-Break"><st c="26783">Power Platform.</st></span></p>
			<p><st c="26798">We have just discovered how to use the familiar Azure Pipelines YAML-based approach for Power Platform CI/CD, just as we do for other custom </st><span class="No-Break"><st c="26940">development projects.</st></span></p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor095"/><st c="26961">GitHub Actions for Power Platform</st></h1>
			<p><strong class="bold"><st c="26995">GitHub Actions</st></strong><st c="27010"> were</st><a id="_idIndexMarker578"/><st c="27015"> originally designed and developed by the same engineering teams that created the Azure Pipelines after Microsoft had acquired GitHub. </st><st c="27150">At the time of acquisition, GitHub did not even support any of the automation that Azure Pipelines </st><span class="No-Break"><st c="27249">offered developers.</st></span></p>
			<p><st c="27268">That’s why it is not surprising that the GitHub Actions engine, the infrastructure, the agents (runners in GitHub), and the concept are more or less the same as in Azure DevOps. </st><st c="27447">And in some cases, GitHub Actions is even better. </st><st c="27497">It can provide much more trigger conditions than Azure Pipelines. </st><st c="27563">For instance GitHub Actions can react to changes in GitHub issues – in pull request comments, in Wiki pages, and in general to changes to any asset surrounding a GitHub project. </st><st c="27741">These actions are lightweight functions, and the trigger framework can easily be extended </st><span class="No-Break"><st c="27831">with webhooks.</st></span></p>
			<p><st c="27845">GitHub has its own build agents, which are </st><a id="_idIndexMarker579"/><st c="27889">called </st><span class="No-Break"><strong class="bold"><st c="27896">GitHub runners</st></strong></span><span class="No-Break"><st c="27910">.</st></span></p>
			<p><st c="27911">Behind the scenes, the agent runtime, the Windows service, and the Linux/macOS daemon that host GitHub Actions are nearly identical to the runtime used in Azure DevOps Services. </st><st c="28090">GitHub runners are virtual machines that run your GitHub Actions workflows. </st><st c="28166">They are available in two</st><a id="_idIndexMarker580"/><st c="28191"> types: </st><strong class="bold"><st c="28199">GitHub-hosted</st></strong><st c="28212"> and </st><strong class="bold"><st c="28217">self-hosted</st></strong><st c="28228">. For </st><a id="_idIndexMarker581"/><st c="28234">professionals, GitHub offers a range of managed virtual machines with more RAM, CPU, and disk space for customers on GitHub Team and GitHub Enterprise Cloud plans. </st><st c="28398">These larger runners are hosted by GitHub and have the runner application and other preinstalled tools. </st><st c="28502">GitHub-hosted runners make it easy for GitHub Enterprise plan customers to securely connect their CI/CD machines to other DevOps services in the cloud or on-prem, such</st><a id="_idIndexMarker582"/><st c="28669"> as </st><strong class="bold"><st c="28673">Artifactory</st></strong><st c="28684">, </st><strong class="bold"><st c="28686">Nexus</st></strong><st c="28691">, or any</st><a id="_idIndexMarker583"/><st c="28699"> other service, with the help of reserved static IP ranges or by using Azure Virtual Networks. </st><st c="28794">In the case of public GitHub repositories, every month, the first 2,000 minutes of GitHub-hosted runners’ executions are free </st><span class="No-Break"><st c="28920">of charge.</st></span></p>
			<p><st c="28930">For more</st><a id="_idIndexMarker584"/><st c="28939"> granular control, you can also combine runner groups with labels. </st><strong class="bold"><st c="29006">Runner groups</st></strong><st c="29019"> can only have large </st><a id="_idIndexMarker585"/><st c="29040">runners or self-hosted runners as members. </st><st c="29083">This provides professionals with the flexibility to choose the best runner for their specific needs. </st><st c="29184">GitHub runners can also run inside Docker containers. </st><st c="29238">By doing so, we can even easily spin up Kubernetes-based </st><span class="No-Break"><st c="29295">build/deployment farms.</st></span></p>
			<p><st c="29318">Both GitHub runners and Azure DevOps agents are open source projects and welcome contributors from all around the world (see the GitHub repository links under </st><span class="No-Break"><em class="italic"><st c="29478">Further reading</st></em></span><span class="No-Break"><st c="29493">).</st></span></p>
			<p><st c="29496">Regarding the workflow definitions: there are also some differences in YAML tags and keywords, but the main design principles are </st><span class="No-Break"><st c="29627">the same.</st></span></p>
			<p class="callout-heading"><st c="29636">Azure DevOps Services versus GitHub</st></p>
			<p class="callout"><st c="29672">A frequently asked question in the </st><a id="_idIndexMarker586"/><st c="29708">industry is whether Azure DevOps Services or </st><a id="_idIndexMarker587"/><st c="29753">GitHub is the future. </st><st c="29775">The Microsoft strategy at the time of writing is to recommend GitHub for greenfield organizations – organizations who are just starting their DevOps journeys. </st><st c="29934">If an organization already uses Azure DevOps, then Microsoft recommends introducing GitHub only in areas in which it brings a compelling advantage. </st><em class="italic"><st c="30082">This compelling advantage is now GitHub Copilot</st></em><st c="30129">. In the last few years, we have seen that the investment in GitHub features has been 5-10 times greater than in Azure </st><span class="No-Break"><st c="30248">DevOps Services.</st></span></p>
			<p><st c="30264">In the next section, we will look closely at GitHub workflows and actions </st><span class="No-Break"><st c="30339">at work.</st></span></p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor096"/><st c="30347">Managed pipelines – source control integration with Git</st></h1>
			<p><st c="30403">In </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="30407">Chapter 4</st></em></span></a><st c="30416">, we created our</st><a id="_idIndexMarker588"/><st c="30432"> first Power Platform managed pipeline, which deployed our </st><strong class="source-inline"><st c="30491">mpa_ITBase</st></strong><st c="30501"> solution from the developer environment to the production environment using a service principal. </st><st c="30599">In this section, we continue our journey and, based on the lessons learned about PAC CLI, build tools for Azure DevOps Services, and GitHub Actions for Power Platform, we will commit our solution artifacts to a GitHub repository with the help of GitHub Actions for Power Platform and the Dataverse trigger events available in the context of Power </st><span class="No-Break"><st c="30946">Platform pipelines.</st></span></p>
			<p><st c="30965">Let us have a look at the events that we can use in our Power Automate cloud flows in the </st><strong class="source-inline"><st c="31056">Pipelinehost</st></strong><st c="31068"> environment to react to certain changes in </st><span class="No-Break"><st c="31112">deployment pipelines:</st></span></p>
			<ul>
				<li><strong class="source-inline"><st c="31133">OnApprovalStarted</st></strong><st c="31151"> – </st><strong class="source-inline"><st c="31154">OnApprovalCompleted</st></strong><st c="31173">: These events are triggered when there is approval configured in the deployment stage prior to deploying the solution to that stage. </st><st c="31308">We usually use this step to notify release managers or environment owners about the </st><span class="No-Break"><st c="31392">planned deployment.</st></span></li>
				<li><strong class="source-inline"><st c="31411">OnPredeploymentStarted</st></strong><st c="31434"> – </st><strong class="source-inline"><st c="31437">OnPredeploymentCompleted</st></strong><st c="31461">: These events occur prior to releasing our solution to the deployment stage. </st><st c="31540">We can use these events to do some configuration in the target environment, such as updating environment variables and importing (static) data before </st><span class="No-Break"><st c="31690">solution deployment.</st></span></li>
				<li><strong class="source-inline"><st c="31710">OnDeploymentRequested</st></strong><st c="31732"> – </st><strong class="source-inline"><st c="31735">OnDeploymentStarted</st></strong><st c="31754"> – </st><strong class="source-inline"><st c="31757">OnDeploymentCompleted</st></strong><st c="31778">: These events occur over the course of deploying the solution to the </st><span class="No-Break"><st c="31849">deployment stage.</st></span></li>
			</ul>
			<p class="callout-heading"><st c="31866">Dataverse pipeline events</st></p>
			<p class="callout"><st c="31892">Dataverse Power Platform pipeline-related events are triggered in every deployment stage regardless of the number of stages and pipelines. </st><st c="32032">Pipeline triggers provide additional attributes to filter down to the pipeline and to the stage that we are </st><span class="No-Break"><st c="32140">interested in.</st></span></p>
			<p><st c="32154">With the help of these </st><a id="_idIndexMarker589"/><st c="32178">building blocks, we can create different strategies for how we are going to manage our pipelines and how we are going to maintain our solutions outside of Power Platform environments. </st><st c="32362">We should decide </st><span class="No-Break"><st c="32379">the following:</st></span></p>
			<ul>
				<li><st c="32393">Shall we use a separate Git repository per solution? </st><st c="32447">Or, shall we plan to store multiple solutions per Git repository? </st><st c="32513">Do we plan to introduce pipeline templating for </st><span class="No-Break"><st c="32561">reusability purposes?</st></span></li>
				<li><st c="32582">Shall we introduce one Git repository </st><span class="No-Break"><st c="32621">per environment?</st></span></li>
				<li><st c="32637">Do we plan to store the solution artifacts deployed to deployment stages in different </st><span class="No-Break"><st c="32724">child branches?</st></span></li>
				<li><st c="32739">Shall we use pull requests to merge back the latest changes from child branches to the main branch? </st><st c="32840">Shall we use pull request triggers in our pipelines to finish the deployments in production environments? </st><st c="32946">This would also mean that the managed pipelines would not reach the production environment, just the </st><span class="No-Break"><st c="33047">pre-prod/test environments.</st></span></li>
				<li><st c="33074">Do we plan to store only the deployment artifacts that have been successfully deployed to production environments on the main branch? </st><st c="33209">Shall we consider a branching strategy </st><span class="No-Break"><st c="33248">at all?</st></span></li>
			</ul>
			<p><st c="33255">There is no silver bullet to answer these questions since the selected strategy really depends on the maturity level of the organization, the complexity of the project, and the overall DevOps processes </st><span class="No-Break"><st c="33458">defined internally.</st></span></p>
			<p><st c="33477">The following figure illustrates a possible approach to commit the solution to the main branch after deploying to production with the help of a Power </st><span class="No-Break"><st c="33628">Platform pipeline:</st></span></p>
			<div>
				<div id="_idContainer058" class="IMG---Figure">
					<img src="image/B22208_05_3.jpg" alt="Figure 5.3 – Git integration with Power Platform pipelines"/><st c="33646"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="34167">Figure 5.3 – Git integration with Power Platform pipelines</st></p>
			<p><st c="34225">The managed and </st><a id="_idIndexMarker590"/><st c="34242">unmanaged solutions are generated at the beginning of the deployment that we initiated through the Power Platform pipeline. </st><st c="34366">When a managed pipeline runs, other developers cannot queue this pipeline, which guarantees mutual exclusion. </st><st c="34476">The generated artifacts are stored in the Dataverse </st><strong class="source-inline"><st c="34528">DeploymentArtifacts</st></strong><st c="34547"> table of the </st><strong class="source-inline"><st c="34561">Pipelinehost</st></strong><st c="34573"> environment. </st><st c="34587">As the package (managed solution) goes through the pipeline stages (</st><strong class="source-inline"><st c="34655">Test</st></strong><st c="34660"> and </st><strong class="source-inline"><st c="34665">Prod</st></strong><st c="34669"> environment, in our example) the previously mentioned events are triggered. </st><st c="34746">We use the </st><strong class="source-inline"><st c="34757">OnDeploymentCompleted</st></strong><st c="34778"> event to execute our cloud flow, which will dispatch our GitHub workflow through </st><strong class="source-inline"><st c="34860">HTTP POST</st></strong><st c="34869">, and that will download the deployment artifacts and unpack and commit them to the </st><span class="No-Break"><st c="34953">main branch.</st></span></p>
			<p><st c="34965">To be able to download the artifacts from Dataverse, we create a service principal, and we use a Bash script in our GitHub flow to directly call the Dataverse Web API and to download our deployment artifacts through the </st><span class="No-Break"><st c="35186">OData protocol.</st></span></p>
			<p><st c="35201">Let us use PAC CLI to create a service principal that we are going to use in </st><span class="No-Break"><st c="35279">GitHub workflows:</st></span></p>
			<pre class="console"><st c="35296">
# First we need to authenticate
pac auth create
# List our environments to find the URL of the environment hosting our Power Platform pipelines (HOST)
pac admin list
# Create the service principal
pac admin create-service-principal -env &lt;&lt;URL&gt;&gt; -n VersionControlSPN --role "System Administrator"</st></pre>			<p><st c="35592">The last call </st><a id="_idIndexMarker591"/><st c="35607">requires administrative privileges not just in the Power Platform tenant, but in Microsoft Entra ID (the </st><strong class="source-inline"><st c="35712">Application.ReadWrite.Allpermission</st></strong><st c="35747"> role), too. </st><st c="35760">The output of this call contains the client secret, application ID (client), and tenant ID of the app registration, and, respectively, the enterprise application. </st><st c="35923">This command also registers this service principal in Dataverse by adding it as an application user to the environment. </st><st c="36043">We need to save the output of the last command for later usage of the client ID, client secret, and tenant ID in our </st><span class="No-Break"><st c="36160">GitHub workflow:</st></span></p>
			<pre class="console"><st c="36176">
pac admin create-service-principal -env https://org48448b9d.crm4.dynamics.com -n VersionControlSPN
Connected as XXXXXX@YYYYYYY.onmicrosoft.com
Creating Entra ID Application 'VersionControlSPN'... </st><st c="36373">Done
Creating Entra ID Service Principal... </st><st c="36417">Done
Connected to... </st><st c="36438">pipelinehost
Registering Application '7be14619-8224-4235-9c6b-2701fb98f203' with Dataverse... </st><st c="36532">Done
Creating Dataverse system user and assigning role... </st><st c="36590">Done
Application Name         VersionControlSPN
Tenant Id                XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
Application Id           XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
Service Principal Id     XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
Client Secret            YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY
Client Secret Expiration 2025. </st><st c="36866">02. </st><st c="36870">24. </st><st c="36874">16:03:31 +00:00
System User Id           XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX</st></pre>			<p><st c="36941">Having created the service principal with a client ID and client secret, let’s move on to the GitHub workflow that will </st><span class="No-Break"><st c="37062">use them.</st></span></p>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor097"/><st c="37071">GitHub workflows</st></h2>
			<p><st c="37088">It is time to set up </st><a id="_idIndexMarker592"/><st c="37110">GitHub flow in one of our GitHub repositories. </st><st c="37157">We will use </st><strong class="bold"><st c="37169">Visual Studio Code</st></strong><st c="37187"> in the</st><a id="_idIndexMarker593"/><st c="37194"> upcoming steps to create our YAML file. </st><st c="37235">Alternatively, we could use the GitHub UI to create </st><span class="No-Break"><st c="37287">our workflow:</st></span></p>
			<ol>
				<li><st c="37300">Create repository secrets with the names </st><strong class="source-inline"><st c="37342">TENANT_ID</st></strong><st c="37351">, </st><strong class="source-inline"><st c="37353">CLIENT_ID</st></strong><st c="37362">, and </st><strong class="source-inline"><st c="37368">CLIENT_SECRET</st></strong><st c="37381"> in the selected </st><span class="No-Break"><st c="37398">GitHub repository.</st></span></li>
				<li><st c="37416">Create a GitHub flow (with the name </st><strong class="source-inline"><st c="37453">downloadunpackcommitbash.yml</st></strong><st c="37481">) and set its trigger condition </st><span class="No-Break"><st c="37514">to </st></span><span class="No-Break"><strong class="source-inline"><st c="37517">workflow_dispatch</st></strong></span><span class="No-Break"><st c="37534">:</st></span><pre class="source-code"><st c="37536">
name: DownloadUnpackCommitBash
run-name: VersionControlIntegration-Bash
on:
  workflow_dispatch:</st></pre></li>				<li><st c="37631">Introduce input parameters that will be called by the Power Automate </st><span class="No-Break"><st c="37701">cloud flow:</st></span><pre class="source-code"><st c="37712">
    inputs:
      </st><strong class="bold"><st c="37721">artifact_url</st></strong><st c="37733">:
        description: "The URL of the Dataverse record ID for the artifact created by the pipelines."
        </st><st c="37829">required: true
      solution_name:
        description: "Name of the solution in Dataverse"
        required: true
      user_name:
        description: "User name for the commit"
        required: true
      user_email:
        description: "User name email address"
        required: true
      source_branch:
        description: "Branch for the solution commit"
        default: "main"
        required: true
      target_branch:
        description: "Branch to create for the solution"
        required: false
      commit_message:
        description: "Message to provide for the commit"
        default: "test without Dataverse trigger"
        required: true</st></pre></li>				<li><st c="38348">Configure standard permissions and </st><a id="_idIndexMarker594"/><st c="38384">the GitHub-hosted build agent’s </st><span class="No-Break"><st c="38416">operating system:</st></span><pre class="source-code"><st c="38433">
permissions:
  contents: write
jobs:
  export-unpack-commit:
    runs-on: ubuntu-latest</st></pre></li>				<li><st c="38513">Check out the source branch in the </st><span class="No-Break"><st c="38549">build agent:</st></span><pre class="source-code"><st c="38561">
    steps:
      - uses: actions/checkout@v3
        with:
            ref: ${{ github.event.inputs.source_branch }}</st></pre></li>				<li><st c="38648">Create a new branch if the target branch </st><span class="No-Break"><st c="38690">is specified:</st></span><pre class="source-code"><st c="38703">
     # Commit changes to the existing or new branch
     - name: create new branch if specified
       shell: bash
       run: |
        if [ -n "${{ github.event.inputs.target_branch }}" ]; then
              git checkout -b ${{ github.event.inputs.target_branch }} ${{ github.event.inputs.source_branch }}
         fi</st></pre></li>				<li><st c="38968">Execute a </st><a id="_idIndexMarker595"/><st c="38979">Bash script that requests an access token from Microsoft Entra ID with the Dataverse scope using the tenant ID, client ID, and client secret generated by PAC CLI. </st><st c="39142">After getting the token, we reach out to the Dataverse Web API endpoint of our table (</st><strong class="source-inline"><st c="39228">DeploymentArtifacts</st></strong><st c="39248">) and we download the artifact identified by its GUID </st><span class="No-Break"><st c="39303">using </st></span><span class="No-Break"><em class="italic"><st c="39309">curl</st></em></span><span class="No-Break"><st c="39313">:</st></span><pre class="source-code"><st c="39315">
      # Export the solution from the artifact created by pipelines
     - name: download solution from artifact
       env:
           CLIENT_ID: ${{secrets.CLIENT_ID}}
           TENANT_ID: ${{secrets.TENANT_ID}}
           CLIENT_SECRET: ${{secrets.CLIENT_SECRET}}
       shell: bash
       run: |
           aadHost="login.microsoftonline.com"
           #adding $value to the end of the artifact url to download binary content
           url="${{ github.event.inputs.artifact_url }}/\$value"
           dataverseHost=$(echo $url | cut -d'/' -f3)
body="client_id=${CLIENT_ID}&amp;client_secret=${CLIENT_SECRET}&amp;grant_type=client_credentials&amp;scope=https://$dataverseHost/.default"
           OAuthReq=$(curl -s -X POST "https://$aadHost/${TENANT_ID}/oauth2/v2.0/token" -d $body)
            spnToken=$(echo $OAuthReq | jq -r .access_token)
            # Download the managed solution
            response=$(curl -H "Authorization: Bearer $spnToken" \
              -X GET $url \
              -o "${{ github.event.inputs.solution_name }}_managed.zip")
            # Download the unmanaged solution (for now we will need to use string manipulation to get the unmanaged solution URL, until the API provides this value)
            unmanaged_artifact_url=$(echo "$url" | sed 's/artifactfile/artifactfileunmanaged/g')
            response=$(curl -H "Authorization: Bearer $spnToken" \
              -X GET $unmanaged_artifact_url \
              -o "${{ github.event.inputs.solution_name }}.zip")</st></pre></li>				<li><st c="40558">Using the </st><a id="_idIndexMarker596"/><st c="40569">GitHub Power Platform action (</st><strong class="source-inline"><st c="40599">unpack-solution</st></strong><st c="40615">), we unpack the managed and unmanaged versions of the solution to the repository on the </st><span class="No-Break"><st c="40705">build agent:</st></span><pre class="source-code"><st c="40717">
      # Unpack the solution to a folder named as the solution
      - name: unpack solution
        </st><strong class="bold"><st c="40798">uses: microsoft/powerplatform-actions/unpack-solution@v0</st></strong><st c="40854">
        with:
          solution-file: "${{ github.event.inputs.solution_name }}.zip"
          solution-folder: "${{ github.event.inputs.solution_name }}"
          solution-type: 'Both'
          process-canvas-apps: false
          overwrite-files: true</st></pre></li>				<li><st c="41053">Commit the</st><a id="_idIndexMarker597"/><st c="41064"> changes locally in the build agent either into the target branch or into the </st><span class="No-Break"><st c="41142">source branch:</st></span><pre class="source-code"><st c="41156">
      # Commit changes to the existing or new branch
     - name: commit changes
       shell: bash
       run: |
         rm -rf ${{ github.event.inputs.solution_name }}.zip
         rm -rf ${{ github.event.inputs.solution_name }}_managed.zip
         git config user.name ${{ github.event.inputs.user_name }}
         git config user.email ${{ github.event.inputs.user_email }}
         git pull
         git add --all
         git commit -am "${{ github.event.inputs.commit_message }}" --allow-empty</st></pre></li>				<li><st c="41571">Push the changes to the </st><span class="No-Break"><st c="41596">remote origins:</st></span><pre class="source-code"><st c="41611">
     # Push the committed changes to the source branch
     - name: push to branch
       shell: bash
       run: |
         if [ -n "${{ github.event.inputs.target_branch }}" ]; then
           git push origin "${{ github.event.inputs.target_branch }}"
         else
           git push origin "${{ github.event.inputs.source_branch }}"
         fi</st></pre></li>			</ol>
			<p class="callout-heading"><st c="41888">The Dataverse Web API – OData protocol</st></p>
			<p class="callout"><st c="41927">We use the Dataverse</st><a id="_idIndexMarker598"/><st c="41948"> Web API to query Dataverse tables and records using the REST API on the OData protocol. </st><st c="42037">Our GitHub workflow’s input parameter, </st><strong class="source-inline"><st c="42076">artifact_url</st></strong><st c="42088">, expects the following string to get the record identified by its unique identifier, and its column, </st><strong class="source-inline"><st c="42190">ArtifactFile</st></strong> <strong class="source-inline"><st c="42202">https://[</st></strong><st c="42212">. </st><strong class="source-inline"><st c="42214">$Value</st></strong><st c="42220">, refers to the binary content. </st><st c="42252">Since we’re using Bash and Bash treats the </st><strong class="source-inline"><st c="42295">$</st></strong><st c="42296"> sign as a special character, we need to use the escape character (backslash) to add </st><strong class="source-inline"><st c="42381">$value</st></strong><st c="42387"> to the end of the </st><span class="No-Break"><st c="42406">artifact URL.</st></span></p>
			<p><st c="42419">To test our GitHub flow, we can use the </st><strong class="source-inline"><st c="42460">run workflow</st></strong><st c="42472"> command in the GitHub UI by providing the </st><span class="No-Break"><st c="42515">inputs manually:</st></span></p>
			<div>
				<div id="_idContainer059" class="IMG---Figure">
					<img src="image/B22208_05_4.jpg" alt="Figure 5.4 – GitHub – run workflow manually"/><st c="42531"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="43098">Figure 5.4 – GitHub – run workflow manually</st></p>
			<p><st c="43141">Now, we have a GitHub workflow</st><a id="_idIndexMarker599"/><st c="43172"> that can download deployment artifacts and commit them to a child branch or the main branch, based on the input parameters. </st><st c="43297">See </st><strong class="source-inline"><st c="43301">.github/downloadunpackcommitbash.yml</st></strong><st c="43337"> in the </st><strong class="source-inline"><st c="43345">Chapter05</st></strong><st c="43354"> folder of the book’s GitHub repo, which contains the entire GitHub workflow. </st><st c="43432">The same workflow can be realized with PowerShell commands as well. </st><st c="43500">See </st><strong class="source-inline"><st c="43504">.github/</st></strong> <strong class="source-inline"><st c="43512">downloadunpackcommit.yml</st></strong><st c="43537"> in the </st><strong class="source-inline"><st c="43545">Chapter05</st></strong><st c="43554"> folder </st><span class="No-Break"><st c="43562">for details.</st></span></p>
			<p><st c="43574">It is good practice to commit changes first to the feature branch and then to submit a pull request because we never work directly on the main branch. </st><st c="43726">There are normally also branch policies in place that block developers from working directly on the main branch. </st><st c="43839">On the other hand, GitHub workflows can initiate a pull request immediately after creating and committing changes to a </st><span class="No-Break"><st c="43958">feature branch.</st></span></p>
			<p><st c="43973">We can use exactly the same </st><a id="_idIndexMarker600"/><st c="44002">approach in conjunction with the integration of </st><strong class="bold"><st c="44050">Azure DevOps Services</st></strong><st c="44071"> repositories, pipelines, and </st><strong class="bold"><st c="44101">Power Platform managed pipelines</st></strong><st c="44133"> while</st><a id="_idIndexMarker601"/><st c="44139"> keeping the following considerations </st><span class="No-Break"><st c="44177">in mind:</st></span></p>
			<ul>
				<li><st c="44185">Secrets are stored as variables or within variable groups in </st><span class="No-Break"><st c="44247">YAML pipelines.</st></span></li>
				<li><st c="44262">GitHub inputs are mapped to Azure DevOps pipeline variables (</st><span class="No-Break"><st c="44324">not parameters).</st></span></li>
				<li><st c="44341">We can use the same Bash scripts as in the case of our GitHub workflow. </st><st c="44414">There is no need to change anything. </st><st c="44451">Microsoft-hosted build agents support Ubuntu </st><span class="No-Break"><st c="44496">Linux distros.</st></span></li>
				<li><st c="44510">We need to install PowerPlatform Tools by using the Power Platform </st><strong class="source-inline"><st c="44578">build tool</st></strong><st c="44588"> task (</st><strong class="source-inline"><st c="44595">PowerPlatformToolInstaller@2</st></strong><st c="44624">) in the </st><span class="No-Break"><st c="44634">build agent.</st></span></li>
				<li><st c="44646">We need to use the </st><strong class="source-inline"><st c="44666">PowerPlatformUnpackSolution@2</st></strong><st c="44695"> task to unpack </st><span class="No-Break"><st c="44711">the solution.</st></span></li>
			</ul>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor098"/><st c="44724">Dataverse with Power Automate cloud flows</st></h2>
			<p><st c="44766">Having created the DevOps part, let us introduce the</st><a id="_idIndexMarker602"/><st c="44819"> Power Automate cloud flow that will react to the </st><strong class="source-inline"><st c="44869">OnDeploymentCompleted</st></strong><st c="44890"> event in </st><a href="https://make.powerautomate.com"><st c="44900">the appropriate deployment sta</st></a><st c="44930">ge. </st><st c="44935">We’ll create this cloud flow in the </st><span class="No-Break"><strong class="source-inline"><st c="44971">Pipelinehost</st></strong></span><span class="No-Break"><st c="44983"> environment:</st></span></p>
			<ol>
				<li><st c="44996">Visit </st><a href="https://make.powerautomate.com"><st c="45003">https://make.powerautomate.com</st></a><st c="45033"> and select the environment in which our Power Platform </st><span class="No-Break"><st c="45089">pipelines reside.</st></span></li>
				<li><st c="45106">We then go to the </st><strong class="bold"><st c="45125">My Flows</st></strong><st c="45133"> blade, open the </st><strong class="bold"><st c="45150">New Flow</st></strong><st c="45158"> drop-down menu, and click on </st><strong class="bold"><st c="45188">Automated </st></strong><span class="No-Break"><strong class="bold"><st c="45198">Cloud Flow</st></strong></span><span class="No-Break"><st c="45208">.</st></span></li>
				<li><st c="45209">We can name the flow something like </st><strong class="source-inline"><st c="45246">ManagedPipelineOnDeploymentCompletedFlow</st></strong><st c="45286"> and need to pick </st><strong class="bold"><st c="45304">When an action is performed</st></strong><st c="45331"> from Dataverse as the </st><span class="No-Break"><st c="45354">trigger condition.</st></span></li>
				<li><st c="45372">After creating the flow, we need to provide the following values as the parameters of the </st><a id="_idIndexMarker603"/><span class="No-Break"><st c="45463">trigger action:</st></span></li>
			</ol>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="image/B22208_05_5.jpg" alt="Figure 5.5 – Dataverse – When an action is performed"/><st c="45478"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="45750">Figure 5.5 – Dataverse – When an action is performed</st></p>
			<p class="list-inset"><st c="45802">Please note that, here, we’re using the service principal to connect to the underlying Dataverse, which is </st><em class="italic"><st c="45910">not</st></em><st c="45913"> the service principal that we used in the GitHub workflow. </st><st c="45973">This is the service principal that we created in </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="46022">Chapter 4</st></em></span></a><st c="46031">, for the </st><em class="italic"><st c="46041">on-behalf-of</st></em> <span class="No-Break"><st c="46053">pipeline deployment.</st></span></p>
			<ol>
				<li value="5"><st c="46074">We can use the output data (</st><strong class="source-inline"><st c="46103">ActionOutputs</st></strong> <strong class="source-inline"><st c="46117">ArtifactName</st></strong><st c="46130">, </st><strong class="source-inline"><st c="46132">ActionOutputs</st></strong> <strong class="source-inline"><st c="46145">DeploymentPipeIineName</st></strong><st c="46168">, </st><strong class="source-inline"><st c="46170">ActionOutputs</st></strong> <strong class="source-inline"><st c="46183">DeploymentStageName</st></strong><st c="46203">) of the trigger action to introduce multiple conditions to react only on our pipeline (</st><strong class="source-inline"><st c="46292">PipelineToProd</st></strong><st c="46307">) and in the final deployment </st><span class="No-Break"><st c="46338">stage (</st></span><span class="No-Break"><strong class="source-inline"><st c="46345">Production</st></strong></span><span class="No-Break"><st c="46356">).</st></span></li>
				<li><st c="46359">After</st><a id="_idIndexMarker604"/><st c="46365"> introducing these conditions to limit our cloud flow execution only to this managed pipeline, we need to get some additional data from the </st><strong class="source-inline"><st c="46505">DeploymentStageRun</st></strong><st c="46523"> Dataverse table in conjunction with this run (identified by </st><strong class="source-inline"><st c="46584">StageRunId</st></strong><st c="46594">). </st><st c="46598">We use the </st><strong class="bold"><st c="46609">Get </st><a id="_idTextAnchor099"/><st c="46613">a row by ID</st></strong><st c="46624"> action with the </st><strong class="bold"><st c="46641">Row ID</st></strong><st c="46647"> parameter from the trigger activity to get </st><span class="No-Break"><st c="46691">this information:</st></span></li>
			</ol>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/B22208_05_6.jpg" alt="Figure 5.6 – Get a row by ID action"/><st c="46708"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="46949">Figure 5.6 – Get a row by ID action</st></p>
			<ol>
				<li value="7"><st c="46984">Finally, we need to call the REST API endpoint of our GitHub workflow. </st><st c="47056">Since these endpoints are</st><a id="_idIndexMarker605"/><st c="47081"> protected, we need to create a </st><strong class="bold"><st c="47113">GitHub personal access token</st></strong><st c="47141"> with the right scopes (repo and workflow) to access workflows and Git repositories. </st><st c="47226">Then, we can use the </st><strong class="bold"><st c="47247">HTTP action</st></strong><st c="47258"> to</st><a id="_idIndexMarker606"/><st c="47261"> manually dispatch the recently created GitHub workflow. </st><st c="47318">The HTTP action expects the </st><span class="No-Break"><st c="47346">following parameters:</st></span><ul><li><span class="No-Break"><st c="47367">URL: </st></span><span class="No-Break"><strong class="source-inline"><st c="47373">https://api.github.com/repos/[org-name]/[repository]/actions/workflows/downloadunpackcommitbash.yml/dispatches</st></strong></span></li><li><st c="47483">HTTP </st><span class="No-Break"><st c="47489">method: POST</st></span></li><li><span class="No-Break"><st c="47501">Headers</st></span></li></ul><p class="list-inset"><st c="47509">We only</st><a id="_idIndexMarker607"/><st c="47517"> define the </st><strong class="bold"><st c="47529">Authorization</st></strong><st c="47542"> header with a bearer token that is exactly the same as our GitHub personal access token, as the following </st><span class="No-Break"><st c="47649">figure shows:</st></span></p></li>
			</ol>
			<div>
				<div id="_idContainer062" class="IMG---Figure">
					<img src="image/B22208_05_7.jpg" alt="Figure 5.7 – Authorization header with GitHub access token"/><st c="47662"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="47708">Figure 5.7 – Authorization header with GitHub access token</st></p>
			<p class="list-inset"><st c="47766">Please note that we should store the bearer token in an environment variable that is backed by the Azure Key </st><span class="No-Break"><st c="47876">Vault service.</st></span></p>
			<p class="list-inset"><st c="47890">The HTTP payload (body) contains the GitHub workflow’s </st><span class="No-Break"><st c="47946">input parameters:</st></span></p>
			<pre class="source-code"><st c="47963">
{
 "ref": "main",
 "inputs": {
   "artifact_url": "https://[your-env-id].api.crm4.dynamics.com/api/data/v9.0/deploymentartifacts(@{body('Get_a_row_by_ID')?['_artifactid_value']})/artifactfile",
   "solution_name": "mpa_ITBase",
   "user_name": "jovadker",
   "user_email": "jozsef.vadkerti@hotmail.com",
   "source_branch": "main",
   "commit_message": "new version deployed to prod"
 }
}</st></pre>			<p class="list-inset"><st c="48331">The following</st><a id="_idIndexMarker608"/><st c="48345"> figure shows how we apply these parameters within the </st><span class="No-Break"><st c="48400">HTTP action:</st></span></p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B22208_05_8.jpg" alt="Figure 5.8 – HTTP action to dispatch a GitHub workflow"/><st c="48412"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="49054">Figure 5.8 – HTTP action to dispatch a GitHub workflow</st></p>
			<p><st c="49108">When everything </st><a id="_idIndexMarker609"/><st c="49125">comes together, our Power Automate cloud flow should contain the following actions and </st><span class="No-Break"><st c="49212">conditional cases:</st></span></p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B22208_05_9.jpg" alt="Figure 5.9 – End-to-end cloud flow"/><st c="49230"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="49340">Figure 5.9 – End-to-end cloud flow</st></p>
			<p><st c="49374">With this final step, we have accomplished our original plan to save the deployment artifacts of our Power Platform pipeline to a </st><span class="No-Break"><st c="49505">GitHub repository.</st></span></p>
			<p><st c="49523">To close the loop, we can introduce another Power Automate cloud flow that is triggered by the </st><em class="italic"><st c="49619">committed to main</st></em><st c="49636"> or </st><em class="italic"><st c="49640">pull request is submitted</st></em><st c="49665"> GitHub event via webhooks to track the result of the GitHub workflow dispatch REST API call back to our Power Platform </st><em class="italic"><st c="49785">Pipelinehost</st></em><st c="49797"> environment. </st><strong class="bold"><st c="49811">Webhooks</st></strong><st c="49819"> provide a mechanism to register HTTP endpoints as event handlers on</st><a id="_idIndexMarker610"/><st c="49887"> other services. </st><st c="49904">In our case, we can register the Power Automate cloud flow as a webhook on the GitHub side. </st><st c="49996">If a well-defined event happens in GitHub, GitHub will execute all registered webhooks. </st><st c="50084">There are already GitHub </st><a id="_idIndexMarker611"/><st c="50109">connectors available for these types of triggers, such as the </st><em class="italic"><st c="50171">When a pull request is created or modified</st></em><st c="50213"> webhook in the Power Automate </st><span class="No-Break"><st c="50244">cloud flow.</st></span></p>
			<p><st c="50255">Last but not least, it is worth having a look at the differences when we use Azure DevOps Services instead of GitHub in our Dataverse-triggered </st><span class="No-Break"><st c="50400">cloud flow:</st></span></p>
			<ul>
				<li><st c="50411">We need to enable the </st><strong class="source-inline"><st c="50434">Third-party application access via OAuth</st></strong><st c="50474"> checkbox at the organization level under </st><strong class="bold"><st c="50516">Organization Settings</st></strong><st c="50537"> | </st><strong class="bold"><st c="50540">Security</st></strong><st c="50548"> | </st><strong class="bold"><st c="50551">Policies</st></strong><st c="50559"> | </st><strong class="bold"><st c="50562">Application access policies</st></strong><st c="50589"> in Azure DevOps Services to be able to use the available Azure DevOps Services actions in our Power Automate </st><span class="No-Break"><st c="50699">cloud flow</st></span></li>
				<li><st c="50709">We then use the </st><strong class="bold"><st c="50726">Queue a new Build</st></strong><st c="50743"> action under the Azure DevOps connector to execute </st><span class="No-Break"><st c="50795">the pipeline</st></span></li>
				<li><st c="50807">As mentioned earlier, our Azure DevOps pipeline expects the input parameters as variables defined in the </st><span class="No-Break"><strong class="bold"><st c="50913">Variable</st></strong></span><span class="No-Break"><st c="50921"> pane</st></span></li>
				<li><st c="50926">The </st><strong class="bold"><st c="50931">Queue a new build</st></strong><st c="50948"> action passes over the parameters in the </st><span class="No-Break"><st c="50990">following format:</st></span><pre class="source-code"><st c="51007">
{
"artifact_url": "https://[your-env-id].api.crm4.dynamics.com/api/data/v9.0/deploymentartifacts(@{body('Get_a_row_by_ID')?['_artifactid_value']})/artifactfile",
"solution_name": "mpa_ITBase",
"user_name": "jovadker",
"user_email": "jozsef.vadkerti@hotmail.com",
"source_branch": "main",
"commit_message": "new version deployed to prod"
}</st></pre></li>			</ul>
			<p><st c="51346">Awesome job! </st><st c="51360">We have just learned how we can get the two workflow engines to collaborate in order to use the same DevOps principles that we apply every day during custom software </st><span class="No-Break"><st c="51526">development projects.</st></span></p>
			<h1 id="_idParaDest-96"><a id="_idTextAnchor100"/><st c="51547">Copilots in Power Platform pipeline development</st></h1>
			<p><st c="51595">To significantly reduce the pipeline development effort in GitHub or Azure DevOps Services, we can leverage the capabilities </st><a id="_idIndexMarker612"/><st c="51721">of </st><strong class="bold"><st c="51724">Large Language Models</st></strong><st c="51745"> (</st><strong class="bold"><st c="51747">LLMs</st></strong><st c="51751">) such as GPT-4 and the products built upon those models to support developers and DevOps engineers. </st><st c="51853">One of these products is </st><strong class="bold"><st c="51878">GitHub Copilot</st></strong><st c="51892">, which</st><a id="_idIndexMarker613"/><st c="51899"> acts as a pair programmer, – an assistant that can synthesize code based on natural language prompts. </st><st c="52002">GitHub Copilot integrates into Visual Studio Code, Visual Studio, Neovim, and the JetBrains IDE (even in Azure Data Studio) and it is also available directly on the </st><span class="No-Break"><st c="52167">GitHub website.</st></span></p>
			<p><st c="52182">Using the GitHub Copilot inline editor or</st><a id="_idIndexMarker614"/><st c="52224"> the </st><strong class="bold"><st c="52229">GitHub Copilot Chat window</st></strong><st c="52255">, we can prompt the foundation model to create pipelines that use the build tools to interact with our Power Platform environments. </st><st c="52387">The more precise our prompts are, the more accurate GitHub Copilot can synthesize the YAML files. </st><st c="52485">This concept is also referred to</st><a id="_idIndexMarker615"/><st c="52517"> as </st><strong class="bold"><st c="52521">prompt engineering</st></strong><st c="52539">. Here are some real-world prompts for the activities we have carried out in </st><span class="No-Break"><st c="52616">this chapter:</st></span></p>
			<ul>
				<li><em class="italic"><st c="52629">“By using the Microsoft Power Platform build tool, tasks create an Azure DevOps pipeline that exports a solution from the Power Platform environment, unpacks it, and commits the changes in a new branch </st></em><span class="No-Break"><em class="italic"><st c="52832">under main.”</st></em></span></li>
				<li><em class="italic"><st c="52844">“Create a Bash script that gets an access token from Dataverse using AAD app registration and query a Dataverse table </st></em><strong class="source-inline"><st c="52963">DeploymentArtifacts</st></strong><em class="italic"><st c="52982"> row by providing its GUID.” The column with the name “artifactfile” shall be </st></em><span class="No-Break"><em class="italic"><st c="53060">downloaded afterward.”</st></em></span></li>
				<li><em class="italic"><st c="53082">“By using Power Platform GitHub actions, create a GitHub workflow with a trigger condition dispatch that exports a solution from the Power Platform environment, unpacks it, and commits the changes in a new branch </st></em><span class="No-Break"><em class="italic"><st c="53296">under main.”</st></em></span></li>
			</ul>
			<p><st c="53308">If we don’t have access to GitHub Copilot, we can </st><a id="_idIndexMarker616"/><st c="53359">use </st><strong class="bold"><st c="53363">Microsoft Copilot</st></strong><st c="53380"> (</st><a href="https://copilot.microsoft.com"><st c="53382">https://copilot.microsoft.com</st></a><st c="53411">) with our personal account or other LLMs to get some templates and step-by-step instructions on how YAML pipelines should </st><span class="No-Break"><st c="53535">be constructed.</st></span></p>
			<p><st c="53550">Copilot is also available in Power Platform to help us in creating apps, flows, websites, chatbots, and reports more intuitively by using natural language. </st><st c="53707">In the previous example of a Dataverse-triggered workflow, we could use the following prompt in the Power Automate UI </st><a id="_idIndexMarker617"/><st c="53825">in </st><strong class="bold"><st c="53828">Copilot for </st></strong><span class="No-Break"><strong class="bold"><st c="53840">Power Automate</st></strong></span><span class="No-Break"><st c="53854">:</st></span></p>
			<p class="author-quote"><st c="53856">“Create a workflow that is triggered by the “When an action is performed” Dataverse action on Power Platform pipelines with the OnDeploymentCompleted event. </st><st c="54013">If the pipeline is “PipelineToProd” and the deployment stage is Production, call an HTTP action.”</st></p>
			<p><st c="54110">Copilots will soon become an integral part of our daily work. </st><st c="54173">It’s essential for us to develop these skills and acquire new competencies to remain at the forefront </st><span class="No-Break"><st c="54275">of technology.</st></span></p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor101"/><st c="54289">Summary</st></h1>
			<p><st c="54297">In this chapter, we explored the world of Git, the distributed version control system, and discovered how to use PAC CLI to export/import and unpack Power Platform solutions in Git repositories. </st><st c="54493">We also delved into the inner workings of professional DevOps pipelines and saw how build tools such as Azure DevOps tasks and GitHub actions use the underlying PAC CLI to perform actions within provider-hosted or </st><span class="No-Break"><st c="54707">self-hosted agents.</st></span></p>
			<p><st c="54726">In the second half of the chapter, we combined the Power Platform managed pipeline results from </st><a href="B22208_04.xhtml#_idTextAnchor074"><span class="No-Break"><em class="italic"><st c="54823">Chapter 4</st></em></span></a><st c="54832"> with professional DevOps tools and achieved a version control integration directly from managed pipelines. </st><st c="54940">To top it all off, we used GitHub Copilot and Copilot for Power Automate to generate YAML pipelines and Power Automate cloud flows that we had previously </st><span class="No-Break"><st c="55094">created manually.</st></span></p>
			<p><st c="55111">But hold on to your hats, because in the next chapter, we will go even further and delve into YAML techniques to do some real magic with pipeline templates</st><a href="https://code.visualstudio.com/learn"><st c="55267">, GitHub workflow templates, and AL</st></a><st c="55302">M Accelerator for </st><span class="No-Break"><st c="55321">Power Platform.</st></span></p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor102"/><st c="55336">Further reading</st></h1>
			<ul>
				<li><a href="https://github.com/git/git"><st c="55352">Learn about Visual Studio </st></a><span class="No-Break"><st c="55379">Code: </st></span><a href="https://code.visualstudio.com/learn"><span class="No-Break"><st c="55385">https://code.visualstudio.com/learn</st></span></a></li>
				<li><st c="55420">Git open source project – the code base of </st><span class="No-Break"><st c="55464">Git: </st></span><a href="https://github.com/git/git"><span class="No-Break"><st c="55469">https://github.com/git/git</st></span></a></li>
				<li><st c="55495">GitHub </st><span class="No-Break"><st c="55503">flow: </st></span><a href="https://docs.github.com/en/get-started/using-github/github-flow"><span class="No-Break"><st c="55509">https://docs.github.com/en/get-started/using-github/github-flow</st></span></a></li>
				<li><st c="55572">PAC CLI </st><span class="No-Break"><st c="55581">reference: </st></span><a href="https://learn.microsoft.com/en-us/power-platform/developer/cli/reference/"><span class="No-Break"><st c="55592">https://learn.microsoft.com/en-us/power-platform/developer/cli/reference/</st></span></a></li>
				<li><st c="55665">Azure Pipelines learning </st><span class="No-Break"><st c="55691">module: </st></span><a href="https://learn.microsoft.com/en-us/training/modules/explore-azure-pipelines/"><span class="No-Break"><st c="55699">https://learn.microsoft.com/en-us/training/modules/explore-azure-pipelines/</st></span></a></li>
				<li><st c="55774">Integrate Azure </st><span class="No-Break"><st c="55791">pipelines: </st></span><a href="https://learn.microsoft.com/en-us/training/modules/integrate-azure-pipelines/"><span class="No-Break"><st c="55802">https://learn.microsoft.com/en-us/training/modules/integrate-azure-pipelines/</st></span></a></li>
				<li><st c="55879">Azure DevOps Demo </st><span class="No-Break"><st c="55898">Generator: </st></span><a href="https://azuredevopsdemogenerator.azurewebsites.net"><span class="No-Break"><st c="55909">https://azuredevopsdemogenerator.azurewebsites.net</st></span></a></li>
				<li><st c="55959">GitHub Actions learning </st><span class="No-Break"><st c="55984">module: </st></span><a href="https://learn.microsoft.com/en-us/training/modules/introduction-to-github-actions/"><span class="No-Break"><st c="55992">https://learn.microsoft.com/en-us/training/modules/introduction-to-github-actions/</st></span></a></li>
				<li><st c="56074">Implement CI pipelines with Azure DevOps and GitHub </st><span class="No-Break"><st c="56127">Actions: </st></span><a href="https://learn.microsoft.com/en-us/training/paths/az-400-implement-ci-azure-pipelines-github-actions/"><span class="No-Break"><st c="56136">https://learn.microsoft.com/en-us/training/paths/az-400-implement-ci-azure-pipelines-github-actions/</st></span></a></li>
				<li><st c="56236">Build continuous integration (CI) workflows by using GitHub </st><span class="No-Break"><st c="56297">Actions: </st></span><a href="https://learn.microsoft.com/en-us/training/modules/github-actions-ci/"><span class="No-Break"><st c="56306">https://learn.microsoft.com/en-us/training/modules/github-actions-ci/</st></span></a></li>
				<li><st c="56375">Microsoft Power Platform Build Tools for Azure DevOps </st><span class="No-Break"><st c="56430">Services: </st></span><a href="https://learn.microsoft.com/en-us/power-platform/alm/devops-build-tools"><span class="No-Break"><st c="56440">https://learn.microsoft.com/en-us/power-platform/alm/devops-build-tools</st></span></a></li>
				<li><st c="56511">GitHub Actions for Microsoft Power </st><span class="No-Break"><st c="56547">Platform: </st></span><a href="https://learn.microsoft.com/en-us/power-platform/alm/devops-github-actions"><span class="No-Break"><st c="56557">https://learn.microsoft.com/en-us/power-platform/alm/devops-github-actions</st></span></a></li>
				<li><st c="56631">GitHub repository for Power Platform build </st><span class="No-Break"><st c="56675">tools: </st></span><a href="https://github.com/microsoft/powerplatform-build-tools"><span class="No-Break"><st c="56682">https://github.com/microsoft/powerplatform-build-tools</st></span></a></li>
				<li><st c="56736">Azure Pipelines agent source </st><span class="No-Break"><st c="56766">code: </st></span><a href="https://github.com/microsoft/azure-pipelines-agent"><span class="No-Break"><st c="56772">https://github.com/microsoft/azure-pipelines-agent</st></span></a></li>
				<li><st c="56822">GitHub runner source </st><span class="No-Break"><st c="56844">code: </st></span><a href="https://github.com/actions/runner/tree/main/src"><span class="No-Break"><st c="56850">https://github.com/actions/runner/tree/main/src</st></span></a></li>
				<li><st c="56897">Pipeline Integration with </st><span class="No-Break"><st c="56924">GitHub: </st></span><a href="https://learn.microsoft.com/en-us/power-platform/alm/extend-pipelines-github-export"><span class="No-Break"><st c="56932">https://learn.microsoft.com/en-us/power-platform/alm/extend-pipelines-github-export</st></span></a></li>
				<li><st c="57015">Dataverse Web </st><span class="No-Break"><st c="57030">API: </st></span><span class="No-Break"><strong class="source-inline"><st c="57035">https://learn.microsoft.com/en-us/power-apps/developer/data-platform/webapi/overview</st></strong></span></li>
				<li><st c="57119">GitHub Invoke REST </st><span class="No-Break"><st c="57139">API: </st></span><a href="https://docs.github.com/en/rest/actions/workflows?apiVersion=2022-11-28#create-a-workflow-dispatch-event"><span class="No-Break"><st c="57144">https://docs.github.com/en/rest/actions/workflows?apiVersion=2022-11-28#create-a-workflow-dispatch-event</st></span></a></li>
				<li><st c="57248">GitHub Secret </st><span class="No-Break"><st c="57263">Management: </st></span><a href="https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions"><span class="No-Break"><st c="57275">https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions</st></span></a></li>
				<li><st c="57357">GitHub Personal Access </st><span class="No-Break"><st c="57381">Tokens: </st></span><a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens"><span class="No-Break"><st c="57389">https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens</st></span></a></li>
				<li><st c="57504">Power Platform GitHub </st><span class="No-Break"><st c="57527">Connectors: </st></span><a href="https://learn.microsoft.com/en-us/connectors/github/"><span class="No-Break"><st c="57539">https://learn.microsoft.com/en-us/connectors/github/</st></span></a></li>
				<li><st c="57591">Application Connection Policies in Azure DevOps </st><span class="No-Break"><st c="57640">Services: </st></span><a href="https://learn.microsoft.com/en-us/azure/devops/organizations/accounts/change-application-access-policies?view=azure-devops"><span class="No-Break"><st c="57650">https://learn.microsoft.com/en-us/azure/devops/organizations/accounts/change-application-access-policies?view=azure-devops</st></span></a></li>
				<li><st c="57772">Prompt engineering with GitHub </st><span class="No-Break"><st c="57804">Copilot: </st></span><a href="https://learn.microsoft.com/en-us/training/modules/introduction-prompt-engineering-with-github-copilot/"><span class="No-Break"><st c="57813">https://learn.microsoft.com/en-us/training/modules/introduction-prompt-engineering-with-github-copilot/</st></span></a></li>
				<li><st c="57916">OpenAI Prompt </st><span class="No-Break"><st c="57931">Engineering: </st></span><a href="https://platform.openai.com/docs/guides/prompt-engineering"><span class="No-Break"><st c="57944">https://platform.openai.com/docs/guides/prompt-engineering</st></span></a></li>
			</ul>
		</div>
	<div id="charCountTotal" value="58002"/></body></html>