<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer103">
			<h1 id="_idParaDest-281" class="chapter-number"><a id="_idTextAnchor1412"/>11</h1>
			<h1 id="_idParaDest-282"><a id="_idTextAnchor1413"/>Continuous Integration with GitHub Actions and Jenkins</h1>
			<p>In the previous chapters, we looked at individual tools that will help us implement several aspects of modern DevOps. Now, it’s time to look at how we can combine all the tools and concepts we’ve<a id="_idIndexMarker1148"/> learned about and use them to create a <strong class="bold">continuous integration</strong> (<strong class="bold">CI</strong>) pipeline. First, we will introduce a sample microservices-based blogging application, <strong class="bold">Blog App</strong>, and <a id="_idIndexMarker1149"/>then look at some popular open source and SaaS-based tools that can get us started quickly with CI. We<a id="_idIndexMarker1150"/> will begin <a id="_idIndexMarker1151"/>with <strong class="bold">GitHub Actions</strong> and then move on to <strong class="bold">Jenkins</strong> with <strong class="bold">Kaniko</strong>. For every tool, we will implement CI for Blog App. We will try to keep the<a id="_idIndexMarker1152"/> implementations cloud-agnostic. Since we’ve used the <strong class="bold">GitOps</strong> approach <a id="_idIndexMarker1153"/>from the beginning, we will also use the same here. Finally, we will cover some best practices related to <span class="No-Break">build performance.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>The importance <span class="No-Break">of automation</span></li>
				<li>Introduction to the sample microservices-based blogging application – <span class="No-Break">Blog App</span></li>
				<li>Building a CI pipeline with <span class="No-Break">GitHub Actions</span></li>
				<li>Scalable Jenkins on <strong class="bold">Kubernetes</strong> <span class="No-Break">with Kaniko</span></li>
				<li>Automating a build <span class="No-Break">with triggers</span></li>
				<li>Build performance <span class="No-Break">best prac<a id="_idTextAnchor1414"/><a id="_idTextAnchor1415"/>tices</span></li>
			</ul>
			<h1 id="_idParaDest-283"><a id="_idTextAnchor1416"/>Technical requirements</h1>
			<p>For this chapter, you will need to clone the following GitHub repository for some of the <span class="No-Break">exercises: </span><a href="https://github.com/PacktPublishing/Modern-DevOps-Practices-2e"><span class="No-Break">https://github.com/PacktPublishing/Modern-DevOps-Practices-2e</span></a><span class="No-Break">.</span></p>
			<p>Run the following command to clone the repository into your home directory, and <strong class="source-inline">cd</strong> into the <strong class="source-inline">ch11</strong> directory to access the <span class="No-Break">required resources:</span></p>
			<pre class="console">
$ git clone https://github.com/PacktPublishing/Modern-DevOps-Practices-2e.git \
modern-devops
$ cd modern-devops/ch11</pre>			<p>So, let’s <span class="No-Break">get sta<a id="_idTextAnchor1417"/><a id="_idTextAnchor1418"/>rted!</span></p>
			<h1 id="_idParaDest-284"><a id="_idTextAnchor1419"/>The importance of automation</h1>
			<p>Automation is akin to having an efficient team of robots at your disposal, tirelessly handling repetitive, time-consuming, and error-prone tasks. Let’s simplify the significance<a id="_idIndexMarker1154"/> <span class="No-Break">of automation:</span></p>
			<ul>
				<li><strong class="bold">Efficiency</strong>: Think of it as having a magical helper who completes tasks in a fraction of the time you would take. Automation accelerates repetitive tasks, executing actions, processing data, and running commands far more swiftly <span class="No-Break">than humans.</span></li>
				<li><strong class="bold">Consistency</strong>: Humans can tire or become distracted, leading to inconsistencies in task execution. Automation guarantees that tasks are consistently carried out according to predefined rules, every <span class="No-Break">single time.</span></li>
				<li><strong class="bold">Accuracy</strong>: Automation operates without the fatigue or lapses that humans may experience. It adheres to instructions with precision, minimizing the likelihood of errors that could result in <span class="No-Break">costly repercussions.</span></li>
				<li><strong class="bold">Scale</strong>: Whether managing one system or a thousand, automation effortlessly scales operations without additional <span class="No-Break">human resources.</span></li>
				<li><strong class="bold">Cost savings</strong>: By reducing the reliance on manual labor, automation yields significant cost savings in terms of time and <span class="No-Break">human resources.</span></li>
				<li><strong class="bold">Risk reduction</strong>: Certain tasks, such as making data backups and performing security checks, are crucial but can be overlooked or skipped by humans. Automation ensures these tasks are consistently performed, <span class="No-Break">mitigating risks.</span></li>
				<li><strong class="bold">Faster response</strong>: Automation detects and responds to issues in real time. For instance, it can automatically restart a crashed server or adjust resource allocation during high traffic, ensuring uninterrupted <span class="No-Break">user experiences.</span></li>
				<li><strong class="bold">Resource allocation</strong>: Automating routine tasks liberates human resources to concentrate on more strategic and creative endeavors that require critical thinking <span class="No-Break">and decision-making.</span></li>
				<li><strong class="bold">Compliance</strong>: Automation enforces and monitors compliance with policies and regulations, reducing the potential for legal and <span class="No-Break">regulatory complications.</span></li>
				<li><strong class="bold">Data analysis</strong>: Automation processes and analyzes vast data volumes rapidly, enabling data-driven decision-making <span class="No-Break">and insights.</span></li>
				<li><strong class="bold">24/7 operations</strong>: Automation operates tirelessly, 24/7, guaranteeing continuous operations <span class="No-Break">and availability.</span></li>
				<li><strong class="bold">Adaptability</strong>: Automation <a id="_idIndexMarker1155"/>can be reprogrammed to adapt to evolving requirements and environments, making it versatile <span class="No-Break">and future-proof.</span></li>
			</ul>
			<p>In the tech realm, automation is the bedrock of modern IT operations, spanning from automating software deployments to managing cloud resources and configuring network devices. It empowers organizations to streamline processes, enhance reliability, and remain competitive in the fast-paced <span class="No-Break">digital landscape.</span></p>
			<p>In essence, automation resembles an exceedingly efficient, error-free, round-the-clock workforce that empowers individuals and organizations to accomplish more with <span class="No-Break">less <a id="_idTextAnchor1420"/>effort.</span></p>
			<p>To benefit from automation, the <a id="_idIndexMarker1156"/>project management function is quickly diluting, and software development teams are transitioning to Agile teams that deliver in Sprints iteratively. Therefore, if there is a new requirement, we don’t wait for the entire thing to be signed off before we start doing design, development, QA, and so on. Instead, we break software into workable features and deliver them in smaller chunks to get value and customer feedback quickly. That means rapid software development with less risk <span class="No-Break">of failure.</span></p>
			<p>Well, the teams are agile, and they develop software faster. Still, many things in the <strong class="bold">software development life cycle</strong> (<strong class="bold">SDLC</strong>) process<a id="_idIndexMarker1157"/> are conducted manually, such as the fact that some teams generate Code Builds only after completing the entire development for that cycle and later find numerous bugs. It becomes difficult to trace what caused that problem in the <span class="No-Break">first place.</span></p>
			<p>What if you could know the cause of a broken Build as soon as you check the code into source control? What if you understand that the software fails some tests as soon as the builds are executed? Well, that<a id="_idTextAnchor1421"/>’s CI for you in <span class="No-Break">a nutshell.</span></p>
			<p>CI is a <a id="_idIndexMarker1158"/>process through which developers frequently check code into a source code repository, perhaps several times a day. Automated tooling behind the scenes can detect these commits and then build, run some tests, and tell you upfront whether the commit has caused any issues. This means that your developers, testers, product owners, operations team, and everyone comes to know what has caused the problem, and the developer can fix it quickly. This creates a feedback loop in software development. We always had a manual feedback loop within software development, which was slow. So, either you wait a long time before doing your next task or do the wrong thing until you realize it is too late to undo all of that. This adds to the rework effort of everything you have <span class="No-Break">done hitherto.</span></p>
			<p>As we all know, fixing a bug earlier in the SDLC cycle is cheaper than fixing it later. Therefore, CI aims to provide continuous feedback on the code quality early in the SDLC. This saves your developers and the organization a lot of time and money on fixing bugs they detect when most of your code is tested. Therefore, CI helps software development teams develop better <span class="No-Break">software faster.</span></p>
			<p>Since we’ve mentioned Agile, let’s briefly discuss how it compares with DevOps. <a id="_idTextAnchor1422"/>Agile is a way of working and is silent on the tools, techniques, and automation required to achieve it.<a id="_idTextAnchor1423"/> DevOps is <a id="_idIndexMarker1159"/>an extension of the Agile<a id="_idIndexMarker1160"/> mindset and helps you implement it effectively. DevOps focuses heavily on automation and looks at avoiding manual work wherever possible. It also encourages software delivery automation and seeks to amplify or replace traditional tools and frameworks. With the advent of modern DevOps, specific tools, techniques, and best practices simplify the life of a developer, QA, and operator. Modern public cloud platforms and<a id="_idIndexMarker1161"/> DevOps provide teams with ready-to-use dynamic infrastructure that helps businesses reduce the time to market and build scalable, elastic, high-performing infrastructure to keep enterprises live with <span class="No-Break">minimal downtime.</span></p>
			<p>When introducing modern DevOps in the first chapter, we discussed that it usually applies to modern cloud-native applications. I’ve built an example microservices-based Blog App to demonstrate this. We will use this application in this and future chapters of this book to ensure seamless development and delivery of this application using modern DevOps tools and practices. We’ll look at the sample application in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-285"><a id="_idTextAnchor1424"/>Introduction to the sample microservices-based blogging application – Blog App</h1>
			<p>Blog App<a id="_idIndexMarker1162"/> is a sample modern microservices-based blogging web application that allows users to create, manage, and interact with blog posts. It caters to both authors and readers. Users can sign up to this platform using their email addresses and start writing blog posts. Readers can publicly view all blog posts created by several authors, and logged-in users can also provide reviews <span class="No-Break">and ratings.</span></p>
			<p>The application is written in a <a id="_idIndexMarker1163"/>popular Python-based web framework <a id="_idIndexMarker1164"/>called <strong class="bold">Flask</strong> and uses <strong class="bold">MongoDB</strong> as the database. The application is split into several microservices for user, post, review, and rating management. There is a separate frontend microservice that allows for user interaction. Let’s look at <span class="No-Break">each microservice:</span></p>
			<ul>
				<li><strong class="bold">User Management</strong>: The User Management microservice<a id="_idIndexMarker1165"/> provides endpoints to create a user account, update the profile (name and password), and delete a <span class="No-Break">user account.</span></li>
				<li><strong class="bold">Posts Management</strong>: The Posts Management microservice<a id="_idIndexMarker1166"/> provides endpoints to create, list, get, update, and <span class="No-Break">delete posts.</span></li>
				<li><strong class="bold">Reviews Management</strong>: The Reviews Management microservice<a id="_idIndexMarker1167"/> allows users to add reviews on posts and update and delete them. Internally, it interacts with the Ratings Management microservice to manage the ratings provided, along with <span class="No-Break">the reviews.</span></li>
				<li><strong class="bold">Ratings Management</strong>: The Ratings Management microservice<a id="_idIndexMarker1168"/> manages ratings for posts associated with a particular review. This microservice is called from the Reviews Management microservice internally and is not exposed to the <span class="No-Break">Frontend microservice.</span></li>
				<li><strong class="bold">Frontend</strong>: The Frontend microservice<a id="_idIndexMarker1169"/> is a Python Flask user interface application built using <strong class="bold">Bootstrap</strong>, which provides users with a rich and interactive user interface. It <a id="_idIndexMarker1170"/>allows users to sign up, log in, view, and navigate between posts, edit their posts, add and update reviews, and manage their profiles. The microservice interacts with the backend microservices seamlessly using <span class="No-Break">HTTP requests.</span></li>
			</ul>
			<p>The <strong class="bold">users</strong>, <strong class="bold">posts</strong>, <strong class="bold">reviews</strong>, and <strong class="bold">ratings</strong> microservices interact <a id="_idIndexMarker1171"/>with <strong class="bold">MongoDB</strong> as <span class="No-Break">the database.</span></p>
			<p>The following service diagram shows the <a id="_idIndexMarker1172"/><span class="No-Break">interactions graphically:</span></p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B19877_11__1.jpg" alt="Figure 11.1 – Blog App services and interactions" width="1628" height="488"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – Blog App services and interactions</p>
			<p>As we can see, the individual microservices are fairly decoupled from each other and, therefore, can independently scale. It is also robust because the other parts of the application will work if a particular microservice is not working. The individual microservices can be independently developed and deployed as separate components, adding to the application’s flexibility and maintainability. This application is an excellent example of leveraging microservices to build a modern, feature-rich <span class="No-Break">web application.</span></p>
			<p>Now, let’s implement CI for this application. To implement CI, we will need a CI tool. We’ll look at some of the popular tools and the options you ha<a id="_idTextAnchor1425"/><a id="_idTextAnchor1426"/>ve in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-286"><a id="_idTextAnchor1427"/>Building a CI pipeline with GitHub Actions</h1>
			<p><strong class="bold">GitHub Actions</strong> is<a id="_idTextAnchor1428"/> a <a id="_idIndexMarker1173"/>SaaS-based tool that com<a id="_idTextAnchor1429"/>es <a id="_idIndexMarker1174"/>with <strong class="bold">GitHub</strong>. So, when you create your GitHub repository, you get access to this service out of the box. Therefore, GitHub Actions is one of the best tools for people new to CI/CD and who want to get started quickly. GitHub Actions helps you automate tasks, build, test, and deploy your code, and even streamline your workflow, making your life as a developer <span class="No-Break">much easier.</span></p>
			<p>Here’s what GitHub Actions can do <span class="No-Break">for you:</span></p>
			<ul>
				<li><strong class="bold">CI</strong>: GitHub <a id="_idIndexMarker1175"/>Actions can automatically build and test your code whenever you push changes to your repository. This ensures that your code remains error-free and ready <span class="No-Break">for deployment.</span></li>
				<li><strong class="bold">CD</strong>: You can use <a id="_idIndexMarker1176"/>GitHub Actions to deploy your application to various hosting platforms, such as AWS, Azure, and GCP. This allows you to deliver updates to your users quickly <span class="No-Break">and efficiently.</span></li>
				<li><strong class="bold">Workflow automation</strong>: You can create custom <a id="_idIndexMarker1177"/>workflows using GitHub Actions to automate repetitive tasks in your development process. For example, you can automatically label and assign issues, trigger builds on specific events, or send notifications to <span class="No-Break">your team.</span></li>
				<li><strong class="bold">Custom scripts</strong>: GitHub Actions<a id="_idIndexMarker1178"/> allows you to run custom scripts and commands, giving you full control over your automation tasks. Whether you need to compile code, run tests, or execute deployment scripts, GitHub Actions can <span class="No-Break">handle it.</span></li>
				<li><strong class="bold">Community actions</strong>: GitHub Actions<a id="_idIndexMarker1179"/> has a marketplace where you can find pre-built actions created by the community. These actions cover a wide range of tasks, from publishing to <strong class="source-inline">npm</strong> to deploying to popular cloud providers. You can easily incorporate these actions into <span class="No-Break">your workflow.</span></li>
				<li><strong class="bold">Scheduled jobs</strong>: You can <a id="_idIndexMarker1180"/>schedule actions to run at specific times or intervals. This is handy for tasks such as generating reports, sending reminders, or performing maintenance during <span class="No-Break">non-peak hours.</span></li>
				<li><strong class="bold">Multi-platform support</strong>: GitHub Actions<a id="_idIndexMarker1181"/> supports various programming languages, operating systems, and cloud environments, which means you can build and deploy applications for different platforms <span class="No-Break">with ease.</span></li>
				<li><strong class="bold">Integration</strong>: GitHub Actions <a id="_idIndexMarker1182"/>seamlessly integrates with your GitHub repositories, making it a natural extension of your development environment. You can define workflows by using YAML files directly in <span class="No-Break">your repository.</span></li>
			</ul>
			<p>GitHub Actions<a id="_idIndexMarker1183"/> revolutionizes the way developers work by <a id="_idIndexMarker1184"/>automating routine tasks, ensuring code quality, and streamlining the SDLC. It’s a valuable tool for teams and individual developers looking to enhance productivity and mai<a id="_idTextAnchor1430"/>ntain <span class="No-Break">high-quality code.</span></p>
			<p>Now, let’s create a CI pipeline for our <a id="_idIndexMarker1185"/>sample Blog App. Blog App consists of multiple micro<a id="_idTextAnchor1431"/>services, and each microservice runs on an<a id="_idIndexMarker1186"/> individual <strong class="bold">Docker</strong> container. We also have unit tests written for each microservice, which we can run to verify the code changes. If the tests pass, the build will pass; otherwise, it <span class="No-Break">will fail.</span></p>
			<p>To access the resources for this section, <strong class="source-inline">cd</strong> into the <span class="No-Break">following directory:</span></p>
			<pre class="console">
$ cd ~/modern-devops/blog-app</pre>			<p>This directory contains multiple microservices and is structured <span class="No-Break">as follows:</span></p>
			<pre class="console">
.
├── frontend
│   ├── Dockerfile
│   ├── app.py
│   ├── app.test.py
│   ├── requirements.txt
│   ├── static
│   └── templates
├── posts
│   ├── Dockerfile
│   ├── app.py
│   ├── app.test.py
│   └── requirements.txt
├── ratings ...
├── reviews ...
└── users ...</pre>			<p>The <strong class="source-inline">frontend</strong> directory<a id="_idIndexMarker1187"/> contains files for the <strong class="bold">frontend</strong> microservice, and notably, it includes <strong class="source-inline">app.py</strong> (the Flask application code), <strong class="source-inline">app.test.py</strong> (the unit tests for the Flask application), <strong class="source-inline">requirements.txt</strong> (which contains all Python<a id="_idIndexMarker1188"/> modules required by the app), and <strong class="source-inline">Dockerfile</strong>. It also includes a few other directories catering to the user interface elements of <span class="No-Break">this app.</span></p>
			<p>The <strong class="bold">posts</strong>, <strong class="bold">reviews</strong>, <strong class="bold">ratings</strong>, and <strong class="bold">users</strong> microservices have the same structure and contain <strong class="source-inline">app.py</strong>, <strong class="source-inline">app.test.py</strong>, <strong class="source-inline">requirements.txt</strong>, and <span class="No-Break"><strong class="source-inline">Dockerfile</strong></span><span class="No-Break"> files.</span></p>
			<p>So, let’s start by <a id="_idIndexMarker1189"/>switching to the <span class="No-Break"><strong class="source-inline">posts</strong></span><span class="No-Break"> directory:</span></p>
			<pre class="console">
$ cd posts</pre>			<p>As we know that Docker is inherently CI-compliant, we can run the tests using <strong class="source-inline">Dockerfile</strong> itself. Let’s investigate the Dockerfile of the <span class="No-Break">posts service:</span></p>
			<pre class="console">
FROM python:3.7-alpine
ENV FLASK_APP=app.py
ENV FLASK_RUN_HOST=0.0.0.0
RUN apk add --no-cache gcc musl-dev linux-headers
COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt
EXPOSE 5000
COPY . .
RUN python app.test<a id="_idTextAnchor1432"/>.py
CMD ["flask", "run"]</pre>			<p>This <strong class="source-inline">Dockerfile</strong> starts <a id="_idIndexMarker1190"/>with the <strong class="source-inline">python:3.7-alpine</strong> base image, installs the requireme<a id="_idTextAnchor1433"/>nts, and copies the code into the working directory. It<a id="_idIndexMarker1191"/> runs the <strong class="source-inline">app.test.py</strong> unit test to check whether the code would work if we deploy it. Finally, the <strong class="source-inline">CMD</strong> command defines a <strong class="source-inline">flask run</strong> command to run when we launch <span class="No-Break">the </span><span class="No-Break"><a id="_idIndexMarker1192"/></span><span class="No-Break">container.</span></p>
			<p>Let’s build our <strong class="source-inline">Dockerfile</strong> and see what <span class="No-Break">we get:</span></p>
			<pre class="console">
$ docker build --progress=plain -t posts .
#4 [1/6] FROM docker.io/library/python:3.7-alpine
#5 [internal] load build context
#6 [2/6] RUN apk add --no-cache gcc musl-dev linux-headers
#7 [3/6] COPY requirements.txt requirements.txt
#8 [4/6] RUN pip install -r requirements.txt
#9 [5/6] COPY . .
#10 [6/6] RUN python app.test.py
#10 0.676 -------------------------------------------------
#10 0.676 Ran 8 tests in 0.026s
#11 exporting to image
#11 naming to doc<a id="_idTextAnchor1434"/>ker.io/library/posts <a id="_idTextAnchor1435"/>done</pre>			<p>As we can see, it built the container, executed a test on it, and responded with <strong class="source-inline">Ran 8 tests in 0.026s</strong> and an <strong class="source-inline">OK</strong> message. Therefore, we could use <strong class="source-inline">Dockerfile</strong> to build and test this app. We used the <strong class="source-inline">--progress=plain</strong> argument with the <strong class="source-inline">docker build</strong> command. This is because we wanted to see the stepwise output of the logs rather than <a id="_idIndexMarker1193"/>Docker merging progress into a single<a id="_idIndexMarker1194"/> message (this is<a id="_idIndexMarker1195"/> now a <span class="No-Break">default behavior).</span></p>
			<p>Now, let’s look at Git<a id="_idTextAnchor1436"/><a id="_idTextAnchor1437"/>Hub Actions and how we can automate <span class="No-Break">this step.</span></p>
			<h2 id="_idParaDest-287"><a id="_idTextAnchor1438"/>Creating a GitHub repository</h2>
			<p>Before we can use GitHub Actions, we <a id="_idIndexMarker1196"/>need to create a GitHub repository. As we know that each microservice can be independently developed, we will place all of them in separate Git repositories. For this exercise, we will focus only on the <strong class="bold">posts</strong> microservice and leave the rest to you as <span class="No-Break">an exercise.</span></p>
			<p>To do so, go to <a href="https://github.com/new">https://github.com/new</a> and create a new repository. Give it an appropriate name. For this exercise, I am going to <span class="No-Break">use </span><span class="No-Break"><strong class="source-inline">mdo-posts</strong></span><span class="No-Break">.</span></p>
			<p>Once you’ve created it, clone the repository by using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ git clone https://github.com/&lt;GitHub_Username&gt;/mdo-posts.git</pre>			<p>Then, change the directory into the repository directory and copy the <strong class="source-inline">app.py</strong>, <strong class="source-inline">app.test.py</strong>, <strong class="source-inline">requirements.txt</strong>, and <strong class="source-inline">Dockerfile</strong> files into the repository’s directory using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cd mdo-posts
$ cp ~/modern-devops/blog-app/posts/* .</pre>			<p>Now, we need to create a GitHub Actions wo<a id="_idTextAnchor1439"/><a id="_idTextAnchor1440"/>rkflow file. We’ll do this in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-288"><a id="_idTextAnchor1441"/>Creating a GitHub Actions workflow</h2>
			<p>A GitHub Actions workflow<a id="_idIndexMarker1197"/> is a simple YAML file that contains the build steps. We must create this workflow in the <strong class="source-inline">.github/workflows</strong> directory within the repository. We can do this using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ mkdi<a id="_idTextAnchor1442"/>r -p .github/workflows</pre>			<p>We will use the following<a id="_idIndexMarker1198"/> GitHub Actions workflow file, <strong class="source-inline">build.yaml</strong>, for <span class="No-Break">this exercise:</span></p>
			<pre class="console">
name: Build and Test App
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Login to Docker Hub
      id: login
      run: docker login -u ${{ secrets.DOCKER_USER  }} -p ${{ secrets.DOCKER_PASSWORD }}
    - name: Build the Docker image
      id: build
      run: docker build . --file Dockerfile --tag ${{ secrets.DOCKER_USER  }}/
mdo-posts:$(git rev-parse --short "$GITHUB_SHA")
    - name: Push the Docker image
      id: push
      run: docker push ${{ secrets.DOCKER_USER  }}/mdo-posts<a id="_idTextAnchor1443"/>:$(git rev-parse --short 
"$GITHUB_SHA")</pre>			<p>This file comprises<a id="_idIndexMarker1199"/> <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="source-inline">name</strong>: The workflow’s name – <strong class="source-inline">Build and Test App</strong> in <span class="No-Break">this case.</span></li>
				<li><strong class="source-inline">on</strong>: This describes when this workflow will run. In this case, it will run if a <strong class="source-inline">push</strong> or <strong class="source-inline">pull</strong> request is sent on the <span class="No-Break"><strong class="source-inline">main</strong></span><span class="No-Break"> branch.</span></li>
				<li><strong class="source-inline">jobs</strong>: A GitHub Actions workflow contains one or more jobs that run in parallel by default. This attribute includes <span class="No-Break">all jobs.</span></li>
				<li><strong class="source-inline">jobs.build</strong>: This is a job that does the <span class="No-Break">container build.</span></li>
				<li><strong class="source-inline">jobs.build.runs-on</strong>: This describes where the build job will run. We’ve specified <strong class="source-inline">ubuntu-latest</strong> here. This means that this job will run on an <span class="No-Break">Ubuntu VM.</span></li>
				<li><strong class="source-inline">jobs.build.steps</strong>: This consists of the steps that run sequentially within the job. The build job consists of four build steps: <strong class="source-inline">checkout</strong>, which will check out the code from your repository; <strong class="source-inline">login</strong>, which will log in to Docker Hub; <strong class="source-inline">build</strong>, which will run a Docker build on your code; and <strong class="source-inline">push</strong>, which will push your Docker image<a id="_idIndexMarker1200"/> to <strong class="bold">Docker Hub</strong>. Note that we tag the image with the Git commit SHA. This relates the build with the commit, making Git the single source <span class="No-Break">of truth.</span></li>
				<li><strong class="source-inline">jobs.build.steps.uses</strong>: This is the first step and describes an action you will run as a part of your job. Actions are reusable pieces of code that you can execute in your pipeline. In this case, it runs the <strong class="source-inline">checkout</strong> action. It checks out the code from the current branch where the action <span class="No-Break">is triggered.</span></li>
			</ul>
			<p class="callout-heading">Tip</p>
			<p class="callout">Always use a version with your actions. This will prevent your build from breaking if a later version is incompatible with <span class="No-Break">your pipeline.</span></p>
			<ul>
				<li><strong class="source-inline">jobs.build.steps.name</strong>: This is the<a id="_idIndexMarker1201"/> name of your <span class="No-Break">build step.</span></li>
				<li><strong class="source-inline">jobs.build.steps.id</strong>: This is the unique identifier of your <span class="No-Break">build step.</span></li>
				<li><strong class="source-inline">jobs.build.steps.run</strong>: This is the command it executes as part of the <span class="No-Break">build step.</span></li>
			</ul>
			<p>The workflow also contains variables within <strong class="source-inline">${{ }}</strong>. We can define multiple variables within the workflow and use them in the subsequent steps. In this case, we’ve used two variables – <strong class="source-inline">${{ secrets.DOCKER_USER }}</strong> and <strong class="source-inline">${{ secrets.DOCKER_PASSWORD }}</strong>. These variables are<a id="_idIndexMarker1202"/> sourced from <span class="No-Break"><strong class="bold">GitHub secrets</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">It is best practice to use GitHub secrets to store sensitive information. Never store these d<a id="_idTextAnchor1444"/>etails directly in the repository <span class="No-Break">with code.</span></p>
			<p>You must define two secrets within your repository using the following <span class="No-Break">URL: </span><span class="No-Break"><strong class="source-inline">https://github.com/&lt;your_user&gt;/mdo-posts/settings/secrets/actions</strong></span><span class="No-Break">.</span></p>
			<p>Define two secrets within <span class="No-Break">the repository:</span></p>
			<pre class="console">
DOCKER_USER=&lt;Your Docker Hub username&gt;
DOCKER_PASSWORD=&lt;Your Docker Hub password&gt;</pre>			<p>Now, let’s move this <strong class="source-inline">build.yml</strong> file to the <strong class="source-inline">workflows</strong> directory by using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ mv build.yml .github/workflows/</pre>			<p>Now, we’re <a id="_idIndexMarker1203"/>ready to push this code to GitHub. Run the following commands to commit and push the changes to your <span class="No-Break">GitHub repository:</span></p>
			<pre class="console">
$ git add --all
$ git commit -m 'Initial commit'
$ git push</pre>			<p>Now, go to the <strong class="bold">Workflows</strong> tab of your GitHub repository by visiting <strong class="source-inline">https://github.com/&lt;your_user&gt;/mdo-posts/action<a id="_idTextAnchor1445"/>s</strong>. You should see something similar to <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B19877_11__2.jpg" alt="Figure 11.2 – GitHub Actions" width="576" height="446"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">F<a id="_idTextAnchor1446"/>igure 11.2 – GitHub Actions</p>
			<p>As we can see, GitHub <a id="_idIndexMarker1204"/>has run a build using our workflow file, and it has built the code<a id="_idIndexMarker1205"/> and pushed the image to <strong class="bold">Docker Hub</strong>. Upon visiting your Docker Hub accou<a id="_idTextAnchor1447"/>nt, you should see your image present in <span class="No-Break">your account:</span></p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B19877_11__3.jpg" alt="Figure 11.3 – Docker Hub image" width="1162" height="717"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – Docker Hub image</p>
			<p>Now, let’s try to break our <a id="_idIndexMarker1206"/>code somehow. Let’s suppose that someone from your team changed the <strong class="source-inline">app.py</strong> code, and instead of returning <strong class="source-inline">post</strong> in the <strong class="source-inline">create_post</strong> response, it started returning <strong class="source-inline">pos</strong>. Let’s see what would happen in <span class="No-Break">that scenario.</span></p>
			<p>Make the following changes to the <strong class="source-inline">create_post</strong> function in the <span class="No-Break"><strong class="source-inline">app.py</strong></span><span class="No-Break"> file:</span></p>
			<pre class="console">
@app.route('/posts', methods=['POST'])
def create_post():
    ...
    return jsonify({'pos': str(inserted_post.inserted_id)}), 201</pre>			<p>Now, commit and push the code to GitHub using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ git add --all
$ git commit -m 'Updated create_<a id="_idTextAnchor1448"/>post'
$ git push</pre>			<p>Now, go to GitHub <a id="_idIndexMarker1207"/>Actions and find the latest build. You will see that <a id="_idTextAnchor1449"/>the build will error out and give the <span class="No-Break">following output:</span></p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B19877_11__4.jpg" alt="Figure 11.4 – GitHub Actions – build failure" width="1160" height="620"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.4 – GitHub Actions – build failure</p>
			<p>As we can <a id="_idIndexMarker1208"/>see, the <strong class="bold">Build the Docker image</strong> step has failed. If you click on the step and scroll down to see what happened with it, you will find that the <strong class="source-inline">app.test.py</strong> execution failed. This is because of a test case failure with <strong class="source-inline">AssertionError: 'post' not found in {'pos': '60458fb603c395f9a81c9f4a'}</strong>. As the expected <strong class="source-inline">post</strong> key was not found in the output, <strong class="source-inline">{'pos': '60458fb603c395f9a81c9f4a'}</strong>, the <a id="_idTextAnchor1450"/>test case failed, as shown in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B19877_11__5.jpg" alt="Figure 11.5 – GitHub Actions – test failure" width="1179" height="974"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figur<a id="_idTextAnchor1451"/>e 11.5 – GitHub Actions – test failure</p>
			<p>We uncovered the error <a id="_idIndexMarker1209"/>when someone pushed the buggy code to the Git repository. Are you able to see the benefits of <span class="No-Break">CI already?</span></p>
			<p>Now, let’s fix the code and commit the <span class="No-Break">code again.</span></p>
			<p>Modify the <strong class="source-inline">create_post</strong> function of <strong class="source-inline">app.py</strong> so that it looks <span class="No-Break">as follows:</span></p>
			<pre class="console">
@app.route('/posts', methods=['POST'])
def create_post():
    ...
    return jsonify({'post': str(inserted_post.inserted_id)}), 201</pre>			<p>Then, <strong class="source-inline">commit</strong> and <strong class="source-inline">push</strong> the code to GitHub using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ git add --all
$ git commit -m 'Updated create_po<a id="_idTextAnchor1452"/>st'
$ git push</pre>			<p>This time, the build <a id="_idIndexMarker1210"/>will <span class="No-Break">be successful:</span></p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B19877_11__6.jpg" alt="Figure 11.6 – GitHub Actions – build success" width="566" height="429"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.6 – GitHub Actions – build success</p>
			<p>Did you see how simple this was? We got started with CI quickly and implemented GitOps behind the scenes since the config file required to build and test the code also resided with the <span class="No-Break">application code.</span></p>
			<p>As an exercise, repeat the same process for the <strong class="bold">reviews</strong>, <strong class="bold">users</strong>, <strong class="bold">ratings</strong>, and <strong class="bold">frontend</strong> microservices. You can play around<a id="_idTextAnchor1453"/> with them to understand how <span class="No-Break">it works.</span></p>
			<p>Not everyone uses GitHub, so the SaaS offering might not be an option for them. Therefore, in the next section, we’l<a id="_idTextAnchor1454"/><a id="_idTextAnchor1455"/>l look at the most popular open source CI <span class="No-Break">tool: Jenkins.</span></p>
			<h1 id="_idParaDest-289"><a id="_idTextAnchor1456"/>Scalable Jenkins on Kubernetes with Kaniko</h1>
			<p>Imagine you’re running a workshop where you build all sorts of machines. In this workshop, you have a magical conveyor belt called Jenkins for assembling these machines. But to make your workshop even more efficient and adaptable, you’ve got a team of tiny robot workers called Kaniko that assist in constructing the individual parts of each machine. Let’s draw parallels between this workshop analogy and the <span class="No-Break">technology world:</span></p>
			<ul>
				<li><strong class="bold">Scalable Jenkins</strong>: Jenkins<a id="_idIndexMarker1211"/> is a widely <a id="_idIndexMarker1212"/>used automation server that helps automate various tasks, particularly those related to building, testing, and deploying software. “Scalable Jenkins” means configuring Jenkins in a way that allows it to efficiently handle a growing workload, much like having a spacious workshop capable of producing <span class="No-Break">numerous machines.</span></li>
				<li><strong class="bold">Kubernetes</strong>: Think of Kubernetes<a id="_idIndexMarker1213"/> as the workshop manager. It’s an orchestration platform that automates the process of deploying, scaling, and managing containerized applications. Kubernetes ensures that Jenkins and the team of tiny robots (Kaniko) work seamlessly together and can adapt to <span class="No-Break">changing demands.</span></li>
				<li><strong class="bold">Kaniko</strong>: Kaniko<a id="_idIndexMarker1214"/> is equivalent to your team of miniature robot workers. In the context of containerization, Kaniko is a tool that aids in building container images, which are akin to the individual parts of your machines. What makes Kaniko special is that it can do this without needing elevated access to the Docker daemon. Unlike traditional container builders, Kaniko doesn’t require special privileges, making it a more secure choice for constructing containers, especially within a <span class="No-Break">Kubernetes environment.</span></li>
			</ul>
			<p>Now, let’s combine the three tools and see what we <span class="No-Break">can achieve:</span></p>
			<ul>
				<li><strong class="bold">Building containers at scale</strong>: Your workshop can manufacture multiple machines simultaneously, thanks to Jenkins and the tiny robots. Similarly, with Jenkins on Kubernetes using Kaniko, you can efficiently and concurrently create container images. This ability to scale is crucial in modern application development, where containerization plays a <span class="No-Break">pivotal role.</span></li>
				<li><strong class="bold">Isolation and security</strong>: Just as Kaniko’s tiny robots operate within a controlled environment, Kaniko ensures that container image building takes place in an isolated and secure manner within a Kubernetes cluster. This means that different teams or projects can use Jenkins and Kaniko without interfering with each other’s <span class="No-Break">container-building processes.</span></li>
				<li><strong class="bold">Consistency and automation</strong>: Similar to how the conveyor belt (Jenkins) guarantees consistent machine assembly, Jenkins on Kubernetes with Kaniko ensures uniform container image construction. Automation is at the heart of this setup, simplifying the process of building and managing container images <span class="No-Break">for applications.</span></li>
			</ul>
			<p>To summarize, scalable Jenkins on Kubernetes with Kaniko refers to the practice of setting up Jenkins to efficiently build and manage container images using Kaniko within a Kubernetes environment. It enables consistent, parallel, and secure construction of container images, aligning perfectly with modern software <span class="No-Break">development workflows.</span></p>
			<p>So, the analogy of a workshop with Jenkins, Kubernetes, and Kaniko vividly illustrates how this setup streamlines container image building, making it scalable, efficient, and secure for contemporary software development practic<a id="_idTextAnchor1457"/>es. Now, let’s dive deeper <span class="No-Break">into Jenkins.</span></p>
			<p><strong class="bold">Jenkins</strong> is the <a id="_idIndexMarker1215"/>most popular CI tool available in the market. It is open source, simple to install, and runs with ease. It is a Java-based tool with a plugin-based architecture designed to support several integrations, such as with a source code management tool such as <em class="italic">Git</em>, <em class="italic">SVN</em>, and <em class="italic">Mercurial</em>, or with popular artifact repositories such as <em class="italic">Nexus</em> and <em class="italic">Artifactory</em>. It also integrates well with well-known build tools such as <em class="italic">Ant</em>, <em class="italic">Maven</em>, and <em class="italic">Gradle</em>, aside from the standard shell scripting and Windows batch <span class="No-Break">file executions.</span></p>
			<p>Jenkins follows a <em class="italic">controller-agent</em> model. Though technically, you can run all your builds on the controller machine itself, it makes sense to offload your CI builds to other servers in your network to have a distributed architecture. This does not overload your controller machine. You can use it to store the build configurations and other management data and manage the entire CI build cluster, somethi<a id="_idTextAnchor1458"/>ng along the lines of what’s shown in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B19877_11__7.jpg" alt="Figure 11.7 – Scalable Jenkins" width="1641" height="986"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figur<a id="_idTextAnchor1459"/>e 11.7 – Scalable Jenkins</p>
			<p>In the preceding diagram, multiple static Jenkins agents connect to a Jenkins controller. Now, this architecture works well, but it <a id="_idIndexMarker1216"/>needs to be more scalable. Modern DevOps emphasizes resource utilization, so we only want to roll out an agent machine when we want to build. Therefore, automating your builds to roll out an agent machine when required is a better way to do it. This might be overkill when rolling out new virtual machines, as it takes some minutes to provision a new VM, even when using a prebuilt image with Packer. A better alternative is to use <span class="No-Break">a container.</span></p>
			<p>Jenkins<a id="_idIndexMarker1217"/> integrates quite well with Kubernetes, allowing you to run your build on a Kubernetes cluster. That way, whenever you trigger a build on Jenkins, Jenkins instructs Kubernetes to create a new agent container that will then connect with the controller machine and run the build within itself. This is <em class="italic">build on-demand</em> at <a id="_idTextAnchor1460"/>its best. The following diagram shows this process <span class="No-Break">in detail:</span></p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B19877_11__8.jpg" alt="Figure 11.8 – Scalable Jenkins CI workflow" width="1650" height="848"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure <a id="_idTextAnchor1461"/>11.8 – Scalable Jenkins CI workflow</p>
			<p>This sounds great, and we can<a id="_idIndexMarker1218"/> go ahead and run this build, but there are issues with this approach. We must understand that the Jenkins controller and agents run as containers and aren’t full-fledged virtual machines. Therefore, if we want to run a Docker build within the container, we must run the container in privileged mode. This isn’t a security best practice, and your admin should already have turned that off. This is because running a container in privileged mode exposes your host filesystem to the container. A hacker who can access your container will have full access so that they can do whatever they want <a id="_idTextAnchor1462"/>in <span class="No-Break">your system.</span></p>
			<p>To solve that problem, you can use a container build tool such <a id="_idIndexMarker1219"/>as <strong class="bold">Kaniko</strong>. Kaniko is a build tool provided by Google that helps you build your containers without access to the Docker daemon, and you do not even need Do<a id="_idTextAnchor1463"/>cker installed in your container. It is a great way to run your builds within<a id="_idIndexMarker1220"/> a <strong class="bold">Kubernetes cluster</strong> and create a scalable CI environment. It is effortless, not hacky, and provides a secure method of building your con<a id="_idTextAnchor1464"/>tainers, as we will see in the <span class="No-Break">subsequent sections.</span></p>
			<p>This section will<a id="_idIndexMarker1221"/> use <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>). As mentioned previously, Google Cloud provides a free trial worth $300 for <a id="_idTextAnchor1465"/>90 days. You can sign up <a id="_idTextAnchor1466"/><a id="_idTextAnchor1467"/>at <a href="https://cloud.google.com/free">https://cloud.google.com/free</a> if you have not <a id="_idTextAnchor1468"/>already <span class="No-Break">done so.</span></p>
			<h2 id="_idParaDest-290"><a id="_idTextAnchor1469"/>Spinning up Google Kubernetes Engine</h2>
			<p>Once <a id="_idIndexMarker1222"/>you’ve signed up and are in your console, open the <strong class="bold">Google Cloud Shell</strong> CLI to run the <span class="No-Break">following commands.</span></p>
			<p>You need to enable the Kubernetes Engine API first using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ gcloud services enable container.googleapis.com</pre>			<p>To create a two-node autoscaling GKE cluster that scales from <em class="italic">one</em> to <em class="italic">five</em> nodes, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ gcloud container clusters create cluster-1 --num-nodes 2 \
--enable-autoscaling --min-nodes 1 --max-nodes 5 --zone us-central1-a</pre>			<p>And that’s it! The cluster will be up <span class="No-Break">and running.</span></p>
			<p>You must also clone the following GitHub repository for some of the exercises <span class="No-Break">provided: </span><a href="https://github.com/PacktPublishing/Modern-DevOps-Practices-2e"><span class="No-Break">https://github.com/PacktPublishing/Modern-DevOps-Practices-2e</span></a><span class="No-Break">.</span></p>
			<p>Run the following command to clone the repository into your home directory and <strong class="source-inline">cd</strong> into the following directory to access the <span class="No-Break">required resources:</span></p>
			<pre class="console">
$ git clone https://github.com/PacktPublishing/Modern-DevOps-Practices-2e.git \
modern-devops
$ cd modern-devops/ch11/jenkins/jenkins-controller</pre>			<p>We will use the <strong class="bold">Jenkins Configuration as Code</strong> feature<a id="_idIndexMarker1223"/> to configure Jenkins as it is a declarative way of managing your configuration and is also GitOps-friendly. You need to create a simple YAML file with all the required configurations and then copy the file to the Jenkins controller after setting an environment variable that points to the file. Jenkins will then automatically configure all aspects defined in the YAML file <span class="No-Break">on bootup.</span></p>
			<p>Let’<a id="_idTextAnchor1470"/>s start by creating the <strong class="source-inline">casc.yaml</strong> file to define <span class="No-Break">our configuration.</span></p>
			<h2 id="_idParaDest-291"><a id="_idTextAnchor1471"/>Creating the Jenkins CaC (JCasC) file</h2>
			<p>The <strong class="bold">Jenkins CaC</strong> (<strong class="bold">JCasC</strong>) file<a id="_idIndexMarker1224"/> is a simple YAML file that helps us define Jenkins configuration declaratively. We will create a single <strong class="source-inline">casc.yaml</strong> file for that purpose, and I will explain<a id="_idIndexMarker1225"/> parts of it. Let’s start by defining <strong class="bold">Jenkins </strong><span class="No-Break"><strong class="bold">Global Security</strong></span><span class="No-Break">.</span></p>
			<h3>Configuring Jenkins Global Security</h3>
			<p>By default Jenkins is insecure – that is, if<a id="_idIndexMarker1226"/> you fire up a vanilla Jenkins from the official Docker image and expose it, anyone can do anything with that Jenkins instance. To ensure that we protect it, we need the <span class="No-Break">following configuration:</span></p>
			<pre class="console">
jenkins:
  remotingSecurity:
   enabled: true
  securityRealm:
    local:
      allowsSignup: false
      users:
       - id: ${JENKINS_ADMIN_ID}
         password: ${JENKINS_ADMIN_PASSWORD}
  authorizationStrategy:
    globalMatrix:
      permissions:
        - "Overall/Administer:admin"
        - "Overall/Read:authenticated"</pre>			<p>In the preceding configuration, we’ve defined <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="source-inline">remotingSecurity</strong>: We’ve enabled this feature, which will secure the communication between the Jenkins controller and agents that we will create dynamically <span class="No-Break">using Kubernetes.</span></li>
				<li><strong class="source-inline">securityRealm</strong>: We’ve set the security realm to <strong class="source-inline">local</strong>, which means that the Jenkins controller itself will do all authentication and user management. We could have also offloaded this to an external entity such <span class="No-Break">as LDAP:</span><ul><li><strong class="source-inline">allowsSignup</strong>: This is set to <strong class="source-inline">false</strong>. This means you don’t see a sign-up link on the Jenkins home page, and the Jenkins admin should manually <span class="No-Break">create users.</span></li><li><strong class="source-inline">users</strong>: We’ll create a single user with <strong class="source-inline">id</strong> and <strong class="source-inline">password</strong> sourced from two environment variables called <strong class="source-inline">JENKINS_ADMIN_ID</strong> and <span class="No-Break"><strong class="source-inline">JENKINS_ADMIN_PASSWORD</strong></span><span class="No-Break">, respectively.</span></li></ul></li>
				<li><strong class="source-inline">authorizationStrategy</strong>: We’ve defined a matrix-based authorization strategy where we provide administrator privileges to <strong class="source-inline">admin</strong> and read privileges to <strong class="source-inline">authenticated</strong> <span class="No-Break">non-admin users.</span></li>
			</ul>
			<p>Also, as we <a id="_idIndexMarker1227"/>want Jenkins to execute all their builds in the agents and not the controller machine, we need to specify the <span class="No-Break">following settings:</span></p>
			<pre class="console">
jenkins:
  systemMessage: "Welcome to Jenkins!"
  numExecutors: 0</pre>			<p>We’ve set <strong class="source-inline">numExecutors</strong> to <strong class="source-inline">0</strong> to allow no builds on the controller and also set <strong class="source-inline">systemMessage</strong> on the Jenkins <span class="No-Break">welcome screen.</span></p>
			<p>Now that we’ve set up the security aspects of the Jenkins contro<a id="_idTextAnchor1472"/>ller, we will configure Jenkins to connect with the <span class="No-Break">Kubernetes cluster.</span></p>
			<h3>Connecting Jenkins with the cluster</h3>
			<p>We will install the Kubernetes <a id="_idIndexMarker1228"/>plugin to connect the Jenkins controller<a id="_idIndexMarker1229"/> with the cluster. We’re doing this because we want Jenkins to dynamically spin up agents for builds as <span class="No-Break">Kubernetes </span><span class="No-Break"><strong class="bold">pods</strong></span><span class="No-Break">.</span></p>
			<p>We will start by creating a <strong class="source-inline">kubernetes</strong> configuration under <strong class="source-inline">jenkins.clouds</strong>, <span class="No-Break">as follows:</span></p>
			<pre class="console">
jenkins
  clouds:
  - kubernetes:
      serverUrl: "https://&lt;kubernetes_control_plane_ip&gt;"
      jenkinsUrl: "http://jenkins-service:8080"
      jenkinsTunnel: "jenkins-service:50000"
      skipTlsVerify: false
      useJenkinsProxy: false
      maxRequestsPerHost: 32
      name: "kubernetes"
      readTimeou<a id="_idTextAnchor1473"/>t: 15
      podLabels:
        - key: jenkins
          value: agent
...</pre>			<p>As we have a placeholder called <strong class="source-inline">&lt;kubernetes_control_plane_ip&gt;</strong> within the configuration, we must replace this with the Kubernetes control plane’s IP address. Run the following command to fetch the control plane’s <span class="No-Break">IP address:</span></p>
			<pre class="console">
$ kubectl cluster-info | grep "control plane"
Kubernetes control plane is running at https://35.224.6.58</pre>			<p>Now, replace <a id="_idIndexMarker1230"/>the <strong class="source-inline">&lt;kubernetes_control_plane_ip&gt;</strong> placeholder with the actual IP address you obtained from the<a id="_idIndexMarker1231"/> preceding command by using the <span class="No-Break">following<a id="_idTextAnchor1474"/> command:</span></p>
			<pre class="console">
$ sed -i 's/&lt;kubernetes_control_plane_ip&gt;/actual_ip/g' casc.yaml</pre>			<p>Let’s look at each attribute in the <span class="No-Break">config file:</span></p>
			<ul>
				<li><strong class="source-inline">serverUrl</strong>: This denotes the Kubernetes control plane server URL, allowing the Jenkins controller to communicate with the Kubernetes <span class="No-Break">API server.</span></li>
				<li><strong class="source-inline">jenkinsUrl</strong>: This denotes the Jenkins controller URL. We’ve set it to  <span class="No-Break">http://jenkins-service:8080</span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">jenkinsTunnel</strong>: This describes how the agent pods will connect with the Jenkins controller. As the JNLP port is <strong class="source-inline">50000</strong>, we’ve set it <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">jenkins-service:50000</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">podLabels</strong>: We’ve also set up some pod labels, <strong class="source-inline">key=jenkins</strong> and <strong class="source-inline">value=agent</strong>. These will be set on the <span class="No-Break">agent pods.</span></li>
			</ul>
			<p>Other attributes are also set to their <span class="No-Break">default values.</span></p>
			<p>Every <a id="_idIndexMarker1232"/>Kubernetes cloud configuration consists of multiple <a id="_idIndexMarker1233"/>pod <strong class="source-inline">templates</strong> describing how the agent pods will be configured. The configuration looks <span class="No-Break">like this:</span></p>
			<pre class="console">
  - kubernetes:
...
      templates:
      - name: "jenkins-agent"
        label: "jenkins-agent"
        hostNetwork: false
        nodeUsageMode: "NORMAL"
        serviceAccount: "jenkins"
        imagePullSecrets:
          - na<a id="_idTextAnchor1475"/>me: regcred
        yamlMergeStrategy: "override"
        containers:
	   ...</pre>			<p>Here, we’ve<a id="_idIndexMarker1234"/> defined <span class="No-Break">the</span><span class="No-Break"><a id="_idIndexMarker1235"/></span><span class="No-Break"> following:</span></p>
			<ul>
				<li>The template’s <strong class="source-inline">name</strong> and <strong class="source-inline">label</strong>. We set both <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">jenkins-agent</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">hostNetwork</strong>: This is set to <strong class="source-inline">false</strong> as we don’t want the container to interact with the <span class="No-Break">host network.</span></li>
				<li><strong class="source-inline">seviceAccount</strong>: We’ve set this to <strong class="source-inline">jenkins</strong> as we want to use this service account to interact <span class="No-Break">with Kubernetes.</span></li>
				<li><strong class="source-inline">imagePullSecrets</strong>: We have also provided an image pull secret called <strong class="source-inline">regcred</strong> to authenticate with the container registry to pull the <span class="No-Break"><strong class="source-inline">jnlp</strong></span><span class="No-Break"> image.</span></li>
			</ul>
			<p>Every pod template also <a id="_idIndexMarker1236"/>contains a <strong class="bold">container template</strong>. We can define that using the <span class="No-Break">following configuration:</span></p>
			<pre class="console">
	   ...
        containers:
        - name: jnlp
          image: "&lt;your_dockerhub_user&gt;/jenkins-jnlp-kaniko"
          workingDir: "/home/jenkins/agent"
          command: ""
          args: ""
          livenessProbe:
            failureThreshold: 1
            initialDelaySeconds: 2
            periodSeconds: 3
            successThreshold: 4
            timeoutSeconds: 5
        volumes:
          - secretVolume:
              mountPath: /kaniko/.docker
              secretName: regcred</pre>			<p>Here, we have specified <span class="No-Break">the following:</span></p>
			<ul>
				<li> <strong class="source-inline">name</strong>: Set <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">jnlp</strong></span><span class="No-Break">.</span></li>
				<li><strong class="source-inline">image</strong>: Here, we’ve specified the <em class="italic">Docker agent image</em> we will build in the next section. Ensure that you replace the <strong class="source-inline">&lt;your_dockerhub_user&gt;</strong> placeholder with your Docker Hub user by using the <span class="No-Break">following command:</span></li>
			</ul>
			<pre class="console">
$ sed -i 's/&lt;your_dockerhub_user&gt;/actual_dockerhub_user/g' casc.yaml</pre>			<ul>
				<li><strong class="source-inline">workingDir</strong>: Set <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">/home/jenkins/agent</strong></span><span class="No-Break">.</span></li>
				<li>We’ve set the <strong class="source-inline">command</strong> and <strong class="source-inline">args</strong> fields to blank as we don’t need to <span class="No-Break">pass them.</span></li>
				<li><strong class="source-inline">livenessProbe</strong>: We’ve defined <a id="_idTextAnchor1476"/>a liveness probe for the <span class="No-Break">agent pod.</span></li>
				<li><strong class="source-inline">volumes</strong>: We’ve mounted the <strong class="source-inline">regcred</strong> secret to the <strong class="source-inline">kaniko/.docker</strong> file as a volume. As <strong class="source-inline">regcred</strong> contains the Docker registry credentials, Kaniko will use this <a id="_idIndexMarker1237"/>to connect<a id="_idIndexMarker1238"/> with your <span class="No-Break">container registry.</span></li>
			</ul>
			<p>Now that our co<a id="_idTextAnchor1477"/>nfiguration file is ready, we’ll go ahead<a id="_idTextAnchor1478"/> and install Jenkins in the <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-292"><a id="_idTextAnchor1479"/>Installing Jenkins</h2>
			<p>As we’re running on a <a id="_idIndexMarker1239"/>Kubernetes cluster, we only need the latest official Jenkins image from Docker Hub. We will customize the image according to <span class="No-Break">our requirements.</span></p>
			<p>The following <strong class="source-inline">Dockerfile</strong> file will<a id="_idIndexMarker1240"/> help us create the image with the required plugins and the <span class="No-Break">initial configuration:</span></p>
			<pre class="console">
FROM jenkins/jenkins
ENV CASC_JENKINS_CONFIG /usr/local/casc.yaml
ENV JAVA_OPTS -Djenkins.install.runSetupWizard=false
COPY casc.yaml /usr/local/casc.yaml
COPY plugins.txt /usr/share/jenkins/ref/plugins.txt
RUN jenkins-plugin-cli --plugin-file /usr/share/jenkins/ref/plugins.txt</pre>			<p>The <strong class="source-inline">Dockerfile</strong> starts from the Jenkins base image. Then, we declare two environment variables – <strong class="source-inline">CASC_JENKINS_CONFIG</strong>, which points to the <strong class="source-inline">casc.yaml</strong> file we defined in the previous section, and <strong class="source-inline">JAVA_OPTS</strong>, which tells Jenkins not to run the setup wizard. Then, we copy the <strong class="source-inline">casc.yaml</strong> and <strong class="source-inline">plugins.txt</strong> files to their respective directories within the Jenkins container. Finally, we run <strong class="source-inline">jenkins-plugins-cli</strong> on the <strong class="source-inline">plugins.txt</strong> file, which installs the <span class="No-Break">required plugins.</span></p>
			<p>The <strong class="source-inline">plugins.txt</strong> file contains a list of all Jenkins plugins that we will need in <span class="No-Break">this setup.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">You can customize and install more plugins for the controller image based on your requirements by updating the <span class="No-Break"><strong class="source-inline">plugins.txt</strong></span><span class="No-Break"> file.</span></p>
			<p>Let’s build the image from the <strong class="source-inline">Dockerfile</strong> file using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/jenkins-controller-kaniko .</pre>			<p>Now that we’ve built the image, use the following command to log in and push the image to <span class="No-Break">Docker Hub</span><span class="No-Break">:</span></p>
			<pre class="console">
$ docker login
$ docker push &lt;your_dockerhub_user&gt;/jenkins-controller-kaniko</pre>			<p>We must also build the Jenkins agent image to run our builds. Remember that Jenkins agents need all the supporting tools you need to run your builds. You can find the resources for the agents in the <span class="No-Break">following directory:</span></p>
			<pre class="console">
$ cd ~/modern-devops/ch11/jenkins/jenkins-agent</pre>			<p>We will use the following <strong class="source-inline">Dockerfile</strong> to <span class="No-Break">do that:</span></p>
			<pre class="console">
FROM gcr.io/kaniko-project/executor:v1.13.0 as kaniko
FROM jenkins/inbound-agent
COPY --from=kaniko /kaniko /kaniko
WORKDIR /kaniko
USER root</pre>			<p>This <strong class="source-inline">Dockerfile</strong> uses a multi-stage build to take the <strong class="source-inline">kaniko</strong> base image and copy the <strong class="source-inline">kaniko</strong> binary from the <strong class="source-inline">kaniko</strong> base image to the <strong class="source-inline">inbound-agent</strong> base image. Let’s go ahead <a id="_idIndexMarker1241"/>and build and push the container using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ docker build -t &lt;your_dockerhub_user&gt;/jenkins-jnlp-kaniko .
$ docker push &lt;your_dockerhub_user&gt;/jenkins-jnlp-kaniko</pre>			<p>To deploy Jenkins on our Kubernetes cluster, we will first create a <strong class="source-inline">jenkins</strong> service account. A Kubernetes <strong class="bold">service account</strong> resource<a id="_idIndexMarker1242"/> helps pods authenticate with the <strong class="bold">Kubernetes API server</strong>. We <a id="_idIndexMarker1243"/>will give the service account permission to interact with the Kubernetes API server as <strong class="source-inline">cluster-admin</strong> using a cluster role binding. A Kubernetes <strong class="bold">ClusterRoleBinding</strong> resource<a id="_idIndexMarker1244"/> helps provide permissions to a service account to perform certain actions in the Kubernetes cluster. The <strong class="source-inline">jenkins-sa-crb.yaml</strong> manifest describes this. To access these resources, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ cd ~/modern-devops/ch11/jenkins/jenkins-controller</pre>			<p>To apply the manifest, <a id="_idTextAnchor1480"/>run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubectl apply -f jenkins-sa-crb.yaml</pre>			<p>The next step involves creating <a id="_idIndexMarker1245"/>a <strong class="bold">PersistentVolumeClaim</strong> resource to store Jenkins data to ensure that the Jenkins data persists beyond the pod’s life cycle and will exist even when we delete <span class="No-Break">the pod.</span></p>
			<p>To apply the manifest, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubectl apply -f jenkins-pvc.yaml</pre>			<p>Then, we will create a <a id="_idIndexMarker1246"/>Kubernetes <strong class="bold">Secret</strong> called <strong class="source-inline">regcred</strong> to help the Jenkins pod authenticate with <a id="_idIndexMarker1247"/>the Docker registry. Use the following command to <span class="No-Break">do so:</span></p>
			<pre class="console">
$ kubectl create secret docker-registry regcred --docker-username=&lt;username&gt; \
--docker-password=&lt;password&gt; --docker-server=https://index.docker.io/v1/</pre>			<p>Now, we’ll define <a id="_idIndexMarker1248"/>a <strong class="bold">Deployment</strong> resource, <strong class="source-inline">jenkins-deployment.yaml</strong>, that will run the Jenkins container. The pod uses the <strong class="source-inline">jenkins</strong> service account and defines a <strong class="bold">PersistentVolume</strong> resource<a id="_idIndexMarker1249"/> called <strong class="source-inline">jenkins-pv-storage</strong> using the <strong class="source-inline">PersistentVolumeClaim</strong> resource called <strong class="source-inline">jenkins-pv-claim</strong> that we defined. We define the Jenkins container that uses the Jenkins controller image we created. It exposes HTTP port <strong class="source-inline">8080</strong> for the <em class="italic">Web UI</em>, and port <strong class="source-inline">50000</strong> for <em class="italic">JNLP</em>, which the agents would use to interact with the Jenkins controller. We will also mount the <strong class="source-inline">jenkins-pv-storage</strong> volume to <strong class="source-inline">/var/jenkins_home</strong> to persist the Jenkins data beyond the pod’s life cycle. We specify <strong class="source-inline">regcred</strong> as the <strong class="source-inline">imagePullSecret</strong> attribute in the pod image. We also use <strong class="source-inline">initContainer</strong> to assign ownership to <strong class="source-inline">jenkins</strong> <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">/var/jenkins_home</strong></span><span class="No-Break">.</span></p>
			<p>As the file contains placeholders, replace <strong class="source-inline">&lt;your_dockerhub_user&gt;</strong> with your Docker Hub user and <strong class="source-inline">&lt;jenkins_admin_pass&gt;</strong> with a Jenkins admin password of your choice using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ sed -i 's/&lt;your_dockerhub_user&gt;/actual_dockerhub_user/g' jenkins-deployment.yaml</pre>			<p>Apply the manifest using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubectl apply -f jenkins-deployment.yaml</pre>			<p>As we’ve created the deployment, we can expose the deployment on a <strong class="bold">LoadBalancer </strong>Service using<a id="_idIndexMarker1250"/> the <strong class="source-inline">jenkins-svc.yaml</strong> manifest. This service exposes ports <strong class="source-inline">8080</strong> and <strong class="source-inline">50000</strong> on a load balancer. Use the following command to apply <span class="No-Break">the</span><span class="No-Break"><a id="_idIndexMarker1251"/></span><span class="No-Break"> manifest:</span></p>
			<pre class="console">
$ kubectl apply -f jenkins-svc.yaml</pre>			<p>Let’s get the service to find the external IP to use that to <span class="No-Break">access Jenkins:</span></p>
			<pre class="console">
$ kubectl get svc jenkins-service
NAME             EXTERNAL-IP<a id="_idTextAnchor1481"/>               PORT(S)
jenkins-service  LOAD_BALANCER_EXTERNAL_IP 8080,50000</pre>			<p>Now<a id="_idTextAnchor1482"/>, to access the service, go to <strong class="source-inline">http://&lt;LOAD_BALANCER_EXTERNAL_IP&gt;:8080</strong> in your <span class="No-Break">browser window:</span></p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/B19877_11_9.jpg" alt="Figure 11.9 – Jenkins login page" width="1590" height="864"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.9 – Jenkins login page</p>
			<p>As we can see, we’re greeted with a login page. This means Global Security is working correctly. Let’s log in using the admin username and password <span class="No-Break">we set:</span></p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/B19877_11_10.jpg" alt="Figure 11.10 – Jenkins home page" width="1640" height="1019"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.10 – Jenkins home page</p>
			<p>As we can see, <a id="_idTextAnchor1483"/><a id="_idTextAnchor1484"/>we’ve <a id="_idIndexMarker1252"/>successfully logged in to Jenkins.<a id="_idTextAnchor1485"/> Now, let’s go ahead and create our first <span class="No-Break">Jenkins job.</span></p>
			<h2 id="_idParaDest-293"><a id="_idTextAnchor1486"/>Running our first Jenkins job</h2>
			<p>Before we create our first<a id="_idIndexMarker1253"/> job, we’ll have to prepare our repository to run the job. We will reuse the <strong class="source-inline">mdo-posts</strong> repository for this. We will copy a <strong class="source-inline">build.sh</strong> file to the repository, which will build the container image for the <strong class="bold">posts</strong> microservice and push it <a id="_idIndexMarker1254"/>to <span class="No-Break">Docker Hub.</span></p>
			<p>The <strong class="source-inline">build.sh</strong> script takes <strong class="source-inline">IMAGE_ID</strong> and <strong class="source-inline">IMAGE_TAG</strong> as arguments. It passes them to the <strong class="bold">Kaniko</strong> executor script, which<a id="_idIndexMarker1255"/> builds the container image using the <strong class="source-inline">Dockerfile</strong> and pushes it to Docker Hub using the <span class="No-Break">following code:</span></p>
			<pre class="console">
IMAGE_ID=$1 &amp;&amp; \
IMAGE_TAG=$2 &amp;&amp; \
export DOCKER_CONFIG=/kaniko/.dockerconfig &amp;&amp; \
/kaniko/executor \
  --context $(pwd) \
  --dockerfile $(pwd)/Dockerfile \
  --destination $IMAGE_ID:$IMAGE_TAG \
  --force</pre>			<p>We will need to copy this file to our local repository using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cp ~/modern-devops/ch11/jenkins/jenkins-agent/build.sh ~/mdo-posts/</pre>			<p>Once you’ve done this, <strong class="source-inline">cd</strong> into your local repository – that is, <strong class="source-inline">~/mdo-posts</strong> – and commit and push your changes to GitHub. Once you’ve done this, you’ll be ready to create a job <span class="No-Break">in Jenkins.</span></p>
			<p>To create a new job <a id="_idIndexMarker1256"/>in Jenkins, go to the Jenkins home page and select <strong class="bold">New Item</strong> | <strong class="bold">Freestyle Job</strong>. Provide a job name (preferably the same as the Git repository name), then <span class="No-Break">click </span><span class="No-Break"><strong class="bold">Next</strong></span><span class="No-Break">.</span></p>
			<p>Click<a id="_idTextAnchor1487"/> on <strong class="bold">Source Code Management</strong>, select <strong class="bold">Git</strong>, and add your Git re<a id="_idTextAnchor1488"/>pository URL, as shown in the following example. Specify the branch from where you want <span class="No-Break">to build:</span></p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/B19877_11_11.jpg" alt="Figure 11.11 – Jenkins Souce Code Management configuration" width="1659" height="1203"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.11 – Jenkins Souce Cod<a id="_idTextAnchor1489"/>e Management configuration</p>
			<p>Go to <strong class="bold">Build Triggers</strong>, select <strong class="bold">Poll SCM</strong>, and <a id="_idIndexMarker1257"/>add the <span class="No-Break">following details:</span></p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/B19877_11__12.jpg" alt="Figure 11.12 – Jenkins – Build Triggers configuration" width="1154" height="579"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.12 – Jenkins – Build Triggers configuration</p>
			<p>Then, cli<a id="_idTextAnchor1490"/>ck on <strong class="bold">Build</strong> | <strong class="bold">Add Build Step</strong> | <strong class="bold">Execute shell</strong>. The <strong class="bold">Execute shell</strong> build step executes a sequence of shell commands on the Linux CLI. In this example, we’re running the <strong class="source-inline">build.sh</strong> script with the <strong class="source-inline">&lt;your_dockerhub_user&gt;/&lt;image&gt;</strong> argument and the<a id="_idTextAnchor1491"/> image tag. Change the details according to your requirements. Once you’ve finished, <span class="No-Break">click </span><span class="No-Break"><strong class="bold">Save</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B19877_11__13.jpg" alt="Figure 11.13 – Jenkins – Execute shell configuration" width="921" height="488"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.13 – Jenkins – Execute shell configuration</p>
			<p>Now, we’re ready to build this <a id="_idIndexMarker1258"/>job. To do so, you can either go to your job configurat<a id="_idTextAnchor1492"/>ion and click <strong class="bold">Build Now</strong> or push a change to GitHub. You shou<a id="_idTextAnchor1493"/>ld see something like <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/B19877_11_14.jpg" alt="Figure 11.14 – Jenkins job page" width="1763" height="1139"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.14 – Jenkins job page</p>
			<p>Jenkins will successfully<a id="_idIndexMarker1259"/> create an agent pod in Kubernetes, where it will run this job, and soon, the job will start building. Click <strong class="bold">Build</strong> | <strong class="bold">Console Output</strong>. If everything is OK, you’ll see that the build was successful and that Jenkins has b<a id="_idTextAnchor1494"/>uilt the <strong class="bold">posts</strong> service and executed a unit test before pushing th<a id="_idTextAnchor1495"/>e Docker image to <span class="No-Break">the registry:</span></p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/B19877_11_15.jpg" alt="Figure 11.15 – Jenkins console output" width="1633" height="1023"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.15 – Jenkins console output</p>
			<p>With that, we’re able to run a Docker build using a scalable Jenkins server. As we can see, we’ve set up polling on the SCM settings to look for changes every minute and build the job if we detect any. However, this is resource-intensive and does not help in the long run. Just imagine that you have hundreds of jobs interacting with multiple GitHub repositories, and the Jenkins controller is polling them every minute. A better approach would be if GitHub could trigger a <strong class="bold">post-commit webhook</strong> on <a id="_idIndexMarker1260"/>Jenkins. Here, Jenkins can build the j<a id="_idTextAnchor1496"/><a id="_idTextAnchor1497"/>ob whenever there are changes in the repository. <a id="_idTextAnchor1498"/>We’ll look at that scenario in the <span class="No-Break">next secti<a id="_idTextAnchor1499"/>on.</span></p>
			<h1 id="_idParaDest-294"><a id="_idTextAnchor1500"/>Automating a build with triggers</h1>
			<p>The <a id="_idIndexMarker1261"/>best way to allow your CI build to trigger when you make<a id="_idIndexMarker1262"/> changes to your code is to use a post-commit webhook. We looked at such an example in the GitHub Actions workflow. Let’s try to automate the build with triggers in the case of Jenkins. We’ll have to make some changes on both the Jenkins and the GitHub sides to do so. We’ll deal with Jenkins first; then<a id="_idTextAnchor1501"/>, we’ll <span class="No-Break">configure GitHub.</span></p>
			<p>Go to <strong class="bold">Job configuration</strong> | <strong class="bold">Build Triggers</strong> and make the <span class="No-Break">following changes<a id="_idTextAnchor1502"/>:</span></p>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="image/B19877_11__16.jpg" alt="Figure 11.16 – Jenkins GitHub hook trigger" width="1171" height="400"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1<a id="_idTextAnchor1503"/>1.16 – Jenkins GitHub hook trigger</p>
			<p>Save the configuration by clicking <strong class="bold">Save</strong>. Now, go to your GitHub repository,<a id="_idTextAnchor1504"/> click <strong class="bold">Settings</strong> | <strong class="bold">Webhooks</strong> | <strong class="bold">Add Webhook</strong>, and add the following details. Then, click <span class="No-Break"><strong class="bold">Add Webhook</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer101" class="IMG---Figure">
					<img src="image/B19877_11__17.jpg" alt="Figure 11.17 – GitHub webhook" width="1102" height="428"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1<a id="_idTextAnchor1505"/>7 – GitHub webhook</p>
			<p>Now, push a change to the repository. The job o<a id="_idTextAnchor1506"/>n Jenkins will <span class="No-Break">start building:</span></p>
			<div>
				<div id="_idContainer102" class="IMG---Figure">
					<img src="image/B19877_11__18.jpg" alt="Figure 11.18 – Jenkins GitHub webhook trigger" width="823" height="457"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.18 – Jenki<a id="_idTextAnchor1507"/>ns GitHub webhook trigger</p>
			<p>This is<a id="_idIndexMarker1263"/> automated build triggers in action. Jenkins is one of the <a id="_idIndexMarker1264"/>most popular open source CI tools on the market. The most significant advantage of it is that you can pretty much run it anywhere. However, it does come with some management overhead. You may have noticed how simple it was to start with GitHub Actions, but Jenkins is slightly <span class="No-Break">more complicated.</span></p>
			<p>Several other SaaS platforms offer CI and CD as a service. For instance, if you are running on AWS, you’d get their inbuilt CI<a id="_idIndexMarker1265"/> with <strong class="bold">AWS Code Commit</strong> and <strong class="bold">Code Build</strong>; Azure<a id="_idIndexMarker1266"/> provides an entire suite <a id="_idTextAnchor1508"/>of services for CI and CD in<a id="_idIndexMarker1267"/> their <strong class="bold">Azure DevOps</strong> offering; and GCP provides <strong class="bold">Cloud Build</strong> for <a id="_idIndexMarker1268"/><span class="No-Break">that job.</span></p>
			<p>CI follows the same principle, regardless of the tooling you choose to implement. It is more of a process and a<a id="_idTextAnchor1509"/><a id="_idTextAnchor1510"/> cultural change within your organization. No<a id="_idTextAnchor1511"/>w, let’s look at some of the best practices <span class="No-Break">regarding CI.</span></p>
			<h1 id="_idParaDest-295"><a id="_idTextAnchor1512"/>Building performance best practices</h1>
			<p>CI is an <a id="_idIndexMarker1269"/>ongoing process, so you will have a lot of parallel builds running within y<a id="_idTextAnchor1513"/><a id="_idTextAnchor1514"/>our environment at a given time. In such <a id="_idTextAnchor1515"/>situations, we can optimize them using several <span class="No-Break">best practices.</span></p>
			<h2 id="_idParaDest-296"><a id="_idTextAnchor1516"/>Aim for faster builds</h2>
			<p>The faster you can complete your build, the quicker you will get feedback and run your next iteration. A slow build slows down your development team. Take steps to ensure that builds are faster. For example, in Docker’s case, it makes sense to use smaller base images as it will download the code from the image registry every time it does a build. Using a single base image for most builds will also speed up your build time. Using tests will help, but make sure that they aren’t long-running. We want to avoid a CI build that runs for hours. Therefore, it would be good to<a id="_idTextAnchor1517"/><a id="_idTextAnchor1518"/> offload long-running tests into another job or use a pipe<a id="_idTextAnchor1519"/>line. Run activities in parallel <span class="No-Break">if possible.</span></p>
			<h2 id="_idParaDest-297"><a id="_idTextAnchor1520"/>Always use post-commit triggers</h2>
			<p>Post-commit triggers help your team significantly. They will not have to log in to the CI ser<a id="_idTextAnchor1521"/><a id="_idTextAnchor1522"/>ver and trigger the build manually. That compl<a id="_idTextAnchor1523"/>etely decouples your development team from <span class="No-Break">CI management.</span></p>
			<h2 id="_idParaDest-298"><a id="_idTextAnchor1524"/>Configure build reporting</h2>
			<p>You don’t want your development team to log in to the CI tool and check how the build runs. Instead, all they want to know is the result of the build and the build logs. Therefore, you ca<a id="_idTextAnchor1525"/><a id="_idTextAnchor1526"/>n configure build <a id="_idIndexMarker1270"/>reporting to send your build status v<a id="_idTextAnchor1527"/>ia email or, even better, using a <span class="No-Break"><strong class="bold">Slack</strong></span><span class="No-Break"> channel.</span></p>
			<h2 id="_idParaDest-299"><a id="_idTextAnchor1528"/>Customize the build server size</h2>
			<p>Not all builds work the same in similar kinds of build machines. You may want to choose machines based on what suits your build environment best. If your builds tend to consume more CPU <a id="_idTextAnchor1529"/><a id="_idTextAnchor1530"/>than memory, it will make sense to choose such machines to run your builds instead of the <span class="No-Break">standard ones.</span></p>
			<h2 id="_idParaDest-300"><a id="_idTextAnchor1531"/>Ensure that your builds only contain what you need</h2>
			<p>Builds <a id="_idIndexMarker1271"/>move across networks. You download base images, build your application image, and push that to the container registry. Bloated images not only take a lot of network bandwidth and time to transmit but also make your build vulnerable to security issues. Therefore, it is always best practice to only include what you require in the build and avoid bloat. You can use Docker’s <strong class="bold">multi-stage builds</strong> for these<a id="_idIndexMarker1272"/> kinds <span class="No-Break">of situations.</span></p>
			<h2 id="_idParaDest-301"><a id="_idTextAnchor1532"/>Parallelize your builds</h2>
			<p>Run tests and build processes concurrently to reduce overall execution time. Leverage distributed systems or cloud-based CI/CD platforms for scalable parallelization, allowing you to handle larger <span class="No-Break">workloads efficiently.</span></p>
			<h2 id="_idParaDest-302"><a id="_idTextAnchor1533"/>Make use of caching</h2>
			<p>Cache dependencies and build artifacts to prevent redundant downloads and builds, saving valuable time. Implement caching mechanisms such as Docker layer caching or use your package manager’s built-in caches to minimize data transfer and <span class="No-Break">build steps.</span></p>
			<h2 id="_idParaDest-303"><a id="_idTextAnchor1534"/>Use incremental building</h2>
			<p>Configure your CI/CD pipeline to perform incremental builds, rebuilding only what has changed since the last build. Maintain robust version control practices to accurately track and <span class="No-Break">identify changes.</span></p>
			<h2 id="_idParaDest-304"><a id="_idTextAnchor1535"/>Optimize testing</h2>
			<p>Prioritize and optimize tests by running quicker unit tests before slower integration or end-to-end tests. Use testing frameworks such as TestNG, JUnit, or PyTest to categorize and parallelize <span class="No-Break">tests effectively.</span></p>
			<h2 id="_idParaDest-305"><a id="_idTextAnchor1536"/>Use artifact management</h2>
			<p>Efficiently store and manage build artifacts, preferably in a dedicated artifact repository such as Artifactory or Nexus. Implement artifact versioning and retention policies to maintain a clean <span class="No-Break">artifact repository.</span></p>
			<h2 id="_idParaDest-306"><a id="_idTextAnchor1537"/>Manage application dependencies</h2>
			<p>Keep a <a id="_idIndexMarker1273"/>clean and minimal set of dependencies to reduce build and test times. Regularly update dependencies to benefit from performance improvements and <span class="No-Break">security updates.</span></p>
			<h2 id="_idParaDest-307"><a id="_idTextAnchor1538"/>Utilize Infrastructure as Code</h2>
			<p>Utilize <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>) to<a id="_idIndexMarker1274"/> provision and configure build and test environments consistently. Optimize IaC templates to minimize resource utilization, ensuring efficient <span class="No-Break">resource allocation.</span></p>
			<h2 id="_idParaDest-308"><a id="_idTextAnchor1539"/>Use containerization to manage build and test environments</h2>
			<p>Containerize applications and utilize container orchestration tools such as Kubernetes to manage test environments efficiently. Leverage container caching to accelerate image builds and enhance <span class="No-Break">resource utilization.</span></p>
			<h2 id="_idParaDest-309"><a id="_idTextAnchor1540"/>Utilize cloud-based CI/CD</h2>
			<p>Consider adopting cloud-based CI/CD services such as AWS CodePipeline, Google Cloud Build, Azure DevOps, or Travis CI for enhanced scalability and performance. Harness on-demand cloud resources to expand parallelization capabilities and adapt to <span class="No-Break">varying workloads.</span></p>
			<h2 id="_idParaDest-310"><a id="_idTextAnchor1541"/>Monitor and profile your CI/CD pipelines</h2>
			<p>Implement performance monitoring and profiling tools to identify bottlenecks and areas for improvement within your CI/CD pipeline. Regularly analyze build and test logs to gather insights for <span class="No-Break">optimizing performance.</span></p>
			<h2 id="_idParaDest-311"><a id="_idTextAnchor1542"/>Pipeline optimization</h2>
			<p>Continuously review and optimize your CI/CD pipeline configuration for efficiency and relevance. Remove unnecessary steps or stages that do not contribute significantly to <span class="No-Break">the process.</span></p>
			<h2 id="_idParaDest-312"><a id="_idTextAnchor1543"/>Implement automated cleanup</h2>
			<p>Implement<a id="_idIndexMarker1275"/> automated cleanup routines to remove stale artifacts, containers, and virtual machines, preventing resource clutter. Regularly purge old build artifacts and unused resources to maintain a <span class="No-Break">tidy environment.</span></p>
			<h2 id="_idParaDest-313"><a id="_idTextAnchor1544"/>Documentation and training</h2>
			<p>Document best practices and performance guidelines for your CI/CD processes, ensuring that the entire team follows these standards consistently. Provide training and guidance to team members to empower them to implement and maintain these optimization <span class="No-Break">strategies effectively.</span></p>
			<p>By implementing these strategies, you can significantly enhance the speed, efficiency, and reliability of your CI/CD pipeline, ultimately leading to smoother software development and delivery processes. These are some of the best practices at a high level<a id="_idTextAnchor1545"/><a id="_idTextAnchor1546"/>, and they are not exhaustive, but they are good enough so that you can start optimizing your <span class="No-Break">CI </span><span class="No-Break"><a id="_idIndexMarker1276"/></span><span class="No-Break">environment.</span></p>
			<h1 id="_idParaDest-314"><a id="_idTextAnchor1547"/>Summary</h1>
			<p>This chapter covered CI, and you understood the need for CI and the basic CI workflow for a container application. We then looked at GitHub Actions, which we can use to build an effective CI pipeline. Next, we looked at the Jenkins open source offering and deployed a scalable Jenkins on Kubernetes with Kaniko, setting up a Jenkins controller-agent model. We then understood how to use hooks for automating builds, both in the GitHub Actions-based workflow and the Jenkins-based workflow. Finally, we learned about build performance best practices and dos <span class="No-Break">and don’ts.</span></p>
			<p>By now, you should be familiar with CI and its nuances, along with the various tooling you can use t<a id="_idTextAnchor1548"/><a id="_idTextAnchor1549"/>o <span class="No-Break">implement it.</span></p>
			<p>In the next chapter, we will delve into continuous deployment/delivery in the <span class="No-Break">container world.</span></p>
			<h1 id="_idParaDest-315"><a id="_idTextAnchor1550"/>Questions</h1>
			<p>Answer the following questions to test your knowledge of <span class="No-Break">this chapter:</span></p>
			<ol>
				<li>Which of the following are CI tools? (<span class="No-Break">Choose three)</span><p class="list-inset"><span class="No-Break">A. Jenkins</span></p><p class="list-inset">B. <span class="No-Break">GitHub Actions</span></p><p class="list-inset"><span class="No-Break">C. Kubernetes</span></p><p class="list-inset">D. AWS <span class="No-Break">Code Build</span></p></li>
				<li>It is a best practice to configure post-commit <span class="No-Break">triggers. </span><span class="No-Break">(True/False)</span></li>
				<li>Jenkins is a SaaS-based CI <span class="No-Break">tool. </span><span class="No-Break">(True/False)</span></li>
				<li>Kaniko requires Docker to build your <span class="No-Break">containers. </span><span class="No-Break">(True/False)</span></li>
				<li>Jenkins agents are required for which of the following reasons? (<span class="No-Break">Choose three)</span><p class="list-inset">A. They make builds <span class="No-Break">more scalable</span></p><p class="list-inset">B. They help offload the management function from the <span class="No-Break">Jenkins controller</span></p><p class="list-inset">C. They allow for <span class="No-Break">parallel builds</span></p><p class="list-inset">D. They keep the Jenkins controller <span class="No-Break">less busy</span></p></li>
				<li>Which of the following is required for a scalable Jenkins server, as described in the example in this chapter? (<span class="No-Break">Choose three)</span><p class="list-inset">A. <span class="No-Break">Kubernetes c<a id="_idTextAnchor1551"/><a id="_idTextAnchor1552"/>luster</span></p><p class="list-inset">B. Jenkins <span class="No-Break">controller node</span></p><p class="list-inset">C. Jenkins <span class="No-Break">agent node</span></p><p class="list-inset">D. Credentials to interact with the <span class="No-Break">container registry</span></p></li>
			</ol>
			<h1 id="_idParaDest-316"><a id="_idTextAnchor1553"/>Answers</h1>
			<p>The following are the answers to this <span class="No-Break">chapter’s questions:</span></p>
			<ol>
				<li>A, <span class="No-Break">B, D</span></li>
				<li><span class="No-Break">True</span></li>
				<li><span class="No-Break">False</span></li>
				<li><span class="No-Break">False</span></li>
				<li>A, <span class="No-Break">C, D</span></li>
				<li>A, <span class="No-Break">B, D</span></li>
			</ol>
		</div>
	</div>
</div>
</body></html>