<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer131">&#13;
			<h1 id="_idParaDest-160" class="chapter-number"><a id="_idTextAnchor161"/>7</h1>&#13;
			<h1 id="_idParaDest-161"><a id="_idTextAnchor162"/>Kubernetes Monitoring and Observability</h1>&#13;
			<p>Monitoring and observability for both Ops and Dev teams have always been crucial. Ops teams used to be focused on infrastructure health (virtual machines, bare-metal, networks, storage, and so on) and Devs used to be focused on application health. With Kubernetes, those lines are blurred. In a standard data center environment, it’s easy to split who’s conducting monitoring and observability in a very traditional sense. Kubernetes blends those lines because, for example, Pods are, in a sense, infrastructure pieces because they have to scale and are sort of <em class="italic">virtual machines</em> in the traditional sense. They are what holds the application. However, the application is running in a Pod, so if you’re monitoring a Pod, you’re automatically monitoring the containers that are running inside of <span class="No-Break">the Pod.</span></p>&#13;
			<p>Because these lines are blurred, both teams are doing both parts of the monitoring process. On a platform engineering or DevOps engineering team, those teams would monitor both application pieces and <span class="No-Break">infrastructure pieces.</span></p>&#13;
			<p>There’s no longer a line that’s used to divide which team monitors and creates observability practices around specific parts of Kubernetes. Instead, the goal is now to have a more unified front to ensure that the overall environment and applications are working <span class="No-Break">as expected.</span></p>&#13;
			<p>In this chapter, you’re going to dive in from a theoretical and hands-on perspective to truly get an understanding of monitoring and observability in Kubernetes. The goal is for you to be able to take what you learn and what you’ve implemented in your lab from this chapter and truly start to use it in production. First, you’ll learn what monitoring and observability actually are. Next, you’ll learn what monitoring and observability mean for the infrastructure layer, which is the virtual machines running the Kubernetes environment, and the specifics around Control Plane and worker node monitoring. After that, you’ll dive into monitoring and observability for specific Kubernetes resources such as Pods and Services. To finish up, you’ll look at specific tools and platforms that are typically used in today’s world for monitoring <span class="No-Break">and observability.</span></p>&#13;
			<p>Without monitoring, engineers wouldn’t know what’s happening inside a system or application. It’s the job of a DevOps and platform engineer to have that information and make good use of that information by fixing whatever <span class="No-Break">is broken.</span></p>&#13;
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>&#13;
			<ul>&#13;
				<li>How monitoring is different <span class="No-Break">than observability</span></li>&#13;
				<li>Monitoring and observability tools <span class="No-Break">for Kubernetes</span></li>&#13;
				<li><span class="No-Break">Observability practices</span></li>&#13;
				<li>Kubernetes <span class="No-Break">resource monitoring</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-162"><a id="_idTextAnchor163"/>Technical requirements</h1>&#13;
			<p>This chapter isn’t going to be a full-blown explanation of monitoring. Although there will be some brief explanations as a refresher/starting point, it’s important that you have some experience in monitoring and observability. For example, maybe you’ve used the Kubernetes Dashboard before or you’ve looked at pre-populated monitors inside of Azure or AWS. It could even be experience monitoring from your <span class="No-Break">local desktop.</span></p>&#13;
			<p>You can find the GitHub repo <span class="No-Break">here: </span><a href="https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch7/prometheus/helm"><span class="No-Break">https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch7/prometheus/helm</span></a><a href="https://github.com/AdminTurnedDevOps/Packt/tree/main/50-Kubernetes-concepts-every-DevOps-Engineer-should-know/Ch7%0D"/></p>&#13;
			<h1 id="_idParaDest-163"><a id="_idTextAnchor164"/>How is monitoring different than observability?</h1>&#13;
			<p>Two of the closest workflows<a id="_idIndexMarker424"/> and the two that are most often interchanged from a verbiage<a id="_idIndexMarker425"/> and explanation perspective are monitoring and observability. Although this chapter isn’t dedicated to observability, to truly understand the differences between monitoring and observability, you must understand both and ultimately see how they work. After the explanations in this section, you’ll see that there are key differences between observability and monitoring, along with differences in how they should be used, when they should be used, and the best practices <span class="No-Break">for them.</span></p>&#13;
			<p>What you might experience in organizations, depending on how mature their engineering teams are, is that monitoring and observability get thrown into one category. They are both either looked at the same way, or engineering teams think they’re doing observability when really all they’re doing is monitoring. One of the goals of this chapter is to give you the ability to differentiate between the two because there can be some blurred lines depending on what platforms and tools you’re using. For example, let’s take two of the most popular platforms – Datadog and New Relic. Both of these platforms are looked at as monitoring platforms and observability platforms. They can both do monitoring and observability, and they do them well. This is not always the case though. A platform such as Prometheus is just for observability and collecting metrics, but you can pair it with a monitoring platform/tool such as Grafana to give you a visual of what’s happening inside of <span class="No-Break">an environment.</span></p>&#13;
			<p>Monitoring and observability<a id="_idIndexMarker426"/> are both lengthy topics, especially<a id="_idIndexMarker427"/> in Kubernetes. The way that monitoring and observability are thought of in Kubernetes is similar to other platforms and systems, but <span class="No-Break">vastly different.</span></p>&#13;
			<p>In the next section, you’re going to look at what monitoring and observability are and how to know which you should use. We’ll also explore a few monitoring versus <span class="No-Break">observability examples.</span></p>&#13;
			<h2 id="_idParaDest-164"><a id="_idTextAnchor165"/>What’s monitoring?</h2>&#13;
			<p>Have you ever opened<a id="_idIndexMarker428"/> up <strong class="bold">Task Manager</strong> in Windows, gone to the performance settings, and looked at the memory and/or CPU usage? What about <strong class="bold">Activity Monitor</strong> on macOS to see what applications and programs were using memory and CPU? If you’ve done either of these things, which it is safe to assume that most engineers have done at one point or another, you’ve officially monitored a system! Now, you may be thinking to yourself that checking out the memory and CPU on a desktop or laptop is drastically different, but it’s actually not. Regardless of whether it’s a desktop or an entire server rack, RAM is RAM, CPU is CPU, and storage is storage. It doesn’t change across systems. The only thing that changes is the amount of CPU, memory, <span class="No-Break">and storage.</span></p>&#13;
			<p>So, what <span class="No-Break">is monitoring?</span></p>&#13;
			<p>Monitoring is the ability to view system resources, performance, and usage in real time. You can monitor anything in a Kubernetes cluster including <span class="No-Break">the following:</span></p>&#13;
			<ul>&#13;
				<li><span class="No-Break">Worker nodes</span></li>&#13;
				<li><span class="No-Break">Control Planes</span></li>&#13;
				<li><span class="No-Break">Pods</span></li>&#13;
				<li><span class="No-Break">Deployments</span></li>&#13;
				<li><span class="No-Break">ConfigMaps</span></li>&#13;
			</ul>&#13;
			<p>As well as these, you can also monitor<a id="_idIndexMarker429"/> literally any other Kubernetes resource that’s running in your cluster. From the application level to the infrastructure level to the networking level, it can all <span class="No-Break">be monitored.</span></p>&#13;
			<p>With monitoring can come the creation of alerts. I remember when I first got into tech and got my first<a id="_idIndexMarker430"/> internship, the coolest thing to me was walking into a <strong class="bold">network operations center</strong> (<strong class="bold">NOC</strong>) and seeing all the big screens with all the monitors on them. It was like we were protecting nuclear launch codes. It was amazing to see that every single system could be watched so engineers could understand what was happening underneath <span class="No-Break">the hood.</span></p>&#13;
			<p>In today’s world, engineers are still using things such as big monitors in a NOC, but with working from home and the remote world being the new norm, engineers are also logging in to monitoring platforms to view how systems are working. Engineers can log in to tools such as Datadog, CloudWatch, or Azure Monitor and see everything that’s happening with <span class="No-Break">every service.</span></p>&#13;
			<p>Let’s take a look at the screenshot in <span class="No-Break"><em class="italic">Figure 7</em></span><em class="italic">.1</em> from Azure. As you can see, there are a ton of monitoring <span class="No-Break">options available.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer097" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_01.jpg" alt="Figure 7.1 – The AKS monitoring options&#13;&#10;" width="509" height="807"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – The AKS monitoring options</p>&#13;
			<p>The monitoring options<a id="_idIndexMarker431"/> that you see in the <strong class="bold">Monitoring</strong> section also contain some observability practices (such as <strong class="bold">Metrics</strong>), which goes back to a point made earlier in the chapter – there’s some confusion when splitting up monitoring and <span class="No-Break">observability practices.</span></p>&#13;
			<p>From a monitoring perspective, what you should care about are the <span class="No-Break">actual monitors.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer098" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_02.jpg" alt="Figure 7.2 – AKS Monitoring&#13;&#10;" width="1209" height="416"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – AKS Monitoring</p>&#13;
			<p>The monitoring information that you can pull from AKS, or nearly any other Azure service, gives you the ability to see what’s happening right now or what’s been happening for an extended<a id="_idIndexMarker432"/> period of time. This gives you the ability to understand how a system is performing but from an ad <span class="No-Break">hoc perspective.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer099" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_03.jpg" alt="Figure 7.3 – The hardware metrics&#13;&#10;" width="1210" height="774"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – The hardware metrics</p>&#13;
			<p>The idea of this type of monitoring is to see and understand how cluster resources such as CPU, memory, storage, and bandwidth (inbound and outbound) are performing to ensure that you can make decisions about how a cluster should <span class="No-Break">be managed.</span></p>&#13;
			<p>You can also monitor applications that are running to see the uptime, how many resources they’re consuming, and the overall performance of <span class="No-Break">the apps.</span></p>&#13;
			<h3>Monitoring specifics on a Kubernetes cluster</h3>&#13;
			<p>The components<a id="_idIndexMarker433"/> on a Control Plane<a id="_idIndexMarker434"/> that you should monitor are the API server, etcd (the cluster store), controllers, and schedulers. The components on a worker node that you should monitor are Kubelet, container runtime, kube-proxy, and DNS. There’s also the need to monitor Pods, but you’ll be learning more about that at the end of <span class="No-Break">this chapter.</span></p>&#13;
			<p>In any circumstance, whether it’s components on the Control Plane or components on the worker node, you should ensure that the Metrics Server is running. You can technically retrieve metrics via the <strong class="source-inline">/metrics/resource</strong> endpoint (example: <strong class="source-inline">/metrics/pods</strong>), but that would mean you have to query each resource. The Metrics Server goes to each resource, fetches the metrics, and exposes them instead of you having to retrieve them one by one. You can find the Metrics Server, which you can use across any Kubernetes cluster, <span class="No-Break">here: </span><a href="https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml"><span class="No-Break">https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</span></a><span class="No-Break">.</span></p>&#13;
			<p>The Metrics Server endpoint<a id="_idIndexMarker435"/> comes from the Kubernetes <strong class="bold">Specific Interest Group</strong> (<strong class="bold">SIG</strong>) and can be deployed<a id="_idIndexMarker436"/> anywhere. Whether it’s a Kubernetes cluster<a id="_idIndexMarker437"/> running in AWS or a Kubeadm cluster running on virtual machines on your Windows 10 laptop, it doesn’t matter where the <span class="No-Break">cluster exists.</span></p>&#13;
			<h3>What’s the downside to monitoring?</h3>&#13;
			<p>The downside<a id="_idIndexMarker438"/> of monitoring, although it’s powerful, is that there’s not much that you can do with the data unless it’s happening in real time. Sure, you can get alerts if there’s an issue with a resource, but this means that an engineer would have to be on-call to fix the issue. They have to stop what they’re doing to put out a fire. With the way that the tech world is going, this is not a sustainable <span class="No-Break">model anymore.</span></p>&#13;
			<p>Along with that, engineers want to spend more time creating value-driven work. They don’t want to wake up at 2:00 A.M. due to getting an alert or stop coding a new feature because of an alert. Instead, they want a way to create automated and repeatable processes for an alert. For example, if an alert goes off, engineers want a way to create an automated process that can fix the problem if it happens. Then, they don’t have to stop what they’re doing to go put out a fire and can continue creating <span class="No-Break">value-driven work.</span></p>&#13;
			<p>This is where observability comes <span class="No-Break">into play.</span></p>&#13;
			<h2 id="_idParaDest-165"><a id="_idTextAnchor166"/>What’s observability?</h2>&#13;
			<p>Because monitoring and observability<a id="_idIndexMarker439"/> are sometimes used interchangeably when explaining them, it’s important to understand their differences. This way, as you dive deeper into monitoring, it’s easier to understand <span class="No-Break">the distinctions.</span></p>&#13;
			<p>Observability is mostly what you’ll see in Kubernetes and almost every other cloud-native system. However, monitoring and observability are starting to blend together in terms of what they mean. For example, in <span class="No-Break"><em class="italic">Figure 7</em></span><em class="italic">.1</em>, you saw the <strong class="bold">Monitoring</strong> section. Under the <strong class="bold">Monitoring</strong> section, there was a subsection for <strong class="bold">Metrics</strong>. The thing is, metrics technically fall <span class="No-Break">under observability.</span></p>&#13;
			<p>The reason why monitoring and observability are getting mashed together, or in other words, the reason why observability is becoming more popular, is that with observability, you can actually make decisions and automate workloads based on the data that <span class="No-Break">you receive.</span></p>&#13;
			<p>The key data points for observability practices are logs, metrics, <span class="No-Break">and traces.</span></p>&#13;
			<p>Again, we don’t want to go too deep in this section because observability has an entire chapter to itself. Just remember three <span class="No-Break">key things:</span></p>&#13;
			<ul>&#13;
				<li>Observability gives you the ability to perform an actual action with the data you’re receiving. That action could be to automatically fix a resource that’s <span class="No-Break">causing problems.</span></li>&#13;
				<li>It’s becoming increasingly popular over <span class="No-Break">traditional monitoring.</span></li>&#13;
				<li>Observability has three key aspects: logs, metrics, <span class="No-Break">and tracing.</span></li>&#13;
			</ul>&#13;
			<p class="callout-heading">A quick note on metrics</p>&#13;
			<p class="callout">Metrics for most Kubernetes resources<a id="_idIndexMarker440"/> are exposed. They’re exposed via the <strong class="source-inline">/metrics/resource</strong> endpoint. For example, <strong class="source-inline">/metrics/pods</strong> would be for the Pods <span class="No-Break">Kubernetes resource.</span></p>&#13;
			<p class="callout">To make things a bit easier, the Metrics Server, which isn’t installed on Kubernetes out of the box (depending on the cloud provider, but out of the box means a raw Kubernetes cluster installation), can scrape and consolidate all of the metric endpoints for the Kubernetes resources. This way, you don’t have to attempt to consume each metric via the resource one <span class="No-Break">by one.</span></p>&#13;
			<p class="callout">To kick things up a notch, there’s the kube-state-metrics tool, which you can install on a Kubernetes server; its job is to focus on the health of the Kubernetes resources/objects on your cluster. For example, if the Pods are actually available and ready is what kube-state-metrics will look at <span class="No-Break">and confirm.</span></p>&#13;
			<p class="callout">If you’re wondering<a id="_idIndexMarker441"/> what the difference is between the Metrics Server and kube-state-metrics, the Metrics Server shows cluster resource usage such as CPU and memory. On the other hand, kube-state-metrics is concerned with the health of the <span class="No-Break">Kubernetes resource.</span></p>&#13;
			<h2 id="_idParaDest-166"><a id="_idTextAnchor167"/>Monitoring versus observability examples</h2>&#13;
			<p>When thinking about<a id="_idIndexMarker442"/> how to implement monitoring, observability, or both, it’s best<a id="_idIndexMarker443"/> to think about the implementation details from a <span class="No-Break">scenario perspective.</span></p>&#13;
			<p>Let’s take two scenarios – one for a containerized application from a monitoring perspective and then taking the same containerized application, but looking at it from an <span class="No-Break">observability perspective.</span></p>&#13;
			<p>The following examples won’t be a complete step-by-step guide. The code works, but it won’t be explained in terms of how exactly to deploy and run it. Feel free to go through it on your own system, but the aim in this chapter is to show examples of the workflow rather than a complete <span class="No-Break">step-by-step tutorial.</span></p>&#13;
			<h3>Monitoring use case</h3>&#13;
			<p>The first scenario<a id="_idIndexMarker444"/> can be thought about as, for example, a frontend application. It could be an Nginx web app, which is simple and hosts a website. It could be something as simple as the following <span class="No-Break">Nginx configuration:</span></p>&#13;
			<pre class="source-code">&#13;
apiVersion: apps/v1&#13;
kind: Deployment&#13;
metadata:&#13;
  name: nginx-deployment&#13;
spec:&#13;
  selector:&#13;
    matchLabels:&#13;
      app: nginxdeployment&#13;
  replicas: 2&#13;
  template:&#13;
    metadata:&#13;
      labels:&#13;
        app: nginxdeployment&#13;
    spec:&#13;
      containers:&#13;
      - name: nginxdeployment&#13;
        image: nginx:latest&#13;
        ports:&#13;
        - containerPort: 80</pre>&#13;
			<p>With the preceding Kubernetes<a id="_idIndexMarker445"/> manifest, you can picture an application that’s running with two replicas on a Kubernetes cluster. To retrieve the memory and CPU information of the Pod, you can run the <strong class="source-inline">kubectl </strong><span class="No-Break"><strong class="source-inline">top</strong></span><span class="No-Break"> command:</span></p>&#13;
			<pre class="console">&#13;
kubectl top pod pod_name</pre>&#13;
			<div>&#13;
				<div id="_idContainer100" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_04.jpg" alt="Figure 7.4 – The top command&#13;&#10;" width="1212" height="154"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – The top command</p>&#13;
			<p>An error can sometimes occur if the Metrics API isn’t enabled, as it’s disabled by default. If you’d like to enable it, check the documentation for where you’re running the Kubernetes cluster. As an example, here’s how you’d enable the Metrics API <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">minikube</strong></span><span class="No-Break">:</span></p>&#13;
			<pre class="console">&#13;
minikube addons enable metrics-server</pre>&#13;
			<p>To stress-test the workload, you<a id="_idIndexMarker446"/> can use a stress/performance testing tool such as <strong class="source-inline">k6</strong>. The following is an example configuration that you <span class="No-Break">can use:</span></p>&#13;
			<pre class="source-code">&#13;
import http from 'k6/http';&#13;
import { sleep } from 'k6';&#13;
export default function () {&#13;
  http.get('https://test.k6.io');&#13;
  sleep(1);&#13;
}</pre>&#13;
			<p>You can then save the preceding configuration and use it as a stress test with the following command, which specifies 100 virtual users and runs for <span class="No-Break">30 seconds:</span></p>&#13;
			<pre class="console">&#13;
k6 run --vus 100 --duration 30s test.js</pre>&#13;
			<div>&#13;
				<div id="_idContainer101" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_05.jpg" alt="Figure 7.5 – The benchmark test&#13;&#10;" width="1186" height="420"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.5 – The benchmark test</p>&#13;
			<p>Running the <strong class="source-inline">kubectl top</strong> command again, you can see that the <span class="No-Break">memory increased:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer102" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_06.jpg" alt="Figure 7.6 – The kubectl top command for a Pod&#13;&#10;" width="1211" height="98"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.6 – The kubectl top command for a Pod</p>&#13;
			<p>After logging in to a piece of monitoring software, such as the Kubernetes Dashboard (which you’ll learn about in the upcoming section), you will be able to see the CPU and memory utilization for <span class="No-Break">both Pods.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer103" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_07.jpg" alt="Figure 7.7 – The Pods running&#13;&#10;" width="1089" height="262"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.7 – The Pods running</p>&#13;
			<p>This information gives you the ability<a id="_idIndexMarker447"/> to monitor what happens when more and more users access your application, which is very common for a <span class="No-Break">frontend application.</span></p>&#13;
			<h3>Observability use case</h3>&#13;
			<p>The second scenario is going<a id="_idIndexMarker448"/> to be around checking out the Nginx Pods and Services that can be created from the Nginx configuration in the previous section. Ultimately, you’ll be able to see how you can capture and view metrics data in an observability tool. Although <span class="No-Break"><em class="italic">Figure 7</em></span><em class="italic">.8</em> shows Prometheus, regardless of which observability tool you use, you’re still going to see the same data because it’s being retrieved via the Kubernetes <span class="No-Break">Metrics API.</span></p>&#13;
			<p>When the Metrics Server is enabled on a Kubernetes cluster, it exposes several resource metric endpoints. One of the resource metric endpoints is Pods. You can confirm that your Pod metrics are getting ingested into Prometheus based on <span class="No-Break"><strong class="bold">Service Discovery</strong></span><span class="No-Break">.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer104" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_08.jpg" alt="Figure 7.8 – A Pod discovery&#13;&#10;" width="768" height="1022"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.8 – A Pod discovery</p>&#13;
			<p>You can then confirm how Pods<a id="_idIndexMarker449"/> are running based on different queries that Prometheus allows you to check with. For example, the following screenshot shows Kubernetes Service resource information, and you can see that the Nginx service <span class="No-Break">is running.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer105" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_09.jpg" alt="Figure 7.9 – Kubernetes Service metrics&#13;&#10;" width="1211" height="978"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.9 – Kubernetes Service metrics</p>&#13;
			<p>You can also dive a little deeper and query based on certain hardware resources, such as memory and CPU. This way, you can understand how many resources (memory, CPU, and so on) are being taken up by <span class="No-Break">each Pod.</span></p>&#13;
			<p>For example, the following snippet is a query to see <span class="No-Break">memory usage:</span></p>&#13;
			<pre class="source-code">&#13;
avg((avg (container_memory_working_set_bytes{pod="nginx-deployment-588c8d7b4b-6dm7m"}) by (container_name , pod ))/ on (container_name , pod)(avg (container_spec_memory_limit_bytes&gt;0 ) by (container_name, pod))*100)</pre>&#13;
			<p>Notice how a Pod name<a id="_idIndexMarker450"/> is specified; this will show you the observability metrics around memory for the <span class="No-Break">specified Pod.</span></p>&#13;
			<h1 id="_idParaDest-167"><a id="_idTextAnchor168"/>Monitoring and observability tools for Kubernetes</h1>&#13;
			<p>Typically, in any tech book, the theory/practical knowledge<a id="_idIndexMarker451"/> comes first, then the tooling. However, monitoring<a id="_idIndexMarker452"/> and observability<a id="_idIndexMarker453"/> are a bit different<a id="_idIndexMarker454"/> because you can’t really talk about the specifics without mentioning or showing a certain tool/platform. Because of this, prior to jumping into the specifics around <em class="italic">how</em> to monitor and implement observability, you’re going to learn about a few <span class="No-Break">key tools.</span></p>&#13;
			<p>The goal of this section is to help you first understand what the tools look like and then take the theory that you learn and utilize it in the tools. When you combine the knowledge and visuals (UI) of the tools with the understanding of what true monitoring and observability are, you can successfully implement them in <span class="No-Break">your environment.</span></p>&#13;
			<p>One of the interesting things about monitoring is that you can fully understand it from a theoretical perspective, but implementing it can be a challenge. For example, you can understand what the metrics endpoint in Kubernetes is, how it works, what metrics are exposed, and what resources you can monitor from those metrics. However, actually setting up a platform to <em class="italic">listen</em> to the metrics and configuring that listener is vastly different than reading about how <span class="No-Break">metrics work.</span></p>&#13;
			<p>Although this section won’t cover all the tools and platforms used to monitor Kubernetes, this list is a great place to start as they are the most widely used in organizations. The good news is that even if you come across a monitoring tool that isn’t covered in this section, monitoring is monitoring. That means once you understand monitoring and how it works with Kubernetes, you’re pretty much good to go in terms of learning other monitoring tools. It’s all the same stuff at the end of the day. The underlying components of what monitoring is doesn’t change. The only thing that changes is how the <span class="No-Break">dashboards look.</span></p>&#13;
			<p>In this section, you’re going to learn about <span class="No-Break">the following:</span></p>&#13;
			<ul>&#13;
				<li>The built-in <span class="No-Break">Kubernetes Dashboard</span></li>&#13;
				<li>Cloud-specific monitoring and <span class="No-Break">observability tools</span></li>&#13;
				<li><span class="No-Break">Grafana/Prometheus</span></li>&#13;
				<li>How to use and set <span class="No-Break">monitoring tools</span></li>&#13;
			</ul>&#13;
			<h2 id="_idParaDest-168"><a id="_idTextAnchor169"/>The Kubernetes Dashboard</h2>&#13;
			<p>The Kubernetes Dashboard<a id="_idIndexMarker455"/> is as <em class="italic">native</em> as it gets in terms of monitoring and observability. Although it’s not configured out of the box, it’s fairly easy to get configuration across almost any environment. It’s the quickest way to see what’s happening inside a <span class="No-Break">Kubernetes cluster.</span></p>&#13;
			<p class="callout-heading">Important note</p>&#13;
			<p class="callout">We’re using <strong class="source-inline">minikube</strong> for this because it’s straightforward. If you decide to use the Kubernetes Dashboard on another Kubernetes cluster, the visual of the dashboard itself isn’t going to be any different. The only difference will be the Kubernetes resources that <span class="No-Break">you see.</span></p>&#13;
			<p>First, start <strong class="source-inline">minikube</strong>. If you don’t have <strong class="source-inline">minikube</strong> already<a id="_idIndexMarker456"/> installed, you can install it here: <a href="https://minikube.sigs.k8s.io/docs/start/"><span class="No-Break">https://minikube.sigs.k8s.io/docs/start/</span></a><span class="No-Break">:</span></p>&#13;
			<pre class="console">&#13;
minikube start</pre>&#13;
			<div>&#13;
				<div id="_idContainer106" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_10.jpg" alt="Figure 7.10 – Starting minikube&#13;&#10;" width="971" height="312"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.10 – Starting minikube</p>&#13;
			<p>Next, run the following command to start <span class="No-Break">the dashboard:</span></p>&#13;
			<pre class="console">&#13;
minikube dashboard –url</pre>&#13;
			<div>&#13;
				<div id="_idContainer107" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_11.jpg" alt="Figure 7.11 – The default Kubernetes Dashboard&#13;&#10;" width="1081" height="618"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.11 – The default Kubernetes Dashboard</p>&#13;
			<p>At this point, you can<a id="_idIndexMarker457"/> see several different pieces of information about your <strong class="source-inline">minikube</strong> cluster, from Pod info to other Kubernetes resources. You can see Pods that are running and healthy, and workloads that may need to <span class="No-Break">be fixed.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer108" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_12.jpg" alt="Figure 7.12 – A Deployment example&#13;&#10;" width="984" height="403"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.12 – A Deployment example</p>&#13;
			<p>Next, you can see the overall <span class="No-Break">deployment status.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer109" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_13.jpg" alt="Figure 7.13 – The Pod status&#13;&#10;" width="1088" height="667"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.13 – The Pod status</p>&#13;
			<p>After that, you can dive<a id="_idIndexMarker458"/> even deeper to see Pods running in the <span class="No-Break"><strong class="bold">Deployments</strong></span><span class="No-Break"> tab.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer110" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_14.jpg" alt="Figure 7.14 – The Pods running&#13;&#10;" width="1050" height="725"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.14 – The Pods running</p>&#13;
			<p>One thing to point out here is that the Kubernetes Dashboard is almost never used for a production-level scenario. It’s typically used to look at some information quickly if needed. For true observability and alerting in an environment, one of the more appropriate (production-ready) monitoring <a id="_idIndexMarker459"/>and observability tools is typically used, which you’ll <span class="No-Break">see next.</span></p>&#13;
			<h2 id="_idParaDest-169"><a id="_idTextAnchor170"/>Azure Monitor</h2>&#13;
			<p>If you strictly have Azure workloads<a id="_idIndexMarker460"/> or even workloads outside of Azure and you’re utilizing Azure Arc (like on-premises), Azure Monitor is a great built-in solution. You have the ability to capture logs and metrics, create alerts, and see in real time what’s happening inside your environment. For example, you can view the CPU and memory usage of a cluster, along with the Pod and other Kubernetes <span class="No-Break">resource data.</span></p>&#13;
			<p>In <a href="B19116_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, you learned how to create an AKS cluster with Terraform. You can utilize that same code for this section. For a quicker reference, here is the <span class="No-Break">link: </span><a href="https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch2/AKS"><span class="No-Break">https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch2/AKS</span></a><span class="No-Break">.</span></p>&#13;
			<p>Once your AKS cluster<a id="_idIndexMarker461"/> is configured, log in to the Azure portal and go to <strong class="bold">Kubernetes services</strong>. Then, you should see an <strong class="bold">Insights</strong> tab <span class="No-Break">under </span><span class="No-Break"><strong class="bold">Monitoring</strong></span><span class="No-Break">.</span></p>&#13;
			<p>Enable Insights by clicking the blue <strong class="bold">Configure azure </strong><span class="No-Break"><strong class="bold">monitor</strong></span><span class="No-Break"> button.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer111" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_15.jpg" alt="Figure 7.15 – Azure Insights&#13;&#10;" width="1022" height="689"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.15 – Azure Insights</p>&#13;
			<p>Azure Insights gives you the ability to monitor everything in your AKS cluster from the entire environment, to the nodes, all the way down to the Pods <span class="No-Break">and containers.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer112" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_16.jpg" alt="Figure 7.16 – Insights data&#13;&#10;" width="1214" height="661"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.16 – Insights data</p>&#13;
			<p>For example, by diving<a id="_idIndexMarker462"/> into <strong class="bold">Containers</strong> (Pods), you can see the status, utilization, <span class="No-Break">and uptime.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer113" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_17.jpg" alt="Figure 7.17 – The Container data&#13;&#10;" width="1170" height="727"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.17 – The Container data</p>&#13;
			<p>Within <strong class="bold">Nodes</strong>, you can see the specific Pods running on each worker node, including the health of <span class="No-Break">the Pod.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer114" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_18.jpg" alt="Figure 7.18 – The Node data&#13;&#10;" width="1104" height="621"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.18 – The Node data</p>&#13;
			<p>Azure Monitor<a id="_idIndexMarker463"/> and Insights is a great overall solution for Kubernetes workloads. If you’re in the Azure ecosystem, I wouldn’t recommend looking at another solution. Stick to <span class="No-Break">what’s native.</span></p>&#13;
			<h2 id="_idParaDest-170"><a id="_idTextAnchor171"/>AWS Container Insights</h2>&#13;
			<p>Container Insights<a id="_idIndexMarker464"/> is part of the AWS CloudWatch family and gives you the ability to view containerized workloads for performance and monitoring-related actions. You can create alerts based on Container Insights, along with pull logs and metrics to take action on anything that may occur from an automated and <span class="No-Break">repeatable perspective.</span></p>&#13;
			<p>In <a href="B19116_02.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, you learned how to create an EKS cluster with Terraform. You can utilize the same code for this section. For a quicker reference, here is the <span class="No-Break">link: </span><a href="https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch2/AWS"><span class="No-Break">https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch2/AWS</span></a><span class="No-Break">.</span></p>&#13;
			<p>After you run the EKS Terraform configuration, run the following command to retrieve the Kubernetes configuration (<strong class="source-inline">kubeconfig</strong>) from the <span class="No-Break">EKS cluster:</span></p>&#13;
			<pre class="console">&#13;
aws eks update-kubeconfig –region region_where_cluster_exists –name name_of_your_cluster</pre>&#13;
			<p>To confirm that your current<a id="_idIndexMarker465"/> context is set, run the following command and you should see a <span class="No-Break">similar output:</span></p>&#13;
			<pre class="console">&#13;
kubectl get nodes&#13;
NAME                             STATUS   ROLES    AGE    VERSION&#13;
ip-192-168-16-238.ec2.internal   Ready    &lt;none&gt;   18m    v1.23.9-eks-ba74326</pre>&#13;
			<p>Next, configure AWS Container Insights for <span class="No-Break">your cluster:</span></p>&#13;
			<pre class="source-code">&#13;
ClusterName= name_of_your_cluster&#13;
RegionName= region_where_cluster_exists&#13;
FluentBitHttpPort='2020'&#13;
FluentBitReadFromHead='Off'&#13;
[[ ${FluentBitReadFromHead} = 'On' ]] &amp;&amp; FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On'&#13;
[[ -z ${FluentBitHttpPort} ]] &amp;&amp; FluentBitHttpServer='Off' || FluentBitHttpServer='On'&#13;
curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | sed 's/{{cluster_name}}/'${ClusterName}'/;s/{{region_name}}/'${RegionName}'/;s/{{http_server_toggle}}/"'${FluentBitHttpServer}'"/;s/{{http_server_port}}/"'${FluentBitHttpPort}'"/;s/{{read_from_head}}/"'${FluentBitReadFromHead}'"/;s/{{read_from_tail}}/"'${FluentBitReadFromTail}'"/' | kubectl apply -f –</pre>&#13;
			<p>After the preceding code runs, you’ll see <a id="_idIndexMarker466"/>an output similar to the terminal output <span class="No-Break">pasted here:</span></p>&#13;
			<pre class="source-code">&#13;
namespace/amazon-cloudwatch created&#13;
serviceaccount/cloudwatch-agent created&#13;
clusterrole.rbac.authorization.k8s.io/cloudwatch-agent-role created&#13;
clusterrolebinding.rbac.authorization.k8s.io/cloudwatch-agent-role-binding created&#13;
configmap/cwagentconfig created&#13;
daemonset.apps/cloudwatch-agent created&#13;
configmap/fluent-bit-cluster-info created&#13;
serviceaccount/fluent-bit created&#13;
clusterrole.rbac.authorization.k8s.io/fluent-bit-role created&#13;
clusterrolebinding.rbac.authorization.k8s.io/fluent-bit-role-binding created&#13;
configmap/fluent-bit-config created&#13;
daemonset.apps/fluent-bit created</pre>&#13;
			<p>At this point, if you log in to AWS and go to <strong class="bold">CloudWatch</strong> | <strong class="bold">Container Insights</strong>, you can see that Container Insights is <span class="No-Break">properly configured.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer115" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_19.jpg" alt="Figure 7.19 – The Container Insights output&#13;&#10;" width="1045" height="733"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.19 – The Container Insights output</p>&#13;
			<p>Next, we’ll dive into a very popular stack in the Kubernetes space – Grafana <span class="No-Break">and Prometheus.</span></p>&#13;
			<h2 id="_idParaDest-171"><a id="_idTextAnchor172"/>Grafana/Prometheus</h2>&#13;
			<p>Arguably, the most popular<a id="_idIndexMarker467"/> implementation<a id="_idIndexMarker468"/> of a monitoring/observability scenario for Kubernetes is Grafana and Prometheus. Grafana and Prometheus work outside of Kubernetes environments as well, but they became extremely popular in the Kubernetes ecosystem. In fact, there’s even a Prometheus operator <span class="No-Break">for Kubernetes.</span></p>&#13;
			<p>Aside from the standard monitoring and observability benefits, engineers really enjoy the combination because it’s 100% open source. In Grafana for example, you can create any type of dashboard you want with a little bit of code and it’s all free. Grafana and Prometheus can also run anywhere. The stack can run inside your Kubernetes cluster or completely separate on its <span class="No-Break">own servers.</span></p>&#13;
			<p>Although you can configure Prometheus and Grafana separately with all the bells and whistles, we’re going<a id="_idIndexMarker469"/> to utilize the power of the <strong class="bold">Prometheus Community Helm Chart</strong>. The reason why is that it radically simplifies the Prometheus and Grafana installation from an automated and repeatable standpoint. It installs both Prometheus and Grafana, along with setting up dashboards <span class="No-Break">for us.</span></p>&#13;
			<p>Before jumping in, one thing<a id="_idIndexMarker470"/> that you’ll always need to do no matter what monitoring and observability<a id="_idIndexMarker471"/> platform you’re on is to ensure that you are collecting metrics in the way you’re expecting. For example, the Kubernetes Metrics Server or an adapter of sorts. For example, Prometheus has an adapter that can be used instead of the Metrics Server. You can also go straight to the source by utilizing the metrics endpoint from <strong class="source-inline">/metrics/resource</strong> (for example, <strong class="source-inline">/metrics/pods</strong>), but generally, engineers opt to use the <span class="No-Break">Metrics Server.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer116" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_20.jpg" alt="Figure 7.20 – The metrics Pods&#13;&#10;" width="757" height="282"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.20 – The metrics Pods</p>&#13;
			<p>If you don’t expose the metrics endpoint, Kubernetes won’t allow the system to consume said metrics. In terms of enabling the Metrics Server, it all depends on where you’re running Kubernetes. For example, in AKS, it’s automatically exposed for you. If you don’t see the metrics Pods in the <strong class="source-inline">kube-system</strong> namespace for your Kubernetes cluster (depending on what environment you deployed Kubernetes in), check the documentation for that type of Kubernetes environment to see how you can enable the <span class="No-Break">metrics endpoint.</span></p>&#13;
			<p>First, add <strong class="source-inline">helm repo</strong> <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">prometheus-community</strong></span><span class="No-Break">:</span></p>&#13;
			<pre class="console">&#13;
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts</pre>&#13;
			<p>Next, ensure that the repo is up <span class="No-Break">to date:</span></p>&#13;
			<pre class="console">&#13;
helm repo update</pre>&#13;
			<p>For the last step, install the Helm chart in the <span class="No-Break"><strong class="source-inline">monitoring</strong></span><span class="No-Break"> namespace:</span></p>&#13;
			<pre class="console">&#13;
helm install prometheus prometheus-community/kube-prometheus-stack –namespace monitoring –create-namespace</pre>&#13;
			<p>Once installed, you should see several Kubernetes resources created in the <strong class="source-inline">monitoring</strong> namespace. To access Grafana, you can use <span class="No-Break">port forwarding:</span></p>&#13;
			<pre class="console">&#13;
kubectl -namespace monitoring port-forward svc/prometheus-grafana :80</pre>&#13;
			<p>The default username/password for Grafana <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">admin/prom-operator</strong></span><span class="No-Break">.</span></p>&#13;
			<p>After logging in to<a id="_idIndexMarker472"/> Grafana, check out the Pods<a id="_idIndexMarker473"/> in the dashboard for the <strong class="source-inline">kube-system</strong> namespace. You can see that metrics are being ingested by Prometheus and pushed to Grafana from <span class="No-Break">all namespaces.</span></p>&#13;
			<p>To see metrics, go to <strong class="bold">Dashboards</strong> | <span class="No-Break"><strong class="bold">Browse</strong></span><span class="No-Break">:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer117" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_21.jpg" alt="Figure 7.21 – Browsing the dashboards&#13;&#10;" width="439" height="423"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.21 – Browsing the dashboards</p>&#13;
			<p>Click the <strong class="bold">Kubernetes / Compute Resources / Namespace (</strong><span class="No-Break"><strong class="bold">Pods)</strong></span><span class="No-Break"> option:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer118" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_22.jpg" alt="Figure 7.22 – The Pods dashboard&#13;&#10;" width="805" height="520"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.22 – The Pods dashboard</p>&#13;
			<p>Change the namespace to a namespace that has Pods already, such as <strong class="source-inline">kube-system</strong>, and you can see the Pod metrics in the <span class="No-Break">following screenshot:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer119" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_23_NEW.jpg" alt="Figure 7.23 – The namespace selection&#13;&#10;" width="667" height="546"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.23 – The namespace selection</p>&#13;
			<p>Prometheus/Grafana<a id="_idIndexMarker474"/> is a powerful combination<a id="_idIndexMarker475"/> that allows you to stay vendor neutral and get everything you need as an open <span class="No-Break">source option.</span></p>&#13;
			<h1 id="_idParaDest-172"><a id="_idTextAnchor173"/>Observability practices</h1>&#13;
			<p>Now, let’s define what observability truly is by looking at logs, traces, and metrics. When you use tools such as Prometheus, you’re doing a <em class="italic">piece</em> of observability. When you use other tools such as Logz.io or another log aggregator, you’re using another piece <span class="No-Break">of observability.</span></p>&#13;
			<h2 id="_idParaDest-173"><a id="_idTextAnchor174"/>Logging</h2>&#13;
			<p>Logging is aggregating<a id="_idIndexMarker476"/> and storing logged event messages written by programs and systems. As you can imagine, depending on how verbose the logs are set in an application, there will be a lot of events. A sysadmin’s favorite tool is a log because it literally shows everything and anything that could happen from an event’s perspective. However, it’s not efficient to simply comb through all of it with your eyes. Instead, using observability practices, you can send the logs to a log aggregator and ensure that a specific type of log that occurs can trigger an alert or some type of automation to go in and fix <span class="No-Break">the issue.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer120" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_24.jpg" alt="Figure 7.24 – Logging service discovery&#13;&#10;" width="1637" height="995"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.24 – Logging service discovery</p>&#13;
			<p>There are a few logging practices when it comes <span class="No-Break">to containers:</span></p>&#13;
			<ul>&#13;
				<li><strong class="bold">Application forwarding</strong>: Sending logs directly via the app. For<a id="_idIndexMarker477"/> example, maybe you have some code inside of your application using a Prometheus library that collects the logs, metrics, and traces, and sends it to whatever backend logging platform <span class="No-Break">you’re using.</span></li>&#13;
				<li><strong class="bold">Sidecar</strong>: Using a sidecar container<a id="_idIndexMarker478"/> to manage logs for an app. For example, you can containerize some logging systems to run as a secondary/sidecar container inside of your Pod(s). The sidecar container’s job is to do one thing; retrieve and send logs about what’s happening on <span class="No-Break">the Pod.</span></li>&#13;
				<li><strong class="bold">Node agent forward</strong>: Run a Pod on each worker node<a id="_idIndexMarker479"/> that forwards all container logs to <span class="No-Break">the backend.</span></li>&#13;
			</ul>&#13;
			<h2 id="_idParaDest-174"><a id="_idTextAnchor175"/>Metrics</h2>&#13;
			<p>Metrics are about collecting time series <a id="_idIndexMarker480"/>data, which is used to predict expected ranges and forecast values, showing it in dashboards (such as Grafana or another UI-centric dashboard), and alerting on it. Metric endpoints will give a bunch of information that you can act upon. From a pure Kubernetes perspective, the metrics endpoint collects Kubernetes resource data from the kubelet that’s running on each worker node and exposes it to the API server through the <span class="No-Break">Metrics API.</span></p>&#13;
			<p>As mentioned in this chapter, there’s a metrics endpoint that runs as a Pod. Depending on the type of Kubernetes cluster you’re running, the Pod could either be enabled by default or it may be something that you have to <span class="No-Break">turn on.</span></p>&#13;
			<p>For example, in an AKS cluster, the metrics Pod is running, which means all of the Kubernetes resources have a metrics endpoint that can <span class="No-Break">be consumed.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer121" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_25.jpg" alt="Figure 7.25 – The metrics Pod&#13;&#10;" width="752" height="275"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.25 – The metrics Pod</p>&#13;
			<p>For another type of Kubernetes<a id="_idIndexMarker481"/> cluster, such as something running on Kubeadm, you would have to enable the metrics endpoint by deploying the Pod. You can do that by deploying the Kubernetes manifest in the <strong class="source-inline">kubernetes-sigs</strong> repo <span class="No-Break">on GitHub:</span></p>&#13;
			<pre class="console">&#13;
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</pre>&#13;
			<p>However, that’s not all. Because a cluster configuration such as Kubeadm has node IPs that aren’t part of the certificate SAN on the cluster, the metrics endpoint will fail due to a TLS <span class="No-Break">connection error.</span></p>&#13;
			<p>To get around this, you have to add the following line to a <span class="No-Break">few configurations:</span></p>&#13;
			<pre class="console">&#13;
serverTLSBootstrap: true</pre>&#13;
			<p>There are two places you need to add <span class="No-Break">it to.</span></p>&#13;
			<p>First, the Kubeadm config. You can edit it by running <strong class="source-inline">kubectl edit cm -n kube-system kubeadm-config</strong> and then add in the <strong class="source-inline">serverTLSBootstrap: </strong><span class="No-Break"><strong class="source-inline">true</strong></span><span class="No-Break"> line.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer122" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_26.jpg" alt="Figure 7.26 – The kubeadm config&#13;&#10;" width="687" height="945"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.26 – The kubeadm config</p>&#13;
			<p>Next, you’ll have to update the kubelet on each node (all Control Planes and worker nodes) with the same<a id="_idIndexMarker482"/> line. To edit the kubelet on each node, you can run the following command and add in <span class="No-Break">the configuration:</span></p>&#13;
			<pre class="console">&#13;
sudo vim /var/lib/kubelet/config.yaml</pre>&#13;
			<div>&#13;
				<div id="_idContainer123" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_27.jpg" alt="Figure 7.27 – The kubelet config&#13;&#10;" width="843" height="599"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.27 – The kubelet config</p>&#13;
			<h2 id="_idParaDest-175"><a id="_idTextAnchor176"/>Traces</h2>&#13;
			<p>Traces are all about telling you the health <a id="_idIndexMarker483"/>of an application from an <span class="No-Break">end-to-end perspective.</span></p>&#13;
			<p>You can think of a trace as the <em class="italic">path</em> or <em class="italic">journey</em> of a request as it goes through the system. For example, when you go to <strong class="source-inline">www.google.com</strong>, although it happens extremely fast, there’s a bunch of work that’s happening underneath the hood. At a high level, the <strong class="source-inline">GET</strong> request that you’re creating to reach <strong class="source-inline">www.google.com</strong> is going through the frontend, then probably some middleware, then to the backend. When you Google something such as <strong class="source-inline">top ten places to go in the summertime</strong>, there are several requests that are occurring to retrieve that information from the <span class="No-Break">backend database.</span></p>&#13;
			<p>The journey from when you perform a Google search request to when the information is portrayed to you – that journey is what a <span class="No-Break">trace is.</span></p>&#13;
			<p>Because it’s a long journey, although only seconds to us humans, it can give us a lot of information from an engineering perspective on how an application is performing. We can then take action on that performance concern from a repeatable methodology instead of fixing the issue manually, or from a troubleshooting perspective. If you’re looking at a trace and realize that the <em class="italic">journey</em> stopped or was held up once it hit the backend, you now<a id="_idIndexMarker484"/> know where to <span class="No-Break">start troubleshooting.</span></p>&#13;
			<h1 id="_idParaDest-176"><a id="_idTextAnchor177"/>Monitoring Kubernetes resources</h1>&#13;
			<p>In the previous section, you learned all about monitoring<a id="_idIndexMarker485"/> from an overall observability<a id="_idIndexMarker486"/> perspective, in particular setting up certain tools and ensuring that they work for you. Now it’s time to go underneath the Kubernetes hood and begin to think about what can be monitored from a resource perspective. Remember, a Kubernetes resource (sometimes<a id="_idIndexMarker487"/> called an object) can be anything, from Services, to Ingress controllers, to Pods. Because of that, there’s a lot <span class="No-Break">to monitor.</span></p>&#13;
			<p>Think about it from this perspective. You’re running a Pod that’s running a container inside of the Pod. The Pod itself is running great. The container image works, with no CPU or memory issues, and all of the events state that the Pod is up and running successfully. However, there’s a problem – the binary (the app entry point) running inside of the container may be down, or not working as expected. Because of this, you need a way to truly see even underneath the hood of a <span class="No-Break">Pod itself!</span></p>&#13;
			<p>As you’ve learned throughout this book, it doesn’t really matter where you’re running Kubernetes. The core components of how it runs and how you would interact with it are the same. That’s no different for monitoring. Because of that, this section of the chapter will show monitoring in AKS. However, as you’ll quickly see, it doesn’t matter whether these Pods are running in AKS or not. They would be looked at (monitored) the same way even if you use a different <span class="No-Break">monitoring system.</span></p>&#13;
			<p>The code in this section, along with the demo app being deployed, can be used on any <span class="No-Break">Kubernetes cluster.</span></p>&#13;
			<h2 id="_idParaDest-177"><a id="_idTextAnchor178"/>Monitoring Pods</h2>&#13;
			<p>Inside a Pod<a id="_idIndexMarker488"/> is either one or more<a id="_idIndexMarker489"/> containers. Whether it’s one container or multiple containers, the containers are what’s actually running an application. Perhaps it’s a core app, a logging software, or even something such as HashiCorp Vault or a service mesh proxy. These containers that are beside<a id="_idIndexMarker490"/> the main app are called sidecar containers. Because there are multiple containers running inside a Pod, you must ensure that each container is actually up and running as expected. Otherwise, the Pod itself may be running properly, and the main app may even be running properly, but the full workload, such as the sidecar containers, may <span class="No-Break">not be.</span></p>&#13;
			<p>First, ensure that the HashiCorp Consul Helm <span class="No-Break">chart exists:</span></p>&#13;
			<pre class="console">&#13;
helm repo add hashicorp https://helm.releases.hashicorp.com</pre>&#13;
			<p>Next, create a new namespace <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">consul</strong></span><span class="No-Break">:</span></p>&#13;
			<pre class="console">&#13;
kubectl create namespace consul</pre>&#13;
			<p>Once the <strong class="source-inline">consul</strong> namespace<a id="_idIndexMarker491"/> exists, deploy Consul<a id="_idIndexMarker492"/> to Kubernetes inside of the <span class="No-Break"><strong class="source-inline">consul</strong></span><span class="No-Break"> namespace:</span></p>&#13;
			<pre class="console">&#13;
helm upgrade –install -n consul consul hashicorp/consul –wait -f - &lt;&lt;EOF&#13;
global:&#13;
  name: consul&#13;
server:&#13;
  replicas: 1&#13;
  bootstrapExpect: 1&#13;
connectInject:&#13;
  enabled: true&#13;
EOF</pre>&#13;
			<p>The last step is to deploy the demo app and ensure that the annotation for injecting <strong class="source-inline">consul</strong> as a <span class="No-Break">sidecar exists:</span></p>&#13;
			<pre class="console">&#13;
Curl -sL https://run.linkerd.io/emojivoto.yml \&#13;
  | sed 's|    metadata: |    metadata:\n      annotations:\n         consul.hashicorp.com/connect-inject" "tr"e'|' \&#13;
  | se' 's|targetPort: 8080|targetPort: 2000'|' \&#13;
  | kubectl apply -f -</pre>&#13;
			<p>After deploying the app, you should see an output similar to the <span class="No-Break">following screenshot:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer124" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_28.jpg" alt="Figure 7.28 – Linkerd deployment&#13;&#10;" width="1162" height="313"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.28 – Linkerd deployment</p>&#13;
			<p>Log in to the Azure portal, go<a id="_idIndexMarker493"/> to your AKS cluster, and turn on Azure Insights<a id="_idIndexMarker494"/> if it’s not <span class="No-Break">already on:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer125" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_29.jpg" alt="Figure 7.29 – Enabling container insights&#13;&#10;" width="1036" height="579"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.29 – Enabling container insights</p>&#13;
			<p>Once <strong class="bold">Insights</strong> is enabled, you should be able to see several resources available. Click on the <span class="No-Break"><strong class="bold">Controllers</strong></span><span class="No-Break"> button.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer126" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_30.jpg" alt="Figure 7.30 – The Controllers dashboard&#13;&#10;" width="827" height="249"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.30 – The Controllers dashboard</p>&#13;
			<p>Looking at the <strong class="bold">Controllers</strong> dashboard, you can<a id="_idIndexMarker495"/> see all the Kubernetes resources running along <a id="_idIndexMarker496"/>with the status, uptime, and how many containers exist in <span class="No-Break">each resource.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer127" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_31.jpg" alt="Figure 7.31 – The Kubernetes resources running&#13;&#10;" width="997" height="616"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.31 – The Kubernetes resources running</p>&#13;
			<p>Drilling in a bit deeper, you can see that for each resource with more than one Pod, you’re able to see the different <span class="No-Break">containers available.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer128" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_32.jpg" alt="Figure 7.32 – The resources in Pods&#13;&#10;" width="915" height="406"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.32 – The resources in Pods</p>&#13;
			<p>But as always, things<a id="_idIndexMarker497"/> may go wrong. You can see in the following screenshot that there’s a Kubernetes<a id="_idIndexMarker498"/> resource running, but some of the containers aren’t running <span class="No-Break">as expected:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer129" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_33.jpg" alt="Figure 7.33 – The warning resource&#13;&#10;" width="1028" height="247"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.33 – The warning resource</p>&#13;
			<p>As you dive into it a bit deeper, you can see the status of the container is waiting to <span class="No-Break">be created.</span></p>&#13;
			<div>&#13;
				<div id="_idContainer130" class="IMG---Figure">&#13;
					<img src="Images/B19116_07_34.jpg" alt="Figure 7.34 – The warning explanation&#13;&#10;" width="1212" height="686"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.34 – The warning explanation</p>&#13;
			<p>So, even though the Pod may be up and running, as in the application running inside of the container, other sidecar containers may not be. On the outside looking in, the app is up so it appears that everything is working as expected. However, after giving it a closer look, you can see that it’s not. This is the big difference between monitoring<a id="_idIndexMarker499"/> an app running on a server and a Pod. Within<a id="_idIndexMarker500"/> a Pod, there may be more than one binary to <span class="No-Break">worry about.</span></p>&#13;
			<h1 id="_idParaDest-178"><a id="_idTextAnchor179"/>Summary</h1>&#13;
			<p>This chapter covered a lot. It’s roughly 35 pages, and the thing is, these topics can be two or three books in themselves. Because of that, not everything was covered at the specific depth that’s most likely needed. However, the good news is that you now have a solid understanding of how to start thinking about implementing these platforms, technologies, and methodologies <span class="No-Break">in production.</span></p>&#13;
			<p>We went over quite a few topics in this chapter, covering what monitoring is, what observability is, and the overall differences between the two. You then dove into the specific tools and platforms available to make monitoring and observability come to life in your <span class="No-Break">Kubernetes environment.</span></p>&#13;
			<p>In the next and final chapter, you’ll learn about security from a <span class="No-Break">Kubernetes perspective.</span></p>&#13;
			<h1 id="_idParaDest-179"><a id="_idTextAnchor180"/>Further reading</h1>&#13;
			<ul>&#13;
				<li><em class="italic">Hands-On Kubernetes on Azure – Second Edition</em> by Nills Franssens, Shivakumar Gopalakrishnan, and Gunther <span class="No-Break">Lenz: </span><span class="No-Break">https://www.packtpub.com/product/hands-on-kubernetes-on-azure-second-edition/9781800209671</span></li>&#13;
				<li><em class="italic">Hands-On Infrastructure Monitoring with Prometheus</em> by Joel Bastos and Pedro <span class="No-Break">Araújo: </span><a href="https://www.packtpub.com/product/hands-on-infrastructure-monitoring-with-prometheus/9781789612349"><span class="No-Break">https://www.packtpub.com/product/hands-on-infrastructure-monitoring-with-prometheus/9781789612349</span></a></li>&#13;
			</ul>&#13;
		</div>&#13;
	</div></body></html>