<html><head></head><body>
		<div id="_idContainer118">
			<h1 id="_idParaDest-244" class="chapter-number"><a id="_idTextAnchor244"/>11</h1>
			<h1 id="_idParaDest-245"><a id="_idTextAnchor245"/>Continuous Integration of Solution Development</h1>
			<p>After PI planning, the teams on the ART are set to work. They’ll look at the outputs of Continuous Exploration and the features selected for the PI and carry them to the next stage of the Continuous Delivery Pipeline, <strong class="bold">Continuous </strong><span class="No-Break"><strong class="bold">Integration</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CI</strong></span><span class="No-Break">).</span></p>
			<p>In this chapter, we will discover the following activities in the CI stage of the Continuous <span class="No-Break">Delivery Pipeline:</span></p>
			<ul>
				<li>Developing <span class="No-Break">the solution</span></li>
				<li>Building the <span class="No-Break">solution package</span></li>
				<li>Performing <span class="No-Break">end-to-end testing</span></li>
				<li>Moving the packages to a <span class="No-Break">staging environment</span></li>
			</ul>
			<p>We will also discover that the processes described in the Continuous Delivery Pipeline will meet up with automation in a <strong class="bold">CI</strong>/<strong class="bold">Continuous Deployment</strong> (<strong class="bold">CD</strong>) pipeline in the <span class="No-Break">CI stage.</span></p>
			<p>Let’s join the ART now as they develop a solution as defined by the features created during <span class="No-Break">Continuous Exploration.</span></p>
			<h1 id="_idParaDest-246"><a id="_idTextAnchor246"/>Developing the solution</h1>
			<p>Teams on an ART work in markedly different ways than those that worked in product development using <a id="_idIndexMarker782"/>waterfall methodologies. An emphasis on Lean thinking and a focus on the system dictates newer ways <span class="No-Break">of working.</span></p>
			<p>We will examine the following aspects of engineering practices that are used by Agile <span class="No-Break">teams today:</span></p>
			<ul>
				<li>Breaking down <span class="No-Break">the work</span></li>
				<li><span class="No-Break">Collaborative development</span></li>
				<li>Building in quality </li>
				<li><span class="No-Break">Version control</span></li>
				<li>Designing to <span class="No-Break">the system</span></li>
			</ul>
			<p>These practices <a id="_idIndexMarker783"/>strive to allow for a continuous flow of work, ready for the next state <span class="No-Break">of building.</span></p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor247"/>Breaking down into stories</h2>
			<p>An important part of the Lean flow we picked up on in <a href="B18756_04.xhtml#_idTextAnchor086"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Leveraging</em> <em class="italic">Lean Flow to Keep the Work Moving</em>, was to <a id="_idIndexMarker784"/>keep batch sizes small. A feature, as presented to us before PI planning, is a large batch of work, meant to be completed by the end of the PI. In order to ensure a smooth flow of work, the feature must be broken down into smaller batches <span class="No-Break">of work.</span></p>
			<p>User stories often describe small pieces of desired user functionality meant to be delivered by the end of a sprint or iteration, which is commonly two weeks. They are commonly phrased in a user-voice form that briefly explains who the story is for and what the desired functionality and intended value are. An example follows of the <span class="No-Break">user-voice form:</span></p>
			<p><em class="italic">As a</em> customer, <em class="italic">I want</em> an itemized receipt of services emailed monthly <em class="italic">so that</em> I can understand and organize <span class="No-Break">my spending.</span></p>
			<p>An essential part of the story is its acceptance criteria. The acceptance criteria outline the correct behavior of the story and are the way the team determines that the story is complete.  </p>
			<p>Acceptance criteria can be written using the Gherkin format. This helps outline pre-conditions, inputs, and the desired behavior and outputs. These are described in clauses that begin <span class="No-Break">with GIVEN-WHEN-THEN.</span></p>
			<p>The following example of acceptance criteria for our story is written in the Gherkin format. Note how it describes the initial conditions, inputs, <span class="No-Break">and outputs:</span></p>
			<table id="table001-7" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Initial conditions</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">GIVEN I have configured the </strong><span class="No-Break"><strong class="bold">notification date…</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Input</span></p>
						</td>
						<td class="No-Table-Style">
							<p>…WHEN the notification <span class="No-Break">date passes…</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Output or <span class="No-Break">desired behavior</span></p>
						</td>
						<td class="No-Table-Style">
							<p>…THEN I receive an email notification containing my <span class="No-Break">itemized receipts.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 11.1: Acceptance criteria in the Gherkin format</p>
			<p>Enabler stories can also come <a id="_idIndexMarker785"/>from features. These stories do not provide direct user value but allow for easier development and architectural capability for future user stories, creating future business value. SAFe® outlines the following four types <a id="_idIndexMarker786"/><span class="No-Break">of enablers.</span></p>
			<ul>
				<li><span class="No-Break">Infrastructure</span></li>
				<li><span class="No-Break">Architectural</span></li>
				<li><span class="No-Break">Exploration</span></li>
				<li><span class="No-Break">Compliance</span></li>
			</ul>
			<p>Splitting a feature into <em class="italic">user</em> and <em class="italic">enabler</em> stories can be done in a variety of ways. The following methods can be used <a id="_idIndexMarker787"/>to create stories that can be completed in <span class="No-Break">a sprint.</span></p>
			<ul>
				<li><strong class="bold">Workflow steps</strong>: Set up stories to perform the necessary steps of a workflow first. The other steps can be released in <span class="No-Break">later sprints.</span></li>
				<li><strong class="bold">Variations of a business rule</strong>: Divide up stories according to different rules for business, such as different classes of service, different product lines, and <span class="No-Break">so on.</span></li>
				<li><strong class="bold">Major effort</strong>: Examine the possible stories that could be followed. Pick the story that appears to be most difficult to <span class="No-Break">do first.</span></li>
				<li><strong class="bold">Simple vs. complex</strong>: When evaluating the feature, is there a story that could be written that would provide the core functionality? That’s the first story to work. Subsequent stories would elaborate on the <span class="No-Break">core functionality.</span></li>
				<li><strong class="bold">Variations present in data</strong>: Start with a story that works with one data type and move to different stories to handle the other <span class="No-Break">data types.</span></li>
				<li><strong class="bold">Different data entry methods</strong>: Start by creating a story that enters the data manually, then progress with further stories with automated <span class="No-Break">data entry.</span></li>
				<li><strong class="bold">Different system qualities</strong>: One example of system qualities could be the different devices or interfaces our application would work with and establishing a story <span class="No-Break">for each.</span></li>
				<li><strong class="bold">By operation</strong>: Divide into <a id="_idIndexMarker788"/>stories that handle different operations. A common breakdown is <strong class="bold">Create, Read, Update, and </strong><span class="No-Break"><strong class="bold">Delete</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CRUD</strong></span><span class="No-Break">).</span></li>
				<li><strong class="bold">Use case scenarios</strong>: Create a story for every <span class="No-Break">use case.</span></li>
				<li><strong class="bold">Setting a spike and follow-up</strong>: A spike is used to set aside development time to research a technical approach or an unknown. Once the research is complete, proceed with stories that implement <span class="No-Break">the approach.</span></li>
			</ul>
			<p>Note that splitting a <a id="_idIndexMarker789"/>large story further may be required so that the story can be completed and delivered by the end of the sprint. The preceding methods can be used to split larger stories into <span class="No-Break">smaller stories.</span></p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor248"/>Collaborative development</h2>
			<p>Although teams can choose how they develop their stories, high-performing teams have found that team members working together instead of working solo produces higher quality products and enables effective knowledge sharing, and this creates stronger, more <span class="No-Break">collaborative teams.</span></p>
			<p>In this section, we’ll discuss two practices that allow teams to collaboratively develop products together, promoting better quality and stronger team cohesion: pair programming and mob programming <span class="No-Break">or swarming.</span></p>
			<h3>Pair programming</h3>
			<p>Pair programming is a <a id="_idIndexMarker790"/>practice that originated with <strong class="bold">Extreme Programming</strong> (<strong class="bold">XP</strong>). Instead of two <a id="_idIndexMarker791"/>developers working separately in front of two computers, the developers are working in front of a shared computer, exchanging ideas back and forth, and simultaneously coding and reviewing <span class="No-Break">their work.</span></p>
			<p>With two developers <a id="_idIndexMarker792"/>working together, the following patterns emerge for how <span class="No-Break">they collaborate.</span></p>
			<ul>
				<li><strong class="bold">Driver/navigator</strong>: In this pattern, one developer takes control of the computer (driver) while the other developer reviews and guides by commenting on what is typed on the screen (navigator). At certain times during the session, the roles are switched. This is the most common pattern used in pair programming. This pattern is frequently used when one of the developers is an expert programmer paired with <span class="No-Break">a novice.</span></li>
				<li><strong class="bold">Unstructured</strong>: In this ad hoc style of pair programming, there are no set roles for the developers. The collaboration tends to be unguided and loose. Typically, this pattern is adopted <a id="_idIndexMarker793"/>when neither developer knows what approach will work. This pattern works well with developers that are at similar levels of expertise, but two novice developers may have problems working with <span class="No-Break">this approach.</span></li>
				<li><strong class="bold">Ping-pong</strong>: This pattern is frequently used where one developer writes the test and the other developer works to pass the test. The developers switch roles frequently between <a id="_idIndexMarker794"/>writing the tests and writing code to pass the tests. This style works well with two developers at an <span class="No-Break">advanced level.</span></li>
			</ul>
			<p>Pair programming has proven to be an effective way of working together. Code written during a pair programming session is frequently reviewed and debugged, resulting in higher-quality code. Knowledge is <a id="_idIndexMarker795"/>shared between developers, creating faster learning for novices or those new to the code base. If the code breaks, there is also more than a single developer with an understanding of the code that can help <span class="No-Break">with repairs.</span></p>
			<p>A common misconception is that pair programming requires twice the effort or resources. This belief is not supported by studies done on the effectiveness of pair programming, including one done by the University of Utah (<a href="https://collaboration.csc.ncsu.edu/laurie/Papers/XPSardinia.PDF">https://collaboration.csc.ncsu.edu/laurie/Papers/XPSardinia.PDF</a>) that found that while development costs increased by 15%, defects discovered at later stages decreased by 15% and code functionality was accomplished using fewer lines of code, which is a sign of better <span class="No-Break">design quality.</span></p>
			<h3>Mob programming or swarming</h3>
			<p>Mob programming can be considered to be pair programming taken to the highest level. Instead of a pair of <a id="_idIndexMarker796"/>developers, the entire team is seated in front of a single computer and <a id="_idIndexMarker797"/>controls. The team is working on the same thing, in the same time and space, and on the <span class="No-Break">same computer.</span></p>
			<p>A typical pattern for this is a variation of the driver/navigator pattern. One person on the team has control of the computer, typing and creating the code or other pieces of work. The other members <a id="_idIndexMarker798"/>of the team review and guide the driver as navigators. After some time (usually 10 minutes), the controls are rotated to another member of the team. The rotation continues until all members of the team have had an opportunity to play <span class="No-Break">the driver.</span></p>
			<p>Mob programming benefits the entire team. Knowledge sharing of the code is applied to the entire team, instead of a pair of developers. Communication is easier with the entire team present. Decisions are made with the most current and <span class="No-Break">relevant information.</span></p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor249"/>Building in quality by “shifting left”</h2>
			<p>During this time, not only is the product being developed but the ways of ensuring that the product is high-quality are also being developed simultaneously. This is a change from traditional development where tests were created and run after the development of code. This change is often referred to as <em class="italic">shifting left</em> as illustrated in the following representation of the <a id="_idIndexMarker799"/>development process. This is one of the important practices in SAFe, which is described in more detail in the SAFe article on <em class="italic">Built-In </em><span class="No-Break"><em class="italic">Quality</em></span><span class="No-Break"> (</span><a href="https://www.scaledagileframework.com/built-in-quality/"><span class="No-Break">https://www.scaledagileframework.com/built-in-quality/</span></a><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B18756_11_01.jpg" alt="Figure 11.1 – Comparison of testing with “shift left” (© Scaled Agile, Inc., All Rights Reserved)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – Comparison of testing with “shift left” (© Scaled Agile, Inc., All Rights Reserved)</p>
			<p>In the preceding diagram, we see on the left that traditional testing may test stories and features long after the stories and features were originally conceived. This delayed feedback may take as long as 3 to 6 months, which may be too late to know whether we are moving in the <span class="No-Break">right direction.</span></p>
			<p>With the diagram on the right, we see that we can accelerate the feedback using TDD and BDD tests to evaluate whether <a id="_idIndexMarker800"/>the behaviors of the feature and story are what <a id="_idIndexMarker801"/>is desired. Ideally, these tests should be automated so that they can be run repeatedly <span class="No-Break">and quickly.</span></p>
			<p>Another thing we can see from the preceding diagram is that there are many levels of tests, some of which <a id="_idIndexMarker802"/>should be run repeatedly with the help of automation, and others that may take some time or can only be run manually. How do we know which tests to automate and which tests should be <span class="No-Break">run frequently?</span></p>
			<p>Mike Cohn described the levels of testing as a “testing pyramid” in his book <em class="italic">Succeeding with Agile</em>. He initially <a id="_idIndexMarker803"/>described the pyramid with the following three levels from bottom <span class="No-Break">to top.</span></p>
			<ul>
				<li><span class="No-Break">Unit testing</span></li>
				<li><span class="No-Break">Service testing</span></li>
				<li><span class="No-Break">UI testing</span></li>
			</ul>
			<p>Other types of testing can <a id="_idIndexMarker804"/>be added and applied to the testing pyramid. This allows us to view the testing pyramid <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B18756_11_02.jpg" alt="Figure 11.2 – Test pyramid"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2 – Test pyramid</p>
			<p>Note that at the bottom of the pyramid, unit tests are both the quickest to execute and the cheapest to run. It makes sense to automate their execution in the pipeline and frequently run them at every commit into version control, ideally during the <span class="No-Break">build phase.</span></p>
			<p>As you move further up the pyramid, the tests gradually take longer to execute and are more expensive. Those tests may not be run as frequently as unit tests. They may be executed through <a id="_idIndexMarker805"/>automation, but only upon entering the testing phase. Examples of these types of tests include story testing from BDD, integration testing, performance testing, and <span class="No-Break">security testing.</span></p>
			<p>The tests at the top of the pyramid take the longest to execute and are also the most expensive to run. These are mostly manual tests. These tests may be run just before release. Examples of testing here include user acceptance testing and exploratory testing done by <span class="No-Break">the customer.</span></p>
			<p>Most tests look to verify either proper code functionality and correctness as well as verification of the behaviors of the story and feature. The primary methods of creating tests to measure <a id="_idIndexMarker806"/>these criteria fall into the following methods: TDD and BDD. Let’s look at how these tests <span class="No-Break">are developed.</span></p>
			<h3>TDD</h3>
			<p>TDD is a practice <a id="_idIndexMarker807"/>derived from XP. With TDD, you practice the <span class="No-Break">following flow:</span></p>
			<ol>
				<li>Create the test. This is done to understand <span class="No-Break">the behavior.</span></li>
				<li>Watch the test fail (even with no code written). This gives us confidence in the test execution environment and demonstrates system behavior when a <span class="No-Break">test fails.</span></li>
				<li>Write the simplest code necessary to pass the test. </li>
				<li>Ensure all tests pass. This may mean any new code created is revised until the <span class="No-Break">tests pass.</span></li>
				<li>Refactor the tests and code <span class="No-Break">as needed.</span></li>
			</ol>
			<p>This flow is repeated as new functionality is developed. A graphical representation of this flow is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B18756_11_03.jpg" alt="Figure 11.3 – TDD (https://en.wikipedia.org/wiki/Test-driven_development#/media/File:TDD_Global_Lifecycle.png licensed under CC BY-SA)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – TDD (https://en.wikipedia.org/wiki/Test-driven_development#/media/File:TDD_Global_Lifecycle.png licensed under CC BY-SA)</p>
			<p>The tests usually written using TDD are unit tests; small, easily executed tests designed to verify the <a id="_idIndexMarker808"/>correct functionality of a code module. Broader tests use BDD to develop tests that verify the systemic behavior of features and stories. Let’s look at <span class="No-Break">BDD now.</span></p>
			<h3>BDD</h3>
			<p>BDD is often seen as an extension of TDD, but while TDD looks to verify the correct behavior of <a id="_idIndexMarker809"/>individual code functions and components, BDD strives to verify the correct behavior of the system as an executable specification expressed in features and stories. One application of BDD was seen earlier in this chapter when we created the acceptance criteria for <span class="No-Break">the story.</span></p>
			<p>Looking at the correct systemic behavior involves three perspectives that work together to bring their point of view of what is eventually specified, what is developed, and what gets tested as correct. The following three perspectives include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Customers who understand the business needs and look for the desirability and viability of <span class="No-Break">new features</span></li>
				<li>Developers who understand the feasible <span class="No-Break">technical approaches</span></li>
				<li>Testers who view the edge cases and boundary conditions of the <span class="No-Break">systemic behavior</span></li>
			</ul>
			<p>BDD brings these three <a id="_idIndexMarker810"/>perspectives together using specifications. These specifications are written in a <strong class="bold">Domain-Specific Language</strong> (<strong class="bold">DSL</strong>) that employs natural language syntax so that technical and non-technical people can <a id="_idIndexMarker811"/>collaboratively develop the specification. One of these DSLs is Gherkin, which divides behavior into the following <span class="No-Break">three clauses:</span></p>
			<ul>
				<li><strong class="bold">GIVEN</strong> outlines the initial conditions that must be present for the desired behavior in <span class="No-Break">a scenario</span></li>
				<li><strong class="bold">WHEN</strong> describes the input that triggers <span class="No-Break">a scenario</span></li>
				<li><strong class="bold">THEN</strong> describes the desired behavior for <span class="No-Break">the scenario</span></li>
			</ul>
			<p>Multiple GIVEN, WHEN, and THEN clauses may be joined together using <strong class="bold">AND</strong> to indicate multiple conditions, inputs, and <span class="No-Break">behaviors accordingly</span></p>
			<p>The specification, using <a id="_idIndexMarker812"/>the DSL, can become several artifacts. Product owners and product management create the acceptance criteria for features and stories with the other members of the development teams. The creation of acceptance criteria can be seen as the discovery of the desired <span class="No-Break">systemic behavior.</span></p>
			<p>The next phase of creating the specification is formulation. In this phase, developers and testers work together to create acceptance tests. They can take the acceptance criteria as written and elaborate specific criteria in each clause, including allowable initial conditions and values to measure for inputs and outputs so that the specification for a specific scenario becomes a test. Ideally, acceptance tests are written in the same DSL as the <span class="No-Break">acceptance criteria.</span></p>
			<p>We can create an automated test by taking the acceptance criteria for our story and adding specific <a id="_idIndexMarker813"/>pre-conditions, input, and desired output or behavior. Let’s look at our previously seen acceptance criteria converted into a test in the <span class="No-Break">following table:</span></p>
			<table id="table002-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Acceptance Criteria</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Test</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>GIVEN I have configured the <span class="No-Break">notification date…</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Given the date state is <span class="No-Break">not x…</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>…WHEN the notification <span class="No-Break">date passes…</span></p>
						</td>
						<td class="No-Table-Style">
							<p>…when it’s one business day after the date state has changed <span class="No-Break">to x…</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>…THEN I receive an email notification containing my <span class="No-Break">itemized receipts.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>…then send an email notification to all users with <span class="No-Break">xxx content.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 11.2 – Conversion of acceptance criteria into a test</p>
			<p>The last phase of the specification is automation. The acceptance test, written in the DSL, can be executed in <a id="_idIndexMarker814"/>a tool that allows for automated testing. Acceptance tests written in Gherkin can be executed by tools such as Cucumber, JBehave, Lettuce Behave, <span class="No-Break">and Behat.</span></p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor250"/>Version control</h2>
			<p>Version control software allows <a id="_idIndexMarker815"/>for multiple developers on a team to develop in parallel on the same code base, test scripts, or other bodies of text without interference from other developers’ changes. Each change in the version control system is recorded. Changes are consolidated <a id="_idIndexMarker816"/>using merge operations to bring together and resolve changes in the bodies <span class="No-Break">of work.</span></p>
			<p>Important practices for the <a id="_idIndexMarker817"/>use of version control include the <span class="No-Break">following ideas:</span></p>
			<ul>
				<li><strong class="bold">Save EVERYTHING in version control</strong>: A lot of design decisions are captured as artifacts in version control beyond source code. Code, test scripts, configuration files, and any other text-based artifacts can be tagged together to show they are part of the same release. Version control also allows for the retrieval of previous versions to roll back any changes or to view the evolution of <span class="No-Break">design decisions.</span></li>
				<li><strong class="bold">Everyone uses the same version control system</strong>: As we saw in <a href="B18756_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introducing SAFe®  and DevOps</em>, the photo-sharing website Flickr had a common version control system between its development and operations people. This allowed for the easy retrieval of artifacts by anyone when production <span class="No-Break">failures occurred.</span></li>
			</ul>
			<p>Other best practices <a id="_idIndexMarker818"/>of version control that take place during the build process will be identified in our <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor251"/>Designing to the system</h2>
			<p>The features and stories are not the only criteria teams have to consider when developing new capabilities for their product. <strong class="bold">Non-Functional Requirements</strong> (<strong class="bold">NFRs</strong>) are qualities that may impact every feature and story acting as a constraint or limitation. These NFRs <a id="_idIndexMarker819"/>may deal with security, compliance, performance, scalability, and reliability, among <span class="No-Break">other things</span></p>
			<p>Two practices are performed to ensure compliance with some NFRs: designing for operations and threat modeling. Let’s take a look at <span class="No-Break">these practices.</span></p>
			<h3>Designing for operations</h3>
			<p>The collaboration <a id="_idIndexMarker820"/>between development and operations is a hallmark of the DevOps movement. Ensuring that operations can easily examine system resources is something that is easily incorporated in the early stages of development rather than added as <span class="No-Break">an afterthought.</span></p>
			<p>A key part of ensuring capabilities are present for proper maintenance of the product is application telemetry. The product as a system must allow for the easy measurement of system resources, including how an application uses resources such as server memory and storage. In addition to system measurements, application telemetry should also allow for the measurement of business data, used as a leading indicator to validate the <span class="No-Break">benefit hypothesis.</span></p>
			<p>Other considerations include ensuring that changes brought by new features can be easily rolled <a id="_idIndexMarker821"/>back or that fixes can be rolled forward through the Continuous Delivery Pipeline. When doing this, be aware of components that may represent the state of the system, such as a database. These may not be easily <span class="No-Break">rolled back.</span></p>
			<h3>Threat modeling</h3>
			<p>Moving toward a DevSecOps approach requires a <em class="italic">shift-left</em> mindset toward security. This mindset allows <a id="_idIndexMarker822"/>for including security concerns in the design and development stages of the Continuous Delivery Pipeline, which gives a more holistic view of <span class="No-Break">the product.</span></p>
			<p>We first saw that threat modeling was part of architecting the system in <a href="B18756_10.xhtml#_idTextAnchor221"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, <em class="italic">Continuous Exploration and Finding New Features</em>. As part of threat modeling during CI, we may be asking the <span class="No-Break">following questions:</span></p>
			<ul>
				<li>What are we working on? This helps you get an idea of <span class="No-Break">the scope.</span></li>
				<li>What can go wrong with it? This allows you to start your assessment using brainstorming or a structured threat modeling process, such as the <strong class="bold">Application Security Framework</strong> (<strong class="bold">ASF</strong>) or <strong class="bold">Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, or Elevation of Privilege</strong> (<strong class="bold">STRIDE</strong>), which identifies the types of possible information <span class="No-Break">security threats.</span></li>
				<li>What can we do about the things that go wrong? Based on the assessment, devise countermeasures or <span class="No-Break">mitigation steps.</span></li>
				<li>Are we doing a good enough job so far for the system as is? Continually evaluate the assessment, countermeasures, and <span class="No-Break">mitigation steps.</span></li>
			</ul>
			<p>Developing toward DevSecOps is then based on the countermeasures and mitigation steps identified during <span class="No-Break">the assessment.</span></p>
			<p>As development changes are completed, they must be integrated with the current product as it stands and be tested. This may start the incorporation of automation into a CI/CD pipeline. Next, let’s <a id="_idIndexMarker823"/>examine how entry into the CI/CD pipeline begins with a <span class="No-Break">build process.</span></p>
			<h1 id="_idParaDest-252"><a id="_idTextAnchor252"/>Building the solution package</h1>
			<p>The CI/CD pipeline can be triggered by version control system actions such as saving a new change as a <a id="_idIndexMarker824"/>commit. Before the changes are accepted by the version control system, they should go through a testing process to ensure they will not adversely affect the current code base. This process of testing and version control integration is an important part of the CI process where practices are divided into a version control perspective and a <span class="No-Break">testing perspective.</span></p>
			<p>Let’s look at each of these perspectives and the <span class="No-Break">practices within.</span></p>
			<h2 id="_idParaDest-253"><a id="_idTextAnchor253"/>Version control practices</h2>
			<p>Good version control practices ensure that changes introduced into version control are evaluated through <a id="_idIndexMarker825"/>testing before they are saved and merged <a id="_idIndexMarker826"/>with the existing code base. This ensures that the code base is robust, without changes that may prevent the code base from being built or packaged correctly. </p>
			<p>Version control practices can further be divided into three types that help ensure a robust code base as changes come in. Let’s look at what these practices are <span class="No-Break">in detail.</span></p>
			<h3>CI of code</h3>
			<p>The practice of CI has <a id="_idIndexMarker827"/>its origins in optimizing the build process through automation by a build script or a CI tool. Saving a change to version control through a commit operation sets off a chain of the <span class="No-Break">following steps:</span></p>
			<ol>
				<li value="1">The application would be built, incorporating the saved changes. If building this code resulted in an error, notifications would be sent regarding the error. The changes would not be allowed to merge with the <span class="No-Break">code base.</span></li>
				<li>If the build succeeded, tests would run against the build with the code changes. These tests are often small tests, measuring a small part of the functionality, that can be quickly executed and don’t take a lot of time. If a test failure was detected, a notification would be sent, and the changes would not be allowed to merge with the <span class="No-Break">code base.</span></li>
				<li>Another type of test that could be executed would be a scan of the code base. Scanning could look for deviations from coding style standards and syntax errors to known security vulnerabilities. Depending on the severity of the findings, changes would not be allowed to merge with the code base. Notifications would be sent on <span class="No-Break">all findings.</span></li>
				<li>Upon successful results from the building, testing, and scanning steps, the code change would <a id="_idIndexMarker828"/>be recorded into the version control system. Merging the change into the main trunk of the code base would proceed on the version control system, integrating the changes with the rest of <span class="No-Break">the code.</span></li>
			</ol>
			<p>The preceding steps are outlined in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B18756_11_04.jpg" alt="Figure 11.4 – CI automation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.4 – CI automation</p>
			<p>When performing the preceding chain of steps, teams eventually figured out that successful code integration relied on the <span class="No-Break">following factors:</span></p>
			<ul>
				<li><strong class="bold">Performing the integration frequently</strong>: Many teams started with performing the build and testing processes nightly, examining changes that had been saved over the previous day. With a lot of changes, the <em class="italic">nightly build</em> often grew until it couldn’t be finished until the next day or later. More frequent builds, often occurring several times a day, allowed people to see the build results and act on <span class="No-Break">them swiftly.</span></li>
				<li><strong class="bold">Performing integration on fewer changes</strong>: A <em class="italic">nightly build</em> that absorbs multiple changes from multiple developers produces problems when the build fails. It becomes more complex to troubleshoot to determine which developer’s change <em class="italic">broke the build</em>. Performing a build based on fewer changes, with the idea of building on each saved change, allows for quicker troubleshooting when <span class="No-Break">errors occur.</span></li>
			</ul>
			<p>CI results in the following outputs, regardless of success <span class="No-Break">or failure:</span></p>
			<ul>
				<li><strong class="bold">Fast feedback</strong>: The results of CI should occur in minutes. Any errors that prevent the successful <a id="_idIndexMarker829"/>completion of CI will be given in a short amount of time, resulting in <span class="No-Break">fewer delays.</span></li>
				<li><strong class="bold">Deployable artifacts upon success</strong>: With a successful build, a build package able to be deployed into non-production environments will <span class="No-Break">be produced.</span></li>
			</ul>
			<p>CI tools such as Jenkins, GitLab pipelines, and GitHub Actions form the basis of the automation that allows the CI of code <span class="No-Break">to occur.</span></p>
			<h3>Trunk-based development</h3>
			<p>Multiple developers in a <a id="_idIndexMarker830"/>single team or even multiple teams (such as the team of teams that is present in an ART) often must work on the same code base that is saved in version control. Version control systems allow for parallel development of the same code base by allowing changes to be branched out. A developer or team could work on a branch without their change affecting the rest of the team or ART until it was ready to merge and be shared with other developers <span class="No-Break">or teams.</span></p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B18756_11_05.jpg" alt="Figure 11.5 – Branching structure example"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.5 – Branching structure example</p>
			<p>In the preceding illustration, <strong class="bold">Team 1</strong> and <strong class="bold">Team 2</strong> have their own branches of the code base, based on different versions of the main branch (commonly referred to as the <em class="italic">trunk</em>). A developer on <strong class="bold">Team 1</strong> has created a change (<strong class="bold">D1</strong>) and merged it back into the <strong class="bold">Team 1</strong> branch as a change, <strong class="bold">T1-2</strong>. With separate team branches, how do we know that a necessary change from <strong class="bold">Team 2</strong> is visible and can be used by <span class="No-Break"><strong class="bold">Team 1</strong></span><span class="No-Break">?</span></p>
			<p>Another problem occurs as <strong class="bold">Team 1</strong> and <strong class="bold">Team 2</strong> develop on their branches without receiving updates <a id="_idIndexMarker831"/>from the trunk and wait to merge when they release or at the end of the sprint. Keeping track of the multiple changes from multiple teams and resolving a large number of merge conflicts results in an <span class="No-Break">incredible challenge.</span></p>
			<p>To keep things simple and ensure changes are visible to all teams, we want to avoid branches that are permanent or last a long time. Developers and teams may form branches to allow for parallel development, but when ready, they must merge back to the main branch, destroying the offshoot branch in the process. This process is known as trunk-based development. The following diagram highlights the process of <span class="No-Break">trunk-based development:</span></p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B18756_11_06.jpg" alt="Figure 11.6 – Branching structure with trunk-based development"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.6 – Branching structure with trunk-based development</p>
			<p>Trunk-based development <a id="_idIndexMarker832"/>allows for easier merge operations to occur since a merge to the main branch is happening on each validated change instead of a group <span class="No-Break">of changes.</span></p>
			<h3>Gated commits</h3>
			<p>With trunk-based development, we are merging changes to the main branch of the code base as often as <a id="_idIndexMarker833"/>possible. This main branch is used by all the teams on the ART. Since the integrity of the main branch is vital for multiple teams, how do we ensure that any errant changes don’t break the current <span class="No-Break">code base?</span></p>
			<p>To ensure a robust code base, we must follow a gated commit process where before a change is allowed to merge with the main branch, it must successfully pass the build and test process. Additional measures, such as a review of the change, may also <span class="No-Break">be taken.</span></p>
			<p>In Git-based environments, Git servers from Bitbucket, GitLab, and GitHub define gated commits as pull requests or merge requests that allow for closer scrutiny when a merge operation <span class="No-Break">is requested.</span></p>
			<h2 id="_idParaDest-254"><a id="_idTextAnchor254"/>Testing practices</h2>
			<p>We saw that build <a id="_idIndexMarker834"/>processes relied on testing to ensure that changes to a code base did not adversely affect the functionality or the security of the product. The tests that were run proved to be important since ideally, the build process would be performed on every saved change and if successful, the next step would be merging the change to the main branch, which is visible to the team or multiple teams in the case of <span class="No-Break">the ART.</span></p>
			<p>The build process involves two types of tests that are run against a potential new version of the <a id="_idIndexMarker835"/>code base: automated unit testing and static analysis for <span class="No-Break">application security.</span></p>
			<p>Let’s take a deeper look at each type of test run as part of the <span class="No-Break">build process.</span></p>
			<h3>Automated unit testing</h3>
			<p>Unit tests are often written <a id="_idIndexMarker836"/>at the same time as code, if not beforehand. These unit tests may be run by <a id="_idIndexMarker837"/>an individual developer on their workstation while the code is being developed. If that’s the case, why run them again as part of the <span class="No-Break">build process?</span></p>
			<p>The main idea of CI is to ensure a standard, reliable process. Automation through a CI/CD pipeline ensures that this occurs for all developers. Adding unit testing during the build process on an automated CI/CD pipeline ensures that the unit tests are run on every developer’s code change <span class="No-Break">every time.</span></p>
			<p>It’s also important to make sure that any unit tests that have been updated are simultaneously part of the potential change to the code base in version control. This ensures that code changes are validated against correct tests preventing a situation where the CI/CD pipeline stops because of incorrect tests. Collaborative development efforts between those creating the code and those creating the tests are required to ensure this situation <span class="No-Break">doesn’t occur.</span></p>
			<h3>Static analysis for application security</h3>
			<p>Static analysis is a <a id="_idIndexMarker838"/>process by which a tool <a id="_idIndexMarker839"/>scans the text of the code base, including the potential code change that is being checked in, to find specific text patterns. These text patterns can <a id="_idIndexMarker840"/>be used to identify the <span class="No-Break">following issues:</span></p>
			<ul>
				<li><span class="No-Break">Coding errors</span></li>
				<li>Known <span class="No-Break">security vulnerabilities</span></li>
				<li>Non-adherence to coding guidelines or <span class="No-Break">coding standards</span></li>
			</ul>
			<p>The analysis is performed without the need for executing the application. Because of this, static analysis is an efficient means of checking for problems in the <span class="No-Break">build process.</span></p>
			<p>As we saw in <a href="B18756_03.xhtml#_idTextAnchor066"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Automation for Efficiency and Quality</em>, static analysis can fall into the following <span class="No-Break">two categories:</span></p>
			<ul>
				<li><strong class="bold">Static code analysis</strong>: Look through <a id="_idIndexMarker841"/>the code for possible coding errors. Linting is an example of static <span class="No-Break">code analysis.</span></li>
				<li><strong class="bold">Static security analysis</strong>: Look through the code for possible security vulnerabilities <a id="_idIndexMarker842"/>and attack vectors. Applications that perform static security analysis may perform the <span class="No-Break">following scans:</span><ul><li><strong class="bold">Dependency scanning</strong>: Scanning code dependencies and references to third-party libraries to <span class="No-Break">find vulnerabilities</span></li><li><strong class="bold">Static Application Security Testing</strong> (<strong class="bold">SAST</strong>): Scanning code to find attack <a id="_idIndexMarker843"/>vectors <span class="No-Break">and vulnerabilities</span></li><li><strong class="bold">License compliance</strong>: Scanning libraries to determine their opensource <span class="No-Break">licensing model</span></li><li><strong class="bold">Container scanning</strong>: Scanning Docker containers to find <span class="No-Break">embedded vulnerabilities</span></li><li><strong class="bold">Secret detection</strong>: Scanning code to find embedded credentials, keys, <span class="No-Break">and tokens</span></li></ul></li>
			</ul>
			<p>Our application <a id="_idIndexMarker844"/>has passed the first set of tests, but is it ready for the rigors of a production environment? To answer that question, we look to perform system-level testing. Our next section examines the practices that enable <span class="No-Break">system-level testing.</span></p>
			<h1 id="_idParaDest-255"><a id="_idTextAnchor255"/>Testing end to end</h1>
			<p>At this point, we have performed tests on individual pieces of code and ensured the correct functionality <a id="_idIndexMarker845"/>while maintaining security. Here, we start to integrate the new changes of code with the existing code base and evaluate the system as a whole by testing the system end <span class="No-Break">to end.</span></p>
			<p>The practices that allow for true end-to-end testing of the system will be examined in the upcoming sections. Let’s <span class="No-Break">dive in.</span></p>
			<h2 id="_idParaDest-256"><a id="_idTextAnchor256"/>Equivalent test environments</h2>
			<p>System-level testing <a id="_idIndexMarker846"/>should be performed in an environment that resembles the production environment as closely as possible. Testing the solution in an environment with as many similarities to the production environment as possible enables higher confidence that the solution will work when actually released into the actual production environment. The more similarities a test environment has with the production environment, the fewer variables come into play when problems are found and troubleshooting for the root <span class="No-Break">cause begins.</span></p>
			<p>A key factor in ensuring the equivalence between test environments and the production environment is the use of configuration management. With configuration management, key resources such as the operating system version, versions of key drivers, and versions of applications are recorded in a text-based configuration file. Ideally, the configuration file is maintained in version control with labels that indicate the version of the solution and its application in the test environments and <span class="No-Break">production environment.</span></p>
			<p>Because the cost of allocating exact duplicates of the resources in production may be prohibitive, the important view is that exact versions of resources, rather than the exact number of resources, are key to <span class="No-Break">maintaining equivalence.</span></p>
			<h2 id="_idParaDest-257"><a id="_idTextAnchor257"/>Test automation</h2>
			<p>System-level testing can <a id="_idIndexMarker847"/>encompass a variety of levels, most of which can be automated. When looking at a variety of tests at various levels, which of these tests could <span class="No-Break">be automated?</span></p>
			<p>In addition to the testing pyramid mentioned earlier, we may need to consider the people who need to understand the test results. A second consideration is whether the test is to verify that the solution is meeting requirements or whether the test is to allow developers to see whether their design approach <span class="No-Break">is correct.</span></p>
			<p>The Agile testing matrix looks at the various kinds of tests and organizes them from these <a id="_idIndexMarker848"/>considerations. The following diagram depicts the Agile testing matrix as seen in the SAFe article on <em class="italic">Agile </em><span class="No-Break"><em class="italic">Testing</em></span><span class="No-Break"> (</span><a href="https://www.scaledagileframework.com/agile-testing/"><span class="No-Break">https://www.scaledagileframework.com/agile-testing/</span></a><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B18756_11_07.jpg" alt="Figure 11.7 – Agile testing matrix (© Scaled Agile, Inc., All Rights Reserved)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.7 – Agile testing matrix (© Scaled Agile, Inc., All Rights Reserved)</p>
			<p>We can see from the preceding diagram that the first consideration looks at the perspective of either the business or the technology. Developers look at the technology tests to ensure the correct functionality and proper operation of the solution. End users look at the business-facing tests to ensure an understanding of the solution and the validation of the <span class="No-Break">benefit hypothesis.</span></p>
			<p>We can also see the second consideration: whether the test informs the complete solution or the implementation. Tests that guide development assist in TDD and BDD approaches <a id="_idIndexMarker849"/>where the test is written first. Tests that critique the product look to see whether the solution complies with <span class="No-Break">user requirements.</span></p>
			<p>With two areas of concern within each of the two considerations, we can divide tests into the following <span class="No-Break">four quadrants:</span></p>
			<ul>
				<li><strong class="bold">Q1</strong>: These contain unit <a id="_idIndexMarker850"/>and component tests. These tests may be created as part of a <span class="No-Break">TDD approach.</span></li>
				<li><strong class="bold">Q2</strong>: These contain functional tests and tests for stories and features. These may be created using a BDD approach to allow for automated testing. Otherwise, some of this validation may <span class="No-Break">be manual.</span></li>
				<li><strong class="bold">Q3</strong>: These are acceptance tests of the entire solution. These may be the final validation before release. These are often manually run with alpha and <span class="No-Break">beta users.</span></li>
				<li><strong class="bold">Q4</strong>: These test overall system qualities, including NFRs. These verify the system in the <span class="No-Break">production environment.</span></li>
			</ul>
			<p>We will see that tests in Q3 are done during CD in <a href="B18756_12.xhtml#_idTextAnchor268"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>,<em class="italic"> Continuous Deployment to Production</em>. Tests in Q4 are done during Release on Demand as mentioned in <a href="B18756_13.xhtml#_idTextAnchor292"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, <em class="italic">Releasing on Demand to </em><span class="No-Break"><em class="italic">Realize Value</em></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-258"><a id="_idTextAnchor258"/>Management of test data</h2>
			<p>A key part of <a id="_idIndexMarker851"/>ensuring the similarities between a testing environment and the production environment is the data used to test the solution. Using data that could be found in production environments allows for more realistic test outcomes, leading to higher confidence in <span class="No-Break">the solution.</span></p>
			<p>Realistic test data can come from either synthetic test data or real production data. Test data may come from a backup of production data restored into the test environment. The test data should have any information that is considered private removed. </p>
			<p>Synthetic test data is <em class="italic">fake data</em> created by a data generation tool such as DATPROF Privacy and Gretel. It offers the advantage of not requiring an anonymization step to redact <span class="No-Break">private information.</span></p>
			<p>Regardless of whether <a id="_idIndexMarker852"/>the data is anonymized production data or synthetic data, the test data should be maintained in version control, using artifact repository software for large <span class="No-Break">binary-based data.</span></p>
			<h2 id="_idParaDest-259"><a id="_idTextAnchor259"/>Service virtualization</h2>
			<p>Service virtualization allows <a id="_idIndexMarker853"/>for test environments to <a id="_idIndexMarker854"/>behave like production environments even when the test environment is missing resources available in production. The production environment may have crucial dependencies on key components that are impossible to copy because <a id="_idIndexMarker855"/>of the <span class="No-Break">following factors:</span></p>
			<ul>
				<li>The component is not <span class="No-Break">complete yet</span></li>
				<li>The component is being developed by a third-party vendor <span class="No-Break">or partner</span></li>
				<li>There is limited access to the component in a <span class="No-Break">test environment</span></li>
				<li>The component is difficult to configure in a <span class="No-Break">test environment</span></li>
				<li>Multiple teams with differing setups require access to <span class="No-Break">the component</span></li>
				<li>The component is too costly to use for performance or <span class="No-Break">load testing</span></li>
			</ul>
			<p>Systems made up of components that communicate together using well-known interfaces can take advantage of service virtualization to simulate the behavior of one or more components. If the virtualized service is a database, it can return synthetic <span class="No-Break">test data.</span></p>
			<p>Components that are simulated in test environments are called virtual assets. Virtual assets are created by <a id="_idIndexMarker856"/>tools that measure the true component’s behavior by the <span class="No-Break">following methods:</span></p>
			<ul>
				<li>Recording the messages, responses, and response times of a component as it communicates on a common channel <span class="No-Break">or bus</span></li>
				<li>Examination of the <span class="No-Break">component’s logs</span></li>
				<li>Viewing the service <span class="No-Break">interface specifications</span></li>
				<li>Manually applying inputs and <span class="No-Break">measuring behavior</span></li>
			</ul>
			<p>Once the virtual <a id="_idIndexMarker857"/>asset is created, it takes its place in the <a id="_idIndexMarker858"/>test environment. An illustration <a id="_idIndexMarker859"/>of the difference between the production environment and the test environment with virtual assets is <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B18756_11_08.jpg" alt="Figure 11.8 – Production vs. test environment"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.8 – Production vs. test environment</p>
			<p>Popular tools for creating virtual assets include SoapUI and ReadyAPI from Smartbear, MockLab, Parasoft Virtualize, <span class="No-Break">and WireMock.</span></p>
			<p>An important difference to consider is that while service virtualization may seem similar to <em class="italic">mocking</em> or stubbing a component, the two concepts are not similar. Adding a mock component or a stub may be done during development when the component is not ready for release. The behavior of a mock object only returns one type of output – a success message – so the development of other components is not impeded. Service virtualization allows for the proper behavior for a wide variety <span class="No-Break">of scenarios.</span></p>
			<p>Environments with virtual assets should be maintained in configuration management tools. The configuration <a id="_idIndexMarker860"/>files and interface definition files for virtual assets should be kept in version control, in close proximity, and with labels identifying their role as test assets for versions of <span class="No-Break">an application.</span></p>
			<h2 id="_idParaDest-260"><a id="_idTextAnchor260"/>Testing nonfunctional requirements</h2>
			<p>As we perform end-to-end system testing, we need to remember the constraints our system has, which <a id="_idIndexMarker861"/>we have previously identified as NFRs. NFRs affect every story and feature, acting as a constraint that must be heeded. Qualities such as security, performance, reliability, and scalability, among other things, should be examined through testing to verify that these constraints aren’t broken. </p>
			<p>The testing of NFRs is often automated, involving specialized testing tools. Agile teams on the ART often work with the system team to ensure that the tooling is established to perform testing for NFRs as part of the <span class="No-Break">end-to-end testing.</span></p>
			<p>After the portfolio of tests is performed on our change, we may want one more opportunity to see whether our change is ready to be deployed to production. We place our changes into a staging environment, a stand-in for the production environment for a final examination before deploying changes to production. Let’s look at the activities involved in deploying changes <span class="No-Break">to staging.</span></p>
			<h1 id="_idParaDest-261"><a id="_idTextAnchor261"/>Moving to staging</h1>
			<p>We may want verification that we can deploy the change to a production-like environment and verify that our solution still works. To enable this last look, we employ <span class="No-Break">certain practices.</span></p>
			<p>Let’s look at these practices <span class="No-Break">in depth.</span></p>
			<h2 id="_idParaDest-262"><a id="_idTextAnchor262"/>Staging environments</h2>
			<p>A staging environment is a facsimile of the production environment, which has several uses throughout <a id="_idIndexMarker862"/>the PI. It is the place where demonstrations of the system as it currently stands are performed in the system demo. User acceptance testing can be performed in this environment, which is as close to production <span class="No-Break">as possible.</span></p>
			<p>As the changes to the product are being developed, the staging environment shows the state of change before deployment to production. At the very least, changes to the staging environment happen every sprint or iteration for the ART. More frequent changes are allowed as long as the build process and end-to-end testing are <span class="No-Break">completed successfully.</span></p>
			<p>A staging environment may also act as an alternative environment for production in a configuration known as blue/green deployment, which may allow for easy rollback in the event of production failures. Let’s take a look at this <span class="No-Break">configuration now.</span></p>
			<h2 id="_idParaDest-263"><a id="_idTextAnchor263"/>Blue/green deployments</h2>
			<p>In a blue/green deployment, you have two identical environments. Of the two environments, one is <a id="_idIndexMarker863"/>the production environment and facing traffic, while the other is idle and <span class="No-Break">on standby.</span></p>
			<p>The idle environment receives the latest change where thorough testing occurs. At the appropriate time, the change is released by making the idle environment live and the other environment idle. This transition is illustrated by the <span class="No-Break">following graphic:</span></p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B18756_11_09.jpg" alt=""/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.9 – Blue/green deployment release of a new version</p>
			<p>If problems are discovered, a switchback can be made to roll back changes. This transition back <a id="_idIndexMarker864"/>and forth is easy for systems that do not track states. Otherwise, blue/green deployments must be carefully architected so that components that are capable of storing states, such as databases, do not get corrupted <span class="No-Break">upon transition.</span></p>
			<h2 id="_idParaDest-264"><a id="_idTextAnchor264"/>System demo</h2>
			<p>At the end of every sprint or iteration in the PI, after each team’s iteration review, the teams get together to <a id="_idIndexMarker865"/>integrate their efforts. Working with the system team, they demonstrate the current state of the product as it stands so far in the PI in the staging environment. Business owners, customers, and other key stakeholders of the ART are present at this demonstration to view progress and supply feedback. This event provides fast feedback on the efforts of the ART so far. </p>
			<p>Note that the system demo does not prevent the deployment of changes into production. That may continue to happen automatically as part of CD (which we will visit in the next chapter), but feedback may prevent the release of the change to customers until changes resulting from the feedback make their way into production and are released <span class="No-Break">on demand.</span></p>
			<p>Successful testing in a staging environment gives us confidence that our change has the correct functionality and is robust enough in a production environment, but the only true way to prove that is to deploy our change into the actual <span class="No-Break">production environment.</span></p>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor265"/>Summary</h1>
			<p>In this chapter, we continued our discovery of the Continuous Delivery Pipeline by looking at CI, the part that implements the features created in Continuous Exploration. Features are divided into more digestible stories. Development of not only the product but also the tests to verify the product begins. Security and designing for operation concerns are included in <span class="No-Break">the development.</span></p>
			<p>The build phase introduces automation into the pipeline. When a commit to version control occurs, unit tests are run to ensure continued, correct functionality. The build is also scanned for coding errors and to find security vulnerabilities. If everything is correct, the commit will be allowed to merge with the main branch, or trunk, of the version <span class="No-Break">control repository.</span></p>
			<p>A successful build can trigger further testing in a testing environment that may be similar to the production environment. Here, system-level, end-to-end testing happens to guard against any production failures. The testing here is as automated as it can be. Accurate test data and service virtualization may offer a reasonable facsimile to a production environment <span class="No-Break">for testing.</span></p>
			<p>When building and testing are complete, the change may find itself in a staging environment, a copy of the production environment, or one-half of a blue/green deployment. A staging environment is also a place where changes are shown during a system demo, an event where the ART receives feedback on the development of the system at the end of each sprint <span class="No-Break">or iteration.</span></p>
			<p>After making its way to the staging environment, we must move our changes into production. That happens in CD, which we will explore in our <span class="No-Break">next chapter.</span></p>
			<h1 id="_idParaDest-266"><a id="_idTextAnchor266"/>Questions</h1>
			<ol>
				<li value="1">What are two examples of <span class="No-Break">collaborative development?</span><ol><li><span class="No-Break">Solo programming</span></li><li><span class="No-Break">Pair programming</span></li><li><span class="No-Break">Gauntlet programming</span></li><li><span class="No-Break">Mob programming</span></li><li><span class="No-Break">Cross-team programming</span></li></ol></li>
				<li>What is the first step <span class="No-Break">in TDD?</span><ol><li>Write <span class="No-Break">the test</span></li><li>Write <span class="No-Break">the code</span></li><li>Refactor <span class="No-Break">the test</span></li><li>Refactor <span class="No-Break">the code</span></li></ol></li>
				<li>When performing trunk-based development, a successful build and test will allow the committed change to merge with <span class="No-Break">which branch?</span><ol><li><span class="No-Break">Release branch</span></li><li><span class="No-Break">Fix branch</span></li><li><span class="No-Break">Main branch</span></li><li><span class="No-Break">Test-complete branch</span></li></ol></li>
				<li>According to the testing pyramid, what types of tests are the quickest <span class="No-Break">to execute?</span><ol><li><span class="No-Break">Unit tests</span></li><li><span class="No-Break">Security tests</span></li><li><span class="No-Break">Story tests</span></li><li>User <span class="No-Break">acceptance tests</span></li></ol></li>
				<li>What text-based artifacts should be stored in <span class="No-Break">version control?</span><ol><li><span class="No-Break">Code</span></li><li><span class="No-Break">Tests</span></li><li><span class="No-Break">Configuration files</span></li><li>A <span class="No-Break">and C</span></li><li>All of <span class="No-Break">the above</span></li></ol></li>
				<li>What can be used to allow test environments to be similar to <span class="No-Break">production environments?</span><ol><li>Using old <span class="No-Break">production servers</span></li><li>Sanitized backups of <span class="No-Break">production data</span></li><li><span class="No-Break">Service virtualization</span></li><li>B <span class="No-Break">and C</span></li><li>All of <span class="No-Break">the above</span></li></ol></li>
				<li>What can a staging environment, identical to the production environment, be <span class="No-Break">used for?</span><ol><li>User <span class="No-Break">acceptance tests</span></li><li>An idle environment for <span class="No-Break">blue/green deployment</span></li><li><span class="No-Break">System demos</span></li><li>All of <span class="No-Break">the above</span></li></ol></li>
			</ol>
			<h1 id="_idParaDest-267"><a id="_idTextAnchor267"/>Further reading</h1>
			<ul>
				<li>Guidance from Scaled Agile on how to decompose f<a href="https://www.scaledagileframework.com/story/">eatures into stories and what good stories </a><span class="No-Break">contain: </span><a href="https://www.scaledagileframework.com/story/"><span class="No-Break">https://www.scaledagileframework.com/story/</span></a></li>
				<li>A guide to common patterns used to decompose features into stories or to split big stories into smaller <span class="No-Break">stories: </span><a href="http://www.humanizingwork.com/wp-content/uploads/2020/10/HW-Story-Splitting-Flowchart.pdf"><span class="No-Break">http://www.humanizingwork.com/wp-content/uploads/2020/10/HW-Story-Splitting-Flowchart.pdf</span></a></li>
				<li>A good article detailing the practice of pair <span class="No-Break">programming: </span><a href="https://www.techtarget.com/searchsoftwarequality/definition/Pair-programming"><span class="No-Break">https://www.techtarget.com/searchsoftwarequality/definition/Pair-programming</span></a></li>
				<li>The study done by the University of Utah detailing the benefits of pair <span class="No-Break">programming: </span><a href="https://collaboration.csc.ncsu.edu/laurie/Papers/XPSardinia.PDF"><span class="No-Break">https://collaboration.csc.ncsu.edu/laurie/Papers/XPSardinia.PDF</span></a></li>
				<li>The original article from Woody Zuill, detailing how mob programming works and its <span class="No-Break">benefits: </span><a href="https://www.agilealliance.org/resources/experience-reports/mob-programming-agile2014/"><span class="No-Break">https://www.agilealliance.org/resources/experience-reports/mob-programming-agile2014/</span></a></li>
				<li>An article from Scaled Agile on “shifting testing left” and adopting TDD and <span class="No-Break">BDD: </span><a href="https://www.scaledagileframework.com/built-in-quality/"><span class="No-Break">https://www.scaledagileframework.com/built-in-quality/</span></a></li>
				<li>Article from the <strong class="bold">Open Web Application Security Project</strong> (<strong class="bold">OWASP</strong>) detailing threat <span class="No-Break">modeling: </span><a href="https://owasp.org/www-community/Threat_Modeling"><span class="No-Break">https://owasp.org/www-community/Threat_Modeling</span></a></li>
				<li>Article from the OWASP detailing processes used for threat modeling, including ASP and <span class="No-Break">STRIDE: </span><a href="https://owasp.org/www-community/Threat_Modeling_Process "><span class="No-Break">https://owasp.org/www-community/Threat_Modeling_Process</span></a></li>
				<li>An article expanding on Mike Cohn’s testing <span class="No-Break">pyramid: </span><a href="https://martinfowler.com/articles/practical-test-pyramid.html"><span class="No-Break">https://martinfowler.com/articles/practical-test-pyramid.html</span></a></li>
				<li>Scaled Agile article on Agile testing and the Agile Testing <span class="No-Break">Matrix: </span><a href="https://www.scaledagileframework.com/agile-testing/"><span class="No-Break">https://www.scaledagileframework.com/agile-testing/</span></a></li>
				<li>An article by Smartbear, vendor of two leading service virtualization tools, on what service virtualization is, its benefits, and how it compares to <span class="No-Break">stubs: </span><a href="https://smartbear.com/learn/software-testing/what-is-service-virtualization/"><span class="No-Break">https://smartbear.com/learn/software-testing/what-is-service-virtualization/</span></a></li>
				<li>Guidance from Scaled Agile on what a system demo <span class="No-Break">is: </span><a href="https://www.scaledagileframework.com/system-demo/"><span class="No-Break">https://www.scaledagileframework.com/system-demo/</span></a></li>
			</ul>
		</div>
	</body></html>