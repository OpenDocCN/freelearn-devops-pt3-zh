<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer266">
			<h1 id="_idParaDest-312"><a id="_idTextAnchor317"/><a href="B17124_13_Final_SK_ePub.xhtml#_idTextAnchor317"><em class="italic">Chapter 13</em></a>: Management and Governance on AWS</h1>
			<p>Managing and monitoring your resources on AWS is a crucial part of ensuring that your applications perform as expected, are highly available and secure, and run in the most cost-efficient manner. You want to be able to monitor how your applications are being consumed, identify any technical issues that may affect performance and availability, and ensure that only authorized entities are granted access. Furthermore, you need to be able to audit your environment, with access to information such as access patterns, and identify any anomalies that may indicate potential performance or security issues. You also want to be able to enforce change management processes to ensure that any modifications or changes made to your AWS resources are accounted for and approved. </p>
			<p>Finally, as part of your day-to-day administrative tasks in maintaining your workloads, you want to be able to effectively manage your resources, such as patching, performing updates, and automating tasks wherever possible.</p>
			<p>In this chapter, we will look at a series of AWS services that allow you to effectively monitor, report, and audit your AWS resources, enabling you to incorporate change management processes and implement a centralized administration of day-to-day tasks. We will also look at tools that offer guidance on where you can improve the performance, fault-tolerance, security, and cost-effectiveness of your resources.</p>
			<p>The following topics are dealt with in this chapter:</p>
			<ul>
				<li>The basics of Amazon CloudWatch</li>
				<li>Meeting compliance requirements with AWS CloudTrail </li>
				<li>Learning about change management with AWS Config</li>
				<li>Managing your AWS resources with AWS Systems Manager</li>
				<li>Learning how to use AWS Trusted Advisor</li>
				<li>Understanding the AWS Well-Architected Framework</li>
			</ul>
			<h1 id="_idParaDest-313"><a id="_idTextAnchor318"/>Technical requirements</h1>
			<p>To complete the exercises in this chapter, you will need to log in to your AWS account as the <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) user <strong class="bold">Alice</strong>.</p>
			<h1 id="_idParaDest-314"><a id="_idTextAnchor319"/>The basics of Amazon CloudWatch</h1>
			<p>Amazon CloudWatch enables you to monitor your AWS resources and applications, running on AWS as well as on-premises. With Amazon CloudWatch, you can see how your resources <a id="_idIndexMarker1370"/>are performing in real time. Using CloudWatch, you can collect resource and application metrics, logs, and events, and have these recorded into CloudWatch for analysis and identifying trends. A metric represents a time-ordered set of data points that are published to CloudWatch.</p>
			<p>Amazon CloudWatch can be used to configure alarms whereby if those metrics breach certain thresholds for a specified period, you can generate an alarm on which action can be taken to remediate.</p>
			<p>With Amazon CloudWatch, you can track and collect metrics for your Amazon EC2 instances, Amazon DynamoDB tables, Amazon <strong class="bold">Relational Database Service</strong> (<strong class="bold">RDS</strong>) instances, and <a id="_idIndexMarker1371"/>more. Every AWS service publishes metrics to Amazon CloudWatch. You get basic metrics, which are offered free of charge, and detailed metrics, for which you pay additional charges.</p>
			<p>Some typical use <a id="_idIndexMarker1372"/>cases of Amazon CloudWatch include the following:</p>
			<ul>
				<li><strong class="bold">Infrastructure monitoring and troubleshooting</strong>: Monitor key metrics, logs and visualize trends over time to identify any potential issues and bottlenecks, enabling you to conduct root-cause analysis that helps to resolve both incidents and problems.</li>
				<li><strong class="bold">Proactive resource optimization</strong>: Configure alarms that monitor metric values and are triggered if breaches occur. Define an automatic remediation action, such as configuring auto-scaling, to launch new instances and terminate failed instances. Send out notification alerts to administrators and system operators.</li>
				<li><strong class="bold">Log analytics</strong>: Analyze log information from various sources to help address operational <a id="_idIndexMarker1373"/>issues, potential security attacks, or application performance issues, and take effective actions to remediate.</li>
			</ul>
			<p>Let's look at metrics in more detail.</p>
			<h2 id="_idParaDest-315"><a id="_idTextAnchor320"/>CloudWatch metrics</h2>
			<p>CloudWatch metrics represent variables that you can monitor as a time-ordered set of data points. Any service <a id="_idIndexMarker1374"/>that you consume will report metrics to CloudWatch. For example, you could monitor the CPU utilization of an EC2 instance over a period that will help you track the performance of that instance.</p>
			<p>Each data point will consist of a timestamp. If the resource does not provide a timestamp as it publishes the metric to CloudWatch, then CloudWatch will create a timestamp based on the time that the data point was received. The following diagram illustrates the CPU utilization metric of Linux-based EC2 instances over the past three days:</p>
			<div>
				<div id="_idContainer258" class="IMG---Figure">
					<img src="Images/B17124_13_01.jpg" alt="Figure 13.1 – CPU utilization metrics for an EC2 instance running an e-commerce application&#13;&#10;" width="1546" height="357"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.1 – CPU utilization metrics for an EC2 instance running an e-commerce application</p>
			<p>Amazon CloudWatch offers a wide range of built-in metrics, but you can also create custom metrics based on your requirements:</p>
			<ul>
				<li><strong class="bold">Built-in metrics</strong>: Amazon CloudWatch allows you to collect default metrics from the <a id="_idIndexMarker1375"/>vast array of AWS services, such as Amazon EC2, Amazon S3, Amazon RDS, and more, out of the box. An example includes CPU utilization, disk read/write, and data-transfer metrics for your EC2 instance.</li>
				<li><strong class="bold">Custom metrics</strong>: Amazon CloudWatch also allows you to collect custom metrics from <a id="_idIndexMarker1376"/>your own applications to monitor performance and troubleshoot any bottlenecks. Examples include web application load times, request error rates, and so on. Another example of a custom metric is <em class="italic">operating system memory consumption</em>. This is because unlike CPU utilization, which monitors the underlying hardware CPU usage patterns, memory metrics are at the OS-level and cannot be monitored by default. To ingest custom metrics, you need to use the CloudWatch Agent or the <strong class="source-inline">PutMetricData</strong> API action to publish them to CloudWatch. </li>
			</ul>
			<p>An important point to note is that metrics exist in the Region in which they are created. However, you can configure <em class="italic">cross-account cross-Region dashboards</em>, which will allow you to <a id="_idIndexMarker1377"/>gain visibility of CloudWatch metrics, logs, and alarms across related accounts and understand the health and performance of your applications across Regions.</p>
			<p>CloudWatch will store your metrics for up to 15 months. Data points older than 15 months are expired, as new data points come in on a rolling basis.</p>
			<p>Next, let's look at how you can use AWS CloudWatch dashboards to get centralized visibility on your resources.</p>
			<h2 id="_idParaDest-316"><a id="_idTextAnchor321"/>Dashboards</h2>
			<p>You can create one or more dashboards on Amazon CloudWatch that allow you to visualize and <a id="_idIndexMarker1378"/>monitor your resources and the metrics that are important, all within a single view pane. As well as visualizing your metrics through a variety of charts and graphs, you can also publish your CloudWatch alarms (discussed next) on your dashboard for high visibility on any potential issues.</p>
			<p>CloudWatch dashboards can be configured to provide insights on your resources' health across AWS accounts and Regions, using the cross-account functionality. This functionality is integrated with <em class="italic">AWS Organizations</em>, enabling you to efficiently build your cross-account dashboards. Here is a quick screenshot of a CloudWatch dashboard:</p>
			<div>
				<div id="_idContainer259" class="IMG---Figure">
					<img src="Images/B17124_13_02.jpg" alt="Figure 13.2 – A CloudWatch dashboard&#13;&#10;" width="1650" height="668"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.2 – A CloudWatch dashboard</p>
			<h2 id="_idParaDest-317"><a id="_idTextAnchor322"/>Alarms</h2>
			<p>You can configure CloudWatch alarms to monitor a given resource metric, for example, the average <a id="_idIndexMarker1379"/>CPU utilization of an EC2 instance. If the metric crosses a specific threshold for a specified period, then the alarm can be triggered to take a certain action. The alarm only triggers if the threshold has been breached for a specified period, and this is important. You do not want the alarm triggering just because there happens to be a momentary spike. So, for example, you would want the alarm to be triggered if the average CPU utilization on your EC2 instance goes above 80% for 15 minutes. </p>
			<p>Alarms can be in one of three states:</p>
			<ul>
				<li><strong class="bold">OK</strong>: Occurs when a metric is within the range defined as acceptable.</li>
				<li><strong class="bold">Alarm</strong>: Occurs when a metric has breached a threshold for a period.</li>
				<li><strong class="bold">Insufficient data</strong>: Occurs when the data needed to make the decision is missing or incomplete. This also generally happens when you first configure an alarm while it waits to receive and analyze data.</li>
			</ul>
			<p>Once an alarm has been triggered, an automatic action can be taken to respond to it, which can include the following:</p>
			<ul>
				<li><strong class="bold">Simple Notification Service (SNS) notification</strong>: You can send out automatic <a id="_idIndexMarker1380"/>alerts to an administrator (<strong class="bold">application-to-person</strong> or <strong class="bold">A2P</strong>) or <a id="_idIndexMarker1381"/>push a <a id="_idIndexMarker1382"/>notification to an application to take some action (<strong class="bold">application-to-application</strong>, or <strong class="bold">A2A</strong>).</li>
				<li><strong class="bold">Auto Scaling action</strong>: The EC2 Auto Scaling service can be triggered to add or remove an EC2 instance <a id="_idIndexMarker1383"/>in response to an alarm state. Auto Scaling groups can be configured to launch additional instances if the average load across the servers is above a given threshold for a period of time, for example, if average CPU is above 80% for more than 10 minutes.</li>
				<li><strong class="bold">EC2 action</strong>: You can <a id="_idIndexMarker1384"/>have an alarm trigger an EC2 action, such as stopping an EC2 instance, terminating it, restarting it, or recovering it. Recovery of an instance simply means that the instances are migrated onto another host, something you would do if there was an underlying issue with the host hardware running the instance. Recovery action is only initiated based on the failure of <em class="italic">system status check</em> errors.</li>
			</ul>
			<p>Finally, you can also publish your alarms in your CloudWatch dashboards, which can give you a quick visual of your alarm statuses. </p>
			<p>Next, we look at Amazon CloudWatch Logs.</p>
			<h2 id="_idParaDest-318"><a id="_idTextAnchor323"/>CloudWatch Logs</h2>
			<p>Amazon CloudWatch offers a feature to centrally collect and store logs from both AWS and non-AWS sources. These <a id="_idIndexMarker1385"/>AWS sources could be EC2 instances, CloudTrail logs (discussed later in this chapter), Route 53 DNS queries, and VPC flow logs. You can also ingest logs from non-AWS sources, such as your web applications access logs, error logs, and operating system event logs.</p>
			<p>CloudWatch gives you a central view of all your logs regardless of their source – log events generated as part of your CloudWatch logs are essentially a time-ordered series of events that you can then query, analyze, search, and filter for specific patterns or error codes, and so on. You can also visualize your log data using dashboards and ingest these logs into other applications for more complex querying.</p>
			<p>In terms of retention, logs are kept indefinitely and never expire. However, you can adjust the retention policy by choosing a retention period between 1 day and 10 years. You can further <a id="_idIndexMarker1386"/>archive your log files into Amazon S3 using one of the Glacier classes for long-term storage.</p>
			<p>Let's look at some of the key components of CloudWatch Logs next:</p>
			<ul>
				<li><strong class="bold">Log events</strong>: This represents some event or activity recorded by the application or resource <a id="_idIndexMarker1387"/>being monitored. The log event will include the timestamp and the log message.</li>
				<li><strong class="bold">Log streams</strong>: This consists of a sequence of log events that share the same source. CloudWatch <a id="_idIndexMarker1388"/>Logs groups log events from the same source into a log stream. For example, a log stream may be associated with a web server access log on a specific host.</li>
				<li><strong class="bold">Log groups</strong>: CloudWatch then organizes these log streams into a <em class="italic">log group</em>. A log group <a id="_idIndexMarker1389"/>represents log streams that have the same retention, monitoring, and access control settings. For example, you can create a log group to collect and organize all related log streams that relate to web server access logs from multiple hosts in a fleet.</li>
				<li><strong class="bold">Metric filters</strong>: These allow you to extract specific data from ingested events and then <a id="_idIndexMarker1390"/>have those data points as custom metrics in CloudWatch. You can then use these filtered metrics to generate visualization representations and perform the necessary analysis. For example, you may wish to run a filter to identify how many times users trying to access your application were not able to connect with a <strong class="source-inline">504 Gateway Timeout</strong> error message, indicating some communication or network problem. </li>
			</ul>
			<p>In this section, we learned about Amazon CloudWatch Logs, which can be used to ingest log information into CloudWatch from both AWS and non-AWS sources. You can use CloudWatch Logs to analyze access patterns, identify security and technical issues, and assist in triaging bottlenecks.</p>
			<p>Next, we will look at Amazon CloudWatch Events, which is a near real-time stream of system events related to your Amazon resources. </p>
			<h2 id="_idParaDest-319"><a id="_idTextAnchor324"/>Amazon CloudWatch Events</h2>
			<p>With Amazon CloudWatch Events, you create <em class="italic">rules</em> that continuously monitor your AWS resources and <a id="_idIndexMarker1391"/>then respond with an action when a given event occurs. Amazon CloudWatch delivers a near real-time stream of system events, and the rules you define can trigger some action when those events occur.</p>
			<p>An example of an event is when an EC2 instance enters the <em class="italic">stop state</em> because someone performed a shutdown operation on the instance. Another example is when an IAM user logs into the AWS Management Console. Every <em class="italic">write API operation</em> is an event that has occurred, and you can choose which events to monitor and what action to take, if necessary, when those events occur.</p>
			<p>When you define a rule to monitor an event, you also specify an action by selecting an appropriate target. Targets can be a <em class="italic">Lambda</em> function, an <em class="italic">EC2 instance action</em>, an <em class="italic">SQS queue</em> or <em class="italic">SNS topic</em> to post a message to, an <em class="italic">ECS task</em>, and more. For example, let's say you want to trigger a Lambda function to process an image as soon as it is uploaded to an S3 bucket. You create an event so that when the upload is complete, the Lambda function is called to process the image in some way, such as creating multiple formats of the image or adding a watermark to it.</p>
			<p>You can also configure Amazon CloudWatch Event rules to trigger an action at a given schedule, using <em class="italic">standard rate</em> and <em class="italic">cron expressions</em>. This can be particularly useful to perform day-to-day operation tasks. In <a href="B17124_12_Final_SK_ePub.xhtml#_idTextAnchor296"><em class="italic">Chapter 12</em></a>, <em class="italic">Automation and Deployment on AWS</em>, you completed an exercise that involved automatically starting an EC2 instance at 8 A.M. and then shutting it down at 6 P.M., Monday to Friday. </p>
			<p>In this section, we learned about Amazon CloudWatch Events, which allow you to use simple rules to perform some action when a given event takes place for a particular resource. CloudWatch Events can help you respond to operational changes to complete workflows and task, or take any corrective action if required. CloudWatch events can also be used to schedule automated actions that trigger at certain times to help repeatable day-to-day operations.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">In <a href="B17124_10_Final_SK_ePub.xhtml#_idTextAnchor249"><em class="italic">Chapter 10</em></a>, <em class="italic">Application Integration Services</em>, you learned about Amazon EventBridge. Amazon CloudWatch Events and EventBridge use the same underlying service and API, and Amazon recommends EventBridge as the preferred way to manage your events as it offers more features.</p>
			<p>Next up, you will <a id="_idIndexMarker1392"/>learn about Amazon CloudTrail, which is a service you use to enforce governance, compliance, and operational and risk auditing of your AWS account.</p>
			<h1 id="_idParaDest-320"><a id="_idTextAnchor325"/>Meeting compliance requirements with Amazon CloudTrail</h1>
			<p>AWS CloudTrail is a <a id="_idIndexMarker1393"/>service that enables you to log every action <a id="_idIndexMarker1394"/>taken in your AWS account, allowing you to track user activity and API usage. CloudTrail is enabled by default on your AWS account when you create it. It stores event history accessible within the CloudTrail dashboard for every activity that occurs in your AWS account. The following screenshot shows an example of the CloudWatch event history:</p>
			<div>
				<div id="_idContainer260" class="IMG---Figure">
					<img src="Images/B17124_13_03.jpg" alt="Figure 13.3 – AWS CloudTrail&#13;&#10;" width="1486" height="551"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.3 – AWS CloudTrail</p>
			<p>You can use CloudTrail for enforcing and managing your overall compliance and governance requirements since it can provide you with a time-ordered series of events that have taken place in your account. You can also respond to events as they occur by ingesting them into Amazon CloudWatch and then configuring alarms or event rules accordingly to react to specific events. AWS CloudTrail events provide a history of both API and non-API activity. API activity includes actions such as launching a new EC2 instance or <a id="_idIndexMarker1395"/>creating a new IAM user. Non-API activity refers to other types of actions, such as logging into the AWS Management Console.</p>
			<p>AWS CloudTrail enables you to record three different types of events, as follows:</p>
			<ul>
				<li><strong class="bold">Management events</strong>: Provides information about management operations you <a id="_idIndexMarker1396"/>carry out in your AWS account. These are also known as <em class="italic">control plane operations</em> and include <em class="italic">write-only events</em>, such as the <strong class="source-inline">RunInstances</strong> API operation to launch an EC2 instance as shown in the preceding screenshot, which was performed by our IAM user, <strong class="bold">Alice</strong>. Write-only events refer to operations that may create/modify a resource. Management events can also include <em class="italic">read-only events</em>, such as the <strong class="source-inline">DescribeInstances</strong> API operation, which will return a list of EC2 instances but where no changes are made. Finally, management events can also include non-API activity, such as when a user logs into the AWS Management Console.</li>
				<li><strong class="bold">Data events</strong>: Provides information about operations performed on or in a resource <a id="_idIndexMarker1397"/>within your AWS account, for example, creating an object (such as uploading a file) in an Amazon S3 bucket using the <strong class="source-inline">PutObject</strong> API operation. Data events are also known as <em class="italic">data plane operations</em> and tend to be high-volume. Other examples of data events include Lambda function executions using the <strong class="source-inline">Invoke</strong> API and the <strong class="source-inline">PutItem</strong> API operation on a DynamoDB table, which results in new items being added to the table. Data events are not logged by default. To record data events, you need to create a trail and explicitly add supported resources or resource types for which you wish to collect events.</li>
				<li><strong class="bold">Insights events</strong>: Provides <a id="_idIndexMarker1398"/>information on unusual activities in your AWS account. Once enabled, CloudTrail will detect any unusual activity, which is determined if there are any API operations that significantly differ from the account's typical usage patterns. For example, typically your account logs no more than 10 Amazon S3 <strong class="source-inline">deleteBucket</strong> API calls per minute, but all of a sudden, it starts to log an average of 200 <strong class="source-inline">deleteBucket</strong> API calls per minute. Insight events contain related <a id="_idIndexMarker1399"/>information about the event, such as API, incident time, and statistics, that help you understand and act on unusual activity.</li>
			</ul>
			<p>CloudTrail will log all API management events automatically when you open a new AWS account. The event history service will store 90 days' worth of management events that can be viewed and downloaded. The event history will not contain any data events – for this, you will need to create a trail. Let's look at trails next. </p>
			<h2 id="_idParaDest-321"><a id="_idTextAnchor326"/>Trails</h2>
			<p>If you wish to configure CloudTrail to store specific management events or data events and require <a id="_idIndexMarker1400"/>more than 90 days' worth of event history, you can configure a <em class="italic">trail</em>. A trail is a configuration that enables CloudTrail to record specific types of events and have them delivered to an Amazon S3 bucket, CloudWatch Logs, and CloudWatch Events.</p>
			<p>Trails can be configured to record events from a single Region or across Regions:</p>
			<ul>
				<li><strong class="bold">Single Region trail</strong>: CloudTrail will records events that are specific to the Region <a id="_idIndexMarker1401"/>you specify, and those log files are delivered to an Amazon S3 bucket you specify. Multiple trails can be delivered to the same S3 bucket or separate buckets. Single trails are viewable only in the AWS Regions where the logs are created.</li>
				<li><strong class="bold">All Regions trail</strong>: CloudWatch will record events in each Region and deliver the event <a id="_idIndexMarker1402"/>log files to the S3 bucket you specify. Note that if Amazon adds a new Region after you have created a trail that applies to <em class="italic">all Regions</em>, then the new Region is automatically included as well.</li>
			</ul>
			<p>By default, an <em class="italic">all-Regions trail</em> is the default option when you create a trail in the CloudTrail console. Furthermore, CloudTrail will deliver log files from multiple Regions to a single Amazon S3 bucket and a CloudWatch Logs log group. </p>
			<p>Most AWS services are Region-specific and so events are recorded in the Region in which the action occurred. However, for global services like <strong class="bold">IAM</strong>, events are recorded as occurring in the <strong class="source-inline">US East (N. Virginia)</strong> Region.</p>
			<p>You can also create an <em class="italic">AWS organization trail</em>, which is a configuration option that allows you to record events in the management account and all member accounts in AWS Organizations. Using an organization trail will ensure that you record important events across all your AWS accounts.</p>
			<p>In this <a id="_idIndexMarker1403"/>section, you learned about AWS CloudTrail, which is a service that enables you to audit your AWS account and enable compliance, monitoring, and governance. AWS CloudTrail is not designed for performance and system health monitoring. Other monitoring services, such as Amazon CloudWatch, are designed to help you address performance or system health-related matters. Often, you are going to be using these tools together as part of the overall management of your AWS services and resources.</p>
			<p>In the next section, we will look at the AWS Config service, which allows you to assess, audit, and evaluate the <em class="italic">configuration changes</em> of your AWS resources, and help in your overall change management process.</p>
			<h1 id="_idParaDest-322"><a id="_idTextAnchor327"/>Learning about change management with AWS Config</h1>
			<p>AWS Config is a service that allows you to gain visibility into how your AWS resources are configured <a id="_idIndexMarker1404"/>and deployed in your AWS account. With AWS Config, you can see how resources are related to each other, how they were configured in the past, and historical changes to those resources over time.</p>
			<p>This can be particularly useful when you start running multiple environments, such as development and production, where within those environments are hosted countless resources across the vast array of services on AWS. For example, you would want to be aware of how your VPCs have been configured, what subnets and security groups are attached to them, what routes have been added to your route tables, and so on. AWS Config can help you maintain an accurate database of all this information as well as track changes as they occur in your AWS accounts.</p>
			<p>You can use AWS Config to ensure that your resources have been configured in accordance with internal guidelines that fulfill compliance requirements. The service enables you <a id="_idIndexMarker1405"/>to effectively implement security analysis, change management processes, and troubleshooting exercises. </p>
			<p>Let's look at some of the core components of AWS Config.</p>
			<h2 id="_idParaDest-323"><a id="_idTextAnchor328"/>Configuration items</h2>
			<p>A <strong class="bold">Configuration Item</strong> (<strong class="bold">CI</strong>) refers to a <em class="italic">point-in-time</em> snapshot of various attributes for a given AWS <a id="_idIndexMarker1406"/>resource in your <a id="_idIndexMarker1407"/>AWS account. A configuration item will include information such as metadata, attributes, relationships with other resources, and its current configuration. A new configuration item is created whenever a change is detected to a resource that is being recorded. You will be able to see what the configuration was previously and what changed. The configuration item is detailed in a <strong class="source-inline">JSON diff</strong> file, highlighting the fields which have changed, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer261" class="IMG---Figure">
					<img src="Images/B17124_13_04.jpg" alt="Figure 13.4 – AWS Config JSON showing a configuration change for an EC2 instance&#13;&#10;" width="1488" height="800"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.4 – AWS Config JSON showing a configuration change for an EC2 instance</p>
			<p>As noted <a id="_idIndexMarker1408"/>in the preceding screenshot, you can see that AWS Config has noted various changes that were made to our EC2 instance, such as the upgrade of the instance type from <strong class="source-inline">t2.micro</strong> to <strong class="source-inline">t2.small</strong>.</p>
			<h2 id="_idParaDest-324"><a id="_idTextAnchor329"/>Configuration history</h2>
			<p>This is <a id="_idIndexMarker1409"/>particularly useful when you want to review changes to your resources over time. The configuration history is a record of configuration items for a given resource over a period. Using the configuration history, you can answer questions such as when a resource was first created, what changes were made over the last week, and what configuration changes were introduced two days ago at 4 P.M. The configuration history file for each resource type is stored in an Amazon S3 bucket that you specify.</p>
			<h2 id="_idParaDest-325"><a id="_idTextAnchor330"/>Configuration recorder</h2>
			<p>The configuration recorder must be enabled and started for AWS Config to start recording <a id="_idIndexMarker1410"/>changes made to your resources and to create CIs. The configuration record can be configured to record all resources or only specific resources in each Region, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer262" class="IMG---Figure">
					<img src="Images/B17124_13_05.jpg" alt="Figure 13.5 – AWS Config settings&#13;&#10;" width="1133" height="839"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.5 – AWS Config settings</p>
			<p>You will also note that you can also choose to record global resources, such as IAM resources.</p>
			<h2 id="_idParaDest-326"><a id="_idTextAnchor331"/>Configuration snapshot</h2>
			<p>This is a collection of configuration items for your resources represented as a point-in-time image <a id="_idIndexMarker1411"/>in your AWS environment. The snapshot can be used to validate configurations and identify any that are incorrectly configured. The snapshots can be stored in a predefined Amazon S3 bucket and can be viewed in the AWS Config console.</p>
			<h2 id="_idParaDest-327"><a id="_idTextAnchor332"/>Configuration stream</h2>
			<p>As you create, modify, or delete resources in your AWS account, new CIs are created, which are <a id="_idIndexMarker1412"/>added to the configuration stream. The configuration stream uses an Amazon SNS topic to send out notifications every time a change to your resources occurs. This can be used to alert an administrator, for example, and potentially watch out for any technical or security issues.</p>
			<p>In this section, you learned about the AWS Config service, which is a service to help you manage changes to your resources in your AWS account. You can use AWS Config to monitor how your resources relate to each other and how the configurations and relationships change over time.</p>
			<p>In the next section, we look at AWS Systems Manager, which enables you to track and resolve operational issues across your AWS accounts, automate day-to-day operational tasks to manage your resources, and enforce security measures for your applications.</p>
			<h2 id="_idParaDest-328"><a id="_idTextAnchor333"/>Managing your AWS resources with AWS Systems Manager</h2>
			<p>AWS Systems Manager is a service that enables you to centrally manage your AWS resources. With AWS Systems Manager, you can gain visibility of your resources across AWS <a id="_idIndexMarker1413"/>services, perform configuration management, and automate day-to-day <a id="_idIndexMarker1414"/>operational tasks. Previously known as <strong class="bold">SSM</strong>, AWS Systems Manager can help you can enforce compliance with desired configuration states and take corrective action on any policy violations where necessary.</p>
			<p>AWS Systems Manager uses the concept of documents (written in JSON or YAML), which define the actions that Systems Manager performs on your managed resources. The documents are used by AWS Systems Manager to fulfill its various capabilities, such as operational management, change management, application management, and node management. AWS Systems Manager comes with a vast collection of predefined documents, and you can create your own. For example, the <strong class="bold">AWS-CreateRdsSnapshot</strong> document can be used to create an RDS snapshot for an RDS instance, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer263" class="IMG---Figure">
					<img src="Images/B17124_13_06.jpg" alt="Figure 13.6 – AWS Systems Manager predefined documents&#13;&#10;" width="1220" height="553"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.6 – AWS Systems Manager predefined documents</p>
			<p>AWS Systems Manager offers a wide range of capabilities, including the following:</p>
			<ul>
				<li><strong class="bold">Run Command</strong>: Part of the node management capability, the Run Command capability <a id="_idIndexMarker1415"/>enables you to remotely run Linux shell scripts and Windows PowerShell commands on your fleet of EC2 instances. This can be used to perform configuration changes, and install and update applications. </li>
				<li><strong class="bold">State Manager</strong>: This ensures that your managed instances are configured to a predefined <a id="_idIndexMarker1416"/>state, enabling you to maintain consistency in your configurations across a fleet of instances, such as firewall configuration, antivirus configurations, and more.</li>
				<li><strong class="bold">Inventory</strong>: This enables you to gather software configuration information about <a id="_idIndexMarker1417"/>your EC2 instances. The Inventory capability will provide information on applications, files, components, and patches across your managed instances.</li>
				<li><strong class="bold">Maintenance Window</strong>: Part of the change management capability, the Maintenance <a id="_idIndexMarker1418"/>Window service enables you to schedule times when administrative tasks such as installing patches and updates can be performed so as not to disrupt your team during normal business hours.</li>
				<li><strong class="bold">Patch Manager</strong>: This enables you to automate patching of your EC2 instances, which can <a id="_idIndexMarker1419"/>comprise security and application updates. Note that updates for applications on Windows servers are limited to those released by Microsoft.</li>
				<li><strong class="bold">Automation</strong>: This enables you to automate various maintenance tasks, such as updating <a id="_idIndexMarker1420"/>AMIs, creating snapshots of <strong class="bold">Elastic Block Store</strong> (<strong class="bold">EBS</strong>) volumes, resetting passwords, and launching or terminating <a id="_idIndexMarker1421"/>EC2 instances, among others.</li>
				<li><strong class="bold">Parameter Store</strong>: This offers a means of securely storing configuration data and secret <a id="_idIndexMarker1422"/>information. For example, in <a href="B17124_09_Final_SK_ePub.xhtml#_idTextAnchor223"><em class="italic">Chapter 9</em></a>, <em class="italic">High Availability, and Elasticity on AWS</em>, you will recall configuring the database connection strings for the <em class="italic">good deed of the month</em> application. The database connection strings consisted of sensitive username and password information, which was saved in plain text in the Amazon S3 bucket repository. Furthermore, the database connections file when copied from the S3 bucket and stored in the HTML directory of your server is a security risk. Sensitive information should always be stored and managed more securely. AWS Systems Manager's Parameter Store enables you to store sensitive information such as passwords and database strings as parameter values. These values can be stored encrypted, and your application can be configured to securely retrieve these values as they are needed from the Parameter Store.</li>
				<li><strong class="bold">Distributor</strong>: This enables you to create and deploy application packages to your managed <a id="_idIndexMarker1423"/>instances. You can create your software packages as executables that operating systems recognize, enabling easy deployments. Distributor can also reinstall new package versions and perform in-place updates.</li>
				<li><strong class="bold">Session Manager</strong>: In <a href="B17124_07_Final_SK_ePub.xhtml#_idTextAnchor157"><em class="italic">Chapter 7</em></a>, <em class="italic">AWS Compute Services</em>, we discussed the importance of bastion hosts, which act as an entry point to administer other EC2 instances you <a id="_idIndexMarker1424"/>deploy in a VPC, across your public and private subnets. While bastion hosts are intended to be highly secure because of how they are configured or accessed, you still need to manage and maintain the servers, including performing security updates, ensuring <a id="_idIndexMarker1425"/>performance levels, and so on. AWS Systems Manager offers <strong class="bold">Session Manager</strong>, which allows remote access to your EC2 instances using a browser-based shell or the CLI. Session Manager provides secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, or manage SSH keys.</li>
				<li><strong class="bold">Incident Manager</strong>: This is another Systems Manager offering that enables you to manage <a id="_idIndexMarker1426"/>and resolve incidents affecting AWS-hosted applications. The Incident Manager service offers a management console to track all your incidents and notify responders of impact, identify data that can help with troubleshooting, and help you get services back up and running. </li>
			</ul>
			<p>These are just some of the capabilities on offer from AWS Systems Manager. Here is a quick screenshot of the Inventory console, showcasing information from a single EC2 instance that was deployed in my AWS account:</p>
			<div>
				<div id="_idContainer264" class="IMG---Figure">
					<img src="Images/B17124_13_07.jpg" alt="Figure 13.7 – AWS Systems Manager Inventory&#13;&#10;" width="1089" height="788"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.7 – AWS Systems Manager Inventory</p>
			<p>So far, we have looked at the AWS Systems Manager service, which offers a suite of capabilities to <a id="_idIndexMarker1427"/>centrally manage and automate day-to-day operations for your AWS resources. </p>
			<p>In the next section, you will learn about the AWS Trusted Advisor service, which enables you to inspect your AWS environment and identify whether your resources have been configured in accordance with AWS best practices.</p>
			<h1 id="_idParaDest-329"><a id="_idTextAnchor334"/>Learning how to use AWS Trusted Advisor</h1>
			<p>The AWS Trusted <a id="_idIndexMarker1428"/>Advisor service analyzes your resources and how they have been configured. The service helps to measure the configuration of your resources against best practices and identify opportunities to save money, improve system availability and performance, or address security concerns. </p>
			<p>Specifically, the <a id="_idIndexMarker1429"/>Trusted Advisor service will report on its analysis against the following core categories:</p>
			<ul>
				<li><strong class="bold">Cost optimization</strong>: Performs checks on your resources to identify which ones are underutilized. AWS Trusted Advisor will then offer recommendations on where you could reduce your costs. For example, Elastic IP addresses are only free if they are attached to a running EC2 instance. AWS charges you an hourly fee for provisioning Elastic IP addresses if they are not being consumed, that is, not attached to any instance, or attached to an instance that is in a stopped state.</li>
				<li><strong class="bold">Performance</strong>: Offers recommendations on where you can improve the responsiveness of your applications. For example, if you are using a gp2 EBS volume type for an EC2 instance that seems to be heavily utilized, it can recommend you an upgrade to an io1 EBS volume, which will improve performance.</li>
				<li><strong class="bold">Security</strong>: Reports on any resources that have not been configured in accordance with security best practices. For example, if you have not configured MFA on the root account, then AWS will highlight this as a potential security risk and recommend that you configure MFA.</li>
				<li><strong class="bold">Fault tolerance</strong>: Identifies options for increasing the resiliency of your AWS solutions. For example, AWS will identify any RDS instance that has not been configured with multi-AZ as a risk factor.</li>
				<li><strong class="bold">Service limits</strong>: Checks your AWS account to identify whether you are approaching any service limits or quotas. For example, when using the AWS Auto Scaling service, you have a default limit of configuring up to 200 launch configurations per Region. Should you start to exceed more than 80% of this limit, you will see an alert in Trusted Advisor.</li>
			</ul>
			<h2 id="_idParaDest-330"><a id="_idTextAnchor335"/>AWS Trusted Advisor and Support plans</h2>
			<p>The AWS Trusted Advisor service offers different levels of checks based on the AWS Support plan <a id="_idIndexMarker1430"/>that you have subscribed to. If you are only on the <em class="italic">Basic</em> Support plan, then you only have access to six checks in the security category and all checks in the service limits category.</p>
			<p>To access the full range of checks across all categories, you must be subscribed to either the <em class="italic">Business</em> or <em class="italic">Enterprise</em> Support plans. With either of these plans, you can also use Amazon CloudWatch Events to monitor the status of Trusted Advisor checks.</p>
			<p>In this section, we discussed the AWS Trusted Advisor service, which is a reporting tool that enables you to identify whether your resources have been configured in accordance with best practices and whether there are opportunities to save on costs. </p>
			<p>In the next section, you will learn about the AWS Well-Architected Framework, which offers a series of recommendations to help you build secure, high-performing, resilient, and efficient application infrastructure.</p>
			<h1 id="_idParaDest-331"><a id="_idTextAnchor336"/>Understanding the AWS Well-Architected Framework</h1>
			<p>The AWS Well-Architected Framework consists of a set of design principles and architectural <a id="_idIndexMarker1431"/>best practices that you can follow when building solutions for the cloud. AWS offers the Well-Architected Tool, which can be used to review the state of your applications and resources, and compares them to the latest AWS architectural best practices.</p>
			<p>The Well-Architected Framework comprises the following <em class="italic">five pillars</em>.</p>
			<h2 id="_idParaDest-332"><a id="_idTextAnchor337"/>Reliability</h2>
			<p>Applications deployed in the cloud must be resilient to failures. The resources that your applications <a id="_idIndexMarker1432"/>depend on (compute, storage, networks, and databases) must be available and reliable. Any technical issues on any of these resources will cause your application to become unreliable and potentially fail.</p>
			<p>The reliability pillar also focuses on how quickly you can recover from failure based on your architectural design. This is because failures are bound to happen and your architecture must be able to recover from these failures swiftly. One key concept that you should also consider is the fact that replacing a failed component is often better than trying to <a id="_idIndexMarker1433"/>figure out why the component failed and attempting to resolve the issue that caused the failure. This is because as <a id="_idIndexMarker1434"/>you spend time trying to troubleshoot the failure, you risk increasing your <strong class="bold">Recovery Time Objective</strong> (<strong class="bold">RTO</strong>). For example, with EC2, you can deploy your application across multiple instances and multiple AZs. You can then configure Elastic Load Balancers and the Auto Scaling service to ensure that if an EC2 instance fails, traffic is routed to only those instances that are healthy, while the failed EC2 instance is replaced automatically in the background.</p>
			<h2 id="_idParaDest-333"><a id="_idTextAnchor338"/>Performance efficiency</h2>
			<p>When architecting your cloud solutions, you want to offer the best performance while still ensuring <a id="_idIndexMarker1435"/>that you are optimized for cost. This means you should always try to select the resource types and sizes based on your performance needs, while monitoring your resources consistently to ensure you maintain those levels of performance in accordance with demand. Performance should not suffer if demand increases. At the same time, you should only provide resources as they are required to avoid underutilization of those resources.</p>
			<p>You'd often need to incorporate resources that fall across different AWS services, such as compute, storage, and networking, and architecting your solution requires careful planning in addition to configuring each of those resources. For example, if your application is hosted in the London Region, your users in London may experience good performance. However, if you have users in South America, you may experience poor performance due to network latency issues. You can consider using Amazon CloudFront to cache your application content at edge locations closer to your South American users, improving overall application performance. </p>
			<h2 id="_idParaDest-334"><a id="_idTextAnchor339"/>Security</h2>
			<p>You should <a id="_idIndexMarker1436"/>always keep security in mind whenever you are designing your cloud solutions. You want to ensure that your applications are accessed securely by only authorized users. You also want to ensure data integrity, privacy, and sovereignty. Assigning permissions to users must always be based on the principle of least privilege, ensuring that access is granted only where required to fulfill the job function and nothing more. </p>
			<p>You should incorporate a backup and disaster recovery strategy for your application solutions, which <a id="_idIndexMarker1437"/>would also comprise securing the underlying resources that power your application. For example, you must ensure that your databases are backed up or that you regularly create EBS snapshots. Another example is to configure Amazon S3 bucket replication and, if possible, to use cross-regional replication configurations. Finally, you must be able to audit every activity that takes place in your account, and you can use tools such as AWS CloudTrail to maintain an audit log.</p>
			<h2 id="_idParaDest-335"><a id="_idTextAnchor340"/>Operational excellence</h2>
			<p>This pillar focuses on achieving operational excellence by making frequent, reversible, and <a id="_idIndexMarker1438"/>continuous changes to your workloads. Your aim should be to achieve continuous improvements in your processes and procedures. Furthermore, automating operational tasks will strengthen <a id="_idIndexMarker1439"/>the other pillars, and using <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>) with tools such as CloudFormation can help to avoid human error and enable consistency in how you respond to events. </p>
			<p>The operational excellence pillar also suggests anticipating failure and to consider performing fail tests and recovery exercises, from which you can learn how to remove potential sources of failure and mitigate risks. Understanding how your applications fail will also help you design automatic recovery solutions, which will offer consistency and rapid recovery.</p>
			<h2 id="_idParaDest-336"><a id="_idTextAnchor341"/>Cost optimization</h2>
			<p>This pillar focuses on ensuring that you architect and build solutions in a manner that avoids <a id="_idIndexMarker1440"/>unnecessary costs. At the same time, you want to be able to ensure that your applications are highly performant, reliable, operationally efficient, and secure. To achieve cost optimization, you should first understand your spending patterns and analyze where the money is going. Using tools such as Cost Explorer and Cost and Usage Reports will help you with this. </p>
			<p>Next, you must always try to adopt a consumption model. If you are running development and test servers that only going to be used for 8 hours a day, Monday to Friday, it makes sense to consider procuring those EC2 instances using the On-Demand pricing option. You should then ensure that those servers stopped outside of normal business hours for a potential cost saving of up to 75% (40 hours versus 168 hours a week). Remember that you can automate the startup and shutdown of your EC2 instances using Lambda functions and CloudWatch Events, as discussed in <a href="B17124_12_Final_SK_ePub.xhtml#_idTextAnchor296"><em class="italic">Chapter 12</em></a>, <em class="italic">Automation and Deployment on AWS</em>.</p>
			<p>Other areas where you can design for cost optimization include using managed service offerings <a id="_idIndexMarker1441"/>instead of performing heavy-lifting, data center-style operations. For example, it is much more cost-effective to host your databases on Amazon RDS and have AWS perform all the management functions for you than spinning up EC2 instances on which you install your database software. The latter results in more management efforts to ensure your database servers are patched, backed up, and secure.</p>
			<p>In this section, you learned about the AWS Well-Architected Framework, which is a set of guiding principles and best-practice recommendations to help you design and run your solutions in the cloud. In the next section, we move on to some exercises for this chapter. </p>
			<h1 id="_idParaDest-337"><a id="_idTextAnchor342"/>Exercise 13.1 – Reviewing the Trusted Advisor reports in your AWS account</h1>
			<p>In this exercise, you <a id="_idIndexMarker1442"/>will log into your AWS account and review the Trusted Advisor service: </p>
			<ol>
				<li>Log in to your AWS Management Console as the IAM user <strong class="bold">Alice</strong>.</li>
				<li>Navigate to the <strong class="bold">Trusted Advisor</strong> console, which is located under the <strong class="bold">Management &amp; Governance</strong> category in your list of services.</li>
				<li>You will be redirected to the Trusted Advisor dashboard.</li>
				<li>Because you may only have subscribed to the Basic Support plan, you will note that only a few checks are visible. From the main dashboard, note the <strong class="bold">Checks Summary</strong> section on the main pane of the dashboard.</li>
				<li>From the right-hand pane, click on the <strong class="bold">Security</strong> category.</li>
				<li>In the right-hand pane, you will note various checks, such as the one for MFA being enabled on your root account.</li>
				<li>Expand the check labeled <strong class="bold">Security Groups - Specific Ports Unrestricted</strong>. This check <a id="_idIndexMarker1443"/>analyzes how your security groups have been configured, highlighting specific ports that should provide restricted access. For example, the number <strong class="source-inline">22</strong> port that enables <strong class="bold">SSH</strong> remote connections should not be opened to the internet. Ideally, you should restrict access to this port to a specific IP range, such as the IP block of your corporate on-premises network. In our previous exercises, we created inbound rules on this port from the entire internet and, therefore, AWS Trusted Advisor will highlight it as a potential security issue. <p>In the following screenshot, you will note that we have three security groups that have been configured to allow inbound traffic on the number <strong class="source-inline">22</strong> port from the internet unrestricted:</p></li>
			</ol>
			<div>
				<div id="_idContainer265" class="IMG---Figure">
					<img src="Images/B17124_13_08.jpg" alt="Figure 13.8 – AWS Trusted Advisor dashboard&#13;&#10;" width="1101" height="629"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.8 – AWS Trusted Advisor dashboard</p>
			<p>From this <a id="_idIndexMarker1444"/>exercise, you should've learned how to review the AWS Trusted Advisor dashboard. You were able to identify some security alerts based on your configuration of security groups from earlier exercises that did not adhere to best practices. You can then use this report to identify which security groups need to be amended to increase security.</p>
			<h1 id="_idParaDest-338"><a id="_idTextAnchor343"/>Summary</h1>
			<p>In this chapter, we looked at several services on AWS that can help you manage and govern your applications in the cloud. We discussed various monitoring and logging tools, such as Amazon CloudWatch, AWS CloudTrail, and AWS Config, and how you can use these services to ensure performance, reliability, security, and effective change management. You also learned about the AWS Systems Manager service, which offers a suite of capabilities to centrally track and resolve operational issues across your AWS resources. We used AWS Systems Manager to automate day-to-day administrative tasks, ensure compliance of your resource configurations, offer incident and change management services, and improve visibility and control.</p>
			<p>The AWS Trusted Advisor service offers a wide range of reports that allow you to cross-reference your resource configurations with various best-practice design principles. Finally, we discussed how you must follow the design principles and recommendations offered by the AWS Well-Architected Framework when building solutions for the cloud. </p>
			<p>In the next chapter, we will cover AWS security concepts and look at various security tools you should use when architecting and managing cloud applications. </p>
			<h1 id="_idParaDest-339"><a id="_idTextAnchor344"/>Questions</h1>
			<ol>
				<li value="1">Which AWS service enables you to track all API activity in your AWS account, regardless of whether the activity was performed using the AWS Management Console of the CLI?<ol><li>AWS CloudTrail</li><li>AWS Config</li><li>AWS Trusted Advisor</li><li>Application load balancer logs</li></ol></li>
				<li>As part of implementing change management, which AWS service can be used to assess, audit, and evaluate change configurations of your AWS resources, enabling you to identify whether a change was the cause of an incident?<ol><li>AWS Config</li><li>AWS CloudTrail</li><li>Amazon CloudWatch</li><li>AWS Outposts</li></ol></li>
				<li>Which AWS service can be used to monitor your company's fleet of EC2 instances, which can be used to identify performance issues related to CPU utilization or memory consumptions?<ol><li>Amazon CloudWatch</li><li>AWS Cloud Monitor</li><li>AWS EC2 Monitor</li><li>AWS CloudTrail</li></ol></li>
			</ol>
			<ol>
				<li value="4">Which AWS service helps you identify potential unused resources, such as Elastic IP addresses, that are not attached to a running instance and thus highlight opportunities to save on costs?<ol><li>AWS Cost Explorer</li><li>AWS Trusted Advisor</li><li>AWS Resource Manager</li><li>AWS Budgets</li></ol></li>
				<li>Which capability of the AWS Systems Manager service enables you to remotely connect to your Linux EC2 instances without having to use bastion hosts in your VPC?<ol><li>Session Manager</li><li>Parameter Store</li><li>Run Command</li><li>Incident Manager</li></ol></li>
			</ol>
		</div>
	</div></body></html>