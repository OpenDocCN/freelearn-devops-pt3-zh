<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer030">
<h1 class="chapter-number" id="_idParaDest-224"><a id="_idTextAnchor325"/>11</h1>
<h1 id="_idParaDest-225"><a id="_idTextAnchor326"/>Using Ansible for Configuration as Code</h1>
<p>In this chapter, we are going to cover <strong class="bold">configuration management</strong> (<strong class="bold">CM</strong>), <strong class="bold">Configuration as Code</strong> (<strong class="bold">CaC</strong>), and our tool of choice for <span class="No-Break">it: Ansible.</span></p>
<p>We will cover the <span class="No-Break">following topics:</span></p>
<ul>
<li>CM systems <span class="No-Break">and CaC</span></li>
<li><span class="No-Break">Ansible</span></li>
<li><span class="No-Break">Ansible Galaxy</span></li>
<li><span class="No-Break">Handling secrets</span></li>
<li>Ansible Tower <span class="No-Break">and alternatives</span></li>
<li><span class="No-Break">Advanced topics</span></li>
</ul>
<h1 id="_idParaDest-226"><a id="_idTextAnchor327"/>Technical requirements</h1>
<p>For this chapter, you will need a Linux system that you can access through <strong class="source-inline">ssh</strong>. If your main operating system is Windows, you will need another Linux system to play the role of the control node. As of now, the Ansible project does not support Windows as a <span class="No-Break">control node.</span></p>
<h1 id="_idParaDest-227"><a id="_idTextAnchor328"/>CM systems and CaC</h1>
<p>Setting up<a id="_idIndexMarker960"/> and maintaining a system other than a hobbyist server (and even those, maybe, too) poses a serious challenge: how do you ensure that the system is installed and configured correctly and according to expectations? When you have to install a new server that is identical in configuration, how do you ensure that? In the past, a way of doing it was documenting the current configuration after the installation process was done. This would be a document describing the hardware, operating system, installed software, created users, and configuration applied. Any person who wanted to recreate it would have to follow steps to achieve the configuration described in <span class="No-Break">the document.</span></p>
<p>The very next logical step is to write shell scripts that achieve the same goal with one additional improvement over the manual process: the scripts—properly written, tested, and maintained—do not require manual work, except, maybe, the initial system installation. But a properly set up environment would take care even <span class="No-Break">of this.</span></p>
<p>The scripts, however, also have some defects or deficiencies. One of them is the fact that you <a id="_idIndexMarker961"/>need to account in your scripts for unfinished execution. This could happen for various reasons and would leave the system in a partially configured state. Executing the script again would perform all configuration actions from the start, sometimes leading to unexpected results. One way to account for incomplete runs would be to wrap every configuration action in a check, to see whether it had been performed previously. That would lead to the configuration script becoming larger and, eventually, evolving into a library of configuration functions and <span class="No-Break">check functions.</span></p>
<p>The task of developing and maintaining such a tool can be daunting and will probably require a whole team. Still, the results are probably worth <span class="No-Break">the effort.</span></p>
<p>Writing and maintaining documentation that describes the desired state of the system may, at first glance, be simpler and more desirable than the previously mentioned method of automating. The script cannot recover from an incomplete execution. The best it can do is inform the sysop about failure, log the error, and stop gracefully. Manually performed configuration allows the sysop to work around any obstacles and inadequacies in the procedure and edit the document to reflect the current state on <span class="No-Break">the go.</span></p>
<p>Still, a properly developed and tested script turns out to be better. Let us enumerate <span class="No-Break">the reasons:</span></p>
<ul>
<li>If the script executes without an error, it is guaranteed to perform actions without a mistake. Time and again, it has been proven that a human is the element most prone to errors <span class="No-Break">in IT.</span></li>
<li>If the script exits prematurely, the action of updating it to account for the new requirements is a perfect equivalent to updating <span class="No-Break">the documentation.</span></li>
<li>People are known to be pretty bad at maintaining documentation. The Holy Grail of programming is self-documenting code, rendering comments unnecessary, thus eliminating the risk of comments being out of sync with <span class="No-Break">the code.</span></li>
<li>The script can be executed on multiple systems at once, scaling very well, if not infinitely. Humans can perform the configuration of one system at a time with minimal risk of making <span class="No-Break">a mistake.</span></li>
<li>Configuration kept in the form of a script or program benefits from typical programming techniques, such as automated testing, dry runs, and static analysis. More so, keeping the code in a repository allows us to easily track a history of changes and integrate it with <span class="No-Break">ticket-tracking tools.</span></li>
<li>Code is unequivocal, which cannot be said about written language. A document may leave space for interpretation; a <span class="No-Break">script won’t.</span></li>
<li>Automating configuration lets you move to other, more interesting tasks, leaving the computers to do what they do best—performing repetitive, boring <span class="No-Break">tasks well.</span></li>
</ul>
<p>The world of <a id="_idIndexMarker962"/>programming and system administration has a tendency to turn small projects into larger ones with a vibrant community of developers and users. It was only a matter of time before CM systems were born. They take the burden of developing and managing portions of the code responsible for configuration actions off your shoulders. The CM system developers write the code, test it, and deem it stable. What you are left with is an action of writing configuration files or directives that tell the system what to do. Most of these systems will be able to cover the most popular platforms, allowing you to describe configuration once and run it with the same expected results on commercial Unix systems, such as AIX or Solaris, as on Linux <span class="No-Break">or Windows.</span></p>
<p>Configuration files for these systems are easily stored in a version control system such as Git. They are easily understandable by a human, which allows for simple review by your colleagues. They can be checked for syntax errors by automated tools and allow you to concentrate on the most important part of the whole endeavor: <span class="No-Break">the configuration.</span></p>
<p>This approach of <a id="_idIndexMarker963"/>keeping your configuration as a set of scripts or other data instead of a procedure to be followed manually is known <span class="No-Break">as CaC.</span></p>
<p>The CaC approach is becoming more important as the number of systems to be managed grows and<a id="_idIndexMarker964"/> the demand for fast and efficient configuration scales up. In the world of DevOps, it is usual practice to set up tens and hundreds of systems a day: systems for developers, testers, and production systems to manage new levels of demand for the service. Managing it manually would be an impossible task. Well-implemented CaC allows to run this task with a click of a button. Thus, developers and testers can deploy their own systems without bothering sysops. Your task will be to develop, maintain, and test the <span class="No-Break">configuration data.</span></p>
<p>If there is one thing sure in the world of programming, it is that there’s never going to be only one solution. The same goes for <span class="No-Break">CM tools.</span></p>
<p>Alternatives for Ansible include <strong class="bold">SaltStack</strong>, <strong class="bold">Chef</strong>, <strong class="bold">Puppet</strong>, and <strong class="bold">CFEngine</strong>, which is the oldest one; its initial release date was 1993, so it’s 30 years old as of the time of writing this book. In general, those solutions differentiate between each other with a method of enforcing configuration (pull or push) and an approach of describing the system’s state (imperative <span class="No-Break">or declarative).</span></p>
<p><strong class="bold">Imperative</strong> means<a id="_idIndexMarker965"/> that we describe the state of the server with commands for the tool to perform. Imperative programming focuses on describing how a given tool operates step <span class="No-Break">by step.</span></p>
<p><strong class="bold">Declarative</strong>, on<a id="_idIndexMarker966"/> the other hand, means we focus on what the CaC tool should accomplish without specifying all the details of how it should achieve <span class="No-Break">the r<a id="_idTextAnchor329"/>esult.</span></p>
<h2 id="_idParaDest-228"><a id="_idTextAnchor330"/>SaltStack</h2>
<p><strong class="bold">SaltStack</strong> is an<a id="_idIndexMarker967"/> open source CM tool that allows for the management of complex IT infrastructure at scale. It enables the automation of routine tasks such as package installation, user management, and software configuration, and is designed to work across a wide range of operating systems and platforms. SaltStack was founded by Thomas Hatch in 2011. The first release of SaltStack, version 0.8.0, was also made <span class="No-Break">in 2011.</span></p>
<p>SaltStack works by utilizing a master-slave architecture, where a central salt-master communicates with salt-minions running on remote machines to execute commands and manage configurations. It operates in a pull method of enforcing configuration: minions pull the latest manifest from the <span class="No-Break">master server.</span></p>
<p>Once the minion is installed and configured, we can use SaltStack to manage the server’s configuration. Here’s an example <strong class="source-inline">nginx.sls</strong> file that would install and <span class="No-Break">configure </span><span class="No-Break"><strong class="source-inline">nginx</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
nginx:
  pkg.installed
/etc/nginx/sites-available/yourdomain.tld.conf:
  file.managed:
    - source: salt://nginx/yourdomain.tld.conf
    - user: root
    - group: root
    - mode: 644</pre>
<p>In this<a id="_idIndexMarker968"/> example, the first line specifies that the <strong class="source-inline">nginx</strong> package should be installed on the target server. The next two lines define the configuration file for a hypothetical website, <strong class="source-inline">example.com</strong>, which is copied <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">/etc/nginx/sites-available/yourdomain.tld.conf</strong></span><span class="No-Break">.</span></p>
<p>To apply this state file to a server, we would use the <strong class="source-inline">state.apply</strong> command in the SaltStack command-line interface, specifying the name of the state file as <span class="No-Break">the argument:</span></p>
<pre class="console">
admin@myhome:~$ salt 'webserver' state.apply nginx</pre>
<p>This would send the instructions in the <strong class="source-inline">nginx.sls</strong> file to the salt-minion running on the web server machine, which would execute the necessary steps to ensure that <strong class="source-inline">nginx</strong> is installed and <span class="No-Break">configured co<a id="_idTextAnchor331"/>rrectly.</span></p>
<h2 id="_idParaDest-229"><a id="_idTextAnchor332"/>Chef</h2>
<p><strong class="bold">Chef</strong> is a <a id="_idIndexMarker969"/>powerful open source CM tool that allows users to automate the deployment and management of infrastructure, applications, and services. It was first released in 2009 by Opscode, which was later acquired by Chef Software Inc. Since then, Chef has been widely adopted by IT professionals and DevOps teams to streamline their workflows and reduce the time and effort required for managing <span class="No-Break">complex systems.</span></p>
<p>Chef works by defining the desired state of an infrastructure in a set of code files, called cookbooks. A <strong class="bold">cookbook</strong> is a<a id="_idIndexMarker970"/> collection of recipes that describe how to install, configure, and manage a specific piece of software or service. Each recipe contains a series of resources, which <a id="_idIndexMarker971"/>are pre-built modules that can perform specific tasks, such as installing a package or configuring a file. Chef uses a declarative approach to CM, meaning that users define what they want the system to look like, and Chef takes care of the details of how to <span class="No-Break">get there.</span></p>
<p>To install <strong class="source-inline">nginx</strong> using Chef, you <a id="_idIndexMarker972"/>would first need to create a cookbook that includes a recipe for installing <strong class="source-inline">nginx</strong>. This recipe would use the <strong class="source-inline">package</strong> resource to install the <strong class="source-inline">nginx</strong> package and the <strong class="source-inline">service</strong> resource to ensure that the <strong class="source-inline">nginx</strong> service is running. You could also use other resources, such as <strong class="source-inline">file</strong>, <strong class="source-inline">directory</strong>, or <strong class="source-inline">template</strong>, to configure <strong class="source-inline">nginx</strong>’s settings, depending on <span class="No-Break">your requirements.</span></p>
<p>Once you had created the cookbook, you would upload it to a Chef server, which acts as a central repository for cookbooks and their associated metadata. You would then use Chef’s command-line tool, called <strong class="source-inline">knife</strong>, to configure the target system to use the cookbook. This involves associating the system with a Chef environment, which defines the set of cookbooks and their versions that should be applied to the system. You would then use the <strong class="source-inline">chef-client</strong> command to run the Chef client on the target system, which will download and apply the necessary cookbooks and recipes to bring the system into the <span class="No-Break">desired state.</span></p>
<p>Here’s an example of installing and <span class="No-Break">configuring </span><span class="No-Break"><strong class="source-inline">nginx</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
# Install Nginx package
package 'nginx'
# Configure Nginx service
service 'nginx' do
  action [:enable, :start]
end
# Configure Nginx site
template '/etc/nginx/sites-available/yourdomain.tld.conf' do
  source 'nginx-site.erb'
  owner 'root'
  group 'root'
  mode '0644'
  notifies :restart, 'service[nginx]'
end</pre>
<p>This recipe <a id="_idIndexMarker973"/>uses three resources, <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="source-inline">package</strong>: This installs the <strong class="source-inline">nginx</strong> package using the default package manager on <span class="No-Break">the system.</span></li>
<li><strong class="source-inline">service</strong>: This starts and enables the <strong class="source-inline">nginx</strong> service so that it will automatically start on boot and <span class="No-Break">stay running.</span></li>
<li><strong class="source-inline">template</strong>: This creates a configuration file for <strong class="source-inline">nginx</strong> by generating it from a template file. The template file (<strong class="source-inline">nginx-site.erb</strong>) is written in <strong class="bold">Embedded Ruby</strong> (<strong class="bold">ERB</strong>) format and is located in the <strong class="source-inline">templates</strong> directory of the cookbook. The <strong class="source-inline">notifies</strong> attribute tells Chef to restart the <strong class="source-inline">nginx</strong> service if the configuration <span class="No-Break">file changes.</span></li>
</ul>
<p>Once you have created this recipe in a cookbook, you can use the <strong class="source-inline">knife</strong> command to upload the cookbook to a Chef server. You can then use the <strong class="source-inline">chef-client</strong> command to apply the recipe to a target system, which will install and configure <strong class="source-inline">nginx</strong> according t<a id="_idTextAnchor333"/>o <span class="No-Break">the recipe.</span></p>
<h2 id="_idParaDest-230"><a id="_idTextAnchor334"/>Puppet</h2>
<p><strong class="bold">Puppet</strong> is <a id="_idIndexMarker974"/>an open source CM tool that allows system administrators to automate the deployment, configuration, and management of infrastructure. It was created by Luke Kanies in 2005 and released under the Apache <span class="No-Break">License </span><span class="No-Break"><strong class="source-inline">2.0</strong></span><span class="No-Break">.</span></p>
<p>Puppet works by defining the desired state of infrastructure resources in a declarative language, known as the Puppet language. Administrators can define the configuration of servers, applications, and other infrastructure components in Puppet code, which can then be applied consistently across <span class="No-Break">multiple systems.</span></p>
<p>Puppet <a id="_idIndexMarker975"/>consists of a master server and multiple agent nodes. The master server acts as a central repository for Puppet code and configuration data, while the agent nodes execute the Puppet code and apply the desired state to <span class="No-Break">the system.</span></p>
<p>Puppet has a robust ecosystem of modules, which are pre-written Puppet code that can be used to configure common infrastructure resources. These modules are available in <strong class="bold">Puppet Forge</strong>, a<a id="_idIndexMarker976"/> public repository of <span class="No-Break">Puppet code.</span></p>
<p>Here’s an example Puppet<a id="_idIndexMarker977"/> manifest that installs <strong class="source-inline">nginx</strong> and creates a configuration file similar to what we did with SaltStack <span class="No-Break">and Chef:</span></p>
<pre class="source-code">
# Install Nginx
package { 'nginx':
  ensure =&gt; installed,
}
# Define the configuration template for the domain
file { '/etc/nginx/sites-available/yourdomain.tld.conf':
  content =&gt; template('nginx/yourdomain.tld.conf.erb'),
  owner   =&gt; 'root',
  group   =&gt; 'root',
  mode    =&gt; '0644',
  notify  =&gt; Service['nginx'],
}
# Enable the site by creating a symbolic link from sites-available to sites-enabled
file { '/etc/nginx/sites-enabled/yourdomain.tld.conf':
  ensure  =&gt; 'link',
  target  =&gt; '/etc/nginx/sites-available/yourdomain.tld.conf',
  require =&gt; File['/etc/nginx/sites-available/yourdomain.tld.conf'],
}
# Restart Nginx when the configuration changes
service { 'nginx':
  ensure     =&gt; running,
  enable     =&gt; true,
  subscribe  =&gt; File['/etc/nginx/sites-enabled/yourdomain.tld.conf'],
}</pre>
<p>Once you’ve created a manifest and put it on the Puppet server, it will be picked up by the Puppet agent installed on your server and executed. Communication, the same as in SaltStack, is being secured by the TLS protocol using the same mechanism as the HTTPS servers on <span class="No-Break">the internet.</span></p>
<p>The agent nodes run a <a id="_idIndexMarker978"/>Puppet agent process, which connects to the master server over TCP port <strong class="source-inline">8140</strong>. The agent sends a <strong class="bold">certificate signing request</strong> (<strong class="bold">CSR</strong>) to the<a id="_idIndexMarker979"/> server, which the administrator must approve. Once the CSR is approved, the agent is granted access to the server’s <span class="No-Break">Puppet configuration.</span></p>
<p>When the agent runs, it sends a request to the master server for its configuration. The server responds with a catalog of resources that should be applied to the node. The catalog is generated based on the Puppet code and manifests stored on the server, as well as any external data sources or hierarchies that <span class="No-Break">are configured.</span></p>
<p>The agent then applies the catalog to the node, which involves making any necessary changes to the node’s configuration to ensure it matches the desired state defined in the catalog. This may involve installing packages, updating configuration files, or starting or <span class="No-Break">stopping services.</span></p>
<p>The agent sends reports back to the server after applying the catalog, which can be used for monitoring and auditing purposes. The server can also use this information to detect changes to the node’s configuration that were not made through Puppet and to take corrective a<a id="_idTextAnchor335"/>ction <span class="No-Break">if necessary.</span></p>
<h2 id="_idParaDest-231"><a id="_idTextAnchor336"/>CFEngine</h2>
<p><strong class="bold">CFEngine</strong> is an<a id="_idIndexMarker980"/> open source CM system that allows users to automate the deployment, configuration, and maintenance of IT systems. It was founded by Mark Burgess in 1993 and has since become a popular tool for managing large-scale IT infrastructures. CFEngine is known for its powerful and flexible language for describing system configurations and enforcing policies, making it a great choice for complex <span class="No-Break">IT environments.</span></p>
<p>CFEngine’s first release was in 1994, making it one of the oldest CM tools in existence. Since then, CFEngine has undergone numerous updates and improvements to keep up with changing IT environments and emerging technologies. The latest release of CFEngine, version 3.18, includes features such as improved encryption, enhanced monitoring capabilities, and better support for <span class="No-Break">cloud infrastructure.</span></p>
<p>CFEngine has gained popularity over the years due to its robust functionality, ease of use, and strong community support. It’s still being used today by many organizations and is actively developed, so it is a safe option to manage the configuration of your servers using <span class="No-Break">this tool.</span></p>
<p>An<a id="_idIndexMarker981"/> example CFengine configuration will be presented here. It is, out of necessity, only a snipped and not a <span class="No-Break">complete configuration:</span></p>
<pre class="source-code">
##############################################################
# cf.main - for master infrastructure server
##################################################################
###
# BEGIN cf.main
###
control:
   access    = ( root )        # Only root should run this
   site      = ( main )
   domain    = ( example.com )
   sysadm    = ( admin@example.com )
   repository = ( /var/spool/cfengine )
   netmask   = ( 255.255.255.0 )
   timezone  = ( CET )
#################################################################
files:
  Prepare::
      /etc/motd              m=0644 r=0 o=root act=touch</pre>
<p>In this<a id="_idIndexMarker982"/> section, we have explained what CaC is and why it is an important tool in the toolbelt of system administrators. We have briefly described the most popular tools available to you. In the next section, we will introduce our t<a id="_idTextAnchor337"/>ool <span class="No-Break">of choice—Ansible.</span></p>
<h1 id="_idParaDest-232">Ansible</h1>
<p>In this section, we<a id="_idIndexMarker983"/> are going to introduce you to <strong class="bold">Ansible</strong>, our tool of choice when it comes <span class="No-Break">to CaC.</span></p>
<p>Ansible is a tool written for managing the configuration of systems and devices. It is written in Python and its source code is freely available to anyone for downloading and modification (within the limits of its license, which is Apache License <strong class="source-inline">2.0</strong>). The name “Ansible” comes from Ursula K. Le Guin’s book <em class="italic">Rocannon’s World</em> and denotes a device that allows instantaneous communication no matter <span class="No-Break">the distance.</span></p>
<p>Some interesting<a id="_idIndexMarker984"/> characteristics of Ansible are set <span class="No-Break">out here:</span></p>
<ul>
<li><strong class="bold">Modularity</strong>: Ansible is not a monolithic tool. Rather, it’s a core program with each task it knows how to perform written as a separate module—a library, if you will. Since this was the design from the start, it produced a clean API that anyone can use to write their <span class="No-Break">own modules.</span></li>
<li><strong class="bold">Idempotence</strong>: No matter how many times you perform a configuration, the result is always the same. This is one of the most important and fundamental characteristics of Ansible. You don’t have to know which actions have been performed. When you extend the configuration and run the tool again, it is its job to find out the state of the system and only apply <span class="No-Break">new actions.</span></li>
<li><strong class="bold">Agentlessness</strong>: Ansible doesn’t install its agent on the configured system. That is not to say it doesn’t need anything at all. To execute the Ansible scripts, the target system will need some means of connecting to it (most often, the SSH server running) and the Python language installed. There are several advantages born from this paradigm, including <span class="No-Break">the following:</span><ul><li>Ansible is not concerned with communication protocol. It uses SSH, but it doesn’t implement it, leaving the details to the operating system, SSH server, and client. An advantage is that you can freely swap one SSH solution with another for whatever reasons, and your Ansible playbooks should work as intended. Also, Ansible doesn’t concern itself with securing the SSH configuration. This leaves developers to concentrate on what the system is really about: configuring <span class="No-Break">your systems.</span></li><li>The Ansible project does not need to develop and maintain separate programs for managed nodes. This not only frees developers from unneeded burdens but also limits the possibility of security exploits being discovered and used against <span class="No-Break">target machines.</span></li><li>In an <a id="_idIndexMarker985"/>agent-utilizing solution, if, for any reason, the agent program stops working, there is no way to deliver new configurations to the system. SSH servers are usually very widely used, and the probability of failure <span class="No-Break">is negligible.</span></li><li>Using SSH as the communication protocol lowers the risk of a firewall blocking the communication port for the <span class="No-Break">CM system.</span></li></ul></li>
<li><strong class="bold">Declarativeness</strong>: A person writing Ansible playbooks shouldn’t trouble themselves much with how things should be done, just what the desired state of the system is after Ansible is done. For example, if the sysop wants Ansible to ensure that <strong class="source-inline">nginx</strong> is installed, the proper configuration entry would look <span class="No-Break">like this:</span><pre class="source-code">
- name: install nginx</pre><pre class="source-code">
  package:</pre><pre class="source-code">
    name: nginx</pre><pre class="source-code">
    state: present</pre></li>
</ul>
<p>The main way of working with Ansible is through writing configuration files in a special syntax called YAML. <strong class="bold">YAML</strong> is <a id="_idIndexMarker986"/>a syntax created specifically for configuration files and is loosely based on Python formatting. Indentations play a significant role in YAML files. YAML’s home page presents a full cheat sheet card (<a href="https://yaml.org/refcard.xhtml">https://yaml.org/refcard.xhtml</a>) for the syntax. However, the most important parts are presented here, as we will be working mostly with those files in <span class="No-Break">this chapter:</span></p>
<ul>
<li>They are clear text files. This means they can be viewed and edited using the simplest editors such as Notepad, Vim, Emacs, or whatever is your favorite tool for working with <span class="No-Break">text files.</span></li>
<li>Indentations <a id="_idIndexMarker987"/>are used to denote scope. Tabulators are not permitted for indentations and it is customary to use spaces for <span class="No-Break">this purpose.</span></li>
<li>A new document opens with three hyphens (<strong class="source-inline">-</strong>). One file can have more than <span class="No-Break">one document.</span></li>
<li>Comments, as in Python, start with a hash (<strong class="source-inline">#</strong>) and continue until the end of the line. The comment must be surrounded by whitespace characters; otherwise, it will be treated as a literal hash (<strong class="source-inline">#</strong>) within <span class="No-Break">a text.</span></li>
<li>Text (strings) can be unquoted, single-quoted (<strong class="source-inline">'</strong>), or <span class="No-Break">double-quoted (</span><span class="No-Break"><strong class="source-inline">"</strong></span><span class="No-Break">).</span></li>
<li>When a list is specified, each member is denoted by a hyphen (<strong class="source-inline">-</strong>) character. Each item will be on a separate line. If single-line representation is required, the list items can be enclosed in square brackets (<strong class="source-inline">[]</strong>) with entries separated by <span class="No-Break">commas (</span><span class="No-Break"><strong class="source-inline">,</strong></span><span class="No-Break">).</span></li>
<li>Associative arrays are represented by a key-value pair with each key separated from the value by a colon and space. If they have to be presented in one line, the array is enclosed in curly brackets (<strong class="source-inline">{}</strong>) and pairs are separated by <span class="No-Break">commas (</span><span class="No-Break"><strong class="source-inline">,</strong></span><span class="No-Break">).</span></li>
</ul>
<p>If the preceding rules are not very transparent now, don’t panic. We are going to write proper Ansible configuration files, and things will become clear as <span class="No-Break">we go.</span></p>
<p>Ansible divides machines<a id="_idIndexMarker988"/> into two groups: the <strong class="bold">control node</strong> is the computer that stores configuration directives and will connect to the target machines and configure them. There can be more than one<a id="_idIndexMarker989"/> control node. The target machines are<a id="_idIndexMarker990"/> called <strong class="bold">inventories</strong>. Ansible runs actions against computers in the inventory listed. Inventories are often written in an <strong class="bold">initialization</strong> (<strong class="bold">INI</strong>) format, which<a id="_idIndexMarker991"/> is simple and easy to follow, as <span class="No-Break">explained here:</span></p>
<ul>
<li>Comments start with a <span class="No-Break">semicolon (</span><span class="No-Break"><strong class="source-inline">;</strong></span><span class="No-Break">)</span></li>
<li>Sections are named and the names are enclosed in square <span class="No-Break">brackets (</span><span class="No-Break"><strong class="source-inline">[]</strong></span><span class="No-Break">)</span></li>
<li>Configuration directives are stored in pairs, each pair on its own line, with the key and value separated by an equals <span class="No-Break">sign (</span><span class="No-Break"><strong class="source-inline">=</strong></span><span class="No-Break">)</span></li>
</ul>
<p>We will see an<a id="_idIndexMarker992"/> example of an inventory file shortly. There is, however, the possibility of having so-called dynamic inventories, which are generated automatically by means of a script or a system with each run <span class="No-Break">of Ansible.</span></p>
<p>The main configuration file that we will be interacting with is called a playbook. A <strong class="bold">playbook</strong> is <a id="_idIndexMarker993"/>an <a id="_idIndexMarker994"/>entry point for Ansible. This is where the tool will start the execution. Playbooks can include other files (and this is <span class="No-Break">often done).</span></p>
<p>Target hosts can be broken down into groups based on custom criteria: operating system, role within organization, physical location—whatever is required. The groups are<a id="_idIndexMarker995"/> <span class="No-Break">called </span><span class="No-Break"><strong class="bold">roles</strong></span><span class="No-Break">.</span></p>
<p>A single <a id="_idIndexMarker996"/>action that <a id="_idTextAnchor338"/>is to be performed is called <span class="No-Break">a </span><span class="No-Break"><strong class="bold">task</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-233"><a id="_idTextAnchor339"/>Basics of using Ansible</h2>
<p>The first <a id="_idIndexMarker997"/>thing to do is to install Ansible. This is pretty straightforward on all major Linux distributions and can be equally so on macOS. We encourage<a id="_idIndexMarker998"/> you to figure out the solution for your chosen <span class="No-Break">operating system.</span></p>
<p>For Debian-based distributions, the following command <span class="No-Break">should suffice:</span></p>
<pre class="console">
$ sudo apt-get install ansible</pre>
<p>For Fedora Linux distributions, you’d run the <span class="No-Break">following command:</span></p>
<pre class="console">
$ sudo dnf install ansible</pre>
<p>To install the latest version of Ansible, however, we recommend using the Python virtual environment and its <strong class="source-inline">pip</strong> tool, <span class="No-Break">like so:</span></p>
<pre class="console">
$ python3 -m venv venv</pre>
<p>In the preceding code, we have activated the virtual environment using the <strong class="source-inline">venv python3</strong> module. It will create a special <strong class="source-inline">venv</strong> directory that contains all important files and libraries that allow us to set up a Python virtual environment. Next, we have <span class="No-Break">the following:</span></p>
<pre class="console">
$ source venv/bin/activate</pre>
<p>In the <a id="_idIndexMarker999"/>preceding code line, we have read a special file that sets the environment by configuring the shell. Next, we <span class="No-Break">have this:</span></p>
<pre class="console">
$ pip install -U pip
Requirement already satisfied: pip in ./venv/lib/python3.11/site-packages (22.3.1)
Collecting pip
  Using cached pip-23.0.1-py3-none-any.whl (2.1 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 22.3.1
    Uninstalling pip-22.3.1:
      Successfully uninstalled pip-22.3.1
Successfully installed pip-23.0.1</pre>
<p>In the preceding <a id="_idIndexMarker1000"/>code, we have upgraded <strong class="source-inline">pip</strong>, a Python package installer. In the next step, we are going to actually install Ansible, also using <strong class="source-inline">pip</strong>. The output will be shortened <span class="No-Break">for brevity:</span></p>
<pre class="console">
$ pip install ansible
Collecting ansible
  Using cached ansible-7.3.0-py3-none-any.whl (43.1 MB)
Collecting ansible-core~=2.14.3
Installing collected packages: resolvelib, PyYAML, pycparser, packaging, MarkupSafe, jinja2, cffi, cryptography, ansible-core, ansible
Successfully installed MarkupSafe-2.1.2 PyYAML-6.0 ansible-7.3.0 ansible-core-2.14.3 cffi-1.15.1 cryptography-39.0.2 jinja2-3.1.2 packaging-23.0 pycparser-2.21 resolvelib-0.8.1</pre>
<p>As you can see in the preceding code, <strong class="source-inline">pip</strong> informs us that Ansible and its dependencies were <span class="No-Break">installed successfully.</span></p>
<p>Either of those ways of installing Ansible will download and install all the packages required to run Ansible on <span class="No-Break">your computer.</span></p>
<p>The <a id="_idIndexMarker1001"/>simplest command you can run is called ad hoc <strong class="source-inline">ping</strong>. It’s so basic that it is one of the most prevalent first uses of Ansible in tutorials and books. We are not going to deviate from it. The following command tries to connect to a specified host and then prints the result of <span class="No-Break">the trial:</span></p>
<pre class="console">
$ ansible all -m ping -i inventory
hostone | SUCCESS =&gt; {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
    },
    "changed": false,
    "ping": "pong"
}</pre>
<p>In the preceding command, we have told Ansible to run against all hosts in inventory, use the <strong class="source-inline">ping</strong> module (<strong class="source-inline">-m ping</strong>), and use an inventory file named <strong class="source-inline">inventory</strong> (<strong class="source-inline">-i inventory</strong>). If you don’t specify the inventory file, Ansible will try to use <strong class="source-inline">/etc/ansible/hosts</strong>, which is generally a <span class="No-Break">bad idea.</span></p>
<p>We will delve into the inventory file in a moment, a few <span class="No-Break">paragraphs ahead.</span></p>
<p>A <strong class="bold">module</strong> is a <a id="_idIndexMarker1002"/>small Python library written for Ansible and should ideally map 1:1 with a command. In the preceding example, we run the <strong class="source-inline">ping</strong> module (which we can also understand as a <strong class="source-inline">ping</strong> command). It is not, however, the same as the OS <strong class="source-inline">ping</strong> command, which sends a specially crafted network packet to determine whether a host is up. The Ansible <strong class="source-inline">ping</strong> command will also try to log in, to determine whether the credentials <span class="No-Break">are correct.</span></p>
<p>By default, Ansible uses the SSH protocol with a private-public key pair. In a normal operation, you don’t want to use password-based authentication, and Ansible will choose a <span class="No-Break">key-based one.</span></p>
<p>Ansible is <a id="_idIndexMarker1003"/>very good at providing self-explanatory information as a result of the execution. The preceding output tells us that Ansible was able to connect to all nodes in the inventory (there’s only one), <strong class="source-inline">python3</strong> is installed there, and nothing <span class="No-Break">was changed.</span></p>
<p>The inventory file is a simple but powerful tool to list, group, and provide variables for managed nodes. Our example inventory file is pasted <span class="No-Break">as follows:</span></p>
<pre class="source-code">
[www]
hostone ansible_host=192.168.1.2  ansible_ssh_private_key_file=~/.ssh/hostone.pem  ansible_user=admin</pre>
<p>The preceding code is two lines. The first one declares a group of nodes called <strong class="source-inline">www</strong>. The second declares a node called <strong class="source-inline">hostone</strong>. Since this is not a name resolvable by DNS, we have declared its IP address using the <strong class="source-inline">ansible_host</strong> variable. Then, we point to the proper <strong class="source-inline">ssh</strong> key file and declare which username should be used while logging in (<strong class="source-inline">admin</strong>). There are more things we can define in this file. Very detailed information about writing your inventory file can be found in the Ansible project <span class="No-Break">documentation (</span><a href="https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.xhtml"><span class="No-Break">https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.xhtml</span></a><span class="No-Break">).</span></p>
<p>We are unable to cover all aspects of Ansible and dig deeper into most of the features that we are going to use here. Packt Publishing, however, has a very good selection of books on Ansible that you may wish to choose if you want to deepen your knowledge—for example, <em class="italic">Mastering Ansible, Fourth <a id="_idTextAnchor340"/>Edition,</em> by James Freeman and <span class="No-Break">Jesse Keating.</span></p>
<h2 id="_idParaDest-234"><a id="_idTextAnchor341"/>Tasks</h2>
<p>Tasks lie at<a id="_idIndexMarker1004"/> the heart of the Ansible configuration. They are exactly that: tasks to be run against managed nodes. Tasks are contained in plays. They can be placed there directly (put into a playbook) or indirectly (included via <span class="No-Break">a role).</span></p>
<p>There’s a special type of <a id="_idIndexMarker1005"/>task called <strong class="bold">handles</strong>. This is a task that will be<a id="_idTextAnchor342"/> executed only when notified by <span class="No-Break">another task.</span></p>
<h2 id="_idParaDest-235"><a id="_idTextAnchor343"/>Roles</h2>
<p>Ansible’s <a id="_idIndexMarker1006"/>documentation defines <strong class="bold">roles</strong> as “<em class="italic">A limited distribution of reusable Ansible content (tasks, handlers, variables, plugins, templates and files) for use inside of a play.</em>” For our purpose, we can think of them as a mechanism to group parts of the play. A role can be a type of host we are going to run the play against: web server, database server, Kubernetes node, and so on. By breaking down playbooks into roles, we can manage separate required tasks more easily and efficiently. Not to mention the files containing those become more readable, since we limit the number of <a id="_idTextAnchor344"/>tasks within and group them by <span class="No-Break">their function.</span></p>
<h2 id="_idParaDest-236"><a id="_idTextAnchor345"/>Plays and playbooks</h2>
<p><strong class="bold">Plays</strong> are <a id="_idIndexMarker1007"/>the context in which tasks are performed. While plays are somewhat of an ephemeral concept, <strong class="bold">playbooks</strong> are <a id="_idIndexMarker1008"/>their physical representations: YAML files in which plays <span class="No-Break">are defined.</span></p>
<p>Let’s look at an example of a playbook. The following playbook will install <strong class="source-inline">nginx</strong> and <strong class="source-inline">php</strong> packages on a <span class="No-Break">managed node:</span></p>
<pre class="source-code">
---
- name: Install nginx  and php
  hosts: www
  become: yes
  tasks:
  - name: Install nginx
    package:
      name: nginx
      state: present
  - name: Install php
    package:
      name: php8
      state: present
  - name: Start nginx
    service:
      name: nginx
      state: started</pre>
<p>The<a id="_idIndexMarker1009"/> first line (three dashes) marks the beginning of a new YAML document. The next line names the whole playbook. Playbook names should be short but descriptive. They are going to end up in logs and <span class="No-Break">debugging information.</span></p>
<p>Next, we inform Ansible that this play should be run against nodes in the inventory placed in the <strong class="source-inline">www</strong> group. We also tell Ansible to use <strong class="source-inline">sudo</strong> when executing the commands. This is required as all distributions that we cover in our guide require root privileges to install and <span class="No-Break">remove packages.</span></p>
<p>Then, we start the <strong class="source-inline">tasks</strong> section. Each task is given a name, the name of the module (command) we are going to use, and the command is given options and arguments. As you can see, the indentation declares the scope. If you are familiar with the Python programming language, this should be intuitive <span class="No-Break">for you.</span></p>
<p>Before we run this playbook, let’s use a very useful <span class="No-Break">tool, </span><span class="No-Break"><strong class="source-inline">ansible-lint</strong></span><span class="No-Break">:</span></p>
<pre class="console">
$ ansible-lint install.yaml
WARNING: PATH altered to expand ~ in it. Read https://stackoverflow.com/a/44704799/99834 and correct your system configuration.
WARNING  Listing 9 violation(s) that are fatal
yaml[trailing-spaces]: Trailing spaces
install.yaml:1
yaml[truthy]: Truthy value should be one of [false, true]
install.yaml:4
fqcn[action-core]: Use FQCN for builtin module actions (package).
install.yaml:6 Use `ansible.builtin.package` or `ansible.legacy.package` instead.
[...]
yaml[empty-lines]: Too many blank lines (1 &gt; 0)
install.yaml:18
Read documentation for instructions on how to ignore specific rule violations.
                   Rule Violation Summary
 count tag                   profile    rule associated tags
     1 yaml[empty-lines]     basic      formatting, yaml
     1 yaml[indentation]     basic      formatting, yaml
     3 yaml[trailing-spaces] basic      formatting, yaml
     1 yaml[truthy]          basic      formatting, yaml
     3 fqcn[action-core]     production formatting
Failed after min profile: 9 failure(s), 0 warning(s) on 1 files.</pre>
<p>I have cut <a id="_idIndexMarker1010"/>part of the output for brevity, but you can see that the tool printed information about violations of YAML syntax and Ansible best practices. Failures are types of errors that will stop the execution of the playbook. Warnings are just that: the playbook will be executed, but there are some errors that go against best practices. Let’s correct our playbook, <span class="No-Break">as follows:</span></p>
<pre class="source-code">
---
- name: Install nginx  and php
  hosts: www
  become: true
  tasks:
    - name: Install nginx
      ansible.builtin.package:
        name: nginx
        state: present
    - name: Install php
      ansible.builtin.package:
        name: php8
        state: present
    - name: Start nginx
      ansible.builtin.service:
        name: nginx
        state: started</pre>
<p>We can <a id="_idIndexMarker1011"/>now run the playbook using the <span class="No-Break"><strong class="source-inline">ansible-playbook</strong></span><span class="No-Break"> command:</span></p>
<pre class="console">
$ ansible-playbook -i inventory install.yaml
PLAY [Install nginx  and php] ********************************************************************
TASK [Gathering Facts] ********************************************************************
ok: [hostone]
TASK [Install nginx] ********************************************************************
changed: [hostone]
TASK [Install php] ********************************************************************
fatal: [hostone]: FAILED! =&gt; {"changed": false, "msg": "No package matching 'php8' is available"}
PLAY RECAP ********************************************************************
hostone     : ok=2    changed=1   reachable=0    failed=1    skipped=0    rescued=0    ignored=0</pre>
<p>In the<a id="_idIndexMarker1012"/> preceding output, we have instructed the <strong class="source-inline">ansible-playbook</strong> command to use an inventory file called <strong class="source-inline">inventory</strong> and run a playbook named <strong class="source-inline">install.yaml</strong>. The output should be self-explanatory: we are informed of the name of the play we run. Then, we see a list of managed nodes that Ansible will try to execute action against. Then, we see tasks and a list of nodes that the tasks succeeded or failed at. The <strong class="source-inline">nginx</strong> task was a success on <strong class="source-inline">hostone</strong>. However, installing <strong class="source-inline">php</strong> failed. Ansible gives us the exact reason for it: there is no <strong class="source-inline">php8</strong> package available for our managed node. Sometimes, a resolution is pretty obvious, but sometimes it requires a bit of digging around. After checking with our distribution, we find out that the actual <strong class="source-inline">php</strong> package available there is <strong class="source-inline">php7.4</strong>. After quickly correcting the offending line, we run the playbook again, <span class="No-Break">as follows:</span></p>
<pre class="console">
$ ansible-playbook -i inventory install.yaml
PLAY [Install nginx  and php] ********************************************************************
TASK [Gathering Facts] ********************************************************************
ok: [hostone]
TASK [Install nginx] ********************************************************************
ok: [hostone]
TASK [Install php] ********************************************************************
changed: [hostone]
TASK [Start nginx] ********************************************************************
ok: [hostone]
PLAY RECAP ********************************************************************
hostone                    : ok=4    changed=1    unreachable=0   failed=0    skipped=0    rescued=0    ignored=0</pre>
<p>Notice the change in the output. First, Ansible tells us that <strong class="source-inline">nginx</strong> on <strong class="source-inline">hostone</strong> is okay. This means that Ansible was able to determine that the package was already installed, and it took no action. Then, it told us that the <strong class="source-inline">php7.4</strong> installation was successful (<strong class="source-inline">changed: [hostone]</strong>) on the <span class="No-Break"><strong class="source-inline">hostone</strong></span><span class="No-Break"> server.</span></p>
<p>The preceding<a id="_idIndexMarker1013"/> playbook is short, but we hope it demonstrates the usefulness of the tool. Playbooks are executed in a linear manner, from top <span class="No-Break">to bottom.</span></p>
<p>There’s one problem with our playbook. While it only installs two packages, you may be worried about maintainability and readability if you need to install tens or hundreds of packages. Having a separate task for each of them is troublesome. There’s a solution. You can create a list of items that a given task will be executed for—something akin to a loop. Let’s edit the <strong class="source-inline">tasks</strong> part of the playbook, <span class="No-Break">as follows:</span></p>
<pre class="source-code">
  tasks:
    - name: Install nginx
      ansible.builtin.package:
        name: '{{ item }}'
        state: present
      with_items:
        - nginx
        - php7.4
       - gcc
       - g++
    - name: Start nginx
      ansible.builtin.service:
        name: nginx
        state: started</pre>
<p>We have added two packages to demonstrate a more complete run. Notice the lack of a separate task <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">php7.4</strong></span><span class="No-Break">.</span></p>
<p>Before running this play, it is always a good idea to check it with <strong class="source-inline">ansible-lint</strong>. Here’s how we can <span class="No-Break">do that:</span></p>
<pre class="console">
$ ansible-lint install.yaml
Passed with production profile: 0 failure(s), 0 warning(s) on 1 files.</pre>
<p>Now, after <strong class="source-inline">ansible-lint</strong> gives us <a id="_idIndexMarker1014"/>the green light, let’s play <span class="No-Break">this playbook:</span></p>
<pre class="console">
$ ansible-playbook -i inventory install.yaml
PLAY [Install nginx  and php] ********************************************************************
TASK [Gathering Facts] ********************************************************************
ok: [hostone]
TASK [Install nginx] ********************************************************************
ok: [hostone] =&gt; (item=nginx)
ok: [hostone] =&gt; (item=php7.4)
changed: [hostone] =&gt; (item=gcc)
changed: [hostone] =&gt; (item=g++)
TASK [Start nginx] ********************************************************************
ok: [hostone]
PLAY RECAP ********************************************************************
hostone            : ok=3    changed=1    unreachable=0   failed=0    skipped=0    rescued=0    ignored=0</pre>
<p>Assume we<a id="_idIndexMarker1015"/> want to install a page configuration in <strong class="source-inline">nginx</strong>. Ansible is able to copy files. We can set it to copy <strong class="source-inline">nginx</strong> virtual server configuration, but we only want to restart <strong class="source-inline">nginx</strong> once: at the <span class="No-Break">service setup.</span></p>
<p>We can do it via <strong class="source-inline">notify</strong> and <strong class="source-inline">handlers</strong>. I’ll paste the whole <span class="No-Break">playbook ahead:</span></p>
<pre class="source-code">
---
- name: Install nginx  and php
  hosts: www
  become: true
  tasks:
    - name: Install nginx
      ansible.builtin.package:
        name: '{{ item }}'
        state: present
      with_items:
        - nginx
        - php7.4
        - gcc
        - g++
      notify:
        - Start nginx
    - name: Copy service configuration
      ansible.builtin.copy:
        src: "files/service.cfg"
        dest: "/etc/nginx/sites-available/service.cfg"
        owner: root
        group: root
        mode: '0640'
    - name: Enable site
      ansible.builtin.file:
        src: "/etc/nginx/sites-available/service.cfg"
        dest: "/etc/nginx/sites-enabled/default"
        state: link
      notify:
        - Restart nginx
  handlers:
    - name: Start nginx
      ansible.builtin.service:
        name: nginx
        state: started
    - name: Restart nginx
      ansible.builtin.service:
        name: nginx
        state: restarted</pre>
<p>Notice the whole <a id="_idIndexMarker1016"/>new section related to copying files. We also create a <strong class="bold">symlink</strong> (an alias to a file) so that the site is enabled. The preceding example is incomplete. It takes more than that to actually set up a virtual server with <strong class="source-inline">nginx</strong>. We have shortened it for brevity’s sake and only to demonstrate <span class="No-Break">a principle.</span></p>
<p>The execution of this play yields the <span class="No-Break">following output:</span></p>
<pre class="console">
$ ansible-playbook -i inventory install.yaml
PLAY [Install nginx  and php] ********************************************************************
TASK [Gathering Facts] ********************************************************************
ok: [hostone]
TASK [Install nginx] ********************************************************************
ok: [hostone] =&gt; (item=nginx)
ok: [hostone] =&gt; (item=php7.4)
ok: [hostone] =&gt; (item=gcc)
ok: [hostone] =&gt; (item=g++)
TASK [Copy service configuration] ********************************************************************
ok: [hostone]
TASK [Enable site] ********************************************************************
ok: [hostone]
PLAY RECAP ********************************************************************
hostone                     ok=4    changed=0    unreachable=0   failed=0    skipped=0    rescued=0    ignored=0</pre>
<p>As soon as you <a id="_idIndexMarker1017"/>start using Ansible in a real production environment, it becomes obvious that even with the <em class="italic">looping</em> technique we demonstrated previously, the playbook grows pretty fast and becomes unwieldy. Thankfully, there’s a way to break the playbook into <span class="No-Break">smaller files.</span></p>
<p>One of the ways to do it is to segregate tasks into roles. As mentioned earlier, a role is a bit of an abstract concept, so the easiest way to think about it is to consider it a group. You group tasks depending on the criteria that are relevant to you. While the criteria are totally up to you, it is pretty common for roles to refer to the type of function a given managed node performs. One managed node can perform more than one function, but it still is probably wise to separate the functions into their own roles. Thus, the HTTP server would be one role, the database server would be another, and the file server would be <span class="No-Break">yet another.</span></p>
<p>Roles in Ansible have a predetermined directory structure. There are eight standard directories defined, although you only need to <span class="No-Break">create one.</span></p>
<p>The following code is copied from the Ansible <span class="No-Break">documentation (</span><a href="https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_reuse_roles.xhtml"><span class="No-Break">https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_reuse_roles.xhtml</span></a><span class="No-Break">):</span></p>
<pre class="source-code">
roles/
    common/               # this hierarchy represents a "role"
        tasks/            #
            main.yml      #  &lt;-- tasks file can include smaller files if warranted
        handlers/         #
            main.yml      #  &lt;-- handlers file
        templates/        #  &lt;-- files for use with the template resource
            ntp.conf.j2   #  &lt;------- templates end in .j2
        files/            #
            bar.txt       #  &lt;-- files for use with the copy resource
            foo.sh        #  &lt;-- script files for use with the script resource
        vars/             #
            main.yml      #  &lt;-- variables associated with this role
        defaults/         #
            main.yml      #  &lt;-- default lower priority variables for this role
        meta/             #
            main.yml      #  &lt;-- role dependencies
        library/          # roles can also include custom modules
        module_utils/     # roles can also include custom module_utils
        lookup_plugins/   # or other types of plugins, like lookup in this case</pre>
<p>The <strong class="source-inline">roles</strong> directory<a id="_idIndexMarker1018"/> exists on the same level as your playbook. The most common subdirectories you will probably see are <strong class="source-inline">tasks</strong>, <strong class="source-inline">templates</strong>, <strong class="source-inline">files</strong>, <strong class="source-inline">vars</strong>, and <strong class="source-inline">handlers</strong>. Within each subdirectory, Ansible will look for a <strong class="source-inline">main.yml</strong>, <strong class="source-inline">main.yaml</strong>, or <strong class="source-inline">main</strong> file (all of them have to be valid YAML files). Their contents will be automatically available to the playbook. So, how would this work in practice? Within the same directory that our <strong class="source-inline">install.yaml</strong> playbook exists, we will create a <strong class="source-inline">roles</strong> directory. Within this directory, we will create another one: <strong class="source-inline">www</strong>. Inside that one, we will create directories: <strong class="source-inline">tasks</strong>, <strong class="source-inline">files</strong>, and <strong class="source-inline">handlers</strong>. A similar structure will be created with <strong class="source-inline">development</strong> as <span class="No-Break">a role:</span></p>
<pre class="source-code">
roles/
    www/               # this hierarchy represents a "role"
        tasks/            #
            main.yml      #  &lt;-- tasks file can include smaller files if warranted
        handlers/         #
            main.yml      #  &lt;-- handlers file
        files/            #
            service.cfg       #  &lt;-- files for use with the copy resource
    development/               # this hierarchy represents a "role"
        tasks/            #
            main.yml      #  &lt;-- tasks file can include smaller files if warranted</pre>
<p>The <strong class="source-inline">development</strong> role has only tasks subdirectory because we don’t require any additional bells and<a id="_idIndexMarker1019"/> whistles. Why the development role, though? When you look back at our current playbook, you’ll notice that we mix up installing things for the <strong class="source-inline">www</strong> server and development packages—namely, compilers. It is bad practice, even if they will end up on the same <span class="No-Break">physical server.</span></p>
<p>Thus, we are going to edit our inventory file so that we have two <span class="No-Break">separate roles:</span></p>
<pre class="source-code">
[www]
hostone ansible_host=192.168.1.2  ansible_ssh_private_key_file=~/.ssh/hostone.pem  ansible_user=admin
[development]
hostone ansible_host=192.168.1.3  ansible_ssh_private_key_file=~/.ssh/hostone.pem  ansible_user=admin</pre>
<p>Both groups contain only one node, which is a bad thing to do overall. We do it only for the purpose of this guide. Don’t install compilers and development software on your HTTP server, especially on the <span class="No-Break">production one.</span></p>
<p>Now, we have to move some stuff around within the playbook. The <strong class="source-inline">install.yml</strong> file will become much shorter, as we can <span class="No-Break">see here:</span></p>
<pre class="source-code">
---
- name: Install nginx and php
  hosts: www
  roles:
    - www
  become: true
- name: Install development packages
  hosts: development
  roles:
    - development
  become: true</pre>
<p>We actually have two plays in this playbook. One of them is for <strong class="source-inline">www</strong> hosts, and the other is for <strong class="source-inline">development</strong> hosts. After we give the play a name and list host groups that we wish it to run against, we use keyword roles and list actual roles to be used. As you can see, Ansible is going to locate the proper roles automatically, as long as you adhere to the <a id="_idIndexMarker1020"/>directory structure explained previously. There are ways to include roles directly by specifying their full path, but we’re not going to cover <span class="No-Break">them here.</span></p>
<p>Now, for the <strong class="source-inline">www</strong> role, we’ll execute the <span class="No-Break">following code:</span></p>
<pre class="source-code">
---
- name: Install nginx
  ansible.builtin.package:
    name: '{{ item }}'
    state: present
  with_items:
    - nginx
    - php7.4
  notify:
    - Start nginx
- name: Copy service configuration
  ansible.builtin.copy:
    src: "files/service.cfg"
    dest: "/etc/nginx/sites-available/service.cfg"
    owner: root
    group: root
    mode: '0640'
- name: Enable site
  ansible.builtin.file:
    src: "/etc/nginx/sites-available/service.cfg"
    dest: "/etc/nginx/sites-enabled/default"
    state: link
  notify:
    - Restart nginx</pre>
<p>You <a id="_idIndexMarker1021"/>should notice several changes from <span class="No-Break">the get-go:</span></p>
<ul>
<li>There is no <strong class="source-inline">tasks</strong> keyword in this document. This is implicit by the fact that this is the <strong class="source-inline">main.yaml</strong> file within the <span class="No-Break"><strong class="source-inline">tasks</strong></span><span class="No-Break"> subdirectory.</span></li>
<li>Indentation has been <span class="No-Break">moved left.</span></li>
<li>There are no <span class="No-Break">handlers here.</span></li>
<li>We have removed the installation of the <strong class="source-inline">gcc</strong> and <span class="No-Break"><strong class="source-inline">g++</strong></span><span class="No-Break"> packages.</span></li>
</ul>
<p>Let’s now see <span class="No-Break">the handlers:</span></p>
<pre class="source-code">
---
- name: Start nginx
  ansible.builtin.service:
    name: nginx
    state: started
  listen: "Start nginx"
- name: Restart nginx
  ansible.builtin.service:
    name: nginx
    state: restarted
  listen: "Restart nginx"</pre>
<p>The overall changes are the same, as <span class="No-Break">noted here:</span></p>
<ul>
<li>We have removed the <span class="No-Break"><strong class="source-inline">handlers</strong></span><span class="No-Break"> keyword</span></li>
<li>We have moved the indentation to <span class="No-Break">the left</span></li>
</ul>
<p>Now, let’s <span class="No-Break">see </span><span class="No-Break"><strong class="source-inline">roles/development/tasks/main.yaml</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
---
- name: Install compilers
  ansible.builtin.package:
    name: '{{ item }}'
    state: present
  with_items:
    - gcc
    - g++</pre>
<p>This is very<a id="_idIndexMarker1022"/> simple. We may have increased the complexity of the directory structure, but we have gained the simplicity of tasks and plays. The gains are well worth the trade-off, especially when your playbooks grow in size <span class="No-Break">and complexity.</span></p>
<p>There are many<a id="_idIndexMarker1023"/> advantages to using a CaC tool, as <span class="No-Break">outlined here:</span></p>
<ul>
<li>Configuration can be linted—that is, checked for syntax errors by <span class="No-Break">automation tools</span></li>
<li>It can be applied infinitely with the <span class="No-Break">same outcomes</span></li>
<li>It can be run on many systems <span class="No-Break">in parallel</span></li>
<li>It can be kept in a version control system, such as Git, where the history of changes and comments for them are stored and can be viewed at <span class="No-Break">any time</span></li>
<li>It can be run by automation tools, removing the need for a human factor besides <span class="No-Break">writing playbooks</span></li>
</ul>
<p>In this <a id="_idIndexMarker1024"/>subsection, we <a id="_idIndexMarker1025"/>have shown how to write simple Ansible playbooks. We have explained what Ansible is and what the building blocks of the configuration scripts are. We have introduced playbooks, roles, and the inventory. There are many more things Ansible can do for you. You can manage devices, filesystems, users, groups, permissions, networking, and so on. The list of all modules Ansible is shipped with out of the box is impressive. You can always check the list at <a href="https://docs.ansible.com/ansible/latest/module_plugin_guide/index.xhtml">https://docs.ansible.com/ansible/latest/module_plugin_guide/index.xhtml</a>. Remember to check the list for your version <span class="No-Break">of Ansible.</span></p>
<p>So, now that we’ve covered installing, configuring, and using Ansible to manage your servers (installing software, creating configuration files, and managing services), we are ready to look into Ansible Galaxy<a id="_idTextAnchor346"/>: community-developed modules that increase <span class="No-Break">Ansible’s usefulness.</span></p>
<h1 id="_idParaDest-237">Ansible Galaxy</h1>
<p>Ansible is a<a id="_idIndexMarker1026"/> powerful automation tool that enables users to configure, deploy, and manage complex IT infrastructures with ease. However, creating and maintaining Ansible playbooks can be time-consuming, especially when working with large-scale environments. Fortunately, Ansible Galaxy exists to help streamline this process by providing a centralized repository of pre-built roles and playbooks that can be easily integrated into an existing <span class="No-Break">Ansible project.</span></p>
<p><strong class="bold">Ansible Galaxy</strong> is a <a id="_idIndexMarker1027"/>community-driven platform that hosts an extensive collection of Ansible roles and playbooks. These roles and playbooks are submitted by users from around the world and are reviewed and curated by Ansible’s maintainers. Ansible Galaxy provides a simple, efficient way to find and use pre-built automation content that can save users time and effort while ensuring quality <span class="No-Break">and consistency.</span></p>
<p>Using Ansible Galaxy, users can quickly find, download, and use pre-built roles and playbooks for popular applications, services, and infrastructure components. These pre-built components can help speed up deployment times, ensure best practices are followed, and<a id="_idIndexMarker1028"/> reduce the likelihood of errors or inconsistencies. Ansible Galaxy can also help users learn from others’ experiences and gain insights into the best practices of <span class="No-Break">their peers.</span></p>
<p>Let’s use one of the Galaxy roles to install the <strong class="source-inline">nginx</strong> web server on our <strong class="source-inline">webserver</strong> role. In order to do that, we will need to install the role from Ansible Galaxy. First, ensure that Ansible is installed on your system by running the <span class="No-Break">following command:</span></p>
<pre class="console">
admin@myhome:~$ ansible-galaxy install nginxinc.nginx</pre>
<p>This command will download and install the <strong class="source-inline">nginx</strong> role from Ansible Galaxy. By default, all roles installed are placed in the <strong class="source-inline">~/.ansible/roles</strong> directory. It’s possible to change that by creating a global Ansible configuration file in your home <span class="No-Break">directory: </span><span class="No-Break"><strong class="source-inline">~/.ansible.cfg</strong></span><span class="No-Break">.</span></p>
<p>An example of a configuration file changing the <strong class="source-inline">roles_path</strong> directory looks <span class="No-Break">like this:</span></p>
<pre class="source-code">
[defaults]
roles_path = /home/admin/myansibleroles</pre>
<p>A good practice is to pin role version numbers and put this version in a YAML file saved in the same Git repository where you will keep your Ansible playbooks. To achieve this, let’s create an <span class="No-Break"><strong class="source-inline">ansible_requirements.yml</strong></span><span class="No-Break"> file:</span></p>
<pre class="source-code">
---
- src: nginxinc.nginx
  version: 0.24.0</pre>
<p>To install the role from Ansible Galaxy using that file, you would run the <span class="No-Break">following command:</span></p>
<pre class="console">
admin@myhome:~$ ansible-galaxy install -r ansible_requirements.yml</pre>
<p>Once the role is installed, it can be used in an Ansible playbook by adding the following line to <span class="No-Break">the playbook:</span></p>
<pre class="source-code">
roles:
    - nginxinc.nginx</pre>
<p>Here’s an example <a id="_idIndexMarker1029"/>playbook that uses the <strong class="source-inline">nginx</strong> role from Ansible Galaxy to install and configure <strong class="source-inline">nginx</strong> on a <span class="No-Break">remote server:</span></p>
<pre class="source-code">
---
- name: Install and configure Nginx
  hosts: webservers
  become: true
  roles:
    - nginxinc.nginx
  vars:
    nginx_sites:
      myapp:
        template: "{{ playbook_dir }}/templates/myapp.conf.j2"</pre>
<p>In this playbook, we specify the <strong class="source-inline">webservers</strong> group as the target hosts and use the <strong class="source-inline">nginxinc.nginx</strong> role to install and configure <strong class="source-inline">nginx</strong>. We also define a variable called <strong class="source-inline">nginx_sites</strong> that specifies the configuration for a <strong class="source-inline">nginx</strong> server block that will be created using a Jinja2 template located in the playbook’s <span class="No-Break"><strong class="source-inline">templates</strong></span><span class="No-Break"> directory.</span></p>
<p>By using Ansible Galaxy and pre-built roles such as <strong class="source-inline">nginxinc.nginx</strong>, users can automate complex tasks quickl<a id="_idTextAnchor347"/>y and reliably, ensuring consistency and reducing the risk <span class="No-Break">of errors.</span></p>
<h1 id="_idParaDest-238">Handling secrets</h1>
<p>Protecting <a id="_idIndexMarker1030"/>secrets such as passwords, tokens, and certificates is crucial in any IT infrastructure. These secrets are the keys to accessing sensitive information and services, and their exposure can lead to severe security breaches. Therefore, it is crucial to keep them safe and secure. Ansible provides several methods for managing secrets, such as Ansible Vault, which allows users to encrypt and decrypt sensitive data using a password or key file. This feature helps to protect secrets and ensures that only authorized users have access <span class="No-Break">to them.</span></p>
<p>Saving secrets <a id="_idIndexMarker1031"/>in a Git repository or any other public place is a significant security risk. Such repositories are often accessible to multiple users, some of whom may not have the necessary permissions to access sensitive data. Additionally, version control systems such as Git retain the history of changes made to files, making it possible for secrets to be exposed inadvertently. This could happen if a user inadvertently commits secrets to a repository or if a hacker gains access to a repository’s commit history. Therefore, it is vital to discourage saving secrets in public places to reduce the risk of unauthorized access. Instead, Ansible provides secure ways to manage secrets, ensuring that they are encrypted and only accessible to authorized users. By d<a id="_idTextAnchor348"/>oing so, users can be confident that their secrets are safe <span class="No-Break">and secure.</span></p>
<h2 id="_idParaDest-239"><a id="_idTextAnchor349"/>Ansible Vault</h2>
<p><strong class="bold">Ansible Vault</strong> is a <a id="_idIndexMarker1032"/>feature provided by Ansible that enables users to encrypt and decrypt sensitive data, such as passwords, keys, and certificates. The vault creates an encrypted file that can be decrypted only by authorized users, ensuring that sensitive data remains secure. The vault can be used to store secrets in files, variables, or other sources that are used <span class="No-Break">by Ansible.</span></p>
<p>Ansible Vault uses a variety of encryption methods to secure the secrets stored within it. By default, Ansible Vault uses AES 256 encryption, a widely accepted and secure encryption algorithm. Additionally, Ansible Vault supports other encryption algorithms, such as AES 192 and AES 128, providing flexibility in the encryption strength used to secure secrets. When encrypting data with Ansible Vault, users can choose to encrypt it with a password or with a key file. This ensures that only authorized users who possess the password or key file can decrypt the secrets stored within <span class="No-Break">the vault.</span></p>
<p>To create a new vault using Ansible Vault, you can use the <span class="No-Break">following command:</span></p>
<pre class="console">
admin@myhome:~$ ansible-vault create secrets.yml
New Vault password:
Confirm New Vault password:</pre>
<p>This will create a new encrypted vault file called <strong class="source-inline">secrets.yml</strong>. You will be prompted to enter a password to encrypt the file. Once you’ve entered the password, the vault file will be created and opened in your default editor. Here’s an example <span class="No-Break"><strong class="source-inline">secrets.yml</strong></span><span class="No-Break"> file:</span></p>
<pre class="source-code">
somesecret: pleaseEncryptMe
secret_pgsql_password: veryPasswordyPassword</pre>
<p>To edit this <a id="_idIndexMarker1033"/>secret file, you’ll need to use the <strong class="source-inline">ansible-vault edit secrets.yml</strong> command and type the encryption <span class="No-Break">password afterward.</span></p>
<p>To write an Ansible task that reads the <strong class="source-inline">pgsql_password</strong> secret from the vault, you can use the <strong class="source-inline">ansible.builtin.include_vars</strong> module with the <strong class="source-inline">vault_password_file</strong> parameter. Here is an <span class="No-Break">example task:</span></p>
<pre class="source-code">
- name: Read pgsql_password from Ansible Vault
  include_vars:
    file: secrets.yml
    vault_password_file: /path/to/vault/password/file
  vars:
    pgsql_password: "{{ secret_pgsql_password }}"</pre>
<p>In this task, we’re using the <strong class="source-inline">include_vars</strong> module to read the variables from the <strong class="source-inline">secrets.yml</strong> vault file. The <strong class="source-inline">vault_password_file</strong> parameter specifies the location of the file containing the password to decrypt the vault. We then assign the value of <strong class="source-inline">secret_pgsql_password</strong> to the <strong class="source-inline">pgsql_password</strong> variable, which can be used elsewhere in <span class="No-Break">the playbook.</span></p>
<p>Note that the <strong class="source-inline">secret_pgsql_password</strong> variable should be defined in the vault. The <strong class="source-inline">secret_</strong> prefix is to indicate that the password was retrieved from the vault. Ansible does not differentiate between regular variables or <span class="No-Break">secret variables.</span></p>
<p>When you run this playbook with an increased Ansible debug level, you will notice that the PostgreSQL password is exposed in the debug output. To prevent that, every task dealing with se<a id="_idTextAnchor350"/>nsitive information can be executed with the <strong class="source-inline">no_log: True</strong> <span class="No-Break">option enabled.</span></p>
<h2 id="_idParaDest-240"><a id="_idTextAnchor351"/>SOPS</h2>
<p><strong class="bold">Secrets OPerationS</strong> (<strong class="bold">SOPS</strong>) is <a id="_idIndexMarker1034"/>an open source tool developed by Mozilla that allows users to securely store and manage their secrets within various configuration files, including Ansible playbooks. SOPS uses a hybrid encryption approach, which means that it combines symmetric and asymmetric encryption to ensure <span class="No-Break">maximum security.</span></p>
<p>SOPS encrypts<a id="_idIndexMarker1035"/> secrets using a master key, which can be either symmetric or asymmetric. <strong class="bold">Symmetric encryption</strong> uses a password or passphrase to encrypt and decrypt secrets, while <strong class="bold">asymmetric encryption</strong> uses<a id="_idIndexMarker1036"/> a pair of keys, one public and one private, to encrypt and decrypt secrets. SOPS encrypts the master key using key wrapping, a technique that encrypts the key with another key. In SOPS, the key that is used <a id="_idIndexMarker1037"/>for key wrapping is often an AWS <strong class="bold">Key Management Service</strong> (<strong class="bold">KMS</strong>) key, but it can<a id="_idIndexMarker1038"/> also be a <strong class="bold">Pretty Good Privacy</strong> (<strong class="bold">PGP</strong>) key or a Google Cloud <span class="No-Break">KMS key.</span></p>
<p>SOPS integrates seamlessly with Ansible and supports various file formats, including YAML, JSON, and INI. It also supports various cloud providers, including AWS, Google Cloud, and Azure, making it a versatile tool for managing secrets across <span class="No-Break">different environments.</span></p>
<p>Here’s an example<a id="_idIndexMarker1039"/> of how to create a SOPS-encrypted YAML file and load its contents into an Ansible playbook <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">community.sops.load_vars</strong></span><span class="No-Break">.</span></p>
<p>First, create a YAML file named <strong class="source-inline">secrets.yaml</strong> with the <span class="No-Break">following content:</span></p>
<pre class="source-code">
postgresql_password: So.VerySecret</pre>
<p>Then, use SOPS to encrypt the file using the <span class="No-Break">following command:</span></p>
<pre class="console">
admin@myhome:~$ sops secrets.yaml &gt; secrets.sops.yaml</pre>
<p>This will create an encrypted version of the <strong class="source-inline">secrets.yaml</strong> file named <strong class="source-inline">secrets.sops.yaml</strong>. It’s safe to remove the <strong class="source-inline">secrets.yaml</strong> plain text file now. The most common mistake is leaving these files behind and committing them to the <span class="No-Break">Git repository.</span></p>
<p>Next, create a new Ansible playbook named <strong class="source-inline">database.yml</strong> with the <span class="No-Break">following content:</span></p>
<pre class="source-code">
---
- hosts: dbserver
  become: true
  vars:
    postgresql_password: "{{ lookup('community.sops.load_vars', 'secrets.sops.yaml')['postgresql_password'] }}"
  tasks:
    - name: Install PostgreSQL
      apt:
        name: postgresql
        state: present
    - name: Create PostgreSQL user and database
      postgresql_user:
        db: mydatabase
        login_user: postgres
        login_password: "{{ postgresql_password }}"
        name: myuser
        password: "{{ postgresql_password }}"
        state: present</pre>
<p>In this <a id="_idIndexMarker1040"/>example, we’re using <strong class="source-inline">community.sops.load_vars</strong> to load the <strong class="source-inline">postgresql_password</strong> variable from the encrypted <strong class="source-inline">secrets.sops.yaml</strong> file. The <strong class="source-inline">postgresql_password</strong> variable is then passed to the <strong class="source-inline">postgresql_user</strong> task using the <strong class="source-inline">{{ postgresql_password }}</strong> <span class="No-Break">Jinja2 syntax.</span></p>
<p>When you run this playbook with Ansible, it will decrypt the <strong class="source-inline">secrets.sops.yaml</strong> file using SOPS and load the <strong class="source-inline">postgresql_password</strong> variable into the <strong class="source-inline">postgresql_password</strong> variable in the playbook. This ensures that the password is not stored in<a id="_idIndexMarker1041"/> plain text in the playbook, providing an extra layer of security for your <span class="No-Break">sensitive information.</span></p>
<p>More information<a id="_idIndexMarker1042"/> about SOP<a id="_idTextAnchor352"/>S is available in its official GitHub <span class="No-Break">repository: </span><a href="https://github.com/mozilla/sops"><span class="No-Break">https://github.com/mozilla/sops</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-241"><a id="_idTextAnchor353"/>Other solutions</h2>
<p>There are several alternatives to Ansible Vault and SOPS that you can use to manage your sensitive data securely, <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="bold">HashiCorp Vault</strong>: An<a id="_idIndexMarker1043"/> open source tool for securely storing and accessing secrets. It provides a service for secure and centralized storage of secrets, access control, <span class="No-Break">and auditing.</span></li>
<li><strong class="bold">Blackbox</strong>: A<a id="_idIndexMarker1044"/> command-line utility that encrypts and decrypts files <a id="_idIndexMarker1045"/>using <strong class="bold">GNU Privacy Guard</strong> (<strong class="bold">GPG</strong>). It works by creating a separate GPG key for each user or team that needs access to the <span class="No-Break">encrypted data.</span></li>
<li><strong class="bold">Keywhiz</strong>: Another <a id="_idIndexMarker1046"/>open source secrets management system that provides a simple way to store and distribute secrets securely. It includes a web interface for managing secrets and a command-line tool for <span class="No-Break">accessing them.</span></li>
<li><strong class="bold">Azure Key Vault, AWS Secrets Manager, or Google Cloud Secret Manager</strong>: Solutions<a id="_idIndexMarker1047"/> you might want to consider keeping secrets in when <a id="_idIndexMarker1048"/>dealing <a id="_idIndexMarker1049"/>with a <span class="No-Break">cloud environment.</span></li>
</ul>
<p>This is, of course, not a complete list of all <span class="No-Break">available options.</span></p>
<p>In this section, we introduced Ansible Vault and SOPS as means to handle secrets such as pass<a id="_idTextAnchor354"/>words. In the next section, we will be introducing a graphical frontend (GUI) <span class="No-Break">to Ansible.</span></p>
<h1 id="_idParaDest-242">Ansible Tower and alternatives</h1>
<p><strong class="bold">Ansible Tower</strong> provides<a id="_idIndexMarker1050"/> a centralized platform for managing Ansible automation workflows, making it easier for IT teams to collaborate, share knowledge, and maintain their infrastructure. Some of its key features include a web-based interface for managing Ansible playbooks, inventories, and job runs, <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>) for <a id="_idIndexMarker1051"/>managing user permissions, a built-in dashboard for monitoring job status and results, and an API for integrating with other tools <span class="No-Break">and platforms.</span></p>
<p>It was first released in 2013 by Ansible, Inc. (now part of Red Hat), and has since become one of the most popular tools for automating <span class="No-Break">IT workflows.</span></p>
<p>Since its initial release, Ansible Tower has undergone numerous updates and enhancements, including support for more complex automation workflows, integration with cloud platforms such as AWS and Azure, and improved scalability and performance. Ansible Tower is a commercial product shipped by the Red Hat company. The closest alternative to Ansible Tower is <strong class="bold">Ansible </strong><span class="No-Break"><strong class="bold">WorX</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">AWX</strong></span><span class="No-Break">).</span></p>
<p><strong class="bold">Ansible AWX</strong> is an<a id="_idIndexMarker1052"/> open source alternative to Ansible Tower, offering many of the same features as Tower but with a greater degree of customization and flexibility. AWX was first released in 2017 and has since become a popular choice for organizations looking to implement Ansible automation at scale without the cost of a <span class="No-Break">commercial license.</span></p>
<p>One of the primary differences between Ansible Tower and Ansible AWX is their licensing model. While Ansible Tower requires a commercial license and is sold as part of Red Hat Ansible Automation Platform, Ansible AWX is open source and freely available for download from the Ansible website. This means that organizations can deploy AWX on their own infrastructure and customize it to their specific needs, rather than relying on a pre-built <span class="No-Break">commercial solution.</span></p>
<p>Feature-wise, Ansible Tower and Ansible AWX are quite similar, with both platforms offering a web-based interface for managing Ansible playbooks, inventories, and job runs, RBAC for managing user permissions, and a built-in dashboard for monitoring job status and results. However, Ansible Tower does offer some additional features not found in Ansible AWX, such as native integration with Red Hat Ansible Automation Platform, advanced analytics and reporting, and certified modules <span class="No-Break">and collections.</span></p>
<p>Another open source alternative to Ansible Tower is <strong class="bold">Ansible Semaphore</strong>. Similar to Tower, it is a<a id="_idIndexMarker1053"/> web-based application designed to simplify the management of Ansible playbooks and projects. It is an open source, free, and easy-to-use alternative to Ansible Tower that allows users to easily automate their infrastructure tasks without the need for extensive coding knowledge. The first release of Ansible Semaphore was in 2016, and since then it has become a popular choice for those who want a simple yet powerful web-based interface for managing their Ansible <span class="No-Break">automation workflows.</span></p>
<p>You can<a id="_idIndexMarker1054"/> read <a id="_idIndexMarker1055"/>more about these alternatives on their <span class="No-Break">respective</span><span class="No-Break"><a id="_idIndexMarker1056"/></span><span class="No-Break"> websites:</span></p>
<ul>
<li><strong class="bold">Ansible </strong><span class="No-Break"><strong class="bold">Tower</strong></span><span class="No-Break">: </span><a href="https://access.redhat.com/products/ansible-tower-red-hat%20"><span class="No-Break">https://access.redhat.com/products/ansible-tower-red-hat</span></a></li>
<li><strong class="bold">A<a id="_idTextAnchor355"/>nsible </strong><span class="No-Break"><strong class="bold">AWX</strong></span><span class="No-Break">: </span><a href="https://github.com/ansible/awx"><span class="No-Break">https://github.com/ansible/awx</span></a></li>
<li><strong class="bold">Ansible </strong><span class="No-Break"><strong class="bold">Semaphore</strong></span><span class="No-Break">: </span><a href="https://www.ansible-semaphore.com/"><span class="No-Break">https://www.ansible-semaphore.com/</span></a></li>
</ul>
<h1 id="_idParaDest-243">Advanced topics</h1>
<p>In this section, we will show you how to handle advanced Ansible feat<a id="_idTextAnchor356"/>ures and techniques for debugging and automatically checking your playbooks for <span class="No-Break">possible errors.</span></p>
<h2 id="_idParaDest-244"><a id="_idTextAnchor357"/>Debugging</h2>
<p>In <a id="_idIndexMarker1057"/>order to debug issues with your Ansible playbook runs, it is often useful to increase the verbosity level to get more detailed output about what Ansible is doing. Ansible has four verbosity levels: <strong class="source-inline">-v</strong>, <strong class="source-inline">-vv</strong>, <strong class="source-inline">-vvv</strong>, and <strong class="source-inline">-vvvv</strong>. The more <strong class="source-inline">v</strong>s you add, the more verbose the <span class="No-Break">output becomes.</span></p>
<p>By default, Ansible runs with <strong class="source-inline">-v</strong>, which provides basic information about the tasks that are executed. However, if you are experiencing issues with your playbook, it may be helpful to increase the verbosity level to get more detailed output. For example, using   -<strong class="source-inline">vv</strong> will provide additional information about the playbooks, roles, and tasks that are being executed, while using <strong class="source-inline">-vvv</strong> will also show the tasks that Ansible <span class="No-Break">is skipping.</span></p>
<p>To increase the verbosity level of an Ansible playbook run, simply add one or more <strong class="source-inline">-v</strong> options to the <strong class="source-inline">ansible-playbook</strong> command. Here’s <span class="No-Break">an example:</span></p>
<pre class="console">
admin@myhome:~$ ansible-playbook playbook.yml -vv</pre>
<p>This will <a id="_idIndexMarker1058"/>run the playbook with verbose output at the <strong class="source-inline">-vvlevel</strong>. If you need even more verbose output, you can add extra <strong class="source-inline">-v</strong> options. You can see an <span class="No-Break">example here:</span></p>
<pre class="console">
admin@myhome:~$ ansible-playbook playbook.yml -vvv</pre>
<p>In addition to using the <strong class="source-inline">-v</strong> options, you can also set the verbosity level in your <strong class="source-inline">ansible.cfg</strong> file by adding the <span class="No-Break">following lines:</span></p>
<pre class="source-code">
[defaults]
verbosity = 2</pre>
<p>This will set the verbosity level to <strong class="source-inline">-vv</strong> for all <strong class="source-inline">ansible-playbook</strong> commands. You can change the value to <strong class="source-inline">3</strong> or <strong class="source-inline">4</strong> to increase the verbosity level <span class="No-Break">even further.</span></p>
<p>If you need to add some custom communication (such as printing a variable) in a verbose mode, you can do it by using the <span class="No-Break"><strong class="source-inline">debug</strong></span><span class="No-Break"> task.</span></p>
<p>Here’s an example playbook that demonstrates how to print out a variable in <strong class="source-inline">-vv </strong><span class="No-Break"><strong class="source-inline">debug</strong></span><span class="No-Break"> mode:</span></p>
<pre class="source-code">
---
- hosts: all
  gather_facts: true
  vars:
    my_variable: "Hello, World!"
  tasks:
    - name: Print variable in debug mode
      debug:
        msg: "{{ my_variable }}"
      verbosity: 2</pre>
<p>In this playbook, we define a <strong class="source-inline">my_variable</strong> variable that holds the <strong class="source-inline">"Hello, World!"</strong> string. Then, we use the <strong class="source-inline">debug</strong> module to print out the value of this variable using the <span class="No-Break"><strong class="source-inline">msg</strong></span><span class="No-Break"> parameter.</span></p>
<p>The <strong class="source-inline">verbosity: 2</strong> line is<a id="_idIndexMarker1059"/> what enables <strong class="source-inline">debug</strong> mode. This tells<a id="_idTextAnchor358"/> Ansible to increase the verbosity level to <strong class="source-inline">-vv</strong>, which will show us the output of the <span class="No-Break"><strong class="source-inline">debug</strong></span><span class="No-Break"> module.</span></p>
<h2 id="_idParaDest-245"><a id="_idTextAnchor359"/>Linting Ansible playbooks</h2>
<p><strong class="bold">Ansible code linting</strong> is<a id="_idIndexMarker1060"/> the process of analyzing and verifying the syntax and style of Ansible code to ensure that it conforms to best practices and standards. The purpose of linting is to catch potential errors or issues before the code is executed, which can save time and effort in the <span class="No-Break">long run.</span></p>
<p>The most common tool used for Ansible code linting is <strong class="source-inline">ansible-lint</strong>. This is an open source command-line tool that analyzes Ansible playbooks and roles for potential problems and provides suggestions <span class="No-Break">for improvement.</span></p>
<p>To run <strong class="source-inline">ansible-lint</strong> against a sample playbook, you can execute the following command in <span class="No-Break">the terminal:</span></p>
<pre class="console">
admin@myhome:~$ ansible-lint sample-playbook.yml</pre>
<p>Assuming the sample playbook is saved as <strong class="source-inline">sample-playbook.yml</strong> in the current working directory, its content looks <span class="No-Break">like this:</span></p>
<pre class="source-code">
---
- name: (Debian/Ubuntu) {{ (nginx_setup == 'uninstall') | ternary('Remove', 'Configure') }} NGINX repository
  ansible.builtin.apt_repository:
    filename: nginx
    repo: "{{ item }}"
    update_cache: true
    mode: "0644"
    state: "{{ (nginx_state == 'uninstall') | ternary('absent', 'present') }}"
  loop: "{{ nginx_repository | default(nginx_default_repository_debian) }}"
  when: nginx_manage_repo | bool
- name: (Debian/Ubuntu) {{ (nginx_setup == 'uninstall') | ternary('Unpin', 'Pin') }} NGINX repository
  ansible.builtin.blockinfile:
    path: /etc/apt/preferences.d/99nginx
    create: true
    block: |
      Package: *
      Pin: origin nginx.org
      Pin: release o=nginx
      Pin-Priority: 900
    mode: "0644"
    state: "{{ (nginx_state == 'uninstall') | ternary('absent', 'present') }}"
  when: nginx_repository is not defined
- name: (Debian/Ubuntu) {{ nginx_setup | capitalize }} NGINX
  ansible.builtin.apt:
    name: nginx{{ nginx_version | default('') }}
    state: "{{ nginx_state }}"
    update_cache: true
    allow_downgrade: "{{ omit if ansible_version['full'] is version('2.12', '&lt;') else true }}"
  ignore_errors: "{{ ansible_check_mode }}"
  notify: (Handler) Run NGINX</pre>
<p>Note that the output of <strong class="source-inline">ansible-lint</strong> may vary depending on the version of Ansible and <strong class="source-inline">ansible-lint</strong> being used, as well as the specific <span class="No-Break">rules enabled.</span></p>
<p>As an <a id="_idIndexMarker1061"/>example, the following is the output of running <strong class="source-inline">ansible-lint</strong> against the sample <span class="No-Break">playbook provided:</span></p>
<pre class="console">
[WARNING]: empty path for ansible.builtin.blockinfile, path set to ''
[WARNING]: error loading version info from /usr/lib/python3.10/site-packages/ansible/modules/system/setup.py: __version__ = '2.10.7'
[WARNING]: 3.0.0 includes an experimental document syntax parser that could result in parsing errors for documents that used the previous parser. Use `--syntax-check` to verify new documents before use or consider setting `document_start_marker` to avoid using the experimental parser.
sample-playbook.yml:1:1: ELL0011: Trailing whitespace
sample-playbook.yml:7:1: ELL0011: Trailing whitespace
sample-playbook.yml:9:1: ELL0011: Trailing whitespace
sample-playbook.yml:17:1: ELL0011: Trailing whitespace
sample-playbook.yml:22:1: ELL0011: Trailing whitespace
sample-playbook.yml:26:1: ELL0011: Trailing whitespace
sample-playbook.yml:29:1: ELL0011: Trailing whitespace
sample-playbook.yml:35:1: ELL0011: Trailing whitespace
sample-playbook.yml:38:1: ELL0011: Trailing whitespace
sample-playbook.yml:41:1: ELL0011: Trailing whitespace
sample-playbook.yml:44:1: ELL0011: Trailing whitespace
sample-playbook.yml:47:1: ELL0011: Trailing whitespace
sample-playbook.yml:50:1: ELL0011: Trailing whitespace
sample-playbook.yml:53:1: ELL0011: Trailing whitespace</pre>
<p>The<a id="_idIndexMarker1062"/> output indicates that the playbook contains trailing whitespace on several lines, which violates the <strong class="source-inline">ELL0011</strong> rule of <strong class="source-inline">ansible-lint</strong>. The warning messages regarding the empty path and version info loading are not critical issues and can be <span class="No-Break">safely ignored.</span></p>
<p>To fix the trailing whitespace issue, simply remove the extra spaces at the end of each affected line. Once the issues<a id="_idTextAnchor360"/> are fixed, you can rerun <strong class="source-inline">ansible-lint</strong> to ensure that there are no further problems with <span class="No-Break">the playbook.</span></p>
<h2 id="_idParaDest-246"><a id="_idTextAnchor361"/>Speeding up SSH connections</h2>
<p>Ansible<a id="_idIndexMarker1063"/> is an open source automation tool that is widely used to deploy and manage IT infrastructure. One of the key features of Ansible is its ability to use SSH for secure communication with remote servers. However, using SSH for every single task can be time-consuming and can impact performance, especially if you’re dealing with a lot of servers. To address this issue, Ansible supports <strong class="bold">SSH multiplexing</strong>, which<a id="_idIndexMarker1064"/> allows multiple SSH connections to share a single <span class="No-Break">TCP connection.</span></p>
<p>SSH multiplexing works by reusing the existing SSH connection rather than creating a new one for every task. When Ansible establishes an SSH connection to a remote server, it opens a TCP socket and creates a control socket for that connection. A <strong class="bold">control socket</strong> is a<a id="_idIndexMarker1065"/> special socket that is used to manage the SSH connection. When another SSH connection is requested to the same host, Ansible checks whether a control socket already exists for that connection. If it does, Ansible reuses the existing control socket and creates a new channel within the same SSH connection for the <span class="No-Break">new task.</span></p>
<p>The benefits of SSH multiplexing are that it saves time and resources by reducing the number of SSH connections that Ansible has to establish. Additionally, it can improve the performance of Ansible by reducing the overhead of creating and tearing down SSH connections for <span class="No-Break">every task.</span></p>
<p>To enable<a id="_idIndexMarker1066"/> SSH multiplexing in Ansible, you need to configure the <strong class="source-inline">ControlMaster</strong> and <strong class="source-inline">ControlPath</strong> options in the SSH client configuration file. The <strong class="source-inline">ControlMaster</strong> option enables the use of SSH multiplexing, while the <strong class="source-inline">ControlPath</strong> option specifies the location of the control socket. By default, Ansible uses the <strong class="source-inline">~/.ansible/cp</strong> directory to store control sockets. You can also configure the maximum number of SSH connections that can be multiplexed simultaneously by setting the <span class="No-Break"><strong class="source-inline">ControlPersist</strong></span><span class="No-Break"> option.</span></p>
<p>To<a id="_idIndexMarker1067"/> customize the SSH multiplexing configuration, you can put SSH options into your default Ansible configuration file placed in <strong class="source-inline">~/.ansible.cfg</strong> by adding the <strong class="source-inline">[ssh_connection]</strong> section, <span class="No-Break">as follows:</span></p>
<pre class="source-code">
[ssh_connection]
ssh_args = -o ControlMaster=auto -o ControlPersist=3600
control_path = ~/.ssh/multiplexing/ansible-ssh-%%r@%%h:%%p</pre>
<p>Make sure to also create a <strong class="source-inline">~/.ssh/multiplexing</strong> directory after adding <span class="No-Break">this configuration.</span></p>
<p>The <strong class="source-inline">ControlMaster=auto</strong> option creates a master session automatically, and if there is a master session already available, subsequent sessions are automatically multiplexed. Setting <strong class="source-inline">ControlPersist=3600</strong> w<a id="_idTextAnchor362"/>ill leave the master connection open in the background to accept new connections for <strong class="source-inline">3600</strong> seconds (<span class="No-Break">1 hour).</span></p>
<h2 id="_idParaDest-247"><a id="_idTextAnchor363"/>Dynamic inventory</h2>
<p>In cloud environments <a id="_idIndexMarker1068"/>such as AWS, servers can be created and terminated dynamically based on demand. Managing these servers manually can be a daunting task, which is why automation tools such as Ansible are essential. One of the critical features of Ansible that makes it well suited for cloud environments is <span class="No-Break">dynamic inventory.</span></p>
<p><strong class="bold">Dynamic inventory</strong> is an<a id="_idIndexMarker1069"/> Ansible feature that enables the automatic discovery of hosts (servers) and groups (tags) in a cloud environment. In AWS, Ansible <a id="_idIndexMarker1070"/>can use the <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) inventory plugin to query the AWS API to retrieve information about EC2 instances <span class="No-Break">and groups.</span></p>
<p>To use <a id="_idIndexMarker1071"/>dynamic inventory in AWS, you need to configure the EC2 inventory plugin in your <span class="No-Break">Ansible configuration.</span></p>
<p>The <strong class="source-inline">amazon.aws.aws_ec2</strong> inventory plugin is an official Ansible plugin that enables dynamic inventory for Amazon EC2 instances. To use this plugin, you need to follow the steps set <span class="No-Break">out next.</span></p>
<p>Depending on which version of Ansible you’re using and whether you’ve installed full Ansible (not only Ansible Core), you might need to use Ansible Galaxy to install an AWS collection plugin, <span class="No-Break">as follows:</span></p>
<pre class="console">
admin@myhome:~$ ansible-galaxy collection install amazon.aws</pre>
<p>Install the <strong class="source-inline">boto3</strong> and <strong class="source-inline">botocore</strong> libraries on your Ansible control node. You can install them using the <strong class="source-inline">pip</strong> package manager, <span class="No-Break">like so:</span></p>
<pre class="console">
admin@myhome:~$ pip install boto3 botocore</pre>
<p>Create<a id="_idIndexMarker1072"/> an <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) user with the necessary permissions to access EC2 instances and groups. You can create an IAM user using the AWS Management Console or the AWS CLI. Make sure to save the IAM user’s access key and secret <span class="No-Break">access key.</span></p>
<p>Create an AWS credentials file (<strong class="source-inline">~/.aws/credentials</strong>) on your Ansible control node and add the IAM user’s access key and secret access key, <span class="No-Break">as follows:</span></p>
<pre class="source-code">
[default]
aws_access_key_id = YOUR_ACCESS_KEY
aws_secret_access_key = YOUR_SECRET_KEY</pre>
<p>Create an Ansible inventory file (<strong class="source-inline">inventory.yml</strong>) in your project directory and configure it to use the <strong class="source-inline">amazon.aws.aws_ec2</strong> plugin, <span class="No-Break">like so:</span></p>
<pre class="source-code">
plugin: amazon.aws.aws_ec2
regions:
  - eu-central-1
filters:
  tag:Environment:
    - webserver
    - frontend</pre>
<p>Here’s a brief explanation of the <span class="No-Break">configuration options:</span></p>
<ul>
<li><strong class="source-inline">plugin</strong>: Specifies the inventory plugin <span class="No-Break">to use</span></li>
<li><strong class="source-inline">regions</strong>: Specifies the AWS regions to search for <span class="No-Break">instances in</span></li>
<li><strong class="source-inline">filters</strong>: Allows you to filter EC2 instances <span class="No-Break">by tags</span></li>
</ul>
<p>Test the <a id="_idIndexMarker1073"/>inventory by running the <span class="No-Break">following command:</span></p>
<pre class="console">
admin@myhome:~$ ansible-inventory -i inventory.yml --list</pre>
<p>This <a id="_idIndexMarker1074"/>command should output a JSON object that lists all the EC2 instances in the specified regions, grouped by their <span class="No-Break">Ansible tags.</span></p>
<p>This way, you won’t <a id="_idTextAnchor364"/>have to update your inventory file on every Ansible playbook run to make sure you have an up-to-date <span class="No-Break">servers list.</span></p>
<h1 id="_idParaDest-248">Summary</h1>
<p>In this chapter, we have presented you with the Ansible CaC tool. We have explained and demonstrated how moving configuration, from tribal knowledge and documents (as well as describing steps required to get your system to a desired state) to tools that can implement said configuration based on a well-defined syntax brings benefits to your organization, such as repeatability, ability to run many configurations in parallel, automated tests, <span class="No-Break">and execution.</span></p>
<p>In the next chapter, we are going to introduce you to <strong class="bold">Infrastructure as </strong><span class="No-Break"><strong class="bold">Code</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">IaC</strong></span><span class="No-Break">).</span></p>
<h1 id="_idParaDest-249">Further reading</h1>
<ul>
<li><em class="italic">Mastering Ansible, Fourth Edition</em> by James Freeman and <span class="No-Break">Jesse Keating</span></li>
<li><em class="italic">Ansible Playbook Essentials</em> by <span class="No-Break">Gourav Shah</span></li>
<li><em class="italic">Ansible for Real-Life Automation</em> by <span class="No-Break">Gineesh Madapparambath</span></li>
</ul>
</div>
</div></body></html>