- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Accelerate Productivity with AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we embark on a journey to explore the exciting realm of AI-powered
    software development. In reality, although the application of large language models
    in coding is gradually becoming more apparent, it remains largely in the research
    and development phase. While we have focused on practical content so far, this
    chapter shifts our attention to the theories that facilitate a wonderful collaboration
    with AI. We aim to provide insights that will help you understand the context
    of AI in development correctly and master its use. With this foundation, let’s
    explore the world of AI-powered coding together.
  prefs: []
  type: TYPE_NORMAL
- en: The essence of AI’s role in coding fundamentally boils down to the age-old notion
    of *how to write good code*, which, in turn, relies on knowledge, skills, and
    experience. If you are looking for a universal magical technique to make AI write
    remarkable code, you might find that, in reality, such a thing probably does not
    exist. Furthermore, even when mentioning specific product features, it is important
    to recognize that the rapid pace of evolution in this field may quickly render
    newly acquired skills obsolete.
  prefs: []
  type: TYPE_NORMAL
- en: This book has consistently focused on the theme of collaboration. In this context,
    we maintain that focus, aiming to understand how to collaborate effectively with
    AI. The gateway to all communication starts with understanding your counterpart.
    By gaining a correct understanding of AI, setting appropriate expectations, and
    focusing on extracting the right information from AI, you will be able to refine
    your interactions with AI tools, regardless of how these tools evolve. As the
    author, it is my belief that we should aim to fundamentally understand AI rather
    than focusing solely on individual tips and tricks.
  prefs: []
  type: TYPE_NORMAL
- en: We will explore best practices for engaging with AI tools, with an emphasis
    on the subtleties of coding with AI assistance. AI-powered coding represents an
    exciting frontier with many uncharted territories. We encourage you to grasp the
    fundamentals and embark on coding alongside AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following main headings in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: AI innovation in coding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the capabilities and interaction with AI in coding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strategies for maximizing AI efficiency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI innovation in coding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The introduction of LLMs by OpenAI has marked a pivotal moment in the evolution
    of software development. We delve into the aftermath of this groundbreaking innovation,
    exploring how it has reshaped the coding landscape.
  prefs: []
  type: TYPE_NORMAL
- en: The impact of LLMs on coding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can say the advent of LLMs has fundamentally changed how programming is approached
    and executed. With the capacity to understand and generate human-like text, these
    models have opened up new avenues in coding, making it more efficient and accessible.
    LLMs have significantly sped up the process of writing code. Developers can now
    leverage AI to quickly generate code snippets, reducing the time spent on routine
    or repetitive coding tasks. The introduction of LLMs has enabled developers to
    tackle coding challenges more creatively. By providing suggestions and alternative
    solutions, these models have become valuable tools in the problem-solving arsenal
    of programmers.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs have introduced a new realm of AI-powered development, where developers
    collaborate with AI tools to enhance their coding workflow. This collaboration
    ranges from generating code snippets to offering insights into complex coding
    problems. For novice developers, AI serves as an educational tool, helping them
    learn coding patterns and best practices. This reduces the entry barriers to programming,
    making it more approachable for beginners. Additionally, for experienced developers,
    this AI integration is a powerful catalyst, enabling them to achieve more by augmenting
    their skills with advanced code suggestions, automating routine tasks, and providing
    deeper insights into code optimization and problem-solving. The combination of
    seasoned developer expertise and AI efficiency creates a synergy that pushes the
    boundaries of what can be accomplished in software development.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of modern LLMs has revolutionized coding, transforming it from
    a purely manual endeavor to a more collaborative, efficient, and innovative process.
    This change has not only accelerated development but has also opened up new possibilities
    for creativity and problem-solving in the realm of software engineering. Additionally,
    this area is being extended right now to a variety of tasks, not only coding but
    also review and documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding LLMs – A basic introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the context of AI-powered programming, LLMs have emerged as a pivotal innovation,
    reshaping our approach to software development. But what are LLMs? Let’s get to
    know this first.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are advanced AI models designed to understand, interpret, and generate
    human-like text. These models are large not only in their size (often comprising
    billions of parameters) but also in their scope of training data and capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs such as **Generative Pre-trained Transformer** (**GPT**) are trained on
    vast datasets comprising a wide range of internet text. This training enables
    them to predict and generate text based on the input they receive, making them
    highly versatile in language understanding and generation. The core technology
    behind LLMs involves neural network architectures, specifically transformer models,
    which have revolutionized **Natural Language Processing** (**NLP**). These networks
    are adept at handling sequential data, making them ideal for language tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'To fully harness their potential, it is essential to understand what LLMs are
    fundamentally designed to do and what they are not. While AI may seem like magic,
    it is more akin to a mirror reflecting your own input; it is not a panacea that
    solves everything. You must approach it with the right expectations, guide it
    properly, and cleverly extract value. Now it is time to take a look at the essential
    characteristics of LLMs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Word prediction engines**: At their core, LLMs are sophisticated engines
    designed to predict the next word in a sequence. This prediction capability is
    based on the extensive training they receive from vast datasets, enabling them
    to generate contextually relevant and coherent text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Probabilistic, not deterministic**: Unlike deterministic models that always
    produce the same output for a given input, LLMs are probabilistic models. This
    means that they predict what comes next based on the probability of various possible
    continuations, leading to potential variations in output for the same input. This
    aspect underscores the inherently stochastic nature of LLMs, highlighting that
    the same “*context*” or input can lead to different outcomes, depending on the
    probabilistic determination of what comes next.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Not a Google search alternative**: It is crucial to note that LLMs are not
    replacements for search engines such as Google. They do not learn in the traditional
    sense or retain information for future output. Each response generated by a typical
    LLM is based on the input provided at that moment, without any memory of past
    interactions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generation, not retrieval**: LLMs operate by generating responses each time
    rather than retrieving stored information. This means that their outputs are created
    anew based on the patterns they have learned during training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs have a critical role in the context of coding, primarily due to their ability
    to predict the next sequence of characters or words. These models are not just
    versatile in handling natural languages, such as English, but extend their capabilities
    to a wide array of programming languages. In fact, the application of LLMs to
    programming languages is where their effectiveness is most recognized and highly
    anticipated.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs’ adaptability to different programming languages stems from their training
    on diverse datasets, which include not only natural language texts but also vast
    repositories of code. This enables them to understand the syntax and semantics
    of various programming languages, making them incredibly useful for tasks such
    as code completion, bug fixing, and even generating entire blocks of functional
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, LLMs can assist developers in translating requirements into code,
    providing suggestions based on best practices, and even offering creative solutions
    to complex programming challenges. Their predictive ability ensures that they
    can recommend the most relevant code snippets, streamline the coding process,
    and significantly enhance coding efficiency and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the key capability, understanding the limitations and handling
    misconceptions is also important:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Not infallible**: The accuracy of LLMs is not absolute. While they can produce
    remarkably relevant and sophisticated outputs, there are instances where their
    predictions can be off the mark. They can sometimes create outputs that seem plausible
    but are actually inaccurate or nonsensical; a phenomenon sometimes referred to
    as **hallucination**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Need for human oversight**: This potential for error underscores the importance
    of human oversight. Users of LLMs should be vigilant and discerning, capable of
    identifying and correcting instances where the model’s output may be misleading
    or incorrect.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Appropriate use and expectation setting**: Understanding these limitations
    is key to setting realistic expectations and finding the most effective use cases
    for LLMs. They should be viewed as tools that augment and assist in tasks such
    as coding or text generation rather than as standalone solutions that operate
    with complete autonomy and accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In essence, LLM is a powerful innovation, offering significant capabilities
    in text generation and language understanding. However, their effective use requires
    an awareness of their limitations and the critical role of human oversight in
    guiding their output.
  prefs: []
  type: TYPE_NORMAL
- en: Application of LLMs in coding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The integration of LLMs in the world of coding has seen one of its most significant
    applications in the form of AI-powered coding tools such as GitHub Copilot. This
    section explores how AI is redefining the coding experience.
  prefs: []
  type: TYPE_NORMAL
- en: AI-powered tools designed to assist developers in writing code leverage the
    power of LLMs to provide real-time code suggestions, automating some aspects of
    coding and enhancing overall productivity. These tools, trained on a vast array
    of code repositories, interpret the context from the current coding environment
    and offer suggestions for the next lines of code, function implementations, or
    even entire classes and modules.
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental capability of these AI tools is that they work as plugins to
    editors such as Visual Studio Code, providing AI assistance as you code within
    the editor. The vision behind these tools includes integrating AI into all phases
    of the software development cycle, with a significant focus on their integration
    into the editor as a major feature. This approach represents a broader effort
    to harness AI for enhancing software development processes, aiming to make coding
    more efficient and accessible to developers at all skill levels.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming the coding process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AI-powered tools assist in enhancing the development process by streamlining
    a variety of coding tasks. Traditionally, coding involves research, reading documentation,
    and ensuring the correctness of the code. These tools help optimize these activities
    in several key areas:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increasing speed and efficiency**: Developers can speed up the coding process
    with these tools. They help reduce the time spent on repetitive code patterns
    and offer quick solutions and suggestions, freeing up developers to tackle more
    complex and innovative work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Facilitating learning and exploration**: For newcomers or those delving into
    new programming languages or frameworks, these AI tools serve as educational aids.
    They provide syntactically accurate code snippets and show best practices in action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reducing cognitive load**: AI-powered tools tackle the more routine aspects
    of coding, alleviating the mental burden developers face. This reduction in cognitive
    load enables developers to concentrate their mental energy on tackling more intricate
    and challenging problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expanding possibilities**: Through their suggestions, these tools not only
    assist with code completion but also stimulate creative thinking. They introduce
    developers to alternative problem-solving approaches and expose them to new coding
    patterns and practices they might not have previously encountered or considered.
    This expansion of possibilities can lead to more innovative solutions and a broadening
    of the developer’s skill set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By minimizing the need for frequent diversions to look up information and by
    offering pertinent code suggestions, these AI-powered tools support a more focused
    and efficient workflow. This not only leads to better code quality but also enhances
    developer productivity, establishing these tools as essential components in contemporary
    software development.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative code creation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When comparing code completion tools to chat-based tools, it is clear that
    each provides a unique set of offerings to developers. Here are the major differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code completion experience**: Tools equipped with code completion capabilities
    can predict the next words or code blocks directly within the editor. They offer
    incremental suggestions that users can quickly accept or reject, streamlining
    the coding process. This is somewhat similar to mob programming alongside an experienced
    engineer or engaging in pair programming with real-time screen sharing, which
    promotes an interactive and dynamic coding environment:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Code completion experience in GitHub Copilot](img/B21203_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Code completion experience in GitHub Copilot
  prefs: []
  type: TYPE_NORMAL
- en: '**Chat experience**: In contrast, the chat experience resembles consulting
    with a senior engineer via platforms such as Slack or Teams or even delegating
    implementation tasks. Some tools also feature a chat interface, enabling developers
    to tap into both direct code assistance and conversational guidance:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Chat experience in GitHub Copilot](img/B21203_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Chat experience in GitHub Copilot
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Copilot, the developer-centric designed tool, supports both chat and
    code completion experiences. ChatGPT, known for its versatility beyond coding,
    requires users to carefully craft prompts to guide their responses. In contrast,
    AI-powered developer tools stand out for enhancing the developer experience within
    the editor, focusing on how engineers can seamlessly integrate their current work
    context with AI assistance.
  prefs: []
  type: TYPE_NORMAL
- en: They are engineered to support developers by intuitively understanding the context
    of their work and making it easier to communicate this context to the AI with
    fewer prompts. The more code developers write, the more these tools can tailor
    their assistance to align with the developers’ objectives and the specifics of
    their work context.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt and context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concept of **prompts** has gained widespread attention with the advent of
    generative AI technologies. Among the various terms you might have encountered,
    “Prompt Engineering” stands out as a particularly common reference. However, what
    is prompt engineering really? Prompt engineering is the art of designing inputs
    or prompts for AI models to generate desired outputs. It is about crafting questions
    or statements in a way that guides the AI to understand and respond in a specific
    manner. This is crucial because the quality and relevance of AI outputs are highly
    dependent on how the prompts are structured. At the same time, however, it is
    also true that there are excessive expectations for this, and it was treated like
    a buzzword in the early days.
  prefs: []
  type: TYPE_NORMAL
- en: The term prompt engineering seems to me to be a mixture of diverse things. I
    will explain them here.
  prefs: []
  type: TYPE_NORMAL
- en: Two types of prompt engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the evolution of AI and machine learning, prompt engineering has emerged
    as an important discipline that shapes how we interact with and extract value
    from AI models. There are two types of prompt engineering. Although not an academic
    classification, I will refer to them here as **reusable prompt engineering** and
    **disposable prompt engineering**, each for different applications and requirements.
    It is important to recognize the difference between these and to know and use
    these objectives in your daily interactions with the AI.
  prefs: []
  type: TYPE_NORMAL
- en: Reusable prompt engineering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Reusable prompt engineering is designed for scenarios where prompts are repeatedly
    used in similar contexts. This is common in consumer-facing AI applications, automated
    systems, and AI-to-machine interactions. The aim here is to create prompts that
    consistently elicit accurate and relevant responses from AI, regardless of minor
    variations in input or context.
  prefs: []
  type: TYPE_NORMAL
- en: In reusable prompt engineering, near-perfect accuracy is essential. This is
    particularly true for machine consumers, where AI responses trigger other functions
    or processes. Similarly, in B2C applications, high accuracy is crucial to maintain
    user engagement and prevent frustration or confusion.
  prefs: []
  type: TYPE_NORMAL
- en: The primary challenge in this type of prompt engineering is maintaining stability
    and consistency in AI responses. This often requires a deep understanding of the
    AI model’s capabilities and limitations. Engineers who build prompts must also
    consider the variability in user inputs and contexts, ensuring that the AI can
    handle these variations without significant loss of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: In reusable prompt engineering, the emphasis is primarily on *how*—crafting
    prompts to ensure reliable and accurate responses. This focus is critical because
    the *what* and *why* can often be unpredictable, particularly in scenarios involving
    a broad and diverse user base. The prompts must be designed to handle a wide range
    of inputs from an unspecified number of users, each with their unique needs and
    ways of interacting with the AI system.
  prefs: []
  type: TYPE_NORMAL
- en: The term prompt engineering in the world is used in this context, especially
    in a narrow sense. It is about how to refine the instructions to the AI in order
    to extract information from it with a high degree of accuracy. However, in the
    actual development field, there is no need to spend time refining prompts that
    are used only once. Prompt engineering in development requires a different context.
  prefs: []
  type: TYPE_NORMAL
- en: Disposable prompt engineering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Disposable prompt engineering is characterized by the creation of one-time-use
    prompts. These are typically crafted by developers or users for specific, often
    unique, situations. Here, the emphasis shifts from broad applicability and consistency
    to specificity and immediate relevance.
  prefs: []
  type: TYPE_NORMAL
- en: This type involves a high degree of creativity and adaptability. Developers
    create prompts on the fly, tailoring them to specific tasks or problems. This
    requires a deep understanding of the context and objectives (the why and what)
    and a flexible approach to interacting with the AI.
  prefs: []
  type: TYPE_NORMAL
- en: In disposable prompt engineering, context is king. The prompts are often designed
    to address specific issues or to generate unique outputs. As such, the engineer
    must provide the AI with sufficient context to understand and respond appropriately
    to the task at hand. In the context of development, you will need to give new
    instructions to the AI each time you do something creative with each development
    task. After all, you will find that when you use AIs in your development, you
    have little need to master each and every type of prompt engineering. What is
    more important is the context.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, it is important to acknowledge that mastering the intricate techniques
    of prompt engineering may not be efficient for every goal. Again, for daily tasks
    requiring fresh ideas and essentially serving as one-off needs, dedicating extensive
    time to perfecting prompts might not be essential. Conversely, in projects such
    as developing an app infused with AI, the quality of prompts is crucial. In these
    instances, it is beneficial to continually refine them to ensure optimal interaction
    with the AI component. This process often involves trial and error, along with
    a sophisticated understanding of how the AI model may interpret various prompts.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of context
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In AI-powered development, particularly in programming, the context in which
    a piece of code exists is paramount. Context includes the surrounding information
    and environment of the code, extending beyond the immediate codebase to encompass
    project specifications, coding standards, and intended functionality. The effectiveness
    of AI hinges on its ability to interpret and respond to this context.
  prefs: []
  type: TYPE_NORMAL
- en: The context provided to an AI system determines the relevance and accuracy of
    its responses and suggestions. In the absence of adequate context, AI tools may
    generate outputs that are technically correct but misaligned with the project’s
    goals or requirements.
  prefs: []
  type: TYPE_NORMAL
- en: As developers integrate AI into their workflow, it is essential to recognize
    their role in providing clear and relevant context. This responsibility involves
    understanding that AI, while powerful, is not infallible or omniscient. It requires
    input that accurately reflects the problem at hand and the desired outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Developers should approach AI as a collaborative tool, guiding it through a
    well-defined context to ensure that its contributions are aligned with project
    objectives. This involves critically evaluating AI suggestions and adapting them
    to fit the specific nuances of their projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following would be important to include context:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Provide detailed comments**: Incorporate comprehensive comments into the
    code that explain not just what the code does but also the purpose behind it.
    This helps AI tools understand the intent behind the code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use descriptive naming conventions**: Choose variable and function names
    that clearly indicate their purpose and usage. This aids AI in generating more
    relevant and readable code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Document code thoroughly**: Ensure that the codebase is well-documented,
    outlining the broader project objectives, coding standards, and specific functionalities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frame problems clearly**: When seeking AI assistance, define the problem
    as specifically as possible. This includes stating the desired outcomes and any
    relevant constraints or considerations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effectively leveraging AI in programming requires a balanced approach that recognizes
    AI as a powerful assistant but not a complete substitute for human expertise.
    By providing clear, detailed context and maintaining critical oversight, developers
    can maximize the benefits of AI-powered tools. This approach ensures that AI serves
    as a catalyst for enhanced productivity and creativity in software development,
    complementing human capabilities rather than attempting to replace them.
  prefs: []
  type: TYPE_NORMAL
- en: The paramount importance of context in AI-powered programming cannot be overstated.
    As AI continues to evolve, its capacity to interpret and utilize context will
    determine the extent of its impact on software development.
  prefs: []
  type: TYPE_NORMAL
- en: For developers to truly harness the potential of AI in programming, a deep understanding
    of programming and technology is essential. While prompt engineering significantly
    amplifies productivity, it is not a standalone solution. The ability to provide
    clear and detailed context to AI is a skill that synergizes with a developer’s
    technical expertise. Ultimately, the effectiveness of AI tools in augmenting development
    work hinges on the developer’s foundational knowledge and experience in coding.
    This combination of technical proficiency and skillful prompt engineering is key
    to maximizing the benefits of AI in software development.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the capabilities and interaction with AI in coding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section is dedicated to providing developers with in-depth insights and
    strategies for effectively leveraging AI within their coding projects, focusing
    on its features and interaction dynamics. Whether it involves integrating AI for
    routine coding tasks or utilizing it for the more intricate and imaginative facets
    of programming, this section intends to offer comprehensive guidance on making
    AI a transformative element in your coding practices.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore the expansive capabilities of AI in coding and learn the best
    practices for interacting with AI tools, enhancing not only the productivity and
    quality of your projects but also your overall experience as a developer.
  prefs: []
  type: TYPE_NORMAL
- en: Code completion – The foundation of AI-powered coding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike ChatGPT, which requires full context in the prompt for each interaction,
    code completion in programming environments is deeply integrated with the code
    editor. AI-powered coding tools dynamically collect necessary data from the code
    you are writing and seamlessly communicate with the backend LLM. This integration
    offers an experience akin to pair programming or mob programming with an AI collaborator.
  prefs: []
  type: TYPE_NORMAL
- en: The typical AI tool continuously analyzes the code within the editor, understanding
    the immediate context to offer relevant suggestions. This contextual awareness
    is key to the effectiveness of code completion. In AI tools, where context is
    important, the most important thing is how the context was collected from the
    editor. Sometimes, humans tend to focus on the accuracy of the model behind it.
    That is never a mistake; the smarter the AI, the better. However, as AI develops
    in the future, any tool will be able to perform certain tasks. What will stand
    out in that case is its excellence as a data collection tool. Therefore, in code
    completion, it is important to know how the AI-powered coding assistant tool collects
    information from the editor and to determine whether code completion should take
    this into account.
  prefs: []
  type: TYPE_NORMAL
- en: As developers type code, an AI-powered coding tool suggests potential code snippets
    that complete or extend the code. Typically, this functionality is not just about
    speeding up the typing process; it is about offering intelligent, contextually
    relevant suggestions that can improve code quality and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of code completion in action. Let’s create a file `calc.js`
    and write the following in JavaScript:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, AI code-completion would complement the contents of a function
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The AI model behind code completion has been exposed to a vast array of code,
    but it is important to clarify that this exposure means it has been “*trained
    on data*” rather than having fundamentally “*learned*” in the traditional sense.
    Essentially, it has become adept at recognizing patterns unique to coding through
    the analysis of these extensive code repositories. By utilizing LLMs, the model
    can discern patterns, best practices, and common coding paradigms to generate
    suggestions. As a predictive engine for the next word or sequence in code, the
    quality of its suggestions is directly influenced by the quality of the input
    code. In essence, the output quality reflects the quality of the code data it
    was trained on, highlighting that its capability to provide relevant suggestions
    depends on recognizing patterns within the training data.
  prefs: []
  type: TYPE_NORMAL
- en: Code generation—the ability of AI-powered coding tools to interpret and respond
    to natural language—is remarkable. The breakthrough with AI is its capacity to
    understand natural language as it is presented, offering code suggestions based
    on that understanding rather than relying on static analysis, as with traditional
    non-AI code completion tools such as IntelliSense. Developers can detail the functionality,
    parameters, and expected outcomes of a code segment through comments, directing
    the AI to generate relevant code.
  prefs: []
  type: TYPE_NORMAL
- en: When we talk about “*code generation*,” it includes what was referred to in
    the previous section as code completion, but here we are discussing it in a broader
    sense, focusing on generating code from natural language and various types of
    information.
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of this feature depends on the precision and clarity of the
    instructions provided. Well-defined and explicit comments empower AI-powered coding
    tools to produce more accurate and suitable code responses.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the importance of your knowledge, experience, and approach to
    prompt crafting becomes evident. It is crucial to leverage your critical thinking
    and logical writing skills in a manner that the AI can comprehend.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let’s create a JavaScript file named `calc.js`, as follows, and
    write the comments you want to implement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If AI-powered tools can generate code, it will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Providing examples within other sections of the code or in comments can be extremely
    helpful. Additionally, one of the strengths of AI-powered coding tools lies in
    their ability to generate code based on structured examples. This feature proves
    especially beneficial in situations such as developing models from given data
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, consider the following comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, AI can produce the following model. The following example will output
    Python if you write Python in the file `user.py`, but similarly, if you write
    a specific language, such as `user.js` or `user.rb`, the same implementation would
    be carried out for a different language:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that the distance between the definition of the implementation
    and the implementation itself is getting very close.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to definitions, table definitions can be turned into SQL queries
    for database tables, cloud infrastructure definitions can be turned into YAML
    files for Terraform, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: For example, from a given JSON example, it is possible to generate commands
    to create a model for Ruby on Rails.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the given JSON example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'All you have to do is provide the prompt “*Generate a rails command to create
    a new user*” for this example, and AI will create a ready-to-use command in CLI
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The code generation capability represents a significant advancement in AI-powered
    coding. By interpreting descriptive comments and structured examples, AI can generate
    accurate and functional code, reducing manual coding efforts and enhancing the
    efficiency of the development process.
  prefs: []
  type: TYPE_NORMAL
- en: Code explanation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI has the capability to analyze existing code and automatically generate explanations
    that clarify the code’s functionality. This feature proves to be invaluable for
    understanding code that is not adequately documented or for demystifying complex
    algorithms for other developers. These generated explanations assist in simplifying
    complex code into more comprehensible segments, thereby facilitating a better
    understanding of the logic and intent behind the code for others.
  prefs: []
  type: TYPE_NORMAL
- en: Such a capability is instrumental in reducing the onboarding time for new team
    members, accelerating the comprehension of code for first-time viewers, and proving
    useful in scenarios where there is a noticeable gap between the specification
    and the actual code. Moreover, it enhances the value of the code by providing
    explanations for previously unmaintained or obscure code, thereby making its functionality
    clearer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of writing an algorithm in Python by creating a file, `eratosthenes.py`,
    and specifically considering generating explanations for the Sieve of the Eratosthenes
    algorithm, which was originally presented without explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If you write a comment at the beginning of a line, the AI will recognize that
    you write a comment on every new line, and the AI will automatically complete
    the rest by simply breaking the line. AI can generate the following comments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In extreme cases, you do not need any specific prompt. Sometimes, all you have
    to do when you use GitHub Copilot is press *Tab* and *Enter*. However, if more
    formatting is done, it can go beyond explanation and have various possibilities,
    such as deriving documentation from code or reverse engineering table definitions
    from a database migration implementation, for example.
  prefs: []
  type: TYPE_NORMAL
- en: Code explanation by AI significantly elevates the overall quality of code by
    enhancing its readability and understandability. This feature plays a crucial
    role in narrowing the gap between intricate code and comprehensive documentation,
    offering an automated solution to make code accessible and intelligible to a broad
    spectrum of developers. By saving time and facilitating better code maintenance
    and collaboration, this capability highlights the transformative influence of
    AI in the coding process.
  prefs: []
  type: TYPE_NORMAL
- en: Strategies for maximizing AI efficiency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we delve into strategies aimed at boosting your mastery of
    AI tools within the realm of programming. By embracing an approach that emphasizes
    specificity, context awareness, and consistency, you will find significant enhancements
    in how you interact with AI, leading to streamlined coding processes and improved
    output quality. Specifically, offering clear, detailed instructions enhances the
    efficacy of AI tools, enabling them to better align with your expectations. A
    deep understanding and communication of the working context lead to more precise
    and applicable AI-generated suggestions. Furthermore, upholding a uniform coding
    style and adhering to established naming conventions greatly aid AI’s interpretation
    of your code, culminating in superior quality outcomes. These strategies collectively
    refine your engagement with AI, transforming it into a more efficient and effective
    partnership in programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, I want to touch upon the iterative process of improving interactions
    with AI. This process involves the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Requesting a suggestion from AI
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reviewing the results critically
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Making a decision to accept, reject, or manually adjust the suggestion
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applying the change or feedback for continuous improvement (kaizen)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By keeping these three principles in mind at each phase of interaction with
    AI, you will foster a more productive and harmonious collaboration. These practices
    blend traditional software engineering principles with the innovative capabilities
    of AI, ensuring that your code remains both human-friendly and optimized for AI
    assistance.
  prefs: []
  type: TYPE_NORMAL
- en: Be specific
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The clarity and specificity of instructions play a crucial role in the effectiveness
    of the tool.
  prefs: []
  type: TYPE_NORMAL
- en: AI-powered coding tools are designed to respond to the nuances of the instructions
    provided by the developer. Their ability to generate useful and accurate code
    is greatly enhanced when the prompts or comments are specific and clear. The more
    detailed the instruction, the better the AI can understand the intended outcome.
    This understanding directly influences the relevance and accuracy of the code
    suggestions provided by the AI tool.
  prefs: []
  type: TYPE_NORMAL
- en: In the example of a vague prompt, a developer might instruct an AI with a statement
    such as “*Sort this list*.” Such a prompt is unclear because it does not specify
    the contents of the list or how it should be sorted. The AI, faced with this ambiguity,
    might struggle to provide an accurate solution. However, when the instruction
    is more specific, such as “*Sort this list of integers in ascending order*,” it
    becomes much clearer. This specific prompt gives the AI precise information about
    the type of data in the list, which is integers, and the desired sorting criterion,
    which is ascending order. With these details, the AI is better equipped to generate
    a more accurate and relevant piece of code, aligned with the developer’s intent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two points can be considered to elicit better results:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tailoring prompts to the task**: When using AI tools, it is important to
    tailor the prompts to the specific task at hand. This includes specifying data
    types, desired outcomes, constraints, and any other relevant details that could
    impact code generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Avoiding ambiguity**: Specific instructions help in avoiding ambiguity, ensuring
    that the AI tool does not misinterpret the task or provide irrelevant code snippets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being specific in instructions is a key best practice when working with AI tools
    in software development. Detailed prompts enable these tools to provide more accurate
    and useful code suggestions, thereby enhancing the efficiency and effectiveness
    of the development process. By focusing on clarity and precision in their interactions
    with AI, developers can harness the full potential of these tools, leading to
    more productive and successful coding experiences.
  prefs: []
  type: TYPE_NORMAL
- en: Be context-aware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Embracing context awareness is paramount. This approach not only enhances the
    efficiency with which tools are utilized but also improves the precision of information
    relayed to AI. Context awareness in software design entails being mindful of the
    boundaries that delineate work, systems, and processes.
  prefs: []
  type: TYPE_NORMAL
- en: The significance of recognizing these boundaries is highlighted when taking
    into account the inherent limitations of both humans and AI. Simply put, this
    underscores that both entities have a finite capacity for processing information
    and must operate within appropriate contexts to function effectively.
  prefs: []
  type: TYPE_NORMAL
- en: '**Human limitations**: Humans have a cognitive threshold. When information
    overload occurs, selecting relevant information becomes challenging, leading to
    what is known as cognitive overload. By being mindful of one’s current context
    and processing information within limited contexts, humans can manage information
    more efficiently. Humans cannot provide AI with unlimited information, nor can
    they effectively sift through vast amounts of information received from AI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AI limitations**: Similarly, AI has its own limits in recognition, primarily
    defined by the token limits of current models. Tokens, the smallest units recognized
    by AI, such as characters or words, have a numerical limit in AI models at the
    time of writing. While AI can continue to generate contextually appropriate information,
    the generation must eventually terminate to ensure the output remains accurate
    and as intended, necessitating an awareness of AI’s performance boundaries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, I provide a practical checklist of items for use during interactions with
    AI. This checklist is vital for ensuring effective collaboration with AI, focusing
    on the right context for your development efforts. Getting into the habit of thinking
    about this in every interaction with the AI will help you have good interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Checklist for every AI interaction:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Does AI know it? – Explicit context provision**: Check if the AI is already
    familiar with the context of your task. If your task ventures beyond AI’s pre-existing
    knowledge, provide additional, detailed context to bridge the gap.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Is AI Capable? – Assessing AI limits**: Verify that your expectations align
    with what AI, such as GPT-4, can realistically achieve. Understanding the capabilities
    and limitations, especially regarding token counts and context expansiveness,
    is crucial.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`#file` and `#editor` to specify the relevant context and using an agent feature
    such as `@workspace` to expand context can enhance accuracy. Please verify the
    accuracy of your approach. The implementation of the specific tool is not covered
    here, but for GitHub Copilot, please refer to the documentation on the latest
    implementation in the *Further* *reading* section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How can I optimize It? – Quality management**: Evaluate and adjust the volume
    of text, characters, and data you are sending to AI. The goal is to optimize the
    amount of information—increasing what’s necessary and reducing what’s not—to ensure
    quality and efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of being context-aware cannot be overstated—it involves providing
    information in just the right measure and utilizing prompts and coding techniques
    to convey intentions with precision. AI-powered development tools such as GitHub
    Copilot stand as aids for engineers, facilitating the provision of rich context
    to AI, thus enhancing the tool’s utility and effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Reflecting on this, it becomes evident that applying these ideas to architecture
    and programming is not a new concept. This principle aligns with methodologies
    that have been in practice for a long time. By embracing a domain-driven development
    approach, one can engage in context-aware design. Additionally, the principle
    of loose coupling in architecture, which has been explored in various contexts,
    has evolved from language-specific domain separation to service-oriented architecture
    and further into microservices architecture.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, incorporating a context-aware approach into AI-powered coding can
    be considered a good strategy in the era of AI software development. Ultimately,
    this approach boils down to adopting good, existing architectural practices that
    are loosely coupled, boundary-conscious, and user-friendly for humans. By focusing
    on the integration of comprehensive context, allowing AI tools to gain a richer
    understanding of the project, developers can enhance the precision and usefulness
    of AI-generated suggestions. This not only enables developers to more effectively
    handle AI but also makes it easier for anyone to navigate and utilize AI capabilities
    to their fullest potential.
  prefs: []
  type: TYPE_NORMAL
- en: Be consistent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In an AI-enhanced programming environment, maintaining a consistent coding style
    and adopting AI-readable naming conventions are pivotal. This section explores
    how these practices enhance interactions with AI-powered coding tools and contribute
    to better code quality.
  prefs: []
  type: TYPE_NORMAL
- en: A consistent coding style, encompassing aspects such as indentation, naming
    conventions, and comment writing, is essential in software development. It not
    only ensures code readability for human developers but also plays a significant
    role in how effectively AI-powered coding tools can interpret and suggest code.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following code in Python could be considered a consistent
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This example demonstrates a clear and consistent use of `snake_case` naming
    and straightforward function naming, facilitating both human understanding and
    AI interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, the following code can be a bad example for AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the inconsistent naming and lack of clarity might result in
    less effective suggestions from AI. If one were to try to complete this content
    with auto-completion, the AI might be able to give an accurate answer for a simple
    example such as this, but if there were countless such random, meaningless notations
    scattered throughout the code base, mistakes could be made.
  prefs: []
  type: TYPE_NORMAL
- en: AI’s capability to interpret both natural and programming languages suggests
    that it reads code not only in its technical syntax but also as a form of natural
    language. This underscores the importance of clear and meaningful naming conventions
    in programming. By naming variables and functions in a way that is easily understandable,
    developers not only aid human comprehension but also enhance the ability of AI
    models to accurately discern the purpose and context of the code.
  prefs: []
  type: TYPE_NORMAL
- en: For example, effective AI-readable naming conventions involve using specific
    and descriptive names for variables and functions. This practice extends beyond
    just aiding human collaborators; it allows AI tools to interpret code with higher
    accuracy. Such clarity in naming is beneficial in reducing the ambiguity that
    might otherwise lead to inaccurate or irrelevant code suggestions by AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Concreteness and context are crucial. Avoid generic names and strive to provide
    clear context, which can be achieved through methods such as type hinting or adding
    explanatory comments. These practices significantly enhance the precision of AI-generated
    suggestions, leading to more relevant and functional code outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, it is clear that code that is easily understandable by AI is
    also inherently more comprehensible to humans. In essence, the advent of AI in
    coding does not always necessitate a reinvention of best practices in software
    engineering. The principles outlined in respected resources like O’Reilly’s *The
    Art of Readable Code: Simple and Practical Techniques for Writing Better Code*
    remain relevant and applicable in the AI era. Maintaining these tried and tested
    practices ensures that code remains accessible and understandable, both for human
    collaborators and AI tools.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI can help you code. However, you may have noticed that no matter how advanced
    AI gets, the approach to coding does not really change much. All you have to do
    is be the great engineer that you always have been. Additionally, using AI well
    will help you improve your skills.
  prefs: []
  type: TYPE_NORMAL
- en: AI will do more than you expect if you approach things with curiosity, so let’s
    work with AI to create a great future, and I hope this chapter will give you a
    hint.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*GitHub Copilot optimization with prompt crafting and context* *setting* ([https://code.visualstudio.com/docs/copilot/prompt-crafting](https://code.visualstudio.com/docs/copilot/prompt-crafting))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Art of Readable Code: Simple and Practical Techniques for Writing Better
    Code* by Dustin Boswell and Trevor Foucher ([https://www.oreilly.com/library/view/the-art-of/9781449318482/](https://www.oreilly.com/library/view/the-art-of/9781449318482/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
