- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Accelerate Productivity with AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 AI 加速生产力
- en: In this chapter, we embark on a journey to explore the exciting realm of AI-powered
    software development. In reality, although the application of large language models
    in coding is gradually becoming more apparent, it remains largely in the research
    and development phase. While we have focused on practical content so far, this
    chapter shifts our attention to the theories that facilitate a wonderful collaboration
    with AI. We aim to provide insights that will help you understand the context
    of AI in development correctly and master its use. With this foundation, let’s
    explore the world of AI-powered coding together.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将开始探索充满激动人心的 AI 驱动软件开发领域。实际上，尽管大型语言模型在编程中的应用逐渐变得越来越明显，但它仍然主要处于研发阶段。虽然到目前为止我们侧重于实践内容，但本章将把我们的注意力转向有助于与
    AI 进行出色协作的理论。我们的目标是提供帮助你正确理解 AI 在开发中的背景，并掌握其使用的洞察力。有了这个基础，让我们一起探索 AI 驱动编程的世界。
- en: The essence of AI’s role in coding fundamentally boils down to the age-old notion
    of *how to write good code*, which, in turn, relies on knowledge, skills, and
    experience. If you are looking for a universal magical technique to make AI write
    remarkable code, you might find that, in reality, such a thing probably does not
    exist. Furthermore, even when mentioning specific product features, it is important
    to recognize that the rapid pace of evolution in this field may quickly render
    newly acquired skills obsolete.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: AI 在编程中的角色本质上归结于古老的观点——*如何编写优质代码*，而这一点又依赖于知识、技能和经验。如果你在寻找一种通用的魔法技巧，让 AI 编写出卓越的代码，你可能会发现，实际上这样的技巧可能并不存在。此外，即使是在提到特定产品功能时，也需要意识到这个领域快速发展的步伐可能很快使新获得的技能变得过时。
- en: This book has consistently focused on the theme of collaboration. In this context,
    we maintain that focus, aiming to understand how to collaborate effectively with
    AI. The gateway to all communication starts with understanding your counterpart.
    By gaining a correct understanding of AI, setting appropriate expectations, and
    focusing on extracting the right information from AI, you will be able to refine
    your interactions with AI tools, regardless of how these tools evolve. As the
    author, it is my belief that we should aim to fundamentally understand AI rather
    than focusing solely on individual tips and tricks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书始终关注协作主题。在这个背景下，我们继续保持这一焦点，旨在理解如何与 AI 进行有效的合作。所有沟通的入口都始于了解你的对方。通过正确理解 AI、设定合理的期望，并专注于从
    AI 中提取正确的信息，你将能够优化与 AI 工具的互动，无论这些工具如何发展。作为作者，我认为我们应该旨在从根本上理解 AI，而不是单纯关注个别技巧和窍门。
- en: We will explore best practices for engaging with AI tools, with an emphasis
    on the subtleties of coding with AI assistance. AI-powered coding represents an
    exciting frontier with many uncharted territories. We encourage you to grasp the
    fundamentals and embark on coding alongside AI.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索与 AI 工具互动的最佳实践，重点关注使用 AI 协助编程的细微差别。AI 驱动的编程代表了一个令人兴奋的前沿领域，充满了许多未知的领域。我们鼓励你掌握基础，并与
    AI 一起开始编程。
- en: 'We will cover the following main headings in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: AI innovation in coding
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编程中的 AI 创新
- en: Exploring the capabilities and interaction with AI in coding
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 AI 在编程中的能力与互动
- en: Strategies for maximizing AI efficiency
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大化 AI 效率的策略
- en: AI innovation in coding
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程中的 AI 创新
- en: The introduction of LLMs by OpenAI has marked a pivotal moment in the evolution
    of software development. We delve into the aftermath of this groundbreaking innovation,
    exploring how it has reshaped the coding landscape.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 推出的 LLM（大型语言模型）标志着软件开发演变中的一个关键时刻。我们将深入探讨这一具有突破性创新的后续影响，探索它如何重塑编程领域。
- en: The impact of LLMs on coding
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 对编程的影响
- en: We can say the advent of LLMs has fundamentally changed how programming is approached
    and executed. With the capacity to understand and generate human-like text, these
    models have opened up new avenues in coding, making it more efficient and accessible.
    LLMs have significantly sped up the process of writing code. Developers can now
    leverage AI to quickly generate code snippets, reducing the time spent on routine
    or repetitive coding tasks. The introduction of LLMs has enabled developers to
    tackle coding challenges more creatively. By providing suggestions and alternative
    solutions, these models have become valuable tools in the problem-solving arsenal
    of programmers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说，LLM的出现从根本上改变了编程的方式和执行过程。凭借理解和生成类人文本的能力，这些模型为编码开辟了新的领域，使其更加高效且易于访问。LLM显著加快了编写代码的过程。开发者现在可以利用AI快速生成代码片段，减少在常规或重复编程任务上花费的时间。LLM的引入使得开发者能够更具创造性地解决编程挑战。通过提供建议和替代方案，这些模型已成为程序员问题解决工具箱中的宝贵工具。
- en: LLMs have introduced a new realm of AI-powered development, where developers
    collaborate with AI tools to enhance their coding workflow. This collaboration
    ranges from generating code snippets to offering insights into complex coding
    problems. For novice developers, AI serves as an educational tool, helping them
    learn coding patterns and best practices. This reduces the entry barriers to programming,
    making it more approachable for beginners. Additionally, for experienced developers,
    this AI integration is a powerful catalyst, enabling them to achieve more by augmenting
    their skills with advanced code suggestions, automating routine tasks, and providing
    deeper insights into code optimization and problem-solving. The combination of
    seasoned developer expertise and AI efficiency creates a synergy that pushes the
    boundaries of what can be accomplished in software development.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: LLM引入了AI驱动开发的新领域，开发者与AI工具合作，提升他们的编码工作流。这种合作涵盖了从生成代码片段到为复杂的编码问题提供见解。对于初学者来说，AI作为一种教育工具，帮助他们学习编码模式和最佳实践。这降低了编程的入门门槛，使其对初学者更加亲近。此外，对于经验丰富的开发者来说，这种AI集成是一个强大的催化剂，通过高级代码建议、自动化常规任务和提供更深层次的代码优化和问题解决见解，帮助他们取得更大的成就。经验丰富的开发者的专业知识与AI的高效性相结合，创造了一种协同效应，推动了软件开发领域的边界。
- en: The introduction of modern LLMs has revolutionized coding, transforming it from
    a purely manual endeavor to a more collaborative, efficient, and innovative process.
    This change has not only accelerated development but has also opened up new possibilities
    for creativity and problem-solving in the realm of software engineering. Additionally,
    this area is being extended right now to a variety of tasks, not only coding but
    also review and documentation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现代LLM的引入彻底改变了编码，将其从纯粹的手工工作转变为更加协作、高效和创新的过程。这一变化不仅加速了开发，还为软件工程领域的创造力和问题解决开辟了新的可能性。此外，这一领域目前正扩展到各种任务，不仅限于编码，还包括审查和文档编写。
- en: Understanding LLMs – A basic introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解LLM – 基本介绍
- en: In the context of AI-powered programming, LLMs have emerged as a pivotal innovation,
    reshaping our approach to software development. But what are LLMs? Let’s get to
    know this first.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI驱动的编程背景下，LLM作为一个关键创新浮出水面，重塑了我们对软件开发的方式。那么，LLM到底是什么呢？让我们先了解一下它。
- en: LLMs are advanced AI models designed to understand, interpret, and generate
    human-like text. These models are large not only in their size (often comprising
    billions of parameters) but also in their scope of training data and capabilities.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: LLM是先进的AI模型，旨在理解、解释和生成类人文本。这些模型不仅在规模上庞大（通常包含数十亿个参数），而且在训练数据的范围和能力上也极为广泛。
- en: LLMs such as **Generative Pre-trained Transformer** (**GPT**) are trained on
    vast datasets comprising a wide range of internet text. This training enables
    them to predict and generate text based on the input they receive, making them
    highly versatile in language understanding and generation. The core technology
    behind LLMs involves neural network architectures, specifically transformer models,
    which have revolutionized **Natural Language Processing** (**NLP**). These networks
    are adept at handling sequential data, making them ideal for language tasks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'To fully harness their potential, it is essential to understand what LLMs are
    fundamentally designed to do and what they are not. While AI may seem like magic,
    it is more akin to a mirror reflecting your own input; it is not a panacea that
    solves everything. You must approach it with the right expectations, guide it
    properly, and cleverly extract value. Now it is time to take a look at the essential
    characteristics of LLMs:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '**Word prediction engines**: At their core, LLMs are sophisticated engines
    designed to predict the next word in a sequence. This prediction capability is
    based on the extensive training they receive from vast datasets, enabling them
    to generate contextually relevant and coherent text.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Probabilistic, not deterministic**: Unlike deterministic models that always
    produce the same output for a given input, LLMs are probabilistic models. This
    means that they predict what comes next based on the probability of various possible
    continuations, leading to potential variations in output for the same input. This
    aspect underscores the inherently stochastic nature of LLMs, highlighting that
    the same “*context*” or input can lead to different outcomes, depending on the
    probabilistic determination of what comes next.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Not a Google search alternative**: It is crucial to note that LLMs are not
    replacements for search engines such as Google. They do not learn in the traditional
    sense or retain information for future output. Each response generated by a typical
    LLM is based on the input provided at that moment, without any memory of past
    interactions.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generation, not retrieval**: LLMs operate by generating responses each time
    rather than retrieving stored information. This means that their outputs are created
    anew based on the patterns they have learned during training.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs have a critical role in the context of coding, primarily due to their ability
    to predict the next sequence of characters or words. These models are not just
    versatile in handling natural languages, such as English, but extend their capabilities
    to a wide array of programming languages. In fact, the application of LLMs to
    programming languages is where their effectiveness is most recognized and highly
    anticipated.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: LLMs’ adaptability to different programming languages stems from their training
    on diverse datasets, which include not only natural language texts but also vast
    repositories of code. This enables them to understand the syntax and semantics
    of various programming languages, making them incredibly useful for tasks such
    as code completion, bug fixing, and even generating entire blocks of functional
    code.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: LLM对不同编程语言的适应性来源于其在多样化数据集上的训练，这些数据集不仅包括自然语言文本，还包括大量的代码库。这使得它们能够理解各种编程语言的语法和语义，从而在代码补全、修复bug，甚至生成完整的功能代码块等任务中变得非常有用。
- en: Moreover, LLMs can assist developers in translating requirements into code,
    providing suggestions based on best practices, and even offering creative solutions
    to complex programming challenges. Their predictive ability ensures that they
    can recommend the most relevant code snippets, streamline the coding process,
    and significantly enhance coding efficiency and accuracy.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LLM还可以帮助开发者将需求转化为代码，提供基于最佳实践的建议，甚至为复杂的编程挑战提供创造性解决方案。它们的预测能力确保能够推荐最相关的代码片段，简化编码过程，显著提高编码效率和准确性。
- en: 'In addition to the key capability, understanding the limitations and handling
    misconceptions is also important:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了关键能力之外，理解局限性和处理误解也是非常重要的：
- en: '**Not infallible**: The accuracy of LLMs is not absolute. While they can produce
    remarkably relevant and sophisticated outputs, there are instances where their
    predictions can be off the mark. They can sometimes create outputs that seem plausible
    but are actually inaccurate or nonsensical; a phenomenon sometimes referred to
    as **hallucination**.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并非万无一失**：LLM的准确性并非绝对。尽管它们能够生成非常相关和复杂的输出，但有时它们的预测也可能不准确。它们有时会生成看似合理但实际上不准确或毫无意义的输出，这种现象有时被称为**幻觉**。'
- en: '**Need for human oversight**: This potential for error underscores the importance
    of human oversight. Users of LLMs should be vigilant and discerning, capable of
    identifying and correcting instances where the model’s output may be misleading
    or incorrect.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**需要人类监督**：这种错误的潜力凸显了人类监督的重要性。LLM的用户应保持警觉和敏锐，能够识别和纠正模型输出中可能存在的误导或错误。'
- en: '**Appropriate use and expectation setting**: Understanding these limitations
    is key to setting realistic expectations and finding the most effective use cases
    for LLMs. They should be viewed as tools that augment and assist in tasks such
    as coding or text generation rather than as standalone solutions that operate
    with complete autonomy and accuracy.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适当使用和设定期望**：理解这些局限性是设定现实期望并找到LLM最有效使用场景的关键。它们应被视为增强和辅助任务的工具，比如编码或文本生成，而不是作为具有完全自主性和准确性的独立解决方案。'
- en: In essence, LLM is a powerful innovation, offering significant capabilities
    in text generation and language understanding. However, their effective use requires
    an awareness of their limitations and the critical role of human oversight in
    guiding their output.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，LLM是一项强大的创新，在文本生成和语言理解方面提供了显著的能力。然而，它们的有效使用需要意识到其局限性，并认识到人类监督在引导其输出中的关键作用。
- en: Application of LLMs in coding
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM在编码中的应用
- en: The integration of LLMs in the world of coding has seen one of its most significant
    applications in the form of AI-powered coding tools such as GitHub Copilot. This
    section explores how AI is redefining the coding experience.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在编码领域的集成最显著的应用之一是AI驱动的编码工具，如GitHub Copilot。本节探讨了AI如何重新定义编码体验。
- en: AI-powered tools designed to assist developers in writing code leverage the
    power of LLMs to provide real-time code suggestions, automating some aspects of
    coding and enhancing overall productivity. These tools, trained on a vast array
    of code repositories, interpret the context from the current coding environment
    and offer suggestions for the next lines of code, function implementations, or
    even entire classes and modules.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在帮助开发者编写代码的AI工具利用LLM的强大功能提供实时代码建议，自动化一些编码过程，并提高整体生产力。这些工具在大量代码库的训练基础上，能够解读当前编码环境中的上下文，并提供下一行代码、函数实现，甚至是整个类和模块的建议。
- en: The fundamental capability of these AI tools is that they work as plugins to
    editors such as Visual Studio Code, providing AI assistance as you code within
    the editor. The vision behind these tools includes integrating AI into all phases
    of the software development cycle, with a significant focus on their integration
    into the editor as a major feature. This approach represents a broader effort
    to harness AI for enhancing software development processes, aiming to make coding
    more efficient and accessible to developers at all skill levels.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Transforming the coding process
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AI-powered tools assist in enhancing the development process by streamlining
    a variety of coding tasks. Traditionally, coding involves research, reading documentation,
    and ensuring the correctness of the code. These tools help optimize these activities
    in several key areas:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '**Increasing speed and efficiency**: Developers can speed up the coding process
    with these tools. They help reduce the time spent on repetitive code patterns
    and offer quick solutions and suggestions, freeing up developers to tackle more
    complex and innovative work.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Facilitating learning and exploration**: For newcomers or those delving into
    new programming languages or frameworks, these AI tools serve as educational aids.
    They provide syntactically accurate code snippets and show best practices in action.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reducing cognitive load**: AI-powered tools tackle the more routine aspects
    of coding, alleviating the mental burden developers face. This reduction in cognitive
    load enables developers to concentrate their mental energy on tackling more intricate
    and challenging problems.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expanding possibilities**: Through their suggestions, these tools not only
    assist with code completion but also stimulate creative thinking. They introduce
    developers to alternative problem-solving approaches and expose them to new coding
    patterns and practices they might not have previously encountered or considered.
    This expansion of possibilities can lead to more innovative solutions and a broadening
    of the developer’s skill set.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By minimizing the need for frequent diversions to look up information and by
    offering pertinent code suggestions, these AI-powered tools support a more focused
    and efficient workflow. This not only leads to better code quality but also enhances
    developer productivity, establishing these tools as essential components in contemporary
    software development.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative code creation
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When comparing code completion tools to chat-based tools, it is clear that
    each provides a unique set of offerings to developers. Here are the major differences:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Code completion experience**: Tools equipped with code completion capabilities
    can predict the next words or code blocks directly within the editor. They offer
    incremental suggestions that users can quickly accept or reject, streamlining
    the coding process. This is somewhat similar to mob programming alongside an experienced
    engineer or engaging in pair programming with real-time screen sharing, which
    promotes an interactive and dynamic coding environment:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Code completion experience in GitHub Copilot](img/B21203_07_01.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Code completion experience in GitHub Copilot
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**Chat experience**: In contrast, the chat experience resembles consulting
    with a senior engineer via platforms such as Slack or Teams or even delegating
    implementation tasks. Some tools also feature a chat interface, enabling developers
    to tap into both direct code assistance and conversational guidance:'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Chat experience in GitHub Copilot](img/B21203_07_02.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Chat experience in GitHub Copilot
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Copilot, the developer-centric designed tool, supports both chat and
    code completion experiences. ChatGPT, known for its versatility beyond coding,
    requires users to carefully craft prompts to guide their responses. In contrast,
    AI-powered developer tools stand out for enhancing the developer experience within
    the editor, focusing on how engineers can seamlessly integrate their current work
    context with AI assistance.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: They are engineered to support developers by intuitively understanding the context
    of their work and making it easier to communicate this context to the AI with
    fewer prompts. The more code developers write, the more these tools can tailor
    their assistance to align with the developers’ objectives and the specifics of
    their work context.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Prompt and context
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concept of **prompts** has gained widespread attention with the advent of
    generative AI technologies. Among the various terms you might have encountered,
    “Prompt Engineering” stands out as a particularly common reference. However, what
    is prompt engineering really? Prompt engineering is the art of designing inputs
    or prompts for AI models to generate desired outputs. It is about crafting questions
    or statements in a way that guides the AI to understand and respond in a specific
    manner. This is crucial because the quality and relevance of AI outputs are highly
    dependent on how the prompts are structured. At the same time, however, it is
    also true that there are excessive expectations for this, and it was treated like
    a buzzword in the early days.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: The term prompt engineering seems to me to be a mixture of diverse things. I
    will explain them here.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Two types of prompt engineering
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the evolution of AI and machine learning, prompt engineering has emerged
    as an important discipline that shapes how we interact with and extract value
    from AI models. There are two types of prompt engineering. Although not an academic
    classification, I will refer to them here as **reusable prompt engineering** and
    **disposable prompt engineering**, each for different applications and requirements.
    It is important to recognize the difference between these and to know and use
    these objectives in your daily interactions with the AI.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Reusable prompt engineering
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Reusable prompt engineering is designed for scenarios where prompts are repeatedly
    used in similar contexts. This is common in consumer-facing AI applications, automated
    systems, and AI-to-machine interactions. The aim here is to create prompts that
    consistently elicit accurate and relevant responses from AI, regardless of minor
    variations in input or context.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: In reusable prompt engineering, near-perfect accuracy is essential. This is
    particularly true for machine consumers, where AI responses trigger other functions
    or processes. Similarly, in B2C applications, high accuracy is crucial to maintain
    user engagement and prevent frustration or confusion.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: The primary challenge in this type of prompt engineering is maintaining stability
    and consistency in AI responses. This often requires a deep understanding of the
    AI model’s capabilities and limitations. Engineers who build prompts must also
    consider the variability in user inputs and contexts, ensuring that the AI can
    handle these variations without significant loss of accuracy.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: In reusable prompt engineering, the emphasis is primarily on *how*—crafting
    prompts to ensure reliable and accurate responses. This focus is critical because
    the *what* and *why* can often be unpredictable, particularly in scenarios involving
    a broad and diverse user base. The prompts must be designed to handle a wide range
    of inputs from an unspecified number of users, each with their unique needs and
    ways of interacting with the AI system.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: The term prompt engineering in the world is used in this context, especially
    in a narrow sense. It is about how to refine the instructions to the AI in order
    to extract information from it with a high degree of accuracy. However, in the
    actual development field, there is no need to spend time refining prompts that
    are used only once. Prompt engineering in development requires a different context.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Disposable prompt engineering
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Disposable prompt engineering is characterized by the creation of one-time-use
    prompts. These are typically crafted by developers or users for specific, often
    unique, situations. Here, the emphasis shifts from broad applicability and consistency
    to specificity and immediate relevance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: This type involves a high degree of creativity and adaptability. Developers
    create prompts on the fly, tailoring them to specific tasks or problems. This
    requires a deep understanding of the context and objectives (the why and what)
    and a flexible approach to interacting with the AI.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: In disposable prompt engineering, context is king. The prompts are often designed
    to address specific issues or to generate unique outputs. As such, the engineer
    must provide the AI with sufficient context to understand and respond appropriately
    to the task at hand. In the context of development, you will need to give new
    instructions to the AI each time you do something creative with each development
    task. After all, you will find that when you use AIs in your development, you
    have little need to master each and every type of prompt engineering. What is
    more important is the context.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: In summary, it is important to acknowledge that mastering the intricate techniques
    of prompt engineering may not be efficient for every goal. Again, for daily tasks
    requiring fresh ideas and essentially serving as one-off needs, dedicating extensive
    time to perfecting prompts might not be essential. Conversely, in projects such
    as developing an app infused with AI, the quality of prompts is crucial. In these
    instances, it is beneficial to continually refine them to ensure optimal interaction
    with the AI component. This process often involves trial and error, along with
    a sophisticated understanding of how the AI model may interpret various prompts.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: The importance of context
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In AI-powered development, particularly in programming, the context in which
    a piece of code exists is paramount. Context includes the surrounding information
    and environment of the code, extending beyond the immediate codebase to encompass
    project specifications, coding standards, and intended functionality. The effectiveness
    of AI hinges on its ability to interpret and respond to this context.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: The context provided to an AI system determines the relevance and accuracy of
    its responses and suggestions. In the absence of adequate context, AI tools may
    generate outputs that are technically correct but misaligned with the project’s
    goals or requirements.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: As developers integrate AI into their workflow, it is essential to recognize
    their role in providing clear and relevant context. This responsibility involves
    understanding that AI, while powerful, is not infallible or omniscient. It requires
    input that accurately reflects the problem at hand and the desired outcomes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Developers should approach AI as a collaborative tool, guiding it through a
    well-defined context to ensure that its contributions are aligned with project
    objectives. This involves critically evaluating AI suggestions and adapting them
    to fit the specific nuances of their projects.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'The following would be important to include context:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '**Provide detailed comments**: Incorporate comprehensive comments into the
    code that explain not just what the code does but also the purpose behind it.
    This helps AI tools understand the intent behind the code.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use descriptive naming conventions**: Choose variable and function names
    that clearly indicate their purpose and usage. This aids AI in generating more
    relevant and readable code.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Document code thoroughly**: Ensure that the codebase is well-documented,
    outlining the broader project objectives, coding standards, and specific functionalities.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frame problems clearly**: When seeking AI assistance, define the problem
    as specifically as possible. This includes stating the desired outcomes and any
    relevant constraints or considerations.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effectively leveraging AI in programming requires a balanced approach that recognizes
    AI as a powerful assistant but not a complete substitute for human expertise.
    By providing clear, detailed context and maintaining critical oversight, developers
    can maximize the benefits of AI-powered tools. This approach ensures that AI serves
    as a catalyst for enhanced productivity and creativity in software development,
    complementing human capabilities rather than attempting to replace them.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: The paramount importance of context in AI-powered programming cannot be overstated.
    As AI continues to evolve, its capacity to interpret and utilize context will
    determine the extent of its impact on software development.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: For developers to truly harness the potential of AI in programming, a deep understanding
    of programming and technology is essential. While prompt engineering significantly
    amplifies productivity, it is not a standalone solution. The ability to provide
    clear and detailed context to AI is a skill that synergizes with a developer’s
    technical expertise. Ultimately, the effectiveness of AI tools in augmenting development
    work hinges on the developer’s foundational knowledge and experience in coding.
    This combination of technical proficiency and skillful prompt engineering is key
    to maximizing the benefits of AI in software development.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the capabilities and interaction with AI in coding
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section is dedicated to providing developers with in-depth insights and
    strategies for effectively leveraging AI within their coding projects, focusing
    on its features and interaction dynamics. Whether it involves integrating AI for
    routine coding tasks or utilizing it for the more intricate and imaginative facets
    of programming, this section intends to offer comprehensive guidance on making
    AI a transformative element in your coding practices.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore the expansive capabilities of AI in coding and learn the best
    practices for interacting with AI tools, enhancing not only the productivity and
    quality of your projects but also your overall experience as a developer.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Code completion – The foundation of AI-powered coding
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike ChatGPT, which requires full context in the prompt for each interaction,
    code completion in programming environments is deeply integrated with the code
    editor. AI-powered coding tools dynamically collect necessary data from the code
    you are writing and seamlessly communicate with the backend LLM. This integration
    offers an experience akin to pair programming or mob programming with an AI collaborator.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: The typical AI tool continuously analyzes the code within the editor, understanding
    the immediate context to offer relevant suggestions. This contextual awareness
    is key to the effectiveness of code completion. In AI tools, where context is
    important, the most important thing is how the context was collected from the
    editor. Sometimes, humans tend to focus on the accuracy of the model behind it.
    That is never a mistake; the smarter the AI, the better. However, as AI develops
    in the future, any tool will be able to perform certain tasks. What will stand
    out in that case is its excellence as a data collection tool. Therefore, in code
    completion, it is important to know how the AI-powered coding assistant tool collects
    information from the editor and to determine whether code completion should take
    this into account.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: As developers type code, an AI-powered coding tool suggests potential code snippets
    that complete or extend the code. Typically, this functionality is not just about
    speeding up the typing process; it is about offering intelligent, contextually
    relevant suggestions that can improve code quality and efficiency.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of code completion in action. Let’s create a file `calc.js`
    and write the following in JavaScript:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For example, AI code-completion would complement the contents of a function
    as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The AI model behind code completion has been exposed to a vast array of code,
    but it is important to clarify that this exposure means it has been “*trained
    on data*” rather than having fundamentally “*learned*” in the traditional sense.
    Essentially, it has become adept at recognizing patterns unique to coding through
    the analysis of these extensive code repositories. By utilizing LLMs, the model
    can discern patterns, best practices, and common coding paradigms to generate
    suggestions. As a predictive engine for the next word or sequence in code, the
    quality of its suggestions is directly influenced by the quality of the input
    code. In essence, the output quality reflects the quality of the code data it
    was trained on, highlighting that its capability to provide relevant suggestions
    depends on recognizing patterns within the training data.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Code generation—the ability of AI-powered coding tools to interpret and respond
    to natural language—is remarkable. The breakthrough with AI is its capacity to
    understand natural language as it is presented, offering code suggestions based
    on that understanding rather than relying on static analysis, as with traditional
    non-AI code completion tools such as IntelliSense. Developers can detail the functionality,
    parameters, and expected outcomes of a code segment through comments, directing
    the AI to generate relevant code.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: When we talk about “*code generation*,” it includes what was referred to in
    the previous section as code completion, but here we are discussing it in a broader
    sense, focusing on generating code from natural language and various types of
    information.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of this feature depends on the precision and clarity of the
    instructions provided. Well-defined and explicit comments empower AI-powered coding
    tools to produce more accurate and suitable code responses.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: This is where the importance of your knowledge, experience, and approach to
    prompt crafting becomes evident. It is crucial to leverage your critical thinking
    and logical writing skills in a manner that the AI can comprehend.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let’s create a JavaScript file named `calc.js`, as follows, and
    write the comments you want to implement:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If AI-powered tools can generate code, it will look like the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Providing examples within other sections of the code or in comments can be extremely
    helpful. Additionally, one of the strengths of AI-powered coding tools lies in
    their ability to generate code based on structured examples. This feature proves
    especially beneficial in situations such as developing models from given data
    examples.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, consider the following comment:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, AI can produce the following model. The following example will output
    Python if you write Python in the file `user.py`, but similarly, if you write
    a specific language, such as `user.js` or `user.rb`, the same implementation would
    be carried out for a different language:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This indicates that the distance between the definition of the implementation
    and the implementation itself is getting very close.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to definitions, table definitions can be turned into SQL queries
    for database tables, cloud infrastructure definitions can be turned into YAML
    files for Terraform, and so on.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: For example, from a given JSON example, it is possible to generate commands
    to create a model for Ruby on Rails.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the given JSON example:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'All you have to do is provide the prompt “*Generate a rails command to create
    a new user*” for this example, and AI will create a ready-to-use command in CLI
    as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The code generation capability represents a significant advancement in AI-powered
    coding. By interpreting descriptive comments and structured examples, AI can generate
    accurate and functional code, reducing manual coding efforts and enhancing the
    efficiency of the development process.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Code explanation
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI has the capability to analyze existing code and automatically generate explanations
    that clarify the code’s functionality. This feature proves to be invaluable for
    understanding code that is not adequately documented or for demystifying complex
    algorithms for other developers. These generated explanations assist in simplifying
    complex code into more comprehensible segments, thereby facilitating a better
    understanding of the logic and intent behind the code for others.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Such a capability is instrumental in reducing the onboarding time for new team
    members, accelerating the comprehension of code for first-time viewers, and proving
    useful in scenarios where there is a noticeable gap between the specification
    and the actual code. Moreover, it enhances the value of the code by providing
    explanations for previously unmaintained or obscure code, thereby making its functionality
    clearer.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of writing an algorithm in Python by creating a file, `eratosthenes.py`,
    and specifically considering generating explanations for the Sieve of the Eratosthenes
    algorithm, which was originally presented without explanation:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you write a comment at the beginning of a line, the AI will recognize that
    you write a comment on every new line, and the AI will automatically complete
    the rest by simply breaking the line. AI can generate the following comments:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In extreme cases, you do not need any specific prompt. Sometimes, all you have
    to do when you use GitHub Copilot is press *Tab* and *Enter*. However, if more
    formatting is done, it can go beyond explanation and have various possibilities,
    such as deriving documentation from code or reverse engineering table definitions
    from a database migration implementation, for example.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Code explanation by AI significantly elevates the overall quality of code by
    enhancing its readability and understandability. This feature plays a crucial
    role in narrowing the gap between intricate code and comprehensive documentation,
    offering an automated solution to make code accessible and intelligible to a broad
    spectrum of developers. By saving time and facilitating better code maintenance
    and collaboration, this capability highlights the transformative influence of
    AI in the coding process.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Strategies for maximizing AI efficiency
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we delve into strategies aimed at boosting your mastery of
    AI tools within the realm of programming. By embracing an approach that emphasizes
    specificity, context awareness, and consistency, you will find significant enhancements
    in how you interact with AI, leading to streamlined coding processes and improved
    output quality. Specifically, offering clear, detailed instructions enhances the
    efficacy of AI tools, enabling them to better align with your expectations. A
    deep understanding and communication of the working context lead to more precise
    and applicable AI-generated suggestions. Furthermore, upholding a uniform coding
    style and adhering to established naming conventions greatly aid AI’s interpretation
    of your code, culminating in superior quality outcomes. These strategies collectively
    refine your engagement with AI, transforming it into a more efficient and effective
    partnership in programming.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, I want to touch upon the iterative process of improving interactions
    with AI. This process involves the following:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Requesting a suggestion from AI
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reviewing the results critically
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Making a decision to accept, reject, or manually adjust the suggestion
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Applying the change or feedback for continuous improvement (kaizen)
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By keeping these three principles in mind at each phase of interaction with
    AI, you will foster a more productive and harmonious collaboration. These practices
    blend traditional software engineering principles with the innovative capabilities
    of AI, ensuring that your code remains both human-friendly and optimized for AI
    assistance.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Be specific
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The clarity and specificity of instructions play a crucial role in the effectiveness
    of the tool.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: AI-powered coding tools are designed to respond to the nuances of the instructions
    provided by the developer. Their ability to generate useful and accurate code
    is greatly enhanced when the prompts or comments are specific and clear. The more
    detailed the instruction, the better the AI can understand the intended outcome.
    This understanding directly influences the relevance and accuracy of the code
    suggestions provided by the AI tool.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: In the example of a vague prompt, a developer might instruct an AI with a statement
    such as “*Sort this list*.” Such a prompt is unclear because it does not specify
    the contents of the list or how it should be sorted. The AI, faced with this ambiguity,
    might struggle to provide an accurate solution. However, when the instruction
    is more specific, such as “*Sort this list of integers in ascending order*,” it
    becomes much clearer. This specific prompt gives the AI precise information about
    the type of data in the list, which is integers, and the desired sorting criterion,
    which is ascending order. With these details, the AI is better equipped to generate
    a more accurate and relevant piece of code, aligned with the developer’s intent.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two points can be considered to elicit better results:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '**Tailoring prompts to the task**: When using AI tools, it is important to
    tailor the prompts to the specific task at hand. This includes specifying data
    types, desired outcomes, constraints, and any other relevant details that could
    impact code generation.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Avoiding ambiguity**: Specific instructions help in avoiding ambiguity, ensuring
    that the AI tool does not misinterpret the task or provide irrelevant code snippets.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being specific in instructions is a key best practice when working with AI tools
    in software development. Detailed prompts enable these tools to provide more accurate
    and useful code suggestions, thereby enhancing the efficiency and effectiveness
    of the development process. By focusing on clarity and precision in their interactions
    with AI, developers can harness the full potential of these tools, leading to
    more productive and successful coding experiences.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Be context-aware
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Embracing context awareness is paramount. This approach not only enhances the
    efficiency with which tools are utilized but also improves the precision of information
    relayed to AI. Context awareness in software design entails being mindful of the
    boundaries that delineate work, systems, and processes.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: The significance of recognizing these boundaries is highlighted when taking
    into account the inherent limitations of both humans and AI. Simply put, this
    underscores that both entities have a finite capacity for processing information
    and must operate within appropriate contexts to function effectively.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '**Human limitations**: Humans have a cognitive threshold. When information
    overload occurs, selecting relevant information becomes challenging, leading to
    what is known as cognitive overload. By being mindful of one’s current context
    and processing information within limited contexts, humans can manage information
    more efficiently. Humans cannot provide AI with unlimited information, nor can
    they effectively sift through vast amounts of information received from AI.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AI limitations**: Similarly, AI has its own limits in recognition, primarily
    defined by the token limits of current models. Tokens, the smallest units recognized
    by AI, such as characters or words, have a numerical limit in AI models at the
    time of writing. While AI can continue to generate contextually appropriate information,
    the generation must eventually terminate to ensure the output remains accurate
    and as intended, necessitating an awareness of AI’s performance boundaries.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, I provide a practical checklist of items for use during interactions with
    AI. This checklist is vital for ensuring effective collaboration with AI, focusing
    on the right context for your development efforts. Getting into the habit of thinking
    about this in every interaction with the AI will help you have good interactions.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Checklist for every AI interaction:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '**Does AI know it? – Explicit context provision**: Check if the AI is already
    familiar with the context of your task. If your task ventures beyond AI’s pre-existing
    knowledge, provide additional, detailed context to bridge the gap.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Is AI Capable? – Assessing AI limits**: Verify that your expectations align
    with what AI, such as GPT-4, can realistically achieve. Understanding the capabilities
    and limitations, especially regarding token counts and context expansiveness,
    is crucial.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`#file` and `#editor` to specify the relevant context and using an agent feature
    such as `@workspace` to expand context can enhance accuracy. Please verify the
    accuracy of your approach. The implementation of the specific tool is not covered
    here, but for GitHub Copilot, please refer to the documentation on the latest
    implementation in the *Further* *reading* section.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How can I optimize It? – Quality management**: Evaluate and adjust the volume
    of text, characters, and data you are sending to AI. The goal is to optimize the
    amount of information—increasing what’s necessary and reducing what’s not—to ensure
    quality and efficiency.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of being context-aware cannot be overstated—it involves providing
    information in just the right measure and utilizing prompts and coding techniques
    to convey intentions with precision. AI-powered development tools such as GitHub
    Copilot stand as aids for engineers, facilitating the provision of rich context
    to AI, thus enhancing the tool’s utility and effectiveness.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Reflecting on this, it becomes evident that applying these ideas to architecture
    and programming is not a new concept. This principle aligns with methodologies
    that have been in practice for a long time. By embracing a domain-driven development
    approach, one can engage in context-aware design. Additionally, the principle
    of loose coupling in architecture, which has been explored in various contexts,
    has evolved from language-specific domain separation to service-oriented architecture
    and further into microservices architecture.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: In summary, incorporating a context-aware approach into AI-powered coding can
    be considered a good strategy in the era of AI software development. Ultimately,
    this approach boils down to adopting good, existing architectural practices that
    are loosely coupled, boundary-conscious, and user-friendly for humans. By focusing
    on the integration of comprehensive context, allowing AI tools to gain a richer
    understanding of the project, developers can enhance the precision and usefulness
    of AI-generated suggestions. This not only enables developers to more effectively
    handle AI but also makes it easier for anyone to navigate and utilize AI capabilities
    to their fullest potential.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Be consistent
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In an AI-enhanced programming environment, maintaining a consistent coding style
    and adopting AI-readable naming conventions are pivotal. This section explores
    how these practices enhance interactions with AI-powered coding tools and contribute
    to better code quality.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: A consistent coding style, encompassing aspects such as indentation, naming
    conventions, and comment writing, is essential in software development. It not
    only ensures code readability for human developers but also plays a significant
    role in how effectively AI-powered coding tools can interpret and suggest code.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following code in Python could be considered a consistent
    code:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This example demonstrates a clear and consistent use of `snake_case` naming
    and straightforward function naming, facilitating both human understanding and
    AI interpretation.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, the following code can be a bad example for AI:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In this example, the inconsistent naming and lack of clarity might result in
    less effective suggestions from AI. If one were to try to complete this content
    with auto-completion, the AI might be able to give an accurate answer for a simple
    example such as this, but if there were countless such random, meaningless notations
    scattered throughout the code base, mistakes could be made.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: AI’s capability to interpret both natural and programming languages suggests
    that it reads code not only in its technical syntax but also as a form of natural
    language. This underscores the importance of clear and meaningful naming conventions
    in programming. By naming variables and functions in a way that is easily understandable,
    developers not only aid human comprehension but also enhance the ability of AI
    models to accurately discern the purpose and context of the code.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: For example, effective AI-readable naming conventions involve using specific
    and descriptive names for variables and functions. This practice extends beyond
    just aiding human collaborators; it allows AI tools to interpret code with higher
    accuracy. Such clarity in naming is beneficial in reducing the ambiguity that
    might otherwise lead to inaccurate or irrelevant code suggestions by AI systems.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Concreteness and context are crucial. Avoid generic names and strive to provide
    clear context, which can be achieved through methods such as type hinting or adding
    explanatory comments. These practices significantly enhance the precision of AI-generated
    suggestions, leading to more relevant and functional code outputs.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, it is clear that code that is easily understandable by AI is
    also inherently more comprehensible to humans. In essence, the advent of AI in
    coding does not always necessitate a reinvention of best practices in software
    engineering. The principles outlined in respected resources like O’Reilly’s *The
    Art of Readable Code: Simple and Practical Techniques for Writing Better Code*
    remain relevant and applicable in the AI era. Maintaining these tried and tested
    practices ensures that code remains accessible and understandable, both for human
    collaborators and AI tools.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI can help you code. However, you may have noticed that no matter how advanced
    AI gets, the approach to coding does not really change much. All you have to do
    is be the great engineer that you always have been. Additionally, using AI well
    will help you improve your skills.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: AI will do more than you expect if you approach things with curiosity, so let’s
    work with AI to create a great future, and I hope this chapter will give you a
    hint.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*GitHub Copilot optimization with prompt crafting and context* *setting* ([https://code.visualstudio.com/docs/copilot/prompt-crafting](https://code.visualstudio.com/docs/copilot/prompt-crafting))'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Art of Readable Code: Simple and Practical Techniques for Writing Better
    Code* by Dustin Boswell and Trevor Foucher ([https://www.oreilly.com/library/view/the-art-of/9781449318482/](https://www.oreilly.com/library/view/the-art-of/9781449318482/))'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
