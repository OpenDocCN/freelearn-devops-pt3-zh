<html><head></head><body>
		<div id="_idContainer133">
			<h1 id="_idParaDest-217"><em class="italic"><a id="_idTextAnchor216"/>Chapter 9</em>: Deploying to Any Platform</h1>
			<p>Now that you have learned how to use GitHub Actions as an automation engine and GitHub Packages to easily share code and containers, we can complete our <strong class="bold">Continuous Integration/Continuous Delivery</strong> (<strong class="bold">CI/CD</strong>) capabilities by automating deployments.</p>
			<p>In this chapter, I'll show you how to easily deploy to any cloud or platform in a secure and compliant way.</p>
			<p>In this chapter, we will cover the following main topics:</p>
			<ul>
				<li>Staged deployments</li>
				<li>Automating your deployments</li>
				<li>Infrastructure as Code</li>
				<li>How to deploy to Azure App Service</li>
				<li>How to deploy to AWS <strong class="bold">Elastic Container Service</strong> (<strong class="bold">ECS</strong>)</li>
				<li>How to deploy to <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>)</li>
				<li>Measuring success<p class="callout-heading">CI/CD</p><p class="callout">CI means that every time you push code changes to your repository, the code is built and tested, and the output is packaged as a build artifact. In CD, you automatically deploy your build artifacts to your environments whenever a new build artifact is created.</p><p class="callout">When practicing CI/CD, the <a id="_idIndexMarker584"/>development and delivery phases are completely automated. The code is ready to be deployed to production at any time.</p><p class="callout">There are various definitions that distinguish between <strong class="bold">continuous delivery</strong> and <strong class="bold">continuous deployment</strong> (both <strong class="bold">CD</strong>) – but these definitions are not consistent in the literature and only add little to no value to the topic.</p></li>
			</ul>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor217"/>Staged deployments</h1>
			<p>A <strong class="bold">stage</strong> or <strong class="bold">tier</strong> is an <a id="_idIndexMarker585"/>environment in which a piece of software is deployed and <a id="_idIndexMarker586"/>executed. Typical stages include <strong class="source-inline">Development</strong>, <strong class="source-inline">Test</strong>, <strong class="source-inline">Staging</strong> (or <strong class="source-inline">Pre-Production</strong>), and <strong class="source-inline">Production</strong>. Typically, the <strong class="source-inline">Staging</strong>, or <strong class="source-inline">Pre-Production</strong>, stage is a <a id="_idIndexMarker587"/>complete mirror of the production environment, and sometimes, it is used for zero-downtime deployments by switching the two environments using load balancing. Typically, stages that are closer to production require manual approval before deployment.</p>
			<p>If a company works with feature flags (please refer to <a href="B17827_10_Epub.xhtml#_idTextAnchor239"><em class="italic">Chapter 10</em></a>, <em class="italic">Feature Flags and the Feature Lifecycle</em>) and CD, normally, the number of stages decreases. Instead of stages, we can talk about <strong class="bold">ring-based deployments</strong> or <strong class="bold">scaling units</strong>. The idea of ring-based deployments is<a id="_idIndexMarker588"/> that you have customers in<a id="_idIndexMarker589"/> different productions rings. You deploy your update to one ring and automatically monitor the system for unexpected exceptions or unusual metrics such as CPU or memory usage. Additionally, you can run automated tests in the production environment. If there are no errors, the release process is continuous and deploys to the next ring. When discussing ring-based deployments, often, we imply that no manual approval is involved. However, there can also be manual approval between the rings.</p>
			<p>In GitHub, you can perform staged and<a id="_idIndexMarker590"/> ring-based deployments using <strong class="bold">Environments</strong>. You can view, configure, or create new ones in your repository under <strong class="bold">Settings</strong> | <strong class="bold">Environments</strong>.</p>
			<p>For each environment, you can define the following:</p>
			<ul>
				<li><strong class="bold">Required reviewers</strong>: These<a id="_idIndexMarker591"/> include up to five users or teams as manual approvers. One of these approvers must approve the deployment before it is executed.</li>
				<li><strong class="bold">Wait timer</strong>: This refers to a<a id="_idIndexMarker592"/> grace period that the deployment will wait before executing. The maximum time is 43,200 minutes or 30 days. Additionally, you can use an API to cancel the deployment if you find any errors at a previous stage.</li>
				<li><strong class="bold">Deployment branches</strong>: Here, you<a id="_idIndexMarker593"/> can restrict what branches are deployed to an environment. You can select all <strong class="source-inline">Protected branches</strong> or define your own pattern. The pattern can include wildcards (such as <strong class="source-inline">release/*</strong>).</li>
				<li><strong class="bold">Environment secrets</strong>: Secrets in<a id="_idIndexMarker594"/> an environment override secrets from the repository or organization scope. The secrets are only loaded after the required reviewers have approved the deployment.</li>
			</ul>
			<p>The configuration looks similar to <em class="italic">Figure 9.1</em>:</p>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/B17827_09_001.jpg" alt="Figure 9.1 – Configuring an environment in GitHub&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – Configuring an environment in GitHub</p>
			<p>In the workflow file, you specify the environment at the job level:</p>
			<pre class="source-code">jobs:</pre>
			<pre class="source-code">  deployment:</pre>
			<pre class="source-code">    runs-on: ubuntu-latest</pre>
			<pre class="source-code">    environment: prod</pre>
			<p>Additionally, you can specify a URL that is then displayed on the overview page:</p>
			<pre class="source-code">jobs:</pre>
			<pre class="source-code">  deployment:</pre>
			<pre class="source-code">    runs-on: ubuntu-latest</pre>
			<pre class="source-code">    environment: </pre>
			<pre class="source-code">      name: production</pre>
			<pre class="source-code">      url: https://writeabout.net</pre>
			<p>With the <strong class="source-inline">needs</strong> keyword, you<a id="_idIndexMarker595"/> can define dependencies between jobs and, therefore, environments (see <em class="italic">Figure 9.2</em>):</p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/B17827_09_002.jpg" alt="Figure 9.2 – The overview page for staged deployments&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.2 – The overview page for staged deployments</p>
			<p>The status of the environments is also displayed on the home page of the repository (see <em class="italic">Figure 9.3</em>):</p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/B17827_09_003.jpg" alt="Figure 9.3 – Environments on the home page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – Environments on the home page</p>
			<p>If you want to play around with the environments, you can run the <strong class="bold">Staged Deployment</strong> workflow in the fork of <a href="https://github.com/wulfland/AccelerateDevOps/">https://github.com/wulfland/AccelerateDevOps/</a> and add yourself as a required reviewer for some stages.</p>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor218"/>Automating your deployments</h1>
			<p>If I ask my customers<a id="_idIndexMarker596"/> whether they have automated their deployments, normally, the answer is <em class="italic">yes</em>. However, on closer look, automation means <em class="italic">we have a script</em>, or <em class="italic">we have an answer file for an installer</em>. That is only partial automation. As long as someone has to log in to a server, create accounts or DNS records, or manually configure a firewall, your deployment is not automated!</p>
			<p>Humans make mistakes – machines do not! Make sure you automate all the steps of your deployment and not just the last steps. Since GitHub Actions is the perfect automation engine, it is a good practice to have a workflow execute all of your automated deployments.</p>
			<h1 id="_idParaDest-220"><a id="_idTextAnchor219"/>How to deploy to Azure App Service </h1>
			<p>To get you started with<a id="_idIndexMarker597"/> automated deployments with GitHub Actions, I created three hands-on labs:</p>
			<ul>
				<li>Deploying to Azure App Service</li>
				<li>Deploying to AWS ECS</li>
				<li>Deploying to GKE</li>
			</ul>
			<p>All hands-on labs assume that you have an account set up in the specified cloud. If you have a single-cloud strategy, you can simply jump to the hands-on step that's relevant for you and skip the others.</p>
			<p>The step-by-step instructions for the hands-on lab are located in GitHub at <a href="https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_Azure_App_Service.md">https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_Azure_App_Service.md</a>. It is recommended that you follow the steps there, as it provides links that are easy to copy and paste. Here, I will explain the background as a step-by-step guide with a focus on how to deploy the application.</p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor220"/>Deployment of Azure resources</h2>
			<p>The deployment of the <a id="_idIndexMarker598"/>Azure resources takes place in the <strong class="source-inline">setup-azure.sh</strong> script. It creates a resource group, an app service plan, and an app service. You could easily execute the script in a workflow. After the deployment, we get the <strong class="source-inline">publish</strong> profile from the web app and store it inside a secret in GitHub. You can either get the publish profile in the Azure portal or from the Azure CLI:</p>
			<p class="source-code">$ az webapp deployment list-publishing-profiles \</p>
			<p class="source-code">    --resource-group $rgname \</p>
			<p class="source-code">    --name $appName \</p>
			<p class="source-code">    --xml</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor221"/>Deploying the application with GitHub Actions</h2>
			<p>The <a id="_idIndexMarker599"/>workflow consists of two jobs: <strong class="source-inline">Build</strong> and <strong class="source-inline">Deploy</strong>. The<a id="_idIndexMarker600"/> build job configures the runner for the correct <strong class="bold">NodeJS</strong> and <strong class="bold">.NET</strong> versions and builds the application. The following task uses <strong class="source-inline">dotnet publish</strong> to publish the website to a folder named <strong class="source-inline">publish</strong>:</p>
			<pre class="source-code">- name: Build and publish with dotnet</pre>
			<pre class="source-code">  working-directory: ch9_release/src/Tailwind.Traders.Web</pre>
			<pre class="source-code">  run: |</pre>
			<pre class="source-code">    dotnet build --configuration Release</pre>
			<pre class="source-code">    dotnet publish -c Release <strong class="bold">-o publish</strong></pre>
			<p>The next step uploads the artifact to GitHub so that it can be used in subsequent jobs. This allows you to publish the same package to multiple environments:</p>
			<pre class="source-code">- name: Upload Artifact</pre>
			<pre class="source-code">  uses: actions/upload-artifact@v2</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    name: <strong class="bold">website</strong></pre>
			<pre class="source-code">    path: ch9_release/src/Tailwind.Traders.Web/<strong class="bold">publish</strong></pre>
			<p>Additionally, you <a id="_idIndexMarker601"/>can see and inspect the artifact after the workflow<a id="_idIndexMarker602"/> has been completed (see <em class="italic">Figure 9.4</em>):</p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/B17827_09_004.jpg" alt="Figure 9.4 – Workflow artifacts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – Workflow artifacts</p>
			<p>The <strong class="source-inline">Deploy</strong> job depends on <strong class="source-inline">Build</strong> and deploys to the <strong class="source-inline">prod</strong> environment. Within the environment, you set the secret and add a required reviewer:</p>
			<pre class="source-code">Deploy:</pre>
			<pre class="source-code">  runs-on: ubuntu-latest</pre>
			<pre class="source-code">  environment: <strong class="bold">prod</strong></pre>
			<pre class="source-code">  needs: Build</pre>
			<p>The workflow downloads the artifact, named <strong class="source-inline">website</strong>, into a folder called <strong class="source-inline">website</strong>:</p>
			<pre class="source-code">- uses: actions/download-artifact@v2</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    name: website</pre>
			<pre class="source-code">    path: website</pre>
			<p>Then, it uses the <strong class="source-inline">azure/webapps-deploy</strong> action to deploy the website using the publish profile:</p>
			<pre class="source-code">- name: Run Azure webapp deploy action using publish profile credentials</pre>
			<pre class="source-code">  uses: azure/webapps-deploy@v2</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    app-name: ${{ env.appName }}</pre>
			<pre class="source-code">    slot-name: Production</pre>
			<pre class="source-code">    publish-profile: ${{ secrets.AZUREAPPSERVICE_PUBLISHPROFILE }}</pre>
			<pre class="source-code">    package: website</pre>
			<p>The last<a id="_idIndexMarker603"/> step is just an example of how you could validate a <a id="_idIndexMarker604"/>deployment. Of course, you would have to <strong class="source-inline">curl</strong> a URL to a site that also targets the database:</p>
			<pre class="source-code">u=https://${{ env.appName }}.azurewebsites.net/</pre>
			<pre class="source-code">status=`curl --silent --head $u | head -1 | cut -f 2 -d' '`</pre>
			<pre class="source-code">if [ "$status" != "200" ]</pre>
			<pre class="source-code">then</pre>
			<pre class="source-code">  echo "Wrong HTTP Status. Actual: '$status'"</pre>
			<pre class="source-code">  exit 1</pre>
			<pre class="source-code">fi</pre>
			<p>If you complete the step-by-step guide in the hands-on lab, you will have a playground where you can add additional environments and deploy to different App Service deployment<a id="_idIndexMarker605"/> slots (for more information, please visit <a href="https://docs.microsoft.com/en-us/azure/app-service/deploy-staging-slots">https://docs.microsoft.com/en-us/azure/app-service/deploy-stagi<span id="_idTextAnchor222"/>ng-slots</a>).</p>
			<h1 id="_idParaDest-223"><a id="_idTextAnchor223"/>How to deploy to AWS ECS</h1>
			<p>We will deploy the <a id="_idIndexMarker606"/>same code to <strong class="bold">AWS</strong> – but this time, we will do so from a <strong class="bold">Docker</strong> container to <strong class="bold">ECS</strong>. ECS is a highly scalable container management service that allows you to run, stop, and manage containers on a cluster. You can find the step-by-step guide at <a href="https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_AWS_ECS.md">https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_AWS_ECS.md</a>.</p>
			<p>Here are some additional notes and background information.</p>
			<h2 id="_idParaDest-224"><a id="_idTextAnchor224"/>Deployment of AWS resources</h2>
			<p>I could not find an <a id="_idIndexMarker607"/>easy script in which I could deploy everything to AWS that did not also include some complex JSON. That's why I'm using the manual steps in the hands-on lab. First, you create an <strong class="bold">Elastic Container Registry</strong> (<strong class="bold">ECR</strong>) repository<a id="_idIndexMarker608"/> to which you can deploy the container. The secrets we use to deploy are<a id="_idIndexMarker609"/> called <strong class="bold">Access keys</strong>, and they consist of two values: <strong class="source-inline">Access Key ID</strong> and <strong class="source-inline">Secret Access Key</strong>.</p>
			<p>After the first deployment, the container is in the registry, and you can use it together with the wizard to set up your ECS resources.</p>
			<p>You have to extract your task definition and save it to the <strong class="source-inline">aws-task-definition.json</strong> file. The second time the workflow runs, it successfully deploys the container to ECS.</p>
			<h2 id="_idParaDest-225"><a id="_idTextAnchor225"/>Deploying the container with GitHub Actions</h2>
			<p>I also split up the <a id="_idIndexMarker610"/>workflow into a <strong class="source-inline">Build</strong> stage and <a id="_idIndexMarker611"/>a <strong class="source-inline">Deploy</strong> stage. This enables you to easily add environments and more stages later. For this to work, you must pass the image name from the <strong class="source-inline">Build</strong> job to the <strong class="source-inline">Deploy</strong> job. To do this, you can use <strong class="source-inline">job outputs</strong>:</p>
			<pre class="source-code">jobs:</pre>
			<pre class="source-code">  Build:</pre>
			<pre class="source-code">    runs-on: ubuntu-latest</pre>
			<pre class="source-code">    outputs:</pre>
			<pre class="source-code">      <strong class="bold">image</strong>: ${{ steps.<strong class="bold">build-image.outputs.image</strong> }}</pre>
			<p>To configure the authentication, we use the <strong class="source-inline">configure-aws-credentials</strong> action with the <strong class="source-inline">Access Key ID</strong> and <strong class="source-inline">Secret Access Key</strong> values.</p>
			<p>Note that GitHub masks part of the image name and does not pass it to the next job. To avoid this, you must prevent the <strong class="source-inline">configure-aws-credentials</strong> action from masking your account ID:</p>
			<pre class="source-code">- name: Configure AWS credentials</pre>
			<pre class="source-code">  uses: aws-actions/configure-aws-credentials@v1</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}</pre>
			<pre class="source-code">    aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}</pre>
			<pre class="source-code">    aws-region: ${{ env.AWS_REGION }}</pre>
			<pre class="source-code">    <strong class="bold">mask-aws-account-id: no</strong></pre>
			<p>The login to ECR returns the name of the registry that you use in the subsequent action:</p>
			<pre class="source-code">- name: Login to Amazon ECR</pre>
			<pre class="source-code">  <strong class="bold">id: login-ecr</strong></pre>
			<pre class="source-code">  uses: aws-actions/amazon-ecr-login@v1</pre>
			<p>In the next step, you <a id="_idIndexMarker612"/>build the image and push it to ECR. Additionally, you <a id="_idIndexMarker613"/>set the output for the next job:</p>
			<pre class="source-code">- name: Build, tag, and push image to Amazon ECR</pre>
			<pre class="source-code">  id: build-image</pre>
			<pre class="source-code">  env:</pre>
			<pre class="source-code">    ECR_REGISTRY: ${{ steps.<strong class="bold">login-ecr</strong>.outputs.registry }}</pre>
			<pre class="source-code">    IMAGE_TAG: ${{ github.sha }}</pre>
			<pre class="source-code">  working-directory: ch9_release/src/Tailwind.Traders.Web</pre>
			<pre class="source-code">  run: |</pre>
			<pre class="source-code">    imagename=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG</pre>
			<pre class="source-code">    echo "Build and push $imagename"</pre>
			<pre class="source-code">    docker build -t $imagename .</pre>
			<pre class="source-code">    docker push $imagename</pre>
			<pre class="source-code">    echo "<strong class="bold">::set-output name=image::$imagename</strong>"</pre>
			<p>The next job depends on <strong class="source-inline">Build</strong> and runs on the <strong class="source-inline">prod</strong> environment:</p>
			<pre class="source-code">Deploy:</pre>
			<pre class="source-code">  runs-on: ubuntu-latest</pre>
			<pre class="source-code">  environment: prod</pre>
			<pre class="source-code">  needs: Build</pre>
			<p>Additionally, it has to configure the AWS credentials and then configure the <strong class="source-inline">aws-task-definition.json</strong> file using the image name that has been passed to the job access through the <strong class="source-inline">needs</strong> context:</p>
			<pre class="source-code">- name: Fill in the new image ID in the ECS task definition</pre>
			<pre class="source-code">  id: <strong class="bold">task-def</strong></pre>
			<pre class="source-code">  uses: aws-actions/amazon-ecs-render-task-definition@v1</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    task-definition: ${{ env.ECS_TASK_DEFINITION }}</pre>
			<pre class="source-code">    container-name: ${{ env.CONTAINER_NAME }}</pre>
			<pre class="source-code">    image: ${{ <strong class="bold">needs.Build.outputs.image</strong> }}</pre>
			<p>The last step is to <a id="_idIndexMarker614"/>deploy the container with the output of the <a id="_idIndexMarker615"/>previous task:</p>
			<pre class="source-code">- name: Deploy Amazon ECS task definition</pre>
			<pre class="source-code">  uses: aws-actions/amazon-ecs-deploy-task-definition@v1</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    task-definition: ${{ steps.<strong class="bold">task-def</strong>.outputs.task-definition }}</pre>
			<pre class="source-code">    service: ${{ env.ECS_SERVICE }}</pre>
			<pre class="source-code">    cluster: ${{ env.ECS_CLUSTER }}</pre>
			<pre class="source-code">    wait-for-service-stability: true</pre>
			<p>If you perform the step-by-step guide, you have a staged working workflow that deploys to ECS. You can add more stages and run different versions of the container in different services.</p>
			<h1 id="_idParaDest-226"><a id="_idTextAnchor226"/>How to deploy to GKE</h1>
			<p>We also deploy the same code to <a id="_idIndexMarker616"/>GKE. You can find the hands-on steps at <a href="https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_GKE.md">https://github.com/wulfland/AccelerateDevOps/blob/main/ch9_release/Deploy_to_GKE.md</a>.</p>
			<p>Before you perform these hands-on steps, here are some details regarding what is happening.</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor227"/>Deployment of Google resources</h2>
			<p>The complete <a id="_idIndexMarker617"/>deployment happens in the <strong class="source-inline">setup-gke.sh</strong> script that you execute in Cloud Shell. The script creates a GKE cluster with one node. For testing purposes, this is enough:</p>
			<pre class="source-code">gcloud container clusters create $GKE_CLUSTER --num-nodes=1</pre>
			<p>Additionally, the script creates an artifact repository for Docker containers and a service account to perform the deployments.</p>
			<p>In Kubernetes, there is the concept of <strong class="bold">pods</strong>. These contain the containers and are deployed using deployments in a <a id="_idIndexMarker618"/>YAML file, which, in this case, is <strong class="source-inline">Deployment.yaml</strong>. The deployment defines the container and binds it to an image:</p>
			<pre class="source-code">spec:</pre>
			<pre class="source-code">  containers:</pre>
			<pre class="source-code">  - name: $GKE_APP_NAME</pre>
			<pre class="source-code">    image: $GKE_REGION-docker.pkg.dev/$GKE_PROJECT/$GKE_PROJECT/$GKE_APP_NAME:$GITHUB_SHA</pre>
			<pre class="source-code">    ports:</pre>
			<pre class="source-code">    - containerPort: 80</pre>
			<pre class="source-code">    env:</pre>
			<pre class="source-code">      - name: PORT</pre>
			<pre class="source-code">        value: "80"</pre>
			<p>I use environment variables in the file and replace them with <strong class="source-inline">envsubst</strong> before passing them to the <strong class="source-inline">kubectl apply</strong> command:</p>
			<pre class="source-code">envsubst &lt; Deployment.yml | <strong class="bold">kubectl apply</strong> -f -</pre>
			<p>A service exposes the pods – in this case, to the internet. The service is deployed, in the same way, using the <strong class="source-inline">Service.yml</strong> file:</p>
			<pre class="source-code">spec:</pre>
			<pre class="source-code">  type: LoadBalancer</pre>
			<pre class="source-code">  selector:</pre>
			<pre class="source-code">    app: $GKE_APP_NAME</pre>
			<pre class="source-code">  ports:</pre>
			<pre class="source-code">  - port: 80</pre>
			<pre class="source-code">    targetPort: 80</pre>
			<p>The deployment of the service takes some time. You might have to execute the following command multiple times:</p>
			<p class="source-code">$ kubectl get service</p>
			<p>If you get an external IP address, you can use it to test your deployment (see <em class="italic">Figure 9.5</em>):</p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/B17827_09_005.jpg" alt="Figure 9.5 – Getting the external IP of the GKE LoadBalancer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – Getting the external IP of the GKE LoadBalancer</p>
			<p>The credentials of the<a id="_idIndexMarker619"/> service account are in the <strong class="source-inline">key.json</strong> file. You have to encode them and save them inside an encrypted secret in GitHub, named <strong class="source-inline">GKE_SA_KEY</strong>:</p>
			<p class="source-code">$ cat key.json | base64</p>
			<p>The script has already done this. So, you can just copy the output and paste it to the secret.</p>
			<h2 id="_idParaDest-228"><a id="_idTextAnchor228"/>Deploying the container with GitHub Actions</h2>
			<p>The deployment in the<a id="_idIndexMarker620"/> GitHub Actions workflow is straightforward. The <a id="_idIndexMarker621"/>authentication and setup of the <strong class="source-inline">gcloud</strong> CLI take place in the <strong class="source-inline">setup-gcloud</strong> action:</p>
			<pre class="source-code">- uses: google-github-actions/setup-gcloud@v0.2.0</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    service_account_key: ${{ secrets.GKE_SA_KEY }}</pre>
			<pre class="source-code">    project_id: ${{ secrets.GKE_PROJECT }}</pre>
			<pre class="source-code">    export_default_credentials: true</pre>
			<p>The workflow then builds and pushes the container to the registry. It uses <strong class="source-inline">gcloud</strong> to authenticate to the Docker registry:</p>
			<pre class="source-code">gcloud auth configure-docker \</pre>
			<pre class="source-code">    $GKE_REGION-docker.pkg.dev \</pre>
			<pre class="source-code">    --quiet</pre>
			<p>To deploy the new image to GKE, we authenticate using the <strong class="source-inline">get-gke-credentials</strong> action:</p>
			<pre class="source-code">- uses: google-github-actions/get-gke-credentials@v0.2.1</pre>
			<pre class="source-code">  with:</pre>
			<pre class="source-code">    cluster_name: ${{ env.GKE_CLUSTER }}</pre>
			<pre class="source-code">    location: ${{ env.GKE_ZONE }}</pre>
			<pre class="source-code">    credentials: ${{ secrets.GKE_SA_KEY }}</pre>
			<p>Following this, we just <a id="_idIndexMarker622"/>replace the variables in the deployment<a id="_idIndexMarker623"/> files and pass them to <strong class="source-inline">kubectl apply</strong>:</p>
			<pre class="source-code">envsubst &lt; Service.yml | kubectl apply -f -</pre>
			<pre class="source-code">envsubst &lt; Deployment.yml | kubectl apply -f –</pre>
			<p>That's it. Following the hands-on steps, you should have a working copy of a deployment to GKE!</p>
			<p class="callout-heading">Deployments to Kubernetes</p>
			<p class="callout">Deployments<a id="_idIndexMarker624"/> to Kubernetes can be very complex; however, this is <a id="_idIndexMarker625"/>beyond the scope of this book. There are different strategies that you can use: <strong class="bold">recreate</strong>, <strong class="bold">rolling updates</strong> (also known<a id="_idIndexMarker626"/> as <strong class="bold">ramped updates</strong>), <strong class="bold">blue/green deployments</strong>, <strong class="bold">canary deployments</strong>, and <strong class="bold">A/B testing</strong>. A good starting point is the official documentation, which can<a id="_idIndexMarker627"/> be found at <a href="https://kubernetes.io/docs/concepts/workloads/controllers/">https://kubernetes.io/docs/concepts/workloads/controllers/</a>. Additionally, a useful visualization of the strategies along with practical examples of how to perform the deployments can be found at <a href="https://github.com/ContainerSolutions/k8s-deployment-strategies">https://github.com/ContainerSolutions/k8s-deployment-strategies</a>.</p>
			<p class="callout">There are also many other <a id="_idIndexMarker628"/>tools that you can leverage when working with Kubernetes. For<a id="_idIndexMarker629"/> instance, <strong class="bold">Helm</strong> (<a href="https://helm.sh/">https://helm.sh/</a>) is a package manager for Kubernetes, and <strong class="bold">Kustomize</strong> (<a href="https://kustomize.io/">https://kustomize.io/</a>) is a tool that can help you manage multiple configurations.</p>
			<h1 id="_idParaDest-229"><a id="_idTextAnchor229"/>Infrastructure as code</h1>
			<p><strong class="bold">Infrastructure as code</strong> (<strong class="bold">IaC</strong>) is the <a id="_idIndexMarker630"/>process of managing and provisioning all your infrastructure resources through machine-readable files. Often, these files are versioned and managed in Git-like code. In this case, it is often referred<a id="_idIndexMarker631"/> to as <strong class="bold">GitOps</strong>.</p>
			<p><em class="italic">IaC</em> can be imperative, declarative, or a mix of both. Imperative means the files are procedural, such as scripts, whereas declarative refers to a functional approach that describes the desired state in a markup language such as YAML or JSON. To get the full power of <em class="italic">IaC</em>, you should manage it in a way where you can also apply changes, not just complete provisioning and <a id="_idIndexMarker632"/>deprovisioning. This is often referred to as <strong class="bold">Continuous Configuration Automation</strong> (<strong class="bold">CCA</strong>).</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor230"/>Tools</h2>
			<p>There are <a id="_idIndexMarker633"/>many tools that you can use for <em class="italic">IaC</em> and <em class="italic">CCA</em>. For instance, there are cloud-specific <a id="_idIndexMarker634"/>tools such<a id="_idIndexMarker635"/> as <strong class="bold">Azure ARM</strong>, <strong class="bold">Bicep</strong>, or <strong class="bold">AWS CloudFormation</strong>. However, there <a id="_idIndexMarker636"/>are also many independent tools that you can use for on-premises infrastructure. Some of the most popular are listed as follows:</p>
			<ul>
				<li><strong class="bold">Puppet</strong>: This was <a id="_idIndexMarker637"/>released by Puppet in 2005 (<a href="https://puppet.com">https://puppet.com</a>).</li>
				<li><strong class="bold">Chef</strong>: This <a id="_idIndexMarker638"/>was released by Chef in 2009 (<a href="https://www.chef.io">https://www.chef.io</a>).</li>
				<li><strong class="bold">Ansible</strong>: This <a id="_idIndexMarker639"/>was released by RedHat in 2021 (<a href="https://www.ansible.com">https://www.ansible.com</a>).</li>
				<li><strong class="bold">Terraform</strong>: This<a id="_idIndexMarker640"/> was released by HashiCorp in 2014 (<a href="https://www.terraform.io">https://www.terraform.io</a>).</li>
				<li><strong class="bold">Pulumi</strong>: This was<a id="_idIndexMarker641"/> released 2017 by Pulumi (<a href="https://www.pulumi.com">https://www.pulumi.com</a>).<p class="callout-heading">IaC and Multi-Cloud Deployments</p><p class="callout">Note that an <em class="italic">IaC</em> tool supporting multiple cloud providers does not mean it can deploy the same resources to multiple clouds! This is a common misconception. You still have to write cloud-specific automations. But you can use the same syntax and tooling.</p></li>
			</ul>
			<p>This is just<a id="_idIndexMarker642"/> the tip of the iceberg. There are many tools on the market. The process of finding the best combination can be very complex and is beyond the scope of this book. If you have a single-cloud strategy, it's probably best if you just start with the cloud-native tools. If you have a complex environment with multiple clouds and on-premises resources and you want to manage them all with the same tooling, you must invest in doing a detailed analysis.</p>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor231"/>Best practices</h2>
			<p>Independent <a id="_idIndexMarker643"/>of the tool you are using, there are some things you should consider when implementing <em class="italic">IaC</em>:</p>
			<ul>
				<li>Store the configuration in Git and treat it like code using protected branches, pull requests, and code owners. Code owners are a great way to ensure compliance, particularly if you store it close to the application code.</li>
				<li>Execute the deployment using GitHub Actions. It's okay to publish the resources interactively while <em class="italic">writing</em> and debugging your IaC. However, once you are finished, you should have complete automated publishing that is done via a workflow. IaC is code, and, as with application code, deploying it from a developer machine comes with the risk of not being reproducible.</li>
				<li>Secrets and key management are the most critical parts of IaC. Make sure that you do not save them in the code but keep them in a secure place (such as GitHub Secrets). A vault such<a id="_idIndexMarker644"/> as <strong class="bold">Hashicorp Vault</strong> or <strong class="bold">Azure KeyVault</strong> allows <a id="_idIndexMarker645"/>for easy key rotation if one of your secrets is compromised. Additionally, it decouples your secure management from the provisioning of resources.</li>
				<li>When <a id="_idIndexMarker646"/>possible, use <strong class="bold">OpenID Connect</strong> (<strong class="bold">OIDC</strong>). This is to avoid using credentials to access cloud <a id="_idIndexMarker647"/>resources but short-lived tokens instead, which can also be rotated (for more information, please refer to <a href="https://docs.github.com/en/actions/deployment/security-hardening-your-deployments">https://docs.github.com/en/actions/deployment/security-hardening-your-deployments</a>).</li>
			</ul>
			<p>I use the cloud-native tools in this book. It is easier to transition from them to an <em class="italic">IaC</em> or <em class="italic">CCA</em> tool than vice versa.</p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor232"/>Strategies</h2>
			<p>There are different <a id="_idIndexMarker648"/>strategies regarding how to organize your infrastructure code in a manageable, scalable, and compliant way. Essentially, it depends on your organizational structure and which one is the best for you. They are as follows:</p>
			<ul>
				<li><strong class="bold">Central</strong>: The<a id="_idIndexMarker649"/> infrastructure resources live in central repositories, and feature teams can provision from there using a self-service (that is, triggering a workflow). This approach has the benefit of having all resources in one place, and the responsible unit will have strong control over it. The disadvantage is that it is not very flexible for developers and that the <em class="italic">distance</em> from the code to the infrastructure will impact the way the engineers treat the infrastructure.</li>
				<li><strong class="bold">Decentral</strong>: The<a id="_idIndexMarker650"/> infrastructure resources live alongside the code. You can use templates (please refer to the <em class="italic">Workflow templates</em> section) to help engineering teams set up the infrastructure. Additionally, you can use <strong class="bold">CODEOWNERS</strong> and protected branches to require approval from a shared, responsible team. This approach is very flexible, but the control of costs and governance are more difficult.</li>
			</ul>
			<p>You could deploy – or ensure the correct state of – the infrastructure with every build. But this would slow down build times and cost valuable build minutes. In most cases, it is preferable to deploy the resources in a separate workflow on demand.</p>
			<ul>
				<li><strong class="bold">Templated</strong>: The <a id="_idIndexMarker651"/>team that is responsible for the shared infrastructure provides fixed templates that can be used by the feature teams. The templates could be <strong class="bold">Actions</strong>, that is, composite<a id="_idIndexMarker652"/> actions with preconfigured native actions or completely customized ones in Docker or JavaScript. Alternatively, you can use a reusable workflow (refer to the <em class="italic">Reusable workflows</em> section). In any case, the ownership of the reused workflow or action stays with the central team. This approach works well if you limit the number of allowed actions within your enterprise.</li>
				<li><strong class="bold">Mixed</strong>: This is a mix<a id="_idIndexMarker653"/> of the preceding three strategies. For example, the test and development infrastructures could be decentralized, and production environments could be templated.</li>
			</ul>
			<p>No matter which strategy you use, be intentional about it. The solution will greatly impact how your teams work together and how infrastructure is used in value delivery!</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor233"/>Workflow templates</h2>
			<p><strong class="bold">Workflow templates</strong> are <a id="_idIndexMarker654"/>workflow files stored in a <strong class="source-inline">workflow-templates</strong> folder in the <strong class="source-inline">.github</strong> repository of an organization alongside a metadata file and an icon file (see <em class="italic">Figure 9.6</em>):</p>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/B17827_09_006.jpg" alt="Figure 9.6 – Workflow templates for an organization&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.6 – Workflow templates for an organization</p>
			<p>The template itself is a <a id="_idIndexMarker655"/>normal workflow file. You can use the <strong class="source-inline">$default-branch</strong> variable for triggers to filter by the default branch.</p>
			<p>Along with the template, you need to save an icon in <strong class="source-inline">.svg</strong> format and a properties file. The properties file looks like this:</p>
			<pre class="source-code">{</pre>
			<pre class="source-code">    "name": "My Workflow Template",</pre>
			<pre class="source-code">    "description": "Description of template workflow",</pre>
			<pre class="source-code">    "iconName": "my-template",</pre>
			<pre class="source-code">    "categories": [</pre>
			<pre class="source-code">        "javascript"</pre>
			<pre class="source-code">    ],</pre>
			<pre class="source-code">    "filePatterns": [</pre>
			<pre class="source-code">        "package.json$",</pre>
			<pre class="source-code">        "^Dockerfile",</pre>
			<pre class="source-code">        ".*\\.md$"</pre>
			<pre class="source-code">    ]</pre>
			<pre class="source-code">}</pre>
			<p>Here, the <strong class="source-inline">name</strong>, <strong class="source-inline">description</strong>, and <strong class="source-inline">iconName</strong> values are required. Note that the <strong class="source-inline">iconName</strong> value is without the extension. In the <strong class="source-inline">categories</strong> array, you can specify the coding languages that this workflow template is relevant for. The same is true for file patterns: you can specify patterns for certain files in the user's repository. The template will be displayed more prominently if the repository contains files that match a pattern.</p>
			<p>Now if a user of the<a id="_idIndexMarker656"/> organization creates a new workflow, they are presented with the templates of the organization (see <em class="italic">Figure 9.7</em>):</p>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/B17827_09_007.jpg" alt="Figure 9.7 – Creating a workflow from a template&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – Creating a workflow from a template</p>
			<p>The template has been copied and <em class="italic">can be modified</em>! That's why workflow templates are not suitable for the templated strategy.</p>
			<p>To learn more about <a id="_idIndexMarker657"/>workflow templates, please visit <a href="https://docs.github.com/en/actions/learn-github-actions/creating-workflow-templates">https://docs.github.com/en/actions/learn-github-actions/creating-workflow-templates</a>.</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor234"/>Reusable workflows</h2>
			<p>A <strong class="bold">reusable workflow</strong> is a <a id="_idIndexMarker658"/>workflow that can be called by another workflow. A workflow must have the <strong class="source-inline">workflow_call</strong> trigger to be reusable:</p>
			<pre class="source-code">on: </pre>
			<pre class="source-code">  workflow_call:</pre>
			<p>You can define inputs that can be passed to the workflow. Inputs can be <strong class="source-inline">boolean</strong>, <strong class="source-inline">number</strong>, <strong class="source-inline">string</strong>, or a <strong class="bold">secret</strong>:</p>
			<pre class="source-code">on:</pre>
			<pre class="source-code">  workflow_call:</pre>
			<pre class="source-code">    inputs:</pre>
			<pre class="source-code">      <strong class="bold">my_environment</strong>:</pre>
			<pre class="source-code">        description: 'The environment to deploy to.'</pre>
			<pre class="source-code">        default: 'Prod'</pre>
			<pre class="source-code">        required: true</pre>
			<pre class="source-code">        type: string</pre>
			<pre class="source-code">    secrets:</pre>
			<pre class="source-code">      <strong class="bold">my_token</strong>:</pre>
			<pre class="source-code">        description: 'The token to access the environment'</pre>
			<pre class="source-code">        required: true</pre>
			<p>You can access the inputs in the reusable workflow using the <strong class="source-inline">inputs</strong> context (<strong class="source-inline">${{ inputs.my_environment }}</strong>) and the secrets using the <strong class="source-inline">secrets</strong> context (<strong class="source-inline">${{ secrets.my_token }}</strong>).</p>
			<p>To use a reusable workflow, you have to reference the file in the following format:</p>
			<pre class="source-code">{owner}/{repo}/{path}/{filename}@{ref}</pre>
			<p>The workflow is called in a job, and you specify the inputs and secrets as follows:</p>
			<pre class="source-code">jobs:</pre>
			<pre class="source-code">  call-workflow-1:</pre>
			<pre class="source-code">    uses: <strong class="bold">org</strong>/<strong class="bold">repo</strong>/.github/workflows/<strong class="bold">reusable</strong>.yml@v1</pre>
			<pre class="source-code">    with: </pre>
			<pre class="source-code">      <strong class="bold">my_environment</strong>: development</pre>
			<pre class="source-code">    secrets:</pre>
			<pre class="source-code">      <strong class="bold">my_token</strong>: ${{ secrets.TOKEN }}</pre>
			<p>Reusable workflows are perfect to avoid duplication. Together with semantic versioning and tags, this is a great way to release reusable workflows to the teams in your organization.</p>
			<p>To learn more about <a id="_idIndexMarker659"/>reusable workflows, please visit <a href="https://docs.github.com/en/actions/learn-github-actions/reusing-workflows">https://docs.github.com/en/actions/learn-github-actions/reusing-workflows</a>.</p>
			<h1 id="_idParaDest-235"><a id="_idTextAnchor235"/>Measuring success</h1>
			<p>In <a href="B17827_01_Epub.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">Metrics that Matter</em>, I introduced you to the <strong class="bold">Four Keys dashboard</strong>. This is a <a id="_idIndexMarker660"/>dashboard that displays the DORA metrics. If you deploy automatically to production, it's time to shift from surveys to real metrics. The dashboard is one way to do this.</p>
			<p>To install the dashboard, follow the instructions at <a href="https://github.com/GoogleCloudPlatform/fourkeys/blob/main/setup/README.md">https://github.com/GoogleCloudPlatform/fourkeys/blob/main/setup/README.md</a>.</p>
			<p>First, create a project in Google Cloud with billing enabled and note the project ID (not the name!). Then, open <strong class="bold">Google Cloud Shell</strong> (located at <a href="https://cloud.google.com/shell">https://cloud.google.com/shell</a>), clone the repository, and execute the deployment script:</p>
			<p class="source-code">$ git clone \</p>
			<p class="source-code">   https://github.com/GoogleCloudPlatform/fourkeys.git</p>
			<p class="source-code">$ cd fourkeys</p>
			<p class="source-code">$ gcloud config set project &lt;project-id&gt;</p>
			<p class="source-code">$ script setup.log -c ./setup.sh</p>
			<p>The script asks you some questions that you can use to tailor your deployment. If everything went well, you should see a nice dashboard in Grafana. To configure GitHub to send data to the event handlers in Google, you have to get the event handler endpoint and secret. Just execute the following two commands in Cloud Shell and copy the output:</p>
			<p class="source-code">$ echo $(terraform output -raw event_handler_endpoint)</p>
			<p class="source-code">&gt; https://event-handler-dup4ubihba-uc.a.run.app</p>
			<p class="source-code">$ echo $(terraform output -raw event_handler_secret)</p>
			<p class="source-code">&gt; 241d0765b5a6cb80208e66a2d3e39d254051377f</p>
			<p>Now, head over to the repository in GitHub where you want to send data to the dashboard and create a webhook under <strong class="bold">Setting</strong> | <strong class="bold">Webhooks</strong> | <strong class="bold">Add webhook</strong>. Paste the URL of the event handler and the secret into the fields and select <strong class="bold">Send me everything</strong>. Click on <strong class="bold">Add webhook</strong> to start sending all the events to the event handler (see <em class="italic">Figure 9.8</em>):</p>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/B17827_09_008_new.jpg" alt="Figure 9.8 – Adding a webhook to send data to the four keys dashboard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – Adding a webhook to send data to the four keys dashboard</p>
			<p>Unfortunately, you can currently only send the deployment data to the dashboard. In previous versions, you were able to send individual events to the workflows.</p>
			<p>To indicate a live-site issue, you must add a tag named <strong class="source-inline">Incident</strong> to an open issue. In the body, you add <strong class="source-inline">root cause:</strong> followed by <strong class="source-inline">SHA</strong> of the commit that caused the event.</p>
			<p>The <strong class="bold">Four Keys</strong> dashboard is a nice way to view your DevOps metrics (see <em class="italic">Figure 9.9</em>):</p>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="image/B17827_09_009.jpg" alt="Figure 9.9 – The Four Keys dashboard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.9 – The Four Keys dashboard</p>
			<p>However, don't forget that these are not metrics to compare teams with each other. Don't let the metrics be the goal!</p>
			<h1 id="_idParaDest-236"><a id="_idTextAnchor236"/>Case study</h1>
			<p>With CI set up, the next thing <a id="_idIndexMarker661"/>our two pilot teams at <strong class="bold">Tailwind Gears</strong> need to do is automate the deployment and release processes of the software.</p>
			<p>The first team runs some web applications that are still hosted on-premises. Instead of automating the on-premises deployment, the team moves the applications to a hosted <strong class="bold">Kubernetes</strong> service in the <strong class="bold">cloud</strong>. The cluster instances, network, and other cloud resources have already been set up by the IT department during the last sprints. Therefore, the team can easily transition the deployment to a staged deployment process. They deploy to a test instance and run all of the automated tests they have. They also add a test using <strong class="bold">curl</strong>, which calls a website that checks the database and backend accessibility to ensure everything is working as expected. If all tests pass, the deployment automatically deploys to production using a rolling update to ensure zero downtime for users.</p>
			<p>Some of the code of the web applications, which contains shared concerns, needs to be adjusted to work in the cloud. This code is also contained in web applications from other teams. The team decides to move the code to <strong class="bold">GitHub Packages</strong> (<strong class="bold">NPM</strong> for the JavaScript and <strong class="bold">NuGet</strong> for .NET) with its own release cycle and <strong class="bold">semantic versioning</strong> to allow other teams, in the future, to reuse the code easily when they move to the cloud.</p>
			<p>The second team produces<a id="_idIndexMarker662"/> software for hardware products that are used in machines for safety-critical functions. This means the development process is highly regulated. They are required to have end-to-end traceability for all changes they do. Since all the requirements were imported into GitHub issues and are linked using nested issues, this is not an issue. They just have to reference the lowest-level issue in the commit message. In addition to end-to-end traceability, there are some test documentations for different levels of requirements that are not yet automated. Plus there are some documents for risk management. To ensure all these criteria are met before releasing the product, <strong class="bold">required reviewers</strong> manually approve a release before deploying to production to ensure that all requirements are in place to be compliant. Together with <strong class="bold">protected branches</strong> and <strong class="bold">codeowners</strong> (the required documents were already converted into markdown), this reduces the effort of releasing a lot at once.</p>
			<p>The installation of the binaries onto the hardware is performed by a custom tool that is owned by the company and runs on a machine in production. This tool is used to pick the binaries up from a file share. This was not optimal for end-to-end traceability and relied on log files. The deployment to test environments was performed manually, which means the way the binaries were distributed was not consistent. To address this, the team puts the binaries together with the tool in a <strong class="bold">Docker container</strong> and publishes the image to the <strong class="bold">container registry</strong> of GitHub Packages. The Docker image can then be used to transfer versions to test machines and during the assembly process in the same way.</p>
			<h1 id="_idParaDest-237"><a id="_idTextAnchor237"/>Summary</h1>
			<p>In this chapter, you learned how to use <strong class="bold">GitHub environments</strong> to stage and protect your deployments and how to use GitHub Actions to deploy to any cloud or platform in a secure manner. I demonstrated how to use workflow templates and reusable workflows to help you collaborate on your <strong class="bold">IaC</strong>.</p>
			<p>In the next chapter, you will learn how to optimize the rolling out of your features and the entire feature life cycle using <strong class="bold">FeatureFlags</strong>/<strong class="bold">FeatureToggles</strong>.</p>
			<h1 id="_idParaDest-238"><a id="_idTextAnchor238"/>Further reading</h1>
			<p>Here is a list of references from this chapter that you can also use to gain more information about the topics we discussed:</p>
			<ul>
				<li>CI/CD: <a href="https://azure.microsoft.com/en-us/overview/continuous-delivery-vs-continuous-deployment">https://azure.microsoft.com/en-us/overview/continuous-delivery-vs-continuous-deployment</a>/</li>
				<li>Deployment rings: <a href="https://docs.microsoft.com/en-us/azure/devops/migrate/phase-rollout-with-rings">https://docs.microsoft.com/en-us/azure/devops/migrate/phase-rollout-with-rings</a></li>
				<li><em class="italic">Deploying to Azure App Service</em>: <a href="https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-azure-app-service">https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-azure-app-service</a></li>
				<li><em class="italic">Deploying to Google Kubernetes Engine</em>: <a href="https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-google-kubernetes-engine">https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-google-kubernetes-engine</a></li>
				<li><em class="italic">Deploy to Amazon Elastic Container Service</em>: <a href="https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-amazon-elastic-container-service">https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-amazon-elastic-container-service</a></li>
				<li><em class="italic">Security hardening your deployments</em>: <a href="https://docs.github.com/en/actions/deployment/security-hardening-your-deployments">https://docs.github.com/en/actions/deployment/security-hardening-your-deployments</a></li>
				<li>Kubernetes deployments: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/">https://kubernetes.io/docs/concepts/workloads/controllers/</a></li>
				<li>Kubernetes deployment strategies: <a href="https://github.com/ContainerSolutions/k8s-deployment-strategies">https://github.com/ContainerSolutions/k8s-deployment-strategies</a></li>
				<li><em class="italic">Helm</em>: <a href="https://helm.sh/">https://helm.sh/</a></li>
				<li><em class="italic">Kustomize</em>: <a href="https://kustomize.io/">https://kustomize.io/</a></li>
				<li><em class="italic">Infrastructure as code</em>: <a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">https://en.wikipedia.org/wiki/Infrastructure_as_code</a></li>
				<li>IaC and environment or configuration drift: <a href="https://docs.microsoft.com/en-us/devops/deliver/what-is-infrastructure-as-code">https://docs.microsoft.com/en-us/devops/deliver/what-is-infrastructure-as-code</a></li>
				<li><em class="italic">Creating workflow templates</em>: <a href="https://docs.github.com/en/actions/learn-github-actions/creating-workflow-templates">https://docs.github.com/en/actions/learn-github-actions/creating-workflow-templates</a></li>
				<li>Reusable workflows: <a href="https://docs.github.com/en/actions/learn-github-actions/reusing-workflows">https://docs.github.com/en/actions/learn-github-actions/reusing-workflows</a></li>
				<li>The four keys project: <a href="https://github.com/GoogleCloudPlatform/fourkeys/">https://github.com/GoogleCloudPlatform/fourkeys/</a></li>
			</ul>
		</div>
	</body></html>