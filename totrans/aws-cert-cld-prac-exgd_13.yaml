- en: '[*Chapter 11*](B17124_11_Final_SK_ePub.xhtml#_idTextAnchor276): Analytics on
    AWS'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[*第11章*](B17124_11_Final_SK_ePub.xhtml#_idTextAnchor276)：AWS上的分析'
- en: In this age of information, understanding your data has become extremely important.
    With current cutting-edge technologies, extensive amounts of data are generated
    every second – data that needs to be stored and analyzed. Companies perform data
    analytics to explain, predict, and ultimately gain a competitive advantage in
    business. Traditional analytics would include retail analytics, supply chain analytics,
    or stock rotation analytics. With **machine learning** (**ML**) and **artificial
    intelligence** taking a firm hold on the economy, new evolutions of analytics
    have come into play, such as cognitive analytics, fraud analytics, and speech
    analytics. The list is almost endless but suffice it to say that understanding
    your raw data has required considerable effort and a whole business unit dedicated
    to **data analytics** alone.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个信息化时代，理解您的数据变得极为重要。借助当前的前沿技术，每秒生成大量的数据——这些数据需要被存储和分析。公司进行数据分析以解释、预测并最终获得商业竞争优势。传统的分析包括零售分析、供应链分析或库存轮换分析。随着**机器学习**（**ML**）和**人工智能**在经济中日益深入，新的分析演变逐渐发挥作用，比如认知分析、欺诈分析和语音分析。这个列表几乎无穷无尽，但可以说，理解您的原始数据已经需要大量的努力，并且需要一个专门的业务部门来负责**数据分析**。
- en: AWS offers a vast array of analytics tools that you can use to ingest, store,
    and effectively understand the data that's generated by your business. In this
    chapter, we will we look at some of those services in detail.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供了一系列广泛的分析工具，您可以使用这些工具来摄取、存储并有效地理解您的业务所生成的数据。在本章中，我们将详细介绍其中一些服务。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Learning about data streaming with Amazon Kinesis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习使用Amazon Kinesis进行数据流处理
- en: Learning how to query data stored in Amazon S3 with Amazon Athena
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何使用Amazon Athena查询存储在Amazon S3中的数据
- en: Introduction to Amazon Elasticsearch
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Elasticsearch简介
- en: Overview of Amazon Glue and QuickSight
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Glue和QuickSight概述
- en: Additional analytics services
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他分析服务
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To complete the exercises in this chapter, you will need access to your AWS
    account and be logged in as the IAM user **Alice**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章的练习，您需要访问您的AWS账户并以IAM用户**Alice**身份登录。
- en: Learning about data streaming with Amazon Kinesis
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习使用Amazon Kinesis进行数据流处理
- en: To analyze your business data, you need to ingest that data into a service that
    can perform the required analysis on it. Businesses generate tons of data from
    a wide range of sources, including logs generated by applications, content such
    as videos, images, and documents, clickstream data from websites, IoT data, and
    more. Ingesting this data is the first step toward understanding it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要分析您的业务数据，您需要将数据摄取到可以对其进行所需分析的服务中。企业从各种来源生成大量数据，包括应用程序生成的日志、视频、图片和文档等内容、网站的点击流数据、物联网数据等。摄取这些数据是理解数据的第一步。
- en: 'However, rather than ingesting all the data first and then figuring out how
    you would go about understanding that data, **Amazon Kinesis** lets you process
    and analyze data as it arrives and respond to it instantly. Amazon Kinesis is
    a fully managed service that enables you to process streaming data at any scale
    in a cost-effective manner. Furthermore, it is **serverless**, meaning that you
    do not need to set up and manage expensive infrastructure to process your data.
    Amazon Kinesis is comprised of the following four key services:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与其先摄取所有数据然后再弄清楚如何理解这些数据，**Amazon Kinesis**让您可以在数据到达时即时处理和分析它，并作出回应。Amazon
    Kinesis是一项完全托管的服务，使您能够以高效且成本效益的方式处理任何规模的流数据。此外，它是**无服务器**的，这意味着您无需设置和管理昂贵的基础设施来处理数据。Amazon
    Kinesis包含以下四项关键服务：
- en: Amazon Kinesis Data Firehose
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Kinesis数据消防队
- en: Amazon Kinesis Data Streams
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Kinesis数据流
- en: Amazon Kinesis Data Analytics
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Kinesis数据分析
- en: Amazon Kinesis Video Streams
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Kinesis视频流
- en: Let's look at each of these services in detail.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解这些服务。
- en: Amazon Kinesis Data Firehose
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Kinesis数据消防队
- en: Modern business approaches and strategies to keep customers loyal and engaged
    have resulted in an insurmountable amount of data to collect, process, and make
    sense of. Whether you are trying to analyze what products your customers click
    on your website, make recommendations based on their product searches, or alert
    your security team about potentially fraudulent transactions, you need to collect
    and process data as it is being generated. Traditionally, you would have had to
    build the infrastructure to provide this kind of backend ingestion and processing
    of data, which can be cost-prohibitive for many businesses – not to mention the
    management overhead associated with maintaining hundreds of servers, storage,
    and network components.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现代商业方法和策略为了保持客户的忠诚度和参与度，导致了大量的数据需要收集、处理和分析。无论您是尝试分析客户在您网站上点击了哪些产品、根据他们的产品搜索进行推荐，还是向您的安全团队发出潜在欺诈交易的警报，您都需要在数据生成时收集和处理数据。传统上，您需要构建基础设施来提供这种类型的数据后端摄取和处理，这对许多企业来说可能是成本过高的——更不用说维护数百台服务器、存储和网络组件所带来的管理开销了。
- en: '**Amazon Kinesis Firehose** is a fully managed service that can ingest and
    deliver streaming data to AWS data stores such as *Amazon S3*, *Redshift*, and
    *Amazon Elasticsearch* for near real-time analytics with existing **business intelligence**
    (**BI**) tools. The service workflow can be illustrated with the following diagram:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Kinesis Firehose** 是一项完全托管的服务，可以将流数据摄取并传输到 AWS 数据存储中，如 *Amazon S3*、*Redshift*
    和 *Amazon Elasticsearch*，以便使用现有的 **商业智能**（**BI**）工具进行近实时分析。该服务的工作流程可以通过以下图示来展示：'
- en: '![Figure 11.1 – Kinesis Firehose'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.1 – Kinesis Firehose'
- en: '](img/B17124_11_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17124_11_01.jpg)'
- en: Figure 11.1 – Kinesis Firehose
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – Kinesis Firehose
- en: Amazon Kinesis Firehose can also deliver data to third-party services such as
    *Datadog*, *New Relic*, *MongoDB*, and *Splunk*. Amazon Kinesis Firehose will
    also allow you to batch process, compress, transform, and even encrypt data before
    loading it into a service, which means you reduce overall storage costs and enhance
    security.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kinesis Firehose 还可以将数据传输到第三方服务，如 *Datadog*、*New Relic*、*MongoDB* 和 *Splunk*。Amazon
    Kinesis Firehose 还允许您在将数据加载到服务之前进行批处理、压缩、转换，甚至加密数据，这意味着您可以降低总体存储成本并增强安全性。
- en: In addition, incoming data streams can be automatically converted into open
    standard formats such as **Apache Parquet** and **Apache ORC**. Finally, with
    Amazon Kinesis Firehose, there are no infrastructure setup costs to worry about.
    You simply pay for the data you transfer through the service, any data conversion
    costs, delivery to Amazon VPCs, and data transfers.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，传入的数据流可以自动转换为开放标准格式，如 **Apache Parquet** 和 **Apache ORC**。最后，使用 Amazon Kinesis
    Firehose，您无需担心基础设施设置成本。您只需为通过该服务传输的数据、任何数据转换成本、传输到 Amazon VPC 的数据以及数据转移费用付费。
- en: Next, we will look at the Kinesis Data Streams service.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解 Kinesis Data Streams 服务。
- en: Amazon Kinesis Data Streams
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Kinesis Data Streams
- en: Whereas Kinesis Firehose is designed to load massive amounts of data into **data
    stores** such as Amazon S3 or Redshift for *near real-time*, **Amazon Kinesis
    Data Streams** is a fully managed *real-time* continuous data streaming service
    that allows you to capture gigabytes of data per second and stream it into custom
    applications for processing and analysis.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Kinesis Firehose 旨在将大量数据加载到 **数据存储**（如 Amazon S3 或 Redshift）以进行 *近实时* 处理不同，**Amazon
    Kinesis Data Streams** 是一项完全托管的 *实时* 持续数据流服务，它允许您每秒捕获数 GB 的数据，并将其流式传输到自定义应用程序进行处理和分析。
- en: Amazon Kinesis Data Streams can make streaming data available to several analytical
    applications, such as Amazon S3 and AWS Lambda, within 70 milliseconds of the
    data being collected. It offers high levels of durability by replicating your
    streaming data across three Availability Zones.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kinesis Data Streams 可以使流数据在数据收集后的 70 毫秒内，提供给多个分析应用程序，如 Amazon S3 和 AWS
    Lambda。通过将流数据复制到三个可用区，它提供了高水平的持久性。
- en: Kinesis Firehose does not offer any data storage capabilities. However, Amazon
    Kinesis Data Streams will store and make your data accessible for up to 24 hours
    by default, but this can be raised to 7 days by enabling the extended data retention
    feature, or even up to 365 days by enabling the long-term data retention feature.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Kinesis Firehose 不提供任何数据存储功能。然而，Amazon Kinesis Data Streams 默认会存储并使您的数据在 24
    小时内可访问，但通过启用扩展数据保留功能，这一时间可以延长至 7 天，甚至通过启用长期数据保留功能延长至 365 天。
- en: You ingest and store streaming data for processing to build real-time applications
    services such as **real-time dashboards**, **real-time anomaly detection**, **dynamic
    pricing**, and so on. Like Kinesis Firehose, you are charged on a pay-as-you-go
    basis with no upfront cost nor minimum fees. However, there is a fundamental difference
    in that Kinesis Data Streams uses the concept of *shards*, which uniquely identify
    the data records in a stream. A stream can be comprised of multiple shards that
    determine the overall capacity. Specifically, each shard represents up to five
    transactions per second for reads with a maximum data read rate of 2 MB per second.
    For writes, you can have up to 1,000 records per second and a total data write
    rate of 1 MB per second (including partition keys). The total capacity of the
    stream is the sum of the capacities of its shards. The important concept to appreciate
    here is that you are charged for each shard that's provisioned per hour, regardless
    of whether you use it or not.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以摄取和存储流数据以进行处理，构建实时应用服务，如**实时仪表盘**、**实时异常检测**、**动态定价**等。与 Kinesis Firehose
    类似，你是按需付费，没有前期费用或最低费用。然而，存在一个根本的区别，即 Kinesis 数据流使用了*分片*的概念，唯一标识流中的数据记录。一个流可以由多个分片组成，这些分片决定了整体容量。具体而言，每个分片每秒最多可处理五次读取事务，最大数据读取速率为每秒
    2 MB。对于写入，你每秒最多可以写入 1,000 条记录，数据写入速率为每秒 1 MB（包括分区键）。流的总容量是其分片容量的总和。这里需要注意的关键概念是，无论是否使用，你都将为每个预配的分片按小时收费。
- en: In [*Chapter 10*](B17124_10_Final_SK_ePub.xhtml#_idTextAnchor249), *Application
    Integration Services*, we discussed a service called **Amazon SQS**. Now, it may
    seem that Kinesis and SQS do the same thing, but they are very different. Amazon
    SQS is a message queueing service that helps store messages while they travel
    between the different components of your application. Amazon SQS helps you decouple
    your application stack so that individual messages can be tracked and managed
    independently, and so that the different components of your application can work
    independently.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第10章*](B17124_10_Final_SK_ePub.xhtml#_idTextAnchor249)《应用集成服务》中，我们讨论了一项名为**Amazon
    SQS**的服务。现在，可能看起来 Kinesis 和 SQS 做的事情相似，但它们其实非常不同。Amazon SQS 是一项消息排队服务，帮助在应用程序的不同组件之间传输时存储消息。Amazon
    SQS 帮助你解耦应用程序栈，从而使单个消息可以独立跟踪和管理，并且使应用程序的不同组件能够独立工作。
- en: Next, we will look at the Kinesis Data Analytics service.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看 Kinesis 数据分析服务。
- en: Amazon Kinesis Data Analytics
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Kinesis 数据分析
- en: '**Kinesis Data Analytics** lets you query and analyze stream data in real time.
    Data can be streamed into the Kinesis Data Analytics application from various
    sources, including Amazon **Managed Streaming for Kafka** (**MSK**) and **Amazon
    Kinesis Data Streams** (discussed earlier). With Kinesis Data Analytics, you do
    not need to build complex streaming integrated applications with other AWS services.
    Instead, you can use standard programming and database query languages such as
    Java, Python, and SQL to query streaming data or build streaming applications.
    The following diagram illustrates these key features:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kinesis 数据分析**让你能够实时查询和分析流数据。数据可以从各种来源流入 Kinesis 数据分析应用程序，包括 Amazon **托管的
    Kafka 流服务**（**MSK**）和**Amazon Kinesis 数据流**（前文有讨论）。使用 Kinesis 数据分析，你不需要与其他 AWS
    服务一起构建复杂的流集成应用程序。相反，你可以使用标准的编程和数据库查询语言，如 Java、Python 和 SQL，来查询流数据或构建流应用程序。以下图表展示了这些关键功能：'
- en: '![Figure 11.2 – Amazon Kinesis Data Analytics'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.2 – Amazon Kinesis 数据分析'
- en: '](img/B17124_11_02.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17124_11_02.jpg)'
- en: Figure 11.2 – Amazon Kinesis Data Analytics
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – Amazon Kinesis 数据分析
- en: Amazon Kinesis Data Analytics also enables you to analyze streaming data in
    real time and build streaming applications using open source libraries and connectors
    for **Apache Flink**. Apache Flink is a fully open source, unified stream processing
    and batch processing framework developed by the **Apache Software Foundation**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kinesis 数据分析还使你能够实时分析流数据，并使用**Apache Flink**的开源库和连接器构建流应用程序。Apache Flink
    是由**Apache 软件基金会**开发的完全开源的统一流处理和批处理框架。
- en: Finally, you have access to the **Kinesis Data Analytics Studio**, which allows
    you to build sophisticated stream processing applications using SQL, Java, Python,
    and Scala.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以访问**Kinesis 数据分析工作室**，它允许你使用 SQL、Java、Python 和 Scala 构建复杂的流处理应用程序。
- en: In terms of pricing, you are only charged for the resources that you use to
    run your streaming applications and there are no upfront commitments.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在定价方面，您只需为运行流媒体应用程序所使用的资源付费，并且无需预先承诺。
- en: Next, we will look at the Amazon Kinesis Video Streams service.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解 Amazon Kinesis Video Streams 服务。
- en: Amazon Kinesis Video Streams
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Kinesis Video Streams
- en: If you are looking to stream video devices to AWS for analytics, ML, playback,
    and other processing services, then the Amazon Kinesis Video Streams service is
    going to be the tool you use. Amazon Kinesis Video Streams can also ingest data
    from edge devices, smartphones, security cameras, and more.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望将视频设备流式传输到 AWS 进行分析、机器学习、回放和其他处理服务，那么 Amazon Kinesis Video Streams 服务将是您使用的工具。Amazon
    Kinesis Video Streams 还可以从边缘设备、智能手机、安全摄像头等设备获取数据。
- en: Amazon Kinesis Video Streams makes use of Amazon S3 as the underlying storage
    repository from your streaming videos, which, as you already know, offers high
    levels of **data durability**. In addition, you can search for and retrieve video
    fragments based on devices and timestamps. Your videos can be encrypted and indexed
    as well.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kinesis Video Streams 使用 Amazon S3 作为流媒体视频的基础存储库，正如您所知道的，它提供了高水平的**数据耐久性**。此外，您还可以根据设备和时间戳搜索并检索视频片段。您的视频也可以加密和索引。
- en: 'With Amazon Kinesis Video Streams, you can play back videos for live or on-demand
    viewing. In addition, you can use Kinesis Video Streams to help you build applications
    that make use of computer vision video analytics technologies on AWS such as **Amazon
    Rekognition**. Incidentally, Amazon Rekognition is a fully managed image and video
    analysis service that can be used to identify objects, people, text, scenes, and
    activities in images and videos. Amazon Rekognition can also be used to detect
    any inappropriate content. The following diagram illustrates the Amazon Kinesis
    Video Streams service:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Amazon Kinesis Video Streams，您可以播放视频进行实时或点播观看。此外，您还可以使用 Kinesis Video Streams
    帮助您构建利用 AWS 上的计算机视觉视频分析技术的应用程序，例如 **Amazon Rekognition**。顺便提一下，Amazon Rekognition
    是一项完全托管的图像和视频分析服务，可用于识别图像和视频中的物体、人物、文本、场景和活动。Amazon Rekognition 还可以用于检测不当内容。以下图表展示了
    Amazon Kinesis Video Streams 服务：
- en: '![Figure 11.3 – Amazon Kinesis Video Streams'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.3 – Amazon Kinesis Video Streams'
- en: '](img/B17124_11_03.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17124_11_03.jpg)'
- en: Figure 11.3 – Amazon Kinesis Video Streams
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – Amazon Kinesis Video Streams
- en: Amazon Kinesis Video Streams enables you to design applications for a wide range
    of use cases. One such use case includes the ability to stream video and audio
    for smart home devices such as doorbells. Amazon Kinesis Video Streams will ingest,
    index, and store the media streams and your application can use HTTP live streaming
    to play the stream to a smartphone app, allowing you to monitor and communicate
    with the person *knocking* on the door.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kinesis Video Streams 使您能够为广泛的用例设计应用程序。一个用例包括能够为智能家居设备（如门铃）流式传输视频和音频。Amazon
    Kinesis Video Streams 将获取、索引并存储媒体流，您的应用程序可以使用 HTTP 实时流媒体将视频流传输到智能手机应用程序，允许您与*敲门*的人进行监控和沟通。
- en: In this section, we looked at Amazon Kinesis and discussed its four key offerings.
    In the next section, we will introduce you to another AWS analytics service known
    as Amazon Athena, which is a fully managed, serverless interactive query service
    that enables you to analyze data in Amazon S3 using standard SQL.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们介绍了 Amazon Kinesis 并讨论了其四项关键功能。在下一部分，我们将向您介绍另一项 AWS 分析服务，即 Amazon Athena，这是一项完全托管的无服务器交互式查询服务，允许您使用标准
    SQL 在 Amazon S3 中分析数据。
- en: Learning how to query data stored in Amazon S3 with Amazon Athena
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习如何使用 Amazon Athena 查询存储在 Amazon S3 中的数据
- en: Businesses store vast amounts of data in repositories such as Amazon S3\. A
    lot of this data is not necessarily being hosted on regular Amazon RDS or NoSQL
    databases. In many cases, this is because the dataset is not being regularly updated
    and queried. Previously, even if you wanted to perform ad hoc queries or analysis
    against some of that data, you would need to ingest it into a database and then
    run your queries against the database.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 企业将大量数据存储在 Amazon S3 等存储库中。许多数据不一定存储在常规的 Amazon RDS 或 NoSQL 数据库中。在许多情况下，这是因为数据集不需要定期更新和查询。以前，即使您想对部分数据进行临时查询或分析，您也需要将其导入到数据库中，然后对数据库进行查询。
- en: '**Amazon Athena** is a fully managed serverless solution that allows you to
    interactively query and analyze data directly in **Amazon S3** using standard
    SQL. There is no infrastructure to provision, and you only pay for the queries
    you run.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Athena**是一个完全托管的无服务器解决方案，允许您使用标准SQL直接在**Amazon S3**中交互式地查询和分析数据。无需配置基础设施，您只需为运行的查询付费。'
- en: Amazon Athena uses **Presto**, which is an open source SQL query engine that's
    designed to allow you to perform ad hoc analysis. You can use standard ANSI SQL,
    which provides full support for large joins, window functions, and arrays.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Athena使用**Presto**，这是一款开源SQL查询引擎，旨在让您执行临时分析。您可以使用标准的ANSI SQL，它提供对大型连接、窗口函数和数组的完全支持。
- en: Data can be presented to Amazon Athena in a variety of formats, such as CSV,
    JSON, ORC, Avro, or Parquet. Furthermore, you can use Athena's JDBC driver to
    connect to a wide range of BI tools.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以以多种格式提供给Amazon Athena，例如CSV、JSON、ORC、Avro或Parquet。此外，您还可以使用Athena的JDBC驱动程序连接到各种商业智能工具。
- en: Amazon Athena allows you to present unstructured, semi-structured, and structured
    data to it, which you can then use to run queries to analyze that data. This process
    involves creating a database within the Athena service and one or more tables
    for each specific dataset that you want to query and analyze. These tables allow
    you to define metadata that tells Athena where the data is held in S3 and the
    structure of that data; for example, the column names and data types.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Athena允许您向其提供非结构化、半结构化和结构化数据，然后您可以使用这些数据运行查询进行分析。此过程涉及在Athena服务中创建一个数据库，并为每个特定的数据集创建一个或多个表，以便查询和分析。这些表允许您定义元数据，告诉Athena数据在S3中的存储位置以及数据的结构；例如，列名和数据类型。
- en: Tables need to be registered in Athena to perform queries and have the results
    returned. These tables can be created automatically or manually. Once your tables
    have been registered, you can use `SQL SELECT` statements to query them. Your
    query results can also be stored in Amazon S3 in a location you specify.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行查询并返回结果，表需要在Athena中注册。这些表可以自动或手动创建。注册表后，您可以使用`SQL SELECT`语句查询它们。查询结果也可以存储在您指定的Amazon
    S3位置。
- en: In an upcoming exercise, *Analyzing your sales report with Amazon Athena and
    AWS Glue*, we will upload some data to Amazon S3 and use Amazon Athena to query
    it. In this section, we introduced you to the Amazon Athena service and provided
    an overview of how you can use Athena to query data stored directly in Amazon
    S3.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在即将到来的练习中，*使用Amazon Athena和AWS Glue分析您的销售报告*，我们将把一些数据上传到Amazon S3，并使用Amazon
    Athena进行查询。在这一部分中，我们向您介绍了Amazon Athena服务，并概述了如何使用Athena查询直接存储在Amazon S3中的数据。
- en: In the next section, we will look at another AWS analytics tool known as Amazon
    Elasticsearch.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将介绍另一个AWS分析工具——Amazon Elasticsearch。
- en: Introduction to Amazon Elasticsearch
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon Elasticsearch简介
- en: '**Elasticsearch** is an open source text search and analytics engine that''s
    capable of storing, analyzing, and performing search functions against big volumes
    of data in near real time. You can use Elasticsearch to analyze all types of data
    such as textual, numerical, geospatial, structured, and unstructured data.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**Elasticsearch**是一个开源文本搜索和分析引擎，能够存储、分析并执行对大量数据的搜索功能，几乎实时地进行处理。您可以使用Elasticsearch分析各种类型的数据，如文本数据、数值数据、地理空间数据、结构化数据和非结构化数据。'
- en: Amazon's offering of Elasticsearch as a service comes as a fully managed service
    with no need to set up and manage any infrastructure, allowing you to focus on
    your applications and their functionalities. Following the same pay-as-you-consume
    model, there are also no upfront costs, although you can reserve instances for
    a 1- or 3-year term for a significant discount over the on-demand pricing model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊提供的Elasticsearch作为服务是一个完全托管的服务，无需设置和管理任何基础设施，让您可以专注于应用程序及其功能。遵循按需付费模式，它没有前期费用，尽管您可以预定1年或3年的实例，以享受比按需定价模型更显著的折扣。
- en: 'Amazon Elasticsearch is designed to be highly scalable and can index all types
    of content to help you deliver applications for use cases such as the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Elasticsearch旨在高度可扩展，可以索引所有类型的内容，帮助您为以下用例交付应用程序：
- en: Website search
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站搜索
- en: Application search
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序搜索
- en: Logging and log analytics
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志记录与日志分析
- en: Infrastructure metrics and monitoring
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施指标和监控
- en: Security analytics
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全分析
- en: Raw data such as log files, messages, metrics, documents, and lists are ingested,
    normalized, and then indexed in Elasticsearch. You can then run complex queries
    against this data and use aggregations to review data summaries.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据如日志文件、消息、指标、文档和列表会被采集、规范化并在Elasticsearch中建立索引。然后，您可以针对这些数据运行复杂的查询，并使用聚合来查看数据摘要。
- en: Amazon Elasticsearch also offers integration with **Kibana**, a data visualization
    tool that's used to analyze large datasets to help you produce visual representations
    of that data in the form of graphs, pie charts, heat maps, and much more.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Elasticsearch还提供与**Kibana**的集成，Kibana是一种数据可视化工具，用于分析大型数据集，帮助您将数据呈现为图表、饼图、热力图等形式的可视化表现。
- en: Another service that Amazon Elasticsearch integrates with is **Logstash**, which
    is an open source, server-side data processing pipeline that allows you to ingest
    data from a wide range of sources and transform it and send it to a **stash**
    such as Elasticsearch. Elasticsearch, Kibana, and Logstash are often referred
    to by the acronym **ELK**.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊Elasticsearch还与**Logstash**集成，Logstash是一款开源的服务器端数据处理管道，它允许您从广泛的来源获取数据，进行转换并将其发送到如Elasticsearch的**stash**中。Elasticsearch、Kibana和Logstash通常统称为**ELK**。
- en: Finally, Amazon Elasticsearch supports querying your cluster using standard
    SQL, making it easy for your developers to start using the service. You can also
    connect to your existing SQL-based BI and ETL tools using a JDBC driver.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Amazon Elasticsearch支持使用标准SQL查询您的集群，使您的开发人员能够轻松开始使用该服务。您还可以通过JDBC驱动程序连接到现有的基于SQL的BI和ETL工具。
- en: In this section, we introduced you to the Amazon Elasticsearch service, which
    allows you to create highly scalable, secure, and available Elasticsearch clusters
    and offers full integration with Kibana and Logstash for a complete managed ELK
    solution.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您介绍了亚马逊Elasticsearch服务，它允许您创建高可扩展、安全且高可用的Elasticsearch集群，并提供与Kibana和Logstash的完整集成，构建完整的托管ELK解决方案。
- en: In the next section, we will look at Amazon Glue and QuickSight.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍Amazon Glue和QuickSight。
- en: Overview of Amazon Glue and QuickSight
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon Glue和QuickSight概述
- en: Business data can often be stored in a wide range of services – databases, storage
    buckets, spreadsheets, and more. Being able to bring all the relevant data together
    for analysis can sometimes be a big project. Later, you may wish to extract and
    present that data in a manner that is easy to digest and understand using BI tools
    or seamlessly integrate insights from that data into your applications, dashboards,
    and reporting. Two services offered by AWS that can help with these types of requirements
    are **Amazon Glue** and **QuickSight**. We'll take a quick look at each of these
    services next.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 商业数据通常存储在各种服务中——数据库、存储桶、电子表格等。能够将所有相关数据汇集在一起进行分析，有时可能是一个庞大的项目。之后，您可能希望使用BI工具提取并以易于理解的方式呈现这些数据，或将这些数据的洞察无缝集成到您的应用程序、仪表板和报告中。AWS提供的两个可以帮助满足这些需求的服务是**Amazon
    Glue**和**QuickSight**。接下来我们将简要介绍这两个服务。
- en: Overview of Amazon Glue
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Glue概述
- en: Amazon Glue is a serverless **Extract, Transform, and Load** (**ETL**) service.
    With Amazon Glue, you can discover, prepare, enrich, clean, and transform your
    data from various sources. You can then load the data into databases, data warehouses,
    and data lakes. Data from streaming sources can also be loaded for regular reporting
    and analysis. This data can then be used for analytics, as per your business requirements,
    and help with decision-making.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Glue是一项无服务器的**提取、转换和加载**（**ETL**）服务。通过Amazon Glue，您可以发现、准备、丰富、清理并转换来自各种来源的数据。然后，您可以将数据加载到数据库、数据仓库和数据湖中。来自流式数据源的数据也可以加载进行定期报告和分析。此数据随后可以根据您的业务需求用于分析，并帮助决策。
- en: Amazon Glue comes with a **Data Catalog**, which is a central metadata repository
    that stores information about your data, such as table definitions. You use a
    **crawler** service to scan various repositories, classify data, and *infer* schema
    information such as its format and data types. The metadata is then stored as
    tables in the Data Catalog and used to generate ETL scripts to transform, flatten,
    and enrich your data. The data is then populated into your chosen data warehousing
    solution or data lakes, for example.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Glue 配备了**数据目录**，这是一个中央元数据存储库，用于存储有关数据的信息，如表定义。你可以使用**爬虫**服务扫描不同的存储库，分类数据，并*推断*数据格式和数据类型等模式信息。然后，这些元数据会作为表格存储在数据目录中，并用于生成
    ETL 脚本，以便转换、扁平化和丰富数据。接着，数据会被填充到你选择的数据仓储解决方案或数据湖中，例如。
- en: 'Amazon Glue also comes with the **AWS Glue console** service to help you define
    and orchestrate your ETL workflow. It lets you do the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Glue 还配备了**AWS Glue 控制台**服务，帮助你定义并编排 ETL 工作流。它让你可以做以下操作：
- en: Define Glue objects such as jobs, crawlers, tables, and so on.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义 Glue 对象，如作业、爬虫、表格等。
- en: Schedule **crawler** run operations.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安排**爬虫**运行操作。
- en: Define events or schedules for job triggers.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义事件或计划以触发作业。
- en: Search for and filter lists of objects in Glue.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Glue 中搜索并筛选对象列表。
- en: Edit transformation scripts directly or by using the visual tools provided.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接编辑转换脚本，或使用提供的可视化工具。
- en: Amazon Glue is a fully managed service and scales resources as needed to run
    your jobs. It handles errors and retries automatically. With Amazon Glue, you
    are charged an hourly rate, which is billing by the second. This pricing is based
    on running crawlers (for discovering data) and performing ETL jobs (for processing
    and loading data). In addition, you pay a monthly fee to store and access the
    metadata in the AWS Glue Catalog.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Glue 是一个完全托管的服务，根据需要扩展资源来运行你的作业。它自动处理错误并进行重试。使用 Amazon Glue 时，你按小时收费，费用按秒计费。此定价基于运行爬虫（用于发现数据）和执行
    ETL 作业（用于处理和加载数据）。此外，你还需要支付月费以存储和访问 AWS Glue 数据目录中的元数据。
- en: Next, we will look at the Amazon QuickSight service.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解 Amazon QuickSight 服务。
- en: Overview of Amazon QuickSight
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon QuickSight 概览
- en: Amazon QuickSight is a serverless and fully managed BI service in the cloud
    that can be used to create and publish interactive BI dashboards for your business
    data. This provides you with access to meaningful information for your business
    so that you can make decisions.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon QuickSight 是一款无服务器、完全托管的云端商业智能（BI）服务，用于创建和发布交互式 BI 仪表盘，帮助企业数据分析。这让你能够获取企业有价值的信息，从而做出决策。
- en: Amazon QuickSight can connect to your data wherever it is stored – whether it's
    stored in **AWS services**, **on-premises databases**, **spreadsheets**, **SaaS
    data**, or **B2B data**. This data can then be transformed into rich dashboards
    and reporting tools that can help your business understand operations, sales figures,
    profits, successes, and where there may be room for improvement. Amazon QuickSight
    can publish dashboards securely to enable collaborative efforts from your organization's
    workforce via mobile phones, email, or web applications.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon QuickSight 可以连接到你数据的存储位置——无论数据存储在**AWS 服务**、**本地数据库**、**电子表格**、**SaaS
    数据**还是**B2B 数据**中。这些数据可以被转化为丰富的仪表盘和报告工具，帮助你的企业了解运营、销售额、利润、成功案例以及可能需要改进的地方。Amazon
    QuickSight 可以安全地发布仪表盘，支持通过移动电话、电子邮件或 Web 应用程序进行组织内部的协作。
- en: Amazon QuickSight also integrates with ML services, which allows it to build
    and deliver deeper insights from your data. With **ML Insights**, you can discover
    hidden insights across your datasets, such as any anomalies and variations, enabling
    you to quickly act to changes that occur. You can also schedule automatic anomaly
    detection jobs. With ML Insights, you can perform better forecasting, which can
    be used to perform accurate *what-if* analysis. Finally, you can summarize your
    data into easy-to-consume natural language narratives, which can help you deliver
    better contextual information in your dashboards and reporting services.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon QuickSight 还与机器学习服务（ML）集成，可以从数据中构建并提供更深入的洞察。通过**机器学习洞察**，你可以发现数据集中的隐藏洞察，比如异常和变化，从而使你能够迅速对变化作出反应。你还可以安排自动的异常检测作业。借助机器学习洞察，你可以进行更好的预测分析，这有助于进行准确的*假设分析*。最后，你可以将数据总结为易于理解的自然语言叙述，这有助于你在仪表盘和报告服务中提供更具上下文的信息。
- en: Amazon QuickSight's pricing model is offered as a pay-as-you-use service and
    is determined by who is using the service; for example, admins, authors, and readers.
    Therefore, the pricing is based on the number of users, similar to a user-based
    license. Additional charges are incurred for services such as alerting and anomaly
    detection too. You can view the pricing overview at [https://aws.amazon.com/quicksight/pricing/](https://aws.amazon.com/quicksight/pricing/).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon QuickSight 的定价模型是按使用付费，费用由谁使用服务来决定；例如，管理员、作者和阅读者。因此，定价基于用户数量，类似于基于用户的许可证。服务如警报和异常检测也会产生额外费用。你可以在
    [https://aws.amazon.com/quicksight/pricing/](https://aws.amazon.com/quicksight/pricing/)
    查看定价概览。
- en: In this section, we reviewed two additional AWS services that fall within the
    analytics category. We introduced you to the Amazon Glue service, which is a fully
    managed and serverless ETL solution. We also provided an overview of the cloud-native
    BI tool, which uses ML to offer greater business insights from your data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了两个额外的 AWS 服务，这些服务属于分析类别。我们向你介绍了 Amazon Glue 服务，它是一个完全托管的无服务器 ETL 解决方案。我们还提供了云原生
    BI 工具的概述，利用机器学习从数据中提供更深入的商业洞察。
- en: In the next section, we will cover a couple of additional tools as part of the
    overall analytics offering.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍一两个额外的工具，作为整体分析解决方案的一部分。
- en: Additional analytics services
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他分析服务
- en: 'In this section, we will take a very quick look at some other AWS analytics
    services that you need to be aware of. Specifically, we will look at the **Elastic
    Map Reduce** (**EMR**) service, **CloudSearch**, and **Data Pipeline**:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将快速浏览一些其他你需要了解的 AWS 分析服务。具体来说，我们将查看 **Elastic Map Reduce**（**EMR**）服务、**CloudSearch**
    和 **Data Pipeline**：
- en: '**AWS EMR**: This provides a managed **Hadoop framework** to enable you to
    process vast amounts of big data. You can use open source tools such as Apache
    Spark, Apache Hive, Apache HBase, Apache Flink, Apache Hudi, and Presto. Amazon
    EMR comes with an **integrated development environment** (**IDE**) called **EMR
    Studio** to help you develop, visualize, and debug data engineering and data science
    applications written in R, Python, Scala, and PySpark. You can run your EMR workloads
    on EC2 Instances, Amazon **Elastic Kubernetes Service** (**EKS**) clusters, and
    on-premises using the AWS Outpost service. In terms of pricing, you are charged
    at a per-instance rate for every second used, with a 1-minute minimum charge.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS EMR**：这提供了一个托管的 **Hadoop 框架**，使你能够处理大量的大数据。你可以使用开源工具，如 Apache Spark、Apache
    Hive、Apache HBase、Apache Flink、Apache Hudi 和 Presto。Amazon EMR 配备了一个名为 **EMR Studio**
    的 **集成开发环境**（**IDE**），帮助你开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用。你可以在
    EC2 实例、Amazon **弹性 Kubernetes 服务**（**EKS**）集群和使用 AWS Outpost 服务的本地环境中运行 EMR 工作负载。定价方面，按照每个实例的每秒使用计费，并且有
    1 分钟的最低计费时间。'
- en: '**AWS Data Pipeline**: This is a web service that allows you to schedule and
    automate how your data is moved and transformed from various sources, including
    **on-premises servers**, into services such as Amazon S3, RDS, DynamoDB, and EMR.
    With AWS Data Pipeline, you can create workflows that transfer and transform data
    at scheduled intervals to ensure alignment with the application processes. For
    example, you can archive your web server logs to an Amazon S3 bucket daily, and
    then run weekly Amazon EMR jobs to analyze those logs and generate traffic reports
    that can be consumed by your application.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS 数据管道**：这是一项 web 服务，允许你安排和自动化数据从各个来源（包括**本地服务器**）移动和转化到如 Amazon S3、RDS、DynamoDB
    和 EMR 等服务。使用 AWS 数据管道，你可以创建在预定时间间隔传输和转化数据的工作流，确保与应用程序过程的对齐。例如，你可以将网页服务器日志每天归档到一个
    Amazon S3 存储桶中，然后每周运行 Amazon EMR 作业来分析这些日志并生成应用程序可使用的流量报告。'
- en: '**AWS CloudSearch**: This is a fully managed service that enables you to deploy,
    manage, and scale a search solution for your web applications. Amazon CloudSearch
    supports 34 languages and adds rich search capabilities to your website, including
    free text, Boolean, and faceted search. It also offers features such as automated
    suggestions, highlighting, and more.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS CloudSearch**：这是一项完全托管的服务，使你能够为你的 web 应用程序部署、管理和扩展搜索解决方案。Amazon CloudSearch
    支持 34 种语言，并为你的网站增加丰富的搜索功能，包括自由文本搜索、布尔搜索和分面搜索。它还提供自动建议、高亮显示等功能。'
- en: In this section, we looked at some additional services offered by AWS that fall
    within the analytics category. In the next section, we will move on to this chapter's
    exercises.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们介绍了 AWS 提供的一些额外服务，这些服务属于分析类别。在接下来的章节中，我们将进入本章的练习。
- en: Exercise 11.1 – analyzing your sales report with Amazon Athena and AWS Glue
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习 11.1 – 使用 Amazon Athena 和 AWS Glue 分析销售报告
- en: In this exercise, you will need to download a sample CSV file, which is available
    in the Packt GitHub repository for this chapter [https://github.com/PacktPublishing/AWS-Certified-Cloud-Practitioner-Exam-Guide](https://github.com/PacktPublishing/AWS-Certified-Cloud-Practitioner-Exam-Guide).
    This is a simple CSV file that contains some sales data for the Vegan Studio,
    the fictitious company that you have been carrying out a series of exercises for
    in the previous chapters.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，你需要下载一个示例 CSV 文件，该文件可以在本章的 Packt GitHub 仓库中找到：[https://github.com/PacktPublishing/AWS-Certified-Cloud-Practitioner-Exam-Guide](https://github.com/PacktPublishing/AWS-Certified-Cloud-Practitioner-Exam-Guide)。这是一个简单的
    CSV 文件，包含了一些关于“Vegan Studio”的销售数据，这是一家虚构公司，你在前几章中已经完成了一系列练习。
- en: You will need to store this CSV file in an Amazon S3 bucket and then use Amazon
    Athena to run queries against the data. Ensure that you have downloaded the CSV
    file and stored it on your computer before you start this exercise.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要将这个 CSV 文件存储在 Amazon S3 存储桶中，然后使用 Amazon Athena 对数据进行查询。在开始本次练习之前，请确保你已经下载了
    CSV 文件并将其存储在你的电脑上。
- en: Step 1 – Amazon S3
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 1 步 – Amazon S3
- en: Log into your AWS account using the IAM user ID of our senior administrator,
    **Alice**.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们高级管理员**Alice**的 IAM 用户 ID 登录到 AWS 账户。
- en: Navigate to the Amazon S3 dashboard.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 Amazon S3 仪表板。
- en: Create two new buckets with appropriate names. For example, I have named my
    buckets `vegan-sales-report` (to store the CSV file) and `vegan-query-results`
    (to store the Athena query results). Since I have taken these names, you will
    not be able to use them since bucket names must be unique in the AWS ecosystem.
    Ensure that the buckets are created in the `us-east-1 (N.Virginia)` Region.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个新的存储桶，并给予适当的名称。例如，我命名了我的存储桶为 `vegan-sales-report`（用于存储 CSV 文件）和 `vegan-query-results`（用于存储
    Athena 查询结果）。由于我已经使用了这些名称，你将不能使用它们，因为存储桶名称在 AWS 生态系统中必须是唯一的。确保在 `us-east-1 (N.Virginia)`
    区域创建存储桶。
- en: 'Next, upload your CSV file to the bucket that will be used to host the data.
    Recall the steps required from the previous chapters to complete the upload. (Tip:
    try to do this from memory as this will help you build your confidence.)'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将你的 CSV 文件上传到将用于托管数据的存储桶中。回顾前几章中完成上传所需的步骤。（提示：尝试凭记忆操作，这有助于增强你的信心。）
- en: Step 2 – Amazon Athena and Amazon Glue
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 2 步 – Amazon Athena 和 Amazon Glue
- en: Navigate to the Amazon Athena dashboard. You can search for the Athena service
    from the top search bar in your AWS Management Console.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 Amazon Athena 仪表板。你可以从 AWS 管理控制台的顶部搜索栏中搜索 Athena 服务。
- en: 'If this is the first time you are accessing Amazon Athena, you should see a
    splash screen. Click **Get Started**. If you do not see the **Get Started** option,
    this is because you are using the new user interface. AWS is notorious for making
    changes to the UI. If you do see the new console, then you will need to click
    on the **Explore the query editor** button. For this lab, we suggest that you
    use the old console for now. To access the old console, click on the ellipsis
    (three dashes) in the top far left of the console and switch the toggle to disable
    the **New Athena experience** option. This will take you back to the old console
    interface:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果这是你第一次访问 Amazon Athena，你应该会看到一个启动屏幕。点击 **开始使用**。如果你没有看到 **开始使用** 选项，那是因为你正在使用新的用户界面。AWS
    以不断更改用户界面而著名。如果你看到了新的控制台界面，你需要点击 **探索查询编辑器** 按钮。对于这个实验室，我们建议你暂时使用旧版控制台。要访问旧版控制台，请点击控制台左上角的省略号（三个横线），然后切换切换开关以禁用
    **新 Athena 体验** 选项。这将带你回到旧版控制台界面：
- en: '![Figure 11.4 – Disabling the New Athena experience toggle switch'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.4 – 禁用新 Athena 体验切换开关'
- en: '](img/B17124_11_04.png)'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_04.png)'
- en: Figure 11.4 – Disabling the New Athena experience toggle switch
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.4 – 禁用新 Athena 体验切换开关
- en: From the top right-hand corner, click on the `s3://bucket-name`. You can also
    store your queries in a sub-folder and choose to encrypt your query results:![Figure
    11.5 – Amazon Athena – Settings
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右上角，点击 `s3://bucket-name`。你也可以将查询存储在子文件夹中，并选择加密查询结果：![图 11.5 – Amazon Athena
    – 设置
- en: '](img/B17124_11_05.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_05.jpg)'
- en: Figure 11.5 – Amazon Athena – Settings
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.5 – Amazon Athena – 设置
- en: Next, click the **Save** button.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，点击 **保存** 按钮。
- en: Next, from the left-hand menu, click on **Connect data source**, as per the
    following screenshot:![Figure 11.6 – Amazon Athena – Connect data source
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，从左侧菜单中点击**连接数据源**，如以下截图所示：![图 11.6 – Amazon Athena – 连接数据源
- en: '](img/B17124_11_06.jpg)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_06.jpg)'
- en: Figure 11.6 – Amazon Athena – Connect data source
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.6 – Amazon Athena – 连接数据源
- en: Under **Choose where your data is located**, ensure that **Query data in Amazon
    S3** is selected.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**选择数据所在位置**下，确保选择了**查询 Amazon S3 中的数据**。
- en: Under **Choose a metadata catalog**, ensure that **AWS Glue Data Catalog** is
    selected. For this exercise, you will use AWS Glue to crawl your data and create
    a schema. There is a slight charge to this, but it is very minimum, and you will
    only need to do this once.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**选择元数据目录**下，确保选择了**AWS Glue 数据目录**。在这个练习中，您将使用 AWS Glue 来爬取数据并创建一个模式。这个操作会产生少量费用，但非常低，而且只需做一次。
- en: Click the **Next** button on the right-hand pane of the page.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击页面右侧窗格中的**下一步**按钮。
- en: Under **Connection details**, ensure that **AWS Glue Data Catalog in this account**
    is selected. Then, under **Choose a way to create a table**, select **Create a
    crawler in AWS Glue**.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**连接详情**下，确保选择了**此账户中的 AWS Glue 数据目录**。然后，在**选择创建表的方式**下，选择**在 AWS Glue 中创建爬虫**。
- en: Click the **Connect to AWS Glue** button. This will launch **AWS Glue** in a
    new browser tab. Switch over to this tab to configure Amazon Glue. Do not close
    the Amazon Athena browser tab as we will return to this later.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**连接到 AWS Glue**按钮。这将会在新的浏览器标签页中启动**AWS Glue**。切换到此标签页来配置 Amazon Glue。不要关闭
    Amazon Athena 浏览器标签页，因为稍后我们还会返回到这个标签页。
- en: If you see the splash screen, click the **Get started** button.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您看到启动画面，请点击**开始使用**按钮。
- en: From the left-hand menu, click **Crawlers**.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧菜单中，点击**爬虫**。
- en: From the right-hand pane, click the `s3://bucket-name.` Note that at the end
    of the path defined for your S3 bucket, ensure that you add another slash (`/`).
    `s3://vegan-sales-report/`.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右侧窗格中，点击`s3://bucket-name`。请注意，在为您的 S3 存储桶定义的路径末尾，确保再添加一个斜杠（`/`）。`s3://vegan-sales-report/`。
- en: Click `VeganSalesRole` so that it is self-explanatory. Click `vegansalesdb`.
    Click **Create**.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`VeganSalesRole`，它的含义一目了然。点击`vegansalesdb`。点击**创建**。
- en: You will be taken back to the **Configure the crawler's output** page, with
    your newly created database name shown in the **Database** text box. Click **Next**.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将被带回到**配置爬虫输出**页面，您新创建的数据库名称将显示在**数据库**文本框中。点击**下一步**。
- en: On the **Review all steps** page, click **Finish**.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**审查所有步骤**页面，点击**完成**。
- en: You will be redirected to the **Crawlers** page. Here, you will be able to see
    that your crawler has been created. Click on the checkbox next to your crawler
    and click the **Run crawler** button, as per the following screenshot:![Figure
    11.7 – Amazon Glue – Run crawler
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您将被重定向到**爬虫**页面。在这里，您将能够看到已创建的爬虫。点击爬虫旁边的复选框，然后点击**运行爬虫**按钮，如以下截图所示：![图 11.7
    – Amazon Glue – 运行爬虫
- en: '](img/B17124_11_07.jpg)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_07.jpg)'
- en: Figure 11.7 – Amazon Glue – Run crawler
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.7 – Amazon Glue – 运行爬虫
- en: After a minute or two, you should find that its **Status** is set to **Ready**
    and that the crawler has successfully run. You will see that a table has been
    added, as per the following screenshot:![Figure 11.8 – Amazon Glue – Crawl complete
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一两分钟后，您应该会看到其**状态**设置为**就绪**，并且爬虫已成功运行。您会看到已经添加了一个表，如以下截图所示：![图 11.8 – Amazon
    Glue – 爬虫完成
- en: '](img/B17124_11_08.jpg)'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_08.jpg)'
- en: Figure 11.8 – Amazon Glue – Crawl complete
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.8 – Amazon Glue – 爬虫完成
- en: Now that the crawl is complete, we can return to the Amazon Athena browser tab.
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬虫完成后，我们可以返回到 Amazon Athena 浏览器标签页。
- en: Step 3 – Amazon Athena
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3 – Amazon Athena
- en: Back in the Athena browser tab, go ahead and click on the **cancel** button
    at the bottom right-hand corner of the page. This will take you back to the main
    **Amazon Athena Data sources** page, where you will see that your recently created
    Glue Catalog is listed under **Data sources**, as per the following screenshot:![Figure
    11.9 – Amazon Athena – Data sources
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回到 Athena 浏览器标签页，点击页面右下角的**取消**按钮。这将带您回到主页面**Amazon Athena 数据源**，您会看到最近创建的 Glue
    目录列在**数据源**下，如以下截图所示：![图 11.9 – Amazon Athena – 数据源
- en: '](img/B17124_11_09.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_09.jpg)'
- en: Figure 11.9 – Amazon Athena – Data sources
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.9 – Amazon Athena – 数据源
- en: Next, click on the **Query editor** tab.*   From the left-hand menu, select
    the database you created earlier in *Step 2*, which will also reveal the table
    that you created within the database, as per the following screenshot:![Figure
    11.10 – Amazon Athena – Query editor
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，点击**Query editor**标签页。*在左侧菜单中，选择你在*步骤 2*中创建的数据库，这将显示你在数据库中创建的表格，具体如以下截图所示：![图
    11.10 – Amazon Athena – 查询编辑器
- en: '](img/B17124_11_10.jpg)'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_10.jpg)'
- en: Figure 11.10 – Amazon Athena – Query editor
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.10 – Amazon Athena – 查询编辑器
- en: Now, you can easily preview the data held in Amazon S3 by clicking on the ellipsis
    (the three dots next to your table name) and then clicking on **Preview table**
    from the context menu that appears. This will run a SQL query and retrieve the
    sample data from your table, as per the following screenshot:![Figure 11.11 –
    Amazon Athena – Sample query
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，你可以通过点击省略号（三个点，位于你的表格名称旁边），然后在出现的上下文菜单中点击**Preview table**，轻松预览存储在 Amazon
    S3 中的数据。这将运行一个 SQL 查询，并根据以下截图从表格中检索示例数据：![图 11.11 – Amazon Athena – 示例查询
- en: '](img/B17124_11_11.jpg)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17124_11_11.jpg)'
- en: Figure 11.11 – Amazon Athena – Sample query
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.11 – Amazon Athena – 示例查询
- en: 'You can run additional queries. For example, you can replace the SQL statement
    in the top half of the pane with the following:'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以运行其他查询。例如，你可以用以下 SQL 语句替换窗格上半部分的 SQL 语句：
- en: '[PRE0]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding statement will showcase all the cities where the sales that were
    achieved were equal to or above $100,000, as per the following screenshot:'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述语句将展示所有销售额达到或超过 $100,000 的城市，具体如以下截图所示：
- en: '![Figure 11.12 – Amazon Athena – Query to identify those cities where'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.12 – Amazon Athena – 查询以识别那些城市'
- en: sales were greater than or equal to $100,000
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 销售额大于或等于 $100,000
- en: '](img/B17124_11_12.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17124_11_12.jpg)'
- en: Figure 11.12 – Amazon Athena – Query to identify those cities where sales were
    greater than or equal to $100,000
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.12 – Amazon Athena – 查询以识别那些销售额大于或等于 $100,000 的城市
- en: As you can see, Amazon Athena is extremely powerful in being able to access
    and query your raw data in Amazon S3\. You do not need to set up and deploy servers
    or run expensive databases for such ad hoc analysis of your data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，Amazon Athena 强大之处在于能够访问并查询你在 Amazon S3 中的原始数据。你无需为这种临时的数据分析设置和部署服务器，也不需要运行昂贵的数据库。
- en: Now, we will perform a cleanup exercise to remove unwanted resources from our
    AWS account.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将执行清理操作，删除 AWS 账户中不需要的资源。
- en: Exercise 11.2 – cleaning up
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习 11.2 – 清理
- en: 'In this exercise, you will delete the resources you created in the previous
    exercise to ensure that there are no unwanted costs:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将删除在前一个练习中创建的资源，以确保没有不必要的费用：
- en: Navigate to the Amazon Glue console.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 Amazon Glue 控制台。
- en: From the left-hand menu, click the **Crawlers** link. In the right-hand pane,
    select **vegan-sales-crawler**. From the **Actions** drop-down list, click the
    **Delete Crawler** option and then confirm the delete operation.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧菜单中，点击**Crawlers**链接。在右侧窗格中，选择**vegan-sales-crawler**。从**Actions**下拉列表中，点击**Delete
    Crawler**选项，然后确认删除操作。
- en: Next, from the left-hand menu, click **Databases**. In the right-hand pane,
    select the **vegansalesdb** database. Then, from the **Actions** drop-down list,
    click the **Delete database** option.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在左侧菜单中点击**Databases**。在右侧窗格中，选择**vegansalesdb**数据库。然后，从**Actions**下拉列表中，点击**Delete
    database**选项。
- en: Click the **Delete** button in the **Delete Database** confirmation dialog box
    that appears.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在出现的**Delete Database**确认对话框中，点击**Delete**按钮。
- en: 'Next, you will need to delete the Amazon S3 buckets as they are no longer required:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要删除 Amazon S3 桶，因为它们不再需要：
- en: Navigate to the Amazon S3 console. From the left-hand menu, click on **Buckets**.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 Amazon S3 控制台。在左侧菜单中，点击**Buckets**。
- en: In the right-hand pane, select the `permanently delete` in the confirmation
    text box. Next, click the **Empty** button. You will get a confirmation message,
    stating that the bucket has been successfully emptied. Click the **Exit** button.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右侧窗格中，在确认文本框中选择`permanently delete`。然后点击**Empty**按钮。你将收到一条确认信息，表示该桶已成功清空。点击**Exit**按钮。
- en: Next, with the **vegan-query-results** bucket still highlighted, click the **Delete**
    button.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，仍然选中**vegan-query-results**桶，点击**Delete**按钮。
- en: Confirm the delete operation by typing the bucket's name in the confirmation
    text box and then clicking on the **Delete bucket** button.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在确认文本框中输入桶的名称并点击**Delete bucket**按钮，确认删除操作。
- en: Repeat *Steps 1* to *4* for the **vegan-sales-report** bucket.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复 *步骤1* 到 *4* 来处理 **vegan-sales-report** 桶。
- en: Now that you have completed the cleanup exercise, we will summarize this chapter.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已完成清理练习，我们将总结本章。
- en: Summary
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed several services from AWS that fall within the
    analytics category. Businesses today possess a vast array of data and being able
    to analyze and make sense of that data is extremely important. Information that's
    obtained from this data can help businesses respond to their customers' needs
    and demands, address potential issues, and even predict future growth. Ultimately,
    businesses can gain an advantage over competitors.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了AWS中属于分析类别的几种服务。当今企业拥有大量数据，能够分析并理解这些数据非常重要。从这些数据中获取的信息可以帮助企业响应客户的需求和要求，解决潜在问题，甚至预测未来的增长。最终，企业可以获得竞争优势。
- en: In this chapter, you learned about services such as Amazon Kinesis, which allows
    customers to stream and respond in real time and near real time to data. You also
    learned about services that can be used to quickly query your data, such as Amazon
    Athena, as well as services to help you present that data using BI tools. Most
    of these analytical services are also offered as fully managed services on a pay-as-you-consume
    pricing model, making them very affordable for almost any business.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了亚马逊Kinesis等服务，允许客户实时或准实时地流式处理和响应数据。您还了解了可以快速查询数据的服务，如亚马逊Athena，以及使用BI工具呈现数据的服务。这些分析服务大多数也以按需付费的完全托管服务形式提供，使几乎任何企业都能负担得起。
- en: In the next chapter, you will learn about various deployment and orchestration
    tools on AWS that can help you provision and deploy your applications in the cloud
    without extensive manual configuration. We will look at **Infrastructure as Code**
    (**IaC**), which has taken the IT world by storm as you can design and deploy
    end-to-end infrastructure solutions in a matter of minutes using predefined templates.
    We will also look at how to automate common IT tasks using serverless compute
    services such as AWS Lambda.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将了解AWS上各种部署和编排工具，这些工具可以帮助您在云中配置和部署应用程序，无需大量手动配置。我们将介绍 **基础设施即代码**（**IaC**），它已经在IT界引起了轰动，因为您可以使用预定义模板设计和部署端到端基础设施解决方案，仅需几分钟。我们还将看看如何使用AWS
    Lambda等无服务器计算服务自动化常见的IT任务。
- en: Questions
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions to test your knowledge of this chapter:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 回答以下问题，测试您对本章内容的了解：
- en: Which AWS service can help you ingest and deliver massive amounts of streaming
    data into Amazon Redshift for near real-time analytics?
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种AWS服务可以帮助您将大量流数据输入到Amazon Redshift进行准实时分析？
- en: Amazon Athena
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Athena
- en: Amazon Kinesis Firehose
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Kinesis Firehose
- en: Amazon Kinesis Video Streams
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Kinesis视频流
- en: Amazon RDS
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊RDS
- en: Which AWS service can help you query streaming data using standard SQL queries
    in real time?
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种AWS服务可以帮助您使用标准SQL查询实时查询流数据？
- en: Amazon Kinesis Data Streams
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Kinesis数据流
- en: Amazon Kinesis Data Analytics
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Kinesis数据分析
- en: Amazon Glue
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Glue
- en: Amazon QuickSight
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊QuickSight
- en: You are planning on building an application that will capture video streams
    from speed cameras on country roads for analysis. You need to be able to capture
    all the vehicles that break the speed limit and identify the offending drivers
    via the vehicles' license plates. Which two services on AWS can help you achieve
    these requirements? (Choose 2 answers.)
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您计划构建一个应用程序，从乡村道路上的速度摄像头捕获视频流以进行分析。您需要能够捕获所有超速的车辆，并通过车辆的牌照识别违规驾驶员。AWS上哪两种服务可以帮助您实现这些要求？（选择2个答案。）
- en: Amazon Athena
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Athena
- en: Amazon Kinesis Data Analytics
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Kinesis数据分析
- en: Amazon Kinesis Video Streams
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Kinesis视频流
- en: Amazon Elasticsearch
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Elasticsearch
- en: Amazon Rekognition
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊识别
- en: Which AWS service enables you to index all types of content, offers integration
    with **Kibana**, and helps you build data visualization tools to analyze large
    datasets?
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种AWS服务使您能够索引所有类型的内容，与**Kibana**集成，并帮助您构建数据可视化工具以分析大型数据集？
- en: Amazon Elasticsearch
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Elasticsearch
- en: Amazon Glue
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Glue
- en: Amazon Athena
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Athena
- en: Amazon Kinesis Firehose
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊Kinesis Firehose
- en: You store several network log files (in CSV format) in an Amazon S3 bucket.
    You have been asked to analyze the contents of a specific file for possible malicious
    attacks. Which AWS service can help you analyze raw data in Amazon S3 and perform
    the necessary ad hoc analysis?
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将多个网络日志文件（CSV 格式）存储在 Amazon S3 存储桶中。你被要求分析一个特定文件的内容，以便检查可能的恶意攻击。哪个 AWS 服务可以帮助你分析
    Amazon S3 中的原始数据，并执行必要的临时分析？
- en: Amazon Glue
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon Glue
- en: Amazon QuickSight
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon QuickSight
- en: Amazon Athena
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon Athena
- en: Amazon Data Pipeline
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon 数据管道
- en: Which AWS service can be used to perform serverless ETL functions to discover,
    prepare, enrich, clean, and transform your data from various sources for analysis?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个 AWS 服务可以用于执行无服务器 ETL 功能，以发现、准备、丰富、清理并转换来自不同来源的数据进行分析？
- en: AWS Glue
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS Glue
- en: AWS Athena
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS Athena
- en: AWS QuickSight
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS QuickSight
- en: AWS Rekognition
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS Rekognition
- en: Which AWS service enables you to create and publish interactive BI dashboards
    for your business data to provide access to meaningful information for your business
    to make decisions?
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个 AWS 服务允许你为企业数据创建并发布交互式商业智能仪表盘，从而为你的企业提供有意义的信息，以便做出决策？
- en: AWS Kinesis Data Analytics
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS Kinesis 数据分析
- en: AWS Glue
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS Glue
- en: AWS QuickSight
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS QuickSight
- en: AWS Kinesis Firehose
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS Kinesis Firehose
