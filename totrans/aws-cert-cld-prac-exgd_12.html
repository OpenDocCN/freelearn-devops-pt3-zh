<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer234">
			<h1 id="_idParaDest-246"><em class="italic"><a id="_idTextAnchor249"/></em><a href="B17124_10_Final_SK_ePub.xhtml#_idTextAnchor249"><em class="italic">Chapter 10</em></a>: Application Integration Services</h1>
			<p>AWS offers a suite of services that enable you to build architectures that enable communication between the different components of your application in a bid to move away from monolith designs. These integration services facilitate design patterns for distributed systems, serverless applications, and decoupled applications.</p>
			<p>Ultimately, decoupling your application from traditional all-in-one monolith architectures ensures a reduced impact when making changes. It also facilitates easier upgrades and new features being released faster.</p>
			<p>In this chapter, we will look at several services that offer integration capabilities. These include messaging solutions between application components using a queuing service, notification services, which can be used for <strong class="bold">application-to-application</strong> (<strong class="bold">A2A</strong>) notifications or <strong class="bold">application-to-person</strong> (<strong class="bold">A2P</strong>) type notifications, event-driven workflow designs, and coordinating multiple services into serverless workloads. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Understanding notification services such as Amazon <strong class="bold">Simple Notification Service</strong> (<strong class="bold">SNS</strong>)</li>
				<li>Decoupling your application architecture with Amazon <strong class="bold">Simple Queue Service</strong> (<strong class="bold">SQS</strong>) and Amazon MQ</li>
				<li>Designing event-driven workflows to connect your application data with various AWS services using EventBridge</li>
				<li>Coordinating multiple AWS services into serverless workloads with Amazon Step Functions and Amazon <strong class="bold">Simple Workflow Service</strong> (<strong class="bold">SWF</strong>)</li>
			</ul>
			<h1 id="_idParaDest-247"><a id="_idTextAnchor250"/>Technical requirements</h1>
			<p>To complete the exercises in this chapter, you will need access to your AWS Free Tier account, as well as permissions to access the various AWS services. You will also need access to the VPC you built in <a href="B17124_06_Final_SK_ePub.xhtml#_idTextAnchor122"><em class="italic">Chapter 6</em></a>, <em class="italic">AWS Networking Services – VPCs, Route53, and CloudFront</em>.</p>
			<h1 id="_idParaDest-248"><a id="_idTextAnchor251"/>Understanding notification services such as Amazon SNS</h1>
			<p>Amazon SNS is <a id="_idIndexMarker1097"/>a push-based messaging and notification system that can be used to allow one application component to send messages to other application components or directly to end users. </p>
			<p>Amazon SNS uses a publisher/subscriber model where one application component will act as a publisher of messages and the other application components will consume those messages as subscribers. Amazon SNS allows you to design high throughput, many-to-many messaging between distributed systems, microservices, and event-driven applications. </p>
			<p>Let's look at an example. Suppose you want to be notified if any of your IAM users upload an object to a particular Amazon S3 bucket that they have access to. To achieve this, you can configure<a id="_idIndexMarker1098"/> <strong class="bold">S3 event notifications</strong> to send out an alert whenever the <strong class="source-inline">s3:ObjectCreated:*</strong> action occurs. This notification can be sent<a id="_idIndexMarker1099"/> to an <strong class="bold">SNS topic</strong> (discussed later), which you subscribe to using your email address. This way, every time your users upload a new object to your S3 bucket, Amazon SNS will send out a notification to you via email. This is an example of A2P messaging using SNS.</p>
			<p>Let's look at <a id="_idIndexMarker1100"/>another example. Suppose you host an S3 bucket that allows end users to upload images in a default format, and you have a requirement to convert those images into multiple formats. To achieve this requirement, you can use Amazon Lambda, which, as we discussed in <a href="B17124_07_Final_SK_ePub.xhtml#_idTextAnchor157"><em class="italic">Chapter 7</em></a>, <em class="italic">AWS Compute Services</em>, is a serverless compute solution that allows you to run code in response to an event or trigger. </p>
			<p>For this specific example, you can configure your S3 notification service to send a message to an Amazon SNS topic and have the Lambda function subscribe to that topic. The message can include information about the new image that has been uploaded and can trigger your Lambda function to access the image in the bucket, create different formats of the image, and save them in another S3 bucket. This automated process is an example of A2A messaging using SNS.</p>
			<p>Next, we will take a look at a key component of the Amazon SNS services, specifically SNS endpoints.</p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor252"/>Amazon SNS endpoints </h2>
			<p>As we mentioned <a id="_idIndexMarker1101"/>previously, Amazon SNS is a push-based messaging solution, enabling one or more publishers to push messages to one or more subscribers. With Amazon SNS, your subscribers need to use a supported endpoint type. These endpoints are depicted in the following diagram:</p>
			<div>
				<div id="_idContainer220" class="IMG---Figure">
					<img src="Images/B17124_10_01.jpg" alt="Figure 10.1 – Amazon SNS subscriber endpoints&#13;&#10;" width="828" height="803"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – Amazon SNS subscriber endpoints</p>
			<p>Amazon SNS <a id="_idIndexMarker1102"/>A2A endpoints include Amazon SQS, HTTP/S endpoints, AWS Lambda, and Amazon Kinesis Firehose. Data from Amazon Kinesis Firehose can then be offloaded and stored in Amazon S3 buckets, AWS Elasticsearch, and Amazon Redshift, as well as other third-party service providers. </p>
			<p>Amazon SNS A2P endpoints include email, mobile text messages, and mobile push endpoints.</p>
			<p>Amazon SNS also ensures high levels of message durability. Messages are stored and replicated on <a id="_idIndexMarker1103"/>multiple devices across geographically separated servers and data centers. </p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor253"/>Amazon SNS topics</h2>
			<p>At the heart of the <a id="_idIndexMarker1104"/>Amazon SNS service is the SNS topic feature, which is a logical access point that acts as a communication channel between your publishers and subscribers. Before you can send out messages to your subscribers, you need to create a topic. Your publisher needs to be made aware of which SNS topic to send messages to and your end clients must subscribe to the topic to be able to receive those messages.</p>
			<p>In the following diagram, we can see that an application component allows us to upload objects to an Amazon S3 bucket (<strong class="bold">1</strong>). Amazon S3 can be set up with an event notification service that pushes out a notification, stating that an upload took place to an Amazon SNS topic. In this diagram, an admin has subscribed to the SNS topic. Any notifications resulting from the objects being uploaded to the S3 bucket are then sent to the admin:</p>
			<div>
				<div id="_idContainer221" class="IMG---Figure">
					<img src="Images/B17124_10_02.jpg" alt="Figure 10.2 – Example – configuring an SNS notification for an S3 event notification&#13;&#10;" width="1193" height="356"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – Example – configuring an SNS notification for an S3 event notification</p>
			<p>Your publishers also need permission to be able to publish messages to the topic. In the previous example, where we wanted to send a notification to an administrator every time a new object was uploaded to an S3 bucket, you would also need to create permissions that grant the S3 bucket the ability to send messages to the SNS topic. You can do this by configuring an IAM policy that specifies which bucket can send messages to the topic and attach it directly to the SNS topic as an inline policy.</p>
			<p>Subscribers to your topic will then have messages pushed out to them whenever a new message is published by the publisher. In the case of the preceding example, the publisher is the S3 notification service, and the subscriber is your administrator's email address.</p>
			<p>Note that when you create a topic, you need to assign it a name. This can be up to 256 characters in length and can contain hyphens (-) and underscores (_). Amazon SNS will assign an <strong class="bold">Amazon Resource Name</strong> (<strong class="bold">ARN</strong>) to the topic you create, which will include the service name – in <a id="_idIndexMarker1105"/>this case, <strong class="source-inline">sns</strong> – the Region, the AWS account ID, and the topic name. So, for example, an SNS topic called <strong class="source-inline">new-recipe-upload-alert</strong>, created in the London<a id="_idIndexMarker1106"/> Region, with an AWS account ID of <strong class="source-inline">123456789789</strong> will have an ARN of <strong class="source-inline">arn:aws:sns:eu-west-2:1234567890123789: new-recipe-upload-alert</strong>.</p>
			<p>Next, we will look at the topics you can create on Amazon SNS, which will depend on the application's use case.</p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor254"/>Standard and FIFO topics</h2>
			<p>When <a id="_idIndexMarker1107"/>configuring<a id="_idIndexMarker1108"/> Amazon SNS, you create a <strong class="bold">standard topic</strong> by default. Standard topics are used when the message's delivery order is not going to affect your application in any way and where duplicating messages will not create any issues in your workflow. All supported delivery protocols support standard topics.</p>
			<p>In addition, you<a id="_idIndexMarker1109"/> can<a id="_idIndexMarker1110"/> create <strong class="bold">FIFO topics</strong>. These are designed to ensure strict message ordering and prevent message duplication. Note that only the Amazon SQS endpoint (specifically, the Amazon SQS FIFO queue) can subscribe to a FIFO topic. We will discuss the Amazon SQS service later in this chapter.</p>
			<h2 id="_idParaDest-252"><a id="_idTextAnchor255"/>Amazon SNS Fanout scenario</h2>
			<p>A key <a id="_idIndexMarker1111"/>feature <a id="_idIndexMarker1112"/>offered by Amazon SNS is the ability to replicate messages pushed out to an SNS topic across multiple endpoints. This is known as the <strong class="bold">Fanout scenario</strong> and it allows parallel asynchronous processing. </p>
			<p>Let's look at an example. Let's say that you are a theatre company and that you sell tickets for your various performances. You are required to process online payments from customers and issue them their tickets. At the same time, you are also required to store information on all sales in AWS's data warehousing solution, which is offered by Amazon Redshift. One way to design this architecture is depicted in the following diagram:</p>
			<div>
				<div id="_idContainer222" class="IMG---Figure">
					<img src="Images/B17124_10_03.jpg" alt="Figure 10.3 – Example of an Amazon SNS Fanout scenario&#13;&#10;" width="1179" height="666"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.3 – Example of an Amazon SNS Fanout scenario</p>
			<p>In the preceding<a id="_idIndexMarker1113"/> diagram, incoming ticket sales are sent to an SNS topic, which then gets replicated to an SQS queue and an Amazon Kinesis Data Firehose stream. Any messages that are sent to the SQS queue are processed by the payment function to complete the sale transaction. Additional queues may be added to the architecture for order fulfillment and customer notification.</p>
			<p>Next, the same message is processed by Amazon Kinesis Data Firehose, which feeds the data into an Amazon Redshift cluster. Note that to stream data from Amazon Kinesis Firehose to Redshift, you need to deliver the data into an S3 bucket and then issue an Amazon Redshift <strong class="source-inline">COPY</strong> command to load the data into your Amazon Redshift cluster. We will discuss Amazon Kinesis in the next chapter.</p>
			<p>At the same time, messages will continue to reside in the S3 bucket, which can be archived using the life cycle management process, as we discussed in <a href="B17124_05_Final_SK_ePub.xhtml#_idTextAnchor094"><em class="italic">Chapter 5</em></a>, <em class="italic">Amazon Simple Storage Service (Amazon S3)</em>. This can help address any compliance <a id="_idIndexMarker1114"/>requirements to store historic information on all ticket sales.</p>
			<h2 id="_idParaDest-253"><a id="_idTextAnchor256"/>Amazon SNS pricing</h2>
			<p>Amazon SNS is a<a id="_idIndexMarker1115"/> managed service with no upfront cost. You pay based on usage and this is based on the type of topic that's used; that is, standard topics or FIFO topics. Standard topics are charged based on the number of API requests made per month and the number of deliveries to the various endpoints. For example, mobile push notifications are charged at $0.50 per million notifications after you have exhausted your free tier threshold of 1 million notifications. </p>
			<p>The maximum payload size for your messages is 256 KB. Except for SMS messages, you are billed for every 64 KB chunk as one request. So, a payload size of 256 KB is equal to four requests. Furthermore, if you need to send messages that are larger than 256 KB, you can use the Amazon Extended SNS Client Library, which allows you to send payloads via the Amazon S3 service. When you do this, additional Amazon S3 storage costs are incurred.</p>
			<p>With regards to FIFO topics, you are charged based on the number of published messages, subscribed messages, and their respective amount of payload data. </p>
			<p>In this section, we looked at the Amazon push-based messaging solution offered by Amazon SNS. Amazon SNS works based on a publisher/subscriber model and enables you to design and architect A2A messaging and A2P messaging. Amazon SNS can help you build integration between different application components, allowing you to design distributed systems, microservices, and serverless architectures.</p>
			<p>You also learned about some of the core features of Amazon SNS, including standard and FIFO topics, as well as the Fanout scenario concept. </p>
			<p>In the next section, we will look at another messaging integration service known as Amazon SQS. Amazon SQS is a pull-based messaging solution and lends itself well to designing decoupled architectures, enabling you to migrate away from monolith application architectures.</p>
			<h1 id="_idParaDest-254"><a id="_idTextAnchor257"/>Decoupling your application architecture with Amazon SQS and Amazon MQ</h1>
			<p>Amazon <a id="_idIndexMarker1116"/>SQS is <a id="_idIndexMarker1117"/>another <a id="_idIndexMarker1118"/>fully<a id="_idIndexMarker1119"/> managed messaging integration solution that enables you to decouple your application components into distributed systems and facilitate the design and architecture of microservices. One of the primary advantages of using a queuing system such as Amazon SQS is the ability to move away from monolithic application designs. In a monolithic design, where all the components of your applications are dependent on each other and always need to be available to each other, you often suffer from frequent failures and outages. A queueing system such as Amazon SQS can help the different components of your application work independently and queues can hold messages in the form of requests/tasks until capacity becomes available. With asynchronous processing and the ability for different components to scale independently, you benefit from higher levels of availability, where each component can scale as needed without impacting the overall workflow.</p>
			<p>In the following diagram, we can see how Amazon SQS can be used to queue messages between various components of your application and achieve a decoupled architecture (also known as loose coupling):</p>
			<div>
				<div id="_idContainer223" class="IMG---Figure">
					<img src="Images/B17124_10_04.jpg" alt="Figure 10.4 – Amazon SQS use case example&#13;&#10;" width="1235" height="656"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.4 – Amazon SQS use case example</p>
			<p>In the<a id="_idIndexMarker1120"/> preceding<a id="_idIndexMarker1121"/> diagram, a <a id="_idIndexMarker1122"/>media <a id="_idIndexMarker1123"/>transcoding example makes use of both the Amazon SNS and Amazon SQS services to convert raw videos uploaded by users into various formats and resolution sizes. In this architecture, we have different auto-scaling groups that are provisioning a fleet of servers, with each fleet responsible for converting the videos into a specific format. Separate queues are created to handle messages destined for the different fleets of servers to process. Here is a quick breakdown of the workflow:</p>
			<ol>
				<li>Users upload videos via a frontend web server farm that is part of an auto-scaling group designed to scale out and scale in based on demand.</li>
				<li>The videos are uploaded to a master bucket.</li>
				<li>At the same time, an SNS notification is sent out to multiple Amazon SQS queues in a fanout configuration (refer to the SNS Fanout scenario discussed earlier in this chapter).</li>
				<li>Each SQS queue holds messages for the appropriate app server to pull when capacity is available.</li>
				<li>The relevant app servers retrieve the messages from the appropriate SQS queue, which identifies the videos that need to be processed in the master bucket. The app servers then retrieve the raw videos from the master bucket.</li>
				<li>The app servers convert the format and resolution of the videos and upload the completed videos in the correct format into the transcode bucket.</li>
			</ol>
			<p>Whereas Amazon SNS offers a push-based message notification solution, Amazon SQS is a fully managed pull-based message queue system that will also retain the messages for a short duration (the default is set to 4 days but this can be configured to a maximum duration of 14 days). </p>
			<p>This means that if you have backend services that need to process lots of messages in the queue from frontend web requests, you can retain those messages until your backend <a id="_idIndexMarker1124"/>services <a id="_idIndexMarker1125"/>can <a id="_idIndexMarker1126"/>process<a id="_idIndexMarker1127"/> new messages in the queue. Amazon SQS increases the overall fault tolerance of your application solutions, allowing your decoupled application components to run independently. </p>
			<h2 id="_idParaDest-255"><a id="_idTextAnchor258"/>Amazon SQS queue types</h2>
			<p>Amazon SQS <a id="_idIndexMarker1128"/>offers two types of queues designed to help address different use cases. These are discussed next.</p>
			<h3>Amazon SQS standard queues</h3>
			<p>Standard <a id="_idIndexMarker1129"/>queues support a nearly unlimited number of API calls per second, (<strong class="source-inline">SendMessage</strong>, <strong class="source-inline">ReceiveMessage</strong>, or <strong class="source-inline">DeleteMessage</strong>) and are designed for messages to be delivered at least once. However, this does mean that on an odd occasion, duplicate copies of the message could be delivered. In addition, messages may not be delivered in the order in which they were introduced into the queue. So, your application must be able to cope with messages that are not delivered in the order in which they entered the queue, as well as the occasional duplicate message:</p>
			<div>
				<div id="_idContainer224" class="IMG---Figure">
					<img src="Images/B17124_10_05.jpg" alt="Figure 10.5 – Amazon SQS standard queue&#13;&#10;" width="975" height="238"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.5 – Amazon SQS standard queue</p>
			<p>Standard queues are particularly useful when you need to process vast amounts of transactions per second. However, note that there is a 120,000 quota for the number of inflight messages for a standard queue. A typical example of where you might use standard queues is, for example, when you need to process a high number of credit card validation<a id="_idIndexMarker1130"/> requests for an e-commerce application.</p>
			<h3>Amazon SQS FIFO queues</h3>
			<p><strong class="bold">FIFO</strong> stands <a id="_idIndexMarker1131"/>for <strong class="bold">first-in first-out</strong>. FIFO queues are designed to<a id="_idIndexMarker1132"/> preserve the order of your messages, as well as ensuring only one-time delivery with no duplicates. </p>
			<p>FIFO queues only offer throughput at a rate of 300 transactions per second. This means that they cannot offer unlimited throughput; however, high throughput of messages can be offered by using a process known as batching, which offers support for 3,000 transactions per second, per API method (<strong class="source-inline">SendMessageBatch</strong>, <strong class="source-inline">ReceiveMessage</strong>, or <strong class="source-inline">DeleteMessageBatch</strong>). These 3,000 transactions represent 300 API calls, each with a batch of 10 messages. </p>
			<p>In addition, as depicted in the following diagram, messages are delivered in the order in which they were introduced into the queue and Amazon SQS will preserve this order: </p>
			<div>
				<div id="_idContainer225" class="IMG---Figure">
					<img src="Images/B17124_10_06.jpg" alt="Figure 10.6 – Amazon SQS FIFO queue&#13;&#10;" width="971" height="238"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.6 – Amazon SQS FIFO queue</p>
			<p>So, FIFO queues are ideal for those applications where the order of events is important, such as when you're making sure that user-entered commands are run in the right order. FIFO queues also ensure no duplicates are created more than once, such as processing payment transactions. However, they are not ideal where exceptional levels of scaling might be required or where you need to process greater than 3,000 transactions<a id="_idIndexMarker1133"/> per second (with batching).</p>
			<h2 id="_idParaDest-256"><a id="_idTextAnchor259"/>Amazon SQS pricing and security</h2>
			<p>To ensure <a id="_idIndexMarker1134"/>sensitive<a id="_idIndexMarker1135"/> data is protected, you can encrypt messages using Amazon <strong class="bold">Key Management Service</strong> (<strong class="bold">KMS</strong>). In<a id="_idIndexMarker1136"/> terms of pricing, there are no upfront costs. You pay based on the number and content of requests and the interactions with Amazon S3 and AWS KMS. Note that as part of the free tier, you also get the first 1 million requests for free every month.</p>
			<p>In this section, we looked at another managed messaging solution offered by Amazon SQS. Amazon SQS is a pull-based message queuing solution that allows you to decouple your application components, enabling them to work independently of each other. Messages are stored in either standard or FIFO queues and application components retrieve these messages as required when there is available capacity. </p>
			<p>In the next section, we will look at Amazon MQ, which is a message broker service designed for Apache ActiveMQ and other message brokers.</p>
			<h1 id="_idParaDest-257"><a id="_idTextAnchor260"/>Amazon MQ</h1>
			<p>A message<a id="_idIndexMarker1137"/> broker is a piece of software designed to help you facilitate communications between application components to exchange information. Message brokers allow different services to communicate with each other directly, even if those services are written in different languages or run on different platforms. </p>
			<p>Many organizations have existing message brokering services within their on-premises environments that support their on-premises applications. One such service is <strong class="bold">Apache ActiveMQ</strong>, which <a id="_idIndexMarker1138"/>is probably one of the most popular Java-based message brokers.</p>
			<p>When clients are looking to migrate their on-premises applications, you must consider where such third-party message brokering services are being consumed. AWS offers a service known as Amazon MQ, which is a fully managed message broker service that provides compatibility with popular message brokers. </p>
			<p>Amazon recommends using Amazon MQ to migrate applications from existing message brokers <a id="_idIndexMarker1139"/>where <a id="_idIndexMarker1140"/>compatibility <a id="_idIndexMarker1141"/>with APIs <a id="_idIndexMarker1142"/>such as <strong class="bold">JMS</strong> or<a id="_idIndexMarker1143"/> protocols such as <strong class="bold">AMQP 0-9-1</strong>, <strong class="bold">AMQP 1.0, MQTT</strong>, <strong class="bold">OpenWire</strong>, and <strong class="bold">STOMP</strong> is required.</p>
			<p>If, as part of the migration, you are looking to completely rearchitect your application layer, then you may wish to consider Amazon SNS and Amazon SQS instead, as you do not require third-party message brokers. Amazon recommends these services for new applications that can benefit from nearly unlimited scalability and simple APIs.</p>
			<p>In this section, we looked at Amazon MQ, which enables customers to easily migrate to a message broker in the cloud and offers compatibility with existing messaging brokers such as Apache ActiveMQ and RabbitMQ. With Amazon MQ, you reduce your overall operational overhead when provisioning, configuring, and maintaining message brokers that depend on connectivity with APIs such as JMS or protocols such as AMQP 0-9-1, AMQP 1.0, MQTT, OpenWire, and STOMP.</p>
			<p>In the next section, we will look at event-driven workflow services and the services offered by Amazon to help architect event-driven solutions for your applications.</p>
			<h1 id="_idParaDest-258"><a id="_idTextAnchor261"/>Designing event-driven application workflows using AWS EventBridge</h1>
			<p>Amazon<a id="_idIndexMarker1144"/> EventBridge<a id="_idIndexMarker1145"/> is a serverless <em class="italic">event bus service</em> that allows you to stream real-time events from your applications, SaaS-based services, and AWS services to a variety of targets. These targets can include AWS Lambda, Kinesis, an HTTP/S endpoint, or another event bus service in another account. Amazon EventBridge helps you create application architectures where you need to react and perform some action against those events that are generated.</p>
			<p>Events can be generated when there is a change in the state of a given resource, such as when an EC2 instance changes its state from a running state to a stopped state. Another example of an event is when your auto-scaling group launches or terminates an EC2 instance. Additional functionality, as required by your application architecture, can be created by reacting to such state changes. </p>
			<p>With EventBridge, you set up rules that define matching incoming patterns or events. When an event occurs, as defined by the rule, it can be sent to a target for further processing. For example, an event that resulted in a critical server being stopped (by accident) can be sent to a Lambda function to have it restarted automatically. </p>
			<p>EventBridge can also be configured to trigger events at a defined schedule. For example, if you have a large fleet of EC2 instances that are used to test new applications, and you generally run your tests every weekday from Monday to Friday during normal business hours, then there is no need to have the servers running outside of those business hours. You can set up a scheduled event to trigger a Lambda function that stops the servers at 6 P.M. Monday to Friday and restarts them every weekday at 8 A.M. This ensures that outside of normal business hours, your servers are in the stopped state. If these are on-demand EC2 instances, you do not get charged while those servers remain stopped.</p>
			<p>Amazon EventBridge is an updated solution from a previous version known as Amazon CloudWatch Events. With CloudWatch Events, you were limited to a default event bus that enabled you to route all AWS events, as well as custom events. However, with the new Amazon EventBridge, you can introduce custom event buses in addition to the default event bus. Custom event buses can be created exclusively for your workloads and enable you to control access to events that are limited to a set of AWS accounts or custom applications. In addition, you can use content-based filtering and advanced rules for routing events. EventBridge can handle more processing, reduce the load on downstream events, and use partner event sources such as Zendesk, PagerDuty, and Datadog.</p>
			<p>In the following <a id="_idIndexMarker1146"/>diagram, we<a id="_idIndexMarker1147"/> can see how EventBridge works at a high level. We can see the sources of events, the types of buses that can be used, and the potential targets for those events:</p>
			<div>
				<div id="_idContainer226" class="IMG---Figure">
					<img src="Images/B17124_10_07.jpg" alt="Figure 10.7 – How EventBridge works&#13;&#10;" width="1416" height="644"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.7 – How EventBridge works</p>
			<p>The following are the key concepts and components of Amazon EventBridge:</p>
			<ul>
				<li><strong class="bold">Events</strong>: As <a id="_idIndexMarker1148"/>mentioned earlier, events represent a change in the state of a given environment or resource. This can be a state change in an application, an AWS resource, or even a SaaS partner service or application.</li>
				<li><strong class="bold">Rules</strong>: A <a id="_idIndexMarker1149"/>rule enables you to match an event to a target for processing. You can have a single rule route to a single target or a parallel processing route to multiple targets. There is no ordering of how the rules are processed but you can customize the JSON that's sent to the target to ensure only data of interest is passed on to the target.</li>
				<li><strong class="bold">Targets</strong>: A<a id="_idIndexMarker1150"/> target can process these events and perform some action. Targets include Lambda functions, SNS topics, ECS tasks, and SQS queues. Events are passed on to targets in JSON format.</li>
				<li><strong class="bold">Event buses</strong>: Event<a id="_idIndexMarker1151"/> buses can receive events. You have a default bus in your AWS account that is used to receive events from AWS services, but you can also create custom events for your custom applications. Partner event buses can be used to receive events from partner SaaS applications and services, which are then directed to your AWS account.</li>
			</ul>
			<p>In this section, we looked at Amazon EventBridge, which allows you to stream real-time events from your applications, SaaS-based services, and AWS services to a variety of targets for processing. Targets can include AWS Lambda functions, Kinesis streams, ECS tasks, and SQS queues, among others. In addition, you can configure Amazon EventBridge <a id="_idIndexMarker1152"/>to <a id="_idIndexMarker1153"/>handle scheduled events that are triggered on a defined schedule. Amazon EventBridge offers more flexibility and advanced features compared to the previous CloudWatch Events services. </p>
			<p>In the next section, we will look at task-oriented integration services such as Amazon Step Functions and Amazon SWF. </p>
			<h1 id="_idParaDest-259"><a id="_idTextAnchor262"/>Coordinating multiple AWS services into serverless workloads with Amazon Step Functions and Amazon SWF</h1>
			<p>In<a id="_idIndexMarker1154"/> this<a id="_idIndexMarker1155"/> section, we'll<a id="_idIndexMarker1156"/> look<a id="_idIndexMarker1157"/> at two different AWS services that enable you to design task-based workflows between your application components. The first service we will look at is AWS Step Functions, while the second will be AWS SWF.</p>
			<h2 id="_idParaDest-260"><a id="_idTextAnchor263"/>AWS Step Functions</h2>
			<p>Applications <a id="_idIndexMarker1158"/>tend to have several components that make up individual workflows and processes. Each workflow represents an element of the application that then leads on to the next to provide a complete end-to-end solution. Amazon Step Functions enables you to define these workflows as a series of state machines that contain "states" that make up the workflow. These states make decisions based on input, perform some action, and produce an output to other states. </p>
			<p>States can be any of the following types:</p>
			<ul>
				<li><strong class="bold">Success or fail state</strong>: Where the execution stops with a success or failure</li>
				<li><strong class="bold">Wait state</strong>: Where the state waits for a timeout period or a scheduled time</li>
				<li><strong class="bold">Parallel state</strong>: Where the state performs parallel branches of execution</li>
				<li><strong class="bold">Map state</strong>: Where the state accesses a list of items such as a list of orders</li>
				<li><strong class="bold">Choice state</strong>: Where the state chooses between branches of execution</li>
				<li><strong class="bold">Task state</strong>: A state that focuses on carrying out a specific task and may call other AWS services, such as Lambda functions, to perform the task </li>
			</ul>
			<p>The state machine coordinates work through the different states and uses the task state to perform the actual work. Steps Functions helps you visualize your workflow as a series of event-driven steps, as well as the state of each step in your workflow to make sure that your application runs in a defined order.</p>
			<p>Amazon Step<a id="_idIndexMarker1159"/> Functions makes use of the <strong class="bold">Amazon States Language</strong> (<strong class="bold">ASL</strong>). This is a JSON-formatted structured language that helps you define your state machines, including states such as <strong class="bold">Task</strong> states, which perform certain actions. ASL is used to define how states transition from one state to the next, as in the case of the <strong class="bold">Choice</strong> state, or when you need to stop execution with an error, as in the case of a <strong class="bold">Fail</strong> state, and so on.</p>
			<p>With Step Functions, you can also introduce human interaction, particularly where manual intervention is required. Let's look at an example of a credit card application process. You are likely to have several steps that form part of the application process. In the<a id="_idIndexMarker1160"/> following diagram, we can see those steps in detail:</p>
			<div>
				<div id="_idContainer227" class="IMG---Figure">
					<img src="Images/B17124_10_08.jpg" alt="Figure 10.8 – Example of a credit card application workflow&#13;&#10;" width="1420" height="619"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.8 – Example of a credit card application workflow</p>
			<p>In the preceding diagram, we have a Step Functions workflow process that illustrates how a potential customer could apply for a new credit card. The initial workflow would involve signing up for a credit card, which would require the customer's details to be verified. The next step could involve enabling a customer to choose the level of credit required. This workflow may include the following steps:</p>
			<ol>
				<li value="1">New customers sign up for a credit card. The initial process involves checking the user's details. Several parallel Lambda functions can be invoked to perform the required verification. For example, in the UK, the customer's name and address could be verified against the electoral roll. </li>
				<li>If the automatic verification process is successful, then a review is not required, and the next step is invoked. If a review is required, then human intervention may be required to perform additional verification tasks. If the human verification is successful, the next step can be invoked; otherwise, the application can be rejected.</li>
				<li>Next, the customer is offered an auto-approval credit amount. The customer is also given the choice to select a higher credit value, which will be subject to additional reviews. If the customer chooses a credit value that is within the auto-approval credit amount, then the application is automatically approved. If the customer chooses a credit value higher than the auto-approval credit amount, then another human intervention step is required. Here, the credit card company may request additional information such as salary slips to check the customer's credit-worthiness. </li>
				<li>If the human intervention is successful, the application is approved; if not, the application will be rejected. There may be additional steps in the workflow for appealing against the rejection decision.</li>
			</ol>
			<p>Step Functions <a id="_idIndexMarker1161"/>enables us to build distributed application solutions and design microservices interactions to provide a complete end-to-end solution. Next, we will look at the different types of workflows you can set up for Step Functions.</p>
			<h2 id="_idParaDest-261"><a id="_idTextAnchor264"/>Workflow types</h2>
			<p>With Amazon <a id="_idIndexMarker1162"/>Step Functions, you can configure two types of workflows, as follows:</p>
			<ul>
				<li><strong class="bold">Standard workflow</strong>: These <a id="_idIndexMarker1163"/>have an exactly once workflow execution and can run for up to 1 year. Standard workflows are ideal if you require human interaction and approval processes as part of your workflow. You are charged on a per-state transition basis, which is each time a step in your execution is completed. Standard workflows also provide access to execution history and visual debugging.</li>
				<li><strong class="bold">Express workflow</strong>: These<a id="_idIndexMarker1164"/> have at least once workflow execution but can only run for up to 5 minutes. Express workflows are ideal for automated tasks and high event rate workloads, such as streaming data processing and IoT data ingestion. You are charged based on the number and duration of executions. Express workflows also offer unlimited state transition rates. Finally, all execution history is sent to Amazon CloudWatch.</li>
			</ul>
			<p>Here is an example of a simple workflow that creates a task timer. In this example, a Step Functions state machine is being configured that implements a <strong class="bold">Wait</strong> state and uses a Lambda<a id="_idIndexMarker1165"/> function to send out an Amazon SNS notification after the waiting period is over. The message that's sent out by the task is a simple <em class="italic">Hello World</em> message. The following screenshot shows the workflow and associated JSON:</p>
			<div>
				<div id="_idContainer228" class="IMG---Figure">
					<img src="Images/B17124_10_09.jpg" alt="Figure 10.9 – AWS Step Functions task timer example&#13;&#10;" width="1650" height="883"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.9 – AWS Step Functions task timer example</p>
			<p>In this section, we looked at the two types of Step Functions execution types and identified the core difference between the two. Step Functions workflows can run for up to 1 year (when using the standard workflow type), so they are particularly useful for long-running application models that may also require human interaction. An example is a health insurance claim application process, which may require human intervention to verify the hospital <a id="_idIndexMarker1166"/>bills and treatment that's dispensed to the claimant. In the next section, we will examine another task-oriented application integration service known as Amazon SWF. </p>
			<h2 id="_idParaDest-262"><a id="_idTextAnchor265"/>Amazon Simple Workflow Service (SWF)</h2>
			<p>Amazon SWF<a id="_idIndexMarker1167"/> is another task-oriented application integration service that allows you to coordinate work across distributed components of your application. Such coordination of tasks may involve processes such as managing dependencies, scheduling tasks, and handling the retries and timeouts of tasks to complete the logical workflow for your application. </p>
			<p>Amazon SWF has a concept where you implement "workers" to complete your tasks. Workers can run either in the cloud across AWS EC2 instances or on the compute services available in your on-premises locations. As part of the logical workflow, Amazon SWF also allows you to incorporate human interaction within the logical distribution of tasks like Amazon Step Functions, as discussed in the previous section. With Amazon SWF, you can store tasks, assign them to workers, track progress, and maintain states. </p>
			<p>While all of this sounds fairly like Amazon Step Functions, a key difference is that with Amazon SWF, <a id="_idTextAnchor266"/>you must write decider programs in any language that gets the latest state of each task from Amazon SWF and uses it to initiate subsequent tasks.</p>
			<p>Amazon Step <a id="_idIndexMarker1168"/>Functions, on the other hand, offers a fully managed service that has a more productive and agile approach to coordinating application components using visual workflows. If you are building new applications on AWS, you should consider using Amazon Step Functions. However, if you require external services to interact with your processes or you need to launch nested processes where a child process needs to return results to a parent process, you should consider using Amazon SWF. </p>
			<p>In this section, we provided a brief introduction to Amazon SWF. Amazon SWF enables you to coordinate tasks across your distribution application components while offering capabilities such as maintaining their execution state durably and reliably. </p>
			<h1 id="_idParaDest-263"><a id="_idTextAnchor267"/>Exercise 10.1 – Amazon S3 event notification using Amazon SNS</h1>
			<p>In the <a id="_idIndexMarker1169"/>previous chapter, you designed, architected, and deployed a complete web application using several AWS services. One such service was the Amazon S3 service, where you created a bucket to host your application source code repository. The source code was comprised of multiple files that helped you build your web application. </p>
			<p>Maintaining this source code is of paramount importance and any changes that are made to the code need to be monitored. There are several best practice strategies you can use to manage your source code, including using DevOps principles. In this exercise, your senior administrator, <strong class="bold">Alice</strong>, would like to know whenever a new file (object) gets uploaded to this source code repository, which is stored in the Amazon S3 bucket. </p>
			<p>Amazon S3 comes with a feature known as event notifications. This feature enables you to receive notifications when certain events occur in your S3 bucket, such as an object being created or deleted. The service can be configured to send out such notifications to an Amazon SNS topic, which an administrator can subscribe to using an email as the endpoint. Let's<a id="_idIndexMarker1170"/> configure an Amazon S3 notification to send email alerts to <strong class="bold">Alice</strong> whenever a new file is uploaded (that is, created) to the S3 bucket that hosts the source code repository.</p>
			<p>This exercise is divided into four main steps, as described in the following sub-sections.</p>
			<h2 id="_idParaDest-264"><a id="_idTextAnchor268"/>Step 1 – creating an SNS topic and subscribing to the topic</h2>
			<p>The first <a id="_idIndexMarker1171"/>step is to<a id="_idIndexMarker1172"/> create an SNS topic that will be used as the logical access point that Alice will subscribe to. Messages sent to this topic will then be emailed to Alice:</p>
			<ol>
				<li value="1">From the AWS Management Console, search for <strong class="source-inline">SNS</strong> in the top search box and select the service to be taken to the Amazon SNS dashboard.</li>
				<li>If you have never created an SNS topic before, you should see the Amazon SNS splash screen.</li>
				<li>Click on the far left-hand menu icon, denoted by the three lines, to expand the sidebar.</li>
				<li>Next, click on the <strong class="bold">Topics</strong> link from the menu.</li>
				<li>Click the <strong class="bold">Create topic</strong> button in the right-hand pane of the screen.</li>
				<li>On the <strong class="bold">Create topic</strong> page, in the <strong class="bold">Details</strong> section, select the <strong class="bold">Standard</strong> type under <strong class="bold">Type</strong>.</li>
				<li>Enter a name for the topic; for example, <strong class="source-inline">source-code-changes</strong>. Next, enter a <a id="_idIndexMarker1173"/>display<a id="_idIndexMarker1174"/> name for the topic; for example, <strong class="source-inline">Source Code Changes Alert</strong>.</li>
				<li>Leave all the remaining settings as their default values and click the <strong class="bold">Create topic</strong> button.</li>
				<li>Once the topic has been created, you will be redirected to the topic page. Make a note of the topic's ARN, as per the following screenshot:<div id="_idContainer229" class="IMG---Figure"><img src="Images/B17124_10_10.jpg" alt="Figure 10.10 – Amazon SNS topic&#13;&#10;" width="1159" height="549"/></div><p class="figure-caption">Figure 10.10 – Amazon SNS topic</p></li>
				<li>Now that you have created a topic, you can create a subscription for it. We will be using email as the endpoint for notifications, and you can use your email address to receive the notifications.</li>
				<li>In the bottom pane of the topics page, as per the previous screenshot, you will find a <a id="_idIndexMarker1175"/>section <a id="_idIndexMarker1176"/>to create subscriptions. Click on the <strong class="bold">Create subscription</strong> button.</li>
				<li>On the <strong class="bold">Create subscription</strong> page, you will note that the topic ARN is already selected. If not, ensure that you paste the topic ARN that you made a note of earlier.</li>
				<li>Next, under <strong class="bold">Protocol</strong>, select <strong class="bold">Email</strong> from the drop-down list.</li>
				<li>In the text box under <strong class="bold">Endpoint</strong>, provide your email address.</li>
				<li>Click the <strong class="bold">Create subscription</strong> button at the bottom of the page.</li>
				<li>You will get a confirmation statement to say that your subscription has been created. However, its status will be set to <strong class="bold">Pending confirmation</strong>. AWS will have sent you a confirmation request to your email account. You will need to log into your email account and confirm the subscription to activate it. I have just logged into my email account to do the same, as per the following screenshot of my Gmail account:<div id="_idContainer230" class="IMG---Figure"><img src="Images/B17124_10_11.jpg" alt="Figure 10.11 – Email subscription request for topic subscription&#13;&#10;" width="998" height="420"/></div><p class="figure-caption">Figure 10.11 – Email subscription request for topic subscription</p></li>
				<li>Once you confirm your subscription, return to the Amazon SNS dashboard and click on the <strong class="bold">Topics</strong> link from the left-hand menu.</li>
			</ol>
			<p>Now that you <a id="_idIndexMarker1177"/>have confirmed<a id="_idIndexMarker1178"/> your subscription to the topic, you can configure an access policy that will grant the Amazon S3 service the permissions to send notifications to the topic.</p>
			<h2 id="_idParaDest-265"><a id="_idTextAnchor269"/>Step 2 – configuring your SNS topic policy</h2>
			<p>For Amazon<a id="_idIndexMarker1179"/> S3 to send notifications to the SNS topic you just created, you will need to configure an <strong class="bold">access policy</strong>. An<a id="_idIndexMarker1180"/> access policy defines who or what can access your topic and publish messages to it. We have provided a sample policy document in the GitHub repository for this study guide that you will need to amend <a href="https://github.com/PacktPublishing/AWS-Certified-Cloud-Practitioner-Exam-Guide">https://github.com/PacktPublishing/AWS-Certified-Cloud-Practitioner-Exam-Guide</a>. You will need to have the following information before editing the policy:</p>
			<ul>
				<li>The ARN of the SNS topic, which you made a note of earlier.</li>
				<li>The Amazon ARN of the S3 bucket, which you created in the previous chapter. You can find the bucket ARN by clicking on the <strong class="bold">Properties</strong> tab on the bucket details page within your Amazon S3 dashboard.</li>
				<li>The AWS account ID (which you can obtain by clicking on your account name in the top right-hand corner of the screen and making a note of the 12-digit number next to <strong class="bold">My Account</strong>).</li>
			</ul>
			<p>Open the sample access policy document in Notepad or a text editor of your choice, as per the <a id="_idIndexMarker1181"/>following screenshot:</p>
			<div>
				<div id="_idContainer231" class="IMG---Figure">
					<img src="Images/B17124_10_12.jpg" alt="Figure 10.12 – Sample access policy&#13;&#10;" width="1159" height="689"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.12 – Sample access policy</p>
			<p>Replace the values in the policy, as highlighted by the arrows in the preceding screenshot, with the following:</p>
			<ul>
				<li>For <strong class="source-inline">Sid</strong>, change <strong class="source-inline">example-statement-ID</strong> to any relevant information you would like to use; for example, <strong class="source-inline">source-code-change-policy</strong>.</li>
				<li>For <strong class="source-inline">Resource</strong>, change <strong class="source-inline">SNS-topic-ARN</strong> to the ARN of your topic, making sure to place the ARN in double quotes.</li>
				<li>For <strong class="source-inline">ArnLike</strong>, change <strong class="source-inline">arn:aws:s3:*:*:bucket-name</strong> to the ARN of your bucket name.</li>
				<li>For <strong class="source-inline">StringEquals</strong>, change <strong class="source-inline">bucket-owner-account-id</strong> to your AWS account ID.</li>
			</ul>
			<p>Save the file and keep it handy for the next step of steps:</p>
			<ol>
				<li value="1">Navigate back to the Amazon SNS dashboard and from the left-hand menu, click ron <strong class="bold">Topics</strong>.</li>
				<li>Click on<a id="_idIndexMarker1182"/> your SNS topic in the middle pane, which will redirect you to the topic's details page, as per the following screenshot:<div id="_idContainer232" class="IMG---Figure"><img src="Images/B17124_10_13.jpg" alt="Figure 10.13 – SNS topic details page&#13;&#10;" width="1246" height="662"/></div><p class="figure-caption">Figure 10.13 – SNS topic details page</p></li>
				<li>Click on the <strong class="bold">Access policy</strong> tab in the bottom section of the pane.</li>
				<li>You will find a default access policy that allows only the topic owner to publish to the topic.</li>
				<li>In the top half of the pane, click on the <strong class="bold">Edit</strong> button.</li>
				<li>Next, expand the <strong class="bold">Access policy – optional</strong> section.</li>
				<li>Next, highlight and delete the existing policy that is in the JSON editor, and paste in a copy of your amended access policy instead.</li>
				<li>Finally, click the <strong class="bold">Save changes</strong> button at the bottom of the page.</li>
			</ol>
			<p>Now that <a id="_idIndexMarker1183"/>you have set up the SNS topic and an appropriate access policy, it is time to set the Amazon S3 event notification service.</p>
			<h2 id="_idParaDest-266"><a id="_idTextAnchor270"/>Step 3 – setting up the Amazon S3 event notification service</h2>
			<p>In this step, you<a id="_idIndexMarker1184"/> will configure the event notification service on your Amazon S3 source code bucket, which hosts your application repository to send out alerts every time a new file is uploaded to the bucket:</p>
			<ol>
				<li value="1">Navigate to the Amazon S3 dashboard and click on the <strong class="bold">Buckets</strong> link from the left-hand menu.</li>
				<li>From the right-hand pane, click on the Amazon S3 bucket that you created in the previous chapter to host your source code files.</li>
				<li>Next, click on the <strong class="bold">Properties</strong> tab and scroll down until you reach the <strong class="bold">Event Notifications</strong> section.</li>
				<li>Click the <strong class="bold">Create event notification</strong> button.</li>
				<li>Enter a name for your event, such as <strong class="source-inline">New files added alert</strong>. </li>
				<li>In the <strong class="bold">Event types</strong> section, tick the box that states <strong class="bold">All object create events</strong>.</li>
				<li>Scroll further down until you reach the <strong class="bold">Destination</strong> section.</li>
				<li>Select <strong class="bold">SNS topic</strong> from the <strong class="bold">Destination</strong> options.</li>
				<li>Under <strong class="bold">Specify SNS topic</strong>, select the SNS topic that you created earlier in <em class="italic">Step 1</em> from the <strong class="bold">SNS topic</strong> drop-down list.</li>
				<li>Finally, click the <strong class="bold">Save changes</strong> button.</li>
			</ol>
			<p>Now that you have configured S3 to send event notifications to your SNS topic, it is time to test the configuration.</p>
			<h2 id="_idParaDest-267"><a id="_idTextAnchor271"/>Step 4 – testing the configuration</h2>
			<p>In this step, we <a id="_idIndexMarker1185"/>will test out the configuration of our Amazon S3 event notification service: </p>
			<ol>
				<li value="1">In the Amazon S3 dashboard, from the left-hand menu, select <strong class="bold">Buckets</strong>.</li>
				<li>From the right-hand pane, select your Amazon S3 bucket, which will contain the source code files.</li>
				<li>Next, click on the <strong class="bold">Upload</strong> button.</li>
				<li>Go ahead and upload any random file you have access to. Alternatively, you can create a text file, save it, and then upload that text file instead. You can either use the <strong class="bold">Add files</strong> button to browse for a file on your computer or simply drag and drop a file from another file explorer window into the upload area.</li>
				<li>Upload your file to the Amazon S3 bucket by clicking on the <strong class="bold">Upload</strong> button at the bottom of the page.</li>
				<li>Once the upload has succeeded, click the <strong class="bold">Close</strong> button. Your object should be visible in the list of objects in the bucket.</li>
				<li>Access your<a id="_idIndexMarker1186"/> email account once again and check whether you have received a notification from AWS, alerting you to the fact that a new object has been uploaded. Refer to the following screenshot as an example:</li>
			</ol>
			<div>
				<div id="_idContainer233" class="IMG---Figure">
					<img src="Images/B17124_10_14.jpg" alt="Figure 10.14 – Amazon S3 event notification alert email&#13;&#10;" width="921" height="498"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.14 – Amazon S3 event notification alert email</p>
			<p>As you can <a id="_idIndexMarker1187"/>see, AWS has sent me an email, alerting me to the fact that an object was uploaded (created) in my Amazon S3 bucket. The email contains lots of information, including the time of the event, the alert's name, the bucket in question, the name of the object that was uploaded, as well as its size. As you can appreciate, this can be very useful for auditing purposes.</p>
			<p>Amazon S3 event notifications can use other destinations too, such as an SQS queue or a Lambda function. In this exercise, you learned how Amazon SNS can be used to push out notification messages to an email address. </p>
			<p>In the next exercise, you will perform a cleanup to remove any resources that are no longer required from our AWS account.</p>
			<h1 id="_idParaDest-268"><a id="_idTextAnchor272"/>Exercise 10.2 – cleaning up</h1>
			<p>In this exercise, you<a id="_idIndexMarker1188"/> will delete the resources that you created in the previous exercise as part of the cleanup process:</p>
			<ol>
				<li value="1">Navigate back to the Amazon SNS console.</li>
				<li>From the left-hand menu, select <strong class="bold">Topics</strong>.</li>
				<li>Next, from the right-hand pane, select the <strong class="bold">source-code-changes</strong> topic. Click the <strong class="bold">Delete</strong> button. </li>
				<li>You will be prompted to confirm the delete request with a dialog box. Type <strong class="source-inline">delete me</strong> in the confirmation text box and then click the <strong class="bold">Delete</strong> button. The topic will be deleted. </li>
			</ol>
			<p>Now that you have deleted the Amazon SNS topic, you can also delete the Amazon S3 bucket as we <a id="_idIndexMarker1189"/>no longer require it:</p>
			<ol>
				<li value="1">Navigate to the Amazon S3 console.</li>
				<li>From the left-hand menu, click on <strong class="bold">Buckets</strong>.</li>
				<li>From the right-hand pane, select the bucket that you uploaded your source code to earlier.</li>
				<li>You can only delete buckets if they are empty. This means that you have to delete the objects in your bucket first. With the bucket selected, click the <strong class="bold">Empty</strong> button. </li>
				<li>Next, you will be prompted to confirm that you wish to delete the objects by typing <strong class="source-inline">permanently delete</strong> in the confirmation text box. Then, you can click on the <strong class="bold">Delete</strong> button to empty the bucket.</li>
				<li>Now that the bucket has been emptied, you can delete it.</li>
				<li>Click the <strong class="bold">Exit</strong> button to go back to the list of buckets. With the bucket still selected, click the <strong class="bold">Delete</strong> button. Next, in the confirmation text box, type in the name of the bucket to confirm that you wish to delete it and click the <strong class="bold">Delete bucket</strong> button.</li>
			</ol>
			<p>Your Amazon S3 bucket will be successfully deleted. </p>
			<p>Next, we will provide a summary of this chapter and the key concepts that you learned. </p>
			<h1 id="_idParaDest-269"><a id="_idTextAnchor273"/>Summary</h1>
			<p>In this chapter, we examined the key application integration services that allow you to build highly robust and distributed application solutions. The array of services offered by AWS for application integration enables communication between the decoupled components of your applications, allowing you to move away from a monolithic architecture to one that can be built using microservices. The application integration tools available from AWS also help you design serverless solutions more easily, allowing you to further benefit from cost savings associated with server-based solutions.</p>
			<p>The various services you learned about in this chapter included Amazon SNS, Amazon SQS, and Amazon MQ, which are message-oriented application integration services. These enable communication between application components, which allows you to build loosely coupled application architectures. </p>
			<p>Amazon Step Functions and Amazon SWF are task-oriented application integration services that offer workflows that run for up to 1 year and can incorporate human intervention as part of the workflow process. Amazon Step Functions also helps you coordinate application components using visual workflows.</p>
			<p>Finally, we looked at Amazon EventBridge, which is a serverless event bus service that makes it easier to build event-driven applications. EventBridge can ingest and process events that are generated by your applications, partner <strong class="bold">Software-as-a-Service</strong> (<strong class="bold">SaaS</strong>) applications, and other AWS services.</p>
			<p>In the next chapter, we will look at a wide range of analytical services that are on offer from AWS that allow you to stream data from a wide range of sources, perform complex queries on ingested data, build data lakes, and build visualization dashboards and reporting.</p>
			<h1 id="_idParaDest-270"><a id="_idTextAnchor274"/>Questions</h1>
			<p>Answer the following questions to test your knowledge of this chapter:</p>
			<ol>
				<li value="1">Which AWS services does Amazon CloudWatch use to send out email alerts to administrators when alarms are triggered and enter the <strong class="source-inline">Alarm</strong> state?<ol><li>Amazon SNS</li><li>Amazon SES</li><li>Amazon CloudTrail</li><li>Amazon Email</li></ol></li>
			</ol>
			<ol>
				<li value="2">Which feature of Amazon CloudWatch enables you to create a visualization of metrics by resource type and service?<ol><li>CloudWatch Events</li><li>CloudWatch Logs</li><li>CloudWatch Alarms</li><li>CloudWatch dashboards</li></ol></li>
				<li>Which AWS application integration service can be configured to offer A2P communication using mobile SMS to send out text alerts?<ol><li>Amazon SQS</li><li>Amazon SNS</li><li>Amazon Amplify</li><li>Amazon Workspaces</li></ol></li>
				<li>You need to configure your Amazon SNS topic to push out messages of newly uploaded videos to an Amazon S3 bucket, across three different SQS queues. Each queue is designed to encode the raw video into a different resolution. Which feature of Amazon SNS enables you to push out such notifications in parallel?<ol><li>Amazon SNS standard topic</li><li>Amazon SNS FIFO topic</li><li>Fanout scenario</li><li>Amazon EventBridge</li></ol></li>
				<li>Which Amazon SQS queue type offers maximum throughput, best-effort ordering, and at least one delivery?<ol><li>SQS standard queue</li><li>SQS power queue</li><li>SQS FIFO queue</li><li>SQS LIFO queue</li></ol></li>
				<li>Which AWS service is designed to help you build a decoupled application architecture where incoming web requests can be held in a queue until a backend application can retrieve and process the request? <ol><li>Amazon SQS</li><li>Amazon SWF</li><li>Amazon SNS</li><li>Amazon Step Functions</li></ol></li>
				<li>You are required to configure an SQS queue for your application where the order of messages needs to be preserved for the application to function correctly. Which type of queue do you need to configure?<ol><li>SQS standard queue</li><li>SQS power queue</li><li>SQS FIFO queue</li><li>SQS LIFO queue</li></ol></li>
				<li>To reduce costs, you have been asked to automate the shutdown of a fleet of UAT test servers every weekday at 7 P.M. and then restart them the following weekday at 8 A.M. The servers should remain in the shutdown state at weekends. <p>Which AWS service can help you achieve the preceding requireme<a id="_idTextAnchor275"/>nts?</p><ol><li>Amazon SQS</li><li>Amazon Athena</li><li>Amazon EventBridge</li><li>Amazon SNS</li></ol></li>
				<li>Which AWS service enables you to manage application workflows as state machines by breaking them into multiple steps, adding flow logic, and tracking the inputs and outputs between the steps?<ol><li>Amazon Step Functions</li><li>Amazon SQS</li><li>Amazon SNS</li><li>Amazon SWF</li></ol></li>
				<li>Which AWS service offers an orchestration service to coordinate work across application components that make use of decider programs to determine the latest state of each task and use it to initiate subsequent tasks?<ol><li>Amazon SNS</li><li>Amazon EventBridge</li><li>Amazon SQS</li><li>Amazon SWF</li></ol></li>
			</ol>
		</div>
	</div></body></html>