<html><head></head><body>
		<div id="_idContainer067">
			<h1 id="_idParaDest-139" class="chapter-number"><a id="_idTextAnchor138"/>6</h1>
			<h1 id="_idParaDest-140"><a id="_idTextAnchor139"/>Recovering from Production Failures</h1>
			<p>We live in an imperfect world. We first see bugs escape into our production environment. Then, we may find as we start moving to DevOps practices, there are gaps in our understanding that affect how we deliver in our production environment. As we get those fixed, we may encounter other problems that are outside our control. What can we <span class="No-Break">possibly do?</span></p>
			<p>In this chapter, we will examine mitigating and dealing with failures that happen in production environments. We will look at the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>The costs of errors in <span class="No-Break">production environments</span></li>
				<li>Preventing as many errors as we can </li>
				<li>Practicing for failures using <span class="No-Break">chaos engineering</span></li>
				<li>Resolving incidents in production with an incident <span class="No-Break">management process</span></li>
				<li>Looking at fixing production failures by rolling back or <span class="No-Break">fixing forward</span></li>
			</ul>
			<h1 id="_idParaDest-141"><a id="_idTextAnchor140"/>Learning from failure</h1>
			<p>Production failures can happen at any time in the product development process, from the first deployment to <a id="_idIndexMarker443"/>supporting a mature product. When these production failures happen, depending on the impact, they may adversely affect the value the customer sees and potentially ruin a <span class="No-Break">business’s reputation.</span></p>
			<p>Often, we don’t see the lessons offered by these production failures until the failures happen or afterward when reading about such failures happening to another organization (or even <span class="No-Break">a competitor!).</span></p>
			<p>We will examine a sample of such famous production failures, hoping to glean lessons through the benefit of hindsight. The following examples include <span class="No-Break">the following:</span></p>
			<ul>
				<li>The rollout of <strong class="source-inline">healthcare.gov</strong> <span class="No-Break">in 2013</span></li>
				<li>The Atlassian cloud outage <span class="No-Break">in 2022</span></li>
			</ul>
			<p>Other lessons <a id="_idIndexMarker444"/>will come from other sections in <span class="No-Break">this chapter.</span></p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor141"/>healthcare.gov (2013)</h2>
			<p>In 2010, the <em class="italic">Patient Protection and Affordable Care Act</em> became law in the USA. A key part of this law, colloquially <a id="_idIndexMarker445"/>known as <em class="italic">Obamacare</em>, was the use of a website <a id="_idIndexMarker446"/>portal called <a href="http://healthcare.gov">healthcare.gov</a> that allowed individuals to find and enroll in an affordable health insurance plan through multiple marketplaces. The portal was required to go online on October <span class="No-Break">1, 2013.</span></p>
			<p><a href="http://healthcare.gov">healthcare.gov</a> was released on that date and immediately encountered problems. The initial demand upon launch, 250,000, was five times what was expected and caused the website to go down in the first 2 hours. By the end of the first day, a total of six users had successfully submitted applications to enroll in a health <span class="No-Break">insurance plan.</span></p>
			<p>A massive troubleshooting effort ensued, eventually allowing the website to handle 35,000 concurrent users, and registering 1.2 million users to a health insurance plan before the enrollment period closed in <span class="No-Break">December 2013.</span></p>
			<p>One of a number of reports looking at the <a href="http://healthcare.gov">healthcare.gov</a> debacle was written by Dr. Gwanhoo Lee and Justin Brumer. In the report (seen at <a href="https://www.businessofgovernment.org/sites/default/files/Viewpoints%20Dr%20Gwanhoo%20Lee.pdf">https://www.businessofgovernment.org/sites/default/files/Viewpoints%20Dr%20Gwanhoo%20Lee.pdf</a>), they specified the challenges of such a massive undertaking, which included <span class="No-Break">the following:</span></p>
			<ul>
				<li>A complex IT system in a limited period <span class="No-Break">of time</span></li>
				<li>Policy problems that created uncertainty in <span class="No-Break">their implementation</span></li>
				<li>High-risk contracting with <span class="No-Break">limited timeframes</span></li>
				<li>A lack <span class="No-Break">of leadership</span></li>
			</ul>
			<p>Lee and Brumer also identified a series of missteps from the early stages of the design and development of the portal that would serve to doom the project. These included <span class="No-Break">the following:</span></p>
			<ul>
				<li>A lack of alignment between the government policy and the technical implementation of <span class="No-Break">the portal</span></li>
				<li>Inadequate <span class="No-Break">requirements analysis</span></li>
				<li>Failure to identify and <span class="No-Break">mitigate risks</span></li>
				<li>Lack <span class="No-Break">of leadership</span></li>
				<li>Inattention <a id="_idIndexMarker447"/>to <span class="No-Break">bad news</span></li>
				<li>Rigid <span class="No-Break">organizational culture</span></li>
				<li>Inattention to project <span class="No-Break">management fundamentals</span></li>
			</ul>
			<h3>Fixing healthcare.gov</h3>
			<p>One of the efforts that <a id="_idIndexMarker448"/>came about after the disastrous initial launch of <a href="http://healthcare.gov">healthcare.gov</a> was the Tech Surge, a takeover by software developers from Silicon Valley, who refactored major parts of the <a href="http://healthcare.gov">healthcare.gov</a> website. The teams in the Tech Surge operated as small teams with a start-up mentality and were accustomed to the use of Agile practices that brought close collaboration, DevOps tools such as New Relic, and <span class="No-Break">cloud infrastructures.</span></p>
			<p>One of the offshoots <a id="_idIndexMarker449"/>from the Tech Surge was a small group of coders led by Loren Yu and Kalvin Wange, known as <strong class="bold">Marketplace Lite</strong> (<strong class="bold">MPL</strong>). They started <a id="_idIndexMarker450"/>as part of the Tech Surge and worked with existing teams at the <strong class="bold">Centers for Medicare and Medicaid Services</strong> (<strong class="bold">CMS</strong>), showing them new practices, such as collaborating over chat instead of emails, as they rewrote the parts of the website to log in and register for a <span class="No-Break">new plan.</span></p>
			<p>MPL continued to work on <a href="http://healthcare.gov">healthcare.gov</a> as many of the contracts ran out for other developers of the Tech Surge. It continued to work alongside CMS to improve systems testing and <a id="_idIndexMarker451"/>deliver fixes incrementally, as demonstrated in a <strong class="bold">Government Accountability Office</strong> (<strong class="bold">GAO</strong>) report at the time. The efforts were starting to bear serious fruit. One of the rewritten parts that MPL worked on, <em class="italic">App 2.0</em>, the tool to register for new healthcare insurance, was <em class="italic">soft-launched</em> for only call centers but became so successful that it was the main tool for registering new applications for those who had a simple <span class="No-Break">medical history.</span></p>
			<p>The work of MPL and the Tech Surge and the success of subsequent rollouts of <a href="http://healthcare.gov">healthcare.gov</a> in further enrollment periods provided a proving ground for Agile and DevOps mindset and practices. Agencies such as 18F and the United States Digital Service took up the <a id="_idIndexMarker452"/>baton and began the job of coaching other federal agencies to apply Agile and DevOps to <span class="No-Break">technology projects.</span></p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor142"/>Atlassian cloud outage (2022)</h2>
			<p>On April 5, 2022, 775 of Atlassian’s more than 200,000 total customer organizations lost access to their Atlassian cloud sites, which served applications such as Jira Service Management, Confluence, Statuspage, and Opsgenie. Many of these customers remained without access for up to 14 days until service to the remaining sites was restored on <span class="No-Break">April 18.</span></p>
			<p>The root cause of the site outage was traced to a script used by Atlassian to delete old instances of Insight, a popular standalone add-on to Jira that was acquired by Atlassian in 2021. Insight eventually became bundled into Jira Service Management, but traces of the legacy app remained and needed to <span class="No-Break">be removed.</span></p>
			<p>A miscommunication occurred where the team responsible for running the script was given a list of site IDs as input for the script instead of a list of Insight instance IDs. What followed was the immediate deletion <span class="No-Break">of sites.</span></p>
			<p>Atlassian’s cloud architecture is composed of multi-tenant services that handle applications for more than one customer. A blanket restoration of services would have affected those customers whose sites weren’t deleted. Atlassian had the knowledge of how to restore a single site but had never anticipated needing to restore the number of sites they currently faced. Atlassian began restoring customer sites. Restoration of a bunch of sites would take 48 hours. A manual restoration effort would have taken weeks for all the missing sites; clearly, Atlassian needed <span class="No-Break">to automate.</span></p>
			<p>The automation effort was designed as Atlassian figured out a method to restore multiple sites at once. The automation was run starting on April 9 and accomplished the restoration of a site in 12 hours. Roughly 47% of the total sites were restored using automation by the time the last site was restored on <span class="No-Break">April 18.</span></p>
			<p>The bigger issue was communicating with the affected customers. Atlassian was first made aware of the incident through a customer support ticket, but it was not immediately aware of the total number of affected customers. This is because deleting the sites also deleted metadata containing customer information that would be used by the customer to create support tickets. Recovering the lost customer metadata was important for <span class="No-Break">customer notification.</span></p>
			<p>The inability of Atlassian to directly contact affected customers made a major communication <a id="_idIndexMarker453"/>problem even greater. Those customers not contacted by Atlassian began reaching out on social media sites such as Twitter and Reddit to get news of what had happened. A general tweet from Atlassian made its way on April 7. A blog article from Atlassian’s CTO, Sri Viswanath, with more detailed explanations came on April 12. After the incident was solved, a post-incident review report was made generally available on <span class="No-Break">April 29.</span></p>
			<h3>Lessons from the Atlassian outage</h3>
			<p>The Atlassian outage provided challenges both from a technical and a customer service perspective. The post-incident review outlined four major learning point that Atlassian must improve upon to prevent <a id="_idIndexMarker454"/>similar outages from occurring. These learnings included <span class="No-Break">the following:</span></p>
			<ul>
				<li>Changing the process of deleting production data to <em class="italic">soft deletes</em>, where it is easier to recover and will be removed only after a certain period of time <span class="No-Break">has elapsed.</span></li>
				<li>Looking at specific processes for multiple-site, multiple-product data for a larger set of <span class="No-Break">affected customers.</span></li>
				<li>Considering incident management for large-scale events. Atlassian had processes in place for one customer’s site. It now needed to consider large-scale incidents, affecting a large number <span class="No-Break">of customers.</span></li>
				<li>Improve customer communication during an incident. Atlassian started communication when it had a grasp of the cause and the efforts needed to correct the incident. This delay in communication allowed the incident to play out on <span class="No-Break">social media.</span></li>
			</ul>
			<p>But there are broader lessons for us as well. Failures in production can happen from the first deployment to any point in the life cycle of a product. Failures can happen to companies starting out with Agile and DevOps or companies such as Atlassian that have succeeded in using Agile and DevOps. With all of these companies, the key to handling production failures includes ensuring that the process roots out as many failures as possible, practicing for failures to determine the best process, and setting up a proper process when failure <span class="No-Break">does occur.</span></p>
			<p>To aid us in this, we turn to a growing discipline called <strong class="bold">Site Reliability Engineering</strong> (<strong class="bold">SRE</strong>). This discipline <a id="_idIndexMarker455"/>was created by Ben Treynor Sloss at Google to initially apply software development methods to system administration. Originally seen as a hybrid approach utilizing methods used in development groups for traditional system administration operations, SRE has grown to its own branch within DevOps to ensure continued reliable systems operations after automated deployment <span class="No-Break">has occurred.</span></p>
			<p>The first step is planning and prevention. Let’s start looking at the safeguards used by SRE for preventing <span class="No-Break">production failures.</span></p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor143"/>Prevention – pulling the Andon Cord</h1>
			<p>The <strong class="bold">Andon Cord</strong> holds a special place in Lean thinking. As part of the Toyota Production System, if you <a id="_idIndexMarker456"/>suspected a problem with a car on the assembly line, you would pull the cord that ran around on the assembly line, and it would stop the line. People would come to the spot where the Andon Cord was pulled to see the defect and determine, first, how to fix the defect, and second, what steps would be needed to prevent the defect from occurring in <span class="No-Break">the future.</span></p>
			<p>Taiichi Ohno, the creator of the Toyota Production System, uses the Andon Cord to practice <em class="italic">jidoka</em>, empowering anyone to stop work to examine and implement <span class="No-Break">continuous improvement.</span></p>
			<p>For site reliability engineers, the following ideas and principles are used as a way of implementing the <a id="_idIndexMarker457"/>Andon Cord and ensuring <span class="No-Break">continuous improvement:</span></p>
			<ul>
				<li>Planning for <a id="_idIndexMarker458"/>risk tolerance by <a id="_idIndexMarker459"/>looking at <strong class="bold">service-level indicators</strong> (<strong class="bold">SLIs</strong>), <strong class="bold">service-level objectives</strong> (<strong class="bold">SLOs</strong>), and <span class="No-Break">error budgets</span></li>
				<li>Enforcing release standards through <span class="No-Break">release engineering</span></li>
				<li>Collaborating on product launches with launch <span class="No-Break">coordination engineering</span></li>
			</ul>
			<p>Let’s examine these ideas in <span class="No-Break">closer detail.</span></p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor144"/>SLIs, SLOs, and error budgets</h2>
			<p>Many people are familiar with the concept of <strong class="bold">service-level agreements</strong> (<strong class="bold">SLAs</strong>), where if the <a id="_idIndexMarker460"/>service does not meet a threshold for service availability or <a id="_idIndexMarker461"/>responsiveness, the vendor is then liable to pay for <a id="_idIndexMarker462"/>that agreed-upon level of performance, typically in the form <span class="No-Break">of credits.</span></p>
			<p>If we take a look at the goal or threshold that an SLA is expected to achieve or maintain, that is called <a id="_idIndexMarker463"/>an SLO. Generally, there are three parts to <span class="No-Break">an SLO:</span></p>
			<ol>
				<li>The quality/component <span class="No-Break">to measure</span></li>
				<li>The <span class="No-Break">measurement periods</span></li>
				<li>The required threshold the quality must meet, typically written as a desired value or range <span class="No-Break">of values</span></li>
			</ol>
			<p>That quality or component to measure is known as an SLI. Common SLIs that are typically used include <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break">Latency</span></li>
				<li><span class="No-Break">Throughput</span></li>
				<li><span class="No-Break">Availability</span></li>
				<li><span class="No-Break">Error rate</span></li>
			</ul>
			<p>For every SLO, the time inside the <a id="_idIndexMarker464"/>measurement period where the threshold is not met is known as the error budget. Closely monitoring the error budget allows SREs to gauge whether the risk is <a id="_idIndexMarker465"/>acceptable to roll out a new release. If the error budget is almost exhausted, the SRE may decide that the focus should change from feature development to more technical work, such as enablers, which would enhance resiliency <span class="No-Break">and reliability.</span></p>
			<p>Teams generally want to understand an error budget in terms of allowable time. The following table may provide guidance on the maximum allowable error on a monthly and an <span class="No-Break">annual basis:</span></p>
			<table id="table001-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">SLO Percentage</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Monthly Allowed </strong><span class="No-Break"><strong class="bold">Error Budget</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Annual Allowed </strong><span class="No-Break"><strong class="bold">Error Budget</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>99% (1% margin <span class="No-Break">of error)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>7 hours, <span class="No-Break">18 minutes</span></p>
						</td>
						<td class="No-Table-Style">
							<p>87 hours, <span class="No-Break">39 minutes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>99.5 (0.5% margin <span class="No-Break">of error)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>3 hours, <span class="No-Break">39 minutes</span></p>
						</td>
						<td class="No-Table-Style">
							<p>43 hours, 49 minutes, 45 seconds </p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>99.9% (0.1% margin <span class="No-Break">of error)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>43 minutes, <span class="No-Break">50 seconds</span></p>
						</td>
						<td class="No-Table-Style">
							<p>8 hours, 45 minutes, <span class="No-Break">57 seconds</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>99.95% (0.05% margin <span class="No-Break">of error</span></p>
						</td>
						<td class="No-Table-Style">
							<p>21 minutes, <span class="No-Break">54 seconds</span></p>
						</td>
						<td class="No-Table-Style">
							<p>4 hours, 22 minutes, <span class="No-Break">48 seconds</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>99.99% (0.01% margin <span class="No-Break">of error)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>4 minutes, <span class="No-Break">23 seconds</span></p>
						</td>
						<td class="No-Table-Style">
							<p>52 minutes, <span class="No-Break">35 seconds</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 6.1 – Error budgets in terms of allowable monthly and annual time</p>
			<p>The journey to implementing SLOs often begins with an evaluation of the product or service. From there, look <a id="_idIndexMarker466"/>at the components or microservices that make up the product: which parts of these, if not available, would contribute to unhappiness for <span class="No-Break">the customer?</span></p>
			<p>After the discovery of components critical to customer happiness, choose those measurements (SLIs) to capture and set up your goals (SLOs), making sure that the measurements give true <a id="_idIndexMarker467"/>indicators of potential problems and that the goals are realistic and attainable (100% of any measurement is not attainable). Start with a small set of SLOs. Communicate these SLOs to your customer so that they understand the role SLOs will play in making a better product and <span class="No-Break">the expectations.</span></p>
			<p>SLIs, SLOs, and error budgets should be documented as policy, but the policy is meant to change and adjust. After some time, reevaluate the SLIs, SLOs, and error budget to see whether these measurements are effective, and revise the SLIs and SLOs <span class="No-Break">as needed.</span></p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor145"/>Release engineering</h2>
			<p>To ensure that SLOs are <a id="_idIndexMarker468"/>maintained, site reliability engineers need to ensure that anything that is released to a customer is reliable and may not contribute to an outage. To that end, they work with software engineers to make sure releases <span class="No-Break">are low-risk.</span></p>
			<p>Google details this <a id="_idIndexMarker469"/>collaboration as release engineering. This aspect of SRE is guided by the <span class="No-Break">following principles:</span></p>
			<ul>
				<li><span class="No-Break">Self-service</span></li>
				<li><span class="No-Break">High velocity</span></li>
				<li><span class="No-Break">Hermetic builds</span></li>
				<li>Policy/procedure enforcement </li>
			</ul>
			<p>Let’s look at these four parts of the release engineering <span class="No-Break">philosophy now.</span></p>
			<h3>Allowing release autonomy through a self-service model</h3>
			<p>For agility to prosper, the teams working must be independent and self-managing. Release engineering processes allow the teams to decide their own release cadence and when to actually release. This ability for teams to release when and how often they need to is aided <span class="No-Break">by automation.</span></p>
			<h3>Aiming for high velocity</h3>
			<p>If teams choose to release more often, they are often doing so with smaller batches of changes of highly tested code. More frequent releases of small changes reduce the risk of outages. This is especially helpful if you have a large <span class="No-Break">error budget.</span></p>
			<h3>Ensuring hermetic builds</h3>
			<p>We want consistency and <a id="_idIndexMarker470"/>repeatability in our build-and-release process. The build output should be identical no matter who creates it. This means that versions of dependent artifacts and tools such as libraries and compilers are standardized from test <span class="No-Break">to production.</span></p>
			<p>Of course, if problems occur out in production, a useful tactic for troubleshooting is known as <em class="italic">cherry-picking</em>, where the team starts with the last-known <em class="italic">good</em> production version, retrieved from <a id="_idIndexMarker471"/>version control, and inserts each change one by one until the problem is discovered. Strong version control procedures ensure that builds are hermetic and allow <span class="No-Break">for cherry-picking.</span></p>
			<h3>Having strongly enforced policies and procedures</h3>
			<p>Automated release processes that produce hermetic builds require standards of access control to ensure that builds are created on the correct build machines using the correct sources. The key is to <a id="_idIndexMarker472"/>avoid adding local edits or dependencies and only use verified code kept in <span class="No-Break">version control.</span></p>
			<p>These four principles we have discussed are really applied when looking at the automation that handles the following parts of the <span class="No-Break">release process:</span></p>
			<ul>
				<li><strong class="bold">Continuous integration/continuous </strong><span class="No-Break"><strong class="bold">deployment</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CI/CD</strong></span><span class="No-Break">)</span></li>
				<li><span class="No-Break">Configuration management</span></li>
			</ul>
			<p>We first saw these parts as automated implementations of the CI/CD pipeline in <a href="B18756_03.xhtml#_idTextAnchor066"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Automation for Efficiency and Quality</em>. Now, let’s see how we tie the process into <span class="No-Break">the automation.</span></p>
			<h3>CI/CD</h3>
			<p>The release <a id="_idIndexMarker473"/>process begins with a commit made to version control. This starts the build process with different tests automatically executed depending on the branch. Release branches run the unit tests as well as applicable system and <span class="No-Break">functional tests.</span></p>
			<p>When the tests pass, the build is labeled so that there is an audit trail of the build date, dependencies, target environment, and <span class="No-Break">revision number.</span></p>
			<h3>Configuration management</h3>
			<p>The files used by the configuration management tools are kept in version control. Versions of the <a id="_idIndexMarker474"/>configuration files are recorded with release versions <a id="_idIndexMarker475"/>as part of the audit trail so that we know which version of the configuration files is associated with which versions of <span class="No-Break">the release.</span></p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor146"/>Launch coordination engineering</h2>
			<p>Launching a new product or feature to customers may have greater expectations than iterative releases of existing products. To facilitate the release of new services, Google created a special <a id="_idIndexMarker476"/>consulting function within SRE called <strong class="bold">launch coordination </strong><span class="No-Break"><strong class="bold">engineering</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">LCE</strong></span><span class="No-Break">).</span></p>
			<p>The engineers in LCE perform a number of functions, all intended to ensure a smooth launch process. These functions <a id="_idIndexMarker477"/>include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Auditing the product or service to <span class="No-Break">ensure reliability</span></li>
				<li>Coordinating between multiple teams involved in <span class="No-Break">the launch</span></li>
				<li>Ensuring completion of tasks related to technical aspects of <span class="No-Break">the launch</span></li>
				<li>Signing off that a launch <span class="No-Break">is </span><span class="No-Break"><em class="italic">safe</em></span></li>
				<li>Training developers on integration with the <span class="No-Break">new service</span></li>
			</ul>
			<p>To aid launch coordination engineers in ensuring a smooth launch, a launch checklist is created. Depending on the product, engineers tailor the checklist, adding or removing the following <span class="No-Break">checklist items:</span></p>
			<ul>
				<li>Shared architecture <span class="No-Break">and dependencies</span></li>
				<li><span class="No-Break">Integration</span></li>
				<li><span class="No-Break">Capacity planning</span></li>
				<li>Possible <span class="No-Break">failure modes</span></li>
				<li><span class="No-Break">Client behavior</span></li>
				<li><span class="No-Break">Processes/automation</span></li>
				<li><span class="No-Break">Development process</span></li>
				<li><span class="No-Break">External dependencies</span></li>
				<li><span class="No-Break">Rollout planning</span></li>
			</ul>
			<p>We have seen techniques and processes SREs use to ensure that the product launch or code release is <a id="_idIndexMarker478"/>ready. We’ve seen the tolerance for failure through SLIs, SLOs, and error budgets. But do we know whether the SREs are ready if an <span class="No-Break">outage occurs?</span></p>
			<p>One way of determining is by simulating a failure and seeing the reaction. This is another tool that SREs use, called chaos engineering. Let’s take a look at <span class="No-Break">what’s involved.</span></p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor147"/>Preparation – chaos engineering</h1>
			<p>On September 20, 2015, <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) experienced an outage with more than 20 services <a id="_idIndexMarker479"/>out of its data centers in the US-EAST-1 region. These services <a id="_idIndexMarker480"/>affected applications from major companies such as Tinder, Airbnb, and IMDb, as well as Amazon’s own services such <span class="No-Break">as Alexa.</span></p>
			<p>One of AWS’s customers that was able to avoid problems during the outage and remain fully operational was Netflix, the streaming service. It was able to do so because it created a series of tools that it called the <em class="italic">Simian Army</em>, discussed in this blog article at <a href="https://netflixtechblog.com/the-netflix-simian-army-16e57fbab116">https://netflixtechblog.com/the-netflix-simian-army-16e57fbab116</a>, which simulated potential problems with AWS so that Netflix engineers could design ways to make their system <span class="No-Break">more resilient.</span></p>
			<p>Over several AWS outages, the Simian Army proved its worth, allowing Netflix to continue providing service. Soon, other companies such as Google started wanting to apply the same techniques. This groundswell of support led to the creation of the discipline of <span class="No-Break">chaos engineering.</span></p>
			<p>Let’s take a closer look at <a id="_idIndexMarker481"/>the following aspects of <span class="No-Break">chaos engineering:</span></p>
			<ul>
				<li><span class="No-Break">Principles</span></li>
				<li><span class="No-Break">Experiments</span></li>
			</ul>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor148"/>Chaos engineering principles</h2>
			<p>The key to chaos engineering is experimentation in production environments. The idea of performing reliability <a id="_idIndexMarker482"/>experiments in production does seem to be laden with risk. This risk, though, is tempered by your confidence in the resiliency of <span class="No-Break">the system.</span></p>
			<p>To guide confidence, chaos engineering starts with the <span class="No-Break">following principles:</span></p>
			<ul>
				<li>Build your hypothesis around the steady-state behavior of your <span class="No-Break">production environment</span></li>
				<li>Create variables that simulate <span class="No-Break">real-world events</span></li>
				<li>Run the experiment in your <span class="No-Break">production environment</span></li>
				<li>Automate <a id="_idIndexMarker483"/><span class="No-Break">the experiment</span></li>
				<li>Minimize the <span class="No-Break">experiment’s fallout</span></li>
			</ul>
			<p>Let’s discuss these principles <span class="No-Break">in detail.</span></p>
			<h3>Basing experiments around steady-state behavior</h3>
			<p>In devising our experiments, we really want to focus on the system outputs rather than the individual components of the system. These outputs form the basis of how our environment behaves in a steady state. The focus in chaos engineering is on the verification of the behavior and not on the validation of <span class="No-Break">individual components.</span></p>
			<p>Mature organizations that look at chaos engineering as a key part of SRE know that this steady-state behavior typically forms the basis <span class="No-Break">for SLOs.</span></p>
			<h3>Creating variables that simulate real-world events</h3>
			<p>Given the known steady-state behavior, we consider <em class="italic">what-if</em> scenarios that happen in the real world. Each event you consider then becomes <span class="No-Break">a variable.</span></p>
			<p>One of the famous tools in Netflix’s Simian Army, <em class="italic">Chaos Monkey</em>, was based on the event that a virtual server node in AWS would become unavailable. So, it tested for that <span class="No-Break">condition only.</span></p>
			<h3>Running the experiment in production</h3>
			<p>Running the experiment in a staging or <em class="italic">production-like</em> environment is beneficial, but at some point, you need to run the experiment with its variable in the production environment to see the effects on real-world processing of <span class="No-Break">real traffic.</span></p>
			<p>At Netflix, Chaos Monkey was run every day in production. It would look at every cluster in operation and randomly deactivate one of <span class="No-Break">the nodes.</span></p>
			<h3>Automating the experiment</h3>
			<p>The benefits of learning from chaos engineering experiments are only apparent when experiments are run consistently and frequently. To achieve this, automating the experiment <span class="No-Break">is necessary.</span></p>
			<p>Chaos Monkey was not initially popular with Netflix engineers when initially rolled out. The idea that every day, this program would intentionally cause errors in production did not sit well with them, but it did consistently raise the problem that instances could vanish. With this problem, engineers had a mandate to find solutions and make the system <span class="No-Break">more resilient.</span></p>
			<h3>Minimizing the fallout</h3>
			<p>Because you are running your experiment in the production environment, your customers who are also using that environment may be affected. Your job is to make sure the fallout from running the experiment <span class="No-Break">is minimized.</span></p>
			<p>Chaos Monkey was run once per day, but only during business hours. This would be to ensure that if any ill effects to production were discovered, it would be while most of the engineers were <a id="_idIndexMarker484"/>present and not off-hours such as at 3 A.M. when there would only be a <span class="No-Break">skeleton crew.</span></p>
			<p>With these principles in place, let’s apply them and look at <span class="No-Break">creating experiments.</span></p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor149"/>Running experiments in chaos engineering</h2>
			<p>Experimenting in <a id="_idIndexMarker485"/>production involves planning and developing a process. The goal of the experiment is to find those weak areas that could be more resilient to ensure SLOs are kept. The goal is not to <em class="italic">break </em><span class="No-Break"><em class="italic">the system</em></span><span class="No-Break">.</span></p>
			<p>In <em class="italic">Chaos Engineering: System Resiliency in Practice</em>, Richard Crowley writes a chapter dealing with creating the <em class="italic">Disasterpiece Theater</em> process for Slack. He outlines the following steps for <span class="No-Break">the process:</span></p>
			<ol>
				<li value="1">Make sure a <em class="italic">safety net</em> is <span class="No-Break">in place.</span></li>
				<li>Prepare for <span class="No-Break">the exercise.</span></li>
				<li>Run <span class="No-Break">the exercise.</span></li>
				<li>Debrief <a id="_idIndexMarker486"/>the results of <span class="No-Break">the exercise.</span></li>
			</ol>
			<p>Let’s examine the details of each <span class="No-Break">step now.</span></p>
			<h3>Ensuring the environment is ready for chaos</h3>
			<p>The goal of chaos engineering is to find weaknesses in resiliency, not to disable the environment. If the existing environment has no fault tolerance, there’s no point in <span class="No-Break">running experiments.</span></p>
			<p>Make sure there is spare capacity for services. That spare capacity should be easy to <span class="No-Break">bring online.</span></p>
			<p>Once the spare capacity and resources have been identified and allocated, have a plan to allow for the removal of malfunctioning resources and automatic replacement with the <span class="No-Break">spare capacity.</span></p>
			<h3>Preparing for the exercise</h3>
			<p>For Crowley, an exercise starts with a worry: Which critical component or service will fail, impacting resiliency? This becomes the basis for <span class="No-Break">the exercise.</span></p>
			<p>Crowley then takes this basis and works on expanding this to an exercise to run in development, staging, and production environments. He sets up a checklist, making sure each of the following items is fulfilled for <span class="No-Break">the exercise:</span></p>
			<ul>
				<li>Describe the server or service that is to fail, including the failure mode, and how to simulate <span class="No-Break">the failure.</span></li>
				<li>Identify the server or service in development and production environments, and confirm the method to simulate is possible in the <span class="No-Break">development environment.</span></li>
				<li>Identify how the failure should be detected. Will an alert be produced that will show up on dashboards? Will logs be produced? If you cannot imagine how it will be detected, it may still be worth running the exercise to determine a way to detect <span class="No-Break">the failure.</span></li>
				<li>Identify redundancies and mitigations that should eliminate or reduce the impact of the failure. Also, identify any runbooks that are run if the failure <span class="No-Break">should occur.</span></li>
				<li>Identify the relevant people that should be invited to contribute their knowledge to the exercise. These people may also be the first responders when the <span class="No-Break">exercise happens.</span></li>
			</ul>
			<p>Preparation culminates in <a id="_idIndexMarker487"/>a meeting with the relevant people to work out the necessary logistics of the exercise. When all the preparations are set, it’s time to run <span class="No-Break">the exercise.</span></p>
			<h3>Running the exercise</h3>
			<p>The exercise should be well publicized to all involved people before it is executed. After all, they will be participating in the exercise, with the goal of creating a more <span class="No-Break">resilient environment.</span></p>
			<p>Crowley executes the exercise with the <span class="No-Break">following checklist:</span></p>
			<ol>
				<li value="1">Make sure everyone is aware the exercise is being recorded. Make a recording if everyone <span class="No-Break">allows it.</span></li>
				<li>Review the plan created in the preparation step. Make adjustments <span class="No-Break">as necessary.</span></li>
				<li>Announce the beginning of the exercise in the <span class="No-Break">development environment.</span></li>
				<li>Create a failure in the development environment. Note <span class="No-Break">the timestamp.</span></li>
				<li>See whether alerts and logs are created for the failure. Note <span class="No-Break">the timestamp.</span></li>
				<li>If there are automated recovery steps, give them time <span class="No-Break">to execute.</span></li>
				<li>If runbooks are being used, follow them to resolve the failure in the development environment. Note the timestamp and whether any deviations from the <span class="No-Break">runbooks occurred.</span></li>
				<li>Have a go/no-go decision to duplicate this failure in the <span class="No-Break">production environment.</span></li>
				<li>Announce the beginning of the exercise in the <span class="No-Break">production environment.</span></li>
				<li>Create a failure in the production environment. Note <span class="No-Break">the timestamp.</span></li>
				<li>See whether alerts and logs are created for the failure. Note <span class="No-Break">the timestamp.</span></li>
				<li>If there are automated recovery steps, give them time <span class="No-Break">to execute.</span></li>
				<li>If runbooks are being used, follow them to resolve the failure in the production environment. Note the timestamp and whether any deviations from the <span class="No-Break">runbooks occurred.</span></li>
				<li>Announce the <a id="_idIndexMarker488"/>all-clear and conclusion of <span class="No-Break">the exercise.</span></li>
				<li>Perform <span class="No-Break">a debrief.</span></li>
				<li>Distribute the recording if one <span class="No-Break">was made.</span></li>
			</ol>
			<p>With the exercise complete, a key part of the exercise begins with the debrief, after the all-clear is announced. Let’s examine how to create a <span class="No-Break">learning debrief.</span></p>
			<h3>Debriefing for learning</h3>
			<p>Crowley recommends performing a debrief while the experience of the exercise is still fresh in everyone’s <a id="_idIndexMarker489"/>minds. During the debrief, only the facts are presented, with a summary of how well the system did (or <span class="No-Break">didn’t) perform.</span></p>
			<p>Crowley has the following starter questions to help display what was learned. These are offered as <span class="No-Break">a template:</span></p>
			<ul>
				<li>What was the time until detection? What was the time <span class="No-Break">until recovery?</span></li>
				<li>Did the end users notice when we ran the exercise in production? How do we know? Are there solutions to make that <span class="No-Break">answer </span><span class="No-Break"><em class="italic">no</em></span><span class="No-Break">?</span></li>
				<li>Which recovery steps could <span class="No-Break">be automated?</span></li>
				<li>Where were our <span class="No-Break">blind spots?</span></li>
				<li>What changes to our dashboards and runbooks have to <span class="No-Break">be made?</span></li>
				<li>Where do we need <span class="No-Break">more practice?</span></li>
				<li>What would our on-call engineers do if this <span class="No-Break">happened unexpectedly?</span></li>
			</ul>
			<p>The outcome of the exercise and the answers in the debrief can form recommendations for the next steps to add resiliency to the system. The exercise can be repeated to ensure that the system correctly identifies and resolves <span class="No-Break">the failure.</span></p>
			<p>Disasterpiece Theater <a id="_idIndexMarker490"/>can be an effective framework for performing your chaos engineering exercises. The flexibility of the exercise is dependent upon how resilient your system <span class="No-Break">is already.</span></p>
			<p>Even with regular chaos engineering exercises, bad things can still happen in your production environments that will affect your customers. Let’s look at ways to solve these production issues with <span class="No-Break">incident management.</span></p>
			<h1 id="_idParaDest-151"><a id="_idTextAnchor150"/>Problem-solving – enabling recovery</h1>
			<p>For SREs, a solid incident <a id="_idIndexMarker491"/>management process is important when things go wrong in production. A good incident management process allows you to follow these necessary goals, commonly referred to as <em class="italic">the </em><span class="No-Break"><em class="italic">three Cs</em></span><span class="No-Break">:</span></p>
			<ul>
				<li><strong class="bold">Coordinate</strong> <span class="No-Break">the response</span></li>
				<li><strong class="bold">Communicate</strong> between the incident participants, others in the organization, and interested parties in the <span class="No-Break">outside world</span></li>
				<li>Maintain <strong class="bold">control</strong> over the <span class="No-Break">incident response</span></li>
			</ul>
			<p>Google identified necessary elements to their incident command system in the <em class="italic">Managing Incidents</em> chapter written by Andrew Stribblehill in <em class="italic">Site Reliability Engineering: How Google Runs Production Systems</em>. These elements include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Clearly defined incident <span class="No-Break">management roles</span></li>
				<li>A (virtual or physical) <span class="No-Break">command post</span></li>
				<li>A living incident <span class="No-Break">state document</span></li>
				<li>Clear handoffs <span class="No-Break">to others</span></li>
			</ul>
			<p>Let’s look at these elements <span class="No-Break">in detail.</span></p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor151"/>Incident management roles</h2>
			<p>Upon recognition that <a id="_idIndexMarker492"/>what you are facing is truly an incident, a team should be assembled to work on the problem and share information until the incident is resolved. The team will have roles so that coordination is properly maintained. Let’s look at these roles <span class="No-Break">in detail.</span></p>
			<h3>The incident commander</h3>
			<p>The incident commander <a id="_idIndexMarker493"/>may start as the person who <a id="_idIndexMarker494"/>originally reports the incident. The incident commander embodies the <em class="italic">three Cs</em> by delegating the necessary roles to others. Any role not delegated is assumed to belong to the <span class="No-Break">incident commander.</span></p>
			<p>The incident commander will work with the other responders to resolve the incident. If there are any roadblocks, the incident commander will facilitate <span class="No-Break">their removal.</span></p>
			<h3>Operations lead</h3>
			<p>The operations lead will <a id="_idIndexMarker495"/>work together with the incident <a id="_idIndexMarker496"/>commander. They will run any needed tools to resolve the incident. The operations lead is the only person allowed to make changes to <span class="No-Break">the system.</span></p>
			<h3>Communications lead</h3>
			<p>The communications lead is the <a id="_idIndexMarker497"/>public face of the incident <a id="_idIndexMarker498"/>and its response. They are responsible for communication with outside groups and stakeholders. They may also ensure that the incident document is kept up <span class="No-Break">to date.</span></p>
			<h3>Incident planning/logistics</h3>
			<p>Planning and logistics will work with the operations people by working on longer-term issues of the incident <a id="_idIndexMarker499"/>such as arranging for <a id="_idIndexMarker500"/>handoffs between roles, ordering meals, and entering tickets in the bug tracking system. They will also track how the system has <a id="_idIndexMarker501"/>diverged from the norm so that <a id="_idIndexMarker502"/>it can be returned to normal when the incident <span class="No-Break">is resolved.</span></p>
			<h2 id="_idParaDest-153"><a id="_idTextAnchor152"/>The incident command post</h2>
			<p>A <em class="italic">war room</em> is needed for <a id="_idIndexMarker503"/>all members of the incident response team to convene and collaborate on the solution. This place should be where outside parties can meet with the incident commander and other members of the incident <span class="No-Break">response team.</span></p>
			<p>Because of <a id="_idIndexMarker504"/>distributed development, these command posts are typically virtual as opposed to a physical room. <strong class="bold">Internet Relay Chat</strong> (<strong class="bold">IRC</strong>) chat rooms or Slack channels can serve as the medium for gathering in <span class="No-Break">one </span><span class="No-Break"><em class="italic">spot</em></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-154"><a id="_idTextAnchor153"/>The incident state document</h2>
			<p>The incident commander’s main responsibility is to record all activity and information related to the incident in <a id="_idIndexMarker505"/>the incident state document. This is a living document, meant to be frequently updated. A wiki may suffice, but that typically allows only one person to edit it at <span class="No-Break">a time.</span></p>
			<p>Suitable alternatives may be a Confluence page or a document shared in a public Google Drive or Microsoft <span class="No-Break">SharePoint folder.</span></p>
			<p>Google maintains a template for an incident state document that can be used as a <span class="No-Break">starting point.</span></p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor154"/>Setting up clear handoffs</h2>
			<p>As we saw with Atlassian’s incident earlier in this chapter, incidents can stretch over several days or <a id="_idIndexMarker506"/>even weeks. So, the handoff of roles is essential, particularly for the incident commander. Communication must be clear to everyone that a handoff has taken place to minimize <span class="No-Break">any confusion.</span></p>
			<p>While in an incident, some actions that may help move toward a solution include rolling back or <em class="italic">rolling forward</em>. These may work if the root cause is diagnosed as a new change recently made. We’ll look at these alternatives in our <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-156"><a id="_idTextAnchor155"/>Perseverance – rolling back or fixing forward</h1>
			<p>If the reason for the production failure is a new change, a quick resolution may involve reverting to the state of the system before the change, or if a fix is found, immediately running it through the CI/CD pipeline to <span class="No-Break">immediately deploy.</span></p>
			<p>Some of the methods for rolling back or rolling forward a fix include the following ones. Let’s examine them <span class="No-Break">in detail.</span></p>
			<h2 id="_idParaDest-157"><a id="_idTextAnchor156"/>Rolling back with blue/green deployment</h2>
			<p>A blue/green deployment makes use of two production environments: one live and the other on standby. The live <a id="_idIndexMarker507"/>environment is the one that customers use, while the standby environment is there as a backup. The change is made on the standby environment and then the standby environment is made live. You can see an illustration of this type of <span class="No-Break">deployment here:</span></p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B18756_06_01.jpg" alt="Figure 6.1 – Blue/green deployment: ﻿environment switch"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – Blue/green deployment: environment switch</p>
			<p>As the preceding diagram indicates, both environments are still present, but only one has access to customer traffic. The arrangement remains this way until changes are deployed into the standby environment or a rollback becomes necessary, as illustrated in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B18756_06_02.jpg" alt="Figure 6.2 – Blue/green deployment: ﻿rollback"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Blue/green deployment: rollback</p>
			<p>A blue/green <a id="_idIndexMarker508"/>deployment works well when the environment is stateless—that is, there is no need to consider the state of data. Complications arise when the data’s state has to be considered in artifacts such as databases or <span class="No-Break">volatile storage.</span></p>
			<h2 id="_idParaDest-158"><a id="_idTextAnchor157"/>Rolling back with feature flags</h2>
			<p>We saw in <a href="B18756_03.xhtml#_idTextAnchor066"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Automation for Efficiency and Quality</em>, that feature flags allowed the propagation of <a id="_idIndexMarker509"/>changes to deployment without the change visible until the flag was <em class="italic">toggled on</em>. In this same way, if a new feature is the root cause of a production failure, the flag can be <em class="italic">toggled off</em> until the new feature can be fixed, as illustrated in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B18756_06_03.jpg" alt="Figure 6.3 – Rollback with a feature flag"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Rollback with a feature flag</p>
			<p>Rolling back by <a id="_idIndexMarker510"/>using feature flags allows for a quick change to previous behavior without extensive changes to the source code <span class="No-Break">or configuration.</span></p>
			<h2 id="_idParaDest-159"><a id="_idTextAnchor158"/>Rolling forward using the CI/CD pipeline</h2>
			<p>Rolling forward or <em class="italic">fixing forward</em> is the method of resolving an incident by developing a fix for the error, allowing it to <a id="_idIndexMarker511"/>go through the CI/CD pipeline so that it can be deployed into production. It can be an effective way to resolve the incident, especially if the change <span class="No-Break">is small.</span></p>
			<p>Fixing forward should be viewed as a <em class="italic">last resort</em>. If fixing forward is the only viable option, your product’s <a id="_idIndexMarker512"/>architecture may be too tightly coupled with dependent components. For example, if the new release depended on a change to the database schema and customer data was already stored in the new tables before the production failure was discovered, there may be no rollback without losing the <span class="No-Break">customer data.</span></p>
			<p>Changes that are intended to be released in a roll-forward solution should undergo the same process as normal releases. <em class="italic">Quick fixes</em> that may not follow the entire process, which may not have the same scrutiny and test coverage, may increase the technical debt by introducing errors in other parts of <span class="No-Break">the system.</span></p>
			<h1 id="_idParaDest-160"><a id="_idTextAnchor159"/>Summary</h1>
			<p>We examined in this chapter what happens when things go wrong in production. We began our chapter by looking at two incidents: the initial release of <a href="http://healthcare.gov">healthcare.gov</a> in 2013 and the Atlassian cloud outage in 2022. We learned from both incidents the importance of prevention and planning for <span class="No-Break">future incidents.</span></p>
			<p>We then explored methods of preparation by looking at important parts of the discipline of SRE. SRE begins this process by setting the SLIs and SLOs so that we have an idea of the tolerance of risk through the error budget. SRE also looks at the process of releasing new changes and launching <span class="No-Break">new products.</span></p>
			<p>We looked at practicing for disaster through the discipline of chaos engineering. We understood the principles behind the discipline and how to create experiments through the Disasterpiece <span class="No-Break">Theater process.</span></p>
			<p>Ultimately, even with adequate preparation, production failures will still happen. We looked at the key parts of Google’s incident management process for incident management and techniques for resolving incidents, such as rolling back or <span class="No-Break">fixing forward.</span></p>
			<p>With this, we have completed <em class="italic">Part 1: Approach – A Look at SAFe</em><em class="italic">®</em><em class="italic"> and DevOps through CALMR</em>. We will now look at a key activity of DevOps, value stream management, in <em class="italic">Part 2: Implement – Moving Toward </em><span class="No-Break"><em class="italic">Value Streams</em></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-161"><a id="_idTextAnchor160"/>Questions</h1>
			<p>Test your knowledge of the concepts in this chapter by answering <span class="No-Break">these questions.</span></p>
			<ol>
				<li value="1">What is an example of <span class="No-Break">an SLI?</span><ol><li><span class="No-Break">Velocity</span></li><li><span class="No-Break">Availability</span></li><li><span class="No-Break">Cycle time</span></li><li><span class="No-Break">Scalability</span></li></ol></li>
				<li>If your organization sets up an SLO of 99% availability on a monthly basis, what is your error budget if the acceptable downtime is <span class="No-Break">7.2 hours/month?</span><ol><li><span class="No-Break">0.072 hours/month</span></li><li><span class="No-Break">0.72 hours/month</span></li><li><span class="No-Break">7.2 hours/month</span></li><li><span class="No-Break">72 hours/month</span></li></ol></li>
				<li>Which is <em class="italic">NOT</em> a principle of <span class="No-Break">release engineering?</span><ol><li><span class="No-Break">Self-service model</span></li><li><span class="No-Break">High velocity</span></li><li><span class="No-Break">Dependent builds</span></li><li>Enforcement <span class="No-Break">of policy/procedures</span></li></ol></li>
				<li>Which company created Chaos Monkey and the <span class="No-Break">Simian Army?</span><ol><li><span class="No-Break">Netflix</span></li><li><span class="No-Break">Google</span></li><li><span class="No-Break">Amazon</span></li><li><span class="No-Break">Apple</span></li></ol></li>
				<li>Which of these are chaos engineering principles (<span class="No-Break">choose two)?</span><ol><li>Decentralized <span class="No-Break">decision making</span></li><li>Organize <span class="No-Break">around value</span></li><li>Minimize the <span class="No-Break">experiment’s fallout</span></li><li>Run the experiment <span class="No-Break">in production</span></li><li>Apply <span class="No-Break">systems thinking</span></li></ol></li>
				<li>Which role in Google’s incident command system is the primary author of the incident <span class="No-Break">state document?</span><ol><li><span class="No-Break">Operations lead</span></li><li><span class="No-Break">Incident commander</span></li><li><span class="No-Break">Communications lead</span></li><li><span class="No-Break">Planning/logistics</span></li></ol></li>
			</ol>
			<h1 id="_idParaDest-162"><a id="_idTextAnchor161"/>Further reading</h1>
			<p>Here are some resources for you to explore this <span class="No-Break">topic further:</span></p>
			<ul>
				<li><a href="https://www.businessofgovernment.org/sites/default/files/Viewpoints%20Dr%20Gwanhoo%20Lee.pdf">https://www.businessofgovernment.org/sites/default/files/Viewpoints%20Dr%20Gwanhoo%20Lee.pdf</a>—<em class="italic">Managing Mission-Critical Government Software Projects: Lessons Learned from the Healthcare.gov Project</em> by <em class="italic">Dr. Gwanhoo Lee</em> and <em class="italic">Justin Brumer</em>. An interesting look at the root causes of the <span class="No-Break">healthcare.gov debacle.</span></li>
				<li><a href="https://www.theatlantic.com/technology/archive/2015/07/the-secret-startup-saved-healthcare-gov-the-worst-website-in-america/397784/">https://www.theatlantic.com/technology/archive/2015/07/the-secret-startup-saved-healthcare-gov-the-worst-website-in-america/397784/</a>—A writeup of the efforts of the Tech Surge and MPL <span class="No-Break">in particular.</span></li>
				<li><a href="https://www.gao.gov/assets/gao-15-238.pdf">https://www.gao.gov/assets/gao-15-238.pdf</a>—A report from the GAO describing the initial problems with the <a href="http://healthcare.gov">healthcare.gov</a> launch and progress toward <span class="No-Break">needed fixes.</span></li>
				<li><a href="https://oig.hhs.gov/oei/reports/oei-06-14-00350.pdf">https://oig.hhs.gov/oei/reports/oei-06-14-00350.pdf</a>—A case study of the initial launch of <a href="http://healthcare.gov">healthcare.gov</a> and the changes brought about by Tech Surge that allowed success in subsequent launches. Created by the <strong class="bold">Office of the Inspector General</strong> (<strong class="bold">OIG</strong>) of <strong class="bold">Health and Human </strong><span class="No-Break"><strong class="bold">Services</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">HHS</strong></span><span class="No-Break">).</span></li>
				<li><a href="https://www.atlassian.com/engineering/post-incident-review-april-2022-outage">https://www.atlassian.com/engineering/post-incident-review-april-2022-outage</a>—Post-incident review of the Atlassian cloud outage from the current CTO, <span class="No-Break">Sri Viswanath.</span></li>
				<li><em class="italic">Site Reliability Engineering: How Google Runs Production Systems</em> edited by <em class="italic">Betsy Beyer</em>, <em class="italic">Chris Jones</em>, <em class="italic">Jennifer Petoff</em>, and <em class="italic">Niall Richard Murphy</em>—Reference book for SRE detailing principles and essays about <span class="No-Break">SRE topics.</span></li>
				<li><a href="https://medium.com/kudos-engineering/managing-reliability-with-slos-and-error-budgets-37346665abf6">https://medium.com/kudos-engineering/managing-reliability-with-slos-and-error-budgets-37346665abf6</a>—A writeup that describes the relationship between SLIs, SLOs, and <span class="No-Break">error budgets.</span></li>
				<li><a href="https://www.techrepublic.com/article/aws-outage-how-netflix-weathered-the-storm-by-preparing-for-the-worst/">https://www.techrepublic.com/article/aws-outage-how-netflix-weathered-the-storm-by-preparing-for-the-worst/</a>—Article that describes how Netflix avoided the effects of an AWS outage in <span class="No-Break">September 2015.</span></li>
				<li><a href="https://netflixtechblog.com/the-netflix-simian-army-16e57fbab116">https://netflixtechblog.com/the-netflix-simian-army-16e57fbab116</a>—Blog article from Netflix explaining the <span class="No-Break">Simian Army.</span></li>
				<li><a href="https://principlesofchaos.org">https://principlesofchaos.org</a>—Repository for chaos <span class="No-Break">engineering principles.</span></li>
				<li><em class="italic">Chaos Engineering: System Resiliency in Practice</em> by <em class="italic">Casey Rosenthal</em> and <em class="italic">Nora Jones</em>—Reference for chaos engineering, describing principles and essays on <span class="No-Break">creating experiments.</span></li>
				<li><em class="italic">The Site Reliability Workbook: Practical Ways to Implement SRE</em> edited by <em class="italic">Betsy Beyer</em>, <em class="italic">Niall Richard Murphy</em>, <em class="italic">David K. Rensin</em>, <em class="italic">Kent Kawahara</em>, and <em class="italic">Stephen Thorne</em>—Reference book for implementing <span class="No-Break">SRE practices.</span></li>
				<li><a href="https://www.linkedin.com/pulse/service-recovery-rolling-back-vs-forward-fixing-mohamed-el-geish/">https://www.linkedin.com/pulse/service-recovery-rolling-back-vs-forward-fixing-mohamed-el-geish/</a>—Blog article by Mohamed El-Geish that talks about recovery strategies, rolling back, and <span class="No-Break">fixing forward.</span></li>
			</ul>
		</div>
	

		<div id="_idContainer068" class="Content">
			<h1 id="_idParaDest-163"><a id="_idTextAnchor162"/>Part 2:Implement – Moving Toward Value Streams</h1>
			<p>In the book <em class="italic">The Phoenix Project: A Novel about IT, DevOps, and Helping your Business Win</em> by Gene Kim, Kevin Behr, and George Spafford, we are introduced to the Three Ways. These ways outline how we can shift toward DevOps <span class="No-Break">and CALMR.</span></p>
			<p>The First Way emphasizes working toward a flow. To do this, we will organize and structure along value streams to visualize the steps and people that perform those steps. Working as a value stream allows us to optimize the flow. We will see how to establish our value streams in <span class="No-Break"><em class="italic">Chapter 7</em></span><span class="No-Break">.</span></p>
			<p>After the First Way, we come to the Second Way, which emphasizes the amplification of feedback loops. To find our feedback, we look at the metrics that can be used to evaluate our value streams in <a href="B18756_08.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic">Chapter 8</em></span></a><span class="No-Break">.</span></p>
			<p>Finally, we come to the Third Way. The Third Way emphasizes moving to continuous experimentation and learning. <a href="B18756_09.xhtml#_idTextAnchor207"><span class="No-Break"><em class="italic">Chapter 9</em></span></a> will discuss what makes an organization that is continuously learning and methods for continuous learning to improve your <span class="No-Break">value streams.</span></p>
			<p>This part strives to set up an easy way to achieve Value Stream Management, a key practice <span class="No-Break">in DevOps.</span></p>
			<p>This part of the book comprises the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B18756_07.xhtml#_idTextAnchor163"><em class="italic">Chapter 7</em></a>, <em class="italic">Mapping Your Value Streams</em></li>
				<li><a href="B18756_08.xhtml#_idTextAnchor183"><em class="italic">Chapter 8</em></a>, <em class="italic">Measuring Value Stream Performance</em></li>
				<li><a href="B18756_09.xhtml#_idTextAnchor207"><em class="italic">Chapter 9</em></a>, <em class="italic">Moving to the Future with Continuous Learning</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer069">
			</div>
		</div>
		<div>
			<div id="_idContainer070">
			</div>
		</div>
	</body></html>