- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Common DevOps Use Cases in Some of the Biggest Companies in the World
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I take great satisfaction in seeing people and organizations achieve goals they
    might have originally believed to be beyond their reach.
  prefs: []
  type: TYPE_NORMAL
- en: – Don W. Wilson
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this book, I have asked you to have a lot of faith in me and the
    things that I write. I have asked you to have an even greater amount of faith
    in the process of **DevOps** and the fruits that it will eventually yield. With
    the start of this new section, I suppose it is time for me to put my money where
    my mouth is and show you a few things under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: All of this chapter is based on public information either provided by the company
    that implemented the use case or the company that consulted on it. They can be
    found publicly in each of the major cloud companies’ customer success story pages.
    This business information has been willingly put out there in order to serve as
    an example of how other businesses and people in the industry can make their own
    workloads better.
  prefs: []
  type: TYPE_NORMAL
- en: I’m going to use these use cases as an example of what you can do with DevOps
    and how you can support their use using Python. I didn’t want to use hypotheticals
    for this part because that would have been disingenuous. However, the way I have
    used these cases is meant to represent how they can be replicated using Python
    as opposed to whether they have used Python or not. They may have, but that’s
    not pertinent.
  prefs: []
  type: TYPE_NORMAL
- en: The primary motivation behind this chapter is to show you that there are real
    places where the philosophies of DevOps have been used in order to create genuine
    value for customers. This is a justification of the skills that you have been
    learning during your DevOps journey and during the course of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, without further ado, in this chapter, you will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An **Amazon Web Services** (**AWS**) use case that helped bridge the divide
    between business analysts and data engineers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Azure use case that saved a lot of coding time and helped make deployments
    more efficient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two **Google Cloud Platform** (**GCP**) use cases involving sports leagues finding
    solutions that made their league more accessible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS use case – Samsung electronics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Samsung uses cloud and DevOps principles for a lot of stuff. That’s pretty
    obvious since Samsung is massive. It is why I haven’t given them a proper introduction,
    because, well, you know what Samsung is. The particular case that we will be talking
    about is an interesting one: one that involves getting the layman business analyst
    involved in **machine learning** (**ML**) while also allowing the people who know
    how to write ML algorithms and applications in code to have their abilities maximized.
    It is a two-pronged approach playing to the abilities of both, enhancing the feedback
    from both of them and increasing collaboration between them. The following figure
    shows Samsung’s original workflow for data analytics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Samsung’s original workflow for data analytics](img/B21320_10_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Samsung’s original workflow for data analytics
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s break down the scenario that Samsung was confronted with and the methods
    that they used to resolve it.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Samsung’s analytical team consisted of two different sections: business analysts
    and data scientists. The business analysts looked at the problem and data provided
    by Samsung’s consumer electronics from the perspective of people who could understand
    human behavior and how it could be used to improve products and predict customer
    behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: To do this, they required data, lots of data, and the ability to process it.
    This is where the data scientists came in; they turned the hunches that the analysts
    had into cases that could be solved to provide concrete data. They created data
    analytics and ML algorithms to provide insights that the business analysts would
    use to provide recommendations and advice on how to continue with their products.
    They would also provide feedback to the data science team.
  prefs: []
  type: TYPE_NORMAL
- en: However, this partnership was not as smooth as one would believe; there was
    a gap between the two teams because of a number of factors, the primary factor
    being that there was a disparity between how the two teams did their jobs despite
    being dependent on each other.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to that, data scientists had to do repetitive tasks on different
    datasets in order to ensure that the correct output was being given back to the
    business analysts. This resulted in the data scientists not having the time to
    experiment with other ML algorithms and various techniques that they might have
    wanted to implement. It also resulted in the business analysts having significantly
    less control over the data that they were responsible for, meaning that they didn’t
    have the full picture to make an effective analysis.
  prefs: []
  type: TYPE_NORMAL
- en: The need became to find a way to coordinate the data and the algorithms in such
    a way that the more common algorithms could be used by the business analysts while
    being tweaked by the data scientists at the same time. This would create an environment
    where the data scientists did not have to wait on the business analysts and vice
    versa, freeing up time and resources for both.
  prefs: []
  type: TYPE_NORMAL
- en: Brainstorming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, you may ask, if you are unfamiliar with the process, in the modern world,
    what is a business analyst doing if they don’t know how to write code? Well, that’s
    a lot more common than you think. An analyst’s job is not to write code or parse
    through data (though this can often be something they do); their job is to analyze
    the information put in front of them and use that to provide some sort of recommendation,
    insight, or solution.
  prefs: []
  type: TYPE_NORMAL
- en: The crux of the problem here is the fact that there is a gap in communication
    and understanding between the two teams concerned that is quite difficult to bridge
    without major personnel upheaval. And that kind of upheaval is usually not in
    the best interests of the company.
  prefs: []
  type: TYPE_NORMAL
- en: You need to make it so that one team is not dependent upon the other and can
    operate on the information that they receive as opposed to the people that they
    receive it from (loosely coupled, remember?). So, an ideal solution would be to
    find a way to allow both teams to work on the same data at the same time without
    hindering each other through unnecessary communication, and that is exactly the
    solution that they found.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Samsung’s new workflow for data analytics](img/B21320_10_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Samsung’s new workflow for data analytics
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution was essentially this: there would be a single source of data that
    both the analysts and the data scientists could work from; the data scientists
    would give the analysts access to a user interface from which they could perform
    the data operations that they wanted. The scientists would then tweak those operations
    and algorithms, trying to get better results without the analysts having to contact
    them to get results on the version of the algorithm that was currently running.
    This was essentially like creating an application for internal use for data analysts
    that was built by the data scientists.'
  prefs: []
  type: TYPE_NORMAL
- en: Different skills and mindsets exist for a reason, and this is why there needs
    to be different people with varied roles and perspectives on a team. The only
    thing to do in such a scenario is to ensure that all of these roles are put in
    a position to succeed. By giving both these roles a platform and a workflow in
    which they would be comfortable, a reasonable way was found for the whole team
    to work optimally. Samsung did this by making the data centralized, with both
    teams having access to it and with neither team needing to be dependent on the
    other to make forward progress, and yet at the same time finding a way in which
    they could complement and support each other.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at a use case where the company had to deal with managing
    people who have similar skill sets with varying levels of experience, while also
    juggling business needs and productivity.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Use Case – Intertech
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While searching through use cases and scenarios, I absolutely fell in love
    with what Intertech did through the power of DevOps transformation. The fact that
    it used Azure is not as relevant as what it did with Azure and how it used the
    Azure and GitHub services to modernize and revolutionize its pipelines. This use
    case is all that DevOps is supposed to bring to a company in terms of value. It
    also addresses something that will become very relevant in the later parts of
    this book (where we are now): generative AI. Let’s take a look at the old Intertech
    workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Old Intertech workflow](img/B21320_10_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Old Intertech workflow
  prefs: []
  type: TYPE_NORMAL
- en: This figure represents a sort of sunk cost fallacy, one that can lead to a severe
    loss of productivity. It represents how Intertech operated suboptimally and wasted
    much of their critical personnel in tasks that should have not been their concern
    in the first place. So, let’s look at how Intertech approaches this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with who Intertech are. They are an IT operations company that supports
    some of the largest business clients in Turkey with their infrastructure and operational
    needs. Now, you can imagine that this kind of operation would be pretty difficult
    to manage on a lot of levels. The pains are not very big; in fact, they are tiny
    cuts and pinpricks, but those are often the most annoying kinds of pain. They
    are irritating and distracting, and if you let them, they will steal your attention.
    In this section, we will talk about mental and physical anguish and how the fine
    people at Intertech worked to reduce it.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Intertech worked in creating and maintaining solutions for some of the biggest
    companies in Turkey. Make a mental note of those two words: creating and maintaining.
    Those are two of the fundamental parts of developing any software solution, but
    they are very different from each other. To create something is to give it life;
    you’re giving birth, it’s painful, and it’s long, but it’s wonderful. Maintaining
    something is changing the diapers on the thing you gave birth to. It’s disgusting,
    but you are responsible for it and the toddler isn’t just going to take care of
    itself, no matter how prepared or independent it may be (and most toddlers are
    not). Keep this analogy in mind as it’ll follow us throughout the subsections.
    Years down the line, if I’m changing the diapers on this book to write a second
    edition, I will keep this in mind as well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, this was the difficulty facing Intertech: the balance of developing new
    projects while maintaining old ones. And the tasks to maintain the old ones were
    mundane, but they required man-hours, manpower, and a lot of power hours that
    could’ve been spent coming up with new ways to deliver value. The cycle of thought
    that runs between the initial problem and finally finding its solution requires
    precious time and intellectual effort that is usually significantly less than
    the capacity of the person solving it. Basically, it forces intelligent people
    to do dumb tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: So, when thinking about the solution to this, what should be the first thing
    we think of? Perhaps there is a way in which solutions can be found without having
    to think about and research them too much. Not, of course, for critical, vital
    tasks that require actual focus but for mundane tasks that require several Googles
    of a bunch of terms to get to the appropriate Stack Overflow page and then copying
    and pasting that into a solution and running it a couple of times to make sure
    it works. Maybe there’s a tool that will collate all of this information and generate
    a simple concise solution for a simple mundane problem and save us all some time.
    Perhaps one that rhymes with *hartificial fintelligence*? Alright, nothing rhymes
    with artificial intelligence. AI, that’s what I’m talking about.
  prefs: []
  type: TYPE_NORMAL
- en: Brainstorming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, by now, you probably know where this is heading, so let me share my personal
    experience on how I usually use generative AI in my daily life. It is a useful
    tool, as most of you who read this book will attest to unless you are staunchly
    against AI or have all the information in the world stored in your head. If you
    have the latter, contact me and tell me what actually happened with *The* *Sopranos*
    ending.
  prefs: []
  type: TYPE_NORMAL
- en: I use generative AI to lay down the steps towards a solution and frame it in
    a way that I can understand and modify according to the context I may have given,
    or ones which it hasn’t been trained on yet. This is so much easier than having
    to look at a tutorial whenever I have to find a way to fix something, and then
    when that tutorial is incomplete, having to find another one. With generative
    AIs such as ChatGPT, the tables are turned; it is my prerogative now to be impatient
    and that of the generative AI to be persistent and patient with my requests. This
    is amazing because, honestly, thinking is exhausting, especially if you have to
    think about the same thing over and over again. It makes your mind go numb, and
    it reduces your productivity. The people of Intertech came to the same conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to follow along with the child analogy, this is like having a magical
    force that will change the diaper and wrap it around the child just waiting for
    you to put the pin on it. So, in that vein, if there is a repetitive task that
    comes in and is simple enough, it can hamper productivity through all of these
    ways. In such cases, it is generative AI that can come to the rescue. Any of you
    who have ever used it know how useful ChatGPT is at this. In fact, in my personal
    experience, the most useful thing that ChatGPT does for me is explaining lines
    of code that I paste into it. It would take me more than the several seconds that
    it takes ChatGPT to do it because I simply cannot collect the information as fast
    as the AI can. So, now that we have justified our generative AI solution, let’s
    see how Intertech – who came to a similar conclusion – used these concepts and
    integrated them into their DevOps and Azure workloads and tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The solution that was created by Intertech revolved around the use of GitHub
    Copilot and Azure’s OpenAI integration. Copilot, once trained on the code for
    a particular repository that was in need of maintenance, could simply write the
    required scripts if given the correct prompts. Intertech integrated Copilot into
    the **integrated development environments** (**IDEs**) used by their developers
    so that once they wrote a line or two, Copilot simply inferred what their intentions
    were and wrote much of the rest. The developers simply had to verify a couple
    of tests and voilà, an efficient code delivery system, one that frees up time
    and thinking power. The following figure demonstrates the solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – New Intertech workflow with generative AI](img/B21320_10_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – New Intertech workflow with generative AI
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution in the diagram can be broken down into the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: When a junior developer performs maintenance on a legacy system, they use an
    instance of Copilot which has been trained on the system’s code base.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This allows them to query and find the answers about the code base that they
    are looking for in a human-readable form.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copilot also helps autocomplete their code in the style of the rest of the code
    base, maintaining consistency.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The senior developer is, for the most part, removed from this process, allowing
    them to work on newer projects and systems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since most of the maintenance operations were being done on the time of the
    senior developers as they had worked on the older projects, these developers (whose
    time is more precious because of their depth of experience) were the ones who
    needed to get hands-on with a lot of the issues to solve them. Even when these
    issues were handed off to junior developers, they still asked the senior developers
    for a large amount of advice, which while not negative behavior at all, still
    hindered the senior developers to an extent.
  prefs: []
  type: TYPE_NORMAL
- en: To make the junior developers less reliant on seniors for advice on the code
    base, the company integrated Azure OpenAI chatbots into their IDEs. These chatbots
    could scrape and infer information from the code and the documentation for projects
    and answer questions about them to the satisfaction of the junior developers most
    of the time. This reduced the amount of time taken by senior personnel in maintaining
    the code and it guided the junior developers through the code base using their
    very own personalized babysitter, if you will. One incredible consequence of this
    was that the number of emails sent within the company was reduced by 50%, which
    is a remarkable number. Wouldn’t you like 50% fewer emails for the same if not
    greater amount of productivity? Not to mention all of the time that is freed up
    by not being in meetings and having to retread old stuff. This is the kind of
    value multiplier that can take companies to the next level.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of value, so far the value that we have seen has been values on fact
    sheets and computer code, but in our next section, we will see the value that
    DevOps can generate in a more physically tangible environment using sports as
    an example.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud use case – MLB and AFL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If there is one thing that you should know about me, it is that I am a massive
    sports fan. I am, and I love learning about new sports just as much as following
    the old ones that I have followed for years.
  prefs: []
  type: TYPE_NORMAL
- en: I have been following **Major League Baseball** (**MLB**) for years, and in
    those years, baseball has always been the sport of analytics. Most modern teams
    in their team selection are driven by analytics and the performance of players
    is measured through statistical analysis of a number of metrics that are collected
    when they play their games. You may have seen the film *Moneyball* (or read the
    book by Michael Lewis), which chronicles the introduction of statistical methods
    in the choice of baseball players and how they led to the success of the Oakland
    Athletics baseball team in the late 90s and early 2000s.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the MLB, one of the results of the introduction of analytical data is the
    analysis of the gameplay itself and the time taken to finish a game. In order
    to streamline the game, MLB introduced the pitch clock, giving players only 15
    seconds to throw a pitch. The clock, as seen in the following figure, needs to
    synchronize throughout the arena and with the clock that is being broadcast over
    television as well. This synchronization presents a unique challenge for MLB to
    implement its newest rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Original MLB play clock system](img/B21320_10_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Original MLB play clock system
  prefs: []
  type: TYPE_NORMAL
- en: 'I wanted to also look at some other sports leagues that may have used data
    analytics and Google Cloud in some way and integrated it into their league’s infrastructure
    (perhaps in a way that was different from MLB’s approach). In my search, I found
    the perfect example with the **Australian Football League** (**AFL**). The following
    diagram shows the AFL’s broadcast situation for coaching:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – The AFL broadcast situation for coaching](img/B21320_10_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – The AFL broadcast situation for coaching
  prefs: []
  type: TYPE_NORMAL
- en: When I started this, I knew practically nothing about Australian rules football
    (also known as Aussie rules football) or the AFL other than the fact that the
    day of the Grand Final is a public holiday in Australia. However, one thing that
    I did figure out during my research was that both of these companies were using
    advanced analytics in order to find ways to improve the way that the play was
    seen and to analyze if there was a way to make the gameplay and the players even
    better.
  prefs: []
  type: TYPE_NORMAL
- en: Given my passion for sports and all the nerd stuff surrounding sports, this
    little section now seems inevitable to me. So, let’s dive in and see what DevOps
    and data insights we can find in these use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start with baseball; I love baseball. It is the sport of the stoic man;
    it is the sport where time stands still. If you ever have 23 hours to spare, do
    yourself a favor and watch Ken Burns’ *Baseball* documentary series; you will
    not regret it. But baseball as a whole and MLB in particular suffered from a few
    setbacks the past few years. There was a cheating scandal involving the Houston
    Astros and live attendance and viewership were down because of the excessive length
    of the games. To solve these problems while maintaining the integrity of the game,
    MLB turned to data. They turned to the analytics that the teams individually used
    and decided to turn it toward the league as a whole. They collected statistics
    related to gameplay, attendance, and viewer engagement from all of the available
    games throughout the season (2,430 games plus playoffs) and decided to create
    infrastructure solutions to bolster the solutions that they would implement. They
    used Google Cloud for this: both for the data analytics and the implementation
    of the solution itself.'
  prefs: []
  type: TYPE_NORMAL
- en: Aussie rules football is the number one sport in Australia. In the land down
    under, it is the sport that has the greatest viewership and the biggest audience.
    It is also the most physical sport played in Australia and as someone who watches
    a lot of sports and does a lot of data science, the more physical a sport is in
    terms of physical contact between human beings, the more difficult it becomes
    to analyze that sport. Here, the data needs to be broken down on a more physical
    level, looking toward the human body itself. This approach allowed the AFL to
    develop a system that used ML with human coaching to develop systems of training
    for the underprivileged and differently able people who were still passionate
    about the sport.
  prefs: []
  type: TYPE_NORMAL
- en: Two very different problems were faced by these two sports leagues, both of
    which required completely different approaches, but both of which were solved
    in Google Cloud using the principles of DevOps. Let’s see how they did it.
  prefs: []
  type: TYPE_NORMAL
- en: Brainstorming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MLB problem was one that affected the game and people’s enjoyment of it. People
    hate it when you waste their time, and they hate slow games. Anyone who has ever
    watched the last two minutes of a close NBA playoff game knows. MLB approached
    this problem by looking at the time taken every inning and what were the longest
    aspects of those innings. They realized that pickoffs and the time taken by pitchers
    to wind up their pitch were slowing down the game. This led to the creation of
    the pitch clock, a timer for how long a pitcher can wait between pitches thrown.
    They had determined that this time between pitches was the main reason that the
    game had slowed down and they believed that the clock would rectify the situation.
    It was implemented using GCP and DevOps principles combining the GCP services
    with on-premises timing hardware. And as a fan, I am very grateful for it as well.
    We will discuss the full extent of the solution in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with the AFL was one of youth outreach and the physical limitations
    that some people have when attempting to play the sport. Australia is also a massive
    country with a very widespread populace, meaning that people in rural areas who
    needed training in Aussie rules football would need to have their training and
    coaching administered remotely. The goal then became to reach as many people as
    possible and to do so with as much data as possible so that it would be accurate,
    and also to reach people who are impaired in some form of communication. This
    problem required an approach of communication between devices as well as the use
    of ML algorithms, particularly for use in tracking the ball used in the sport
    with respect to the player who is being coached.
  prefs: []
  type: TYPE_NORMAL
- en: So, looking at these problems, and the approaches we could potentially take
    to solve them, we can now start coming up with a couple of solutions that might
    help these organizations achieve their goals. Let’s see what exactly it was that
    they did to achieve these goals.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The solution to MLB’s problems involved using Google Cloud’s Anthos service
    mesh to coordinate all the pitch clocks together. Centralized yet distributed
    time clocks added to the integrity of the game and these new rules.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with MLB was one of synchronization. The goal was to synchronize
    the play clocks that were running throughout the stadium, to coordinate their
    timing. Here, Google used their Anthos service mesh (as shown in the following
    diagram) as a sort of connector between a number of devices in the cloud and on-premises
    devices at baseball stadiums. This allowed the timer for pitchers to be visible
    and accurate everywhere with no delays, ensuring the fairness of the new system.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Anthos synchronized game clock for MLB](img/B21320_10_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Anthos synchronized game clock for MLB
  prefs: []
  type: TYPE_NORMAL
- en: 'The introduction of the play clock reduced the time of games for the average
    baseball game by 24 minutes. That is significant and I think it is the most significant
    application of the DevOps philosophy that I have seen in such a non-tech scenario.
    Let’s do the math here: 24 minutes was reduced from every game, which increased
    the average attendance of games from 26,843 to 29,295, which is a significant
    achievement. So, how much time was really saved? Well, that is 24 minutes x 29,295
    people x 2,430 regular season games. That is 1,708,484,400 minutes in total saved,
    which is 28,474,740 hours, 1,186,447.5 days, or 3,250 years. That is quite the
    saving, and the fans have felt it too, which is why the attendance is up. All
    of this is because of the ability to coordinate loosely coupled infrastructure.'
  prefs: []
  type: TYPE_NORMAL
- en: The approach to the AFL’s problem required the delivery of ML models that could
    perform motion tracking over networks that were not always reliable. This meant
    that any sort of ML model that was used would have to use the computing power
    on the side of the mobile device and be lightweight enough to not affect the functioning
    of that device. Google’s development team had helped facilitate a similar teaching
    solution with cricket in the **Indian Premier League** (**IPL**). So, the solution
    that they ended up with was an application called the Footy Skills app.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Instruction broadcast system for AFL coaching](img/B21320_10_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – Instruction broadcast system for AFL coaching
  prefs: []
  type: TYPE_NORMAL
- en: 'The application used two ML models: one to detect an Aussie rules ball based
    on size, shape, and color, and another to determine its spatial depth and location.
    They also added features that would assist the hearing and visually impaired as
    well as wheelchair-using athletes who played the sport.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was quite the journey. It was unique, even among some of the weird
    stuff I have written in this book. But I can honestly say that it was an enjoyable
    chapter to write simply because of all of the unique solutions that I got to research
    while I was writing it.
  prefs: []
  type: TYPE_NORMAL
- en: We started with the AWS solution and that was a great demonstration of what
    can happen when you put people in a position where their skills can be valued
    and used with other skills as opposed to clashing with them. It also showed us
    how DevOps solutions don’t just facilitate technologies, but the people behind
    those technologies as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the Azure use case, we learned about how AI and ML mixed with DevOps can
    increase the productivity of a team that engages in creative endeavors. We saw
    how generative AI is being used to facilitate developers, reduce the amount of
    mundane and redundant work that key personnel have to do, and free up time and
    communication channels to make teams more productive.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first GCP use case, MLB needed a way to justify changing rules in baseball
    that had been around for over a century. They used solid data and hard facts to
    do this. These facts were provided through the collation of data from an entire
    season of baseball. They then used this and other loosely coupled coordination
    technology to implement their vision of changed rules. Through data and technological
    coordination, they achieved the creation of a rule that was profitable to them
    but also popular with the fans: a feat that is practically unheard of.'
  prefs: []
  type: TYPE_NORMAL
- en: In the second GCP use case, the AFL extended its range of availability and inclusivity
    using ML models delivered with DevOps principles directly onto devices that were
    spread throughout Australia, giving people in even the most remote areas of Australia
    access to great coaching and instruction to help them improve in the sport. This
    gave the AFL an invaluable platform for growth and outreach amongst their fans
    and future players.
  prefs: []
  type: TYPE_NORMAL
- en: So, in conclusion, this DevOps stuff is pretty useful in real life. A lot of
    these solutions couldn’t have been done without Python either, especially the
    ones that involved ML and AI. And that is just the beginning of how high you can
    go with DevOps. In the next chapter, we will dive even deeper into the data science
    aspect of DevOps, Python with data, and **MLOps**.
  prefs: []
  type: TYPE_NORMAL
