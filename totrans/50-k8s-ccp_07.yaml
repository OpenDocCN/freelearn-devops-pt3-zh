- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Deploying Kubernetes Apps Like a True Cloud Native
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 像真正的云原生应用一样部署 Kubernetes 应用
- en: When engineers start hearing about Kubernetes or want to start implementing
    it, the typical reason is from a Dev perspective of managing and deploying applications.
    The whole premise around Kubernetes making engineering teams’ lives easier, regardless
    of whether it’s Dev or Ops, is based on application deployment.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当工程师开始听说 Kubernetes 或者想要开始实施它时，通常是出于管理和部署应用的开发视角。Kubernetes 使工程团队生活更轻松的整个前提，无论是开发还是运维，都是基于应用部署的。
- en: Deploying applications is at the forefront of every business’s mind, whether
    it’s a website, some mobile application, or an internal app in any company, from
    a software company to an auto-parts company to a beer manufacturer. Regardless
    of the industry, almost every company deploys some type of application and some
    type of software. As all engineers know, deploying and maintaining an application
    successfully isn’t an easy task. Whether you’re running an app on bare metal,
    on a VM, in the cloud, or even in a container, that app could be (and most likely
    is) the make or break between a successful business and a bankrupt company.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 部署应用是每个企业头脑中的重点，不管是网站、移动应用，还是任何公司的内部应用，从软件公司到汽车零件公司再到啤酒制造商。无论行业如何，几乎每家公司都部署某种类型的应用和软件。正如所有工程师所知道的那样，成功部署和维护一个应用并不是一件容易的事情。无论你是在裸金属上、虚拟机上、云端，还是甚至在容器中运行应用，这个应用可能是（而且很可能是）决定一个成功的企业和破产公司的关键。
- en: Throughout this chapter, you’re going to notice that a lot of topics covered
    will remind you of how other application deployments work. From the actual deployment
    to scaling and upgrading, the overall concepts are the same. For example, scaling
    an application is scaling an application. There’s no magical new methodology with
    Kubernetes. However, what Kubernetes does give you is the ease of scalability.
    With that being said, the major thing you’ll notice throughout this chapter is
    that Kubernetes isn’t reinventing the wheel. It’s making what we’ve been doing
    for 30+ years easier.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你会发现很多话题会让你想起其他应用部署的方式。从实际部署到扩展和升级，整体概念是相同的。例如，扩展应用就是扩展应用。在 Kubernetes
    中没有什么神奇的新方法。然而，Kubernetes 给你带来的好处是扩展的简易性。话虽如此，你会注意到的一个重要点是，Kubernetes 并没有重新发明轮子。它只是让我们已经做了
    30 多年的事情变得更加简单。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要话题：
- en: Cloud-native apps
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云原生应用
- en: Controllers, controller deployments, and Pods
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器、控制器部署和 Pods
- en: Segregation and namespaces
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隔离和命名空间
- en: Stateless and stateful apps
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无状态应用和有状态应用
- en: Upgrading deployments
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级部署
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To follow along with this chapter, you should have already deployed a Kubernetes
    app via a Kubernetes manifest. This chapter is going to break down the process
    of things such as deploying apps and what a Kubernetes manifest is, but to fully
    grasp the chapter, you should be familiar with the deployment process. Think of
    it like this – you should be at a beginner/mid level with the Kubernetes deployment
    process, and this chapter will get you to the production level.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟上本章的内容，你应该已经通过 Kubernetes 清单部署了一个 Kubernetes 应用。本章将详细讲解部署应用的过程以及什么是 Kubernetes
    清单，但要完全理解本章，你应该熟悉部署过程。可以这样想——你应该处于 Kubernetes 部署过程的初级/中级水平，而本章将帮助你达到生产级水平。
- en: 'The code for this chapter can be found at the following GitHub URL: [https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch5](https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch5)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下 GitHub 链接中找到：[https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch5](https://github.com/PacktPublishing/50-Kubernetes-Concepts-Every-DevOps-Engineer-Should-Know/tree/main/Ch5)
- en: Understanding cloud-native apps
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解云原生应用
- en: Although the whole *cloud-native* thing can feel a bit buzzword-ish in today’s
    world, there is some merit behind the idea of building cloud-native apps. The
    way an application is architected matters as it relates to how it can be deployed,
    managed, and maintained later. The way a platform is built matters because that’s
    the starting point for how an application can be deployed and how it can be run.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管今天的*云原生*概念可能感觉有些像流行词，但构建云原生应用的想法还是有一定价值的。应用的架构方式很重要，因为它关系到应用后期如何部署、管理和维护。平台的构建方式也很重要，因为这是应用如何部署和运行的起点。
- en: Throughout the years of technology’s existence, there have been multiple different
    methodologies around how applications are architected and built. The original
    methods were formed around on-premises systems, such as mainframes and servers.
    After that, applications started to be architected for virtualized hardware platforms,
    such as ESXi, and other virtualization products, with the idea in mind of utilizing
    more of the server, but for different workloads instead of just one workload running
    like in the bare-metal days. After virtualization, there was architecture and
    planning for apps around cloud workloads, which started to introduce the idea
    of cloud native and how applications would work if they only ran in the cloud.
    Considerations such as bandwidth, size of servers, and overall cost consumed a
    lot of conversations around cloud workloads, and still do.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术发展多年的过程中，关于应用架构和构建方法，曾经有过多种不同的思路。最初的方法围绕着本地系统形成，比如大型主机和服务器。之后，应用开始针对虚拟化硬件平台进行架构设计，比如
    ESXi 和其他虚拟化产品，目的是利用服务器的更多资源，而不是像裸金属时代那样仅运行单一工作负载。虚拟化之后，应用的架构和规划开始围绕云工作负载展开，这引入了云原生的概念，即如果应用仅在云中运行，它们将如何工作。带宽、服务器大小以及整体成本等因素引发了许多关于云工作负载的讨论，而且至今仍在讨论之中。
- en: Now, we’re faced with the *fourth phase*, which is containerized workloads.
    Containerized workloads really kicked off the focus around cloud-native applications
    and deployments, and for good reason, especially with the idea of microservices
    starting to become a real thing for many organizations that would’ve thought it
    wasn’t possible just 5 years ago.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们正面临着*第四阶段*——容器化工作负载。容器化工作负载真正推动了云原生应用和部署的关注，特别是随着微服务概念开始成为许多组织的现实，五年前它们可能还认为这是不可能的。
- en: In this section, you’re going to learn what cloud-native applications are and
    a brief history of application architecture, cloud deployments, and microservices.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你将学习云原生应用是什么，以及应用架构、云部署和微服务的简要历史。
- en: What’s a cloud-native app?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是云原生应用？
- en: Before deploying applications in a cloud-native way, let’s take a step back
    and think about a core computer science concept – distributing computing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在以云原生方式部署应用之前，让我们先退一步，思考一个核心计算机科学概念——分布式计算。
- en: Distributed computing is a field that studies distributed systems, and distributed
    systems are systems that have components located on different network-connected
    computers. Those different network-connected computers then communicate with each
    other to send data, or packets, back and forth.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式计算是研究分布式系统的领域，而分布式系统是指那些其组件位于不同网络连接的计算机上的系统。这些不同的网络连接的计算机随后相互通信，来来回回地发送数据或数据包。
- en: The important part here is this – distributed systems equal multiple software
    components that are on multiple systems but run as a single system. Distributed
    computing sounds like microservices, right? (More on microservices later.)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这里重要的是——分布式系统等于多个系统上的多个软件组件，它们作为一个单一系统运行。分布式计算听起来像微服务，对吧？（稍后会详细介绍微服务。）
- en: Cloud native takes the concept of distributed computing and expands it to a
    whole other level. Think about it from an AWS or Azure perspective. AWS and Azure
    are by definition distributed systems. When you log in to the AWS portal, there
    are a ton of services at your fingertips – EC2, databases, storage, and a lot
    more. All of those services that you interact with are from a *single system*,
    but the network components that make up the *single system* span hundreds of thousands
    of servers, across multiple data centers across the entire world. Cloud native
    doesn’t just mean the public cloud, however. Remember, the cloud is a distribution
    of services. Something that’s *cloud native* can also be, for example, an entire
    OpenStack server farm.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生将分布式计算的概念扩展到一个全新的层次。想象一下从AWS或Azure的角度来看。AWS和Azure从定义上来说就是分布式系统。当你登录AWS控制台时，数不清的服务触手可及——EC2、数据库、存储，还有更多其他服务。你与这些服务的互动来源于一个*单一系统*，但构成该*单一系统*的网络组件跨越了全球多个数据中心，涵盖了成千上万台服务器。然而，云原生并不仅仅意味着公共云。请记住，云是服务的分布。举个例子，*云原生*的东西也可以是一个完整的OpenStack服务器集群。
- en: 'Combining the whole idea of cloud native and distributed computing, you have
    a major concept – cloud-native applications. Cloud-native apps aim to give you
    the ability to design and build apps that are the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 结合云原生和分布式计算的整体概念，你会得到一个主要概念——云原生应用。云原生应用旨在赋予你设计和构建以下类型应用的能力：
- en: Easily scalable
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于扩展
- en: Resilient
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韧性
- en: Elastic
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弹性
- en: The important thing to remember is that these concepts aren’t any different
    than what we’ve already had in the engineering world. We’ve had distributed computing
    for a long time. We’ve had distributed applications for a while. What we didn’t
    always have is the ability to easily implement distributed computing. Thinking
    about the AWS or Azure example from previously, how long would it take us to build
    the same infrastructure as Azure or AWS? Then, think about how many people it
    would take to manage and maintain it. With distributed computing at the cloud
    level, all of the *day-one* configurations are abstracted away from you, leaving
    you with only worrying about the *day-two* complexities of building a cloud-native/distrusted
    computing application.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的重要一点是，这些概念与我们在工程领域中已经有的并没有什么不同。我们已经有了分布式计算很长时间。我们已经有了分布式应用一段时间。我们以前没有的是轻松实现分布式计算的能力。回想之前提到的AWS或Azure的例子，我们需要多久才能构建出像Azure或AWS那样的基础设施？再想想，管理和维护这些基础设施需要多少人。借助云级别的分布式计算，所有的*第一天*配置都已经被抽象出来，你只需要担心*第二天*的复杂性，构建云原生/分布式计算应用。
- en: In the cloud, if you want to scale your application, you click a few buttons,
    write a few lines of code, and boom, you have autoscaling groups. If you want
    to build resilient applications, you point and click on what data centers you
    want your apps to run in instead of having to physically build out those data
    centers. Again, the concept of distributed computing is the same thing as cloud
    native and cloud-native apps. The difference is that you don’t have to worry about
    building out the data center. You just have to worry about scaling the app.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中，如果你想要扩展应用，只需要点击几个按钮，写几行代码，瞬间就能创建自动扩展组。如果你想构建韧性强的应用，只需要指点并点击选择数据中心来运行你的应用，而无需物理建设这些数据中心。再次强调，分布式计算的概念与云原生及云原生应用是相同的。不同之处在于，你无需担心构建数据中心，你只需关注应用的扩展。
- en: Cloud-specific cloud native
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云特定的云原生
- en: One major point to keep in mind, whether it’s with a standard app deployment
    in the cloud or an app deployment in Kubernetes, is *cloud native* doesn’t just
    mean *the cloud*. It’s more or less the overall concept, but again, the whole
    idea of cloud native is distributed computing without the need to focus on the
    day-one implementation and configuration.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是在云中进行标准应用部署，还是在Kubernetes中进行应用部署，必须记住的一个重要点是，*云原生*并不仅仅意味着*云*。它更多的是一个整体概念，但再说一次，云原生的核心思想是分布式计算，而无需关注第一天的实现和配置。
- en: For example, let’s take OpenStack. OpenStack is a private cloud. You can deploy
    OpenStack in your data center and interact with it just like you would with any
    other cloud service. However, here’s the catch – some teams may see it as cloud
    native and others may see it as general distributed computing. The infrastructure
    teams that are building out OpenStack will see the *behind-the-scenes* configurations,
    such as building out the hardware and scaling it across multiple data centers.
    To them, it’s no different than a standard distributed computing environment.
    Same for the infrastructure engineers that are building, managing, and maintaining
    the infrastructure for AWS or Azure. Then, there are the teams that interact with
    OpenStack after it’s already built. They’re logging into the UI and communicating
    with OpenStack via the CLI and other API methods, so they’re getting the full
    satisfaction of a true cloud-native environment just like many engineers are getting
    the full satisfaction of interacting with AWS and Azure without needing to worry
    about the infrastructure and services on-premises.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们以 OpenStack 为例。OpenStack 是一个私有云。你可以在自己的数据中心部署 OpenStack，并像使用任何其他云服务一样与之互动。然而，问题在于——一些团队可能会将其视为云原生，而另一些团队则可能将其视为一般的分布式计算。正在构建
    OpenStack 的基础设施团队将看到*幕后*的配置，例如构建硬件并在多个数据中心之间扩展。对他们来说，这与标准的分布式计算环境没有什么不同。对于构建、管理和维护
    AWS 或 Azure 基础设施的工程师们来说，也是如此。然后，还有一些团队会在 OpenStack 已经搭建好后与其互动。他们通过 UI 登录并通过 CLI
    以及其他 API 方法与 OpenStack 通信，因此他们体验到的是真正的云原生环境的完整满足感，就像许多工程师在与 AWS 和 Azure 互动时，能够充分满足对基础设施和本地服务无需担心的需求。
- en: Another example is the hybrid cloud. If you’re running Azure Stack HCI on-premises,
    that means you’re utilizing some server that runs the Azure Stack HCI operating
    system, which interacts with the Azure cloud. The engineers that are managing
    Azure Stack HCI see what’s happening behind the scenes. Other engineers that are
    simply interacting with **Azure Kubernetes Service** (**AKS**) don’t see the underlying
    infrastructure. They just know that they go to a specific location to create a
    new Kubernetes cluster.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是混合云。如果你在本地运行 Azure Stack HCI，那么意味着你正在使用某些服务器运行 Azure Stack HCI 操作系统，并与
    Azure 云进行交互。管理 Azure Stack HCI 的工程师们看到的是幕后发生的事情。而那些仅仅与**Azure Kubernetes 服务**（**AKS**）互动的工程师则看不到底层基础设施。他们只知道他们去特定的位置创建一个新的
    Kubernetes 集群。
- en: Regardless of where a platform or app is deployed, it could be considered cloud
    native to some and standard distributed computing to others. You could be an engineer
    that’s building a cloud-native platform so others can interact with it in a cloud-native
    fashion.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 无论平台或应用程序在哪里部署，它对于某些人来说可能是云原生的，而对于另一些人来说则是标准的分布式计算。你可以是一个正在构建云原生平台的工程师，以便其他人可以以云原生的方式与之互动。
- en: What are microservices?
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是微服务？
- en: Taking the idea of distributed computing and cloud native to the next level
    gives us a microservice. By definition, a microservice is a loosely coupled architecture
    that has components that have no dependencies on each other.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将分布式计算和云原生的概念提升到一个新高度，就得到了微服务。按定义，微服务是一种松耦合架构，组件之间没有相互依赖。
- en: 'Say you have five pieces that make up your application: three backend APIs,
    some middleware to connect the backend and frontend, and a frontend that consists
    of a website with multiple paths. In a monolithic-style environment, you would
    take that entire application, package it up, deploy it to a server, and run the
    binary. Then, if you had to update or upgrade any part of that application, such
    as the one backend API, you would have to take down the rest of the application.
    This not only brings down production but also would slow down the ability to get
    new updates and features out because you’d have to specify a specific window to
    bring down the entire platform.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有五个部分组成你的应用程序：三个后端 API，一些中间件用于连接后端和前端，和一个由多个路径组成的前端网站。在单体式环境中，你会将整个应用程序打包，部署到服务器上并运行二进制文件。然后，如果你需要更新或升级该应用程序的任何部分，例如某个后端
    API，你就必须关闭其他部分的应用程序。这样不仅会导致生产环境停机，还会减缓推出新更新和新功能的能力，因为你必须指定一个特定的时间窗口来关闭整个平台。
- en: Microservices allow you to take those five pieces of the application and split
    them out into their own individual pieces. Then, you can manage those *pieces*
    separately instead of having to worry about combining them to deploy and have
    a working platform.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务允许你将应用程序的这五个部分拆分成各自独立的部分。然后，你可以单独管理这些*部分*，而不是担心将它们组合起来进行部署并确保平台正常工作。
- en: 'In a Kubernetes environment, you would have the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 环境中，你将拥有以下内容：
- en: One container image for backend API 1
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后端 API 1 的一个容器镜像
- en: One container image for backend API 2
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后端 API 2 的一个容器镜像
- en: One container image for backend API 3
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后端 API 3 的一个容器镜像
- en: One container image for the middleware
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间件的一个容器镜像
- en: One container image for the frontend
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前端的一个容器镜像
- en: Then, each of those container images can be updated, upgraded, deployed, and
    managed separately.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，每个容器镜像都可以分别进行更新、升级、部署和管理。
- en: It’s important to note that microservices aren’t just for containers and Kubernetes.
    The same concepts talked about previously can work just as well on five different
    Ubuntu VMs. It’s just easier to manage a container from a microservice perspective
    than it is to manage it from a VM perspective. Way less automation and repeatable
    practices are needed to do the same thing you would have to do on a VM inside
    of Kubernetes. It’s possible and 100% doable, but it takes more effort.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，微服务不仅适用于容器和 Kubernetes。之前讨论的相同概念在五个不同的 Ubuntu 虚拟机上也可以很好地工作。只是从微服务的角度管理容器要比从虚拟机的角度管理容器更容易。在
    Kubernetes 中做同样的事情，比在虚拟机上做需要的自动化和可重复实践要少得多。虽然这完全可行，但需要更多的努力。
- en: In the next section, you’re going to take what you learned in this section and
    start applying it to Kubernetes-based scenarios.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将把本节所学的内容应用到基于 Kubernetes 的场景中。
- en: Learning about Kubernetes app deployments
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习 Kubernetes 应用程序部署
- en: 'When engineers are first getting started with deploying an application to a
    Kubernetes cluster, it looks something like this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当工程师首次开始将应用程序部署到 Kubernetes 集群时，它看起来像这样：
- en: Create a Kubernetes manifest.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 Kubernetes 清单。
- en: Run a command such as `kubectl apply -f` or `kubectl create -f` against the
    manifest.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行类似`kubectl apply -f`或`kubectl create -f`的命令，针对清单进行操作。
- en: Ensure that the application has Pods running.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保应用程序有 Pods 正在运行。
- en: Access your app to ensure it’s running the way you were expecting it to run.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问你的应用程序，以确保它按照预期的方式运行。
- en: Although this is a great approach to getting started with deploying applications
    to Kubernetes, we must dive a little bit deeper to fully understand how the deployment
    process of an app occurs, why it works the way that it does, how manifests interact
    with Kubernetes to ensure an application is deployed, and how Kubernetes keeps
    the desired state of Pods running.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一种很好的开始部署应用程序到 Kubernetes 的方法，但我们必须深入探讨，以便完全理解应用程序部署过程是如何进行的，为什么它以这种方式工作，清单如何与
    Kubernetes 交互以确保应用程序部署，以及 Kubernetes 如何保持 Pods 的期望状态。
- en: It seems like how Kubernetes deploys apps is simply magic that occurs on the
    platform because that’s how it’s built and that’s the way it’s supposed to be,
    but there’s a ridiculous number of pieces built that allow Kubernetes to appear
    to be the magical deployment platform that it makes itself out to be.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来 Kubernetes 部署应用程序的方式简直像是在平台上发生的魔法，因为它就是这样构建的，应该就是这种方式，但实际上，Kubernetes 背后有着大量的组件，它们使得
    Kubernetes 看起来像是一个神奇的部署平台。
- en: In this section, you’re going to learn from start to finish how app deployments
    work inside of Kubernetes and the internals of everything that’s needed to make
    a successful deployment.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将从头到尾学习 Kubernetes 中应用程序部署的工作原理以及成功部署所需的一切内部细节。
- en: Kubernetes manifests
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 清单
- en: Before actually deploying an application, you’ll need to learn the ins and outs
    of how most applications are deployed to Kubernetes – a **Kubernetes manifest**.
    The idea is that you already know what a Kubernetes manifest is, but perhaps you
    don’t know the breakdown of the internals of a Kubernetes manifest.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际部署应用程序之前，你需要了解大多数应用程序是如何部署到 Kubernetes 的——一个**Kubernetes 清单**。这个概念是你已经知道什么是
    Kubernetes 清单，但可能不了解 Kubernetes 清单的内部结构。
- en: 'A Kubernetes manifest is a YAML- or JSON-based configuration that interacts
    differently with the Kubernetes API. The Kubernetes manifest is where you specify
    what API you want to work with and what resource you want to work with from that
    API. There are two groups of APIs:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 清单是一个基于 YAML 或 JSON 的配置，它以不同的方式与 Kubernetes API 进行交互。Kubernetes 清单是你指定想要使用哪个
    API，以及从该 API 中要操作哪个资源的地方。API 分为两大类：
- en: '`/api/v1`'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/api/v1`'
- en: '`/apis/$GROUP_NAME/$VERSION`'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/apis/$GROUP_NAME/$VERSION`'
- en: 'For example, the following is a code snippet showcasing that the Deployment
    resource is in the `/``api/v1` group:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是一个代码片段，展示了 Deployment 资源位于 `/``api/v1` 组中：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following is another example of an Ingress controller, which you can see
    is in `/apis/networking.k8s.io/v1`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是另一个 Ingress 控制器的示例，你可以看到它位于 `/apis/networking.k8s.io/v1`：
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`apiVersion` is the Kubernetes API you’re utilizing, and `kind` is what Kubernetes
    resource you’re creating, updating, or deleting.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion` 是你正在使用的 Kubernetes API，`kind` 是你正在创建、更新或删除的 Kubernetes 资源。'
- en: 'A Kubernetes manifest consists of four key parts:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Kubernetes 清单由四个关键部分组成：
- en: '`apiVersion`: Which version of the Kubernetes API you’re using to create the
    object/resource'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apiVersion`: 你用来创建对象/资源的 Kubernetes API 版本'
- en: '`Kind`: What kind of object you want to create, update, or delete'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Kind`: 你想要创建、更新或删除的对象类型'
- en: '`Metadata`: Data that helps uniquely identify the resource/object'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Metadata`: 帮助唯一标识资源/对象的数据'
- en: '`Spec`: What you want the resource to look like'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Spec`: 你希望资源的样子'
- en: 'The following is a Kubernetes manifest:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个 Kubernetes 清单：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s break that down.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来解析一下。
- en: First, you have the API version. You can see that the API version indicates
    that it’s utilizing a resource in the core group. Next, there’s `kind`, which
    specifies what resource you’re creating/updating/deleting. Then there’s `metadata`,
    which is specifying a name for the deployment to uniquely identify it via metadata.
    Finally, there’s `spec`, which indicates how you want your containerized app to
    look. For example, the spec shown earlier indicates that the manifest is using
    the latest version of the Nginx container image and utilizing port `80`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是 API 版本。你可以看到 API 版本表示它正在使用核心组中的资源。接下来是 `kind`，它指定你正在创建/更新/删除的资源类型。然后是 `metadata`，它为部署指定了一个名称，以便通过元数据唯一标识它。最后是
    `spec`，它表示你希望容器化应用的样子。例如，之前显示的 spec 指示清单正在使用最新版本的 Nginx 容器镜像并使用端口 `80`。
- en: To wrap up this section, something you should know about Kubernetes manifests,
    and the way Kubernetes works in general, is that it’s declarative. Declarative
    means “*tell me what to do, not how to do it*.” Imperative means “*tell me what
    to do and how to* *do it*.”
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这一部分，你需要了解关于 Kubernetes 清单以及 Kubernetes 的一般工作方式的一点是，它是声明式的。声明式意味着“*告诉我做什么，而不是如何做*”。命令式意味着“*告诉我做什么以及如何做*”。
- en: For example, let’s say you were teaching someone how to bake a cake. If it was
    imperative, you would be telling the person what ingredients to use, the size
    for each ingredient, and how to do it step by step, ultimately leading them to
    the finished product. Declarative would mean you tell them what ingredients they
    need and they figure out how to do it on their own.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你在教别人如何做蛋糕。如果是命令式，你会告诉这个人使用什么食材、每种食材的分量以及如何一步步操作，最终引导他们完成成品。声明式则意味着你告诉他们需要哪些食材，剩下的由他们自己想办法完成。
- en: Kubernetes manifests are declarative because you tell Kubernetes what resource
    you want to create, including the name of the resource, ports, volumes, and so
    on, but you don’t tell Kubernetes how to make that resource. You simply define
    what you want, but not how to do it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 清单是声明式的，因为你告诉 Kubernetes 你想创建什么资源，包括资源的名称、端口、卷等，但你并不告诉 Kubernetes
    如何创建该资源。你只需定义你想要的内容，而不告诉它怎么做。
- en: The common way but not the only way
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 常见但非唯一的方式
- en: Nine times out of ten, when you’re deploying a resource to Kubernetes, you’ll
    most likely be using a Kubernetes manifest. However, as you’ve learned throughout
    this book so far, the core of Kubernetes is an API. Because it’s an API, you can
    utilize any programmatic approach to interact with it.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 十有八九，当你将资源部署到 Kubernetes 时，你很可能会使用 Kubernetes 清单。然而，正如你在本书中所学到的那样，Kubernetes
    的核心是一个 API。因为它是一个 API，所以你可以使用任何编程方法与它进行交互。
- en: For example, the following is a code snippet using Pulumi, a popular IaaS platform
    to create an Nginx deployment inside of Kubernetes. This code requires more to
    run it, so don’t try to run it. This is just a pseudo example.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是使用 Pulumi（一种流行的 IaaS 平台）在 Kubernetes 内创建 Nginx 部署的代码片段。此代码需要更多步骤才能运行，所以不要尝试运行它。这只是一个伪代码示例。
- en: 'There’s no YAML and no configuration language. It’s raw Go (Golang) code interacting
    with the Kubernetes API:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有 YAML，也没有配置语言。它是原生的 Go (Golang) 代码与 Kubernetes API 交互：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Although you won’t see this too often, you should know that this type of method
    exists and you can create any resource you want in Kubernetes, in any programmatic
    fashion, as long as you do it via the Kubernetes API.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你不会经常看到这种方法，但你应该知道这种方法的存在，你可以在 Kubernetes 中以任何编程方式创建任何资源，只要你通过 Kubernetes
    API 来操作。
- en: Controllers and operators
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制器和操作员
- en: Kubernetes comes out of the box with a way to ensure that the current state
    of a deployed application is the desired state. For example, let’s say you deploy
    a Kubernetes deployment that is supposed to have two replicas. Then, for whatever
    reason, one of the Pods goes away. The deployment controller would see that and
    do whatever it needs to do to ensure a second replica/Pod gets created. All resources
    that can be created in Kubernetes (Pods, Services, Ingress, Secrets, and so on)
    have a **controller**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 默认提供了一种方式来确保已部署应用程序的当前状态是期望的状态。例如，假设你部署了一个 Kubernetes 部署，它应该有两个副本。然后，由于某种原因，其中一个
    Pod 被删除。部署控制器会察觉到这一点，并做出相应处理，确保创建第二个副本/Pod。所有可以在 Kubernetes 中创建的资源（如 Pods、Services、Ingress、Secrets
    等）都有一个 **控制器**。
- en: An **operator** is a special form of a controller. Operators implement the controller
    pattern, and their primary job is to move the resources inside of the Kubernetes
    cluster to the desired state.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作员**是控制器的一种特殊形式。操作员实现了控制器模式，它们的主要工作是将 Kubernetes 集群中的资源移动到期望的状态。'
- en: Operators also add the Kubernetes API extendibility to use **CustomResourceDefinitions**
    (**CRDs**), which are a way that engineers can utilize the existing Kubernetes
    API without having to build an entire controller and, instead, just use the CRD
    controller. You’ll see a lot of products/platforms that tie into Kubernetes to
    create a CRD.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 操作员还通过使用 **CustomResourceDefinitions** (**CRDs**) 扩展了 Kubernetes API，CRD 是一种让工程师可以利用现有
    Kubernetes API 的方式，而无需构建整个控制器，而是直接使用 CRD 控制器。你会看到许多与 Kubernetes 集成的产品/平台来创建 CRD。
- en: 'A popular way of building your own operator and controller is with Kubebuilder:
    [https://book.kubebuilder.io/](https://book.kubebuilder.io/).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 构建你自己的操作员和控制器的流行方式是使用 Kubebuilder：[https://book.kubebuilder.io/](https://book.kubebuilder.io/)。
- en: '![Figure 5.1 – Controllers'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1 – 控制器](img/B19116_05_01.jpg)'
- en: '](img/B19116_05_01.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B19116_05_01.jpg)'
- en: Figure 5.1 – Controllers
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 控制器
- en: You’ll hear the terms *operator* and *controller* used interchangeably. To give
    a frame of reference, just remember that the operator is like the big boss working
    at a high level, ensuring that things are going well for the organization, and
    the operator is like the engineer doing the hands-on work to make sure that the
    organization gets what it needs.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你会听到 *操作员* 和 *控制器* 这两个术语交替使用。为了帮助理解，只需记住，操作员就像是高层的大老板，确保组织运作良好，而控制器则像是工程师，亲自操作，确保组织得到所需的资源。
- en: Another form of this that’s gaining increased popularity is GitOps. GitOps looks
    at the desired state of a Kubernetes manifest that’s in source control as opposed
    to what controllers do, which is look at what’s actively deployed on a Kubernetes
    cluster.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一种日益流行的形式是 GitOps。GitOps 查看存储在源代码管理中的 Kubernetes 清单的期望状态，而不是像控制器那样查看 Kubernetes
    集群中当前部署的内容。
- en: Different ways to deploy with higher-level controllers
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用更高层次控制器的不同部署方式
- en: 'When you deploy a Pod by itself, the manifest can look like the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当你单独部署一个 Pod 时，清单可能看起来如下所示：
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The problem with this method is you have no high-level controller that manages
    the Pod(s) for you. Without the higher-level controller, like a Deployment or
    DaemonSet, if the Pod fails, the kubelet watches the static Pod and restarts it
    if it fails. There’s also no management of the current state and desired state.
    From a production perspective, you never want to deploy a Pod resource by itself.
    It’s fine if you want to test a container image, but that’s about it. It should
    be used for testing/development purposes only.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的问题在于你没有一个高层次的控制器来管理 Pod。如果没有像 Deployment 或 DaemonSet 这样的高层次控制器，当 Pod 失败时，kubelet
    会监视静态 Pod 并在其失败时重新启动它。并且也没有对当前状态和期望状态的管理。从生产角度来看，你永远不应该单独部署一个 Pod 资源。如果你想测试一个容器镜像，那是可以的，但就仅此而已。它应该仅用于测试/开发目的。
- en: 'Not always, but most of the time, you’ll see the following production-level
    controllers that manage Pods:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 并非总是如此，但大多数情况下，你会看到以下这些管理 Pods 的生产级控制器：
- en: '**Deployments**: A deployment is one of the highest-level controllers in the
    Core API group. It gives you the ability to control one Pod or multiple replicas
    and scale out across the cluster. Deployments also give you the ability to self-heal
    and confirm that the current state of a deployed containerized application is
    the desired state. The following code is an example deployment resource:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Deployments**：部署是 Core API 组中最高层次的控制器之一。它让你能够控制一个 Pod 或多个副本，并在集群中进行扩展。Deployments
    还让你具备自我修复能力，并确认已部署的容器化应用的当前状态是期望的状态。以下是一个部署资源的示例代码：'
- en: '[PRE5]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**DaemonSets**: This is like a deployment resource but is cluster wide. It
    ensures that either all nodes or the nodes you choose run a copy/replica of the
    Pod. A key difference you’ll see in a DaemonSet is that there’s no field for replicas.
    That’s because the Pod can’t run more replicas than the number of worker nodes,
    meaning you can’t have five Pod replicas if you only have three worker nodes.
    In that case, you’d only be able to have three Pods. The following code is an
    example DaemonSet:'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DaemonSets**：这类似于一个部署资源，但它是集群范围的。它确保所有节点或你选择的节点都运行 Pod 的副本/复制品。你会看到 DaemonSet
    的一个关键区别是没有副本字段。这是因为 Pod 的副本数不能超过工作节点的数量，也就是说，如果你只有三个工作节点，就不能有五个 Pod 副本。在这种情况下，你只能有三个
    Pods。以下是一个 DaemonSet 示例代码：'
- en: '[PRE24]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '`StatefulSet`:'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StatefulSet`：'
- en: '[PRE43]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: In terms of which controller to use, it’s going to depend on your use case.
    There’s no right or wrong answer here unless it’s something straightforward, for
    example, if you have a containerized app that needs to hold on to its network
    ID, in which case you’d use a StatefulSet.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择使用哪个控制器时，这将取决于你的使用场景。除非是一些直接明了的情况，比如，如果你有一个需要保持其网络 ID 的容器化应用，那么你将使用 StatefulSet。
- en: Scaling
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展
- en: One of the key components out of the box with Kubernetes is its ability to easily
    scale both horizontally and vertically. From a production perspective, this takes
    a ton of load off of your back. In a standard VM environment, you would have to
    worry about deploying a new server, installing the operating system, getting packages
    up to date, and deploying the application binary, and finally, the app would be
    running.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的一个关键组件是它能够轻松地实现水平和垂直扩展。从生产角度来看，这大大减轻了你的负担。在标准的虚拟机环境中，你需要担心部署新的服务器、安装操作系统、更新软件包并部署应用程序二进制文件，最后，应用才会运行。
- en: Horizontal Pod autoscaling is the most common, which means more Pods get created
    to handle load. Vertical autoscaling means the CPU/memory of a Pod gets raised.
    Vertical Pod autoscaling is not all that common, but possible.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 水平 Pod 自动扩展是最常见的方式，这意味着会创建更多的 Pods 来处理负载。垂直自动扩展意味着提升 Pod 的 CPU/内存。垂直 Pod 自动扩展并不常见，但也是可行的。
- en: When you’re scaling, you can have standard ReplicaSets, but in production, the
    number may not be so cut and dry. For example, if you have three replicas, but
    you may need four or ten, you need a way to account for that. The best thing that
    you can do is start with at least three to four replicas, and if needed, work
    your way up. If you have to scale up to five or ten, you can update the Kubernetes
    manifest and redeploy it with a GitOps solution or in another repeatable fashion
    using the `kubectl apply -f` `name_of_manifest.yaml` command.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在扩展时，你可以使用标准的ReplicaSets，但在生产环境中，副本数可能并不那么简单。例如，如果你有三个副本，但可能需要四个或十个副本，你需要一种方法来应对这种情况。你能做的最好的事情是至少从三个到四个副本开始，如果需要，逐步增加。如果你必须扩展到五个或十个副本，你可以更新Kubernetes清单，并使用GitOps解决方案或其他可重复的方式，使用`kubectl
    apply -f` `name_of_manifest.yaml`命令重新部署。
- en: When you’re scaling a Pod, or for that matter, when you’re doing anything for
    a Pod deployment, never use commands such as `kubectl patch` or any of the other
    quick fixes on the command line. If you do, any time the Pod gets redeployed,
    your configurations won’t exist because you did them ad hoc/manually on the command
    line. Always make changes in a Kubernetes manifest and deploy them properly (remember,
    current state versus desired state).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在扩展一个Pod，或者说，当你在进行任何Pod部署操作时，永远不要使用像`kubectl patch`这样的命令，或者在命令行上的其他快速修复方法。如果你这么做，每次Pod被重新部署时，你的配置将不复存在，因为你是在命令行上临时/手动修改的。始终在Kubernetes清单中进行更改，并正确部署（记住，当前状态与期望状态的关系）。
- en: How to horizontally scale Pods
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何水平扩展Pods
- en: 'When you’re scaling Pods horizontally, it’s all about replica count. For example,
    let’s say you have a Kubernetes manifest like the following, which contains two
    replicas:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当你水平扩展Pods时，关键在于副本数。例如，假设你有一个像下面这样的Kubernetes清单，其中包含两个副本：
- en: '[PRE75]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'You run `kubectl apply -f nginx.yaml` on the preceding manifest, and then you
    come to realize that due to user load on the Nginx frontend, you need to bump
    the replicas from two to four. At that point, you can update the Kubernetes manifest
    to go from two replicas to four:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 你在前述清单上运行`kubectl apply -f nginx.yaml`，然后你意识到，由于Nginx前端的用户负载，你需要将副本数从两个增加到四个。此时，你可以更新Kubernetes清单，将副本数从两个更改为四个：
- en: '[PRE76]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: This method won’t recreate anything as you’re using `kubectl apply -f` instead
    of `kubectl create -f`. `create` is for creating net-new resources and `apply`
    is for updating/patching a resource.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法不会重新创建任何东西，因为你使用的是`kubectl apply -f`而不是`kubectl create -f`。`create`用于创建全新的资源，而`apply`用于更新/修补现有资源。
- en: How to vertically scale Pods
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何垂直扩展Pods
- en: 'Vertically scaling Pods, as discussed, is not a common practice. However, it
    is doable. The typical method is to use the `VerticalPodAutoscaler` resource from
    the `autoscaling.k8s.io` API. It gives you the ability to point to an existing
    deployment so that deployment is managed by the autoscaler. For example, the following
    Kubernetes manifest shows a target reference of a deployment called `nginxdeployment`:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，垂直扩展Pods并不是常见的做法。然而，它是可行的。典型的方法是使用来自`autoscaling.k8s.io` API的`VerticalPodAutoscaler`资源。它使你能够指向现有的部署，以便该部署由自动扩展器管理。例如，以下Kubernetes清单显示了一个名为`nginxdeployment`的部署的目标引用：
- en: '[PRE77]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Please note that with the vertical Pod autoscaler turned to `Auto` for the
    update mode, it’ll have the ability to do the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，启用垂直Pod自动扩展器并将更新模式设置为`Auto`时，它将具备以下能力：
- en: Delete Pods
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除Pods
- en: Adjust the CPU
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整CPU
- en: Adjust the memory
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整内存
- en: Create a new Pod
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的Pod
- en: It requires a restart of the application running inside the Pod.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要重新启动在Pod内运行的应用程序。
- en: Multi-container Pods
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多容器Pods
- en: '**Sidecars**, sometimes called **multi-container Pods**, are a way to tightly
    couple containers into one Pod. Typically, and especially from an application
    perspective, one Pod runs one container. However, there may be use cases where
    you want to run sidecars. The biggest use case is when you’re running some type
    of log collector/aggregator for your Pods. A lot of engineers will put the container
    running the log collector into the same Pod where the application is running.
    That way, it’s straightforward to communicate with the application and pull the
    logs from it as containers inside of a Pod share the same IP address but are reachable
    on different ports.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sidecar**，有时也叫做**多容器Pod**，是一种将容器紧密耦合到一个Pod中的方式。通常，尤其从应用程序的角度来看，一个Pod运行一个容器。然而，也有一些使用场景需要运行sidecar。最大的使用场景是当你运行某种日志收集器/聚合器时。许多工程师会将运行日志收集器的容器放到与应用程序一起运行的同一个Pod中。这样，容器之间可以直接通信，并且可以从应用程序中拉取日志，因为Pod内的容器共享相同的IP地址，但可以通过不同的端口进行访问。'
- en: One thing you should absolutely never do is run multiple applications in a Pod.
    For example, you never want to put the frontend app and the backend app inside
    of the same Pod. That defeats the whole purpose of containers and microservices.
    Sidecars are only for very specific use cases and if it’s absolutely necessary.
    A personal belief of mine is that you should never use sidecars unless you absolutely
    have to. Other engineers will disagree with me, but I believe a Pod should run
    one workload. That’s the purpose of a microservice architecture. The only time
    that I see it absolutely necessary is when you’re running a service mesh and you
    need the service mesh proxy inside of the Pod.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你绝对不应该做的一件事是将多个应用程序运行在一个Pod中。例如，你绝对不想把前端应用和后端应用放在同一个Pod中。这完全违背了容器和微服务的初衷。Sidecar
    仅适用于非常特定的用例，并且只有在绝对必要的情况下才使用。我个人的看法是，除非你真的必须使用，否则绝不要使用sidecar。其他工程师可能不同意我，但我认为一个Pod应该只运行一个工作负载。这正是微服务架构的目的。我认为唯一绝对必要的情况是，当你运行服务网格并且需要将服务网格代理放入Pod中时。
- en: 'The following is what a Kubernetes manifest would look like if you have multiple
    containers inside of a Pod. Notice how under `spec.containers`, there’s `container1`
    and `container2`:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如果你在Pod中有多个容器，Kubernetes清单将是什么样子。注意在`spec.containers`下有`container1`和`container2`：
- en: '[PRE78]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Liveness and readiness probes
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活跃性和就绪性探针
- en: Whenever you’re deploying any type of application, whether it’s containerized
    or not, you want to ensure that the application is running as expected. Within
    a containerized environment, it’s no different. Let’s say you have a Pod that’s
    running an Nginx frontend. The Pod could be up and running, have all of the appropriate
    resources, and so on. However, that doesn’t mean that the binary running inside
    the Pod is working as expected. To ensure that the actual application is running
    as expected, you can use **liveness probes** and **readiness probes**.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 每当你部署任何类型的应用程序时，无论它是否容器化，你都需要确保该应用程序按预期运行。在容器化环境中，情况也是一样的。假设你有一个运行Nginx前端的Pod。Pod可能已经启动并运行，具备所有适当的资源，等等。然而，这并不意味着Pod内运行的二进制文件按预期工作。为了确保实际应用程序按预期运行，你可以使用**活跃性探针**和**就绪性探针**。
- en: A liveness probe indicates whether a container is running. It helps Kubernetes
    understand the overall health of the Pod. The kubelet continuously sends a *ping*
    of sorts to the container to ensure that it’s running as expected. If the liveness
    probe deems a container unhealthy, the kubelet restarts the Pod.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 活跃性探针表示容器是否正在运行。它帮助Kubernetes了解Pod的整体健康状况。kubelet会不断向容器发送类似*ping*的信号，确保容器按预期运行。如果活跃性探针认为容器不健康，kubelet会重启Pod。
- en: A readiness probe indicates whether the container is ready to receive requests.
    Readiness probes are a bit more important from an application perspective because
    they tell Kubernetes whether or not to route service traffic to Pods. If a service
    is trying to route traffic to a Pod and that Pod is down or unhealthy, the application
    won’t be reachable. The readiness probe tells the service which Pods are ready
    to receive requests and which aren’t.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪性探针表示容器是否准备好接收请求。从应用程序的角度来看，就绪性探针更为重要，因为它告诉Kubernetes是否将服务流量路由到Pod。如果服务尝试将流量路由到一个Pod，而这个Pod已经宕机或不健康，应用程序将无法访问。就绪性探针告诉服务哪些Pod已准备好接收请求，哪些没有。
- en: 'The following is an example of a readiness probe:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个就绪性探针的示例：
- en: '[PRE79]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The following is an example of a liveness probe:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个活跃性探针的示例：
- en: '[PRE80]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: All production-level Kubernetes deployments should use readiness probes.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 所有生产级的Kubernetes部署都应该使用就绪探针（readiness probes）。
- en: In the next section, you’re going to dive into an important topic, which is
    segregating your containerized apps, and a few different ways of doing it.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将深入探讨一个重要的话题——如何隔离你的容器化应用程序，以及几种不同的实现方式。
- en: Exploring segregation and namespaces
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索隔离和命名空间
- en: 'Once applications are deployed, engineers wipe the sweat off their foreheads,
    give high fives to their team, and rejoice in their victory. However, what comes
    after the deployment? Better yet, what if you have to deploy the applications
    again? Or other types of applications? Or to a different location or segregation
    point? (Segregation will be discussed later in this chapter.) Getting an application
    up and running is a mental workout in itself, but the *what-comes-next* questions
    you ask yourself are typically the most important. These are things such as the
    following:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用程序部署完成，工程师们会擦去额头上的汗水，与团队击掌庆祝胜利。然而，部署之后发生了什么呢？更重要的是，如果你需要重新部署这些应用程序呢？或者部署其他类型的应用程序？或者部署到不同的位置或隔离点？（隔离将在本章后面讨论。）让一个应用程序上线本身就是一项心理挑战，但你问自己的*接下来会发生什么*的问题通常是最重要的。这些问题包括以下内容：
- en: Will the next deployment be automated and repeatable?
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下一次部署会是自动化且可重复的吗？
- en: If you have to deploy the application again, will it be an effective deployment?
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要重新部署应用程序，这次部署会有效吗？
- en: Can (or should) the apps run right next to each other?
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序能（或应该）相互靠得这么近一起运行吗？
- en: Which engineers should have access to what apps and why?
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些工程师应该访问哪些应用程序，为什么？
- en: Deploying an application is a great victory but designing how and where an application
    should run is the difference between a successful and a broken-down production
    environment. Questions around application segregation and multi-tenancy keep engineers
    up at night because it’s less *engineering* work and more planning/architecture
    work. It’s less hands-on-keyboard and more critical thinking at a higher level
    compared to being down in the trenches in the code.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 部署应用程序是一项巨大的胜利，但设计应用程序应该如何运行以及在哪运行，是决定成功与失败生产环境之间的关键。关于应用程序隔离和多租户的问题常常让工程师们彻夜难眠，因为它们不仅仅是*工程*工作，更是规划和架构工作。它们更少涉及实际的键盘操作，而更多是需要从更高层次进行批判性思考，而非埋头写代码。
- en: In this section, you’re going to learn about a few of the most popular segregation
    techniques. Let’s get started!
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习一些最流行的隔离技术。让我们开始吧！
- en: Namespaces
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命名空间
- en: The first level of segregation, typically, is a **namespace**. When you’re deploying
    Pods, the last thing that you want to do is deploy everything and anything to
    the default namespace. Instead, you want to ensure that applications have their
    own namespaces. At a network level, Pods within one namespace can communicate
    with another namespace. However, if you have a service account that’s used for
    Pod deployments in one namespace and a service account that’s used to deploy Pods
    in another namespace, that means the same service account cannot be used to manage
    all of the Pods. That gives you a bit more segregation from a Pod management perspective
    and ensures that there’s proper authentication and authorization. But from a network
    perspective, Pods can still communicate with other Pods in separate namespaces.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离的第一个层次通常是**命名空间**。当你部署Pods时，最不希望做的事就是将所有东西都部署到默认命名空间。相反，你希望确保应用程序有各自的命名空间。在网络层面，一个命名空间中的Pods可以与另一个命名空间中的Pods通信。然而，如果你有一个用于在某个命名空间中部署Pods的服务账户，而另一个命名空间有一个用于部署Pods的服务账户，那么同一个服务账户就不能用于管理所有Pods。这从Pod管理的角度提供了一定程度的隔离，并确保有适当的身份验证和授权。但从网络的角度来看，Pods仍然可以与其他命名空间中的Pods进行通信。
- en: 'Notice in *Figure 5**.2* that there are three namespaces:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意*图 5.2*中有三个命名空间：
- en: '`argoCD`'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`argoCD`'
- en: '`kube-system`'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-system`'
- en: '`monitoring`'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`monitoring`'
- en: '![Figure 5.2 – Kubernetes resources'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.2 – Kubernetes 资源](img/B19116_05_02.jpg)'
- en: '](img/B19116_05_02.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B19116_05_02.jpg)'
- en: Figure 5.2 – Kubernetes resources
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – Kubernetes 资源
- en: The preceding screenshot shows that everything in the `argocd` namespace is
    segregated/isolated from everything in the `kube-system` namespace. If an engineer
    were to run `kubectl get pods`, they would only see the Pods in the namespace
    that they have access to.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图显示，`argocd`命名空间中的所有内容都与`kube-system`命名空间中的所有内容隔离/分开。如果工程师运行`kubectl get
    pods`，他们将只会看到他们有权限访问的命名空间中的Pods。
- en: Single tenancy
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单一租户
- en: Taking segregation and isolation a step further, there are **tenancy models**.
    First, let’s start with **single tenancy**, but before diving in, let’s talk about
    what tenancy models mean in Kubernetes.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 将隔离和分离推向更深层次的是**租户模型**。首先，让我们从**单租户**开始，但在深入之前，先讨论一下Kubernetes中的租户模型是什么意思。
- en: Isolating via tenancy could be anything from users to engineers to applications
    and all different resources. For example, single tenancy could mean running one
    containerized application across a cluster, or it could mean ensuring that one
    engineer has access to a cluster that no one else has access to it, but they can
    run as many applications as they want.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 通过租户隔离可以涉及用户、工程师、应用以及各种不同的资源。例如，单租户可能意味着在集群上运行一个容器化的应用，或者可能意味着确保一个工程师可以访问一个集群，而其他人无法访问，但他们可以运行任意多的应用。
- en: A typical scenario of single tenancy is isolating development environments.
    Let’s say you’re a developer and you need a Kubernetes cluster to test an application
    stack. The scenario would be that the platform engineering team, or whichever
    team manages Kubernetes clusters, gives you your own Kubernetes cluster to test
    the application stack. This is a great way to perform single tenancy as it allows
    all engineers working on different tech stacks to test their code without it compromising
    or interfering with other application stacks.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 单租户的一个典型场景是隔离开发环境。假设你是一个开发人员，需要一个Kubernetes集群来测试应用栈。场景是，平台工程团队，或任何管理Kubernetes集群的团队，给你一个专属的Kubernetes集群来测试应用栈。这是执行单租户的一个好方法，因为它允许不同技术栈的所有工程师在不干扰或影响其他应用栈的情况下测试他们的代码。
- en: Multi-tenancy
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多租户
- en: On the flip side is **multi-tenancy**. Multi-tenancy is where you have multiple
    engineers, users, or applications running on the same Kubernetes cluster. If you
    take a look again at *Figure 5**.2* showing the namespaces, you’ll see that Prometheus,
    ArgoCD, and Nginx are running on the same cluster. That would be considered a
    multi-tenancy cluster. Single tenancy would be if ArgoCD, Nginx, and Prometheus
    were all running on separate clusters.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 相对而言，**多租户**则是另一种情况。多租户指的是多个工程师、用户或应用在同一个Kubernetes集群上运行。如果你再次查看显示命名空间的*Figure
    5**.2*，你会看到Prometheus、ArgoCD和Nginx运行在同一个集群上。这被认为是一个多租户集群。如果ArgoCD、Nginx和Prometheus分别运行在不同的集群上，那就是单租户。
- en: In the real world, rarely do you see applications running on different clusters,
    or rather, an application per cluster. Instead, you usually see the multi-tenancy
    model for applications and the single-tenancy model for developers testing application
    stacks, and once the application stack is tested, it moves into the Kubernetes
    cluster with the rest of the applications.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，很少看到应用程序运行在不同的集群上，或者说每个集群运行一个应用程序。相反，你通常会看到应用程序使用多租户模型，而开发人员测试应用栈时使用单租户模型，一旦应用栈经过测试，它就会与其他应用一起迁移到Kubernetes集群中。
- en: In the next section, you’re going to learn how to think about stateless apps,
    stateful apps, and volumes.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何理解无状态应用、有状态应用和卷。
- en: Investigating stateless and stateful apps
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调查无状态和有状态应用
- en: At a high level, applications come in two forms – apps that need data stored
    and apps that don’t care whether the state of the data is stored. Let’s think
    about two different scenarios.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，应用有两种形式——需要存储数据的应用和不关心数据是否存储状态的应用。让我们思考两个不同的场景。
- en: When you log in to your Gmail account, or another email service provider, everything
    stays where it’s supposed to be. You can see the emails in your inbox, the sent
    messages, the emails in your trash bin, and so on. The application/platform stays
    how it’s supposed to be because the data is stateful. Now, on the opposite side
    of the spectrum, let’s take `www.google.com` into consideration. When you go to
    `www.google.com` in a web browser, you always have a fresh start. The entry box
    to type in your question is there, but the results to the previous question that
    you asked Google isn’t there. It’s always a fresh, clean slate. That’s because
    `www.google.com` is stateless, as in, it doesn’t just hold on to your data (well,
    it does… but that’s a separate discussion) and keep it in the web browser after
    every search.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 当你登录到Gmail帐户或其他电子邮件服务提供商时，一切都会保持在应该存在的位置。你可以看到收件箱中的邮件、已发送的邮件、垃圾桶中的邮件，等等。应用程序/平台保持正常工作，因为数据是有状态的。现在，换一个角度来讲，考虑一下`www.google.com`。当你在网页浏览器中访问`www.google.com`时，你总是从头开始。输入问题的框在那儿，但是你之前向Google提出的问题的结果却没有显示。它总是一个全新的、干净的页面。这是因为`www.google.com`是无状态的，也就是说，它不会在每次搜索后将你的数据保存到网页浏览器中（当然，它确实会保存一些数据，但那是另一个话题）。
- en: Of course, stateless versus stateful is a much deeper discussion, but that’s
    a high-level definition of how you can think about the two different types of
    applications.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有状态与无状态的问题是一个更为深刻的讨论，但这只是你可以用来理解这两种不同类型应用的一个高层次定义。
- en: In the next section, you’re going to learn about the different deployment methods
    for stateless and stateful applications inside of Kubernetes, along with resource
    considerations including limits, quotas, and requests for Pods to ensure that
    the production-level environment you’re running is sustainable.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习Kubernetes中有状态和无状态应用的不同部署方法，以及包括Pod的限制、配额和请求在内的资源考虑因素，以确保你运行的生产级环境是可持续的。
- en: Stateful versus stateless
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有状态与无状态
- en: In the opening of this section, I shared the Gmail example, which essentially
    shows what a stateful app is and what a stateless app is. From a Kubernetes perspective,
    the key difference is that a stateless application doesn’t need to store data.
    Stateful applications require backend storage, such as volumes. Another key difference
    is that stateful applications require keeping unique IDs, so if a Pod goes down,
    the Pod that comes up and replaces it must have the same unique ID. A stateless
    app doesn’t need to keep unique IDs.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节开头，我分享了Gmail的例子，实际上展示了什么是有状态应用，什么是无状态应用。从Kubernetes的角度来看，关键区别在于无状态应用不需要存储数据。
    有状态应用需要后端存储，例如卷。另一个关键区别是，有状态应用需要保持唯一的ID，所以如果一个Pod宕机，替代它的Pod必须拥有相同的唯一ID。而无状态应用则不需要保持唯一的ID。
- en: A common misconception is that stateless apps never use volumes, and that’s
    not the case. You can have a stateless application that, for example, requires
    a backend database or a volume/hard drive to store values.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的误解是，无状态应用从不使用卷，但事实并非如此。例如，你可以有一个无状态应用，它可能需要一个后端数据库或一个卷/硬盘来存储值。
- en: Volumes and hard drives aren’t what make a stateful application. The unique
    ID is what makes a stateful application.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 卷和硬盘并不是构成有状态应用的因素，唯一的ID才是构成有状态应用的关键。
- en: Container Storage Interface
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器存储接口
- en: For Kubernetes to interact with outside components that aren’t native, there
    must be a plugin of sorts. In the previous chapters, you learned about **Container
    Network Interface** (**CNI**), which is a plugin to use different network frameworks
    in Kubernetes. **Container Storage Interface** (**CSI**) is the same thing, but
    for storage devices. For example, you can have a CSI for NetApp, AWS S3, Azure
    Storage, and a ton of other storage providers.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使Kubernetes与非本地的外部组件进行交互，必须有一种插件。你在前几章中学习了**容器网络接口**（**CNI**），它是一个插件，可以在Kubernetes中使用不同的网络框架。**容器存储接口**（**CSI**）与此类似，但它是针对存储设备的。例如，你可以为NetApp、AWS
    S3、Azure存储以及许多其他存储提供商使用CSI。
- en: Before these interfaces, organizations had to put the code to connect the resources
    that aren’t native in the core Kubernetes code. Just as an example, let’s say
    that Azure wanted to allow Kubernetes engineers to utilize Azure Storage inside
    of Kubernetes for storing the output of a Pod. Before CSI, Azure would’ve had
    to put the code to make it all possible inside of the core Kubernetes code. That
    was a major hassle because not only did Azure have to wait for a new release of
    the Kubernetes API to push the feature out, but if there was a bug or a new update
    that they wanted to push out, they would’ve had to wait for the next Kubernetes
    API release.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在有了这些接口之前，组织必须将代码放入以连接不在核心 Kubernetes 代码中的资源。仅举个例子，假设 Azure 想允许 Kubernetes 工程师在
    Kubernetes 内部使用 Azure 存储来存储 Pod 的输出。在 CSI 出现之前，Azure 必须将使这一切成为可能的代码放入核心 Kubernetes
    代码中。这是一个很大的麻烦，因为 Azure 不仅需要等待 Kubernetes API 的新版本发布才能推出该功能，而且如果存在 Bug 或需要推出新更新，它们还必须等待下一个
    Kubernetes API 发布。
- en: CSI, and interfaces/plugins across Kubernetes in general, ensures that organizations
    can create plugins for Kubernetes separately from the core Kubernetes code.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: CSI，以及 Kubernetes 中的通用接口/插件，确保组织可以单独为 Kubernetes 创建插件，而不是依赖核心 Kubernetes 代码。
- en: 'If you want to see an example of CSI, you can check it out on GitHub: [https://github.com/kubernetes-sigs/azuredisk-csi-driver.](https://github.com/kubernetes-sigs/azuredisk-csi-driver%0D)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想看一个 CSI 的例子，可以在 GitHub 上查看：[https://github.com/kubernetes-sigs/azuredisk-csi-driver.](https://github.com/kubernetes-sigs/azuredisk-csi-driver%0D)
- en: Volumes
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷
- en: '**Volumes** are hard drives, plain and simple.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '**Volumes** 是硬盘，简单明了。'
- en: With a volume, you give a Pod, or multiple Pods, the ability to store data in
    a location. That location could be Azure, AWS, NetApp, some other storage provider,
    or even the worker node that the Pod is running on (definitely not recommended.
    Just an example).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 有了卷，你可以让一个 Pod 或多个 Pod 在某个位置存储数据。该位置可以是 Azure、AWS、NetApp、其他某个存储提供者，甚至是 Pod 运行的
    worker 节点（绝对不推荐。这只是一个例子）。
- en: 'When you’re creating a volume for a Pod, there are typically three steps:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 当为 Pod 创建卷时，通常有三个步骤：
- en: '**StorageClass**: A storage class is a way to ask some storage vendor (dynamically)
    for a hard drive. For example, you can create a storage class that connects to
    EBS. Then, you can call upon that storage class later with a volume (which you’ll
    learn about in a minute) and utilize the connection to the storage. You can do
    the same thing in Azure, GCP, and all of the other cloud providers, including
    most of the storage providers:'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StorageClass**: 存储类是向某个存储供应商（动态地）请求硬盘的一种方式。例如，你可以创建一个连接到 EBS 的存储类。然后，稍后可以使用卷（你马上就会学到的）调用该存储类，并利用与存储的连接。你可以在
    Azure、GCP 和所有其他云提供商，包括大多数存储提供者中做同样的事情：'
- en: '[PRE81]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '**PersistentVolume**: A persistent volume is created manually by an engineer
    that uses the storage class to utilize storage from an available source. For example,
    the Persistent Volume would connect to the EBS storage class from the previous
    example:'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PersistentVolume**: 持久化卷由工程师手动创建，使用存储类从可用源利用存储。例如，持久化卷将连接到先前示例中的 EBS 存储类：'
- en: '[PRE97]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '**PersistentVolumeClaim**: The last piece is the persistent volume claim, which
    is a request made by a user, usually in a Kubernetes manifest that’s creating
    a Pod, to use some of the storage that’s available in the storage class. The engineer
    can say “hey, I want 10 GB of storage from this storage class for my Pod”:'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PersistentVolumeClaim**: 最后一部分是持久化卷索取，这是用户通常在创建 Pod 的 Kubernetes 清单中提出的请求，以使用存储类中可用的一些存储空间。工程师可以说：“嘿，我想要从这个存储类中为我的
    Pod 使用 10 GB 存储空间”：'
- en: '[PRE106]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: At this point, you may be wondering “well, why do I need a persistent volume
    if I can just automatically request some storage with a claim?”, and that’s a
    good question. The answer is going to depend on your environment. If you’re using
    NetApp storage, and you have 1,000 GB of storage, you want an engineer to create
    a persistent volume and manage those volumes because you only have 1,000 GB of
    storage. If you attempt to go over that 1,000 GB, failures will start to occur,
    so having someone manage it makes sense. On the flip side, if you’re using cloud
    storage, such as in Azure or AWS, that storage is *unlimited* to a user (you of
    course have to pay for it), so going straight to a persistent volume claim instead
    of having an engineer create a persistent volume would make sense.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，你可能会想：“如果我可以通过声明自动请求一些存储，那为什么还需要持久化存储卷呢？”这是个好问题。答案取决于你的环境。如果你使用的是NetApp存储，且你有1,000
    GB的存储空间，你需要工程师创建持久化存储卷并管理这些存储卷，因为你只有1,000 GB的存储。如果你尝试超过1,000 GB，故障就会开始发生，因此让有人来管理它是有意义的。反过来，如果你使用的是云存储，如Azure或AWS，那么这些存储对于用户来说是*无限*的（当然，你需要为此付费），所以直接申请一个持久化存储卷而不是让工程师创建持久化存储卷会更合理。
- en: Resource requests and limits
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源请求和限制
- en: In any production environment, you have Kubernetes clusters that are running
    on servers, regardless of whether it’s on-premises or a managed Kubernetes service.
    Because they are running on servers, those servers have hardware resources, and
    all servers have a limit. There’s no *unlimited CPU* on a server or *unlimited
    memory*. There are limits to a server’s resources and servers can reach 100% capacity.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何生产环境中，你都有Kubernetes集群在服务器上运行，无论它是在本地还是托管的Kubernetes服务中。因为它们运行在服务器上，所以这些服务器有硬件资源，而所有服务器都有其资源限制。服务器上没有*无限的CPU*或*无限的内存*。服务器的资源是有限的，服务器也能达到100%的容量。
- en: Because of that, when you’re creating Pods, you should specify limits and requests.
    You never want to give anything, whether it’s a virtualized VM or a containerized
    app, open reign in an environment to take as much CPU and memory as it wants.
    If you don’t control resources, such as memory and CPU, every application could
    take whatever resources it wanted to take.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当你创建Pod时，你应该指定资源限制和请求。你绝不希望让任何东西——无论是虚拟化的虚拟机还是容器化的应用程序——在环境中自由地占用尽可能多的CPU和内存。如果你不控制资源（例如内存和CPU），每个应用程序都可能会随意占用它所需要的资源。
- en: Let’s think about a basic example. Say you have an application that has a memory
    leak. If you containerize it, the Pod that it’s running in will continue to take
    more and more memory until the worker node eventually fails and/or the application
    crashes, and you’ll only know when it’s too late.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个基本的例子。假设你有一个存在内存泄漏的应用程序。如果你将其容器化，那么它所在的Pod将持续消耗越来越多的内存，直到工作节点最终失败或应用程序崩溃，而你只能在为时已晚时才会知道。
- en: Before diving in, let’s define the difference between a **limit** and a **request**.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解之前，我们先定义一下**限制**和**请求**之间的区别。
- en: A limit is telling a Pod “you cannot go above this.” For example, if you specify
    *X* amount of CPU or memory on a Pod, that Pod cannot go above that limit. It’s
    completely blocked.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 限制是告诉Pod：“你不能超过这个限制。”例如，如果你为Pod指定了*X*数量的CPU或内存，那么该Pod就不能超过这个限制。它被完全封锁。
- en: 'The following is an example of a limit. As you can see, the Nginx app is limited
    to 128 Mi of memory. Anything above that and Kubernetes will say “nope, you can’t
    have it”:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是限制的示例。如你所见，Nginx应用程序的内存限制为128 Mi。超过这个值，Kubernetes会说：“不行，你不能拥有更多”：
- en: '[PRE117]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: A request is what the Pod is guaranteed to get. If a Pod requests a resource,
    Kubernetes will only schedule it on a worker node that can give it that resource.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 请求是Pod能够保证获得的资源。如果Pod请求某个资源，Kubernetes只会将它调度到能够提供该资源的工作节点上。
- en: 'The following is an example of a request. In this example, Kubernetes will
    say “alright, you want 64 Mi of memory and 250m of CPU. Let me schedule you onto
    a worker node that can handle this”:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是请求的示例。在这个例子中，Kubernetes会说：“好吧，你想要64 Mi内存和250m的CPU。让我把你调度到一个可以处理这些的工作节点上”：
- en: '[PRE118]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'The following is an entire manifest example:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是完整的清单示例：
- en: '[PRE119]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: Which should you choose?
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你应该选择哪个？
- en: There’s some confusion around how requests and limits work.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 对于请求和限制的工作方式，存在一些困惑。
- en: When Pods are done using memory, they give that memory back to the worker node
    and it goes back into the pool for other Pods to use. With the CPU, it does not.
    The Pod will hold on to that CPU. Because of that, it’s not a best practice to
    let the Pod just hold on to the CPU until it gets deleted because it may not always
    need that amount of CPU. It’s essentially wasting CPU resources.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Pods 使用完内存后，它们会将内存归还给工作节点，然后这些内存会回到资源池中供其他 Pods 使用。而 CPU 则不同，它不会被归还。Pod 会继续占用这个
    CPU。因为这个原因，最佳实践不是让 Pod 一直占用 CPU 直到它被删除，因为它可能并不总是需要这么多的 CPU。这实际上是在浪费 CPU 资源。
- en: So, which should you choose?
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，您应该选择哪一个呢？
- en: In every production environment, you should always set up requests, but you
    should only limit CPU.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个生产环境中，您应该始终设置请求，但您只应限制 CPU。
- en: Namespace quotas
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命名空间配额
- en: 'When it comes to limits and requests, one of the really awesome things that
    you can do is set them up for namespaces. For example, you can have a namespace
    that has a limit of 1,000 Mi and a request of 512 Mi. That way, all nodes running
    in that namespace automatically get limited to the required resources, which means
    you don’t have to put limits and requests into every single Kubernetes Pod manifest.
    The following code block showcases the resource quota:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到限制和请求时，您可以做的其中一件非常棒的事情就是为命名空间设置它们。例如，您可以为一个命名空间设置 1,000 Mi 的限制和 512 Mi 的请求。这样，所有在该命名空间中运行的节点会自动被限制到所需的资源，这意味着您不需要在每一个
    Kubernetes Pod 清单中都设置限制和请求。以下代码块展示了资源配额：
- en: '[PRE120]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: In the next and final section, you’re going to learn how to upgrade apps and
    different types of update methods.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的最后一节中，您将学习如何升级应用程序以及不同类型的更新方法。
- en: Upgrading Kubernetes apps
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级 Kubernetes 应用
- en: 'Throughout this chapter, you learned some very important lessons:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学到了一些非常重要的知识：
- en: How to deploy an app
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何部署应用程序
- en: How to deploy different types of apps on Kubernetes
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Kubernetes 上部署不同类型的应用
- en: How to ensure apps are properly scaled
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何确保应用程序正确扩展
- en: How to ensure apps are running as you expected
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何确保应用程序按预期运行
- en: Once you get an application to where you’d like it to be, it’s a great accomplishment.
    Then, before you know it, it’s time to upgrade or update the application and you
    have to start on the journey all over again. You must test out the new version
    of the app, get it deployed without taking down the entire production environment,
    and retest all the components to ensure it’s running as expected.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将应用程序部署到理想的状态，那将是一个巨大的成就。然后，不久之后，您就需要升级或更新应用程序，而您必须重新开始这整个过程。您必须测试新版本的应用程序，在不影响整个生产环境的情况下进行部署，并重新测试所有组件，以确保它按预期运行。
- en: There may also be times, which is extremely common, when you must roll back
    an update or upgrade to a previous application version. Perhaps it wasn’t properly
    tested in the staging environment, or something popped up that the QA/regression
    testing didn’t catch. In any case, you need a solid plan and methodology on how
    to do a rollback.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 可能还有一些情况下，尤其是非常常见的情况，您必须将更新或升级回滚到先前的应用版本。也许它在预发布环境中没有经过充分测试，或者出现了 QA/回归测试没有捕获到的问题。无论如何，您都需要有一个可靠的计划和方法来进行回滚操作。
- en: In this section, you’re going to learn a few different ways to test out application
    updates and upgrades, how you can upgrade and update applications running in Kubernetes,
    and how you can roll back updates and upgrades when necessary.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习几种不同的方式来测试应用程序的更新和升级，如何升级和更新在 Kubernetes 中运行的应用程序，以及如何在必要时回滚更新和升级。
- en: Types of upgrades
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级类型
- en: First, let’s break down the typical types of upgrades in Kubernetes.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们解析 Kubernetes 中的典型升级类型。
- en: A/B testing is a way to have a set of users on one version of the application
    and a set of users on another version of the application. For example, let’s say
    you’re testing out two versions of an app, v1.1 and v1.2\. A set of users would
    get v1.1 and another set of users would get v1.2\. At that point, you can test
    things such as performance, how the users are interacting with the new version
    of the app, bugs, and issues. This type of test is a controlled experiment.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: A/B 测试是一种将一组用户放在应用程序的一个版本上，另一组用户放在另一个版本上的方法。例如，假设您正在测试应用程序的两个版本，v1.1 和 v1.2。一个用户组将使用
    v1.1，另一个用户组将使用 v1.2。此时，您可以测试诸如性能、用户如何与新版本应用程序交互、漏洞和问题等内容。这种测试类型是一种受控实验。
- en: Canary deployments are pretty much identical to A/B testing except they’re done
    with real users. Taking the previous example, let’s say you had v1.1 and v1.2
    of an app. You would roll out v1.2 in production and put a set of users on v1.2
    but keep a set of users on v1.1\. That way, you can see how users interact with
    the new version in production.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: Blue/green testing is when you have two production environments, one on v1.1
    and one on v1.2\. All the users are still on v1.1, but you slowly start to migrate
    all of the users to v1.2\. All users are moved over to v1.2 once it’s confirmed
    to be working.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes, the most popular upgrade method is a **rolling update**, which,
    based on the preceding explanations, is a blue/green deployment.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: What happens to an app being upgraded?
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you’re upgrading a container image in a Pod, what happens is the new Pod
    comes up and is tested and the old Pod then gets deleted.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take the example from the previous section regarding v1.1 and v.1.2 with
    the help of the following diagram:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Rolling update'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19116_05_03.jpg)'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Rolling update
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding architecture diagram, what’s happening is v1.1 is running on
    a Pod with an IP address of 10.0.0.5\. Then, the new Pod running v1.2 comes up
    and is running at the same time as the old Pod. Once the deployment confirms that
    v1.2 of the Pod is working properly and as expected, the users will begin to move
    over to the new Pod. Once all users are on the new Pod running v1.2, the old Pod
    running v1.1 gets deleted.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: Rolling updates
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What was explained in the previous section was a rolling update. Let’s take
    a look at it from a code perspective. The following is a Kubernetes manifest that’s
    running a deployment spec with a containerized Nginx image using v1.1:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'Then, the time comes to upgrade the containerized app. To upgrade the app with
    `RollingUpdate` (blue/green deployment), you would swap out the `nginx:1.1` container
    image version with `nginx:1.2`. The `RollingUpdate` configuration contains a `progressDeadlineSeconds`
    and `minReadySeconds` configuration to confirm that the new version of the containerized
    app comes up appropriately. Within the strategy map, you specify a `RollingUpdate`
    type and ensure that one replica is always running the old containerized app version
    as the update occurs. That way, users aren’t kicked off the app. The following
    code will perform the proper rolling update action:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: You would then run `kubectl apply -f` against the Kubernetes manifest, and the
    rolling update would begin.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Rollbacks
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’d like to roll back `RollingUpdate`, you’ll need two commands.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: 'First, get the revision number that you want to roll back to from the following
    command:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'Next, undo `RollingUpdate`:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: Not only are updates and rollbacks important to understand from an educational
    perspective, but you’ll most likely see this a fair amount as your organization
    moves to a more microservice-driven approach.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many types of resource deployments when it comes to Kubernetes and
    often, there’s no right or wrong answer to which you choose. The only time that
    there’s a true right or wrong answer is depending on the deployment. If you have
    a stateful application, you want to use a StatefulSet. There’s no mystery as to
    which controller you should be using and there’s no *good or bad*. It simply depends
    on the type of application and workload you need to deploy and manage.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，有许多类型的资源部署方式，通常没有明确的“对”与“错”之分，选择哪种方式取决于具体情况。只有在部署特定应用时，才会有真正的“对”与“错”。如果你有一个有状态的应用程序，你应该使用
    StatefulSet。关于你应该使用哪种控制器，实际上没有什么神秘的，*也没有好坏之分*。这仅仅取决于你需要部署和管理的应用程序和工作负载类型。
- en: In the next chapter, we’ll be diving a little bit deeper into different types
    of deployments from a more advanced perspective.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将从更高级的角度深入探讨不同类型的部署。
- en: Further reading
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Kubernetes – An Enterprise Guide* by Marc Boorshtein and Scott Surovich: [https://www.packtpub.com/product/kubernetes-an-enterprise-guide-second-edition/9781803230030](https://www.packtpub.com/product/kubernetes-an-enterprise-guide-second-edition/9781803230030)'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes – 企业指南* 由 Marc Boorshtein 和 Scott Surovich 编著：[https://www.packtpub.com/product/kubernetes-an-enterprise-guide-second-edition/9781803230030](https://www.packtpub.com/product/kubernetes-an-enterprise-guide-second-edition/9781803230030)'
