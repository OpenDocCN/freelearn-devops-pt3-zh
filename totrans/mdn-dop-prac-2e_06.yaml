- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing Advanced Kubernetes Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we covered Kubernetes and why we need it and then discussed
    bootstrapping a Kubernetes cluster using MiniKube and KinD. We then looked at
    the `Pod` resource and discussed how to create and manage pods, how to troubleshoot
    them, and how to ensure your application’s reliability using probes, along with
    multi-container design patterns to appreciate why Kubernetes uses pods in the
    first place instead of containers. We also looked at `Secrets` and `ConfigMaps`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will dive deep into the advanced aspects of Kubernetes and Kubernetes
    command-line best practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The need for advanced Kubernetes resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Services and Ingresses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Horizontal pod autoscaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing stateful applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes command-line best practices, tips, and tricks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, let’s dive in!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, we will spin up a cloud-based Kubernetes cluster, **Google
    Kubernetes Engine** (**GKE**), for the exercises. That is because you will not
    be able to spin up load balancers and PersistentVolumes within your local system,
    and therefore, we cannot use KinD and MiniKube in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, **Google Cloud Platform** (**GCP**) provides a free $300 trial for
    90 days, so you can go ahead and sign up for one at [https://cloud.google.com/free](https://cloud.google.com/free).
  prefs: []
  type: TYPE_NORMAL
- en: Spinning up GKE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you’ve signed up and logged in to your console, you can open the Google
    Cloud Shell CLI to run the commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'You need to enable the GKE API first using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To create a three-node GKE cluster, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: And that’s it! The cluster is up and running.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also need to clone the following GitHub repository for some exercises:
    [https://github.com/PacktPublishing/Modern-DevOps-Practices-2e](https://github.com/PacktPublishing/Modern-DevOps-Practices-2e).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to clone the repository into your home directory
    and `cd` into the `ch6` directory to access the required resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s understand why we need advanced Kubernetes resources.
  prefs: []
  type: TYPE_NORMAL
- en: The need for advanced Kubernetes resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we looked at pods, the basic building blocks of Kubernetes
    that provide everything for your containers to run within a Kubernetes environment.
    However, pods on their own are not that effective. The reason is that while they
    define a container application and its specification, they do not replicate, auto-heal,
    or maintain a particular state. When you delete a pod, the pod is gone. You cannot
    maintain multiple versions of your code or roll out and roll back releases using
    a pod. You also cannot autoscale your application with traffic with pods alone.
    Pods do not allow you to expose your containers to the outside world, and they
    do not provide traffic management capabilities such as load balancing, content
    and path-based routing, storing persistent data to externally attached storage,
    and so on. To solve these problems, Kubernetes provides us with specific advanced
    resources, such as Deployments, Services, Ingresses, PersistentVolumes and claims,
    and StatefulSets. Let’s start with Kubernetes Deployments in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s understand Kubernetes Deployments using a simple analogy.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you’re a chef preparing a particular dish in your kitchen. You want
    to make sure that it is consistently perfect every time you serve it, and you
    want to be able to change the recipe without causing a chaotic mess.
  prefs: []
  type: TYPE_NORMAL
- en: In the world of Kubernetes, a “Deployment” is like your sous chef. It helps
    you create and manage copies of your pods effortlessly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating consistency**: You want to serve your dish to many guests. Therefore,
    instead of cooking each plate separately, you prepare a bunch of them at once.
    All of them should taste the same and strictly as intended. A Kubernetes Deployment
    does the same for your pod. It creates multiple identical copies of your pod,
    ensuring they all have the same setup.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Deployment` resource slowly and carefully replaces old copies with new ones
    individually, so your app is always available, and your guests (or users) don’t
    notice any hiccups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rolling back gracefully**: Sometimes, experiments don’t go as planned, and
    you must revert to the original recipe. Just as in your kitchen, Kubernetes lets
    you roll back to the previous version of your pod if things don’t work out with
    the new one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scaling easily**: Imagine your restaurant suddenly gets a rush of customers,
    and you need more plates for your special dish. A Kubernetes Deployment helps
    with that, too. It can quickly create more copies of your pod to handle the increased
    demand and remove them when things quieten down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing multiple kitchens**: If you have multiple restaurants, you’d want
    your signature dish to taste the same in all of them. Similarly, if you’re using
    Kubernetes across different environments such as testing, development, and production,
    Deployments help keep things consistent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In essence, Kubernetes Deployments help manage your pod, like a sous chef manages
    the dishes served from a kitchen. They ensure consistency, safety, and flexibility,
    ensuring your application runs smoothly and can be updated without causing a mess
    in your *software kitchen*.
  prefs: []
  type: TYPE_NORMAL
- en: Container application Deployments within Kubernetes are done through `Deployment`
    resources. `Deployment` resources employ `ReplicaSet` resources behind the scenes,
    so it would be good to look at `ReplicaSet` resources before we move on to understand
    `Deployment` resources.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ReplicaSet` resources are Kubernetes controllers that help you run multiple
    pod replicas at a given time. They provide horizontal scaling for your container
    workloads, forming the basic building block of a horizontal scale set for your
    containers, a group of similar containers tied together to run as a unit.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ReplicaSet` resources define the number of pod replicas to run at a given
    time. The Kubernetes controller then tries to maintain the replicas and recreates
    a pod if it goes down.'
  prefs: []
  type: TYPE_NORMAL
- en: You should never use `ReplicaSet` resources on their own, but instead, they
    should act as a backend to a `Deployment` resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'For understanding, however, let’s look at an example. To access the resources
    for this section, `cd` into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ReplicaSet` resource manifest, `nginx-replica-set.yaml`, looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The resource manifest includes `apiVersion` and `kind`, as with any other resource.
    It also contains a `metadata` section that defines the resource’s `name` and `labels`
    attributes, similar to any other Kubernetes resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `spec` section contains the following attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`replicas`: This defines the number of pod replicas matched by the selector
    to run at a given time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selector`: This defines the basis on which the `ReplicaSet` resource will
    include pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selector.matchLabels`: This defines labels and their values to select pods.
    Therefore, the `ReplicaSet` resource will select any pod with the `app:` `nginx`
    label.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`template`: This is an optional section that you can use to define the pod
    template. This section’s contents are very similar to defining a pod, except it
    lacks the `name` attribute, as the `ReplicaSet` resource will generate dynamic
    names for pods. If you don’t include this section, the `ReplicaSet` resource will
    still try to acquire existing pods with matching labels. However, it cannot create
    new pods because of the missing template. Therefore, it is best practice to specify
    a template for a `ReplicaSet` resource.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s go ahead and apply this manifest to see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s run the following command to list the `ReplicaSet` resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Right—so, we see that there are three desired replicas. Currently, `3` replicas
    are running, but `0` are ready. Let’s wait for a while and then rerun the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, we see `3` ready pods that are awaiting a connection. Now, let’s list
    the pods and see what the `ReplicaSet` resource has done behind the scenes using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: There are three `nginx` pods, each with a name that starts with `nginx` but
    ends with a random hash. The `ReplicaSet` resource has appended a random hash
    to generate unique pods at the end of the `ReplicaSet` resource name. Yes—the
    name of every resource of a particular kind in Kubernetes should be unique.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go ahead and use the following command to delete one of the pods from
    the `ReplicaSet` resource and see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We see that even though we deleted the `nginx-9kvkj` pod, the `ReplicaSet` resource
    has replaced it with a new pod, `nginx-9xbdf`. That is how `ReplicaSet` resources
    work.
  prefs: []
  type: TYPE_NORMAL
- en: You can delete a `ReplicaSet` resource just like any other Kubernetes resource.
    You can run the `kubectl delete replicaset <ReplicaSet name>` command for an imperative
    approach or use `kubectl delete -f <manifest_file>` for a declarative approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use the former approach and delete the `ReplicaSet` resource by using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s check whether the `ReplicaSet` resource has been deleted by running the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We don’t have anything in the `default` namespace. This means that the `ReplicaSet`
    resource is deleted.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed, `ReplicaSet` resources should not be used on their own but
    should instead be the backend of `Deployment` resources. Let’s now look at Kubernetes
    `Deployment` resources.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes `Deployment` resources help to manage deployments for container applications.
    They are typically used for managing stateless workloads. You can still use them
    to manage stateful applications, but the recommended approach for stateful applications
    is to use `StatefulSet` resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes Deployments use `ReplicaSet` resources as a backend, and the chain
    of resources looks like what’s shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Deployment chain](img/B19877_Figure_6.01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Deployment chain
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take the preceding example and create an nginx `Deployment` resource
    manifest—`nginx-deployment.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The manifest is very similar to the `ReplicaSet` resource, except for the `kind`
    attribute—`Deployment`, in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply the manifest by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'So, as the `Deployment` resource has been created, let’s look at the chain
    of resources it created. Let’s run `kubectl get` to list the `Deployment` resources
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: And we see there is one `Deployment` resource called `nginx`, with `3/3` ready
    pods and `3` up-to-date pods. As `Deployment` resources manage multiple versions,
    `UP-TO-DATE` signifies whether the latest `Deployment` resource has rolled out
    successfully. We will look into the details of this in the subsequent sections.
    It also shows `3` available pods at that time.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we know `Deployment` resources create `ReplicaSet` resources in the background,
    let’s get the `ReplicaSet` resources using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: And we see that the `Deployment` resource has created a `ReplicaSet` resource,
    which starts with `nginx` and ends with a random hash. That is required as a `Deployment`
    resource might contain one or more `ReplicaSet` resources. We will look at how
    in the subsequent sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next in the chain are pods, so let’s get the pods using the following command
    to see for ourselves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: And, as expected, we have three pods. Each begins with the `ReplicaSet` resource
    name and ends with a random hash. That’s why you see two hashes in the pod name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume you have a new release and want to deploy a new version of your
    container image. So, let’s update the `Deployment` resource with a new image using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To check the deployment status, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Imperative commands such as those just shown are normally not used in production
    environments because they lack the audit trail you would get with declarative
    manifests using Git to version them. However, if you do choose to use imperative
    commands, you can always record the change cause of the previous rollout using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To check the Deployment history, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, there are two revisions in the Deployment history. Revision `1`
    was the initial Deployment, and revision `2` was because of the `kubectl set image`
    command we ran, as evident from the `CHANGE-CAUSE` column.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say you find an issue after Deployment and want to roll it back to the
    previous version. To do so and also recheck the status of the Deployment, run
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, let’s recheck the deployment history using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: And we get revision `3` with a `CHANGE-CAUSE` value of `<none>`. In this case,
    we did not annotate the rollback as in the last command.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Always annotate Deployment updates as it becomes easier to peek into the history
    to see what got deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at some common Kubernetes Deployment strategies to understand
    how to use Deployments effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Deployment strategies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Updating an existing Deployment requires you to specify a new container image.
    That is why we version container images in the first place so that you can roll
    out, and roll back, application changes as required. As we run everything in containers—and
    containers, by definition, are ephemeral—this enables a host of different deployment
    strategies that we can implement. There are several deployment strategies, and
    some of these are set out as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Recreate**: This is the simplest of all. Delete the old pod and deploy a
    new one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rolling update**: Slowly roll out the pods of the new version while still
    running the old version, and slowly remove the old pods as the new pods get ready.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blue/green**: This is a derived deployment strategy where we keep both versions
    running simultaneously and switch the traffic to the newer version when we want.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canary**: This applies to Blue/Green Deployments where we switch a percentage
    of traffic to the newer version of the application before fully rolling out the
    release.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A/B testing**: A/B testing is more of a technique to apply to Blue/Green
    Deployments. This is when you want to roll out the newer version to a subset of
    willing users and study the usage patterns before completely rolling out the newer
    version. You do not get A/B testing out of the box with Kubernetes but instead
    should rely on service mesh technologies that plug in well with Kubernetes, such
    as **Istio**, **Linkerd**, and **Traefik**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes provides two deployment strategies out of the box—`Recreate` and
    `RollingUpdate`.
  prefs: []
  type: TYPE_NORMAL
- en: Recreate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Recreate` strategy is the most straightforward deployment strategy. When
    you update the `Deployment` resource with the `Recreate` strategy, Kubernetes
    immediately spins down the old `ReplicaSet` resource and creates a new one with
    the required number of replicas along the lines of the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Recreate strategy](img/B19877_Figure_6.02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Recreate strategy
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes does not delete the old `ReplicaSet` resource but instead sets `replicas`
    to `0`. That is required to roll back to the old version quickly. This approach
    results in downtime and is something you want to use only in case of a constraint.
    Thus, this strategy isn’t the default deployment strategy in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: You can use the `Recreate` strategy if your application does not support multiple
    replicas, if it does not support more than a certain number of replicas (such
    as applications that need to maintain a quorum), or if it does not support multiple
    versions at once.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s update `nginx-deployment` with the `Recreate` strategy. Let’s look at
    the `nginx-recreate.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The YAML file now contains a `strategy` section with a `Recreate` type. Now,
    let’s apply the `nginx-recreate.yaml` file and watch the `ReplicaSet` resources
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The `Deployment` resource creates a new `ReplicaSet` resource—`nginx-6799fc88d8`—with
    `0` desired replicas. It then sets `0` desired replicas to the old `ReplicaSet`
    resource and waits for the old `ReplicaSet` resource to be completely evicted.
    It then starts automatically rolling out the new `ReplicaSet` resource to the
    desired images.
  prefs: []
  type: TYPE_NORMAL
- en: RollingUpdate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you update the Deployment with a `RollingUpdate` strategy, Kubernetes
    creates a new `ReplicaSet` resource, and it simultaneously spins up the required
    number of pods on the new `ReplicaSet` resource while slowly spinning down the
    old `ReplicaSet` resource, as evident from the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – RollingUpdate strategy](img/B19877_Figure_6.03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – RollingUpdate strategy
  prefs: []
  type: TYPE_NORMAL
- en: '`RollingUpdate` is the default deployment strategy. You can use the `RollingUpdate`
    strategy in most applications, apart from ones that cannot tolerate more than
    one version of the application at a given time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s update the `nginx` `Deployment` resource using the `RollingUpdate` strategy.
    We will reuse the standard `nginx-deployment.yaml` file that we used before. Use
    the following command and see what happens to the `ReplicaSet` resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As we see, the old `ReplicaSet` resource—`nginx-6799fc88d8`—is being rolled
    down, and the new `ReplicaSet` resource—`nginx-6889dfccd5`—is being rolled out
    simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: The `RollingUpdate` strategy also has two options—`maxUnavailable` and `maxSurge`.
  prefs: []
  type: TYPE_NORMAL
- en: While `maxSurge` defines the maximum number of additional pods we can have at
    a given time, `maxUnavailable` defines the maximum number of unavailable pods
    we can have at a given time.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Set `maxSurge` to `0` if your application cannot tolerate more than a certain
    number of replicas. Set `maxUnavailable` to `0` if you want to maintain reliability
    and your application can tolerate more than the set replicas. You cannot specify
    `0` for both parameters, as that will make any rollout attempts impossible. While
    setting `maxSurge`, ensure your cluster has spare capacity to spin up additional
    pods, or the rollout will fail.
  prefs: []
  type: TYPE_NORMAL
- en: Using these settings, we can create different kinds of custom rollout strategies—some
    popular ones are discussed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Ramped slow rollout
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you have numerous replicas but want to roll out the release slowly, observe
    the application for any issues, and roll back your deployment if needed, you should
    use this strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create an `nginx` deployment, `nginx-ramped-slow-rollout.yaml`, using
    the **ramped slow** **rollout** strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The manifest is very similar to the generic Deployment, except that it contains
    `10` replicas and a `strategy` section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `strategy` section contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`type`: `RollingUpdate`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rollingUpdate`: The section describing rolling update attributes –`maxSurge`
    and `maxUnavailable`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let’s apply the YAML file and wait for the deployment to completely roll
    out to `10` replicas using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'As we see, the pods have rolled out completely. Let’s now update the `Deployment`
    resource with a different `nginx` image version and see what we get using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: So, we see two `ReplicaSet` resources here—`nginx-6799fc88d8` and `nginx-6889dfccd5`.
    While the `nginx-6799fc88d8` pod is slowly rolling down from `10` pods to `0`,
    one at a time, simultaneously, the `nginx-6889dfccd5` pod is slowly rolling up
    from `0` pods to `10`. At any given time, the number of pods never exceeds `11`.
    That is because `maxSurge` is set to `1`, and `maxUnavailable` is `0`. This is
    a slow rollout in action.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Ramped slow rollout is useful when we want to be cautious before we impact many
    users, but this strategy is extremely slow and may only suit some applications.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the best-effort controlled rollout strategy for a faster rollout
    without compromising application availability.
  prefs: []
  type: TYPE_NORMAL
- en: Best-effort controlled rollout
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Best-effort controlled rollout** helps you roll out your deployment on a
    best-effort basis, and you can use it to roll out your release faster and ensure
    that your application is available. It can also help with applications that do
    not tolerate more than a certain number of replicas at a given point.'
  prefs: []
  type: TYPE_NORMAL
- en: We will set `maxSurge` to `0` and `maxUnavailable` to any percentage we find
    suitable for remaining unavailable at a given time to implement this. It can be
    specified using the number of pods or as a percentage.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Using a percentage is a better option since, with this, you don’t have to recalculate
    your `maxUnavailable` parameter if the replicas change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the manifest—`nginx-best-effort-controlled-rollout.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s now apply the YAML file and see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: So, we see the `ReplicaSet` resource rolling out such that the total pods are
    at most `10` at any point, and the total unavailable pods are never more than
    `25%`. You may also notice that instead of creating a new `ReplicaSet` resource,
    the `Deployment` resource uses an old `ReplicaSet` resource containing the `nginx:latest`
    image. Remember when I said the old `ReplicaSet` resource is not deleted when
    you update a `Deployment` resource?
  prefs: []
  type: TYPE_NORMAL
- en: '`Deployment` resources on their own are great ways of scheduling and managing
    pods. However, we have overlooked an essential part of running containers in Kubernetes—exposing
    them to the internal or external world. Kubernetes provides several resources
    to help expose your workloads appropriately—primarily, `Service` and `Ingress`
    resources. Let’s have a look at these in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Services and Ingresses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s story time! Let’s simplify Kubernetes Services.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have a group of friends who love to order food from your restaurant.
    Instead of delivering each order to their houses separately, you set up a central
    delivery point in their neighborhood. This delivery point (or hub) is your “service.”
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes, a Service is like that central hub. It’s a way for the different
    parts of your application (such as your website, database, or other things) to
    talk to each other, even if they’re in separate containers or machines. It gives
    them easy-to-remember addresses to find each other without getting lost.
  prefs: []
  type: TYPE_NORMAL
- en: The `Service` resource helps expose Kubernetes workloads to the internal or
    external world. As we know, pods are ephemeral resources—they can come and go.
    Every pod is allocated a unique IP address and hostname, but once a pod is gone,
    the pod’s IP address and hostname change. Consider a scenario where one of your
    pods wants to interact with another. However, because of its transient nature,
    you cannot configure a proper endpoint. If you use the IP address or the hostname
    as the endpoint of a pod and the pod is destroyed, you will no longer be able
    to connect to it. Therefore, exposing a pod on its own is not a great idea.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes provides the `Service` resource to provide a static IP address to
    a group of pods. Apart from exposing the pods on a single static IP address, it
    also provides load balancing of traffic between pods in a round-robin configuration.
    It helps distribute traffic equally between the pods and is the default method
    of exposing your workloads.
  prefs: []
  type: TYPE_NORMAL
- en: '`Service` resources are also allocated a static `Service` resource FQDN instead
    of the IP address within your cluster to make your endpoints fail-safe.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, coming back to `Service` resources, there are multiple `Service` resource
    types— `ClusterIP`, `NodePort`, and `LoadBalancer`, each having its own respective
    use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Kubernetes Services](img/B19877_Figure_6.04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Kubernetes Services
  prefs: []
  type: TYPE_NORMAL
- en: Let’s understand each of these with the help of examples.
  prefs: []
  type: TYPE_NORMAL
- en: ClusterIP Service resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ClusterIP` `Service` resources are the default `Service` resource type that
    exposes pods within the Kubernetes cluster. It is not possible to access `ClusterIP`
    `Service` resources outside the cluster; therefore, they are never used to expose
    your pods to the external world. `ClusterIP` `Service` resources generally expose
    backend apps such as data stores and databases—the business and data layers—in
    a three-tier architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: When choosing between `Service` resource types, as a general rule of thumb,
    always start with the `ClusterIP` `Service` resource and change it if needed.
    This will ensure that only the required Services are exposed externally.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand `ClusterIP` `Service` resources better, let’s create a `redis
    Deployment` resource first using the imperative method with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s try exposing the `redis` deployment pods using a `ClusterIP` `Service`
    resource. To access the resources for this section, `cd` into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the `Service` resource manifest, `redis-clusterip.yaml`, first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The `Service` resource manifest starts with `apiVersion` and `kind` as any other
    resource. It has a `metadata` section that contains `name` and `labels`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `spec` section contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ports`: This section includes a list of ports that we want to expose via the
    `Service` resource:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A. `port`: The port we wish to expose.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'B. `protocol`: The protocol of the port we expose (TCP/UDP).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'C. `targetPort`: The target container port where the exposed port will forward
    the connection. This allows us to have a port mapping similar to Docker.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`selector`: This section contains `labels` based on which pod group is selected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s apply the `Service` resource manifest using the following command and
    see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s run `kubectl get` to list the `Service` resource and get the cluster
    IP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: We see a `redis` `Service` resource running with a `ClusterIP` type. But as
    this pod is not exposed externally, the only way to access it is through a second
    pod running within the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a `busybox` pod in interactive mode to inspect the `Service` resource
    and run some tests using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: And with this, we see a prompt. We have launched the `busybox` container and
    are currently within that. We will use the `telnet` application to check the connectivity
    between pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s telnet the cluster IP and port to see whether it’s reachable using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The IP/port pair is reachable from there. Kubernetes also provides an internal
    DNS to promote service discovery and connect to the `Service` resource. We can
    do a reverse `nslookup` on the cluster IP to get the `Service` resource’s FQDN
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the IP address is accessible from the FQDN—`redis.default.svc.cluster.local`.
    We can use the entire domain or parts of it based on our location. The FQDN is
    formed of these parts: `<service_name>.<namespace>.svc.<cluster-domain>.local`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes uses `default` namespace till now and will continue doing so. If
    your source pod is located in the same namespace as the `Service` resource, you
    can use `service_name` to connect to your `Service` resource—something like the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to call a `Service` resource from a pod situated in a different
    namespace, you can use `<service_name>.<namespace>` instead—something like the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Some service meshes, such as Istio, allow multi-cluster communication. In that
    situation, you can also use the cluster name for connecting to the `Service` resource,
    but as this is an advanced topic, it is beyond the scope of this discussion.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Always use the shortest domain name possible for endpoints, as it allows for
    more flexibility in moving your Kubernetes resources across your environments.
  prefs: []
  type: TYPE_NORMAL
- en: '`ClusterIP` Services work very well for exposing internal pods, but what if
    we want to expose our pods to the external world? Kubernetes offers various `Service`
    resource types for that; let’s look at the `NodePort` `Service` resource type
    first.'
  prefs: []
  type: TYPE_NORMAL
- en: NodePort Service resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`NodePort` `Service` resources are used to expose your pods to the external
    world. Creating a `NodePort` `Service` resource spins up a `ClusterIP` `Service`
    resource and maps the `ClusterIP` port to a random high port number (default:
    `30000`-`32767`) on all cluster nodes. You can also specify a static `NodePort`
    number if you so desire. So, with a `NodePort` `Service` resource, you can access
    your pods using the IP address of any node within your cluster and the `NodePort`
    of the service.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Though it is possible to specify a static `NodePort` number, you should avoid
    using it. That is because you might end up in port conflicts with other `Service`
    resources and put a high dependency on config and change management. Instead,
    keep things simple and use dynamic ports.
  prefs: []
  type: TYPE_NORMAL
- en: Going by the Flask application example, let’s create a `flask-app` pod with
    the `redis` `Service` resource we created before, acting as its backend, and then
    we will expose the pod on `NodePort`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to create a pod imperatively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, as we’ve created the `flask-app` pod, let’s check its status using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The `flask-app` pod is running successfully and is ready to accept requests.
    It’s time to understand the resource manifest for the `NodePort` `Service` resource,
    `flask-nodeport.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The manifest is similar to the `ClusterIP` manifest but contains a `type` attribute
    specifying the `Service` resource type—`NodePort`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply this manifest to see what we get using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s list the `Service` resource to get the `NodePort` Service using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: And we see that the type is now `NodePort`, and the container port `5000` is
    mapped to node port `32618`.
  prefs: []
  type: TYPE_NORMAL
- en: If you are logged in to any Kubernetes node, you can access the `Service` resource
    using `localhost:32618`. But as we are using Google Cloud Shell, we need to SSH
    into a node to access the `Service` resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s list the nodes first using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'And as we can see, we have three nodes. Let’s SSH into the `gke-node-1dhh`
    node using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, as we are within the `gke-node-1dhh` node, let’s curl `localhost:32618`
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: And we get a response back! You can SSH into any node and curl the endpoint
    and should get a similar response.
  prefs: []
  type: TYPE_NORMAL
- en: 'To exit from the node and get back to the Cloud Shell prompt, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: And you are back at the Cloud Shell prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: A `NodePort` `Service` resource is an intermediate kind of resource. This means
    that while it forms an essential building block of providing external services,
    it is not used on its own most of the time. When you are running on the cloud,
    you can use `LoadBalancer` `Service` resources instead. Even for an on-premises
    setup, it makes sense not to use `NodePort` for every `Service` resource and instead
    use `Ingress` resources.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at the `LoadBalancer` `Service` resource used extensively to
    expose your Kubernetes workloads externally.
  prefs: []
  type: TYPE_NORMAL
- en: LoadBalancer Service resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`LoadBalancer` `Service` resources help expose your pods on a single load-balanced
    endpoint. These `Service` resources can only be used within cloud platforms and
    platforms that provide Kubernetes controllers with access to spin up external
    network resources. A `LoadBalancer` Service practically spins up a `NodePort`
    `Service` resource and then requests the Cloud API to spin up a load balancer
    in front of the node ports. That way, it provides a single endpoint to access
    your `Service` resource from the external world.'
  prefs: []
  type: TYPE_NORMAL
- en: Spinning up a `LoadBalancer` `Service` resource is simple—just set the type
    to `LoadBalancer`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s expose the Flask application as a load balancer using the following manifest—`flask-loadbalancer.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s apply the manifest using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s get the `Service` resource to notice the changes using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The `Service` resource type is now `LoadBalancer`. As you can see, it now contains
    an external IP along with the cluster IP.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then curl on the external IP on port `5000` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: And you get the same response as before. Your `Service` resource is now running
    externally.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: '`LoadBalancer` `Service` resources tend to be expensive as every new resource
    spins up a network load balancer within your cloud provider. If you have HTTP-based
    workloads, use `Ingress` resources instead of `LoadBalancer` to save on resource
    costs and optimize traffic as they spin up an application load balancer instead.'
  prefs: []
  type: TYPE_NORMAL
- en: While Kubernetes Services form the basic building block of exposing your container
    applications internally and externally, Kubernetes also provides `Ingress` resources
    for additional fine-grained control over traffic. Let’s have a look at this in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you have a beautiful front entrance to your restaurant where customers
    come in. They walk through this main entrance to reach different parts of your
    restaurant, such as the dining area or the bar. This entrance is like your “ingress.”
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes, an Ingress is like that front entrance. It helps manage external
    access to the Services inside your cluster. Instead of exposing each Service individually,
    you can use an Ingress to decide how people from the outside can reach different
    parts of your application.
  prefs: []
  type: TYPE_NORMAL
- en: In simple terms, a Kubernetes Service is like a central delivery point for your
    application’s different parts, and an Ingress is like a front entrance that helps
    people from the outside find and access those parts easily.
  prefs: []
  type: TYPE_NORMAL
- en: '`Ingress` resources act as reverse proxies into Kubernetes. You don’t need
    a load balancer for every application you run within your estate, as load balancers
    normally forward traffic and don’t require high levels of computing power. Therefore,
    spinning up a load balancer for everything does not make sense.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, Kubernetes provides a way of routing external traffic into your
    cluster via `Ingress` resources. These resources help you subdivide traffic according
    to multiple conditions. Some of these are set out here:'
  prefs: []
  type: TYPE_NORMAL
- en: Based on the URL path
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the hostname
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A combination of the two
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram illustrates how `Ingress` resources work:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Kubernetes Ingress resources](img/B19877_Figure_6.05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Kubernetes Ingress resources
  prefs: []
  type: TYPE_NORMAL
- en: '`Ingress` resources require an ingress controller to work. While most cloud
    providers have a controller installed, you must install an ingress controller
    on-premises or in a self-managed Kubernetes cluster. For more details on installing
    an ingress controller, refer to [https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/).
    You can install more than one ingress controller, but you will have to annotate
    your manifests to denote explicitly which controller the `Ingress` resource should
    use.'
  prefs: []
  type: TYPE_NORMAL
- en: For this chapter, we will use the `Ingress` resources before and do an exact
    like-for-like migration.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how the nginx ingress controller works on GKE (or any other cloud),
    let’s look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – nginx ingress controller on GKE](img/B19877_Figure_6.06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – nginx ingress controller on GKE
  prefs: []
  type: TYPE_NORMAL
- en: The client connects to the `Ingress` resource via an ingress-managed load balancer,
    and the traffic moves to the ingress controllers that act as the load balancer’s
    backend. The ingress controllers then route the traffic to the correct `Service`
    resource via routing rules defined on the `Ingress` resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s go ahead and install the `nginx` ingress controller using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This will boot up several resources under the `ingress-nginx` namespace. Most
    notable is the `ingress-nginx-controller` `Deployment`, which is exposed via the
    `ingress-nginx-controller` `LoadBalancer` `Service`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now expose the `flask-app` `Service` via an `Ingress` resource, but before
    we do that, we will have to expose the `flask-app` `Service` on a `ClusterIP`
    instead, so let’s apply the relevant manifest using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to define an `Ingress` resource. Remember that as GKE is running
    on a public cloud, it has the ingress controllers installed and running. So, we
    can simply go and create an ingress manifest—`flask-basic-ingress.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: This resource defines a default backend that passes all traffic to the `flask-app`
    pod, so it is counter-productive, but let’s look at it for simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the manifest using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s list the `Ingress` resources using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the `flask-app` `Ingress` resource is now listed with `HOSTS
    *`. That means that this would listen on all hosts on all addresses. So, anything
    that does not match other Ingress rules will be routed here. As mentioned, we
    need the `nginx-ingress-controller` Service external IP address to invoke all
    Services exposed via Ingress. To get the external IP of the `nginx-ingress-controller`
    Service, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: We see an external IP allocated to it, which we will use further.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Remember that Ingress rules take a while to propagate across the cluster, so
    if you receive an error initially when you curl the endpoint, wait for 5 minutes,
    and you should get the response back.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s curl this IP and see what we get using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s clean up the `Ingress` resource using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The simple Ingress rule is counterproductive as it routes all traffic to a single
    `Service` resource. The idea of Ingress is to use a single load balancer to route
    traffic to multiple targets. Let’s look at two ways to do this—**path-based**
    and **name-based** routing.
  prefs: []
  type: TYPE_NORMAL
- en: Path-based routing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s consider an application with two versions, `v1` and `v2`, and you want
    both to co-exist on a single endpoint. You can use **path-based routing** for
    such a scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create the two application versions first using the imperative method
    by running the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, expose the two pods as `ClusterIP` `Service` resources using the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then create an `Ingress` resource using the following manifest file,
    `nginx-app-path-ingress.yaml`, which will expose two endpoints—`<external-ip>/v1`,
    which routes to the `v1` `Service` resource, and `<external-ip>/v2`, which routes
    to the `v2` `Service` resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: The Ingress manifest contains several rules. The `http` rule has two paths—`/v1`
    and `/v2`, having the `pathType` value set to `Prefix`. Therefore, any traffic
    arriving on a URL that starts with `/v1` is routed to the `nginx-v1` `Service`
    resource on port `80`, and traffic arriving on `/v2` is routed to the `nginx-v2`
    `Service` resource on port `80`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply the manifest by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s list the `Ingress` resources by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the external IP, we can `curl` both endpoints to see what
    we get using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Sometimes, a path-based route is not always feasible, as you might not want
    your users to remember the path of multiple applications. However, you can still
    run multiple applications using a single Ingress endpoint—that is, by using **name-based
    routing**.
  prefs: []
  type: TYPE_NORMAL
- en: Name-based routing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`host` header we pass while making an HTTP request. The `Ingress` resource
    can route based on the header. For example, if we want to access the `v1` `Service`
    resource, we can use `v1.example.com`, and for the `v2` `Service` resource, we
    can use the `v2.example.com` URL.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now have a look at the `nginx-app-host-ingress.yaml` manifest to understand
    this concept further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The manifest now contains multiple hosts—`v1.example.com` routing to `nginx-v1`,
    and `v2.example.com` routing to `nginx-v2`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s apply this manifest and get the Ingress using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: This time, we can see that two hosts are defined, `v1.example.com` and `v2.example.com`,
    running on the same address. Before we hit those endpoints, we need to make an
    entry on the `/etc/hosts` file to allow our machine to resolve `v1.example.com`
    and `v2.example.com` to the Ingress address.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the `/etc/hosts` file and add the following entry at the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s `curl` both endpoints and see what we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: And, as we can see, the name-based routing is working correctly! You can create
    a more dynamic setup by combining multiple hosts and path-based routing.
  prefs: []
  type: TYPE_NORMAL
- en: '`Service`, `Ingress`, `Pod`, `Deployment`, and `ReplicaSet` resources help
    us to maintain a set number of replicas within Kubernetes and help to serve them
    under a single endpoint. As you may have noticed, they are linked together using
    a combination of `labels` and `matchLabels` attributes. The following diagram
    will help you visualize this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Linking Deployment, Service, and Ingress](img/B19877_Figure_6.07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Linking Deployment, Service, and Ingress
  prefs: []
  type: TYPE_NORMAL
- en: Till now, we have been scaling our pods manually, but a better way would be
    to autoscale the replicas based on resource utilization and traffic. Kubernetes
    provides a resource called `HorizontalPodAutoscaler` to handle that requirement.
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal Pod autoscaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine you’re the manager of a snack bar at a park. On a sunny day, lots of
    people come to enjoy the park, and they all want snacks. Now, you have a few workers
    at your snack bar who make and serve the snacks.
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal Pod autoscaling in Kubernetes is like having magical helpers who
    adjust the number of snack makers (pods) based on how many people want snacks
    (traffic).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Average days**: You might only need one or two snack makers on regular days
    with fewer people. In Kubernetes terms, you have a few pods running your application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Busy days**: But when it’s a sunny weekend, and everyone rushes to the park,
    more people want snacks. Your magical helpers (Horizontal Pod autoscaling) notice
    the increase in demand. They say, “*We need more snack makers!*” So, more snack
    makers (pods) are added automatically to handle the rush.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scaling down**: Once the sun sets and the crowd leaves, you don’t need as
    many snack makers anymore. Your magical helpers see the decrease in demand and
    say, “*We can have fewer snack makers now.*” So, extra snack makers (pods) are
    removed, saving resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automatic adjustment**: These magical helpers monitor the crowd and adjust
    the number of snack makers (pods) in real time. When the demand goes up, they
    deploy more. When it goes down, they remove some.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the same way, Kubernetes Horizontal pod autoscaling watches how busy your
    application is. If there’s more traffic (more people wanting your app), it automatically
    adds more pods. If things quieten down, it scales down the number of pods. This
    helps your app handle varied traffic without you manually doing everything.
  prefs: []
  type: TYPE_NORMAL
- en: So, Horizontal pod autoscaling is like having magical assistants that ensure
    your application has the correct number of workers (pods) to handle the crowd
    (traffic) efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: '`HorizontalPodAutoscaler` is a Kubernetes resource that helps you to update
    replicas within your `ReplicaSet` resources based on defined factors, the most
    common being CPU and memory.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this better, let’s create an `nginx` Deployment, and this time,
    we will set the resource limits within the pod. Resource limits are a vital element
    that enables `HorizontalPodAutoscaler` resources to function. It relies on the
    percentage utilization of the limits to decide when to spin up a new replica.
    We will use the following `nginx-autoscale-deployment.yaml` manifest under `~/modern-devops/ch6/deployments`
    for this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following command to perform a new deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s expose this deployment with a `LoadBalancer` `Service` resource and get
    the external IP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s autoscale this deployment. The `Deployment` resource needs at least
    1 pod replica and can have a maximum of 5 pod replicas while maintaining an average
    CPU utilization of `25%`. Use the following command to create a `HorizontalPodAutoscaler`
    resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the `HorizontalPodAutoscaler` resource created, we can load
    test the application using the `hey` load testing utility preinstalled in Google
    Cloud Shell. But before you fire the load test, open a duplicate shell session
    and watch the `Deployment` resource using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Open another duplicate shell session and watch the `HorizontalPodAutoscaler`
    resource using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, in the original window, run the following command to fire a load test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'It will start a load test for 2 minutes, with 10 concurrent users continuously
    hammering the `Service`. You will see the following output if you open the window
    where you’re watching the `HorizontalPodAutoscaler` resource. As soon as we start
    firing the load test, the average utilization reaches `46%`. The `HorizontalPodAutoscaler`
    resource waits for some time, then it increases the replicas, first to `2`, then
    to `4`, and finally to `5`. When the test is complete, the utilization drops quickly
    to `27%`, `25%`, and finally, `0%`. When the utilization goes to `0%`, the `HorizontalPodAutoscaler`
    resource spins down the replicas from `5` to `1` gradually:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Likewise, we will see the replicas of the `Deployment` changing when the `HorizontalPodAutoscaler`
    resource actions the changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Besides CPU and memory, you can use other parameters to scale your workloads,
    such as network traffic. You can also use external metrics such as latency and
    other factors that you can use to decide when to scale your traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: While you should use the `HorizontalPodAutoscaler` resource with CPU and memory,
    you should also consider scaling on external metrics such as response time and
    network latency. That will ensure better reliability as they directly impact customer
    experience and are crucial to your business.
  prefs: []
  type: TYPE_NORMAL
- en: Till now, we have been dealing with stateless workloads. However, pragmatically
    speaking, some applications need to save the state. Let’s look at some considerations
    for managing stateful applications.
  prefs: []
  type: TYPE_NORMAL
- en: Managing stateful applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine you’re a librarian in a magical library. You have a bunch of enchanted
    books that store valuable knowledge. Each book has a unique story and is kept
    in a specific spot on the shelf. These books are like your “stateful applications,”
    and managing them requires extra care.
  prefs: []
  type: TYPE_NORMAL
- en: Managing stateful applications in the world of technology is like taking care
    of these magical books in your library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stateful books**: Some books in your library are “stateful.” This means they
    hold vital information that changes over time, such as bookmarks or notes from
    readers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fixed locations**: Just as each book has a specific place on the shelf, stateful
    applications must also be in particular locations. They might need to be on certain
    machines or use specific storage to keep their data safe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maintaining inventory**: You must remember where each book is placed. Similarly,
    managing stateful applications means remembering their exact locations and configurations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Careful handling**: When someone borrows a stateful book, you must ensure
    they return it in good condition. With stateful applications, you must handle
    updates and changes carefully to avoid losing important data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backup spells**: Sometimes, you cast a spell to create a copy of a book,
    just in case something happens to the original. With stateful applications, you
    back up your data to restore it if anything goes wrong.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Moving with caution**: If you need to rearrange the library, you move books
    one at a time so that nothing gets lost. Similarly, with stateful applications,
    if you need to move them between machines or storage, it’s done cautiously to
    avoid data loss.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the world of technology, managing stateful applications means taking extra
    care of applications that hold important data. You ensure they’re placed in the
    right spots, handle updates carefully, and create backups to keep valuable information
    safe, just like how you protect your enchanted books in the magical library!
  prefs: []
  type: TYPE_NORMAL
- en: '`Deployment` resources are beneficial for stateless workloads, as they do not
    need to add any state considerations while updating `ReplicaSet` resources, but
    they cannot work effectively with stateful workloads. To manage such workloads,
    you can use a `StatefulSet` resource.'
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSet resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`StatefulSet` resources help manage stateful applications. They are similar
    to `Deployment` resources, but unlike a `Deployment` resource, they also keep
    track of state and require `Volume` and `Service` resources to operate. `StatefulSet`
    resources maintain a sticky identity for each pod. This means that the volume
    mounted on one pod cannot be used by the other. In a `StatefulSet` resource, Kubernetes
    orders pods by numbering them instead of generating a random hash. Pods within
    a `StatefulSet` resource are also rolled out and scaled-in in order. If a particular
    pod goes down and is recreated, the same volume is mounted to the pod.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates a `StatefulSet` resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – StatefulSet resource](img/B19877_Figure_6.08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – StatefulSet resource
  prefs: []
  type: TYPE_NORMAL
- en: A `StatefulSet` resource has a stable and unique network identifier, therefore,
    it requires a headless `Service` resource. Headless Services are `Service` resources
    that do not have a cluster IP. Instead, the Kubernetes DNS resolves the `Service`
    resource’s FQDN directly to the pods.
  prefs: []
  type: TYPE_NORMAL
- en: As a `StatefulSet` resource is supposed to persist data, it requires Persistent
    Volumes to operate. Therefore, let’s look at how to manage volumes using Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Managing Persistent Volumes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Persistent Volumes** are Kubernetes resources that deal with storage. They
    can help you manage and mount **hard disks**, **SSDs**, **filestores**, and other
    block and network storage entities. You can provision Persistent Volumes manually
    or use dynamic provisioning within Kubernetes. When you use dynamic provisioning,
    Kubernetes will request the cloud provider via the cloud controller manager to
    provide the required storage. Let’s look at both methods to understand how they
    work.'
  prefs: []
  type: TYPE_NORMAL
- en: Static provisioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`PersistentVolume` resource using the disk information. The developer can then
    use the `PersistentVolume` resource within their `StatefulSet` resource, as in
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Static provisioning](img/B19877_Figure_6.09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Static provisioning
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now look at a static provisioning example.
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the resources for this section, `cd` into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: So, we first need to create a disk within the cloud platform. Since we’re using
    Google Cloud, let’s proceed and use the `gcloud` commands to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to create a persistent zonal disk. Ensure that you
    use the same zone as your Kubernetes cluster. As we are using the `us-central1-a`
    zone for the Kubernetes cluster, we will use the same in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: As the disk is now ready, we can then create a `PersistentVolume` resource from
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The manifest file, `nginx-manual-pv.yaml`, looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'The `spec` section contains `capacity`, `accessModes`, and the kind of disk
    it needs to provision. You can specify one or more access modes to a PersistentVolumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ReadWriteOnce`: Only one pod can read and write to the disk at a time; therefore,
    you cannot mount such a volume to multiple pods'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ReadOnlyMany`: Multiple pods can read from the same volume simultaneously,
    but no pod can write to the disk'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ReadWriteMany`: Multiple pods can read and write to the same volume at once'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Not all kinds of storage support all access modes. You need to decide the volume
    type during the initial requirement analysis and architectural assessment phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'OK—let’s now go and apply the manifest to provision the `PersistentVolume`
    resource using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s now check whether the Persistent Volume is available by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'As the Persistent Volume is now available, we must create a headless `Service`
    resource to help maintain network identity in the `StatefulSet` resource. The
    following `nginx-manual-service.yaml` manifest describes it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: It is very similar to the regular `Service` resource, except that we have specified
    `clusterIP` as `None`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s go and apply the manifest using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'As the `Service` resource is created, we can create a `StatefulSet` resource
    that uses the created `PersistentVolume` and `Service` resources. The `StatefulSet`
    resource manifest, `nginx-manual-statefulset.yaml`, looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: The manifest contains various sections. While most are similar to the `Deployment`
    resource manifest, this requires a `volume` definition and a separate `volumeClaimTemplates`
    section. The `volumeClaimTemplates` section consists of the `accessModes`, `resources`,
    and `selector` sections. The `selector` section defines the `matchLabels` attribute,
    which helps to select a particular `PersistentVolume` resource. In this case,
    it selects the `PersistentVolume` resource we defined previously. It also contains
    the `serviceName` attribute that defines the headless `Service` resource it will
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s go ahead and apply the manifest using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s inspect a few elements to see where we are. The `StatefulSet` resource
    creates a `PersistentVolumeClaim` resource to claim the `PersistentVolume` resource
    we created before.
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the `PersistentVolumeClaim` resource using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the `StatefulSet` resource has created a `PersistentVolumeClaim`
    resource called `html-nginx-manual-0` that is bound to the `nginx-manual-pv` `PersistentVolume`
    resource. Therefore, manual provisioning has worked correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we query the `PersistentVolume` resource using the following command, we
    will see that the status is now showing as `Bound`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s have a look at the pods using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: As we see, the `StatefulSet` resource has created a pod and appended it with
    a serial number instead of a random hash. It wants to maintain ordering between
    the pods and mount the same volumes to the pods they previously mounted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s open a shell into the pod and create a file within the `/usr/share/nginx/html`
    directory using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Great! So, let’s go ahead and delete the pod and see whether we can get the
    file in the same location again using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: And, as we can see, the file still exists, even after we deleted the pod.
  prefs: []
  type: TYPE_NORMAL
- en: Static provisioning isn’t one of the best ways of doing things, as you must
    manually keep track and provision volumes. That involves a lot of manual activities
    and may be error-prone. Some organizations that want to keep a line between Dev
    and Ops can use this technique. Kubernetes allows this provision. However, for
    more DevOps-friendly organizations, **dynamic provisioning** is a better way of
    doing it.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic provisioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dynamic provisioning is when Kubernetes provides storage resources for you by
    interacting with the cloud provider. When we provisioned the disk manually, we
    interacted with the cloud APIs using the `gcloud` command line. What if your organization
    decides to move to some other cloud provider later? That would break many existing
    scripts, and you would have to rewrite the storage provisioning steps. Kubernetes
    is inherently portable and platform-independent. You can provision resources in
    the same way on any cloud platform.
  prefs: []
  type: TYPE_NORMAL
- en: But then, different cloud providers have different storage offerings. How would
    Kubernetes know what kind of storage it needs to provision? Well, Kubernetes uses
    `StorageClass` resources for that. `StorageClass` resources are Kubernetes resources
    that define the type of storage they need to provide when someone uses it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates dynamic provisioning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Dynamic provisioning](img/B19877_Figure_6.010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Dynamic provisioning
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example storage class manifest, `fast-storage-class.yaml`, that
    provisions an SSD within GCP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: The `StorageClass` resource contains a provisioner and any parameters the provisioner
    requires. You may have noticed that I have kept the name `fast` instead of `gce-ssd`
    or similar. That is because we want to keep the names as generic as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Keep generic storage class names such as `fast`, `standard`, `block`, and `shared`,
    and avoid names specific to the cloud platform. Because storage class names are
    used in Persistent Volume claims, if you migrate to another cloud provider, you
    may end up changing a lot of manifests just to avoid confusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go ahead and apply the manifest using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: As the `StorageClass` resource is created, let’s use it to provision an `nginx`
    `StatefulSet` resource dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to create a `Service` resource manifest, `nginx-dynamic-service.yaml`,
    first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'The manifest is very similar to the manual `Service` resource. Let’s go ahead
    and apply it using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s look at the `StatefulSet` resource manifest, `nginx-dynamic-statefulset.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The manifest is similar to the manual one, but this one contains the `storageClassName`
    attribute in the `volumeClaimTemplates` section and lacks the `selector` section,
    as we are dynamically provisioning the storage. Use the following command to apply
    the manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'As the `StatefulSet` resource is created, let’s go ahead and check the `PersistentVolumeClaim`
    and `PersistentVolume` resources using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: And we can see that the claim is bound to a Persistent Volume that is dynamically
    provisioned. Now, let’s proceed and run the following command to do similar tests
    with this `StatefulSet` resource.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a file in the `nginx-dynamic-0` pod using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, delete the pod and open a shell session again to check whether the file
    exists by using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: And as we can see, the file exists in the volume, even if the pod was deleted.
    That is dynamic provisioning in action for you!
  prefs: []
  type: TYPE_NORMAL
- en: You will have observed that we have used the `kubectl` command multiple times
    throughout this chapter. When you perform activities throughout the day, using
    shortcuts and best practices wherever you can makes sense. Let’s look at some
    best practices while using `kubectl`.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes command-line best practices, tips, and tricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For seasoned Kubernetes developers and administrators, `kubectl` is a command
    they run most of the time. The following steps will simplify your life, save you
    a ton of time, let you focus on more essential activities, and set you apart from
    the rest.
  prefs: []
  type: TYPE_NORMAL
- en: Using aliases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most system administrators use aliases for an excellent reason—they save valuable
    time. Aliases in Linux are different names for commands, and they are mostly used
    to shorten the most frequently used commands; for example, `ls -l` becomes `ll`.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the following aliases with `kubectl` to make your life easier.
  prefs: []
  type: TYPE_NORMAL
- en: k for kubectl
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Yes—that’s right. By using the following alias, you can use `k` instead of
    typing `kubectl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: That will save a lot of time and hassle.
  prefs: []
  type: TYPE_NORMAL
- en: Using kubectl --dry-run
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`kubectl --dry-run` helps you to generate YAML manifests from imperative commands
    and saves you a lot of typing time. You can write an imperative command to generate
    a resource and append that with a `--dry-run=client -o yaml` string to generate
    a YAML manifest from the imperative command. The command does not create the resource
    within the cluster, but instead just outputs the manifest. The following command
    will generate a `Pod` manifest using `--dry-run`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: And you now have the skeleton YAML file that you can edit according to your
    liking.
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine typing this command multiple times during the day! At some point,
    it becomes tiring. Why not shorten it by using the following alias?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: You can then use the alias to generate other manifests.
  prefs: []
  type: TYPE_NORMAL
- en: 'To generate a `Deployment` resource manifest, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: You can use the dry run to generate almost all resources from imperative commands.
    However, some resources do not have an imperative command, such as a `DaemonSet`
    resource. You can generate a manifest for the closest resource and modify it for
    such resources. A `DaemonSet` manifest is very similar to a `Deployment` manifest,
    so you can generate a `Deployment` manifest and change it to match the `DameonSet`
    manifest.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at some of the most frequently used `kubectl` commands and their
    possible aliases.
  prefs: []
  type: TYPE_NORMAL
- en: kubectl apply and delete aliases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you use manifests, you will use the `kubectl apply` and `kubectl delete`
    commands most of the time within your cluster, so it makes sense to use the following
    aliases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'You can then use them to apply or delete resources using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: While troubleshooting containers, most of us use `busybox`. Let’s see how to
    optimize it.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting containers with busybox using an alias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We use the following commands to open a `busybox` session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: Now, opening several `busybox` sessions during the day can be tiring. How about
    minimizing the overhead by using the following alias?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then open a shell session to a new `busybox` pod using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, that is much cleaner and easier. Likewise, you can also create aliases
    of other commands that you use frequently. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: And so on, according to your needs. You may also be used to autocompletion within
    `bash`, where your commands autocomplete when you press *Tab* after typing a few
    words. `kubectl` also provides autocompletion of commands, but not by default.
    Let’s now look at how to enable `kubectl` autocompletion within `bash`.
  prefs: []
  type: TYPE_NORMAL
- en: Using kubectl bash autocompletion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To enable `kubectl` `bash` autocompletion, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: The command adds the `kubectl` completion `bash` command as a source to your
    `.bashrc` file. So, the next time you log in to your shell, you should be able
    to use `kubectl` autocomplete. That will save you a ton of time when typing commands.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We began this chapter by managing pods with `Deployment` and `ReplicaSet` resources
    and discussed some critical Kubernetes deployment strategies. We then looked into
    Kubernetes service discovery and models and understood why we required a separate
    entity to expose containers to the internal or external world. We then looked
    at different `Service` resources and where to use them. We talked about `Ingress`
    resources and how to use them to create reverse proxies for our container workloads.
    We then delved into Horizontal Pod autoscaling and used multiple metrics to scale
    our pods automatically.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at state considerations and learned about static and dynamic storage
    provisioning using `PersistentVolume`, `PersistentVolumeClaim`, and `StorageClass`
    resources, and talked about some best practices surrounding them. We looked at
    `StatefulSet` resources as essential resources that help you schedule and manage
    stateful containers. Finally, we looked at some best practices, tips, and tricks
    surrounding the `kubectl` command line and how to use them effectively.
  prefs: []
  type: TYPE_NORMAL
- en: The topics covered in this and the previous chapter are just the core of Kubernetes.
    Kubernetes is a vast tool with enough functionality to write an entire book, so
    these chapters only give you the gist of what it is all about. Please feel free
    to read about the resources in detail in the Kubernetes official documentation
    at [https://kubernetes.io](https://kubernetes.io).
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will delve into the world of the cloud and look at **Container-as-a-Service**
    (**CaaS**) and serverless offerings for containers.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Kubernetes Deployment deletes an old `ReplicaSet` resource when the image
    is updated. (True/False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the primary deployment strategies supported by Kubernetes? (Choose
    two)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Recreate
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Rolling update
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Ramped slow rollout
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Best-effort controlled rollout
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which types of resources can you use to expose containers externally? (Choose
    three)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. `ClusterIP Service`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. `NodePort Service`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. `LoadBalancer Service`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. `Ingress`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It is a best practice to start with a `ClusterIP` Service and change the Service
    type later if needed. (True/False)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Deployment` resources are suitable for stateful workloads. (True/False)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which kinds of workloads can you run with Ingresses?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. HTTP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. TCP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. FTP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. SMTP
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Which resources would you define for dynamic volume provisioning? (Choose two)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. `StorageClass`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. `PersistentVolumeClaim`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. `PersistentVolume`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. `StatefulSet`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To make your horizontal scaling more meaningful, what parameters should you
    use to scale your pods? (Choose three)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. CPU
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Memory
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. External metrics, such as response time
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Packets per second (PPS)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What are the forms of routing within an `Ingress` resource? (Choose two)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A. Simple
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B. Path-based
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C. Name-based
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D. Complex
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: False. An image Deployment just scales the old `ReplicaSet` resource to `0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A and B
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: B, C, and D
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False. Use `StatefulSet` resources instead.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A and B
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A, B, and C
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: B and C
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
