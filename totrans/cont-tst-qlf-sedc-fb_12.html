<html><head></head><body>
		<div id="_idContainer122">
			<h1 id="_idParaDest-203" class="chapter-number"><a id="_idTextAnchor222"/><st c="0">12</st></h1>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor223"/><st c="3">Measuring Progress and Outcomes</st></h1>
			<p><st c="35">This chapter focuses on methods and frameworks that are important for measuring progress and outcomes as organizations implement and improve their continuous testing, quality, security, and feedback capabilities. </st><st c="249">As businesses and projects become more complex, it’s crucial to be able to measure how well things are going and to predict future results. </st><st c="389">This chapter explains how to create, choose, and use measurements that accurately show progress and offer useful insights for management and </st><span class="No-Break"><st c="530">continuous improvement.</st></span></p>
			<p><st c="553">The first section provides an overview of the different kinds of measurements for continuous testing, quality, security, and feedback. </st><st c="689">Then, we will discuss how to select the right measurements for both outcomes and progress. </st><st c="780">Then, we will move on to implementing these metrics and look at how to set up metrics and dashboards that do more than just inform – they </st><span class="No-Break"><st c="918">motivate action.</st></span></p>
			<p><st c="934">We will wrap up the chapter by discussing how to keep these measurements useful over time, offering strategies to update and maintain them so that they keep supporting your organization as it grows and changes. </st><st c="1146">This chapter will equip you with the skills to not only select effective measures but also to apply and maintain them, in ways that continuously add value to </st><span class="No-Break"><st c="1304">your work.</st></span></p>
			<p><st c="1314">In this chapter, we’ll cover the following </st><span class="No-Break"><st c="1358">main topics:</st></span></p>
			<ul>
				<li><st c="1370">Measures of progress </st><span class="No-Break"><st c="1392">and outcomes</st></span></li>
				<li><span class="No-Break"><st c="1404">Selecting measures</st></span></li>
				<li><st c="1423">Practices to design metrics </st><span class="No-Break"><st c="1452">and dashboards</st></span></li>
				<li><st c="1466">Sustaining measures of progress </st><span class="No-Break"><st c="1499">and outcomes</st></span></li>
			</ul>
			<p><st c="1511">Let’s </st><span class="No-Break"><st c="1518">get started!</st></span></p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor224"/><st c="1530">Measures of progress and outcomes</st></h1>
			<p><st c="1564">In this section, we </st><a id="_idIndexMarker1007"/><st c="1585">will understand what makes a measurement effective and how to align it with your organization’s goals. </st><st c="1688">By exploring different measurements, you’ll get a solid base for later discussions on how to choose and use </st><span class="No-Break"><st c="1796">these metrics.</st></span></p>
			<p><st c="1810">Organizations that undergo transformation processes for continuous testing, quality, security, and feedback need to keep track of two key types of measures – </st><em class="italic"><st c="1969">progress</st></em><st c="1977"> and </st><em class="italic"><st c="1982">outcomes</st></em><st c="1990">. These measures are crucial for understanding how well an organization is adapting and improving its processes, and for ensuring that these changes contribute positively to its </st><span class="No-Break"><st c="2168">overall goals.</st></span></p>
			<p><span class="No-Break"><em class="italic"><st c="2182">Figure 12</st></em></span><em class="italic"><st c="2192">.1</st></em><st c="2194"> illustrates the two types of metrics, in </st><span class="No-Break"><st c="2236">chart form.</st></span></p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B21936_12_1.jpg" alt="Figure 12.1 – Progress and outcome metric charts"/><st c="2247"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="2502">Figure 12.1 – Progress and outcome metric charts</st></p>
			<p><st c="2550">Progress metrics are typically represented in the form of burn-down charts, in which a declining trend is desirable because they indicate how many project units are remaining. </st><st c="2727">Outcome metrics are typically represented as a trend line, in which an increasing trend is desirable as </st><span class="No-Break"><st c="2831">performance increases.</st></span></p>
			<p><st c="2853">The next section will explain the importance of measures of progress </st><span class="No-Break"><st c="2923">and outcomes.</st></span></p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor225"/><st c="2936">Why measures of progress and outcomes are important</st></h2>
			<p><st c="2988">There</st><a id="_idIndexMarker1008"/><st c="2994"> are several reasons why measures of progress and outcomes are important, including strategic alignment and decision making, performance monitoring, demonstrating value, and to help create a </st><span class="No-Break"><st c="3185">learning organization.</st></span></p>
			<ul>
				<li><strong class="bold"><st c="3207">Strategic alignment and decision making</st></strong><st c="3247">: Knowing how far along transformation projects and initiatives are helps companies make better decisions about where to focus their resources. </st><st c="3392">It ensures that every effort contributes toward the broader goals of </st><span class="No-Break"><st c="3461">an organization.</st></span></li>
				<li><strong class="bold"><st c="3477">Performance monitoring</st></strong><st c="3500">: Organizations need to check regularly whether they are on the right path to meeting their goals. </st><st c="3600">Measures of progress help by showing </st><a id="_idIndexMarker1009"/><st c="3637">how much has been done and how much is left to do. </st><st c="3688">This is especially important in environments where updates and improvements are constant, such as in software development </st><span class="No-Break"><st c="3810">or cybersecurity.</st></span></li>
				<li><strong class="bold"><st c="3827">Demonstrating value</st></strong><st c="3847">: Outcome measures inform a company whether any changes made have had the desired effect. </st><st c="3938">This is important not just for internal records but also to show external stakeholders, such as customers or investors, that the company is improving and worth </st><span class="No-Break"><st c="4098">investing in.</st></span></li>
				<li><strong class="bold"><st c="4111">Organizational learning</st></strong><st c="4135">: Both types of measures provide valuable feedback. </st><st c="4188">This feedback helps companies learn from their successes and mistakes, leading to better planning and more effective management </st><span class="No-Break"><st c="4316">of risks.</st></span></li>
			</ul>
			<p><st c="4325">Next, we will explain how to link measures of performance and progress to the capability maturity of </st><span class="No-Break"><st c="4427">an organization.</st></span></p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor226"/><st c="4443">Linking measures to capability maturity</st></h2>
			<p><st c="4483">The </st><a id="_idIndexMarker1010"/><st c="4488">concept of capability maturity in an organization, as explained in </st><a href="B21936_04.xhtml#_idTextAnchor053"><span class="No-Break"><em class="italic"><st c="4555">Chapter 4</st></em></span></a><st c="4564">, relates to its ability to consistently deliver expected results. </st><st c="4631">Progress and outcome measures are integral to this because they help an organization understand its current level of maturity, as described in </st><a href="B21936_04.xhtml#_idTextAnchor053"><span class="No-Break"><em class="italic"><st c="4774">Chapter 4</st></em></span></a><st c="4783">, and identify areas for improvement. </st><st c="4821">For instance, as an organization matures, it should see more predictable and positive outcomes from its processes, which should be evident in the measures it tracks. </st><st c="4987">Tracking these measures over time can show how the organization’s capability maturity evolves. </st><span class="No-Break"><em class="italic"><st c="5082">Figure 12</st></em></span><em class="italic"><st c="5091">.2</st></em><st c="5093"> illustrates important factors and stakeholders for progress and </st><span class="No-Break"><st c="5158">outcome measures.</st></span></p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B21936_12_2.jpg" alt="Figure 12.2 – The importance of measures to stakeholders"/><st c="5175"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="5312">Figure 12.2 – The importance of measures to stakeholders</st></p>
			<p><st c="5368">The following </st><a id="_idIndexMarker1011"/><st c="5383">explains why these measures are important for </st><span class="No-Break"><st c="5429">various stakeholders:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="5450">Business managers</st></strong><st c="5468">: These managers look at outcome measures to see whether the changes positively affect a business’s bottom line. </st><st c="5582">They use progress measures to ensure that strategic projects are </st><span class="No-Break"><st c="5647">on schedule.</st></span></li>
				<li><strong class="bold"><st c="5659">Technical managers and developers</st></strong><st c="5693">: They rely on progress measures to plan and adjust their workloads and timelines. </st><st c="5777">Outcome measures help them see whether their technical solutions are effective in solving the problems they are meant </st><span class="No-Break"><st c="5895">to address.</st></span></li>
				<li><strong class="bold"><st c="5906">Quality assurance (QA) engineers</st></strong><st c="5939">: QA teams use these measures to track and improve the testing processes. </st><st c="6014">They need to know that the quality of the product meets the set standards, which is directly tied to </st><span class="No-Break"><st c="6115">outcome measures.</st></span></li>
				<li><strong class="bold"><st c="6132">Security operations staff</st></strong><st c="6158">: For these teams, outcome measures might include metrics such as a reduced number of security incidents. </st><st c="6265">Progress measures help them gauge the implementation of security protocols </st><span class="No-Break"><st c="6340">and training.</st></span></li>
				<li><strong class="bold"><st c="6353">DevOps and SRE engineers</st></strong><st c="6378">: These engineers use both types of measures to optimize the deployment and operation of software. </st><st c="6478">Progress measures help them monitor the continuous delivery pipeline, while outcome measures evaluate the stability and performance of the software </st><span class="No-Break"><st c="6626">in production.</st></span></li>
			</ul>
			<p><st c="6640">In summary, measures </st><a id="_idIndexMarker1012"/><st c="6662">of progress and outcomes provide a structured way to track how well an organization implements changes and achieves results. </st><st c="6787">They offer critical insights that help various stakeholders, from business managers to technical teams, make informed decisions that drive the organization forward. </st><st c="6952">Understanding and utilizing these measures effectively can lead to better strategic alignment, improved performance, and a mature capability to deliver </st><span class="No-Break"><st c="7104">consistent results.</st></span></p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor227"/><st c="7123">Examples of outcome metrics</st></h2>
			<p><st c="7151">Outcome metrics </st><a id="_idIndexMarker1013"/><st c="7168">are essential tools in software development, delivery, and operations. </st><st c="7239">They help teams track how well</st><a id="_idIndexMarker1014"/><st c="7269"> they are doing at various stages of building and maintaining software. </st><st c="7341">These metrics focus on areas such as testing, quality, security, and feedback to ensure that every phase, from planning to operations, meets set standards and improves </st><span class="No-Break"><st c="7509">over time.</st></span></p>
			<h3><st c="7519">Common outcome metrics across all stages</st></h3>
			<p><st c="7560">The </st><strong class="bold"><st c="7565">DevOps Research and Assessment</st></strong><st c="7595"> group</st><a id="_idIndexMarker1015"/><st c="7601"> created a set of metrics known as DORA which </st><a id="_idIndexMarker1016"/><st c="7647">are a set of four key performance indicators that have become industry standards for measuring the effectiveness of software development and </st><span class="No-Break"><st c="7788">operations teams.</st></span></p>
			<p><st c="7805">These metrics, recommended by DORA, are broadly applicable and provide insights into the overall health and efficiency of the </st><span class="No-Break"><st c="7932">development process:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="7952">Deployment frequency (DORA)</st></strong><st c="7980">: Counts how often software is deployed </st><span class="No-Break"><st c="8021">to production.</st></span></li>
				<li><strong class="bold"><st c="8035">Lead time for changes (DORA)</st></strong><st c="8064">: Measures the time from code commit </st><span class="No-Break"><st c="8102">to deployment.</st></span></li>
				<li><strong class="bold"><st c="8116">Change failure rate (DORA)</st></strong><st c="8143">: Calculates the percentage of deployments </st><span class="No-Break"><st c="8187">that fail.</st></span></li>
				<li><strong class="bold"><st c="8197">Mean time to recover (MTTR) (DORA)</st></strong><st c="8232">: Gauges the average time taken to recover from </st><span class="No-Break"><st c="8281">a failure.</st></span></li>
				<li><strong class="bold"><st c="8291">Availability</st></strong><st c="8304">: Tracks the percentage of time an application is available </st><span class="No-Break"><st c="8365">without issues.</st></span></li>
			</ul>
			<p><span class="No-Break"><em class="italic"><st c="8380">Figure 12</st></em></span><em class="italic"><st c="8390">.3</st></em><st c="8392"> shows that </st><a id="_idIndexMarker1017"/><st c="8404">the outcome metrics apply to every stage in the </st><span class="No-Break"><st c="8452">value stream.</st></span></p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B21936_12_3.jpg" alt="Figure 12.3 – Common outcome metrics across all stages"/><st c="8465"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="8685">Figure 12.3 – Common outcome metrics across all stages</st></p>
			<p><st c="8739">The importance of </st><span class="No-Break"><st c="8758">DORA Metrics</st></span></p>
			<p><st c="8770">DORA metrics </st><a id="_idIndexMarker1018"/><st c="8784">are important because they</st><a id="_idIndexMarker1019"/><st c="8810"> provide an objective measurement of outcomes, including measures of DevOps performance, a benchmark for improvements, and alignment with business goals, </st><span class="No-Break"><st c="8964">as follows:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="8975">Objective measurement of DevOps Performance</st></strong><st c="9019">: DORA metrics provide quantitative data that organizations can use to assess the performance of their DevOps practices objectively. </st><st c="9153">These metrics have been validated across various organizations and are shown to correlate with higher software delivery performance and </st><span class="No-Break"><st c="9289">organizational performance.</st></span></li>
				<li><strong class="bold"><st c="9316">Benchmarks for improvement</st></strong><st c="9343">: By establishing benchmarks based on these metrics, organizations can gauge their current performance and identify areas where they need to improve. </st><st c="9494">This can lead to more targeted investments in technology, processes, and training, ultimately leading to more efficient and effective development </st><a id="_idIndexMarker1020"/><st c="9640">and </st><span class="No-Break"><st c="9644">operational practices.</st></span></li>
				<li><strong class="bold"><st c="9666">Alignment with business goals</st></strong><st c="9696">: High performance on DORA metrics generally correlates with higher organizational efficiency, better product quality, faster time to market, and improved customer satisfaction. </st><st c="9875">These aspects are crucial for achieving broader business goals, such as growth, profitability, and </st><span class="No-Break"><st c="9974">competitive advantage.</st></span></li>
			</ul>
			<p><st c="9996">The utility of DORA metrics across software value </st><span class="No-Break"><st c="10047">stream stages</st></span></p>
			<p><st c="10060">DORA metrics, with </st><a id="_idIndexMarker1021"/><st c="10080">some adaptations, can be applied across the entire end-to-end value stream and each stage in the value stream, </st><span class="No-Break"><st c="10191">as follows:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="10202">Requirements stage</st></strong><st c="10221">: While DORA metrics are traditionally more aligned with the deployment stage of the software development life cycle, they indirectly influence the requirements stage by ensuring that the processes that follow are streamlined and efficient, thereby enabling quicker and more reliable requirement changes </st><span class="No-Break"><st c="10526">and deployments.</st></span></li>
				<li><strong class="bold"><st c="10542">Development and continuous integration stages</st></strong><st c="10588">: As indicated previously, DORA metrics are traditionally more aligned with the deployment stage of the software development life cycle. </st><st c="10726">With some logical revisions, DORA metrics can be used to measure the effectiveness of the development and continuous integration stages, such as </st><span class="No-Break"><st c="10871">the following:</st></span><ul><li><strong class="bold"><st c="10885">Lead time for changes</st></strong><st c="10907"> reflects the efficiency of the development process, including how quickly code changes can be integrated, tested, and ready </st><span class="No-Break"><st c="11032">for release.</st></span></li><li><strong class="bold"><st c="11044">Deployment frequency</st></strong><st c="11065"> during these stages can indicate the health of the CI/CD pipeline, showing how mature continuous testing practices are and how often integrations and potential releases occur, even if they are to staging environments rather </st><span class="No-Break"><st c="11290">than production.</st></span></li></ul></li>
				<li><strong class="bold"><st c="11306">Continuous delivery and </st></strong><span class="No-Break"><strong class="bold"><st c="11331">deployment stages</st></strong></span><span class="No-Break"><st c="11348">:</st></span><ul><li><strong class="bold"><st c="11350">Deployment frequency</st></strong><st c="11370"> directly measures how often deployments occur, which is crucial in </st><span class="No-Break"><st c="11438">these stages.</st></span></li><li><strong class="bold"><st c="11451">Change failure rate</st></strong><st c="11471"> provides insights into the maturity and quality of SDLC practices and deployment processes, indicating how often deployments lead to operational disruptions that need </st><span class="No-Break"><st c="11639">quick fixes.</st></span></li><li><st c="11651">MTTR is crucial here, as it shows a team’s capability to quickly resolve issues that occur after code is deployed to production or </st><span class="No-Break"><st c="11783">staging environments.</st></span></li></ul></li>
				<li><span class="No-Break"><strong class="bold"><st c="11804">Operations stage</st></strong></span><span class="No-Break"><st c="11821">:</st></span><ul><li><st c="11823">MTTR shines in the operations stage by measuring operational resilience and the ability to quickly restore service </st><span class="No-Break"><st c="11938">after incidents.</st></span></li><li><strong class="bold"><st c="11954">Change failure rate</st></strong><st c="11974"> also helps assess the stability of the production environment, as frequent failures can indicate systemic problems that might originate from earlier stages of the </st><span class="No-Break"><st c="12138">value stream.</st></span></li></ul></li>
			</ul>
			<p><st c="12151">By providing a</st><a id="_idIndexMarker1022"/><st c="12166"> clear picture of these key aspects, DORA metrics help organizations not only measure outcomes but also understand the flow of value through the entire software development life cycle. </st><st c="12351">They enable teams to iterate on and refine their practices, promoting a cycle of continuous improvement that is aligned with both technical and </st><span class="No-Break"><st c="12495">business outcomes.</st></span></p>
			<h3><st c="12513">Continuous testing outcome metrics</st></h3>
			<p><st c="12548">Continuous testing ensures </st><a id="_idIndexMarker1023"/><st c="12576">that every part of the software is tested at every stage of its development to catch and fix issues early. </st><st c="12683">Examples of these metrics are illustrated in </st><span class="No-Break"><em class="italic"><st c="12728">Figure 12</st></em></span><em class="italic"><st c="12737">.4</st></em><st c="12739"> and described </st><span class="No-Break"><st c="12754">as follows:</st></span></p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B21936_12_4.jpg" alt="Figure 12.4 – Continuous testing outcome metrics by stage"/><st c="12765"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="12888">Figure 12.4 – Continuous testing outcome metrics by stage</st></p>
			<ul>
				<li><strong class="bold"><st c="12945">Requirements stage</st></strong><st c="12964">: </st><em class="italic"><st c="12967">Test case creation speed</st></em><st c="12991"> – measures how quickly test cases are created for </st><span class="No-Break"><st c="13042">new requirements.</st></span></li>
				<li><strong class="bold"><st c="13059">Development stage</st></strong><st c="13077">: </st><em class="italic"><st c="13080">Code coverage</st></em><st c="13093"> – calculates the percentage of the code base tested by </st><span class="No-Break"><st c="13149">automated tests.</st></span></li>
				<li><strong class="bold"><st c="13165">CI stage</st></strong><st c="13174">: </st><em class="italic"><st c="13177">Build pass rate</st></em><st c="13192"> – tracks the percentage of builds that pass </st><span class="No-Break"><st c="13237">all tests.</st></span></li>
				<li><strong class="bold"><st c="13247">Continuous delivery stage</st></strong><st c="13273">: </st><em class="italic"><st c="13276">Test automation rate</st></em><st c="13296"> – measures the percentage of tests that </st><span class="No-Break"><st c="13337">are automated.</st></span></li>
				<li><strong class="bold"><st c="13351">Continuous deployment stage</st></strong><st c="13379">: </st><em class="italic"><st c="13382">Deployment health checks</st></em><st c="13406"> – assesses the success of deployments based on automated post-deployment </st><span class="No-Break"><st c="13480">health checks.</st></span></li>
				<li><strong class="bold"><st c="13494">Continuous operations stage</st></strong><st c="13522">: </st><em class="italic"><st c="13525">Post-deployment testing speed</st></em><st c="13554"> – measures how quickly tests are conducted and results returned </st><span class="No-Break"><st c="13619">after deployment.</st></span></li>
			</ul>
			<p><st c="13636">As you </st><a id="_idIndexMarker1024"/><st c="13644">can see from </st><span class="No-Break"><em class="italic"><st c="13657">Figure 12</st></em></span><em class="italic"><st c="13666">.4</st></em><st c="13668">, some of the continuous testing metrics are best applied at specific stages of the software value stream. </st><st c="13775">In the next section, we will see that this is also true for continuous </st><span class="No-Break"><st c="13846">quality metrics.</st></span></p>
			<h3><st c="13862">Continuous quality outcome metrics</st></h3>
			<p><st c="13897">Continuous quality metrics, illustrated in </st><span class="No-Break"><em class="italic"><st c="13941">Figure 12</st></em></span><em class="italic"><st c="13950">.5</st></em><st c="13952">, focus on maintaining high standards </st><a id="_idIndexMarker1025"/><st c="13990">throughout the life cycle of </st><span class="No-Break"><st c="14019">the software.</st></span></p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B21936_12_5.jpg" alt="Figure 12.5 – Continuous quality outcome metrics by stage"/><st c="14032"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="14168">Figure 12.5 – Continuous quality outcome metrics by stage</st></p>
			<ul>
				<li><strong class="bold"><st c="14225">Requirements stage</st></strong><st c="14244">: </st><em class="italic"><st c="14247">Requirements clarity index</st></em><st c="14273"> – Rates how clear and understandable the project </st><span class="No-Break"><st c="14323">requirements are.</st></span></li>
				<li><strong class="bold"><st c="14340">Development stage</st></strong><st c="14358">: </st><em class="italic"><st c="14361">Bug discovery rate</st></em><st c="14379"> – tracks the rate at which bugs are found </st><span class="No-Break"><st c="14422">during development.</st></span></li>
				<li><strong class="bold"><st c="14441">Continuous integration stage</st></strong><st c="14470">: </st><em class="italic"><st c="14473">Integration error rate</st></em><st c="14495"> – measures the frequency of errors during the </st><span class="No-Break"><st c="14542">integration phase.</st></span></li>
				<li><strong class="bold"><st c="14560">Continuous delivery stage</st></strong><st c="14586">: </st><em class="italic"><st c="14589">Release quality score</st></em><st c="14610"> – evaluates the quality of software at the release based on </st><span class="No-Break"><st c="14671">predefined criteria.</st></span></li>
				<li><strong class="bold"><st c="14691">Continuous deployment stage</st></strong><st c="14719">: </st><em class="italic"><st c="14722">User experience scores</st></em><st c="14744"> – tracks activities affecting user experience discovered </st><span class="No-Break"><st c="14802">after deployment.</st></span></li>
				<li><strong class="bold"><st c="14819">Continuous operations stage</st></strong><st c="14847">: </st><em class="italic"><st c="14850">System downtime</st></em><st c="14865"> – measures the total time the system is non-operational due to </st><span class="No-Break"><st c="14929">quality issues.</st></span></li>
			</ul>
			<p><st c="14944">As you can see, it is a good practice to have a continuous quality metric for each stage of the value stream. </st><st c="15055">The same is true for continuous security </st><span class="No-Break"><st c="15096">metrics also.</st></span></p>
			<h3><st c="15109">Continuous security outcome metrics</st></h3>
			<p><st c="15145">Security metrics, illustrated in </st><span class="No-Break"><em class="italic"><st c="15179">Figure 12</st></em></span><em class="italic"><st c="15188">.6</st></em><st c="15190">, ensure that software is protected against threats </st><a id="_idIndexMarker1026"/><st c="15242">at </st><span class="No-Break"><st c="15245">every stage.</st></span></p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B21936_12_6.jpg" alt="Figure 12.6 – Continuous security outcome metrics by stage"/><st c="15257"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="15510">Figure 12.6 – Continuous security outcome metrics by stage</st></p>
			<ul>
				<li><strong class="bold"><st c="15568">Requirements stage</st></strong><st c="15587">: </st><em class="italic"><st c="15590">Security requirements completion</st></em><st c="15622"> – tracks how completely security requirements are met in the </st><span class="No-Break"><st c="15684">planning phase.</st></span></li>
				<li><strong class="bold"><st c="15699">Development stage</st></strong><st c="15717">: </st><em class="italic"><st c="15720">Vulnerabilities per line of code</st></em><st c="15752"> – measures the number of security vulnerabilities relative to the size of the </st><span class="No-Break"><st c="15831">code base.</st></span></li>
				<li><strong class="bold"><st c="15841">CI stage</st></strong><st c="15850">: </st><em class="italic"><st c="15853">Security scan pass rate</st></em><st c="15876"> – the percentage of passes in routine security scans </st><span class="No-Break"><st c="15930">during integration.</st></span></li>
				<li><strong class="bold"><st c="15949">Continuous delivery stage</st></strong><st c="15975">: </st><em class="italic"><st c="15978">Critical security issue rate</st></em><st c="16006"> – tracks the rate of critical security issues found </st><span class="No-Break"><st c="16059">before delivery.</st></span></li>
				<li><strong class="bold"><st c="16075">Continuous deployment stage</st></strong><st c="16103">: </st><em class="italic"><st c="16106">Security incident response time</st></em><st c="16137"> – measures how quickly security incidents are addressed </st><span class="No-Break"><st c="16194">after deployment.</st></span></li>
				<li><strong class="bold"><st c="16211">Continuous operations stage</st></strong><st c="16239">: </st><em class="italic"><st c="16242">Ongoing security compliance rate</st></em><st c="16274"> – measures compliance with ongoing security standards </st><span class="No-Break"><st c="16329">and regulations.</st></span></li>
			</ul>
			<p><st c="16345">As explained in this section, continuous security metrics are recommended for each stage in the</st><a id="_idIndexMarker1027"/><st c="16441"> value stream. </st><st c="16456">The next section shows that this is also true for continuous </st><span class="No-Break"><st c="16517">feedback metrics.</st></span></p>
			<h3><st c="16534">Continuous feedback outcome metrics</st></h3>
			<p><st c="16570">Feedback metrics, as shown in </st><span class="No-Break"><em class="italic"><st c="16601">Figure 12</st></em></span><em class="italic"><st c="16610">.7</st></em><st c="16612">, evaluate how effectively an organization gathers</st><a id="_idIndexMarker1028"/><st c="16662"> and implements feedback from users throughout the </st><span class="No-Break"><st c="16713">development process.</st></span></p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B21936_12_7.jpg" alt="Figure 12.7 – Continuous feedback outcome metrics by stage"/><st c="16733"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="16993">Figure 12.7 – Continuous feedback outcome metrics by stage</st></p>
			<ul>
				<li><strong class="bold"><st c="17051">Requirements stage</st></strong><st c="17070">: </st><em class="italic"><st c="17073">Feedback integration effectiveness</st></em><st c="17107"> – measures how effectively user feedback is integrated </st><span class="No-Break"><st c="17163">into requirements.</st></span></li>
				<li><strong class="bold"><st c="17181">Development stage</st></strong><st c="17199">: </st><em class="italic"><st c="17202">Developer response time to feedback</st></em><st c="17237"> – tracks how quickly developers address feedback during </st><span class="No-Break"><st c="17294">the development.</st></span></li>
				<li><strong class="bold"><st c="17310">Continuous integration stage</st></strong><st c="17339">: </st><em class="italic"><st c="17342">Feedback resolution rate</st></em><st c="17366"> – measures the rate at which feedback issues are resolved </st><span class="No-Break"><st c="17425">during integration.</st></span></li>
				<li><strong class="bold"><st c="17444">Continuous delivery stage</st></strong><st c="17470">: </st><em class="italic"><st c="17473">Feedback impact score</st></em><st c="17494"> – evaluates the impact of implemented feedback on </st><span class="No-Break"><st c="17545">software quality.</st></span></li>
				<li><strong class="bold"><st c="17562">Continuous deployment stage</st></strong><st c="17590">: </st><em class="italic"><st c="17593">Customer satisfaction post-deployment</st></em><st c="17630"> – measures customer satisfaction levels after deploying new features </st><span class="No-Break"><st c="17700">or fixes.</st></span></li>
				<li><strong class="bold"><st c="17709">Continuous operations stage</st></strong><st c="17737">: </st><em class="italic"><st c="17740">Long-term feedback trends</st></em><st c="17765"> – analyzes trends in user feedback over the operation phase to guide </st><span class="No-Break"><st c="17835">future improvements.</st></span></li>
			</ul>
			<p><st c="17855">Overall, outcome metrics </st><a id="_idIndexMarker1029"/><st c="17881">help teams monitor and improve the efficiency, security, and quality of their software from start to finish, ensuring that each stage of the value stream is measured and can be optimized to meet both user needs and </st><span class="No-Break"><st c="18096">business goals.</st></span></p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor228"/><st c="18111">Examples of progress metrics</st></h2>
			<p><st c="18140">Progress metrics </st><a id="_idIndexMarker1030"/><st c="18158">are critical in tracking the advancement of transformation and software development projects. </st><st c="18252">They </st><a id="_idIndexMarker1031"/><st c="18257">help teams monitor the efficiency and effectiveness of their work at different stages of the software life cycle. </st><st c="18371">These metrics are specifically designed to measure how projects progress against planned schedules, goals, and benchmarks in areas such as testing, quality, security, </st><span class="No-Break"><st c="18538">and feedback.</st></span></p>
			<h3><st c="18551">Common progress metrics across all stages</st></h3>
			<p><st c="18593">Progress metrics </st><a id="_idIndexMarker1032"/><st c="18611">play a pivotal role in software development, providing teams with real-time insights into the progress and efficiency of their projects. </st><st c="18748">These metrics help track advancement through various stages of the software life cycle, including testing, quality, security, and feedback, ensuring that projects meet deadlines </st><span class="No-Break"><st c="18926">and benchmarks.</st></span></p>
			<p><st c="18941">These metrics, including key flow metrics (as shown in </st><span class="No-Break"><em class="italic"><st c="18997">Figure 12</st></em></span><em class="italic"><st c="19006">.8</st></em><st c="19008">), help teams monitor overall project health and progress, ensuring that timelines and productivity goals </st><span class="No-Break"><st c="19115">are met.</st></span></p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B21936_12_8.jpg" alt="Figure 12.8 – Progress metrics relevant to all stages of the value stream"/><st c="19123"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="19428">Figure 12.8 – Progress metrics relevant to all stages of the value stream</st></p>
			<p><st c="19501">The following are</st><a id="_idIndexMarker1033"/><st c="19519"> examples of useful progress metrics and </st><span class="No-Break"><st c="19560">visualization artifacts:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="19584">Sprint burndown chart</st></strong><st c="19606">: Shows the remaining work in the sprint versus time, indicating whether the team is </st><span class="No-Break"><st c="19692">on track.</st></span></li>
				<li><strong class="bold"><st c="19701">Release burndown</st></strong><st c="19718">: Measures the amount of remaining work against the timeline for </st><span class="No-Break"><st c="19784">the release.</st></span></li>
				<li><strong class="bold"><st c="19796">Cumulative flow diagram (flow metric)</st></strong><st c="19834">: Visualizes the quantity of work in different stages of development, helping to identify bottlenecks and understand work balance and flow through </st><span class="No-Break"><st c="19982">a system.</st></span></li>
				<li><strong class="bold"><st c="19991">Velocity</st></strong><st c="20000">: Assesses the amount of work a team completes during a sprint, which is useful for future </st><span class="No-Break"><st c="20092">sprint planning.</st></span></li>
				<li><strong class="bold"><st c="20108">Work in progress (WIP) limits (flow metric)</st></strong><st c="20152">: Sets the maximum amount of tasks that can be in progress at any one time, helping teams manage workload and </st><span class="No-Break"><st c="20263">reduce bottlenecks.</st></span></li>
				<li><strong class="bold"><st c="20282">Cycle time (flow metric)</st></strong><st c="20307">: Measures the time it takes for work to move from start to finish, providing insights into </st><span class="No-Break"><st c="20400">process efficiency.</st></span></li>
			</ul>
			<p><st c="20419">Flow metrics are essential indicators used to measure the movement of work items through various</st><a id="_idIndexMarker1034"/><st c="20516"> stages of the software development life cycle. </st><st c="20564">These metrics focus on the efficiency, effectiveness, and predictability of software </st><span class="No-Break"><st c="20649">delivery processes.</st></span></p>
			<h3><st c="20668">The importance of flow metrics</st></h3>
			<p><st c="20699">Flow metrics </st><a id="_idIndexMarker1035"/><st c="20713">help organizations understand how work progresses from initial concept to delivery in a tangible and </st><span class="No-Break"><st c="20814">actionable way:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="20829">Enhancing visibility</st></strong><st c="20850">: Flow metrics provide clear visibility into the current state of work processes. </st><st c="20933">By tracking the progression of work items, teams can identify where bottlenecks or delays occur and understand their </st><span class="No-Break"><st c="21050">root causes.</st></span></li>
				<li><strong class="bold"><st c="21062">Improving efficiency</st></strong><st c="21083">: With insights from flow metrics, organizations can streamline processes, remove inefficiencies, and optimize resource allocation. </st><st c="21216">This can lead to quicker development cycles and more efficient use of time </st><span class="No-Break"><st c="21291">and resources.</st></span></li>
				<li><strong class="bold"><st c="21305">Boosting predictability</st></strong><st c="21329">: Flow metrics allow teams to predict future performance based on historical data. </st><st c="21413">This predictability helps in better planning and forecasting, reducing uncertainties in </st><span class="No-Break"><st c="21501">delivery timelines.</st></span></li>
				<li><strong class="bold"><st c="21520">Promoting continuous improvement</st></strong><st c="21553">: Regular measurement and analysis of flow metrics encourage a culture of continuous improvement. </st><st c="21652">Teams can iteratively refine their processes based on quantifiable data, striving for leaner and more </st><span class="No-Break"><st c="21754">efficient workflows.</st></span></li>
				<li><strong class="bold"><st c="21774">Alignment with business objectives</st></strong><st c="21809">: By improving efficiency and predictability, flow metrics help ensure that software delivery is aligned with broader business goals, such as increasing customer satisfaction, reducing time to market, and improving </st><span class="No-Break"><st c="22025">product quality.</st></span></li>
			</ul>
			<h3><st c="22041">The utility of flow metrics across software value stream stages</st></h3>
			<p><st c="22105">The following details the recommended applications of flow metrics for each stage in the</st><a id="_idIndexMarker1036"/><st c="22194"> software </st><span class="No-Break"><st c="22204">value stream:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="22217">The </st></strong><span class="No-Break"><strong class="bold"><st c="22222">requirements stage</st></strong></span><span class="No-Break"><st c="22240">:</st></span><ul><li><strong class="bold"><st c="22242">Work item age</st></strong><st c="22255">: Measures how long a requirement has been under discussion before being approved. </st><st c="22339">This metric helps identify delays in the early stages of the </st><span class="No-Break"><st c="22400">value stream.</st></span></li><li><strong class="bold"><st c="22413">Flow efficiency</st></strong><st c="22429">: The ratio of active work time to the total elapsed time. </st><st c="22489">Low efficiency at this stage might indicate too much wait time or indecision in </st><span class="No-Break"><st c="22569">defining requirements.</st></span></li></ul></li>
				<li><strong class="bold"><st c="22591">The </st></strong><span class="No-Break"><strong class="bold"><st c="22596">development stage</st></strong></span><span class="No-Break"><st c="22613">:</st></span><ul><li><strong class="bold"><st c="22615">WIP</st></strong><st c="22618">: Limits the number of tasks being worked on simultaneously to reduce context switching and focus on completing </st><span class="No-Break"><st c="22731">tasks quicker.</st></span></li><li><strong class="bold"><st c="22745">Cycle time</st></strong><st c="22756">: Measures the time it takes for work to move from the start of development to completion. </st><st c="22848">Monitoring cycle time helps in identifying slowdowns and improving </st><span class="No-Break"><st c="22915">developer productivity.</st></span></li></ul></li>
				<li><strong class="bold"><st c="22938">The </st></strong><span class="No-Break"><strong class="bold"><st c="22943">CI/CD stage</st></strong></span><span class="No-Break"><st c="22954">:</st></span><ul><li><strong class="bold"><st c="22956">Throughput</st></strong><st c="22966">: Tracks the number of work items passing through the CI/CD pipeline during a given period. </st><st c="23059">High throughput indicates a healthy </st><span class="No-Break"><st c="23095">CI/CD pipeline.</st></span></li><li><strong class="bold"><st c="23110">Lead time</st></strong><st c="23120">: The time from work item initiation to delivery. </st><st c="23171">It includes cycle time and all forms of delay. </st><st c="23218">Reducing lead time at this stage is critical for </st><span class="No-Break"><st c="23267">faster releases.</st></span></li></ul></li>
				<li><strong class="bold"><st c="23283">The deployment and </st></strong><span class="No-Break"><strong class="bold"><st c="23303">operations stage</st></strong></span><span class="No-Break"><st c="23319">:</st></span><ul><li><strong class="bold"><st c="23321">Release frequency</st></strong><st c="23338">: Measures how often new releases are deployed to production. </st><st c="23401">Frequent releases can indicate a smooth flow from development </st><span class="No-Break"><st c="23463">to deployment.</st></span></li><li><strong class="bold"><st c="23477">MTTR</st></strong><st c="23482">: Although traditionally a DORA metric, MTTR in</st><a id="_idIndexMarker1037"/><st c="23530"> the context of flow metrics helps measure the speed at which a team can recover from failures in production, reflecting the </st><span class="No-Break"><st c="23655">operational agility.</st></span></li></ul></li>
			</ul>
			<p><st c="23675">In all stages, the </st><a id="_idIndexMarker1038"/><st c="23695">application of flow metrics provides a clear, data-driven view of how tasks are progressing, where issues are occurring, and what improvements are necessary. </st><st c="23853">This level of insight is invaluable for any organization undergoing transformation and aiming to enhance its software delivery and operational capabilities continuously. </st><st c="24023">By measuring and optimizing each stage of the software value stream, organizations can achieve a smoother, faster, and more reliable flow of value to </st><span class="No-Break"><st c="24173">their customers.</st></span></p>
			<h3><st c="24189">Continuous testing progress metrics</st></h3>
			<p><st c="24225">Progress metrics</st><a id="_idIndexMarker1039"/><st c="24242"> in continuous testing, as shown in </st><span class="No-Break"><em class="italic"><st c="24278">Figure 12</st></em></span><em class="italic"><st c="24287">.9</st></em><st c="24289">, track the development and execution of tests to ensure timely </st><span class="No-Break"><st c="24353">quality assessments.</st></span></p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B21936_12_9.jpg" alt="Figure 12.9 – Continuous testing progress metrics"/><st c="24373"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="24620">Figure 12.9 – Continuous testing progress metrics</st></p>
			<ul>
				<li><strong class="bold"><st c="24669">Requirements stage</st></strong><st c="24688">: </st><em class="italic"><st c="24691">Test case preparation progress</st></em><st c="24721"> – tracks the percentage of test cases prepared against the </st><span class="No-Break"><st c="24781">total planned.</st></span></li>
				<li><strong class="bold"><st c="24795">Development stage</st></strong><st c="24813">: </st><em class="italic"><st c="24816">Test execution progress</st></em><st c="24839"> – measures the percentage of tests run against the total </st><span class="No-Break"><st c="24897">tests planned.</st></span></li>
				<li><strong class="bold"><st c="24911">Continuous integration stage</st></strong><st c="24940">: </st><em class="italic"><st c="24943">Build integration progress</st></em><st c="24969"> – tracks the number of successful integrations against </st><span class="No-Break"><st c="25025">planned integrations.</st></span></li>
				<li><strong class="bold"><st c="25046">Continuous delivery stage</st></strong><st c="25072">: </st><em class="italic"><st c="25075">Test automation progress</st></em><st c="25099"> – monitors the percentage of tests automated against </st><span class="No-Break"><st c="25153">the target.</st></span></li>
				<li><strong class="bold"><st c="25164">Continuous deployment stage</st></strong><st c="25192">: </st><em class="italic"><st c="25195">Deployment progress tracking</st></em><st c="25223"> – measures the frequency and success rate of deployments against </st><span class="No-Break"><st c="25289">the schedule.</st></span></li>
				<li><strong class="bold"><st c="25302">Continuous operations stage</st></strong><st c="25330">: </st><em class="italic"><st c="25333">Monitoring system implementation progress</st></em><st c="25374"> – tracks the implementation and fine-tuning of system </st><span class="No-Break"><st c="25429">monitoring tools.</st></span></li>
			</ul>
			<p><st c="25446">Here, we </st><a id="_idIndexMarker1040"/><st c="25456">looked at the recommended progress metrics for continuous testing. </st><st c="25523">In the next section, we will do the same for continuous quality </st><span class="No-Break"><st c="25587">progress metrics.</st></span></p>
			<h3><st c="25604">Continuous quality progress metrics</st></h3>
			<p><st c="25640">Continuous quality progress metrics, as shown in </st><span class="No-Break"><em class="italic"><st c="25690">Figure 12</st></em></span><em class="italic"><st c="25699">.10</st></em><st c="25702">, focus on tracking the progress </st><a id="_idIndexMarker1041"/><st c="25735">of efforts to ensure and enhance a product’s quality throughout its </st><span class="No-Break"><st c="25803">life cycle.</st></span></p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B21936_12_10.jpg" alt="Figure 12.10 – Continuous quality progress metrics"/><st c="25814"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="26047">Figure 12.10 – Continuous quality progress metrics</st></p>
			<ul>
				<li><strong class="bold"><st c="26097">Requirements stage</st></strong><st c="26116">: </st><em class="italic"><st c="26119">Requirements review completion</st></em><st c="26149"> – the percentage of project requirements reviewed </st><span class="No-Break"><st c="26200">and approved.</st></span></li>
				<li><strong class="bold"><st c="26213">Development stage</st></strong><st c="26231">: </st><em class="italic"><st c="26234">Code review coverage</st></em><st c="26254"> – tracks the percentage of new code that has </st><span class="No-Break"><st c="26300">been reviewed.</st></span></li>
				<li><strong class="bold"><st c="26314">CI stage</st></strong><st c="26323">: </st><em class="italic"><st c="26326">Code quality improvement</st></em><st c="26350"> – measures improvements in code quality metrics </st><span class="No-Break"><st c="26399">over time.</st></span></li>
				<li><strong class="bold"><st c="26409">Continuous delivery stage</st></strong><st c="26435">: </st><em class="italic"><st c="26438">Pre-release testing completion</st></em><st c="26468"> – the percentage of planned testing completed </st><span class="No-Break"><st c="26515">before release.</st></span></li>
				<li><strong class="bold"><st c="26530">Continuous deployment stage</st></strong><st c="26558">: </st><em class="italic"><st c="26561">Post-deployment quality checks</st></em><st c="26591"> – tracks the completion of quality checks after </st><span class="No-Break"><st c="26640">each deployment.</st></span></li>
				<li><strong class="bold"><st c="26656">Continuous operations stage</st></strong><st c="26684">: </st><em class="italic"><st c="26687">Quality metrics monitoring</st></em><st c="26713"> – the percentage of operational quality metrics being monitored </st><span class="No-Break"><st c="26778">as planned.</st></span></li>
			</ul>
			<p><st c="26789">Here, we</st><a id="_idIndexMarker1042"/><st c="26798"> looked at the metrics to track continuous quality progress. </st><st c="26859">Next, we will discuss the metrics to demonstrate continuous </st><span class="No-Break"><st c="26919">security progress.</st></span></p>
			<h3><st c="26937">Continuous security progress metrics</st></h3>
			<p><st c="26974">Continuous security progress metrics, as shown in </st><span class="No-Break"><em class="italic"><st c="27025">Figure 12</st></em></span><em class="italic"><st c="27034">.11</st></em><st c="27037">, focus on monitoring the progress </st><a id="_idIndexMarker1043"/><st c="27072">of integrating and improving security measures throughout the </st><span class="No-Break"><st c="27134">development process.</st></span></p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B21936_12_11.jpg" alt="Figure 12.11 – Continuous security progress metrics"/><st c="27154"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="27390">Figure 12.11 – Continuous security progress metrics</st></p>
			<ul>
				<li><strong class="bold"><st c="27441">Requirements stage</st></strong><st c="27460">: </st><em class="italic"><st c="27463">Security plan completion</st></em><st c="27487"> – measures how much of the security planning has </st><span class="No-Break"><st c="27537">been completed.</st></span></li>
				<li><strong class="bold"><st c="27552">Development stage</st></strong><st c="27570">: </st><em class="italic"><st c="27573">Security integration progress</st></em><st c="27602"> – tracks the integration of security features into </st><span class="No-Break"><st c="27654">the product.</st></span></li>
				<li><strong class="bold"><st c="27666">Continuous integration stage</st></strong><st c="27695">: </st><em class="italic"><st c="27698">Security test execution</st></em><st c="27721"> – the percentage of planned security tests that have </st><span class="No-Break"><st c="27775">been executed.</st></span></li>
				<li><strong class="bold"><st c="27789">Continuous delivery stage</st></strong><st c="27815">: </st><em class="italic"><st c="27818">Security audit completion</st></em><st c="27843"> – measures the completion of security audits </st><span class="No-Break"><st c="27889">before delivery.</st></span></li>
				<li><strong class="bold"><st c="27905">Continuous deployment stage</st></strong><st c="27933">: </st><em class="italic"><st c="27936">Security deployment checks</st></em><st c="27962"> – tracks the completion of security checks </st><span class="No-Break"><st c="28006">during deployment.</st></span></li>
				<li><strong class="bold"><st c="28024">Continuous operations stage</st></strong><st c="28052">: </st><em class="italic"><st c="28055">Security update implementation</st></em><st c="28085"> – measures the implementation rate of security updates </st><span class="No-Break"><st c="28141">and patches.</st></span></li>
			</ul>
			<p><st c="28153">Here, we </st><a id="_idIndexMarker1044"/><st c="28163">looked at the metrics to demonstrate the progress of continuous security. </st><st c="28237">The next section will suggest metrics to demonstrate the progress of </st><span class="No-Break"><st c="28306">continuous feedback.</st></span></p>
			<h3><st c="28326">Continuous feedback progress metrics</st></h3>
			<p><st c="28363">Continuous feedback progress metrics, as shown in </st><span class="No-Break"><em class="italic"><st c="28414">Figure 12</st></em></span><em class="italic"><st c="28423">.12</st></em><st c="28426">, assess how efficiently feedback is </st><a id="_idIndexMarker1045"/><st c="28463">collected and acted upon throughout the </st><span class="No-Break"><st c="28503">development process.</st></span></p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B21936_12_12.jpg" alt="Figure 12.12 – Continuous feedback progress metrics"/><st c="28523"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="28772">Figure 12.12 – Continuous feedback progress metrics</st></p>
			<ul>
				<li><strong class="bold"><st c="28823">Requirements stage</st></strong><st c="28842">: </st><em class="italic"><st c="28845">Feedback collection completion</st></em><st c="28875"> – tracks the percentage of planned feedback collection </st><span class="No-Break"><st c="28931">activities completed.</st></span></li>
				<li><strong class="bold"><st c="28952">Development stage</st></strong><st c="28970">: </st><em class="italic"><st c="28973">Feedback implementation progress</st></em><st c="29005"> – measures the progress of implementing feedback into the </st><span class="No-Break"><st c="29064">development process.</st></span></li>
				<li><strong class="bold"><st c="29084">CI stage</st></strong><st c="29093">: </st><em class="italic"><st c="29096">Feedback integration rate</st></em><st c="29121"> – tracks the rate at which feedback is integrated during </st><span class="No-Break"><st c="29179">integration testing.</st></span></li>
				<li><strong class="bold"><st c="29199">Continuous delivery stage</st></strong><st c="29225">: </st><em class="italic"><st c="29228">Feedback review completion</st></em><st c="29254"> – the percentage of feedback review tasks completed </st><span class="No-Break"><st c="29307">before delivery.</st></span></li>
				<li><strong class="bold"><st c="29323">Continuous deployment stage</st></strong><st c="29351">: </st><em class="italic"><st c="29354">Customer feedback analysis</st></em><st c="29380"> – measures the completion of post-deployment customer </st><span class="No-Break"><st c="29435">feedback analysis.</st></span></li>
				<li><strong class="bold"><st c="29453">Continuous operations stage</st></strong><st c="29481">: </st><em class="italic"><st c="29484">Ongoing feedback monitoring</st></em><st c="29511"> – tracks the ongoing monitoring and analysis of </st><span class="No-Break"><st c="29560">user feedback.</st></span></li>
			</ul>
			<p><st c="29574">These progress metrics provide teams with the necessary tools to ensure that they are moving</st><a id="_idIndexMarker1046"/><st c="29667"> toward their project goals efficiently, allowing for timely adjustments in strategy and execution to meet the </st><span class="No-Break"><st c="29778">desired outcomes.</st></span></p>
			<h1 id="_idParaDest-210"><a id="_idTextAnchor229"/><st c="29795">Selecting measures</st></h1>
			<p><st c="29814">This is </st><a id="_idIndexMarker1047"/><st c="29823">where we apply what we’ve learned; you’ll see how to tell apart measurements that only provide information from those that can truly transform your processes. </st><st c="29982">We’ll focus on making sure the measurements you pick are relevant, reliable, and able to drive </st><span class="No-Break"><st c="30077">significant changes.</st></span></p>
			<p><st c="30097">When selecting and prioritizing outcomes or progress metrics for a project or organization, it’s crucial to follow a systematic process to ensure the metrics chosen effectively measure success and align with business objectives. </st><span class="No-Break"><em class="italic"><st c="30327">Figure 12</st></em></span><em class="italic"><st c="30336">.13</st></em><st c="30339"> shows a recommended approach to </st><span class="No-Break"><st c="30372">do so.</st></span></p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/B21936_12_13.jpg" alt="Figure 12.13 – Selecting outcome and progress metrics"/><st c="30378"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="30517">Figure 12.13 – Selecting outcome and progress metrics</st></p>
			<p><st c="30570">The following is the</st><a id="_idIndexMarker1048"/><st c="30591"> recommended process to select both outcome and </st><span class="No-Break"><st c="30639">progress metrics.</st></span></p>
			<ul>
				<li><strong class="bold"><st c="30656">Define business and project objectives</st></strong><st c="30695">: Start by clearly defining the business objectives. </st><st c="30749">Understanding what an organization aims to achieve with its projects or processes is critical. </st><st c="30844">Whether it’s improving customer satisfaction, increasing software deployment frequency, enhancing security measures, or reducing operational costs, having a clear set of goals will guide the selection of </st><span class="No-Break"><st c="31048">relevant metrics.</st></span></li>
				<li><strong class="bold"><st c="31065">Identify metrics</st></strong><st c="31082">: Once business or project objectives are defined, identify the key metrics</st><a id="_idIndexMarker1049"/><st c="31158"> that directly reflect success toward these objectives. </st><st c="31214">Metrics should be actionable, meaning they can guide decision-making and influence outcomes. </st><st c="31307">For example, if the objective is to enhance customer satisfaction, a possible KPI could be the </st><strong class="bold"><st c="31402">Net Promoter Score</st></strong><st c="31420"> (</st><strong class="bold"><st c="31422">NPS</st></strong><st c="31425">). </st><st c="31429">The metrics described earlier in this chapter provide suggestions of both outcome and progress metrics that you can </st><span class="No-Break"><st c="31545">choose from.</st></span></li>
				<li><strong class="bold"><st c="31557">Ensure metrics are measurable and achievable</st></strong><st c="31602">: Select metrics that are not only aligned with business objectives but are also measurable and achievable. </st><st c="31711">Each metric should have a clear method of measurement and be grounded in data that can be consistently and accurately collected. </st><st c="31840">Avoid vague metrics that are open to interpretation, as they can lead to inconsistent results </st><span class="No-Break"><st c="31934">and decisions.</st></span></li>
				<li><strong class="bold"><st c="31948">Prioritize metrics based on impact and relevance</st></strong><st c="31997">: Not all metrics are created equal. </st><st c="32035">Some will have a greater impact on business outcomes than others. </st><st c="32101">Prioritize metrics based on their potential impact on business goals and their relevance to current projects or strategies. </st><st c="32225">Metrics that offer insights into customer behavior, product performance, and operational efficiency often take precedence, as they directly correlate with </st><span class="No-Break"><st c="32380">business success.</st></span></li>
				<li><strong class="bold"><st c="32397">Consider stakeholder input</st></strong><st c="32424">: Engage with stakeholders across different departments of an organization to get their input on which metrics they believe are most important. </st><st c="32569">This not only ensures a holistic view but also facilitates buy-in across the organization. </st><st c="32660">Stakeholders can provide insights into the practical aspects of metric tracking and implications that might not be obvious at the </st><span class="No-Break"><st c="32790">strategic level.</st></span></li>
				<li><strong class="bold"><st c="32806">Review and refine regularly</st></strong><st c="32834">: Outcome metrics should not be static. </st><st c="32875">As business goals shift, technologies evolve, and markets change, the relevance of different metrics will vary. </st><st c="32987">Regularly review metrics to ensure they remain aligned with business objectives and make adjustments as necessary. </st><st c="33102">This might mean refining the way metrics are measured or replacing less relevant metrics with ones that better match the current </st><span class="No-Break"><st c="33231">business landscape.</st></span></li>
			</ul>
			<p><st c="33250">By following</st><a id="_idIndexMarker1050"/><st c="33263"> these steps, organizations can effectively select and prioritize outcome metrics that not only provide a clear indication of performance but also drive meaningful improvements aligned with strategic goals. </st><st c="33470">The set of metrics should be relevant </st><span class="No-Break"><st c="33508">and balanced.</st></span></p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor230"/><st c="33521">Leadership and teams for selecting outcome and progress metrics</st></h2>
			<p><st c="33585">Selecting</st><a id="_idIndexMarker1051"/><st c="33595"> both outcome and progress metrics for projects involves strategic decision-making and should include input from various roles within an organization. </st><st c="33746">It’s important to have a balanced team of leaders and team members to ensure that the metrics chosen align with business goals, project objectives, and practical implementation considerations. </st><st c="33939">Here’s a guideline on who should lead and be involved in the selection process for both types </st><span class="No-Break"><st c="34033">of metrics:</st></span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold"><st c="34044">Leadership</st></strong></span><span class="No-Break"><st c="34055">:</st></span><ul><li><strong class="bold"><st c="34057">Project or program managers</st></strong><st c="34084"> are typically at the forefront of leading the selection process for both outcome and progress metrics. </st><st c="34188">They have a holistic view of a project’s goals, scope, timeline, and resources, which positions them well to understand which metrics are most relevant and how they can be effectively implemented </st><span class="No-Break"><st c="34384">and tracked.</st></span></li></ul></li>
				<li><strong class="bold"><st c="34396">Team </st></strong><span class="No-Break"><strong class="bold"><st c="34402">member involvement</st></strong></span><span class="No-Break"><st c="34420">:</st></span><ul><li><strong class="bold"><st c="34422">Executive sponsors</st></strong><st c="34440">: Their involvement ensures that the selected metrics align with an organization’s strategic objectives. </st><st c="34546">Executives can provide the necessary support and resources, helping to integrate these metrics into broader business </st><span class="No-Break"><st c="34663">performance evaluations.</st></span></li><li><strong class="bold"><st c="34687">Business analysts</st></strong><st c="34705">: These professionals help translate business objectives into measurable metrics. </st><st c="34788">They ensure that both outcome and progress metrics reflect the value and impact the project should deliver to </st><span class="No-Break"><st c="34898">the business.</st></span></li><li><strong class="bold"><st c="34911">Technical leads and architects</st></strong><st c="34942">: For technology-driven projects, their technical expertise is vital in determining the feasibility of capturing specific metrics. </st><st c="35074">They can advise on the tools and systems needed to track these </st><span class="No-Break"><st c="35137">metrics effectively.</st></span></li><li><strong class="bold"><st c="35157">QA managers</st></strong><st c="35169">: Involving QA managers is crucial for defining metrics related to product or service quality. </st><st c="35265">They contribute to selecting progress metrics </st><a id="_idIndexMarker1052"/><st c="35311">that monitor ongoing quality controls and outcome metrics that reflect the final </st><span class="No-Break"><st c="35392">quality standards.</st></span></li><li><strong class="bold"><st c="35410">Finance representatives</st></strong><st c="35434">: They can provide insight into how the outcomes and the progress of the project align with financial goals, offering metrics that may relate to cost efficiency, </st><strong class="bold"><st c="35597">return on investment</st></strong><st c="35617"> (</st><strong class="bold"><st c="35619">ROI</st></strong><st c="35622">), and </st><span class="No-Break"><st c="35630">budget adherence.</st></span></li><li><strong class="bold"><st c="35647">Marketing and sales teams</st></strong><st c="35673">: For projects that impact product offerings, involving these teams can help align metrics with customer satisfaction, market response, and sales performance. </st><st c="35833">This ensures that the metrics chosen will help measure market success and </st><span class="No-Break"><st c="35907">customer engagement.</st></span></li><li><strong class="bold"><st c="35927">Operations managers</st></strong><st c="35947">: Particularly for projects impacting operations, these managers ensure that the metrics reflect operational efficiencies, process improvements, and service </st><span class="No-Break"><st c="36105">delivery standards.</st></span></li><li><strong class="bold"><st c="36124">IT and data analysts</st></strong><st c="36145">: Their role is essential in defining and setting up systems for data collection, analysis, and reporting selected metrics. </st><st c="36270">They help ensure that data-driven metrics are accurate, timely, </st><span class="No-Break"><st c="36334">and relevant.</st></span></li></ul></li>
			</ul>
			<p><st c="36347">A collaborative approach to selecting metrics helps to cover all bases, from strategic alignment to practical measurement and day-to-day impact. </st><st c="36493">This diversity in perspectives ensures that the metrics chosen are comprehensive and provide meaningful insights into both the progress of a project and its </st><span class="No-Break"><st c="36650">final outcomes.</st></span></p>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor231"/><st c="36665">Practices for designing metrics and dashboards</st></h1>
			<p><st c="36712">This </st><a id="_idIndexMarker1053"/><st c="36718">section will give you practical advice on how to present data effectively so that all stakeholders can make quick, </st><span class="No-Break"><st c="36833">informed decisions.</st></span></p>
			<p><st c="36852">To effectively track and visualize outcome and progress metrics in areas such as continuous testing, quality, security, and feedback, organizations need a thoughtful approach to designing these metrics and the dashboards that will display them. </st><span class="No-Break"><em class="italic"><st c="37098">Figure 12</st></em></span><em class="italic"><st c="37107">.14</st></em><st c="37110"> illustrates the recommended process for </st><span class="No-Break"><st c="37151">selecting metrics.</st></span></p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/B21936_12_14.jpg" alt="Figure 12.14 – Designing metrics and dashboards"/><st c="37169"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><st c="37425">Figure 12.14 – Designing metrics and dashboards</st></p>
			<p><st c="37472">Here’s a breakdown of the process for designing these metrics and an exploration of the different architectures for </st><span class="No-Break"><st c="37589">the dashboards.</st></span></p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor232"/><st c="37604">Designing an outcome and progress metrics</st></h2>
			<p><st c="37646">Here is the </st><a id="_idIndexMarker1054"/><st c="37659">process for </st><span class="No-Break"><st c="37671">designing metrics:</st></span></p>
			<ol>
				<li><strong class="bold"><st c="37689">Define the measurement criteria</st></strong><st c="37721">: Once metrics have been selected based on strategic goals, define specific measurement criteria and standards. </st><st c="37834">This includes setting clear definitions for each metric measure, how data will be collected, and the frequency of measurement. </st><st c="37961">For instance, if the metric is “the time to detect security incidents,” determine whether this starts when the incident occurs or when it’s first noticed by systems </st><span class="No-Break"><st c="38126">or personnel.</st></span></li>
				<li><strong class="bold"><st c="38139">Establish baselines and targets</st></strong><st c="38171">: For each metric, establish a baseline that reflects current performance and set realistic targets for improvement. </st><st c="38289">This provides a starting</st><a id="_idIndexMarker1055"/><st c="38313"> point to measure progress and a clear goal that drives actions. </st><st c="38378">Baselines can be historical data, industry standards, </st><span class="No-Break"><st c="38432">or benchmarks.</st></span></li>
				<li><strong class="bold"><st c="38446">Choose data sources and collection methods</st></strong><st c="38489">: Identify where and how data for each metric will be collected. </st><st c="38555">For continuous testing, data might come from testing tools and CI/CD pipelines; for security metrics, data could be sourced from security monitoring and incident </st><span class="No-Break"><st c="38717">management systems.</st></span></li>
				<li><strong class="bold"><st c="38736">Implement data collection</st></strong><st c="38762">: Ensure that the infrastructure and tools needed for automatic data collection are in place. </st><st c="38857">This might involve configuring software tools, setting up APIs, and ensuring data accuracy </st><span class="No-Break"><st c="38948">and consistency.</st></span></li>
				<li><strong class="bold"><st c="38964">Validate and refine metrics</st></strong><st c="38992">: Periodically review the metrics to ensure they provide valuable insights, and refine them based on feedback and changing objectives. </st><st c="39128">This might involve adjusting data sources, collection frequency, or even the metric </st><span class="No-Break"><st c="39212">definitions themselves.</st></span></li>
			</ol>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor233"/><st c="39235">Architectures for dashboards displaying metrics</st></h2>
			<p><st c="39283">Alternative</st><a id="_idIndexMarker1056"/><st c="39295"> dashboard architectures, as illustrated in </st><span class="No-Break"><em class="italic"><st c="39339">Figure 12</st></em></span><em class="italic"><st c="39348">.14</st></em><st c="39351">, are </st><span class="No-Break"><st c="39357">as follows:</st></span></p>
			<ul>
				<li><strong class="bold"><st c="39368">Integrated Development Environment (IDE)-embedded dashboards</st></strong><st c="39429">: For metrics related to development activities such as continuous testing or code quality, dashboards can be integrated directly into the IDE. </st><st c="39574">This allows developers to see metrics in real time within their working environment, enhancing immediacy </st><span class="No-Break"><st c="39679">and relevance.</st></span></li>
				<li><strong class="bold"><st c="39693">Standalone Business Intelligence (BI) tools</st></strong><st c="39737">: Tools such as Tableau, Power BI, or custom-built dashboard solutions can be used to pull data from various sources into a central dashboard. </st><st c="39881">These tools offer powerful data visualization capabilities and can combine data from multiple areas, such as testing, security, and customer feedback, into a </st><span class="No-Break"><st c="40039">comprehensive overview.</st></span></li>
				<li><strong class="bold"><st c="40062">Web-based dashboards</st></strong><st c="40083">: Implementing web-based dashboards using frameworks such as Django (Python), Flask, or Angular, or even JavaScript libraries </st><a id="_idIndexMarker1057"/><st c="40210">such as React, allows for highly customizable and accessible dashboards. </st><st c="40283">These can be accessed via any web browser, providing flexibility and central access to stakeholders across </st><span class="No-Break"><st c="40390">an organization.</st></span></li>
				<li><strong class="bold"><st c="40406">Real-time monitoring dashboards</st></strong><st c="40438">: For metrics that require real-time monitoring, such as security incident detection or live feedback collection, dashboards built on platforms such as Grafana or Kibana can be used. </st><st c="40622">These tools can integrate with databases and monitoring systems to provide live updates </st><span class="No-Break"><st c="40710">and alerts.</st></span></li>
				<li><strong class="bold"><st c="40721">Cloud-based dashboards</st></strong><st c="40744">: Cloud platforms such as Amazon CloudWatch, Google Cloud’s operations suite, or Azure Monitor provide built-in tools to create dashboards that are scalable and accessible from anywhere. </st><st c="40932">These are particularly useful for organizations with cloud-first strategies, offering integrated security </st><span class="No-Break"><st c="41038">and maintenance.</st></span></li>
			</ul>
			<p><st c="41054">By following these processes and considering various architectural approaches for dashboards, organizations can ensure they have effective and efficient ways to monitor, analyze, and act on outcome and progress metrics across different domains. </st><st c="41300">This enhances decision-making, improves strategic alignment, and drives </st><span class="No-Break"><st c="41372">operational efficiency.</st></span></p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor234"/><st c="41395">Sustaining measures of progress and outcomes</st></h1>
			<p><st c="41440">Sustaining </st><a id="_idIndexMarker1058"/><st c="41452">measures of outcomes and progress in an organization is an ongoing process that requires regular evaluation and adjustment, ensuring that metrics remain relevant and effective. </st><st c="41629">Here are some recommended approaches for maintaining, evaluating, updating, and validating </st><span class="No-Break"><st c="41720">these metrics:</st></span></p>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor235"/><st c="41734">Evaluating and deprecating metrics</st></h2>
			<ul>
				<li><strong class="bold"><st c="41769">Regular review cycles</st></strong><st c="41791">: Establish regular intervals (e.g., quarterly or biannually) to</st><a id="_idIndexMarker1059"/><st c="41856"> review the effectiveness and relevance of each metric. </st><st c="41912">These reviews should assess whether the metrics </st><a id="_idIndexMarker1060"/><st c="41960">are still aligned with current business objectives </st><span class="No-Break"><st c="42011">and strategies.</st></span></li>
				<li><strong class="bold"><st c="42026">Performance analysis</st></strong><st c="42047">: Evaluate metrics based on their ability to influence decision-making and business outcomes. </st><st c="42142">If a metric consistently fails to provide actionable insights or drive improvements, it may need to be revised </st><span class="No-Break"><st c="42253">or deprecated.</st></span></li>
				<li><strong class="bold"><st c="42267">Stakeholder feedback</st></strong><st c="42288">: Gather feedback from users of the metrics, such as managers, team leaders, and analysts, to understand their practical utility and any challenges in using them. </st><st c="42452">If metrics are found to be confusing, misaligned, or redundant, consider modifying or </st><span class="No-Break"><st c="42538">removing them.</st></span></li>
				<li><strong class="bold"><st c="42552">Trigger events for deprecation</st></strong><st c="42583">: Define specific criteria or trigger events that would warrant the deprecation of a metric. </st><st c="42677">This could include significant changes in business processes, shifts in strategic focus, or the introduction of new technologies that make older </st><span class="No-Break"><st c="42822">metrics obsolete.</st></span></li>
			</ul>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor236"/><st c="42839">Introducing new metrics</st></h2>
			<ul>
				<li><strong class="bold"><st c="42863">Gap analysis</st></strong><st c="42876">: Regularly</st><a id="_idIndexMarker1061"/><st c="42888"> perform gap analyses to identify areas where existing metrics do not fully cover key performance aspects. </st><st c="42995">This helps to identify the need for </st><span class="No-Break"><st c="43031">new metrics.</st></span></li>
				<li><strong class="bold"><st c="43043">Pilot testing</st></strong><st c="43057">: Before fully implementing new metrics, conduct pilot tests to assess their relevance and effectiveness. </st><st c="43164">This can be done in a controlled segment of an organization to minimize disruption and gather insightful data on a </st><span class="No-Break"><st c="43279">metric’s performance.</st></span></li>
				<li><strong class="bold"><st c="43300">Stakeholder buy-in</st></strong><st c="43319">: Ensure that stakeholders understand the value of new metrics and how they</st><a id="_idIndexMarker1062"/><st c="43395"> contribute to an organization’s goals. </st><st c="43435">This includes training sessions, demonstrations, and discussions on how these metrics help in </st><span class="No-Break"><st c="43529">decision-making processes.</st></span></li>
			</ul>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor237"/><st c="43555">Validating metric implementations</st></h2>
			<ul>
				<li><strong class="bold"><st c="43589">Version management</st></strong><st c="43608">: Treat metrics</st><a id="_idIndexMarker1063"/><st c="43624"> and their definitions as you would any software asset. </st><st c="43680">Use version control systems to manage changes over time. </st><st c="43737">This ensures that any modifications to metrics are well-documented </st><span class="No-Break"><st c="43804">and traceable.</st></span></li>
				<li><strong class="bold"><st c="43818">Regression testing</st></strong><st c="43837">: Each time a metric is updated or a new metric is introduced, perform regression testing to ensure that these changes do not adversely affect the accuracy and reliability of other metrics or the data collection process itself. </st><st c="44066">This is critical to maintaining the integrity of </st><span class="No-Break"><st c="44115">data analytics.</st></span></li>
				<li><strong class="bold"><st c="44130">Continuous validation</st></strong><st c="44152">: Implement continuous validation mechanisms to monitor the performance of metrics. </st><st c="44237">This could involve automated alerts that notify stakeholders when data patterns deviate significantly from historical trends, indicating potential issues with the </st><span class="No-Break"><st c="44400">metric’s implementation.</st></span></li>
				<li><strong class="bold"><st c="44424">Documentation and transparency</st></strong><st c="44455">: Maintain comprehensive documentation for each metric, including its definition, purpose, calculation method, data source, and any changes made over time. </st><st c="44612">This transparency helps build trust in the metrics and facilitates easier onboarding and training of new </st><span class="No-Break"><st c="44717">team members.</st></span></li>
			</ul>
			<p><st c="44730">By following these approaches, organizations can ensure that their outcome and progress metrics remain relevant, reliable, and aligned with their strategic goals. </st><st c="44894">This dynamic approach to metric management helps organizations adapt to changing environments and maintain their competitive edge by making informed, </st><span class="No-Break"><st c="45044">data-driven decisions.</st></span></p>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor238"/><st c="45066">Summary</st></h1>
			<p><st c="45074">This chapter explained the critical role of measuring progress and outcomes within organizations, with a focus on continuous testing, quality, security, and feedback. </st><st c="45242">It began by emphasizing the importance of establishing effective measures to track how well organizations performed and adapted as they grew more complex. </st><st c="45397">The chapter explained the fundamentals of different kinds of measurements, providing a basis for understanding what makes an effective metric and how metrics should align with an </st><span class="No-Break"><st c="45576">organization’s goals.</st></span></p>
			<p><st c="45597">As the chapter progressed, it offered detailed guidance on selecting the right metrics for both outcomes and progress. </st><st c="45717">This section highlighted the importance of distinguishing between metrics that simply provide data and those that can truly drive transformative changes </st><span class="No-Break"><st c="45870">within processes.</st></span></p>
			<p><st c="45887">We then offered practical advice on implementing these metrics through well-designed metrics systems and dashboards. </st><st c="46005">This included how to present data in a way that is actionable and accessible for all stakeholders, enabling them to make informed </st><span class="No-Break"><st c="46135">decisions quickly.</st></span></p>
			<p><st c="46153">The chapter concluded by addressing the sustainability of these measurements. </st><st c="46232">It outlined strategies to maintain their relevance and usefulness over time, ensuring that they continue to support an organization’s evolving needs. </st><st c="46382">The next chapter will build on this by exploring emerging trends in continuous testing, quality, security, and feedback, offering insights into how these areas are likely to evolve and how organizations can adapt to </st><span class="No-Break"><st c="46598">these changes.</st></span></p>
		</div>
	<div id="charCountTotal" value="46612"/>

		<div id="_idContainer123" class="Content">
			<h1 id="_idParaDest-220" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor239"/><st c="0">Part 4: Exploring Future Trends and Continuous Learning</st></h1>
			<p><em class="italic"><st c="56">Part 4</st></em><st c="63"> of this book delves into the evolving landscape of continuous practices in software development. </st><st c="161">This section begins by identifying emerging trends that are reshaping how continuous testing, quality, security, and feedback are integrated within software development frameworks. </st><st c="342">It provides insights into the latest advancements and how they can be leveraged to enhance operational maturity </st><span class="No-Break"><st c="454">in organizations.</st></span></p>
			<p><st c="471">Following the discussion on emerging trends, the book shifts focus to the importance of continuous improvements and learning. </st><st c="598">It outlines effective strategies for fostering an environment of ongoing development and refinement in the areas of testing, quality, security, and feedback. </st><st c="756">This part of the book emphasizes the need for organizations to adapt and evolve continuously to keep pace with technological changes and to maintain a competitive edge in their </st><span class="No-Break"><st c="933">respective industries.</st></span></p>
			<p><st c="955">This part includes the </st><span class="No-Break"><st c="979">following chapters:</st></span></p>
			<ul>
				<li><a href="B21936_13.xhtml#_idTextAnchor240"><em class="italic"><st c="998">Chapter 13</st></em></a><st c="1009">, </st><em class="italic"><st c="1011">Emerging Trends</st></em></li>
				<li><a href="B21936_14.xhtml#_idTextAnchor248"><em class="italic"><st c="1026">Chapter 14</st></em></a><st c="1037">, </st><em class="italic"><st c="1039">Exploring Continuous Learning and Improvement</st></em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer124">
			</div>
		</div>
		<div>
			<div id="_idContainer125" class="Basic-Graphics-Frame">
			</div>
		</div>
	<div id="charCountTotal" value="1084"/></body></html>