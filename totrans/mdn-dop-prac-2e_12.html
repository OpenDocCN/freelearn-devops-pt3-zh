<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer121">
			<h1 id="_idParaDest-317" class="chapter-number"><a id="_idTextAnchor1554"/>12</h1>
			<h1 id="_idParaDest-318"><a id="_idTextAnchor1555"/>Continuous Deployment/Delivery with Argo CD</h1>
			<p>In the previous chapter, we looked at one of the key aspects of modern DevOps – <strong class="bold">continuous integration</strong> (<strong class="bold">CI</strong>). CI is <a id="_idIndexMarker1277"/>the first thing most organizations implement when they embrace DevOps, but things don’t end with CI, which only delivers a tested build in an artifact repository. Instead, we would also want to deploy the artifact to our environments. In this chapter, we’ll implement the next part of the DevOps toolchain – <strong class="bold">continuous </strong><span class="No-Break"><strong class="bold">deployment/delivery</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CD</strong></span><span class="No-Break">).</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>The importance of CD <span class="No-Break">and automation</span></li>
				<li>CD models <span class="No-Break">and tools</span></li>
				<li>The Blog App and its <span class="No-Break">deployment configuration</span><a id="_idTextAnchor1556"/><a id="_idTextAnchor1557"/></li>
				<li>Continuous declarative IaC using an <span class="No-Break">Environment repository</span></li>
				<li>Introduction to <span class="No-Break">Argo CD</span></li>
				<li>Installing and setting up <span class="No-Break">Argo CD</span></li>
				<li>Managing sensitive configurations <span class="No-Break">and secrets</span></li>
				<li>Deploying the sample <span class="No-Break">Blog App</span></li>
			</ul>
			<h1 id="_idParaDest-319"><a id="_idTextAnchor1558"/>Technical requirements</h1>
			<p>In this chapter, we will spin up a cloud-based Kubernetes cluster, <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>), for the exercises. At the time of writing, <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) provides a free $300 trial for 90 days, so you can go ahead and sign up for one <span class="No-Break">at </span><a href="https://console.cloud.google.com/"><span class="No-Break">https://console.cloud.google.com/</span></a><span class="No-Break">.</span></p>
			<p>You will also need to clone the following GitHub repository for some <span class="No-Break">exercises: </span><a href="https://github.com/PacktPublishing/Modern-DevOps-Practices"><span class="No-Break">https://github.com/PacktPublishing/Modern-DevOps-Practices</span></a><span class="No-Break">.</span></p>
			<p>Run the following command to clone the repository into your home directory, and <strong class="source-inline">cd</strong> into the <strong class="source-inline">ch12</strong> directory to access the <span class="No-Break">required resources:</span></p>
			<pre class="console">
$ git clone https://github.com/PacktPublishing/Modern-DevOps-Practices-2e.git \
modern-devops
$ cd modern-devops/ch12</pre>			<p>So, let’s <span class="No-Break">get started!</span><a id="_idTextAnchor1559"/><a id="_idTextAnchor1560"/></p>
			<h1 id="_idParaDest-320"><a id="_idTextAnchor1561"/>The importance of CD and automation</h1>
			<p>CD forms<a id="_idIndexMarker1278"/> the Ops part of your DevOps toolchain. So, while your developer<a id="_idTextAnchor1562"/>s are continuously building and pushin<a id="_idTextAnchor1563"/>g code and your CI pipeline is building, testing, and publishing the builds to your artifact repository, the Ops tea<a id="_idTextAnchor1564"/>m will deploy the build to the test and staging environments. The QA team is the gatekeeper that will ensure that the code meets a certain quality, and only then will the Ops team deploy the code <span class="No-Break">to production.</span></p>
			<p>Now, for organizations <a id="_idIndexMarker1279"/>implementing only the CI part, the rest of the activities are manual. For example, operators will pull the artifacts and run commands to do the deployments manually. Therefore, your deployment’s velocity will depend on the availability of your Ops team to do it. As the deployments are manual, the process is error-prone, and human beings tend to make mistakes in <span class="No-Break">repeatable jobs.</span></p>
			<p>One of the essential principles of modern DevOps is to avoid <strong class="bold">toil</strong>. Toil is<a id="_idIndexMarker1280"/> nothing but repeatable jobs that developers and operators do day in and day out, and all of that toil can be removed by automation. This will help your team focus on the more important things <span class="No-Break">at hand.</span></p>
			<p>With <strong class="bold">continuous delivery</strong>, standard tooling can deploy code to higher environme<a id="_idTextAnchor1565"/>nts based on certain gate conditions. CD pipelines will trigger when a tested build arrives at the artifact repository or, in the case of GitOps, if any changes are detected in the Environment repository. The pipeline then decides, based on a set configuration, where and how to deploy the code. It also establishes whether manual checks are required, such as raising a change ticket and checking whether <span class="No-Break">it’s approved.</span></p>
			<p>While <strong class="bold">continuous deployment</strong> and delivery are often confused with being the same thing, there is a slight difference between them. Continuous delivery enables your team to deliver tested code in your environment based on a human trigger. So, while you don’t have to do anything more than click a button to do a deployment to production, it would still be initiated by someone at a convenient time (a maintenance window). Continuous deployments go a step further when they integrate with the CI process and will start the deployment process as soon as a new tested build is available for them to consume. There is no need for manual intervention, and continuous deployment will only stop in case of a <span class="No-Break">failed test.</span></p>
			<p>The monitor<a id="_idTextAnchor1566"/>ing tool <a id="_idIndexMarker1281"/>forms the next part of the DevOps toolchain. The Ops team can learn from managing their production environment and provide developers with feedback regarding what they need to do better. <a id="_idTextAnchor1567"/>That feedback ends up in the development backlog, and they can deliver it as features in future releases. That completes the cycle, and now you have your team churning out a technology <span class="No-Break">product continuously.</span></p>
			<p>CD offers several<a id="_idIndexMarker1282"/> advantages. Some of them are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Faster time to market</strong>: CD and CI reduce the time it takes to deliver new features, enhancements, and bug fixes to end users. This agility can give your organization a competitive edge by allowing you to respond quickly to <span class="No-Break">market demands.</span></li>
				<li><strong class="bold">Reduced risk</strong>: By automating the deployment process and frequently pushing small code changes, you minimize the risk of large, error-prone deployments. Bugs and issues are more likely to be caught early, and rollbacks can be <span class="No-Break">less complex.</span></li>
				<li><strong class="bold">Improved code quality</strong>: Frequent automated testing and quality checks are an integral part of CD and CI. This results in higher code quality as developers are encouraged to write cleaner, more maintainable code. Any issues are caught and addressed sooner in the <span class="No-Break">development process.</span></li>
				<li><strong class="bold">Enhanced collaboration</strong>: CD and CI encourage collaboration between development and operations teams. It breaks down traditional silos and encourages cross-functional teamwork, leading to better communication <span class="No-Break">and understanding.</span></li>
				<li><strong class="bold">Efficiency and productivity</strong>: Automation of repetitive tasks, such as testing, building, and<a id="_idIndexMarker1283"/> deployment, frees up developers’ time to focus on more valuable tasks, such as creating new features <span class="No-Break">and improvements.</span></li>
				<li><strong class="bold">Customer feedback</strong>: CD allows you to gather feedback from real users more quickly. By deploying small changes frequently, you can gather user feedback and adjust your development efforts accordingly, ensuring that your product better meets <span class="No-Break">user needs.</span></li>
				<li><strong class="bold">Continuous improvement</strong>: CD promotes a culture of continuous improvement. By analyzing data on deployments and monitoring, teams can identify areas for enhancement and iterate on <span class="No-Break">their processes.</span></li>
				<li><strong class="bold">Better security</strong>: Frequent updates mean that security vulnerabilities can be addressed promptly, reducing the window of opportunity for attackers. Security checks can be automated and integrated into the <span class="No-Break">CI/CD pipeline.</span></li>
				<li><strong class="bold">Reduced manual intervention</strong>: CD minimizes the need for manual intervention in the deployment process. This reduces the potential for human error and streamlines the <span class="No-Break">release process.</span></li>
				<li><strong class="bold">Scalability</strong>: As your product grows and the number of developers and your code base complexity increases, CD can help maintain a manageable development process. It scales effectively by automating many of the release and <span class="No-Break">testing processes.</span></li>
				<li><strong class="bold">Cost savings</strong>: Although implementing CI/CD requires an initial investment in tools and processes, it can lead to cost savings in the long run by reducing the need for extensive manual testing, lowering deployment-related errors, and improving <span class="No-Break">resource utilization.</span></li>
				<li><strong class="bold">Compliance and auditing</strong>: For organizations with regulatory requirements, CD can improve compliance by providing a detailed history of changes and deployments, making<a id="_idIndexMarker1284"/> it easier to track and audit <span class="No-Break">code changes.</span></li>
			</ul>
			<p>It’s important to note that while CD and CI offer many advantages, they also require careful planning, infrastructure, and cultural changes to <span class="No-Break">be effective.</span></p>
			<p>There are several models and tools available to implement CD. We’ll have a look at some of them in the <span class="No-Break">next s<a id="_idTextAnchor1568"/><a id="_idTextAnchor1569"/>ection.</span></p>
			<h1 id="_idParaDest-321"><a id="_idTextAnchor1570"/>CD models and tools</h1>
			<p>A typical <a id="_idIndexMarker1285"/>CI/CD <a id="_idTextAnchor1571"/>workflow <a id="_idIndexMarker1286"/>looks as described in the following figure and the <span class="No-Break">subsequent<a id="_idTextAnchor1572"/> steps:</span></p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/B19877_12_1.jpg" alt="Figure 12.1 – CI/CD workflow" width="1630" height="920"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.1 – CI/CD workflow</p>
			<ol>
				<li>Your developers write code and push it to a code repository (typically a <span class="No-Break">Git repository).</span></li>
				<li>Your CI tool builds the code, runs a series of tests, and pushes the tested build to an artifact repository. Your CD tool then picks up the artifact and deploys it to your test and staging environments. Based on whether you want to do continuous deployment or delivery, it automatically deploys the artifact to the <span class="No-Break">production environment.</span></li>
			</ol>
			<p>Well, what do you choose for a delivery tool? Let’s look at the example we covered in <a href="B19877_11.xhtml#_idTextAnchor1412"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Continuous Integration</em>. We picked up the <strong class="bold">posts</strong> microservice app and used a CI tool such as GitHub Actions/Jenkins that uses <strong class="bold">Docker</strong> to <a id="_idIndexMarker1287"/>create a container out of it and push it to <a id="_idIndexMarker1288"/>our <strong class="bold">Docker Hub</strong> container registry. Well, we could have used the same tool for <a id="_idIndexMarker1289"/>deploying to <span class="No-Break">our environment.</span></p>
			<p>For exa<a id="_idTextAnchor1573"/>mple, if <a id="_idIndexMarker1290"/>we wanted to deploy to <strong class="bold">Kubernetes</strong>, it <a id="_idIndexMarker1291"/>would have been a simple YAML update and <strong class="source-inline">kubectl apply</strong>. We could easily do this with any of those tools, but we chose not to do it. Why? The answer is simple – CI tools are meant for CI, and if you want to use them for anything else, you’ll get stuck at a certain point. That does not mean that you cannot use these tools for CD. It will only suit a few use cases based on the deployment model <span class="No-Break">you follow.</span></p>
			<p>Several deployment models exist based on your application, technology stack, customers, risk appetite, and cost consciousness. Let’s look at some of the popular deployment models that are used within <a id="_idTextAnchor1574"/><a id="_idTextAnchor1575"/><span class="No-Break">the industry.</span></p>
			<h2 id="_idParaDest-322"><a id="_idTextAnchor1576"/>Simple deployment model</h2>
			<p>The <strong class="bold">simple deployment model</strong> is one<a id="_idIndexMarker1292"/> of the most straightforward of all: you deplo<a id="_idTextAnchor1577"/>y the required v<a id="_idTextAnchor1578"/>ersion of your application after removing the<a id="_idIndexMarker1293"/> old one. It completely replaces the previous version, and rolling back involves redeploying the older version after removing the<a id="_idTextAnchor1579"/> <span class="No-Break">deployed one:</span></p>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/B19877_12_2.jpg" alt="Figure 12.2 – Simple deployment model" width="1464" height="813"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.2 – Simple deployment mo<a id="_idTextAnchor1580"/>del</p>
			<p>As it is a<a id="_idIndexMarker1294"/> simple way of deploying things, you can<a id="_idIndexMarker1295"/> manage this using a CI tool such as <strong class="bold">Jenkins</strong> or <strong class="bold">GitHub Actions</strong>. However, the s<a id="_idTextAnchor1581"/>imple deployment model is not the most desired d<a id="_idTextAnchor1582"/>eployment <a id="_idIndexMarker1296"/>method because of some inherent risks. This <a id="_idTextAnchor1583"/>kind of change is disruptive and <a id="_idIndexMarker1297"/>typically needs do<a id="_idTextAnchor1584"/>wntime. This means your service would remain unavailable to your customers for the upgrade period. <a id="_idTextAnchor1585"/>It might be OK for organizations that do not have users 24/7, but disruptions eat <a id="_idIndexMarker1298"/>into the <strong class="bold">service-level objectives</strong><strong class="bold"> </strong>(<strong class="bold">SLOs</strong>) and <strong class="bold">service-level agreemen<a id="_idTextAnchor1586"/>ts</strong> (<strong class="bold">SLAs</strong>) of global organizations. Even<a id="_idIndexMarker1299"/> if there isn’t one, they hamper customer experience and the <span class="No-Break">organization’s reputation.</span></p>
			<p>Therefore, to manage such kinds of situations, we have some comple<a id="_idTextAnchor1587"/><a id="_idTextAnchor1588"/>x <span class="No-Break">deployment models.</span></p>
			<h2 id="_idParaDest-323"><a id="_idTextAnchor1589"/>Complex deployment models</h2>
			<p><strong class="bold">Complex deployment models</strong>, unlike simple deployment models, try to <a id="_idTextAnchor1590"/>minimize disru<a id="_idTextAnchor1591"/>ptions<a id="_idIndexMarker1300"/> and downtimes within the application<a id="_idIndexMarker1301"/> and make rolling out releases more seamless to the extent that most users don’t even notice when the upgrade is being conducted. Two main kinds of complex deployments are prevalent in the industry; let’s take <span class="No-Break">a look.</span></p>
			<h3>Blue/Green deployments</h3>
			<p><strong class="bold">Blue/Green deployments</strong> (also known as <strong class="bold">Red/Black deployments</strong>) roll out the new version (<em class="italic">Green</em>) in<a id="_idIndexMarker1302"/> addition<a id="_idIndexMarker1303"/> to the existing version (<em class="italic">Blue</em>). You can t<a id="_idTextAnchor1592"/>hen do sanity checks and <a id="_idIndexMarker1304"/><a id="_idTextAnchor1593"/>other activities with the late<a id="_idTextAnchor1594"/>st version to ensure that everything is good to<a id="_idTextAnchor1595"/> go. Then, you can switch traffic from the old to the new version and monitor for any issues. If you encounter problems, you switch back traffic to the old version. Otherwise, you keep the latest version running and<a id="_idTextAnchor1596"/> remove the <span class="No-Break">old version:</span></p>
			<div>
				<div id="_idContainer106" class="IMG---Figure">
					<img src="image/B19877_12_3.jpg" alt="Figure 12.3 – Blue/Green deployments" width="1554" height="658"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.3 – Blue/Green deployments</p>
			<p>You can take Blue/Green deployments to the next level using <span class="No-Break">canary deployments.</span></p>
			<h3>Canary deployments and A/B testing</h3>
			<p><strong class="bold">Canary<a id="_idTextAnchor1597"/> deployments</strong> are similar to Blue/Green deployments but ar<a id="_idTextAnchor1598"/>e generally utilized<a id="_idIndexMarker1305"/> for risky <a id="_idIndexMarker1306"/>upgrades. So, like <a id="_idTextAnchor1599"/>Blue/Green deployments,<a id="_idTextAnchor1600"/> we deploy the new version alongside the existing one. Instead of switching all traffic to the latest version at once, we only switch traffic to a small subset of users. As we do that, we can understand from our logs and user behaviors whether the<a id="_idIndexMarker1307"/> switchover is<a id="_idIndexMarker1308"/> causing any issues. This is called <strong class="bold">A/B testing</strong>. When we do A/B testing, we can target a specific group of users based on location, l<a id="_idTextAnchor1601"/>anguage, age group, or users who have opted to test Beta versions of a product. That will help organizations gather feedback without disru<a id="_idTextAnchor1602"/>pting general users and make changes to the pr<a id="_idTextAnchor1603"/>oduct once they’re satisfied with what they a<a id="_idTextAnchor1604"/>re rolling out. You can make the release generally available by switching over the total traffic to the new version and gett<a id="_idTextAnchor1605"/>ing rid of the <span class="No-Break">old version:</span></p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B19877_12_4.jpg" alt="Figure 12.4 – Canary deployments" width="1627" height="741"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.4 – Canary deployments</p>
			<p>While complex<a id="_idIndexMarker1309"/> deployments cause the least disruption to users, they are generally complex to manage using traditional<a id="_idIndexMarker1310"/> CI tools such as Jenkins. Therefor<a id="_idTextAnchor1606"/>e, we need to get the<a id="_idTextAnchor1607"/> tooling right on it. S<a id="_idTextAnchor1608"/>everal CD tools <a id="_idIndexMarker1311"/>are available in the <a id="_idIndexMarker1312"/>market, including <strong class="bold">Argo CD</strong>, <strong class="bold">Spinnaker</strong>, <strong class="bold">Circle CI</strong>, and <strong class="bold">AWS Code Deploy</strong>. As <a id="_idIndexMarker1313"/>this entire book is focused on GitOps, and Argo CD i<a id="_idTextAnchor1609"/>s a GitOps native tool, for this chapter, we will focus on Argo CD. Before we delve into deploying the application, let’s revisit what we want <span class="No-Break">to deploy.</span></p>
			<h1 id="_idParaDest-324"><a id="_idTextAnchor1610"/>The Blog App and its deployment configuration</h1>
			<p>Since we discussed the<a id="_idIndexMarker1314"/> Blog App in the last chapter, let’s look at the services and their <span class="No-Break">interactions again:</span></p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B19877_12_5.jpg" alt="Figure 12.5 – The Blog App and its services and interactions" width="1628" height="488"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.5 – The Blog App and its services and interactions</p>
			<p>So far, we’ve <a id="_idIndexMarker1315"/>created CI pipelines for building, testing, and pushing our Blog App microservice containers. These microservices need to run somewhere. So, we need an environment for this. We will deploy the application<a id="_idIndexMarker1316"/> in a <strong class="bold">GKE</strong> cluster; for that, we will need a Kubernetes YAML manifest. We built the container for the <strong class="source-inline">posts</strong> microservice as an example in the previous chapter, and I also left building the rest of the services as an exercise for you. Assuming you’ve built them, we will need the following resources for the application to <span class="No-Break">run seamlessly:</span></p>
			<ul>
				<li><strong class="bold">MongoDB</strong>: We<a id="_idIndexMarker1317"/> will deploy an auth-enabled MongoDB database with root credentials. The credentials will be injected via environment variables sourced from a Kubernetes <strong class="bold">Secret</strong> resource. We also need to persist our database data, so for that, we<a id="_idIndexMarker1318"/> need a <strong class="bold">PersistentVolume</strong> mounted to the container, which we will provision dynamically using<a id="_idIndexMarker1319"/> a <strong class="bold">PersistentVolumeClaim</strong>. As the container is stateful, we will use a <strong class="bold">StatefulSet</strong> to manage it and, therefore, a headless <strong class="bold">Service</strong> to expose <span class="No-Break">the database.</span></li>
				<li><strong class="bold">Posts</strong>, <strong class="bold">reviews</strong>, <strong class="bold">ratings</strong>, <strong class="bold">and</strong> <strong class="bold">users</strong>: The <strong class="source-inline">posts</strong>, <strong class="source-inline">reviews</strong>, <strong class="source-inline">ratings</strong>, <strong class="source-inline">and</strong> <strong class="source-inline">users</strong> microservices will interact with MongoDB through the root credentials injected via environment variables sourced from the same <strong class="bold">Secret</strong> as MongoDB. We will deploy them using their respective <strong class="bold">Deployment</strong> resources and expose all of them via<a id="_idIndexMarker1320"/> individual <span class="No-Break"><strong class="bold">ClusterIP Services</strong></span><span class="No-Break">.</span></li>
				<li><strong class="bold">Frontend</strong>: The <em class="italic">frontend</em> microservice <a id="_idIndexMarker1321"/>does not need to interact with MongoDB, so there will be no interaction with the Secret resource. We will also deploy this service using a <strong class="bold">Deployment</strong> resource. As we want to expose the service on the internet, we will <a id="_idIndexMarker1322"/>create a <strong class="bold">LoadBalancer Service</strong> <span class="No-Break">for it.</span></li>
			</ul>
			<p>We can summarize these aspects with the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B19877_12_6.jpg" alt="Figure 12.6 – The Blog App – Kubernetes resources and interactions" width="1639" height="1365"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.6 – The Blog App – Kubernetes resources and interactions</p>
			<p>Now, as we’re <a id="_idIndexMarker1323"/>following the GitOps model, we need to store the manifests of all the resources on Git. However, since Kubernetes Secrets are not inherently secure, we cannot store their manifests directly on Git. Instead, we will use another resource <a id="_idIndexMarker1324"/>called <strong class="bold">SealedSecrets</strong> to manage <span class="No-Break">this securely.</span></p>
			<p>In <a href="B19877_02.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Source Code Management with Git and GitOps</em>, we discussed application and environment repositories forming the fundamental building blocks of GitOps-based CI and CD, respectively. In the previous chapter, we created an application repository on GitHub and used GitHub Actions (and Jenkins) to build, test, and push our application container to Docker Hub. As CD focuses on the Ops part of DevOps, we will need <a id="_idIndexMarker1325"/>an <strong class="bold">Environment repository</strong> to implement it, so let’s go ahead and create our E<a id="_idTextAnchor1611"/>nvironment repository in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-325"><a id="_idTextAnchor1612"/>Continuous declarative IaC using an Environment repository</h1>
			<p>As we<a id="_idIndexMarker1326"/> know by now, we must create a GKE cluster to host our microservices. So far, we’ve been using <strong class="source-inline">gcloud</strong> commands<a id="_idIndexMarker1327"/><a id="_idTextAnchor1613"/> to do this; however, because <strong class="source-inline">gcloud</strong> commands are not declarative, using them is not ideal when implementing GitOps. Instead, we’ll use <strong class="bold">Terraform</strong> to<a id="_idIndexMarker1328"/> create the GKE cluster for us. This will ensure we can deploy and manage the cluster declaratively using a Git Environment repository. So, let’s go ahead and <span class="No-Break">create one.</span></p>
			<h2 id="_idParaDest-326"><a id="_idTextAnchor1614"/>Creating and setting up our Environment repository</h2>
			<p>Navigate <a id="_idIndexMarker1329"/>to <a href="https://github.com">https://github.com</a> and create a repository using a <a id="_idIndexMarker1330"/>name of your choice. For this exercise, we will use <strong class="source-inline">mdo-environments</strong>. Once you have done that, navigate to Google Cloud Shell, generate a <strong class="source-inline">ssh-key</strong> pair using the <strong class="source-inline">ssh-keygen</strong> command, copy the public key to GitHub (refer to <a href="B19877_02.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 2</em></span></a><em class="italic">, Source Code Management with Git and GitOps</em>, for step-by-step instructions), and clone the repository using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cd ~
$ git clone https://github.com/PacktPublishing/Modern-DevOps-Practices-2e.git \
modern-devops
$ git clone git@github.com:&lt;your_account&gt;/mdo-environments.git
$ cd mdo-environments</pre>			<p>Let’s copy a <strong class="source-inline">.gitignore</strong> file for Terraform to ensure that we do not unexpectedly check in Terraform state, backend, or <strong class="source-inline">.tfvars</strong> files by using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ cp -r ~/modern-devops/ch12/.gitignore .</pre>			<p>Now, let’s push this code to GitHub using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ git add --all
$ git commit -m 'Added gitignore'
$ git push</pre>			<p>Now that <a id="_idIndexMarker1331"/>we’ve pushed our first file and initialized our repository, let’s structure our repository according to our environments. We will have two branches withi<a id="_idTextAnchor1615"/>n the Environment repository – <strong class="bold">dev</strong> and <strong class="bold">prod<a id="_idTextAnchor1616"/></strong>. All configurations in <a id="_idIndexMarker1332"/>the <strong class="bold">dev</strong> branch will apply to the <strong class="bold">develo<a id="_idTextAnchor1617"/>pment environment</strong>, and those<a id="_idIndexMarker1333"/> on <strong class="bold">prod</strong> will apply to the <strong class="bold">production environment</strong>. The follo<a id="_idTextAnchor1618"/>wing diagram illustrates this approach <span class="No-Break">in detail:</span></p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B19877_12_7.jpg" alt="Figure 12.7 – CD process" width="1641" height="1075"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.7 – CD process</p>
			<p>The existing repository has a single branch called <strong class="source-inline">m<a id="_idTextAnchor1619"/>aster</strong>. Howeve<a id="_idTextAnchor1620"/>r, since we will be managing multiple environments in this repository, it would be good to rename the <strong class="source-inline">master</strong> branch <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">prod</strong></span><span class="No-Break">.</span></p>
			<p>Go to <strong class="source-inline">https://github.com/&lt;your_user&gt;/mdo-environments/branches</strong> and click the pencil icon beside <strong class="bold">master</strong>. Type in <strong class="source-inline">prod</strong> and click on <span class="No-Break"><strong class="bold">Rename Branch</strong></span><span class="No-Break">.</span></p>
			<p>Now that <a id="_idIndexMarker1334"/>we’ve renamed the branch, let’s remove the existing local repository and clone the repository again using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cd ~ &amp;&amp; rm -rf mdo-environments
$ git clone git@github.com:&lt;your_account&gt;/mdo-environments.git
$ cd mdo-environments</pre>			<p>We want to start with the dev environment, so it will be good to create a branch called <strong class="source-inline">dev</strong> from the <strong class="source-inline">prod</strong> branch. Run the following command to <span class="No-Break">do so:</span></p>
			<pre class="console">
$ git branch dev &amp;&amp; git checkout dev</pre>			<p>Now, we can start writing the Terraform configuration within this directory. The configuration is available in <strong class="source-inline">~/modern-devops/ch12/mdo-environments/environments</strong>. Copy everything from that directory to the current directory using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cp -r ~/modern-devops/ch12/environments/terraform .
$ cp -r ~/modern-devops/ch12/environments/.github .</pre>			<p>Within the <strong class="source-inline">terraform</strong> directory, the<a id="_idTextAnchor1621"/>re are several <span class="No-Break">Terraform files.</span></p>
			<p>The <strong class="source-inline">cluster.tf</strong> file <a id="_idTextAnchor1622"/>contains the configuration to create the Kubernetes cluster. It looks <span class="No-Break">like this:</span></p>
			<pre class="console">
resource "google_service_account" "main" {
  account_id   = "gke-${var.cluster_name}-${var.branch}-sa"
  display_name = "GKE Cluster ${var.cluster_name}-${var.branch} Service Account"
}
resource "google_container_cluster" "main" {
  name               = "${var.cluster_name}-${var.branch}"
  location           = var.location
  initial_node_count = 3
  node_config {
    service_account = google_service_account.main.email
    oauth_scopes = [
      "https://www.googleapis.com/auth/cloud-platform"
    ]
  }
  timeouts {
    create = "30m"
    update = "40m"
  }
}</pre>			<p>It creates two <a id="_idIndexMarker1335"/>resources – a <strong class="bold">service account</strong> and a three-<a id="_idTextAnchor1623"/>node <strong class="bold">GKE instance</strong> that <a id="_idIndexMarker1336"/>uses the<a id="_idIndexMarker1337"/> service account with the <strong class="source-inline">cloud platform</strong> <span class="No-Break"><strong class="bold">OAuth scope</strong></span><span class="No-Break">.</span></p>
			<p>We name <a id="_idIndexMarker1338"/>the service account with a combination of the <strong class="source-inline">cluster_name</strong> and <strong class="source-inline">branch</strong> variables. This is necessary as we need to distinguish clusters between environments. So, if the cluster name is <strong class="source-inline">mdo-cluster</strong> and the Git branch is <strong class="source-inline">dev</strong>, we will have a service account called <strong class="source-inline">gke-mdo-cluster-dev-sa</strong>. We will use the same naming convention on the GKE cluster. Therefore, the cluster’s name would <span class="No-Break">be </span><span class="No-Break"><strong class="source-inline">mdo-cluster-dev</strong></span><span class="No-Break">.</span></p>
			<p>We have a <strong class="source-inline">provider.tf</strong> file that conta<a id="_idTextAnchor1624"/>ins the <strong class="source-inline">provider</strong> and <strong class="source-inline">backend</strong> configuration. We’re using a <a id="_idTextAnchor1625"/>remote backend here as we want to persist the <a id="_idTextAnchor1626"/>Terraform state remotely. In this<a id="_idIndexMarker1339"/> scenario, we will use a <strong class="bold">Google Cloud Storage</strong> (<strong class="bold">GCS</strong>) <strong class="bold">bucket</strong>. The <strong class="source-inline">provider.tf</strong> file looks <span class="No-Break">like this:</span></p>
			<pre class="console">
provider "google" {
  project     = var.project_id
  region      = "us-central1"
  zone        = "us-central1-c"
}
terraform {
  backend "gcs" {
    prefix  = "mdo-terraform"
  }
}</pre>			<p>Here, we’ve <a id="_idIndexMarker1340"/>specified our default <strong class="source-inline">region</strong> and <strong class="source-inline">zone</strong> within the <strong class="source-inline">provider</strong> config. Additionally, we’ve declared the <strong class="source-inline">gcs</strong> backend, which only contains the <strong class="source-inline">prefix</strong> attribute with a value of <strong class="source-inline">mdo-terraform</strong>. We can separate configurations using the prefixes to store multiple Terraform states in a single bucket. We have purposefully not supplied the <strong class="source-inline">bucket</strong> name, which we will do at runtime using <strong class="source-inline">-backend-config</strong> during <strong class="source-inline">terraform init</strong>. The bucket name will <span class="No-Break">be </span><span class="No-Break"><strong class="source-inline">tf-state-mdo-terraform-&lt;PROJECT_ID&gt;</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">As GCS buckets should have a globally unique name, it is good to use something such as <strong class="source-inline">tf-state-mdo-terraform-&lt;PROJECT_ID&gt;</strong> as the project ID is <span class="No-Break">globally unique.</span></p>
			<p>We also have the <strong class="source-inline">variables.tf</strong> file, which declares the <strong class="source-inline">project_id</strong>, <strong class="source-inline">branch</strong>, <strong class="source-inline">cluster_name</strong>, and <strong class="source-inline">location</strong> variables, <span class="No-Break">as follows:</span></p>
			<pre class="console">
variable project_id {}
variable branch {...
  default     = "dev"
}
variable cluster_name {...
  default   = "mdo-cluster"
}
variable "location" {...
  defau<a id="_idTextAnchor1627"/>lt     = "us-central1-a"
}</pre>			<p>Now that we<a id="_idIndexMarker1341"/> have the Terraform configuration ready, we need a workflow file that can be applied to our<a id="_idTextAnchor1628"/> GCP project. For that, we’ve created the following GitHub Actions workflow file – that <span class="No-Break">is, </span><span class="No-Break"><strong class="source-inline">.github/workflows/create-cluster.yml</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
name: Create Kubernetes Cluster
on: push
jobs:
  deploy-terraform:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./terraform
    steps:
    - uses: actions/checkout@v2
    - name: Install Terraform
      id: install-terraform
      run: wget -O terraform.zip https://releases.hashicorp.com/terraform/1.5.5/
terraform_1.5.5_linux_amd64.zip &amp;&amp; unzip terraform.zip &amp;&amp; chmod +x terraform &amp;&amp; sudo mv 
terraform /usr/local/bin
    - name: Apply Terraform
      id: apply-terraform
      run: terraform init -backend-config="bucket=tf-state-mdo-terraform-${{ secrets.
PROJECT_ID }}" &amp;&amp; terraform workspace select ${GITHUB_REF##*/} ||  terraform workspace new 
${GITHUB_REF##*/} &amp;&amp; terraform apply -auto-approve -var="project_id=${{ secrets.PROJECT_
ID  }}" -var="branch=${GITHUB_REF##*/}"
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}</pre>			<p>This is a <a id="_idIndexMarker1342"/>two-step build file. The first step installs Terraform, while the second step applies the Terraform configuration. Apart from that, we’ve specified <strong class="source-inline">./terraform</strong> as the working directory at the global level. Additionally, we’re using a few secrets in this file, namely <strong class="source-inline">GCP_CREDENTIALS</strong>, which is the key file of the service account that Terraform uses to authenticate and authorize the GCP API, and the Google <span class="No-Break">Cloud </span><span class="No-Break"><strong class="source-inline">PROJECT_ID</strong></span><span class="No-Break">.</span></p>
			<p>We’ve also supplied the bucket name as <strong class="source-inline">tf-state-mdo-terraform-${{ secrets.PROJECT_ID }}</strong> to ensure that we have a unique <span class="No-Break">bucket name.</span></p>
			<p>As we’ve used Terraform workspaces to manage multiple environments, the preceding code selects an existing Terraform workspace with the branch name denoted by <strong class="source-inline">${GITHUB_REF##*/}</strong> or creates a new one. Workspaces are important here as we<a id="_idTextAnchor1629"/> want to use the same configuration with different variable values for different environments. The Terraform workspaces correspond to environments, and environments correspond to the Git branch. So, as we have the <strong class="source-inline">dev</strong> and <strong class="source-inline">prod</strong> environments, we have the correspondin<a id="_idTextAnchor1630"/>g Terraform workspaces and <span class="No-Break">Git branches.</span></p>
			<p>F<a id="_idTextAnchor1631"/>rom the Terraform and workflow configuration, we can deduce that we will need <span class="No-Break">the following:</span></p>
			<ul>
				<li>A <strong class="bold">service account</strong> for<a id="_idIndexMarker1343"/> Terraform to authenticate and authorize the GCP API and a JSON key file that we need to add as a <span class="No-Break">GitHub secret</span></li>
				<li>The <strong class="bold">project ID</strong> that<a id="_idIndexMarker1344"/> we’ll configure as a <span class="No-Break">GitHub secret</span></li>
				<li>A <strong class="bold">GCS bucket</strong> that<a id="_idIndexMarker1345"/> we’ll use as a backend <span class="No-Break">for Terraform</span></li>
			</ul>
			<p>So, let’s go ahead and create a service account within GCP so that Terraform can use it to authenticate and authorize with the Google APIs. Use<a id="_idTextAnchor1632"/> the following commands to create the service account, provide <a id="_idIndexMarker1346"/>relevant <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) permissions, and download the <span class="No-Break">credentials file:</span></p>
			<pre class="console">
$ PROJECT_ID=&lt;project_id&gt;
$ gcloud iam service-accounts create terraform \
--description="Service Account for terraform" \
--display-name="Terraform"
$ gcloud projects add-iam-policy-binding $PROJECT_ID \
--member="serviceAccount:terraform@$PROJECT_ID.iam.gserviceaccount.com" \
--role="roles/editor"
$ gcloud iam service-accounts keys create key-file \
--iam-account=terraform@$PROJECT_ID.iam.gserviceaccount.com</pre>			<p>You will see<a id="_idIndexMarker1347"/> a file called <strong class="source-inline">key-file</strong> within your working directory. Now, navigate to <strong class="source-inline">https://github.com/&lt;your_github_user&gt;/mdo-environments/settings/secrets/actions/new</strong> and create a secret named <strong class="source-inline">GCP_CREDENTIALS</strong>. For the value, print the <strong class="source-inline">key-file</strong> file, copy its contents, and paste it into the <strong class="bold">values</strong> field of the <span class="No-Break">GitHub secret.</span></p>
			<p>Next, create another secret, <strong class="source-inline">PROJECT_ID</strong>, and specify you<a id="_idTextAnchor1633"/>r GCP project ID within the <span class="No-Break"><strong class="bold">values</strong></span><span class="No-Break"> field.</span></p>
			<p>The next thing we need to do is create a GCS bucket for Terraform to use as a remote backend. To do this, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ gsutil mb<a id="_idTextAnchor1634"/> gs://tf-state-mdo-terraform-${PROJECT_ID}</pre>			<p>Additionally, we need to enable the GCP APIs that Terraform will use to create the resources. To do this, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ gcloud services enable iam.googleapis.com container.googleapis.com</pre>			<p>So, now that all the prerequisites have been met, we can push our code to the repository. Run the following commands to <span class="No-Break">do this:</span></p>
			<pre class="console">
$ git add --all
$ git commit -m 'Initial commit'
$ git push --set-upstream origin dev</pre>			<p>As soon as we push<a id="_idIndexMarker1348"/> the code, we’ll see that the GitHub Actions workflow has been triggered. Soon, the workflow will apply the configuration an<a id="_idTextAnchor1635"/>d create the Kubernetes cluster. This should appear <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B19877_12_8.jpg" alt="Figure 12.8 – GitOps with GitHub Actions and Terraform" width="1080" height="653"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.8 – GitOps with GitHub Actions and Terraform</p>
			<p>To verify whether the cluster has been created successfully, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ gcloud container clusters list
NAME: mdo-cluster-dev
LOCATION: us-central1-a
MASTER_VERSION: 1.27.3-gke.100
MASTER_IP: x.x.x.x
MACHINE_TYPE: e2-medium
NODE_VERSION: 1.27.3-gke.100
NUM_NODES: 3
STATUS: RUNNING</pre>			<p>As you can see, the <strong class="source-inline">mdo-cluster-dev</strong> cluster is running successfully in the environment. If<a id="_idTextAnchor1636"/> <a id="_idIndexMarker1349"/>we make any changes to the Terraform configuration, the changes will automatically be applied. We’ve successfully created our Environment using an Environment repository. That is the <em class="italic">push model GitOps</em> in action for you. Now, we need to run our application in the environment; to manage and deploy the application, we will need a dedicated CD tool. As state<a id="_idTextAnchor1637"/><a id="_idTextAnchor1638"/>d previously, we will use Argo CD for this, so let’s look <span class="No-Break">at it.</span></p>
			<h1 id="_idParaDest-327"><a id="_idTextAnchor1639"/>Introduction to Argo CD</h1>
			<p>Argo CD is<a id="_idIndexMarker1350"/> an open source, declarative, GitOps-based CD tool designed to automate deploying and managing applications and infrastructure on Kubernetes clusters. Argo CD serves as a robust application controller, efficiently managing and ensuring the smooth and secure operation of your applications. Argo CD works in the <em class="italic">pull-based GitOps model</em> and, therefore, polls the Environment repository regularly to detect any configuration drift. Suppose it finds any drift between the state in Git and the actual state of applications running in the environment. In that case, it will make corrective changes to reflect the desired configuration declared in the <span class="No-Break">Git repository.</span></p>
			<p>Argo CD is tailored explicitly to Kubernetes environments, making it a popular choice for managing applications on <span class="No-Break">Kubernetes clusters.</span></p>
			<p>In addition to the traditional Kubernetes manifest YAML files, Argo CD offers support for various alternative methods of defining <span class="No-Break">Kubernetes configurations:</span></p>
			<ul>
				<li><span class="No-Break">Helm charts</span></li>
				<li><span class="No-Break">Kustomize</span></li>
				<li><span class="No-Break">Ksonnet</span></li>
				<li><span class="No-Break">Jsonnet files</span></li>
				<li>Plain YAML/JSON <span class="No-Break">manifest files</span></li>
				<li>Integration with other customized configuration management tools <span class="No-Break">through plugins</span></li>
			</ul>
			<p>Within Argo CD, you <a id="_idIndexMarker1351"/>can define applications encompassing both a <em class="italic">source</em> and a <em class="italic">target</em>. The source specifies details about the associated Git repository, the location of the manifests, helm charts, or kustomize files, and then applies these configurations to designated target environments. This empowers you to monitor changes within a specific branch, tag, or watch particular versions within your Git repository. Diverse tracking strategies are also at <span class="No-Break">your disposal.</span></p>
			<p>You can access a user-friendly web-based UI<a id="_idIndexMarker1352"/> and a <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) to interact with Argo CD. Moreover, Argo CD facilitates reporting on the application’s status via sync hooks and app actions. If any modifications are made directly within the cluster that deviate from the GitOps approach, Argo CD can promptly notify your team, perhaps through a <span class="No-Break">Slack channel.</span></p>
			<p>The following diagram <a id="_idIndexMarker1353"/>provides an overview of the Argo <span class="No-Break">CD architecture:</span></p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B19877_12_9.jpg" alt="Figure 12.9 – Argo CD architecture" width="1645" height="1573"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.9 – Ar<a id="_idTextAnchor1640"/>go CD arc<a id="_idTextAnchor1641"/>hitecture</p>
			<p>So, without fu<a id="_idTextAnchor1642"/><a id="_idTextAnchor1643"/><a id="_idTextAnchor1644"/>rther ado, let’s<a id="_idIndexMarker1354"/> spin up <span class="No-Break">Argo CD.</span></p>
			<h1 id="_idParaDest-328"><a id="_idTextAnchor1645"/>Installing and setting up Argo CD</h1>
			<p>Installing<a id="_idIndexMarker1355"/> Argo CD is simple – we need to apply the <strong class="source-inline">install.yaml</strong> manifest bundle that’s available online at <a href="https://github.com/argoproj/argo-cd/blob/master/manifests/install.yaml">https://github.com/argoproj/argo-cd/blob/master/manifests/install.yaml</a> on the Kubernetes cluster where we wish to install it. For a more customized installation, you can refer <span class="No-Break">to </span><a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/installation/"><span class="No-Break">https://argo-cd.readthedocs.io/en/stable/operator-manual/installation/</span></a><span class="No-Break">.</span></p>
			<p>As we’re using GitOps for this chapter, we will not deploy Argo CD manually. Instead, we will use Terraform to set it up using the <span class="No-Break">Environment repository.</span></p>
			<p>The resources<a id="_idIndexMarker1356"/> for this section are present in <strong class="source-inline">~/modern-devops/ch12/environments-argocd-app</strong>. We will use the same Environment repository as before for managing <span class="No-Break">this environment.</span></p>
			<p>Therefore, let’s <strong class="source-inline">cd</strong> into the <strong class="source-inline">mdo-environments</strong> local repository and run the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cd ~/mdo-environments
$ cp -r ~/modern-devops/ch12/environments-argocd-app/terraform .
$ cp -r ~/modern-devops/ch12/environments-argocd-app/manifests .
$ cp -r ~/modern-devops/ch12/environments-argocd-app/.github .</pre>			<p>Now, let’s look at the directory structure to understand what <span class="No-Break">we’re doing:</span></p>
			<pre class="console">
.
├── .github
│   └── workflows
│       └── create-cluster.yml
├── manifests
│   └── argocd
│       ├── apps.yaml
│       ├── install.yaml
│       └── namespace.yaml
└── terraform
    ├── app.tf
    ├── argocd.tf
    ├── cluster.tf
    ├── provider.tf
    └── variables.tf</pre>			<p>As we can see, the<a id="_idIndexMarker1357"/> structure is similar to before, except for a few changes. Let’s look at the Terraform <span class="No-Break">configuration first.</span></p>
			<h2 id="_idParaDest-329"><a id="_idTextAnchor1646"/>Terraform changes</h2>
			<p>The <strong class="source-inline">terraform</strong> directory<a id="_idIndexMarker1358"/> now <a id="_idIndexMarker1359"/>contains two <span class="No-Break">more files:</span></p>
			<ul>
				<li><strong class="source-inline">argocd.tf</strong>: This contains the Terraform configuration for deploying <span class="No-Break">Argo CD</span></li>
				<li><strong class="source-inline">app.tf</strong>: This contains the Terraform configuration for configuring Argo <span class="No-Break">CD apps</span></li>
			</ul>
			<p>Let’s explore both files <span class="No-Break">in detail.</span></p>
			<h3>argocd.tf</h3>
			<p>This files <a id="_idIndexMarker1360"/>starts with the <strong class="source-inline">time_sleep</strong> resource with an explicit dependency on the <strong class="source-inline">google_container_cluster</strong> resource. It will sleep for 30 seconds after the cluster is created so that it is ready to <span class="No-Break">serve requests:</span></p>
			<pre class="console">
resource "time_sleep" "wait_30_seconds" {
  depends_on = [google_container_cluster.main]
  create_duration = "30s"
}</pre>			<p>To connect with GKE, we will use the <strong class="source-inline">gke_auth</strong> module provided by <strong class="source-inline">terraform-google-modules/kubernetes-engine/google<a id="_idTextAnchor1647"/>//modules/auth</strong>. We will add an explicit dependency to the <strong class="source-inline">time_sleep</strong> module so that authentication happens 30 seconds after the cluster <span class="No-Break">is created:</span></p>
			<pre class="console">
module "gke_auth" {
  depends_on           = [time_sleep.wait_30_seconds]
  source               = "terraform-google-modules/kubernetes-engine/google//modules/auth"
  project_id           = var.project_id
  cluster_name         = google_container_cluster.main.name
  location             = var.location
  use_private_endpoint = false
}</pre>			<p>Now that we’ve <a id="_idIndexMarker1361"/>authenticated with the GKE cluster, we need to apply manifests to deploy Argo CD to the cluster. We will use the <strong class="source-inline">gavinbunney/kubectl</strong> plugin (<a href="https://registry.terraform.io/providers/gavinbunney/kubectl/latest/docs">https://registry.terraform.io/providers/gavinbunney/kubectl/latest/docs</a>) <span class="No-Break">for that.</span></p>
			<p>We start by defining some data sources to help generate Kubernetes manifests that we will apply to install Argo CD. We will create two <strong class="source-inline">kubectl_file_documents</strong> data sources for the namespace and Argo CD app that point to the corresponding <strong class="source-inline">namespace.yaml</strong> and <strong class="source-inline">install.yaml</strong> files within the <span class="No-Break"><strong class="source-inline">manifests/argocd</strong></span><span class="No-Break"> directory:</span></p>
			<pre class="console">
data "kubectl_file_documents" "namespace" {
  content = file("../manifests/argocd/namespace.yaml")
}
data "kubectl_file_documents" "argocd" {
  content = file("../manifests/argocd/install.yaml")
}</pre>			<p>Using these data sources, we can create two <strong class="source-inline">kubectl_manifest</strong> resources for the namespace and Argo CD app. These resources will apply the manifests within the <span class="No-Break">GKE cluster:</span></p>
			<pre class="console">
resource "kubectl_manifest" "namespace" {
  for_each  = data.kubectl_file_documents.namespace.manifests
  yaml_body = each.value
  override_namespace = "argocd"
}
resource "kubectl_manifest" "argocd" {
  depends_on = [
    kubectl_manifest.namespace,
  ]
  for_each  = data.kubectl_file_documents.argocd.manifests
  yaml_body = each.value
  override_namespace = "argocd"
}</pre>			<p>Now that we’ve <a id="_idIndexMarker1362"/>added the configuration to install Argo CD, we also need to configure argo CD Applications. To do that, we have the <span class="No-Break"><strong class="source-inline">app.tf</strong></span><span class="No-Break"> file.</span></p>
			<h3>app.tf</h3>
			<p>Similar to<a id="_idIndexMarker1363"/> the Argo CD configuration, we have a <strong class="source-inline">kubectl_file_documents</strong> data source reading from the <strong class="source-inline">manifests/argocd/apps.yaml</strong> file; the <strong class="source-inline">kubectl_manifest</strong> resource will apply the manifest to the <span class="No-Break">Kubernetes cluster:</span></p>
			<pre class="console">
data "kubectl_file_documents" "apps" {
    content = file("../manifests/argocd/apps.yaml")
}
resource "kubectl_manifest" "apps" {
  depends_on = [
    kubectl_manifest.argocd,
  ]
  for_each  = data.kubectl_file_documents.apps.manifests
  yaml_body = each.value
  override_namespace = "argocd"
}</pre>			<p>We’ve also <a id="_idIndexMarker1364"/>modified the <strong class="source-inline">provider.tf</strong> file, so we’ll explore <span class="No-Break">that next.</span></p>
			<h3>provider.tf</h3>
			<p>Within<a id="_idIndexMarker1365"/> this file, we have included the <strong class="source-inline">kubectl</strong> provider, <span class="No-Break">as follows:</span></p>
			<pre class="console">
...
provider "kubectl" {
  host                   = module.gke_auth.host
  cluster_ca_certificate = module.gke_auth.cluster_ca_certificate
  token                  = module.gke_auth.token
  load_config_file       = false
}
terraform {
  required_providers {
    kubectl = {
      source  = "gavinbunney/kubectl"
      version = "&gt;= 1.7.0"
    }
  }...
}</pre>			<p>Now, let’s inspect the <span class="No-Break">manifests directory.</span></p>
			<h2 id="_idParaDest-330"><a id="_idTextAnchor1648"/>The Kubernetes manifests</h2>
			<p>The <a id="_idIndexMarker1366"/>manifests directory contains Kubernetes manifests that we will apply to the Kubernetes cluster. As we’re setting up Argo CD first, it only contains the <strong class="source-inline">argocd</strong> directory at the moment; however, we will extend this to add further directories later in <span class="No-Break">this chapter.</span></p>
			<p>The <strong class="source-inline">manifests/argocd</strong> directory <a id="_idIndexMarker1367"/>contains the<a id="_idIndexMarker1368"/> <span class="No-Break">following files:</span></p>
			<ul>
				<li><strong class="source-inline">namespace.yaml</strong>: The manifest to create the <strong class="source-inline">argocd</strong> namespace where Argo CD <span class="No-Break">will run.</span></li>
				<li><strong class="source-inline">install.yaml</strong>: The manifest to create the Argo CD application. The manifest is downloaded from the official Argo CD <span class="No-Break">release URL.</span></li>
				<li><strong class="source-inline">apps.yaml</strong>: This contains an Argo CD <span class="No-Break"><strong class="bold">ApplicationSet</strong></span><span class="No-Break"> configuration.</span></li>
			</ul>
			<p>While the <strong class="source-inline">namespace.yaml</strong> and <strong class="source-inline">install.yaml</strong> files are self-explanatory, let’s discuss the <strong class="source-inline">apps.yaml</strong> file and the Argo CD ApplicationSet resource in <span class="No-Break">more detail.</span></p>
			<h2 id="_idParaDest-331"><a id="_idTextAnchor1649"/>Argo CD Application and ApplicationSet</h2>
			<p>To manage<a id="_idIndexMarker1369"/> applications declaratively, Argo CD uses the <strong class="bold">Application</strong> resource. An Application resource defines the configuration required for Argo CD to access Kubernetes deployment configuration stored in the Git repository using the <strong class="source-inline">source</strong> attribute and where it needs to apply them using the <strong class="source-inline">target</strong> attribute. An Application resource caters to one application. For example, to deploy our Blog App, we will need to create an Application resource like <span class="No-Break">the following:</span></p>
			<pre class="console">
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: blog-app
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/&lt;your_github_repo&gt;/mdo-environments.git
    targetRevision: HEAD
    path: manifests/nginx
  destination:
    server: https://kubernetes.default.svc
  syncPolicy:
    automated:
      selfHeal: true</pre>			<p>This manifest defines an<a id="_idIndexMarker1370"/> Argo CD Application resource with the <span class="No-Break">following sections:</span></p>
			<ul>
				<li><strong class="source-inline">project</strong>: We can organize applications into distinct projects. In this case, we will stick to the <span class="No-Break"><strong class="source-inline">default</strong></span><span class="No-Break"> project.</span></li>
				<li><strong class="source-inline">source</strong>: This section defines the configuration Argo CD requires to track and pull the application configuration from the Git repository. It typically contains <strong class="source-inline">repoURL</strong>, <strong class="source-inline">targetRevision</strong>, and the <strong class="source-inline">path</strong> value where the application manifests <span class="No-Break">are located.</span></li>
				<li><strong class="source-inline">destination</strong>: This section defines the <strong class="source-inline">target</strong> value to which we want to apply the manifest. It typically contains the <strong class="source-inline">server</strong> section and contains the Kubernetes <span class="No-Break">cluster’s URL.</span></li>
				<li><strong class="source-inline">syncPolicy</strong>: This section defines any policies Argo CD should apply while syncing the Blog App from the Git repository and what to do when it detects a drift. In the preceding configuration, it would try to correct any drift from the Git repository automatically as <strong class="source-inline">selfHeal</strong> is set <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">true</strong></span><span class="No-Break">.</span></li>
			</ul>
			<p>We can very well go ahead and define multiple application manifests for each application. However, for larger projects, it might turn out to be an overhead. To manage this, Argo CD provides a generic way of creating and managing applications via the <span class="No-Break"><strong class="source-inline">ApplicationSet</strong></span><span class="No-Break"> resource.</span></p>
			<p>The <strong class="source-inline">ApplicationSet</strong> resource<a id="_idIndexMarker1371"/> provides us with a way to dynamically generate Application resources by using a defined pattern. In our case, we have the <span class="No-Break">following structure:</span></p>
			<pre class="console">
manifests
└── argocd
│   ├── apps.yaml
│   ├── install.yaml
│   └── namespace.yaml
└── blog-app
│   └── manifest.yaml
└── &lt;other-app&gt;
    └── manifest.yaml</pre>			<p>So, logically, for every subdirectory of the <strong class="source-inline">manifests</strong> directory, we would need to create a new application with the directory name. The respective application configuration should source all manifests from <span class="No-Break">the subdirectory.</span></p>
			<p>We’ve defined the following <strong class="source-inline">ApplicationSet</strong> within the <span class="No-Break"><strong class="source-inline">apps.yaml</strong></span><span class="No-Break"> file:</span></p>
			<pre class="console">
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: argo-apps
  namespace: argocd
spec:
  generators:
  - git:
      repoURL: https://github.com/&lt;your_github_repo&gt;/mdo-environments.git
      revision: HEAD
      directories:
      - path: manifests/*
      - path: manifests/argocd
        exclude: true
  template:
    metadata:
      name: '{{path.basename}}'
    spec:
      project: default
      source:
        repoURL: https://github.com/&lt;your_github_repo&gt;/mdo-environments.git
        targetRevision: HEAD
        path: '{{path}}'
      destination:
        server: https://kubernetes.default.svc
      syncPolicy:
        automated:
          selfHeal: true</pre>			<p><strong class="source-inline">ApplicationSet</strong> has the<a id="_idIndexMarker1372"/> <span class="No-Break">following sections:</span></p>
			<ul>
				<li><strong class="source-inline">generators</strong>: This section defines how Argo CD should generate Application resources. We’ve used the <strong class="source-inline">git</strong> generator, which contains the <strong class="source-inline">repoURL</strong>, <strong class="source-inline">revision</strong>, and <strong class="source-inline">directories</strong> sections. The <strong class="source-inline">directories</strong> section defines the directory from where we would want to source our applications. We’ve set that to <strong class="source-inline">manifests/*</strong>. So, it will look for every subdirectory within the <strong class="source-inline">manifests</strong> directory. We have also defined an exclude directory called <strong class="source-inline">manifests/argocd</strong>. This is because we don’t want Argo CD to manage the configuration to <span class="No-Break">deploy itself.</span></li>
				<li><strong class="source-inline">templates</strong>: This section<a id="_idIndexMarker1373"/> defines the template for creating the application. As we can see, the contents are very similar to an Application resource definition. For <strong class="source-inline">metadata.name</strong>, we specified <strong class="source-inline">{{path.basename}}</strong>, which means it will create Application resources with the subdirectory name as we intended. The <strong class="source-inline">template.spec.source.path</strong> attribute contains the source path of the corresponding application manifests, so we’ve set that to <strong class="source-inline">{{path}}</strong> – that is, the subdirectory. So, we will have <strong class="source-inline">blog-app</strong> and <strong class="source-inline">&lt;other-app&gt;</strong> applications based on the preceding directory structure. The rest of the attributes are the same as those for the Application resource we <span class="No-Break">discussed previously.</span></li>
			</ul>
			<p>Now that we’ve configured everything we need to install and set up Argo CD, let’s commit and push this configuration to the remote repository by using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ git add --all
$ git commit -m "Added argocd configuration"
$ git push</pre>			<p>We will see that GitHub will run the Actions workflow on update and deploy Argo CD. Once the workflow is successful, we can go ahead and access the Argo CD <span class="No-Break">Web UI.</span></p>
			<h2 id="_idParaDest-332"><a id="_idTextAnchor1650"/>Accessing the Argo CD Web UI</h2>
			<p>Before we <a id="_idIndexMarker1374"/>can access the Argo CD Web UI, we must authenticate with the GKE cluster. To do so, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ gcloud container clusters get-credentials \
 mdo-cluster-dev --zone us-central1-a --project $PROJECT_ID</pre>			<p>To utilize the Argo CD Web UI, you will require the external IP address of the <strong class="source-inline">argo-server</strong> service. To get that, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubectl get svc argocd-server -n argocd
NAME          TYPE        EXTERNAL-IP  PORTS          AGE
argocd-server LoadBalaner 34.122.51.25 80/TCP,443/TCP 6m15s</pre>			<p>We now know<a id="_idIndexMarker1375"/> that Argo CD is accessible at <a href="https://34.122.51.25/">https://34.122.51.25/</a>. Upon visiting this link, you’ll notice that username and password are required <span class="No-Break">for authentication:</span></p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B19877_12_10.jpg" alt="Figure 12.10 – Argo CD Web UI – login page" width="1187" height="651"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.10 – Argo CD Web UI – login page</p>
			<p>Argo CD provides an initial <strong class="source-inline">admin</strong> user by default, and the password for this user is stored in the <strong class="source-inline">argocd-initial-admin-secret</strong> <strong class="bold">Secret</strong> resource as plaintext. While you can use this default setup, it’s worth noting that it is generated from the publicly available YAML manifest. Therefore, it’s advisable to update it. To do so, execute the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubectl patch secret argocd-secret -n argocd \
-p '{"data": {"admin.password": null, "admin.passwordMtime": null}}'
$ kubectl scale deployment argocd-server --replicas 0 -n argocd
$ kubectl scale deployment argocd-server --replicas 1 -n argocd</pre>			<p>Now, allow two minutes<a id="_idIndexMarker1376"/> for the new credentials to be generated. After that, execute the following command to retrieve <span class="No-Break">the password:</span></p>
			<pre class="console">
$ kubectl -n argocd get secret argocd-initial-admin-secret \
-o jsonpath="{.data.password}" | base64 -d &amp;&amp; echo</pre>			<p>Now that you have the necessary credentials, log in and you will see the <span class="No-Break">following page:</span></p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B19877_12_11.jpg" alt="Figure 12.11 – Argo CD Web UI – home page" width="1209" height="668"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.11 – Argo CD Web UI – home page</p>
			<p>We’ve successfully set up Argo CD. The next step is to deploy our application; however, as we know that our application uses Kubernetes Secrets, which we cannot store on Git, we will have to find a mechanism to store it securely. To solve that p<a id="_idTextAnchor1651"/>roblem, we have Bitnami’s <strong class="bold">SealedSecret</strong> resource. We’ll look at that<a id="_idTextAnchor1652"/> in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-333"><a id="_idTextAnchor1653"/>Managing sensitive configurations and Secrets</h1>
			<p><strong class="bold">Sealed Secrets</strong> solves <a id="_idIndexMarker1377"/>the problem of <em class="italic">I can manage all my Kubernetes config in Git, except Secrets</em>. Sealed Secrets function as secure containers for your sensitive information. When you require a storage solution for secrets, such as <a id="_idIndexMarker1378"/>passwords or keys, you place them in these specialized packages. Only the Sealed Secrets controller within Kubernetes can unlock and access the contents. This ensures the utmost security and protection<a id="_idTextAnchor1654"/> for your valuable secre<a id="_idTextAnchor1655"/>ts. Created by <em class="italic">Bitnami Labs</em> and open sourced, they help you encrypt your Kubernetes Secrets into Sealed Secrets using asymmetric cryptography that only the Sealed Secrets controller running on the cluster can decrypt. This means you can store the Sealed Secrets in Git and use GitOps to set up everything, <span class="No-Break">including Secrets.</span></p>
			<p>Sealed Secrets comprises <a id="_idIndexMarker1379"/><span class="No-Break">two components:</span></p>
			<ul>
				<li>A client-side utility called <strong class="source-inline">kubeseal</strong> helps us generate Sealed Secrets from standard Kubernetes <span class="No-Break">Secret YAML</span></li>
				<li>A cluster-side Kubernetes controller/operator unseals your secrets and provides the key certificate to the <span class="No-Break">client-side utili<a id="_idTextAnchor1656"/>ty</span></li>
			</ul>
			<p>The typical workflow<a id="_idIndexMarker1380"/> when using Sealed Secrets is illustrated in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B19877_12_12.jpg" alt="Figure 12.12 – Sealed Secrets workflow" width="1651" height="898"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1<a id="_idTextAnchor1657"/><a id="_idTextAnchor1658"/>2.12 – Sealed Secrets workflow</p>
			<p>Now, let’s go ahea<a id="_idTextAnchor1659"/>d and install the Sealed <span class="No-Break">Secrets operator.</span></p>
			<h2 id="_idParaDest-334"><a id="_idTextAnchor1660"/>Installing the Sealed Secrets operator</h2>
			<p>To <a id="_idIndexMarker1381"/>install the <strong class="bold">Sealed Secrets operator</strong>, all you need to do is download the controller manifest from the latest release at <a href="https://github.com/bitnami-labs/sealed-secrets/releases">https://github.com/bitnami-labs/sealed-secrets/releases</a>. At the time of writing this book, <a href="https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.23.1/controller.yaml">https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.23.1/controller.yaml</a> is the latest <span class="No-Break">controller manifest.</span></p>
			<p>Create a new directory called <strong class="source-inline">sealed-secrets</strong> within the <strong class="source-inline">manifest</strong> directory and download <strong class="source-inline">controller.yaml</strong> using the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ cd ~/mdo-environments/manifests &amp; mkdir sealed-secrets
$ cd sealed-secrets
$ wget https://github.com/bitnami-labs/sealed-secrets\
/releases/download/v0.23.1/controller.yaml</pre>			<p>Then, commit and push the changes to the remote repository. After about five minutes, Argo CD will create a new application called <strong class="bold">sealed-secrets</strong> and deploy it. You can visualize this in the Argo CD Web UI <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B19877_12_13.jpg" alt="Figure 12.13 – Argo CD Web UI – Sealed Secrets" width="1637" height="1164"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.13 – Argo CD Web UI – Sealed Secrets</p>
			<p>In the <a id="_idIndexMarker1382"/>Kubernetes cluster, <strong class="source-inline">sealed-secrets-controller</strong> will be visible in the <strong class="source-inline">kube-system</strong> namespace. Run the following command to <span class="No-Break">check this:</span></p>
			<pre class="console">
$ kubectl get deployment -n kube-system sealed-secrets-controller
NAME                      READY UP-TO-DATE AVAILABL<a id="_idTextAnchor1661"/>E AGE
sealed-secrets-controller 1/1   1          1         6m4s</pre>			<p>As we can see,<a id="_idTextAnchor1662"/><a id="_idTextAnchor1663"/> the controller is running and ready. We can n<a id="_idTextAnchor1664"/>ow install the client-side utility – <span class="No-Break"><strong class="source-inline">kubeseal</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-335"><a id="_idTextAnchor1665"/>Installing kubeseal</h2>
			<p>To install the<a id="_idIndexMarker1383"/> client-side utility, you can go to <a href="https://github.com/bitnami-labs/sealed-secrets/releases">https://github.com/bitnami-labs/sealed-secrets/releases</a> and get the <strong class="source-inline">kubeseal</strong> installation binary link from that page. The following commands will install <strong class="source-inline">kubeseal</strong> <strong class="source-inline">0.23.1</strong> on <span class="No-Break">your system:</span></p>
			<pre class="console">
$ KUBESEAL_VERSION='0.23.1'
$ wget "https://github.com/bitnami-labs/sealed-secrets/releases/download\
/v${KUBESEAL_VERSION:?}/kubeseal-${KUBESEAL_VERSION:?}-linux-amd64.tar.gz"
$ tar -xvzf kubeseal-${KUBESEAL_VERSION:?}-linux-amd64.tar.gz kubeseal
$ sudo install -m 755 kubeseal /usr/local/bin/kubeseal
$ rm -rf ./kubeseal*</pre>			<p>To check whether <strong class="source-inline">kubeseal</strong> has been installed successfully, run the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubeseal --version
kubeseal version: 0.23.1</pre>			<p>S<a id="_idTextAnchor1666"/><a id="_idTextAnchor1667"/>ince <strong class="source-inline">kubeseal</strong> has been installed, let’s go ahead and create a Sealed Secret for <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">blog-app</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-336"><a id="_idTextAnchor1668"/>Creating Sealed Secrets</h2>
			<p>To create a <a id="_idIndexMarker1384"/>Sealed Secret, we have to define the Kubernetes Secret resource. The <strong class="source-inline">mongodb-creds</strong> Secret should contain some key-value pairs with the <strong class="source-inline">MONGO_INITDB_ROOT_USERNAME</strong> key with a value of <strong class="source-inline">root</strong> and the <strong class="source-inline">MONGO_INITDB_ROOT_PASSWORD</strong> key with any value you want as <span class="No-Break">the password.</span></p>
			<p>As we don’t want to store the plaintext Secret as a file, we will first create the Kubernetes secret manifest called <strong class="source-inline">mongodb-creds</strong> using the <strong class="source-inline">--dry-run</strong> and <strong class="source-inline">-o yaml</strong> flags and then pipe the output directly to <strong class="source-inline">kubeseal</strong> to generate the <strong class="source-inline">SealedSecret</strong> resource using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubectl create secret generic mongodb-creds \
  --dry-run=client -o yaml --namespace=blog-app \
  --from-literal=MONGO_INITDB_ROOT_USERNAME=root \
  --from-literal=MONGO_INITDB_ROOT_PASSWORD=&lt;your_pwd&gt; \
  | kubeseal -o yaml &gt; mongodb-creds-sealed.yaml</pre>			<p>This<a id="_idIndexMarker1385"/> generates the <strong class="source-inline">mongodb-creds-sealed.yaml</strong> Sealed Secret, which looks <span class="No-Break">like this:</span></p>
			<pre class="console">
apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: mongodb-creds
  namespace: blog-app
spec:
  encryptedData:
    MONGO_INITDB_ROOT_PASSWORD: AgB+tyskf72M/…
    MONGO_INITDB_ROOT_USERNAME: AgA95xKJg8veOy8v/…
  template:
    metadata:
      name: mongodb-creds
      namespace: blog-app</pre>			<p>As you can see, the Sealed Secret is very similar to the Secret manifest. Still, instead of containing a Base64-encoded secret value, it has encrypted it so that only the Sealed Secrets controller can decrypt it. You can easily check this file into source control. Let’s go ahead and do that. Move the Sealed Secret YAML file to the <strong class="source-inline">manifests/blog-app</strong> directory using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ mkdir -p ~/mdo-environments/manifests/blog-app/
$ mv mongodb-creds-sealed.yaml ~/mdo-environments/manifests/blog-app/</pre>			<p>Now that we’ve successfully <a id="_idIndexMarker1386"/>generated the Sealed Secret and moved it to the <strong class="source-inline">manifests/blog-app</strong> directory, we’ll set up the rest of our application in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-337"><a id="_idTextAnchor1669"/>Deploying the sample Blog App</h1>
			<p>To deploy the <a id="_idIndexMarker1387"/>sample Blog App, we need to define application resources. We’ve already discussed what our app is composed of. We have defined the application bundle as a Kubernetes manifest file called <strong class="source-inline">blog-app.yaml</strong>. We need to copy this YAML to the <strong class="source-inline">manifests/blog-app</strong> directory using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ cp ~/modern-devops/ch12/blog-app/blog-app.yaml \
 ~/mdo-environments/manifests/blog-app/</pre>			<p>I’ve prebuilt the microservices and used the required <strong class="source-inline">git-sha</strong> as the tag, as we did in the previous chapter. You can edit the YAML and replace it with your image for <span class="No-Break">each application.</span></p>
			<p>Once done, commit and push the changes to the <span class="No-Break"><strong class="source-inline">mdo-environments</strong></span><span class="No-Break"> repository.</span></p>
			<p>As soon as you push the changes, you should notice that the <strong class="source-inline">blog-app</strong> application starts appearing in the Argo CD UI in less than <span class="No-Break">five minutes:</span></p>
			<div>
				<div id="_idContainer117" class="IMG---Figure">
					<img src="image/B19877_12_14.jpg" alt=" Figure 12.14 – Argo CD Web UI – Applications" width="1621" height="1033"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 12.14 – Argo CD Web UI – Applications</p>
			<p>Wait for the <a id="_idIndexMarker1388"/>application to progress. Once it turns green, you should see the following within <span class="No-Break">the application:</span></p>
			<div>
				<div id="_idContainer118" class="IMG---Figure">
					<img src="image/B19877_12_15.jpg" alt="Figure 12.15 – Argo CD Web UI – blog-app" width="1649" height="1331"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.15 – Argo CD Web UI – blog-app</p>
			<p>Now that the<a id="_idIndexMarker1389"/> application is all synced up, we can check the resources that were created within the <strong class="source-inline">blog-app</strong> namespace. Let’s list the Services first using the <span class="No-Break">following command:</span></p>
			<pre class="console">
$ kubectl get svc -n blog-app
NAME     TYPE         CLUSTER-IP    EXTERNAL-IP PORT(S)
frontend LoadBalancer 10.71.244.154 34.68.221.0 80:3203/TCP
mongodb  ClusterIP    None          &lt;none&gt;      27017/TCP
posts    ClusterIP    10.71.242.211 &lt;none&gt;      5000/TCP
ratings  ClusterIP    10.71.244.78  &lt;none&gt;      5000/TCP
reviews  ClusterIP    10.71.247.128 &lt;none&gt;      5000/TCP
users    ClusterIP    10.71.241.25  &lt;none&gt;      5000/TCP</pre>			<p>As we can see, it lists all the Services that we’ve defined. Note that the <em class="italic">frontend</em> service is of the <strong class="source-inline">LoadBalancer</strong> type and has an <strong class="bold">External IP</strong>. Note down this External IP as we will use it to access <span class="No-Break">our application.</span></p>
			<p>Now, let’s <a id="_idIndexMarker1390"/>list the <strong class="bold">pods</strong> to see whether all the microservices are <span class="No-Break">running fine:</span></p>
			<pre class="console">
$ kubectl get pod -n blog-app
NAME                        READY   STATUS    RESTARTS
frontend-7cbdc4c6cd-4jzdw   1/1     Running   0
mongodb-0                   1/1     Running   0
posts-588d8bcd99-sphpm      1/1     Running   0
ratings-7dc45697b-wwfqd     1/1     Running   0
reviews-68b7f9cb8f-2jgvv    1/1     Running   0
users-7cdd4cd94b-g67zw      1/1     Running   0</pre>			<p>As we can see, all pods are running fine. Note that the <strong class="source-inline">mongodb-0</strong> pod contains a numeric prefix, but the rest of the pods have random UUIDs. You might recall that when we<a id="_idIndexMarker1391"/> created a <strong class="bold">StatefulSet</strong>, the pods always maintained a unique ID and were created in order. At first glance, the application seems to be set up correctly. Let’s list the Secrets as well to see whether the <strong class="source-inline">mongodb-creds</strong> secret has <span class="No-Break">been created:</span></p>
			<pre class="console">
$ kubectl get secret -n blog-app
NAME            TYPE     DATA   AGE
mongodb-creds   Opaque   2      80s</pre>			<p>Here, we can<a id="_idIndexMarker1392"/> see that the <strong class="source-inline">mongodb-creds</strong> Secret has been created. This shows us that SealedSecret is <span class="No-Break">working fine.</span></p>
			<p>Now, let’s go ahead and access our application by opening <strong class="source-inline">http://&lt;frontend-svc-external-ip&gt;</strong>. If you see the following page, the application was <span class="No-Break">deployed correctly:</span></p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B19877_12_16.jpg" alt="Figure 12.16 – Blog App home page" width="877" height="154"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.16 – Blog App home page</p>
			<p>As an exercise, play around with the application by clicking on <strong class="bold">Sign In</strong> &gt; <strong class="bold">Not a user? Create an Account</strong> and then fill in the details to register. You can <em class="italic">create</em> a new <strong class="bold">Post</strong>, add <strong class="bold">Reviews</strong>, and provide <strong class="bold">Ratings</strong>. You can also <em class="italic">update</em> your reviews, <em class="italic">delete</em> them, update ratings, and more. Try out the app to see whether all aspects are working correctly. You should be able to see something like <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/B19877_12_17.jpg" alt="Figure 12.17 – Blog App posts" width="1047" height="763"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.17 – Blog App posts</p>
			<p>As we’re happy <a id="_idIndexMarker1393"/>with the application, we can raise a pull request from the <strong class="source-inline">dev</strong> branch to the <strong class="source-inline">prod</strong> branch. Once you merge the pull request, you will see that similar services will emerge in the production environment. You can use pull request-based gating for CD as well. This ensures that your environmen<a id="_idTextAnchor1670"/><a id="_idTextAnchor1671"/>ts remain independent while being sourced from the same repository, albeit from <span class="No-Break">different branches.</span></p>
			<h1 id="_idParaDest-338"><a id="_idTextAnchor1672"/>Summary</h1>
			<p>This chapter has covered continuous deployment and delivery, and we understood the need for CD and the basic CD workflow for a container application. We discussed several modern deployment strategies and how CI tools cannot fulfill those responsibilities. Using the GitOps principles, we created an Environment repository and deployed our GKE-based environment using GitHub Actions by employing the push-based model. Then, we looked at using Argo CD as our CD tool and installed it. To avoid committing sensitive information in Git, such as secrets, we discussed Bitnami’s Sealed Secrets. We then deployed the sample Blog App using Argo CD, using GitOps all <span class="No-Break">the while.</span></p>
			<p>In the next<a id="_idTextAnchor1673"/><a id="_idTextAnchor1674"/> chapter, we will explore another vital aspect of modern DevOps – securing the <span class="No-Break">deployment pipeline.</span></p>
			<h1 id="_idParaDest-339"><a id="_idTextAnchor1675"/>Questions</h1>
			<p>Answer the following questions to test your knowledge of <span class="No-Break">this chapter:</span></p>
			<ol>
				<li>Which of the following are CD tools? (<span class="No-Break">Choose three)</span><p class="list-inset"><span class="No-Break">A. Spinnaker</span></p><p class="list-inset"><span class="No-Break">B. GitHub</span></p><p class="list-inset">C. <span class="No-Break">Argo CD</span></p><p class="list-inset">D. AWS <span class="No-Break">Code Deploy</span></p></li>
				<li>CD requires human input for deployment to <span class="No-Break">production</span><span class="No-Break">. (True/False)</span></li>
				<li>Argo CD supports Blue/Green deployments out of the <span class="No-Break">box</span><span class="No-Break">. (True/False)</span></li>
				<li>What would you use to initiate deployment using <span class="No-Break">Argo CD?</span><p class="list-inset">A. Trigger the <span class="No-Break">pipeline manually</span></p><p class="list-inset">B. Check in changes to your <span class="No-Break">Git repository</span></p><p class="list-inset">C. Use CI to trigger Argo <span class="No-Break">CD pipelines</span></p><p class="list-inset">D. Argo CD pipelines don’t react to <span class="No-Break">external stimuli</span></p></li>
				<li>An Argo CD ApplicationSet helps generate applications based on <span class="No-Break">templates</span><span class="No-Break">. (True/False)</span></li>
				<li>What branch names should you prefer for your <span class="No-Break">Environment repository?</span><p class="list-inset">A. <strong class="source-inline">dev</strong>, <strong class="source-inline">staging</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">prod</strong></span></p><p class="list-inset">B. <strong class="source-inline">feature</strong>, <strong class="source-inline">develop</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">master</strong></span></p><p class="list-inset">C. <strong class="source-inline">release</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">main</strong></span></p></li>
				<li>Which of the following deployment models does Argo <span class="No-Break">CD use?</span><p class="list-inset">A. <span class="No-Break">Push model</span></p><p class="list-inset">B. <span class="No-Break">Pull model</span></p><p class="list-inset">C. <span class="No-Break">Staggering model</span></p></li>
				<li>You should use Terraform to install Argo CD as you can store all configurations in <span class="No-Break">Git</span><span class="No-Break">. (True/False)</span></li>
				<li>Argo CD can sync resources from which of the following sources? (<span class="No-Break">Choose two)</span><p class="list-inset">A. <span class="No-Break">Git repository</span></p><p class="list-inset">B. <span class="No-Break">Container Registry</span></p><p class="list-inset">C. JFrog Artifactory’s <span class="No-Break">raw repository</span></p></li>
				<li>What would Argo CD do if you manually changed a resource <span class="No-Break">outside Git?</span><p class="list-inset">A. Argo CD would change the resource so that it matches the <span class="No-Break">Git configuration</span></p><p class="list-inset">B. Argo CD would notify you that a resource has changed <span class="No-Break">outside <a id="_idTextAnchor1676"/><a id="_idTextAnchor1677"/>Git</span></p><p class="list-inset">C. Argo CD would <span class="No-Break">do nothing</span></p></li>
				<li>You can check in Sealed Secrets to a Git <span class="No-Break">repository</span><span class="No-Break">. (True/False)</span></li>
			</ol>
			<h1 id="_idParaDest-340"><a id="_idTextAnchor1678"/>Answers</h1>
			<p>Here are the answers to this <span class="No-Break">chapter’s questions:</span></p>
			<ol>
				<li>A, C, <span class="No-Break">and D</span></li>
				<li><span class="No-Break">True</span></li>
				<li><span class="No-Break">True</span></li>
				<li>B</li>
				<li><span class="No-Break">True</span></li>
				<li>A</li>
				<li>B</li>
				<li><span class="No-Break">True</span></li>
				<li><span class="No-Break">A, B</span></li>
				<li>A</li>
				<li><span class="No-Break">True</span></li>
			</ol>
		</div>
	</div>
</div>
</body></html>