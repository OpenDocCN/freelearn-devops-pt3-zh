- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Monitoring, Tracing, and Distributed Logging
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控、追踪和分布式日志
- en: Applications developed nowadays tend to be running inside Docker containers
    or as a serverless application stack. Traditionally, applications were built as
    a monolithic entity—one process running on a server. All logs were stored on a
    disk. It made it easy to get to the right information quickly. To diagnose a problem
    with your application, you had to log in to a server and search through logs or
    stack traces to get to the bottom of the problem. But when you run your application
    inside a Kubernetes cluster in multiple containers that are executed on different
    servers, things get complicated.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现代开发的应用程序往往运行在 Docker 容器中或作为无服务器应用栈。传统上，应用程序是作为一个单体实体构建的——一个进程在服务器上运行。所有的日志都存储在磁盘上，便于快速获取相关信息。若要诊断应用程序的问题，您需要登录到服务器，查找日志或堆栈跟踪以找出问题所在。但当您将应用程序运行在多个容器中的
    Kubernetes 集群里，并且这些容器在不同的服务器上执行时，事情就变得复杂了。
- en: This also makes it very difficult to store logs, let alone view them. In fact,
    while running applications inside a container, it’s not advisable to save any
    files inside it. Oftentimes, we run those containers in a read-only filesystem.
    This is understandable as you should treat a running container as an ephemeral
    identity that can be killed at any time.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这也使得存储日志变得非常困难，更不用说查看它们了。实际上，在容器中运行应用程序时，不建议在其中保存任何文件。我们通常在只读文件系统中运行这些容器。这是可以理解的，因为您应该将正在运行的容器视为一个短暂的身份，随时可能被销毁。
- en: We face an identical situation when running serverless applications; on **Amazon
    Web Services** (**AWS**) Lambda, the process starts when you get a request, data
    inside that request gets processed, and the application dies after it finishes
    its job. If you happen to save anything to disk, it will get deleted once processing
    is concluded.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 运行无服务器应用程序时，我们也面临类似的情况；在 **Amazon Web Services** (**AWS**) Lambda 上，进程在收到请求时开始，处理完请求中的数据后，应用程序会在完成任务后终止。如果您保存了任何数据到磁盘，它将在处理完成后被删除。
- en: The most logical solution is, of course, sending all logs to some external system
    that will save, catalog, and make your logs searchable. There are multiple solutions,
    including **Software as a Service** (**SaaS**) and cloud-specific applications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最合逻辑的解决方案当然是将所有日志发送到某个外部系统，该系统将保存、编目并使您的日志可以被搜索。有多种解决方案，包括 **软件即服务** (**SaaS**)
    和特定于云的应用程序。
- en: Incidentally, sending logs to an external system is also beneficial for bare-metal
    servers—for analysis and alerting, or diagnosing if you happen to lose access
    to the server or it stops responding.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，将日志发送到外部系统对于裸金属服务器也是有益的——无论是用于分析、警报，还是诊断服务器无法访问或停止响应的情况。
- en: Along with system and application logs, we can also send application-tracing
    metrics. Tracing is a more in-depth form of metrics where the application will
    provide you with more insights into system performance and how it behaves in given
    circumstances. Examples of trace data are the time in which a given request was
    handled by your application, how many CPU cycles it took, and how long your application
    was waiting for a database to respond.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 除了系统和应用程序日志外，我们还可以发送应用程序追踪指标。追踪是比指标更深入的一种形式，它可以提供更多关于系统性能及应用程序在特定情况下表现的洞察。追踪数据的示例包括：某个请求被应用程序处理的时间、耗费的
    CPU 周期数，以及应用程序等待数据库响应的时间。
- en: 'In this chapter, you will learn about the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习以下内容：
- en: What are monitoring, tracing, and logging?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控、追踪和日志是什么？
- en: How to choose and configure one of the cloud-ready logging solutions
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何选择并配置一种云原生的日志解决方案
- en: Self-hosted solutions and how to choose them
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自托管解决方案及如何选择它们
- en: SaaS solutions and how to evaluate which will be most useful for your organization
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SaaS 解决方案及如何评估哪些对您的组织最有用
- en: 'Additionally, we will be covering the following topics:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将涵盖以下主题：
- en: Differences between monitoring, tracing, and logging
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控、追踪和日志之间的区别
- en: Cloud solutions
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云解决方案
- en: Open source solutions for self-hosting
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自托管的开源解决方案
- en: SaaS solutions
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SaaS 解决方案
- en: Log and metrics retention
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志和指标的保留
- en: So, let’s jump right into it!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们直接开始吧！
- en: Differences between monitoring, tracing, and logging
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控、追踪和日志之间的区别
- en: You will hear these terms being used interchangeably depending on the context
    and person you’re talking to, but there’s a subtle and very important difference
    between them.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上下文和交流对象的不同，您会听到这些术语交替使用，但它们之间存在微妙且非常重要的差异。
- en: '**Monitoring** refers to instrumenting your servers and applications and gathering
    data about them for processing, identifying problems, and, in the end, bringing
    results in front of interested parties. This also includes alerting.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**监控**是指对你的服务器和应用程序进行仪表化，并收集关于它们的数据以进行处理、识别问题，最终将结果呈现给相关方。这也包括警报功能。'
- en: '**Tracing**, on the other hand, is more specific, as we already mentioned.
    Trace data can tell you a lot about how your system is performing. With tracing,
    you can observe statistics that are very useful to developers (such as how long
    a function ran and whether the SQL query is fast or bottleneck), DevOps engineers
    (how long we were waiting for a database or network), or even the business (what
    was the experience of the user with our application?). So, you can see that when
    it’s used right, it can be a very powerful tool under your belt.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**追踪**，另一方面，更为具体，正如我们已经提到的。追踪数据可以告诉你很多关于系统性能的信息。通过追踪，你可以观察对开发者非常有用的统计数据（例如一个函数的运行时间，以及
    SQL 查询是否快速或存在瓶颈），对 DevOps 工程师有用的数据（例如我们等待数据库或网络的时间），甚至对业务部门有用的数据（例如用户在我们的应用程序中的体验）。所以，你可以看到，当它被正确使用时，它可以成为你手中的一个非常强大的工具。'
- en: The purpose of **logging** is to bring actionable information in a centralized
    way, which commonly is just saving all messages to a file (it’s called a log file).
    These messages typically consist of the success or failure of a given operation
    with configurable verbosity. Logging is primarily used by system administrators
    or DevOps engineers to provide a better view of what’s going on in the operating
    system or with any given application.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**日志记录**的目的是以集中化的方式提供可操作的信息，通常就是将所有消息保存到文件中（称为日志文件）。这些消息通常包括给定操作的成功或失败，并可配置详细程度。日志记录主要由系统管理员或
    DevOps 工程师使用，以便更好地了解操作系统或任何给定应用程序中的情况。'
- en: With that cleared up, we can jump into specific implementations of the distributed
    monitoring solutions in the cloud, DIY solutions, or as a SaaS application.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 澄清了这些后，我们可以进入云中分布式监控解决方案的具体实现，无论是自定义解决方案，还是作为 SaaS 应用程序使用。
- en: Cloud solutions
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云解决方案
- en: Every cloud provider out there is fully aware of the need for proper monitoring
    and distributed logging, so they will have built their own native solutions. Sometimes
    it’s worth using native solutions, but not always. Let’s take a look at the major
    cloud providers and what they have to offer.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每个云服务提供商都完全意识到进行适当监控和分布式日志记录的必要性，因此他们都会开发自己的本地解决方案。有时候，使用本地解决方案是值得的，但并非总是如此。让我们来看一看主要的云服务提供商及其提供的服务。
- en: One of the first services available in AWS was **CloudWatch**. At first, it
    would just collect all kinds of metrics and allow you to create dashboards to
    better understand system performance and easily spot issues or simply a denial-of-service
    attack, which in turn allowed you to quickly react to them.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 最早提供的服务之一就是**CloudWatch**。最初，它只是收集各种度量数据，并允许你创建仪表板以更好地理解系统性能，轻松发现问题，或者简单地识别是否发生了拒绝服务攻击，从而使你能够快速响应。
- en: Another function of CloudWatch is alerting, but it’s limited to sending out
    emails using another Amazon service, **Simple Email Service**. Alerting and metrics
    could also trigger other actions inside your AWS account, such as scaling up or
    down the number of running instances.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 的另一个功能是警报，但它仅限于使用另一个 Amazon 服务——**简单邮件服务**（**Simple Email Service**）发送电子邮件。警报和指标也可以触发
    AWS 账户中的其他操作，比如扩展或缩减运行实例的数量。
- en: As of the time of writing this book, CloudWatch can do so much more than monitoring.
    The developers of this service have added the ability to collect and search through
    logs (**CloudWatch Logs Insights**), monitor changes in AWS resources itself,
    and trigger actions. We’re also able to detect anomalies within our applications
    using **CloudWatch** **anomaly detection**.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本书撰写时，CloudWatch 的功能已经远不止监控。该服务的开发者新增了收集和搜索日志的功能（**CloudWatch Logs Insights**），监控
    AWS 资源本身的变化，以及触发操作的能力。我们还能够利用**CloudWatch** **异常检测**在应用程序中检测异常。
- en: 'As for tracing, AWS has prepared a service called **AWS X-Ray**, which is an
    advanced distributed tracing system that can give you information about how your
    application is working in the production environment in almost real time. Unfortunately,
    its capabilities are limited to only a couple of languages out there: Node.js,
    Java, and .NET. So, you’re out of luck if your application is written in Python.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 至于追踪，AWS准备了一个名为**AWS X-Ray**的服务，这是一个先进的分布式追踪系统，几乎可以实时提供有关应用程序在生产环境中如何运行的信息。不幸的是，它的能力仅限于几个语言：Node.js、Java和.NET。如果你的应用程序是用Python编写的，那么就没那么幸运了。
- en: Looking at other popular cloud solutions, there’s Google. The **Google Cloud
    Platform** (**GCP**) consists of a smart solution for gathering logs, querying,
    and error reporting, and it’s called… **Cloud Logging**. If using this service
    within GCP, similarly to CloudWatch Logs, you will be able to send your application
    logs, store them, search for data you need (IP addresses, query strings, debug
    data, and so on), and analyze your logs by using SQL-like queries.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 看看其他流行的云解决方案，谷歌提供了**Google Cloud Platform**（**GCP**），这是一个智能的日志收集、查询和错误报告解决方案，称为…
    **Cloud Logging**。如果在GCP中使用此服务，与CloudWatch Logs类似，你将能够发送应用程序日志，存储它们，搜索所需数据（IP地址、查询字符串、调试数据等），并使用类似SQL的查询分析日志。
- en: The similarities end here, though, as Google went a couple of steps further
    with additional features such as the ability to create log dashboards with visualizations
    of errors reported by your application, or creating log-based metrics.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，相似之处到此为止，因为谷歌在一些额外功能上走得更远，比如能够创建带有可视化错误报告的日志仪表板，或者创建基于日志的指标。
- en: In GCP, monitoring is carried out by another service entirely–Google Cloud Monitoring.
    It’s focused on gathering data about your application, creating **Service-Level
    Objectives** (**SLOs**), extensive metrics collection from Kubernetes (**Google
    Kubernetes Engine**, or **GKE**), and third-party integrations, for example, with
    a well-known service such as **Prometheus**.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在GCP中，监控是由另一个完全不同的服务来完成的——Google Cloud Monitoring。它专注于收集应用程序数据，创建**服务级目标**（**SLOs**），从Kubernetes（**Google
    Kubernetes Engine**，或**GKE**）收集大量指标，并进行第三方集成，例如与知名服务**Prometheus**的集成。
- en: Looking at the Microsoft Cloud Platform—Azure—you will find **Azure Monitor
    Service**, which consists of several parts that cover the requirements for full-scope
    application monitoring and tracing. There is **Azure Monitor Logs** for gathering
    logs, obviously. There is also **Azure Monitor Metrics** for monitoring and visualizing
    all metrics you push there. You can also analyze, query, and set alerts like you
    would be able to in GCP or AWS. Tracing is being done by **Azure Application Insights**.
    It is being promoted by Microsoft as an **Application Performance Management**
    (**APM**) solution and is part of **Azure Monitor**. It offers a visual map of
    the application, real-time metrics, code analysis, usage data, and many more features.
    The implementation, obviously, differs between all cloud providers and their solutions.
    You will have to refer to the documentation on how to instrument and configure
    each of those services.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 看看微软的云平台——Azure，你会找到**Azure Monitor Service**，它由多个部分组成，涵盖了完整应用监控和追踪的需求。显然，**Azure
    Monitor Logs**用于收集日志。还有**Azure Monitor Metrics**，用于监控和可视化你推送到平台的所有指标。你还可以像在GCP或AWS中一样分析、查询并设置警报。追踪是由**Azure
    Application Insights**完成的。微软将其推广为**应用性能管理**（**APM**）解决方案，并且它是**Azure Monitor**的一部分。它提供了应用程序的可视化地图、实时指标、代码分析、使用数据和许多其他功能。显然，不同云服务商及其解决方案的实现方式有所不同。你需要参考文档来了解如何对这些服务进行工具化和配置。
- en: We will focus on AWS services. We will create a log group for our application
    and gather metrics from an EC2 instance. We will also talk about tracing with
    AWS X-Ray in Python, which we could use for our application running inside AWS
    infrastructure no matter the underlying service.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重点介绍AWS服务。我们将为我们的应用程序创建一个日志组，并从EC2实例收集指标。我们还将讨论如何在Python中使用AWS X-Ray进行追踪，无论底层服务如何，这都可以用于在AWS基础设施中运行的应用程序。
- en: CloudWatch Logs and metrics
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CloudWatch日志和指标
- en: CloudWatch Logs is a log management service provided by AWS that enables you
    to centralize, search, and monitor log data from various sources in a single place.
    It allows you to troubleshoot operational problems and security incidents, as
    well as monitor resource utilization and performance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch Logs 是 AWS 提供的日志管理服务，使您能够集中、搜索并监控来自多个来源的日志数据。它允许您排查操作问题和安全事件，以及监控资源利用率和性能。
- en: CloudWatch metrics are a monitoring service provided by AWS that allows you
    to collect, track, and monitor various metrics for your AWS resources and applications.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 指标是 AWS 提供的一项监控服务，允许您收集、跟踪并监控 AWS 资源和应用程序的各种指标。
- en: CloudWatch metrics provide users with a detailed view of how their AWS resources
    are performing, by collecting and displaying key metrics, such as CPU utilization,
    network traffic, and disk I/O, and other metrics related to AWS resources, such
    as EC2 instances, RDS instances, S3 buckets, and Lambda functions.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 指标通过收集并显示关键指标（如 CPU 利用率、网络流量、磁盘 I/O 以及与 AWS 资源相关的其他指标，如 EC2 实例、RDS
    实例、S3 存储桶和 Lambda 函数）为用户提供详细的 AWS 资源性能视图。
- en: Users can use CloudWatch metrics to set alarms that will notify them when certain
    thresholds are exceeded, as well as to create custom dashboards that display important
    metrics in near real time. CloudWatch metrics also allow users to retrieve and
    analyze historical data, which can be used to identify trends and optimize resource
    usage.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以使用 CloudWatch 指标设置警报，当某些阈值被超越时会通知他们，并且创建自定义仪表板，近实时显示重要指标。CloudWatch 指标还允许用户检索和分析历史数据，这些数据可用于识别趋势并优化资源使用。
- en: 'To be able to send logs and metrics to CloudWatch, we will need the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够将日志和指标发送到 CloudWatch，我们需要以下内容：
- en: An IAM policy that grants permissions to send logs to CloudWatch Logs. Additionally,
    we will allow pushing metrics data along with the logs.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一项 IAM 策略，授予将日志发送到 CloudWatch Logs 的权限。此外，我们还将允许将指标数据与日志一起推送。
- en: To create an IAM role with the previously created policy attached to it. This
    role then can be assumed by EC2 instances, Lambda functions, or any other AWS
    services that require the ability to send logs to CloudWatch Logs.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个 IAM 角色，并将之前创建的策略附加到其中。此角色然后可以被 EC2 实例、Lambda 函数或任何其他需要将日志发送到 CloudWatch
    Logs 的 AWS 服务假设。
- en: To attach the role to a resource that we want to send logs to CloudWatch Logs.
    For our purpose, we will attach the role to an EC2 instance.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将角色附加到我们希望将日志发送到 CloudWatch Logs 的资源。为了我们的目的，我们将角色附加到 EC2 实例。
- en: 'An example of an IAM policy is as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 IAM 策略的示例如下：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this policy, the `logs:CreateLogStream` and `logs:PutLogEvents` actions are
    allowed for all CloudWatch Logs resources (`arn:aws:logs:*:*:*`), and the `cloudwatch:PutMetricData`
    action is allowed for all CloudWatch metric resources (`*`).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在此策略中，`logs:CreateLogStream` 和 `logs:PutLogEvents` 操作对于所有 CloudWatch Logs 资源（`arn:aws:logs:*:*:*`）都是允许的，`cloudwatch:PutMetricData`
    操作对于所有 CloudWatch 指标资源（`*`）也是允许的。
- en: 'We will also need a trust policy allowing EC2 to assume a role we’re going
    to create for it, in order to be able to send metrics and logs. The trust policy
    looks like this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一项信任策略，允许 EC2 假设我们为其创建的角色，以便能够发送指标和日志。信任策略如下所示：
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Save this to a `trust-policy.json` file, which we will use in a moment.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 将其保存为 `trust-policy.json` 文件，我们稍后将使用它。
- en: 'Using the AWS CLI tool, to create an instance profile and attach the preceding
    policy to it, you will need to run the following commands:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AWS CLI 工具，创建实例配置文件并将之前的策略附加到其中，您需要运行以下命令：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will also need a role with a trust policy attached to it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个附加了信任策略的角色：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can attach the role we just created to the instance profile, so we
    can use it in the EC2 instance:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将刚刚创建的角色附加到实例配置文件上，以便在 EC2 实例中使用它：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And now, let’s attach a policy to use against the EC2 service:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们附加一个用于 EC2 服务的策略：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `policy.json` file is the file where you’ve saved the policy.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`policy.json` 文件是您保存策略的文件。'
- en: An instance profile, as the name suggests, will work only with EC2 instances.
    To use the same policy for a Lambda function, we will need to create an IAM role
    instead and attach the newly created role to a function.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 实例配置文件，顾名思义，仅适用于 EC2 实例。要在 Lambda 函数中使用相同的策略，我们需要创建一个 IAM 角色并将新创建的角色附加到函数上。
- en: Let’s create a new instance using the AWS CLI as well, and attach the instance
    profile we’ve just created. This particular instance will be placed in a default
    VPC and in a public subnet. This will cause the instance to get a public IP address
    and will be available from the public internet.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也使用AWS CLI创建一个新实例，并附加我们刚刚创建的实例配置文件。这个特定的实例将被放置在默认VPC和公共子网中。这将导致实例获得一个公网IP地址，并且可以从公共互联网访问。
- en: 'To create an EC2 instance in a public subnet of the default VPC using `DefaultInstanceProfile`,
    you can follow these steps:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要在默认VPC的公共子网上创建一个EC2实例，并使用`DefaultInstanceProfile`，你可以按照以下步骤操作：
- en: 'Get the ID of the default VPC:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取默认VPC的ID：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This command will return the ID of the default VPC. We will need it in the following
    steps.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将返回默认VPC的ID。我们将在后续步骤中使用它。
- en: 'Get the ID of a public subnet in the default VPC and save it for later use:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取默认VPC中一个公共子网的ID，并保存以备后用：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To launch an EC2 instance, we will need an instance template called an **Amazon
    Machine Image** (**AMI**) and an SSH key that we will use to access this instance.
    To get an ID of an Ubuntu image, we can also use the AWS CLI tool.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动EC2实例，我们需要一个叫做**Amazon机器镜像**（**AMI**）的实例模板和一个我们将用于访问该实例的SSH密钥。为了获得Ubuntu镜像的ID，我们也可以使用AWS
    CLI工具。
- en: 'We will filter out the most recent AMI ID of Ubuntu 20.04 with the following
    command:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将通过以下命令筛选出最新的Ubuntu 20.04的AMI ID：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This command will list all available Ubuntu 20.04 images owned by Canonical
    (`099720109477`) and filter them by name (`ubuntu-focal-20.04-*`), architecture
    (we need `x86_64`, not ARM), and whether they are available for use (state is
    available). It will also sort them by creation date in descending order and return
    the most recent (first on the list) image ID.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将列出Canonical（`099720109477`）拥有的所有可用的Ubuntu 20.04镜像，并通过名称（`ubuntu-focal-20.04-*`）、架构（我们需要`x86_64`，而非ARM）以及是否可用（状态为可用）进行过滤。它还将按照创建日期降序排序，并返回最新的（列表中的第一个）镜像ID。
- en: 'Now, to create an SSH key, you will need to generate one for yourself or use
    the key you have already on your machine. We will need to upload a public part
    of our key to AWS. You can simply run another CLI command to achieve this:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，要创建一个SSH密钥，你需要为自己生成一个密钥，或者使用你已经在机器上拥有的密钥。我们需要将密钥的公钥部分上传到AWS。你可以简单地运行另一个CLI命令来实现这一点：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'With all that, finally, we’re ready to launch a new instance in the public
    subnet with `DefaultInstanceProfile`:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有这些步骤后，最后，我们准备好在公共子网中使用`DefaultInstanceProfile`启动一个新的实例：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The output of the preceding command is information about newly launched instances
    you could use for scripting purposes or simply to save the instance IP address
    for later use.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令的输出是有关新启动实例的信息，你可以将其用于脚本化操作，或者仅仅保存实例的IP地址以备后用。
- en: At this point, you won’t be able to connect to the machine yet as, by default,
    all ports are closed. To open the SSH port (`22`), we will need to create a new
    security group.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你还无法连接到机器，因为默认情况下，所有端口都被关闭。为了打开SSH端口（`22`），我们需要创建一个新的安全组。
- en: 'Use the following command to achieve that:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令来实现：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The VPC ID we used is the one we saved earlier in the process, and the output
    is the ID of our new security group. We will need to add an ingress rule to it
    and connect it to our EC2 instance. See the `InstanceID` value in the long output
    once the machine is created (`i-06f35cbb39f6e5cdb`).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的VPC ID是我们在之前步骤中保存的，而输出是我们新安全组的ID。我们需要为其添加一个入站规则，并将其连接到我们的EC2实例。在机器创建后，查看长输出中的`InstanceID`值（例如：`i-06f35cbb39f6e5cdb`）。
- en: 'Use the following command to add an inbound rule to the security group that
    allows SSH access from `0.0.0.0/0`:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令为安全组添加一个入站规则，允许来自`0.0.0.0/0`的SSH访问：
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We’ve used the ID of the security group that we created in a previous step.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了在之前步骤中创建的安全组的ID。
- en: This command added a new inbound rule to the security group that allows TCP
    traffic on port `22` (SSH) from any IP address (`0.0.0.0/0`). Instead of allowing
    full internet access to your new EC2 instance, you could choose to use your own
    public IP address instead.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令向安全组添加了一个新的入站规则，允许来自任何IP地址（`0.0.0.0/0`）的TCP流量通过端口`22`（SSH）。你也可以选择使用自己的公网IP地址，而不是允许新EC2实例完全访问互联网。
- en: 'Now, we can attach this security group to an instance:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以将这个安全组附加到一个实例上：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: At this point, port `22` should be open and ready to receive connections.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，端口`22`应该已经打开，并准备接收连接。
- en: Let’s stop here for a moment. You’re probably wondering whether there is a better
    way to do this instead of with the AWS CLI. Yes, there is; there are various tools
    to automate the creation of the infrastructure. Those tools are generally called
    **Infrastructure as Code** (**IaC**) and we will talk about them in [*Chapter
    12*](B18197_12.xhtml#_idTextAnchor365). There are various options we could have
    used in this example, from CloudFormation, which is the go-to IaC tool for AWS,
    to Terraform, from HashiCorp to the Pulumi project, which is gaining traction.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时停下来。你可能会想，是否有更好的方法来完成此操作，而不是使用 AWS CLI。是的，确实有；有许多工具可以自动化创建基础设施。这些工具通常被称为**基础设施即代码**（**IaC**），我们将在[*第
    12 章*](B18197_12.xhtml#_idTextAnchor365)中讨论它们。在这个示例中，我们本可以使用多种选择，从 AWS 的首选 IaC
    工具 CloudFormation，到 HashiCorp 的 Terraform，再到逐渐受到关注的 Pulumi 项目。
- en: 'Now that we have an EC2 instance, we can connect to it and install the **CloudWatch
    agent**. It’s needed because AWS by default monitors only two metrics: CPU and
    memory usage. If you want to monitor disk space and send additional data to CloudWatch
    (such as logs or custom metrics), the agent is a must.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个 EC2 实例，我们可以连接到它并安装**CloudWatch 代理**。之所以需要它，是因为 AWS 默认只监控两个指标：CPU 和内存使用率。如果您想要监控磁盘空间并将附加数据（如日志或自定义指标）发送到
    CloudWatch，则必须使用该代理。
- en: 'After getting into the SSH console, we will need to download the CloudWatch
    agent `deb` package and install it using the `dpkg` tool:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 SSH 控制台后，我们需要下载 CloudWatch 代理的`deb`包并使用`dpkg`工具安装：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let’s become the `root` user so we can omit `sudo` from every command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们切换到`root`用户，以便可以在每个命令中省略`sudo`：
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'It will ask a lot of questions, but it’s safe to leave most of them as their
    default and just hit *Enter*. There are some questions, however, that will require
    additional attention from us:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 它会询问很多问题，但大多数问题可以保持默认设置，直接按 *Enter* 即可。然而，有一些问题需要我们特别注意：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If you answered `yes` (`1`) to this question, you will need to install collectd
    by invoking the following command:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您回答了`yes`（`1`）这个问题，您将需要通过以下命令安装 collectd：
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To the following question, answer `no` (`2`) unless you want some particular
    log file to be uploaded to CloudWatch Logs:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于以下问题，除非您希望上传某些特定的日志文件到 CloudWatch Logs，否则请回答`no`（`2`）：
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The final question is whether to save the agent configuration in AWS SSM, to
    which you can safely answer `no` (`2`) as well:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后的问题是是否将代理配置保存在 AWS SSM 中，您可以安全地回答`no`（`2`）：
- en: '[PRE19]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The wizard will save the configuration in `/opt/aws/amazon-cloudwatch-agent/bin/config.json`.
    You will be able to alter it later or launch the wizard again if needed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 向导会将配置保存在`/opt/aws/amazon-cloudwatch-agent/bin/config.json`中。如果需要，您可以稍后修改它或再次启动向导。
- en: 'Before we start the agent, we will need to convert the output JSON file into
    new **Tom’s Obvious, Minimal Language** (**TOML**) format, which is what the agent
    is using. Fortunately, there’s also a command for this job, too. We will use the
    agent control script to load the existing schema, save the TOML file, and optionally,
    start the agent if everything is in order:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在启动代理之前，我们需要将输出的 JSON 文件转换为新的**Tom 的显而易见、最小化语言**（**TOML**）格式，这是代理使用的格式。幸运的是，执行此任务的命令也有。我们将使用代理控制脚本加载现有的架构，保存
    TOML 文件，并在一切就绪时可选择启动代理：
- en: '[PRE20]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now, we can go to the AWS web console and navigate to CloudWatch to see whether
    we can see the metrics coming in. It may take several minutes until they’re shown.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以前往 AWS Web 控制台并导航到 CloudWatch，查看是否能看到传入的指标。可能需要几分钟才能显示。
- en: 'Before starting the CloudWatch agent, we will get about 17 different metrics
    for our EC2 instance, as seen in the following screenshot:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动 CloudWatch 代理之前，我们将为 EC2 实例获取大约 17 个不同的指标，如下图所示：
- en: '![Figure 10.1 – Basic EC2 and EBS metrics in CloudWatch without the CloudWatch
    agent installed](img/B18197_10_01.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – 在未安装 CloudWatch 代理的情况下，CloudWatch 中的基本 EC2 和 EBS 指标](img/B18197_10_01.jpg)'
- en: Figure 10.1 – Basic EC2 and EBS metrics in CloudWatch without the CloudWatch
    agent installed
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 在未安装 CloudWatch 代理的情况下，CloudWatch 中的基本 EC2 和 EBS 指标
- en: 'After we’ve started the CloudWatch agent, we will start receiving a lot more
    metrics and we will see an additional namespace in the CloudWatch **Metrics**
    panel. See the following screenshot:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 CloudWatch 代理后，我们将开始接收更多的指标，并且在 CloudWatch **Metrics** 面板中会看到一个额外的命名空间。请参见以下屏幕截图：
- en: '![Figure 10.2 – CloudWatch metrics after successfully enabling the CloudWatch
    agent on the EC2 instance](img/B18197_10_02.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 成功启用 CloudWatch 代理后 EC2 实例中的 CloudWatch 指标](img/B18197_10_02.jpg)'
- en: Figure 10.2 – CloudWatch metrics after successfully enabling the CloudWatch
    agent on the EC2 instance
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 在 EC2 实例上成功启用 CloudWatch 代理后的 CloudWatch 指标
- en: All metrics we’re receiving can be used to create dashboards and alerts (including
    anomaly detection) in the CloudWatch service.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接收到的所有指标都可以用于在 CloudWatch 服务中创建仪表板和警报（包括异常检测）。
- en: AWS X-Ray
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS X-Ray
- en: AWS X-Ray is a service that enables you to trace requests through distributed
    systems and microservice applications. It provides an end-to-end view of requests
    as they travel through an application, allowing developers to identify performance
    bottlenecks, diagnose errors, and improve overall application efficiency.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: AWS X-Ray 是一项服务，允许您跟踪分布式系统和微服务应用程序中的请求。它提供了请求在应用程序中流动的端到端视图，使开发人员能够识别性能瓶颈、诊断错误并提高整体应用程序效率。
- en: With X-Ray, it’s possible to visualize the different components of your application
    and see how requests are being processed as they travel through each component.
    This includes details such as the time taken to complete each component, any errors
    that occur, and the cause of those errors.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 X-Ray，可以可视化应用程序的不同组件，并查看请求如何在各个组件间流动时被处理。这包括诸如完成每个组件所需时间、发生的任何错误以及错误的原因等细节。
- en: X-Ray also provides a range of analysis tools, including statistical analysis
    and heat maps, to help developers identify trends and patterns in request processing.
    These insights can be used to optimize performance and ensure that the application
    is running as efficiently as possible.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: X-Ray 还提供了一系列分析工具，包括统计分析和热图，帮助开发人员识别请求处理中的趋势和模式。这些见解可以用于优化性能，确保应用程序尽可能高效地运行。
- en: 'AWS X-Ray supports a wide range of programming languages, including the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: AWS X-Ray 支持多种编程语言，包括以下几种：
- en: Node.js
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Node.js
- en: Java
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java
- en: .NET
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: .NET
- en: Go
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go
- en: Python
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python
- en: Ruby
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ruby
- en: PHP
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PHP
- en: 'To instrument your application with the diagnostic tools provided by AWS X-Ray,
    you can use the AWS SDK. Consider the following code (found in the GitHub repository
    at [https://github.com/Sysnove/flask-hello-world](https://github.com/Sysnove/flask-hello-world)):'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AWS X-Ray 提供的诊断工具来为应用程序进行监控，您可以使用 AWS SDK。考虑以下代码（可以在 GitHub 仓库中找到：[https://github.com/Sysnove/flask-hello-world](https://github.com/Sysnove/flask-hello-world)）：
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To gather tracing data about this service, you’ll need to install the `aws_xray_sdk`
    package using the `pip` package manager. Then, import the `xray_recorder` subpackage
    into our code. In this case, we will also use this SDK''s integration with the
    Flask framework. The modified code will look like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要收集此服务的追踪数据，您需要使用 `pip` 包管理器安装 `aws_xray_sdk` 包。然后，将 `xray_recorder` 子包导入到我们的代码中。在这种情况下，我们还将使用此
    SDK 与 Flask 框架的集成。修改后的代码如下所示：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The rest of the code can remain unchanged. Here, we are configuring the X-Ray
    recorder to use the service name `FlaskHelloWorldApp`, which will show up in the
    X-Ray console as the name of our service. When the service starts running, you
    can go to the X-Ray console and see the service name `FlaskHelloWorldApp` with
    a list of traces.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 其余代码可以保持不变。在这里，我们将配置 X-Ray 记录器使用服务名称 `FlaskHelloWorldApp`，该名称将在 X-Ray 控制台中显示为我们的服务名称。当服务开始运行时，您可以进入
    X-Ray 控制台，查看服务名称 `FlaskHelloWorldApp` 以及相关的追踪列表。
- en: 'The full documentation for the AWS X-Ray SDK can be found on this website:
    [https://docs.aws.amazon.com/xray-sdk-for-python/latest/reference/index.xhtml](https://docs.aws.amazon.com/xray-sdk-for-python/latest/reference/index.xhtml).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: AWS X-Ray SDK 的完整文档可以在以下网站找到：[https://docs.aws.amazon.com/xray-sdk-for-python/latest/reference/index.xhtml](https://docs.aws.amazon.com/xray-sdk-for-python/latest/reference/index.xhtml)。
- en: When running the preceding application on the EC2 instance we created in a previous
    section, you will see a complete picture of the running environment of your application
    including the internals of the running Flask processes.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当在我们之前创建的 EC2 实例上运行上述应用程序时，您将看到应用程序运行环境的完整图像，包括 Flask 进程的内部情况。
- en: There are multiple projects that deal with application monitoring, tracing,
    and gathering logs. Apart from cloud-hosted solutions that are available in the
    cloud environment, there are commercial and open source solutions worth knowing
    about. This awareness might prove useful when dealing with more and more common
    hybrid solutions.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个项目涉及应用程序监控、追踪和日志收集。除了云环境中可用的云托管解决方案外，还有一些值得了解的商业和开源解决方案。这些认知在处理越来越常见的混合解决方案时可能会非常有用。
- en: Open source solutions for self-hosting
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自托管的开源解决方案
- en: One of the most popular projects built around monitoring that is also adopted
    by commercial solutions is **OpenTelemetry**. It’s an open source project for
    application monitoring and observability. It provides a set of APIs, libraries,
    agents, and integrations for collecting, processing, and exporting telemetry data
    such as traces, metrics, and logs from different sources in distributed systems.
    OpenTelemetry is designed to be vendor-agnostic and cloud-native, meaning it can
    work with various cloud providers, programming languages, frameworks, and architectures.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最受欢迎的监控相关项目之一，也是商业解决方案采用的项目是**OpenTelemetry**。它是一个开源的应用程序监控与可观察性项目，提供了一整套 API、库、代理和集成，用于收集、处理和导出来自分布式系统中不同来源的遥测数据，如跟踪、指标和日志。OpenTelemetry
    设计上是供应商无关的且云原生的，这意味着它可以与各种云服务提供商、编程语言、框架和架构兼容。
- en: The main goal of OpenTelemetry is to provide developers and operators with a
    unified and standardized way to instrument, collect, and analyze telemetry data
    across the entire stack of their applications and services, regardless of the
    underlying infrastructure. OpenTelemetry supports different data formats, protocols,
    and export destinations, including popular observability platforms such as **Prometheus**,
    **Jaeger**, **Zipkin**, **Grafana**, and **SigNoz**. This allows users to mix
    and match their preferred tools and services to build a comprehensive observability
    pipeline that meets their specific needs.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 的主要目标是为开发者和运维人员提供一种统一和标准化的方式，在其应用程序和服务的整个堆栈中对遥测数据进行注入、收集和分析，而不管底层基础设施是什么。OpenTelemetry
    支持不同的数据格式、协议和导出目标，包括流行的可观察性平台，如**Prometheus**、**Jaeger**、**Zipkin**、**Grafana**
    和 **SigNoz**。这使得用户可以根据需要灵活组合他们喜欢的工具和服务，构建一个全面的可观察性管道。
- en: Some examples of commercial software that adopts OpenTelemetry are **Datadog**,
    AWS, and **New Relic**. AWS provides OpenTelemetry Collector as a managed service
    for collecting and exporting telemetry data to AWS services such as Amazon CloudWatch,
    AWS X-Ray, and AWS App Runner.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一些采用 OpenTelemetry 的商业软件示例包括**Datadog**、AWS 和**New Relic**。AWS 提供 OpenTelemetry
    Collector 作为托管服务，用于收集和导出遥测数据到 AWS 服务，如 Amazon CloudWatch、AWS X-Ray 和 AWS App Runner。
- en: Prometheus
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prometheus
- en: Prometheus is an open source monitoring solution that is widely used for collecting
    and querying metrics from distributed systems. It was created by the developers
    at SoundCloud and is now maintained by the **Cloud Native Computing Foundation**
    (**CNCF**). Prometheus is designed to be highly scalable and adaptable, with support
    for a wide range of data sources and integration options. It allows users to define
    and collect custom metrics, visualize data through a built-in dashboard, and set
    alerts based on predefined thresholds or anomalies. Prometheus is often used in
    conjunction with Kubernetes and other cloud-native technologies, but it can also
    be used to monitor traditional infrastructure and applications.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 是一个开源的监控解决方案，广泛用于收集和查询分布式系统中的指标。它由 SoundCloud 的开发人员创建，现在由**云原生计算基金会**（**CNCF**）维护。Prometheus
    设计上具有高度的可扩展性和适应性，支持多种数据源和集成选项。它允许用户定义和收集自定义指标，通过内置仪表板可视化数据，并基于预定义的阈值或异常设置警报。Prometheus
    常与 Kubernetes 及其他云原生技术一起使用，但也可以用于监控传统的基础设施和应用程序。
- en: One common use case is to track request latencies and error rates, which can
    help identify performance bottlenecks and potential issues in the application.
    To get started with monitoring a Flask application using Prometheus, you can use
    the Prometheus client library for Python. This library provides decorators that
    can be added to Flask routes to automatically generate metrics such as request
    count, request duration, and HTTP response codes. These metrics can then be collected
    by a Prometheus server and displayed on a Grafana dashboard for visualization
    and analysis.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的使用场景是跟踪请求延迟和错误率，这有助于识别应用程序中的性能瓶颈和潜在问题。要开始使用 Prometheus 监控 Flask 应用程序，您可以使用
    Python 的 Prometheus 客户端库。该库提供了可以添加到 Flask 路由中的装饰器，自动生成请求计数、请求持续时间和 HTTP 响应码等指标。然后，这些指标可以由
    Prometheus 服务器收集，并显示在 Grafana 仪表板上进行可视化和分析。
- en: Here’s an example of how you can instrument the “*Hello World*” Flask application
    with Prometheus to send metrics. We used the same application with AWS X-Ray in
    a previous section.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例，展示如何将“*Hello World*” Flask 应用程序与 Prometheus 配合使用以发送指标。我们在前一节中使用了相同的应用程序和
    AWS X-Ray。
- en: 'First, you’ll need to install the `prometheus_client` library using `pip`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要使用 `pip` 安装 `prometheus_client` 库：
- en: '[PRE23]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, you can modify the `app.py` file in the `flask-hello-world` repository
    to add the Prometheus client library and instrument the routes with metrics. Here’s
    an example:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你可以修改 `flask-hello-world` 仓库中的 `app.py` 文件，添加 Prometheus 客户端库，并用指标对路由进行仪器化。以下是一个示例：
- en: '[PRE24]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In this example, we’ve defined two Prometheus metrics: `hello_world_request_count`
    and `hello_world_request_latency_seconds`. The `hello()` route is instrumented
    with these metrics using decorators. The `REQUEST_LATENCY` histogram measures
    the request latency for each request, while the `REQUEST_COUNT` counter increments
    on each request.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们定义了两个 Prometheus 指标：`hello_world_request_count` 和 `hello_world_request_latency_seconds`。`hello()`
    路由使用装饰器对这些指标进行了仪器化。`REQUEST_LATENCY` 直方图度量每个请求的延迟，而 `REQUEST_COUNT` 计数器在每个请求时递增。
- en: We’ve started the Prometheus server on port `8000` using `start_http_server()`.
    This will make the metrics available for collection by a Prometheus server.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过 `start_http_server()` 在端口 `8000` 启动了 Prometheus 服务器。这样可以使这些指标可供 Prometheus
    服务器收集。
- en: To view the metrics, you can navigate to [http://localhost:8000/metrics](http://localhost:8000/metrics)
    in your web browser. This will display the raw metrics data in Prometheus format.
    You can also use a tool such as Grafana to visualize the metrics on a dashboard.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看这些指标，你可以在浏览器中访问 [http://localhost:8000/metrics](http://localhost:8000/metrics)。这将以
    Prometheus 格式显示原始的指标数据。你也可以使用像 Grafana 这样的工具在仪表盘上可视化这些指标。
- en: Grafana
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Grafana
- en: Grafana is a popular open source dashboard and data visualization platform that
    enables users to create interactive and customizable dashboards for monitoring
    and analyzing metrics from various data sources. It is usually used alongside
    Prometheus.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 是一个流行的开源仪表盘和数据可视化平台，允许用户创建交互式和可定制的仪表盘，用于监控和分析来自各种数据源的指标。它通常与 Prometheus
    一起使用。
- en: With Grafana, users can create visualizations, alerting rules, and dashboards
    that provide insight into the performance and behavior of their applications and
    infrastructure. Grafana supports a wide range of data sources, including popular
    time-series databases such as Prometheus, InfluxDB, and Graphite, making it a
    versatile tool for monitoring and visualization. Once you have connected your
    data source, you can start creating dashboards by adding panels to visualize the
    data. These panels can include various types of visualizations, including line
    graphs, bar charts, and gauges. You can also customize the dashboard layout, add
    annotations, and set up alerts to notify you of anomalies or issues in your metrics.
    With its powerful features and flexibility, Grafana is a go-to tool for visualizing
    and analyzing application and infrastructure metrics.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Grafana，用户可以创建可视化图表、警报规则和仪表盘，以便深入了解他们应用程序和基础设施的性能和行为。Grafana 支持多种数据源，包括流行的时序数据库，如
    Prometheus、InfluxDB 和 Graphite，使其成为一个多功能的监控和可视化工具。一旦你连接了数据源，你就可以通过添加面板来开始创建仪表盘，以便可视化数据。这些面板可以包含各种类型的可视化图表，包括折线图、条形图和仪表盘。你还可以自定义仪表盘布局、添加注释，并设置警报以在指标出现异常或问题时通知你。凭借其强大的功能和灵活性，Grafana
    成为可视化和分析应用程序及基础设施指标的首选工具。
- en: Grafana Labs also created the Grafana Loki project, which can be used to extend
    your monitoring with logs visualization. **Grafana Loki** is a horizontally scalable
    log aggregation system that provides a way to centralize logs from various sources
    and quickly search and analyze them. It’s being seen as an alternative to Prometheus,
    but both tools have different use cases and could be complementary to each other.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Labs 还创建了 Grafana Loki 项目，可以用来扩展你的监控，提供日志可视化。**Grafana Loki** 是一个水平可扩展的日志聚合系统，提供了一种集中化来自不同源的日志并快速搜索和分析它们的方法。它被视为
    Prometheus 的替代品，但这两种工具有不同的使用场景，并且可以相互补充。
- en: Loki, unlike traditional log management solutions, does not index or parse logs
    upfront. Instead, it uses a streaming pipeline that extracts log labels and stores
    them in a compact and efficient format, making it ideal for ingesting and querying
    large volumes of logs in real time. Grafana Loki integrates seamlessly with Grafana,
    allowing users to correlate logs with metrics and create powerful dashboards that
    provide insight into the behavior of their applications and infrastructure.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的日志管理解决方案不同，Loki 不会预先对日志进行索引或解析。相反，它使用一个流式管道，提取日志标签并以紧凑高效的格式存储，这使得它非常适合实时摄取和查询大量日志。Grafana
    Loki 与 Grafana 无缝集成，允许用户将日志与指标关联，并创建强大的仪表盘，深入了解他们的应用程序和基础设施的行为。
- en: To use Grafana Loki, you need to set up a Loki server and configure it to receive
    log data from your applications and infrastructure. Once Loki is set up, you can
    use the Grafana Explore feature to search and visualize logs in real time. Explore
    provides a user-friendly interface that enables you to search logs using various
    filters, such as labels, time range, and query expressions
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Grafana Loki，你需要设置一个 Loki 服务器并配置它接收来自你的应用程序和基础设施的日志数据。一旦 Loki 设置完成，你可以使用
    Grafana 的 Explore 功能实时搜索和可视化日志。Explore 提供了一个用户友好的界面，使你能够使用各种过滤器（如标签、时间范围和查询表达式）来搜索日志。
- en: SigNoz
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SigNoz
- en: SigNoz is an observability platform that enables users to collect, store, and
    analyze application metrics’ telemetry data and provides log management under
    a single web panel. It is built on top of the OpenTelemetry specification, which
    is an industry-standard framework for distributed tracing and metric collection.
    SigNoz provides a simple, intuitive interface for users to view real-time and
    historical data about their applications’ performance and health.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: SigNoz 是一个可观察性平台，使用户能够收集、存储和分析应用程序的指标遥测数据，并提供统一的日志管理界面。它基于 OpenTelemetry 规范构建，这是一个分布式追踪和指标收集的行业标准框架。SigNoz
    提供了一个简单、直观的界面，供用户查看其应用程序性能和健康状况的实时和历史数据。
- en: SigNoz has its own agent that you can install on your servers, but it also supports
    Prometheus as a data source. So, if you’re already using Prometheus, you can use
    SigNoz without any significant changes to your monitoring infrastructure.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: SigNoz 有自己的代理程序，可以安装在你的服务器上，但它也支持 Prometheus 作为数据源。因此，如果你已经在使用 Prometheus，你可以在不对监控基础设施进行重大更改的情况下使用
    SigNoz。
- en: 'To install SigNoz on your server, you can follow a comprehensive guide on the
    official project website: [https://signoz.io/docs/install/](https://signoz.io/docs/install/).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 要在服务器上安装 SigNoz，你可以参考官方项目网站上的详细安装指南：[https://signoz.io/docs/install/](https://signoz.io/docs/install/)。
- en: New Relic Pixie
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: New Relic Pixie
- en: New Relic is a well-known monitoring SaaS solution; we will get back to it later
    in this chapter in the *SaaS solutions* section. Pixie is an open source project
    started by New Relic and was contributed to CNCF.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: New Relic 是一个知名的监控 SaaS 解决方案；我们将在本章的*SaaS 解决方案*部分稍后详细介绍它。Pixie 是一个由 New Relic
    启动的开源项目，并且已贡献给 CNCF。
- en: CNCF is an open source software foundation that was established in 2015 to advance
    the development and adoption of cloud-native technologies. CNCF is the home of
    many popular projects, such as Kubernetes, Prometheus, and Envoy, which are widely
    used in modern cloud-native applications. The foundation aims to create a vendor-neutral
    ecosystem for cloud-native computing, promoting interoperability and standardization
    among different cloud platforms and technologies. CNCF also hosts several certification
    programs that help developers and organizations validate their proficiency in
    cloud-native technologies. CNCF plays a critical role in driving innovation and
    standardization in the rapidly evolving cloud-native landscape.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: CNCF 是一个开源软件基金会，成立于 2015 年，旨在推动云原生技术的发展和采用。CNCF 是许多流行项目的家园，例如 Kubernetes、Prometheus
    和 Envoy，这些项目在现代云原生应用中得到了广泛应用。该基金会的目标是创建一个云原生计算的供应商中立生态系统，促进不同云平台和技术之间的互操作性和标准化。CNCF
    还主持多个认证项目，帮助开发者和组织验证他们在云原生技术方面的能力。CNCF 在推动云原生领域快速发展的创新和标准化方面起着至关重要的作用。
- en: New Relic Pixie is an open source, Kubernetes-native observability solution
    that provides real-time monitoring and tracing capabilities for modern applications.
    It can help developers and operations teams to quickly identify and troubleshoot
    performance issues in microservices-based applications running on Kubernetes clusters.
    Pixie can be easily deployed on any Kubernetes cluster and provides out-of-the-box
    support for popular open source tools such as Prometheus, Jaeger, and OpenTelemetry.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: New Relic Pixie 是一个开源的、Kubernetes 原生的可观测性解决方案，提供现代应用程序的实时监控和追踪功能。它可以帮助开发人员和运维团队快速识别和排查在
    Kubernetes 集群上运行的微服务应用程序中的性能问题。Pixie 可以轻松部署在任何 Kubernetes 集群上，并提供对流行的开源工具（如 Prometheus、Jaeger
    和 OpenTelemetry）的开箱即用支持。
- en: One of the key benefits of using New Relic Pixie is that it provides end-to-end
    visibility into the performance of applications and infrastructure, from the application
    code to the underlying Kubernetes resources. By collecting and analyzing data
    from various sources, including logs, metrics, and traces, Pixie can help pinpoint
    the root cause of performance bottlenecks and issues. This can significantly reduce
    the **Mean Time to Resolution** (**MTTR**) and improve application reliability
    and uptime.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 New Relic Pixie 的一个主要好处是，它提供了从应用代码到底层 Kubernetes 资源的端到端性能可见性。通过收集和分析来自不同来源的数据，包括日志、度量和追踪，Pixie
    可以帮助准确找出性能瓶颈和问题的根本原因。这可以显著减少 **平均修复时间** (**MTTR**)，并提高应用程序的可靠性和正常运行时间。
- en: Another advantage of New Relic Pixie is that it uses a unique instrumentation
    approach that does not require any code changes or configuration. Pixie uses **extended
    Berkeley Packet Filter** (**eBPF**) technology to collect performance data at
    the kernel level, allowing for low-overhead monitoring without adding any additional
    load to applications or infrastructure. This makes it an ideal solution for monitoring
    and tracing modern, cloud-native applications that are highly dynamic and scalable.
    Overall, New Relic Pixie provides a powerful and easy-to-use observability solution
    that can help teams to optimize the performance and reliability of their Kubernetes-based
    applications.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: New Relic Pixie 的另一个优势是，它采用了一种独特的监控方式，无需任何代码更改或配置。Pixie 使用 **扩展伯克利数据包过滤器** (**eBPF**)
    技术在内核级别收集性能数据，从而实现低开销监控，且不会给应用程序或基础设施
- en: Graylog
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Graylog
- en: Graylog is an open source log management platform that allows users to collect,
    index, and analyze log data from various sources. The platform provides a centralized
    location for monitoring and troubleshooting applications, systems, and network
    infrastructure. It is built on top of Elasticsearch, MongoDB, and Apache Kafka,
    which ensures high scalability and availability.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Graylog 是一个开源的日志管理平台，允许用户从各种来源收集、索引和分析日志数据。该平台提供了一个集中位置，用于监控和排查应用程序、系统和网络基础设施的问题。它构建在
    Elasticsearch、MongoDB 和 Apache Kafka 之上，确保了高可扩展性和可用性。
- en: Graylog has the ability to scale horizontally, which means that you can add
    additional Graylog nodes to handle increased log data volume and query load. The
    system can also distribute the workload across multiple nodes, which allows for
    efficient use of resources and faster processing of data. This scalability makes
    Graylog suitable for organizations of any size, from small start-ups to large
    enterprises.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Graylog 具有横向扩展能力，这意味着您可以添加额外的 Graylog 节点来处理增加的日志数据量和查询负载。该系统还可以将工作负载分配到多个节点，从而实现资源的高效利用和数据的快速处理。这种可扩展性使
    Graylog 适用于任何规模的组织，从小型初创公司到大型企业。
- en: Graylog uses Elasticsearch as the primary data store for indexing and searching
    log data. Elasticsearch is a powerful search and analytics engine that enables
    fast and efficient querying of large datasets. MongoDB in Graylog is used to store
    metadata about log data and manage the configuration and state of the system.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Graylog 使用 Elasticsearch 作为索引和搜索日志数据的主要数据存储。Elasticsearch 是一个强大的搜索和分析引擎，可以快速高效地查询大型数据集。Graylog
    中的 MongoDB 用于存储有关日志数据的元数据，并管理系统的配置和状态。
- en: 'Graylog also has a web-based user interface that allows users to search and
    visualize log data, as well as manage system configuration and settings:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Graylog 还提供了一个基于 Web 的用户界面，允许用户搜索和可视化日志数据，以及管理系统配置和设置：
- en: '![Figure 10.3 – Graylog logging system architecture](img/B18197_10_03.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – Graylog 日志系统架构](img/B18197_10_03.jpg)'
- en: Figure 10.3 – Graylog logging system architecture
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – Graylog 日志系统架构
- en: The architecture of this solution is pretty simple, as you can notice in the
    preceding diagram.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 该解决方案的架构非常简单，正如你在前面的图示中所看到的。
- en: Sentry
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sentry
- en: Sentry is an open source error tracking tool that helps developers monitor and
    fix errors in their applications. It allows developers to track errors and exceptions
    in real time, enabling them to quickly diagnose and fix issues before they become
    critical. Sentry supports multiple programming languages, including Python, Java,
    JavaScript, and Ruby, among others.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Sentry 是一个开源的错误追踪工具，帮助开发者监控和修复他们应用中的错误。它允许开发者实时追踪错误和异常，使他们能够在问题变得严重之前迅速诊断和修复问题。Sentry
    支持多种编程语言，包括 Python、Java、JavaScript 和 Ruby 等。
- en: One of the key benefits of using Sentry is its ease of setup and integration.
    Sentry can be easily integrated with popular frameworks and platforms, such as
    Django, Flask, and Rails, among others. It also provides a range of plugins and
    integrations with third-party tools, such as Slack and GitHub, to help developers
    streamline their workflows and collaborate more effectively.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Sentry 的一个关键优势是其易于设置和集成。Sentry 可以轻松与流行的框架和平台集成，如 Django、Flask 和 Rails 等。它还提供了一系列插件和与第三方工具的集成，如
    Slack 和 GitHub，以帮助开发者简化工作流程并更有效地协作。
- en: Sentry provides developers with detailed error reports that include information
    about the error, such as the stack trace, environment variables, and request parameters.
    This allows developers to quickly identify the cause of the error and take corrective
    action. Sentry also provides real-time notifications when errors occur, so developers
    can respond immediately.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Sentry 为开发者提供详细的错误报告，其中包含关于错误的信息，如堆栈跟踪、环境变量和请求参数。这使得开发者能够快速识别错误的根本原因并采取纠正措施。Sentry
    还在错误发生时提供实时通知，帮助开发者及时响应。
- en: Another benefit of using Sentry is its ability to analyze errors over time.
    Sentry allows developers to track error rates and identify patterns in error occurrence,
    making it easier to identify and address systemic issues in the application. This
    data can also be used to improve the overall performance and reliability of the
    application.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Sentry 的另一个好处是它能够分析错误随时间的变化。Sentry 允许开发者追踪错误率并识别错误发生的模式，这使得发现和解决应用中的系统性问题变得更容易。这些数据还可以用于改善应用的整体性能和可靠性。
- en: Sentry provides integration with Jira, which is a popular ticketing and issue-tracking
    system. The integration allows developers to create Jira issues directly from
    within Sentry, making it easier to manage and track issues that are discovered
    through Sentry.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Sentry 提供与 Jira 的集成，Jira 是一个流行的工单和问题追踪系统。该集成使得开发者可以直接从 Sentry 内创建 Jira 问题，从而更方便地管理和追踪通过
    Sentry 发现的问题。
- en: 'To set up the integration, you will first need to create a Jira API token and
    configure the integration settings in Sentry. Once the integration is set up,
    you can create Jira issues directly from Sentry by clicking the **Create JIRA
    issue** button on the **Error details** page. This will automatically populate
    the Jira issue with relevant information about the error, such as the error message,
    stack trace, and request parameters. You can find detailed instructions on how
    to do it on the official documentation page here: [https://docs.sentry.io/product/integrations/issue-tracking/jira/](https://docs.sentry.io/product/integrations/issue-tracking/jira/).'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置集成，首先需要创建 Jira API 令牌并在 Sentry 中配置集成设置。集成设置完成后，你可以通过点击 **创建 JIRA 问题** 按钮，在
    **错误详情** 页面上直接从 Sentry 创建 Jira 问题。这将自动填充有关错误的相关信息，如错误消息、堆栈跟踪和请求参数。你可以在官方文档页面上找到详细的操作说明：[https://docs.sentry.io/product/integrations/issue-tracking/jira/](https://docs.sentry.io/product/integrations/issue-tracking/jira/)。
- en: Sentry provides integrations with several other popular ticketing and issue-tracking
    systems, such as GitHub, Trello, Asana, Clubhouse, and PagerDuty, which allows
    you to trigger PagerDuty incidents directly from Sentry.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Sentry 提供与其他多个流行的工单和问题追踪系统的集成，如 GitHub、Trello、Asana、Clubhouse 和 PagerDuty，允许你直接从
    Sentry 触发 PagerDuty 事件。
- en: In this section, we have shown you several leading solutions that are both open
    source and suitable for self-hosting. Self-hosting may, however, not be what you
    are looking for, if you wish to lower the complexity of both deployment and maintenance.
    The next section will cover monitoring and logging software hosted for you by
    third-party companies.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您展示了几种领先的解决方案，这些解决方案既是开源的，又适合自托管。然而，如果您希望降低部署和维护的复杂性，自托管可能并不是您需要的。下一节将介绍由第三方公司为您托管的监控和日志软件。
- en: SaaS solutions
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SaaS 解决方案
- en: SaaS monitoring solutions are the easiest (and most expensive) to use. In most
    cases, what you’ll need to do is install and configure a small daemon (agent)
    on your servers or inside a cluster. And there you go, all your monitoring data
    is visible within minutes. SaaS is great if your team doesn’t have the capacity
    to implement other solutions but your budget allows you to use one. Here are some
    more popular applications for handling your monitoring, tracing, and logging needs.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: SaaS 监控解决方案是最容易（也是最昂贵）使用的。在大多数情况下，您需要做的就是在服务器或集群内安装并配置一个小型守护进程（代理）。这样，所有的监控数据就会在几分钟内显示出来。如果您的团队没有能力实施其他解决方案，但预算允许您使用SaaS，那它就是一个不错的选择。以下是一些更受欢迎的应用程序，用于处理您的监控、追踪和日志需求。
- en: Datadog
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Datadog
- en: '**Datadog** is a monitoring and analytics platform that provides visibility
    into the performance and health of applications, infrastructure, and networks.
    It was founded in 2010 by Olivier Pomel and Alexis Lê-Quôc and is headquartered
    in New York City, with offices around the world. According to Datadog’s financial
    report for the fiscal year 2021 (ending December 31, 2021), their total revenue
    was $2.065 billion, which represents a 60% increase from the previous year (fiscal
    year 2020).'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**Datadog** 是一个监控和分析平台，提供对应用程序、基础设施和网络性能与健康状况的可视化。它由 Olivier Pomel 和 Alexis
    Lê-Quôc 于 2010 年创立，总部位于纽约市，并在全球设有办公室。根据 Datadog 2021 财年（截至 2021 年 12 月 31 日）的财务报告，公司的总收入为
    20.65 亿美元，同比增长了 60%（相比 2020 财年）。'
- en: Datadog’s platform integrates with more than 450 technologies, including cloud
    providers, databases, and containers, allowing users to collect and correlate
    data from across their entire technology stack. It provides real-time monitoring,
    alerting, and collaboration tools that enable teams to troubleshoot issues, optimize
    performance, and improve the user experience.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Datadog 的平台与超过 450 种技术集成，包括云服务提供商、数据库和容器，使用户能够收集和关联来自整个技术栈的数据。它提供实时监控、警报和协作工具，使团队能够排查问题、优化性能并改善用户体验。
- en: Datadog allows users to monitor the health and performance of their servers,
    containers, and cloud services, providing insights into CPU usage, memory utilization,
    network traffic, and more.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Datadog 允许用户监控其服务器、容器和云服务的健康状况和性能，提供关于 CPU 使用率、内存利用率、网络流量等方面的见解。
- en: Datadog’s APM tools provide detailed insights into the performance of web applications,
    microservices, and other distributed systems, allowing users to identify and diagnose
    bottlenecks and issues.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Datadog 的 APM 工具提供关于 Web 应用程序、微服务和其他分布式系统性能的详细见解，使用户能够识别并诊断瓶颈和问题。
- en: Log management tools in Datadog enable users to collect, process, and analyze
    logs from across their entire infrastructure, helping to troubleshoot issues and
    identify trends.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Datadog 的日志管理工具使用户能够收集、处理和分析来自整个基础设施的日志，帮助排查问题并识别趋势。
- en: And finally, Datadog security monitoring helps detect and respond to threats
    by analyzing network traffic, identifying anomalies, and integrating with security
    solutions.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Datadog 的安全监控通过分析网络流量、识别异常并与安全解决方案集成，帮助检测和响应威胁。
- en: 'Dashboarding in Datadog allows users to visualize and analyze data from their
    applications, infrastructure, and network in a centralized location. Users can
    create a dashboard in Datadog by clicking on the **Create Dashboard** button and
    selecting the type of dashboard they want to create (e.g., **Infrastructure**,
    **APM**, **Log**, or **Custom**). They can then add widgets to the dashboard and
    configure their settings. There are multiple automated dashboards available; for
    instance, if you start sending data from a Kubernetes cluster, Datadog will show
    a dashboard for that. You can find more detailed information about using dashboards
    on the Datadog documentation website: [https://docs.datadoghq.com/getting_started/dashboards/](https://docs.datadoghq.com/getting_started/dashboards/).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Datadog中的仪表板功能使用户能够在集中位置可视化和分析来自应用、基础设施和网络的数据。用户可以通过点击**创建仪表板**按钮并选择他们希望创建的仪表板类型（例如，**基础设施**、**APM**、**日志**或**自定义**）来创建Datadog中的仪表板。然后，他们可以向仪表板添加小部件并配置其设置。有多个自动化仪表板可用；例如，如果您开始从Kubernetes集群发送数据，Datadog将显示一个相关的仪表板。您可以在Datadog文档网站上找到更多关于如何使用仪表板的详细信息：[https://docs.datadoghq.com/getting_started/dashboards/](https://docs.datadoghq.com/getting_started/dashboards/)。
- en: 'Widgets are the building blocks of a dashboard in Datadog. They can display
    metrics, logs, traces, events, or custom data. To add a widget, users can click
    on the **+** button and select the type of widget they want to add. They can then
    configure the widget’s settings, such as selecting the data source, applying filters,
    and setting the time range. For instance, you can view an example dashboard for
    the nginx web server on the Datadog web page: [https://www.datadoghq.com/dashboards/nginx-dashboard/](https://www.datadoghq.com/dashboards/nginx-dashboard/).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 小部件是Datadog仪表板的构建模块。它们可以显示指标、日志、追踪、事件或自定义数据。要添加小部件，用户可以点击**+**按钮并选择他们希望添加的小部件类型。然后，他们可以配置小部件的设置，如选择数据源、应用过滤器和设置时间范围。例如，您可以在Datadog网页上查看nginx
    Web服务器的示例仪表板：[https://www.datadoghq.com/dashboards/nginx-dashboard/](https://www.datadoghq.com/dashboards/nginx-dashboard/)。
- en: In addition to displaying data on a dashboard, Datadog provides various tools
    for exploring and analyzing data, such as the query builder, Live Tail, and tracing.
    Users can use these tools to dive deeper into the data and troubleshoot issues.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在仪表板上显示数据外，Datadog还提供了各种工具来探索和分析数据，例如查询构建器、Live Tail和追踪。用户可以使用这些工具深入挖掘数据并排查问题。
- en: New Relic
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: New Relic
- en: '**New Relic** is a cloud-based software analytics company that provides real-time
    insights into the performance of web and mobile applications. Founded in 2008
    by Lew Cirne (a software engineer and entrepreneur with experience at companies
    such as Apple and Wily Technology), New Relic has become a leading player in the
    **Application Performance Management** (**APM**) market. The company is headquartered
    in San Francisco and has offices in a number of other cities around the world.
    New Relic went public in 2014 and is traded on the New York Stock Exchange under
    the symbol *NEWR*.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**New Relic**是一家基于云的软件分析公司，提供有关Web和移动应用性能的实时洞察。New Relic由Lew Cirne（拥有在苹果公司和Wily
    Technology等公司工作经验的软件工程师和企业家）于2008年创立，现已成为**应用性能管理**（**APM**）市场的领先者。公司总部位于旧金山，并在全球多个城市设有办事处。New
    Relic于2014年上市，并在纽约证券交易所交易，股票代码为*NEWR*。'
- en: New Relic reported its 2021 fiscal year financial results in May 2021\. According
    to the report, New Relic’s revenue for the full fiscal year 2021 was $600.8 million,
    which represents a 3% increase compared to the previous fiscal year.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: New Relic于2021年5月公布了2021财年的财务报告。根据报告，New Relic在2021财年的总收入为6.008亿美元，较上一财年增长了3%。
- en: It’s worth noting that New Relic experienced some challenges in fiscal year
    2021, including the impact of the COVID-19 pandemic and a strategic shift to a
    new pricing model.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，New Relic在2021财年面临了一些挑战，包括COVID-19大流行的影响以及向新定价模式的战略转变。
- en: New Relic’s main purpose is to help companies optimize their application performance
    and identify issues before they become major problems. The platform provides real-time
    visibility into the entire application stack, from the frontend user interface
    to the backend infrastructure, allowing developers and operations teams to quickly
    identify bottlenecks and optimize performance.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: New Relic的主要目的是帮助公司优化其应用性能，并在问题变成重大问题之前识别它们。该平台提供了对整个应用堆栈的实时可见性，从前端用户界面到后端基础设施，使开发人员和运维团队能够快速识别瓶颈并优化性能。
- en: New Relic’s APM solution offers a variety of features, including code-level
    visibility, transaction tracing, real-time monitoring, and alerting. The platform
    also provides insights into application dependencies, database performance, and
    user behavior.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: New Relic 的 APM 解决方案提供多种功能，包括代码级可见性、事务追踪、实时监控和告警。该平台还提供有关应用依赖、数据库性能和用户行为的洞察。
- en: In addition to APM, New Relic also offers a range of other products and services,
    including infrastructure monitoring, mobile APM, and browser monitoring.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 APM，New Relic 还提供一系列其他产品和服务，包括基础设施监控、移动 APM 和浏览器监控。
- en: Ruxit
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ruxit
- en: '**Ruxit** is a comprehensive APM solution that helps businesses identify and
    troubleshoot performance issues across complex distributed applications, microservices,
    and cloud-native environments. It was initially founded in 2012 as an independent
    company and was later acquired by Dynatrace in 2015, expanding Dynatrace’s APM
    capabilities.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ruxit** 是一款全面的 APM 解决方案，帮助企业在复杂的分布式应用、微服务和云原生环境中识别和排查性能问题。它最初于2012年作为独立公司成立，并在2015年被
    Dynatrace 收购，扩展了 Dynatrace 的 APM 能力。'
- en: One of the key features of Ruxit is its ability to provide end-to-end visibility
    into the performance of applications, including code-level diagnostics, user experience
    monitoring, and infrastructure monitoring. This means that it can help businesses
    quickly pinpoint the root cause of performance problems and identify opportunities
    for optimization.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Ruxit 的一个关键特性是其能够提供应用性能的端到端可视化，包括代码级诊断、用户体验监控和基础设施监控。这意味着它可以帮助企业快速找出性能问题的根本原因，并发现优化的机会。
- en: Ruxit also has a range of other features designed to make monitoring and troubleshooting
    easier and more efficient. For example, it uses artificial intelligence and machine
    learning to automatically detect anomalies and performance degradations, alerting
    users in real time. It also provides a range of analytics and visualization tools
    to help users understand application performance trends and identify patterns
    over time.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Ruxit 还具有一系列其他功能，旨在使监控和故障排除变得更加简单和高效。例如，它使用人工智能和机器学习自动检测异常和性能下降，并实时警报。它还提供一系列分析和可视化工具，帮助用户了解应用性能趋势，并识别随着时间推移的模式。
- en: In addition to its monitoring capabilities, Ruxit also provides a range of integrations
    with other tools and services commonly used in modern application environments.
    This includes integration with container orchestration platforms such as Kubernetes,
    as well as with popular application development frameworks and tools.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 除了监控功能外，Ruxit 还提供与现代应用环境中常用的其他工具和服务的集成。这包括与容器编排平台（如 Kubernetes）的集成，以及与流行的应用开发框架和工具的集成。
- en: Splunk
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Splunk
- en: '**Splunk** was founded in 2003 by Erik Swan, Rob Das, and Michael Baum in San
    Francisco, California. Since then, the company has grown significantly and is
    now a publicly traded company with a global presence. Splunk’s software solutions
    are used by organizations in various industries, including financial services,
    healthcare, government, and retail, to name a few.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**Splunk** 成立于2003年，由 Erik Swan、Rob Das 和 Michael Baum 在美国加利福尼亚州旧金山创办。从那时起，公司的规模迅速扩大，并成为一家全球化的上市公司。Splunk
    的软件解决方案被各行各业的组织广泛使用，包括金融服务、医疗保健、政府和零售等行业。'
- en: Splunk, you guessed it, is a data analysis and monitoring software solution
    used to monitor, search, analyze, and visualize machine-generated data in real
    time. The software can gather and analyze data from various sources, including
    servers, applications, networks, and mobile devices, and provide insights into
    the performance and behavior of an organization’s IT infrastructure.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所猜到的，Splunk 是一款数据分析和监控软件解决方案，用于实时监控、搜索、分析和可视化机器生成的数据。该软件可以从多个来源收集和分析数据，包括服务器、应用、网络和移动设备，并提供关于组织
    IT 基础设施性能和行为的洞察。
- en: The main uses of Splunk include security monitoring, application monitoring,
    log management, and business analytics. With Splunk, users can identify security
    threats, troubleshoot application performance issues, monitor network activity,
    and gain insights into business operations.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Splunk 的主要用途包括安全监控、应用监控、日志管理和业务分析。使用 Splunk，用户可以识别安全威胁、排查应用性能问题、监控网络活动，并深入了解业务运营。
- en: One of the key features of Splunk is its ability to collect and analyze data
    from a wide range of sources, including structured and unstructured data. The
    software can also scale to handle large volumes of data, making it a powerful
    tool.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Splunk的一个关键特点是其能够从多种来源收集和分析数据，包括结构化数据和非结构化数据。该软件还可以扩展以处理大量数据，使其成为一个强大的工具。
- en: In this section, we have presented you with a few leading solutions hosted by
    third-party companies that are ready to use; they just require integration with
    your systems. In the next section, we are going to describe and explain retention
    policies for both logs and metrics.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您展示了一些由第三方公司托管的领先解决方案，这些解决方案已经可以使用；它们只需要与您的系统进行集成。在下一节中，我们将描述并解释日志和指标的保留策略。
- en: Log and metrics retention
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志和指标保留
- en: '**Data retention** refers to the practice of retaining data, or keeping data
    stored for a certain period of time. This can involve storing data on servers,
    hard drives, or other storage devices. The purpose of data retention is to ensure
    that data is available for future use or analysis.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据保留**是指保留数据或将数据存储一定时间的做法。这可以包括将数据存储在服务器、硬盘或其他存储设备上。数据保留的目的是确保数据在未来可以用于使用或分析。'
- en: Data retention policies are often developed by organizations to determine how
    long specific types of data should be retained. These policies may be driven by
    regulatory requirements, legal obligations, or business needs. For example, some
    regulations may require financial institutions to retain transaction data for
    a certain number of years, while businesses may choose to retain customer data
    for marketing or analytics purposes.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 数据保留策略通常由组织制定，以确定特定类型的数据应保留多久。这些策略可能受到法规要求、法律义务或业务需求的推动。例如，一些法规可能要求金融机构保留交易数据若干年，而企业可能会选择保留客户数据用于营销或分析目的。
- en: Data retention policies typically include guidelines for how data should be
    stored, how long it should be retained, and when it should be deleted. Effective
    data retention policies can help organizations to manage their data more efficiently,
    reduce storage costs, and ensure compliance with applicable regulations and laws.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 数据保留策略通常包括有关如何存储数据、数据应保留多长时间以及何时应删除数据的指南。有效的数据保留策略可以帮助组织更高效地管理数据、减少存储成本，并确保遵守适用的法规和法律。
- en: When it comes to data retention strategies, organizations have a number of options
    to consider. Depending on the specific needs of the organization, different strategies
    may be more or less suitable.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据保留策略方面，组织有多种选择可供考虑。根据组织的具体需求，不同的策略可能更适合或不适合。
- en: Full retention
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完全保留
- en: In this strategy, all data is kept indefinitely. This is often used for compliance
    purposes, such as for regulatory requirements that mandate data retention for
    a specific period of time. This strategy can be expensive as it requires a large
    amount of storage, but it can also provide significant benefits in terms of historical
    analysis and trend spotting.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种策略中，所有数据将被无限期保留。通常用于合规目的，例如满足法规要求，要求数据在特定时间段内进行保留。虽然这种策略可能会很昂贵，因为它需要大量的存储，但它也可以在历史分析和趋势分析方面提供显著的好处。
- en: Time-based retention
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于时间的保留
- en: Time-based retention is a strategy where data is kept for a specific period
    of time before it is deleted. This strategy is often used to balance the need
    for data with storage costs. The retention period can be set based on regulatory
    requirements, business needs, or other factors.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 基于时间的保留是一种策略，其中数据在被删除之前会被保留特定的时间段。这种策略通常用于平衡数据需求与存储成本。保留期限可以根据法规要求、业务需求或其他因素来设定。
- en: Event-based retention
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于事件的保留
- en: Event-based retention is a strategy where data is kept based on specific events
    or triggers. For example, data may be retained for a specific customer or transaction,
    or based on the severity of an event. This strategy can help to reduce storage
    costs while still maintaining access to important data.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 基于事件的保留是一种策略，其中数据根据特定事件或触发条件进行保留。例如，数据可以根据特定的客户或交易进行保留，或者根据事件的严重性进行保留。这种策略可以帮助减少存储成本，同时仍保持对重要数据的访问。
- en: Selective retention
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有选择的保留
- en: Selective retention is a strategy where only certain types of data are retained.
    This strategy can be used to prioritize the retention of the most important data
    while reducing storage costs. For example, an organization may choose to retain
    only data related to financial transactions or customer interactions.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 选择性保留是一种仅保留特定类型数据的策略。这种策略可以用来优先保留最重要的数据，同时减少存储成本。例如，一个组织可能选择仅保留与财务交易或客户互动相关的数据。
- en: Tiered retention
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分层保留
- en: Tiered retention is a strategy where data is stored in different tiers based
    on its age or importance. For example, recent data may be stored on fast, expensive
    storage, while older data is moved to slower, less expensive storage. This strategy
    can help to balance the need for fast access to recent data with the need to reduce
    storage costs over time.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 分层保留是一种根据数据的年龄或重要性将数据存储在不同层级中的策略。例如，最近的数据可能会存储在快速且昂贵的存储上，而较旧的数据则移至速度较慢且成本较低的存储。这种策略可以帮助平衡对近期数据快速访问的需求与逐步降低存储成本的需求。
- en: Each of these data retention strategies has its own benefits and drawbacks,
    and the best strategy for an organization will depend on its specific needs and
    goals. It’s important to carefully consider the trade-offs between cost, storage
    capacity, and the value of the data being retained when choosing a data retention
    strategy.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 每种数据保留策略都有其自身的优点和缺点，适合组织的最佳策略将取决于其特定的需求和目标。在选择数据保留策略时，仔细考虑成本、存储容量和所保留数据的价值之间的权衡是非常重要的。
- en: The most common mistake in organizations is to use full retention strategies
    *just in case*, which often leads to exhausted disk space and increased cloud
    costs. Sometimes this strategy is justified, but not in most cases.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 组织中最常见的错误是采用全量保留策略*以防万一*，这通常会导致磁盘空间耗尽和云成本增加。有时这种策略是合理的，但在大多数情况下并不适用。
- en: Summary
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the differences between monitoring, tracing, and
    logging. Monitoring is the process of observing and collecting data on a system
    to ensure it’s running correctly. Tracing is the process of tracking requests
    as they flow through a system to identify performance issues. Logging is the process
    of recording events and errors in a system for later analysis.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了监控、追踪和日志记录之间的差异。监控是观察和收集系统数据的过程，以确保系统正常运行。追踪是跟踪请求在系统中流动的过程，以识别性能问题。日志记录是记录系统事件和错误的过程，以便后续分析。
- en: We also discussed cloud solutions for monitoring, logging, and tracing in Azure,
    GCP, and AWS. For Azure, we mentioned Azure Monitor for monitoring and Azure Application
    Insights for tracing. For AWS, we mentioned CloudWatch for monitoring and logging,
    and X-Ray for tracing.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了在Azure、GCP和AWS中的云解决方案，用于监控、日志记录和追踪。对于Azure，我们提到了Azure Monitor用于监控，Azure
    Application Insights用于追踪。对于AWS，我们提到了CloudWatch用于监控和日志记录，X-Ray用于追踪。
- en: We then went on to explain and provide an example of configuring the AWS CloudWatch
    agent on an EC2 instance. We also introduced AWS X-Ray with a code example to
    show how it can be used to trace requests in a distributed system.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们解释了如何配置AWS CloudWatch代理在EC2实例上运行，并通过一个代码示例介绍了如何使用AWS X-Ray在分布式系统中追踪请求。
- en: Finally, we named some open source and SaaS solutions for monitoring, logging,
    and tracing, including Grafana, Prometheus, Datadog, New Relic, and Splunk. These
    solutions provide various features and capabilities for monitoring and troubleshooting
    systems, depending on the user’s requirements and preferences.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们列举了一些用于监控、日志记录和追踪的开源和SaaS解决方案，包括Grafana、Prometheus、Datadog、New Relic和Splunk。这些解决方案根据用户的需求和偏好，提供了不同的监控和故障排除功能。
- en: 'In the next chapter, we will get hands-on with automating server configuration
    with the use of a configuration as code solution: Ansible.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过使用配置即代码解决方案：Ansible，亲自实践自动化服务器配置。
