- en: '[*Chapter 8*](B17124_08_Final_SK_ePub.xhtml#_idTextAnchor189): AWS Database
    Services'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most applications need to store, access, organize, and manipulate data in some
    way. Normally, the data would reside externally to the actual application in what
    we call a *database* for several reasons, including efficiency improvements. Databases
    are designed to do more than simply store data, however. Depending on the type
    of database, data can be organized and stored in a structured or semi-structured
    manner, offer high-speed access to the data, and give you the ability to perform
    queries and scans against the data. Data can also be combined from different *tables*
    within the database to help you create complex analytics and reporting. Typical
    examples of where you would use a database include storing customer records and
    their orders for your e-commerce website, storing a product listing catalog, and
    storing temperature information from your home IoT thermostat devices. AWS offers
    three primary database solutions and several others for specific application types.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Managed databases versus unmanaged databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to database concepts and models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to **Amazon Relational Database Service** (**Amazon RDS**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about Amazon DynamoDB (aNoSQL database solution)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the use cases for Amazon Redshift and data warehousing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the importance of in-memory caching options with Amazon Elasticache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about additional database services for specific niche requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database Migration Service** (**DMS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the various managed databases solutions
    offered by AWS and launch your very first Amazon Relational Database service running
    the MySQL engine. Later in this book, we will configure a database to store data
    that's been uploaded via a web application.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete the exercises in this chapter, you will need to access your AWS
    account and be logged in as our fictitious administrator, **Alice**, using her
    IAM user credentials.
  prefs: []
  type: TYPE_NORMAL
- en: Managed databases versus unmanaged databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditionally, in an on-premises setup, you would configure a server (physical
    or virtual) with a base operating system and then proceed to install the database
    software on it. Because the primary purpose of a database is to store data, you
    would also need to ensure that you had adequate storage attached to your server.
    Due to the importance of the data store, you would take additional security measures
    to protect the data and ensure you had adequate backups and copies of the data
    (ideally stored offsite in another location) in case of disasters.
  prefs: []
  type: TYPE_NORMAL
- en: On AWS, you can set up an **Elastic Compute Cloud** (**EC2**) instance and install
    your database, such as **Microsoft SQL Server** or **Oracle**, in the same manner
    to serve your frontend web and application servers as required. In this case,
    you take full ownership of managing the database, provisioning the required amount
    of **Elastic Block Store** (**EBS**) volumes for storage, and ensuring adequate
    backups are made. You also need to design for high availability and performance.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, AWS also offers **managed database solutions**. AWS takes care
    of provisioning your database instances, where you specify certain parameters
    to ensure the required capacity for your application. AWS will also provision
    and manage the required storage for your database, as well as perform all backups
    and replications as required. Ultimately, you get a fully managed solution where
    AWS takes care of almost every configuration option you choose, except for ensuring
    that your application is optimized for the chosen database solution.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about additional database services for specific niche requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we introduced you to the concept of unmanaged databases and
    how traditionally, we would have to install our database software on a physical
    or virtual server. However, hosting a database on a server carries additional
    administrative efforts. While on AWS, you can install a database on an EC2 instance,
    it makes more sense to consider using AWS managed database offerings such as **Amazon
    RDS** as this reduces the management burden on the customer. In the next section,
    we will introduce you to database concepts and models.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to database concepts and models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, there are several types of database models, but the most common are *relational*
    and *non-relational* models. Relational databases have existed for years and allow
    you to efficiently manage your data with the ability to perform complex queries
    and analyses. However, they have certain restrictions, such as the fact that you
    need to define the database schema (its structure) before you can add data, and
    changing this later can be difficult. Non-relational databases offer a lot more
    flexibility and are used for many modern-day web and mobile applications. Let's
    look at the key differences.
  prefs: []
  type: TYPE_NORMAL
- en: Relational databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A `tables`. Within each table, you have rows and columns – columns define `attributes`
    for your data and rows contain individual `records` in the database. Each row
    in your table then contains data that relates to the attributes that were defined
    in the columns. So, for example, in a customer's table, you can have columns such
    as `First Name` and `Last Name`, then your rows will contain data related to those
    columns comprised of your customer's first and last names.
  prefs: []
  type: TYPE_NORMAL
- en: Another important factor to consider with `First Name` and a second column called
    `Date of Birth`, then you need to define the type of data you will permit in each
    of those columns prior to adding any data; for the `First Name` column, the type
    of data will be `string`, whereas for the `Date of Birth` column, you will define
    the type of data as `date`.
  prefs: []
  type: TYPE_NORMAL
- en: 'An important column (`attribute`) that must exist in a relational database
    is the `Primary Key` field. Each record must have a primary key that is unique
    across the whole table. This ensures that each record within the table is unique,
    allowing you to easily query specific records in the table. As shown in the following
    table, the customer records table has a primary key called `CustomerID`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Customer contact table'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Customer contact table
  prefs: []
  type: TYPE_NORMAL
- en: A database can also host multiple tables for specific record sets. Rather than
    storing all the records within a single table, you can have separate tables for
    related data. So, for example, in one table, you can have your *customer contact*
    details and in another, you can have your *customer order* details. In most cases,
    the tables will have some relationship with other tables in the same database.
    In this example, the tables are related to specific customers; one for their contact
    details and another for their orders.
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of separating different sets of data into separate tables is to
    allow for better management, performance, and to avoid duplicate data. For example,
    if you have a single table to host customers'' contact details as well as their
    orders, then you would have multiple records relisting the customers'' contact
    information for every single order they placed. By separating the orders from
    the contact details into separate tables, we can avoid this duplication of data
    and improve performance. The following is an example of a customers'' orders table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Customer order table'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Customer order table
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding two tables, note that we avoided replicating the data by separating
    the customer contact details table from the orders table. If we have all the data
    in one table, then we would have multiple columns with the same pieces of information
    repeated, such as First Name and Last Name for every order placed by the same
    customer.
  prefs: []
  type: TYPE_NORMAL
- en: The tables in a database can relate to each other, and we need some form of
    connection between the two tables to effectively structure the data. In the previous
    example, rather than repeating all customer address details in the orders table,
    we simply include the `Customer-ID` column, where we identify which customer the
    order relates to. Remember that the `Customer-ID` column is the primary key of
    the **Customer Contacts Table**, so each Customer ID uniquely identifies a customer.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, we can now query the database by combining data from both columns
    using the Customer ID as a reference point. We can then produce a report from
    a query to list all the orders that have been placed by a customer, whose `Customer-ID`
    is `Cust002`. In this report, we can list the customer contact details, which
    will be extracted from the first table, and the list of orders placed from the
    second table, where `Customer-ID` is `Cust002`. This report could then be sent
    to the customer as a statement of account.
  prefs: []
  type: TYPE_NORMAL
- en: Relational databases enable you to perform such complex queries, analyses, and
    reports from large datasets. Performance is directly correlated to the types of
    queries you need to perform and the volume of data you host. Often, this means
    that your infrastructure may need to be upgraded from time to time to cope with
    demanding applications.
  prefs: []
  type: TYPE_NORMAL
- en: Relational databases use the `SELECT` statement enables you to query specific
    data, whereas the `WhereHERE` statement enables you to restrict your `SELECT`
    query to match a specific condition. For the *AWS Certified Cloud Practitioner*
    exam, you are not expected to know how to use the SQL language.
  prefs: []
  type: TYPE_NORMAL
- en: Relational databases are also known as **Online Transaction Processing** (**OLTP**)
    **databases**. **OLTP databases** are designed for adding, updating, and deleting
    small amounts of data in a database regularly. Typical examples include a *customer
    orders* database for an e-commerce website or a student's database for a university.
  prefs: []
  type: TYPE_NORMAL
- en: Non-relational (NoSQL) databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With relational databases, you store data in a structured format of a defined
    schema in tables. Each column of a table (known as an attribute) will only hold
    one type of data and this needs to be predefined. You usually query multiple tables
    of related data and combining queries across your tables can yield required pieces
    of information.
  prefs: []
  type: TYPE_NORMAL
- en: However, the problem with relational databases is the lack of flexibility since
    data needs to be structured. Furthermore, the more tables you have across your
    database, the more complex the queries tend to be, and the more resources are
    required to run and manage the databases. Relational databases also do not lend
    themselves well when trying to perform thousands of reads and writes to the database
    per second.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, non-relational databases do not follow the traditional relational
    approach to storing data. Non-relational database data is stored using different
    models, depending on the type of data being stored. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Key-value stores**: This is a collection of key-value pairs contained within
    an object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Document data stores**: This is typically a **JavaScript Object Notation**
    (**JSON**) format document (although other formats can be used) that''s used to
    store data in a structured or semi-structured form. Data can be comprised of nested
    attributes of key-value pairs. All the documents in the store are not required
    to maintain identical data structures and this offers greater levels of flexibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: "**Columnar data stores**: Data is organized into cells grouped by columns rather\
    \ \Lthan by rows. Furthermore, reads and writes are carried out using columns\
    \ rather than rows."
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no requirement to predefine the schema of the database, and this creates
    a lot of flexibility because you can freely add fields (attributes) to a document
    without the need to define them first. Therefore, you have documents with different
    numbers of fields. For example, one document listing a customer's details could
    include their name, address details, order history, and credit card information,
    while another document could include a list of their favorite products.
  prefs: []
  type: TYPE_NORMAL
- en: Non-relational databases were developed as an alternative to relational databases
    where the flexibility of the schema was required, as well as to handle very large
    data stores that required thousands of reads/writes per second, something that
    relational databases have traditionally found difficult to do. Non-relational
    databases can cope with this kind of load because a query does not have to view
    several related tables to extract the results. Furthermore, a non-relational database
    can handle frequent changes to the data.
  prefs: []
  type: TYPE_NORMAL
- en: Like relational databases, though, non-relational databases do require you to
    have at least one primary key field (attribute) and this is the only attribute
    required. Beyond this, your database tables are effectively schemaless. The primary
    key is used to ensure that each record of the database is unique.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we reviewed the primary differences between relational and
    non-relational databases. We looked at the use cases for both types of database
    solutions and compared the key differences between the two. On AWS, both relational
    databases and non-relational databases are offered. In the next section, we will
    look at the services that are offered in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Amazon RDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Amazon RDS** offers traditional relational databases as fully managed services
    on the AWS platform. Ideal for transactional database requirements, also known
    as **OLTP**, AWS offers six different database engines, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: MySQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PostgreSQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MariaDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft SQL server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oracle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Aurora
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another term you might have heard of is **Relational Database Management System**
    (**RDBMS**). An RDBMS performs functions to **create, read, update, and delete**
    (**CRUD**) data from the database using an underlying software component, which
    we call the database engine.
  prefs: []
  type: TYPE_NORMAL
- en: An important point to understand here is that when you choose to set up an Amazon
    RDS database, you are setting up a *database instance* with a chosen engine to
    run on that instance. You can then create one or more databases supported by that
    engine on your database instance. This means you can have several databases running
    on an individual database instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, on Amazon RDS, when you set up a database instance, you specify
    hardware capabilities in the form of CPU and memory allocation. The type of instance
    will also determine the maximum storage bandwidth and network performance that
    the instance can offer. AWS offers three different types of instance classes with
    varying virtual hardware specifications and is designed for various uses cases.
    These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Standard classes (includes m classes**): These classes offer a balance of
    compute, memory, and network resources, and they are ideal for most application
    requirements. Standard classes offer the following specs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Between 2 and 96 vCPUs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Up to 384 GB of memory
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory-optimized classes (includes r and x classes)**: These classes are
    ideal for most demanding applications that require greater levels of memory and
    are optimized for memory-intensive applications. Memory-optimized classes offer
    the following specs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Between 4 and 128 vCPUs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Up to 3,904 GB of memory
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Burstable classes (includes t classes)**: These classes are designed for
    nonproduction databases and provide a baseline performance level, with the ability
    to burst to full CPU usage. Burstable classes are ideal for database workloads
    with moderate CPU usage that experience occasional spikes. Burstable classes offer
    the following specs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Between 1 and 8 vCPUs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Up to 32 GB of memory
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the different **DB instance class** options
    you can select from:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Database instance class options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Database instance class options
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the compute resource, Amazon RDS also requires storage capabilities
    to host all the required data. The storage platform runs on Amazon **EBS**, so
    it is decoupled from the actual database instance class. This allows you to upgrade
    the storage volumes without necessarily having to upgrade the instance class and
    vice versa, so long as compatibility is maintained. The volume''s throughput is
    determined by the instance types chosen, as well as the **input/output operations
    per second** (**IOPS**) that the EBS volume supports. AWS offers the following
    different storage options for your databases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**General Purpose SSD**: Designed for standard workloads and ideal for most
    databases, General Purpose SSD volumes offer between 20 GiB to 64 TiB of storage
    data for MariaDB, MySQL, PostgreSQL, and Oracle databases, and between 20 GiB
    to 16 TiB for Microsoft SQL Server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of IOPS that's achieved is dependent on the size of the storage volume,
    with a baseline I/O performance of 3 IOPS per GiB (minimum 100 IOPS). The larger
    the volume size, the higher the performance; for example, a 60 GiB volume would
    give you 180 IOPS.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: General Purpose SSDs also offer bursts in performance for volumes less than
    1 TiB in size for extended periods. This means that smaller volumes will get an
    additional performance boost when required and you do not need to allocate unnecessary
    storage for short-term occasional spikes. Bursting is not relevant for volume
    sizes above 1 TiB, however.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Provisioned IOPS SSD**: AWS recommends using Provisioned IOPS SSDs for production
    applications that require fast and consistent I/O performance. With Provisioned
    IOPS SSDs, you specify the IOPS rate and the size of the volume. Like General
    Purpose SSDs, you can allocate up to 64 TiB of storage, depending on the underlying
    database engine you use. Provisioned IOPS SSD does not offer any bursting, however.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Magnetic**: AWS also offers magnetic storage volumes for backward compatibility.
    They are not recommended for any production environments and are limited to 1,000
    IOPS and up to 3 TiB of storage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ultimately, you can upgrade your storage if required, but this will usually
    require a short outage, typically of a few minutes (for Magnetic, this can take
    much longer), so this must be planned for.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying in Amazon VPCs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon RDS is a regional service, which means that you need to select the Region
    you want to deploy your database instance in first. Amazon RDS database instances
    can only be deployed in a VPC, and like EC2 instances, in a specified subnet.
    Since a subnet is always only associated with a single Availability Zone, this
    also means that if there is an Availability Zone failure, your database will not
    be accessible. With Amazon RDS, you can only deploy a **single master database
    instance**. This type of instance can perform both read and write operations to
    the database. Amazon does offer various solutions in case the master database
    instance fails and we look at these options later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying your RDS database in a VPC gives granular control over how the databases
    is going to be accessed and allows you to configure various network security components
    such as the private IP addressing range you will use, security groups to protect
    your RDS instance, and **Network Access Control Lists** (**NACLs**) to protect
    traffic in the subnet that will host the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploying your RDS database in a VPC also means that you can configure various
    architectures from which to access that database. The following are some scenarios
    that you could configure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`3306` for a MySQL RDS instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A DB instance in a VPC that''s accessed by an EC2 instance in a different
    VPC**: In [*Chapter 6*](B17124_06_Final_SK_ePub.xhtml#_idTextAnchor122), *AWS
    Networking Services, VPCs, Route53, and CloudFront*, we discussed that you could
    connect two VPCs using a service known as VPC peering. Instances in either VPC
    can then communicate with each other over that peering connection using private
    IP addresses as though they were within the same network. Once the peering connection
    has been established, you would then need to configure the necessary rules for
    your security groups to enable traffic to flow between the EC2 instance and your
    RDS database. VPC peering can allow you to peer connections between VPCs in the
    same Region, cross-Region, and even across AWS accounts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A DB instance in a VPC that''s accessed by a client application through the
    internet**: While nothing is stopping you from placing your RDS database instance
    in a public subnet of a VPC, this is not considered a best practice for production
    environments. Databases are considered backend services that contain critical
    and maybe sensitive information. They should always be placed in the private subnet
    of the VPC. Placing your RDS database in a public subnet should only really be
    done for testing purposes or specific use cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A DB instance in a VPC that''s accessed by a private network**: With a VPC
    in place, you can set up a VPN tunnel or a Direct Connect service between your
    on-premises network and the VPC. This allows you to place your RDS database in
    a private subnet of the VPC, and still be able to access it from your corporate
    offices via the VPN tunnel or Direct Connect service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For production environments, always place your RDS database instances in the
    private subnet(s) of your VPC. The architecture shown in the following diagram
    illustrates one such best practice methodology. Here, the RDS database has deployed
    a private subnet, dubbed a **database subnet**. To access the database via a standard
    web application, traffic from the internet is routed via an **Elastic Load Balancer**
    (**ELB**) (discussed in detail in [*Chapter 9*](B17124_09_Final_SK_ePub.xhtml#_idTextAnchor223),
    *High Availability and Elasticity on AWS*) and distributed to web servers placed
    in another set of private subnets within your VPC. Your web servers then connect
    to the RDS database to perform any data operations such as adding, updating, or
    deleting records as required by the application. Traffic can flow based on the
    rules that have been defined by your **Network Access Control Lists** (**NACLs**)
    and security groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Amazon RDS deployed in a VPC in private subnets'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.4 – Amazon RDS deployed in a VPC in private subnets
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, users from the internet can access the database via
    the web/app server rather than have direct access to the database. Users will
    connect to the web/app servers via an **Application Load Balancer** (**ALB**)
    (which distributes traffic among healthy EC2 instances in the fleet). The web/app
    server will have a process in place to send database operations requests to the
    RDS database in the backend private subnet.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the RDS database will only accept traffic from the EC2 instances that
    are attached to the appropriate security groups. This ensures that if the EC2
    instances are replaced or if additional EC2 instances are attached to the fleet,
    and if they are attached to the same security sroup, they will be able to communicate
    with the RDS database.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Your applications connect to the backend database via an RDS DNS endpoint name,
    rather than the database instance's specific IP addresses. This allows you to
    easily manage failovers in the event of a disaster, which we will discuss next
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Backup and recovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your database is going to be very important to you and ensuring that you can
    recover from failures, data loss, or even data corruption is going to be an important
    factor in your design architecture. AWS enables you to address your disaster recovery
    and business continuity concerns, and Amazon RDS comes with several configuration
    options to choose from.
  prefs: []
  type: TYPE_NORMAL
- en: What are your RPO and RTO requirements?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When deciding on a strategy to protect your database on AWS from unexpected
    failures or data corruption, you need to consider what configuration options are
    going to meet your organization''s expectations for recovery. If your business
    hosts critical data that needs to be recovered fast in the event of a failure,
    you need to design an architecture that will support this requirement. To help
    you identify how critical your recovery is going to be, you need to determine
    your **Recovery Point Objective** (**RPO**) and **Recovery Time Objective** (**RTO**).
    These two parameters will help you design a recovery strategy that meets your
    business requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '**RTO**: This represents the time (in hours) it takes to recover from a disaster
    and return to a working state. The time taken will involve provisioning a new
    database instance, performing a restore job, and any other administrative or technical
    tasks that need to be completed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RPO**: This represents how much data (again, as a measure of time, and generally
    in hours) you will lose in the event of a disaster. The shorter the RPO, the less
    data you are likely to lose in the event of a failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your organization stipulates that it can only afford an RTO of 2 hours and
    an RPO of 4 hours, this means that you need to recover from failure to a working
    state within 2 hours and the maximum amount of data you can afford to lose (probably
    because you can create that data) is 4 hours' worth.
  prefs: []
  type: TYPE_NORMAL
- en: Based on your RPO and RTO levels, you can then choose a disaster recovery strategy
    that fits your requirements. For example, if your RPO is set to 4 hours and your
    recovery strategy was based on restoring older backups of your database, then
    you should be performing a backup of your database every 4 hours.
  prefs: []
  type: TYPE_NORMAL
- en: High availability with Multi-AZ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For Amazon RDS database engines running MariaDB, MySQL, PostgreSQL, Oracle,
    Microsoft SQL, and Amazon Aurora, AWS offers high availability and failover support
    using the **RDS Multi-AZ** solution. Multi-AZ is an architectural design pattern
    where a primary (master) copy of your database is deployed in one Availability
    Zone and a secondary (standby) copy is deployed in another Availability Zone.
    Data is then **synchronously** replicated from the master copy to the standby
    copy continuously. Normally, with relational databases, only one database can
    hold the *master* status, meaning that data can be both written to and read from
    it. In the case of Multi-AZ deployments, this is still true, and the standby copy
    of the database simply receives all the changes that have been made to the master
    synchronously. However, you cannot write or read from the standby directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the master copy of your database fails, then AWS will perform a failover
    operation to the standby copy of the database. The standby copy will be promoted
    to become the new master, and the previous master will be terminated and replaced
    with another standby copy. Replication will then be initiated in the opposite
    direction. During failover, your application may experience a brief outage (about
    2 minutes), but then will be able to reconnect to the database (the standby copy
    that has been promoted to the new master) and continue operating:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Amazon RDS configured with Multi-AZ'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Amazon RDS configured with Multi-AZ
  prefs: []
  type: TYPE_NORMAL
- en: Failover can be triggered for several reasons other than Availability Zone outages,
    including patching the master database or upgrades of the instance. You can also
    perform a failover test to ensure that the configuration has been set up correctly
    by performing a reboot of the master database and requesting a failover operation
    on reboot.
  prefs: []
  type: TYPE_NORMAL
- en: With Multi-AZ, you can reduce your RTO and RPO levels drastically. Because existing
    data has already been replicated to a standby copy in another Availability Zone,
    failover happens in a matter of minutes and data loss is minimized.
  prefs: []
  type: TYPE_NORMAL
- en: However, in certain circumstances, Multi-AZ alone as a DR strategy may not be
    enough. For example, what happens if there is data corruption on the master copy
    of your database? That corrupted data will be replicated across to the standby
    too.
  prefs: []
  type: TYPE_NORMAL
- en: Backup and recovery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'AWS also offers options to perform regular backups of your database, which
    you can use to perform point-in-time restores. AWS offers two options here: *automatic
    backups* and *manual snapshots*.'
  prefs: []
  type: TYPE_NORMAL
- en: Automatic backups
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AWS offers a fully managed automatic backup service free of cost up to the
    total size of your database. While performing automatic backups, the first snapshot
    that''s created will be a full backup; subsequent snapshots will be incremental,
    ensuring that only changes to the data are backed up. Some additional features
    of automatic backups include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Backup window**: Automatic backups are performed during a predefined window
    that is configurable for the customer. The default backup time allocated is 30
    minutes but you can change this as well. Furthermore, if the backup requires more
    time than what''s been allotted to the backup window, the backup continues after
    the window ends, until it finishes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0` days, which essentially translates to disabling backup operations. If you
    disabled automatic backups at the time of launching your RDS instance, you can
    enable this later by setting the backup retention period to a positive non-zero
    value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LatestRestorableTime`, which is typically the last 5 minutes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual snapshots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to automatic backups, you can also create manual snapshots of your
    database, which can provide additional protection. You can then use manual snapshots
    to restore your DB instance to a known state as frequently as you like.
  prefs: []
  type: TYPE_NORMAL
- en: Manual snapshots can be very useful if you plan to make a major change to your
    database and would like an additional snapshot before making that change.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic and manual backups are particularly useful if you need to restore
    due to data corruption. Remember that even if you have Multi-AZ enabled, any data
    corruption on the master copy will be replicated across to the standby, and having
    older backups can enable you to revert your database to a time before that data
    corruption occurred.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Region snapshots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can copy your snapshots across Regions to improve the availability of your
    backups even further, in the event of a regional outage or disaster. You can also
    configure the replication of your automatic backups and transactional logs across
    to another Region. Amazon RDS initiates a cross-Region copy of all snapshots and
    transaction logs as soon as they are ready on the DB instance.
  prefs: []
  type: TYPE_NORMAL
- en: I/O suspense issue
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An important behavior pattern to be aware of is that a brief I/O suspension
    (usually lasting only a few seconds) is experienced when your backup process initializes.
    In scenarios where you have a single Database instance deployed, this results
    in a brief outage when connecting to the database. This means that if your backup
    operations are taking place during business hours, then users may experience some
    interruption during the backup process.
  prefs: []
  type: TYPE_NORMAL
- en: To work around this problem, you can choose to ensure that your backup processes
    take place outside of business hours, or better still, follow Amazon's recommendations
    for deploying a Multi-AZ deployment for database, particularly for MariaDB, MySQL,
    Oracle, and PostgreSQL engines. This is because, in a Multi-AZ configuration,
    the backup is taken from the standby copy of the database and not the master.
    Note that for Microsoft SQL Server, I/O activity is suspended briefly during backup,
    even for Multi-AZ deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal scaling with read replicas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Traditionally, relational databases do not scale well horizontally due to their
    architecture. A relational database can normally only have one master copy (the
    copy that you can write data to), which means that if you experience a failure
    on the master copy, you need to resort to restoring data from backups. AWS offers
    Multi-AZ as a means to overcome this single point of failure by enabling you to
    create a standby copy of the database that has data synchronously replicated to
    it.
  prefs: []
  type: TYPE_NORMAL
- en: However, you cannot use a standby copy to perform write or read queries since
    your standby copy is only accessible in the event of the failure of the master
    copy. If the master copy of your database fails, your standby copy gets promoted
    to become the new master copy of the database, upon which you will be reading
    and writing to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to scaling horizontally, where you can have multiple nodes of
    your database, AWS offers an option to scale read copies of your database using
    a feature called **read replicas**. AWS RDS can use its built-in replication functionality
    for Microsoft SQL, MySQL, Oracle, and PostgreSQL to create additional read replicas
    of the source DB instance. Data is then replicated from the source DB to the replicas
    using *asynchronous* replication. This can help reduce the load on your master
    copy by redirecting read queries to the read replicas instead. Application components
    that only need to read from the database can be routed to send requests to the
    read replicas, allowing your master copy to focus on those applications that need
    to write to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – AWS RDS with read replicas'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – AWS RDS with read replicas
  prefs: []
  type: TYPE_NORMAL
- en: Read replicas can also be configured for cross-Region replication, as depicted
    in the preceding diagram. (The exception is for the Microsoft SQL Server engine,
    which doesn't allow Multi-AZ read replicas or cross-Region read replicas.) This
    means that you can maintain read copies of your database in a different Region
    that can be used by other applications that may only require read access to the
    data. Storing read replicas across Regions can also help you address any compliance
    or regulatory needs that stipulate that you need to maintain copies of your data
    at a considerable distance.
  prefs: []
  type: TYPE_NORMAL
- en: You can also set the read replica as Multi-AZ, which will enable you to use
    the read replicas as a DR target. This means that if you ever need to promote
    the read replica to a standalone database, it will already be configured for Multi-AZ.
    This feature is available for MySQL, MariaDB, PostgreSQL, and Oracle engines.
    Finally you can add up to five read replicas to each DB instance.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, in the event of a major disaster, a read replica can also be promoted
    to become the master copy, after which it becomes independent of the original
    master copy of the database.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we examined Amazon RDS and the key offerings by its managed
    RDS. We reviewed the various database engines on offer, concepts related to high
    availability and scalability, as well as backup and recovery.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will briefly look at one AWS RDS offering, specifically
    Amazon Aurora. While Amazon Aurora is an RDS database solution from AWS, it offers
    several enhanced capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction to Amazon Aurora
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon Aurora is AWS's proprietary MySQL- and PostgreSQL-compatible database
    solution and was designed for enterprise-grade production environments. Amazon
    Aurora comes with a vast array of features that enable you to design your database
    solution with high availability, scalability, and cost-effective deployments to
    suit a variety of business needs.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Aurora is architected to offer high resilience, with copies of the database
    placed across a minimum of three Availability Zones, It is up to five times faster
    than standard MySQL databases and three times faster than standard PostgreSQL
    databases.
  prefs: []
  type: TYPE_NORMAL
- en: The service offers *fault tolerance* and *self-healing storage capabilities*
    that can scale up to 128 TB per database instance. Amazon Aurora also offers the
    ability to host up to 15 low latency read replicas. Let's review some of the key
    features of Amazon Aurora.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Aurora DB clusters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Aurora is deployed as **DB clusters** that consist of one or more **DB
    instances** and a *cluster volume*. This cluster volume spans multiple Availability
    Zones, within which copies of the cluster data are stored.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Aurora DB cluster is made of up two types of DB instances, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Primary DB instance**: This instance supports both read and write operations,
    and it performs all of the data modifications to the cluster volume. You have
    *one* Primary DB instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aurora Replica**: You can have up to 15 Aurora Replicas in addition to the
    primary DB instance. Aurora Replicas connect to the same storage volume as the
    primary DB instance but are only used for read operations. You use Aurora Replicas
    as a failover option if the primary DB instance fails. You can also offload read
    queries from the primary DB instance to the replicas.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With regard to the architecture, DB instances (compute capacity) and cluster
    volume (storage) are decoupled, as illustrated in the following diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Amazon Aurora DB cluster architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Amazon Aurora DB cluster architecture
  prefs: []
  type: TYPE_NORMAL
- en: This decoupling of the computer capacity and storage also means that even a
    single DB instance is still a cluster due to the fact storage volumes are spread
    across multiple storage nodes, across multiple Availability Zones.
  prefs: []
  type: TYPE_NORMAL
- en: With regards to provisioning your DB instances, you have a choice of two instance
    classes. These are memory optimized (designed for memory-intensive workloads)
    and burstable performance (which provides a baseline performance level with the
    ability to burst to full CPU usage).
  prefs: []
  type: TYPE_NORMAL
- en: While the standard Amazon Aurora deployment seems somewhat similar to deploying
    an Amazon RDS database, where you choose the compute capacity and underlying storage,
    AWS also offers a serverless alternative, which we will look at briefly next.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Aurora Serverless
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Aurora Serverless (version 1) is an on-demand autoscaling configuration
    for Amazon Aurora. The DB Cluster automatically scales compute capacity up and
    down based on your requirements. The serverless alternative automatically starts
    up, scales compute capacity to match your application's usage, and shuts down
    when it's not in use. Furthermore, the cluster volume is always encrypted.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of use cases, Amazon Aurora Serverless is ideal for applications with
    unpredictable workloads. Another use case is where you have a lightweight application
    that experiences peaks for 30 minutes to several hours a few times a day or perhaps
    at regular intervals throughout the year. Examples include budgeting, accounting,
    and reporting applications.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we were briefly introduced to the Amazon Aurora Service. In
    the next section, we will examine Amazon DynamoDB, which is AWS's non-relational
    (NoSQL) database offering.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about Amazon DynamoDB (NoSQL database solution)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon offers a fully managed non-relational database solution called Amazon
    DynamoDB. Unlike AWS's relational database offerings (excluding Amazon Aurora,
    which also has a serverless offering, as discussed earlier), you do not need to
    worry about provisioning the right DB instance with the right specification for
    your application. DynamoDB is offered as a serverless solution because you do
    not need to define any database instance configuration, such as CPU or memory
    configuration. Amazon manages the underlying infrastructure that hosts the DynamoDB
    service.
  prefs: []
  type: TYPE_NORMAL
- en: DynamoDB is a regional service just like Amazon RDS, but it comes with higher
    levels of scalability and high availability. You do not need to provision a single
    DB instance in one Availability Zone as you do with a single instance of an Amazon
    RDS database. Instead, when you provision a DynamoDB table, Amazon provisions
    the database and automatically spreads the data across several servers to handle
    your throughput and storage requirements. All data is stored on **solid-state
    disks** (**SSDs**) and the underlying storage is replicated across multiple Availability
    Zones.
  prefs: []
  type: TYPE_NORMAL
- en: The architecture of DynamoDB means that it can be used for use cases that are
    similar Amazon RDS's, although they are more ideal for applications that can have
    millions of concurrent users and where the application needs to perform thousands
    of reads and writes per second.
  prefs: []
  type: TYPE_NORMAL
- en: Tables, items, and attributes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s look at the core components of a DynamoDB database:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tables**: Like Amazon RDS databases, your data is stored in tables. So, you
    can have a customers table that will host information about your customers and
    their orders. Each table will also have a unique primary key, which is crucial
    for uniquely identifying every record in the table. Records are known as items
    in DynamoDB Tables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`400 KB` in size and can contain key-value pairs called attributes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`First-Name` or `Last-Name` and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike Amazon RDS, you do not need to predefine the schema of the table. This
    offers greater flexibility as your table evolves. Other than the primary key,
    you can add new attributes and define them to expand the table at will.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the items don't have to have a value for all attributes – so, for
    example, you can have a table that contains customer address details, their orders,
    and their favorite dessert for a restaurant. Some items may have a value set against
    the favorite dessert, while some may not, and this is perfectly fine.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, attributes need to have data types defined. The following are the
    options that are available here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalar**: This only has one value and it can be a number, string, binary,
    Boolean, or null.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set**: This represents multiple scalar values and can be a string set, number
    set, or binary set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Document**: This is a complex structure with options for nested attributes.
    You can use JSON formatted documents and retrieve data you need without having
    to retrieve the entire document. There are two subtypes of the document data type:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**List**: An ordered collection of values'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Map**: An unordered collection of name-value pairs'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we examined the different components of a DynamoDB database.
    In the next section, we will learn how to provision the required capacity for
    our database requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning capacity for DynamoDB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to provisioning your database, all you need to provide is the
    parameters that define the **read capacity units** (**RCUs**) and **write capacity
    units** (**WCUs**). These values enable Amazon to determine the underlying infrastructure
    to provision to host your database and your throughput levels.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your RCU and WCU, DynamoDB will provision one or more partitions
    to store your data in and use the primary key to distribute your items across
    multiple partitions. Spreading data across multiple partitions enables DynamoDB
    to achieve ultra-low latency reads and writes, regardless of the number of items
    you have in the table.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two options that are available for provisioning capacity are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**On-Demand**: DynamoDB will provision capacity based on your read and write
    requests and provision capacity dynamically. This option is ideal when you have
    unpredictable application traffic and unknown workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Provisioned**: You specify the number of reads and writes per second that
    are required by your application. This is ideal if you have predictable application
    access patterns. You can always also enable *auto-scaling* to automatically adjust
    to traffic changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we looked at Amazon DynamoDB and AWS's non-relational database
    solution. We discovered how DynamoDB is suitable for modern web applications that
    require thousands of reads and writes per second, as well as how DynamoDB is built
    for this purpose specifically.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at Amazon's data warehousing solution, known
    as Amazon Redshift.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the use cases for Amazon Redshift and data warehousing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A data warehousing solution is a specialized database solution designed to pull
    data from other relational databases and enable complex querying and analytics
    to be performed across different datasets. For example, you can combine data across
    customer orders, inventory data, and financial information to analyze product
    trends, demands, and return on investments.
  prefs: []
  type: TYPE_NORMAL
- en: Clients of Amazon Redshift include **business intelligence** (**BI**) applications,
    reporting, and analytics toolsets.
  prefs: []
  type: TYPE_NORMAL
- en: Online Analytical Processing (OLAP)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon Redshift is designed for analytics and is optimized for scanning many
    rows of data for one or multiple columns. Instead of organizing data as rows,
    Redshift transparently organizes data by columns; it converts the data into columnar
    storage for each of the columns. Let's look at what this means.
  prefs: []
  type: TYPE_NORMAL
- en: In a traditional database, data for each record is stored as rows. The columns
    represent the attributes of your data, and each row will contain field values
    for the relevant columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at a table we saw earlier and see how the data is stored in blocks
    on disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Data stored in blocks on disk'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 – Data stored in blocks on disk
  prefs: []
  type: TYPE_NORMAL
- en: Note that the data is stored sequentially for each column that makes up the
    entire row in blocks on the disk (*block 1, 2, 3, and so on*). If the record size
    is greater than the block size, then the record is stored across more than one
    block. Similarly, if the record size is smaller than the block size, then the
    record may consume less than the size of one block. Ultimately, this way of storing
    data leads to inefficiencies in the use of storage.
  prefs: []
  type: TYPE_NORMAL
- en: Having said that, in a traditional relational database, most transactions will
    involve frequent read and write queries for a small set of records at a time,
    where the entire record set needs to be retrieved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at how Redshift stores data. Using the same customer data
    table, each data block stores values of a single column for multiple rows, as
    per the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Data stored on Amazon Redshift'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9 – Data stored on Amazon Redshift
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Redshift converts the data as it is added into columnar storage. With
    this architecture, Amazon Redshift can store column field values for as many as
    three times the number of records compared to traditional row-based database storage.
    This means that you only consume a third of the I/O operations when it comes to
    reading column field values for a given set of records, compared to row-wise storage.
    Furthermore, because the data that's stored in blocks will be of the same type,
    you can use a compression method design for the columnar data type to achieve
    even better I/O and reduce the overall storage space. This architecture works
    well for data warehousing solutions because, by its very nature, your queries
    are designed to read only a few columns for a very large number of rows to extract
    data for analysis. In addition, queries require a fraction of the memory that
    would be required for processing row-wise blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, Redshift is designed to host petabytes of data and supports massively
    parallel data processing for high-performance queries.
  prefs: []
  type: TYPE_NORMAL
- en: Redshift architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Redshift architecture is built on a cluster model that is comprised of
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Leader node**: A single node that manages all communications between client
    applications and with *compute nodes*. The leader node carries out all operations
    such as the steps required to carry out various complex queries – the leader node
    will compile code and distribute these to compute nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`128` compute nodes can be part of a Redshift cluster. The compute nodes execute
    the compiled code that was provided by the leader node and sends back intermediate
    results for the final aggregation. Each compute node will have its own dedicated
    CPU, memory, and disk type, which determines the node''s type:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dense compute nodes**: These can store up to 326 TB of data on magnetic disks.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dense storage nodes**: Can store up to 2 PB of data on **solid-state disks**
    (**SSDs**).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RA3 instances**: This next generation of Nitro-powered compute instances
    come with *managed storage* (unlike the other previous node types). You choose
    some nodes based on your performance requirements and only pay for the managed
    storage that you consume. This architecture has the compute and storage components
    decoupled. Furthermore, data storage is split, whereby local SSD storage is used
    for fast access to cached data and Amazon S3 is used to use longer-term durable
    storage that scales automatically. You will need to upgrade your dense compute
    and dense storage nodes if you wish to make use of managed storage.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we introduced you to the Amazon Redshift service, a cloud-hosted
    data warehousing solution designed for **OLAP** operations. In the next section,
    we will look at another feature of Amazon Redshift known as the Redshift Spectrum
    service, which allows you to directly query data held in Amazon S3.
  prefs: []
  type: TYPE_NORMAL
- en: About Redshift Spectrum
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another solution from Amazon Redshift is the **Redshift Spectrum** service,
    which allows you to perform SQL queries against data stored directly on Amazon
    S3 buckets. This is particularly useful if, for instance, you store frequently
    accessed data in Redshift and some infrequent data in Amazon S3\. Rather than
    import the infrequent data into Redshift, which will only be queried occasionally,
    storing them in Amazon S3 and using Redshift Spectrum will be more cost-effective.
  prefs: []
  type: TYPE_NORMAL
- en: It is also important to note that data in S3 must be structured and you must
    define the structure to enable Redshift to consume it.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the importance of in-memory caching options with Amazon Elasticache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often, you will find yourself accessing a set of data regularly, which is what
    we term as frequently accessed data. Every time you run a query on the database,
    you consume resources to perform the query operation and then retrieve that data.
    Overall, this can add additional load to your database and may even affect performance
    as you constantly write new data to the database.
  prefs: []
  type: TYPE_NORMAL
- en: As part of your overall application architecture, you should consider using
    in-memory caching engines offered by AWS to alleviate the load on your primary
    databases. **Amazon Elasticache** is a web service that offers in-memory caching
    in the cloud. By caching frequently accessed data on Amazon Elasticache, applications
    can be configured to retrieve frequently accessed data from it rather than make
    more expensive database calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS offers two in-memory caching engines, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Elasticache for Redis**: This is built as a cluster, which is a collection
    of one or more cache nodes, all of which run an instance of the Redis cache engine
    software. Redis is designed for **complex data types**, offers Multi-AZ capabilities,
    encryption of data, and compliance with FedRAMP, HIPAA, and PCI-DSS, as well as
    high availability and automatic failover options.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon Elasticache for Memcached**: This is designed for **simple data types**.
    Here, you can run large nodes with multiple cores or threads and scale out. It
    should be used where you require object caching.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we learned about the various AWS Elasticache services, which
    offer in-memory caching capabilities for our applications. In-memory caching can
    be used to alleviate the load on your primary databases by caching frequently
    access data rather than having to run expensive queries repeatedly. In the next
    section, we will look at some additional databases offered by AWS that address
    specific niche market requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Learning about additional database services for specific niche requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In addition to Amazon RDS and DynamoDB, AWS also offers additional databases
    that meet the requirements of specific niche applications. In this section, we
    will take a look at two of those databases: **Amazon Neptune** and **Amazon Quantum
    Ledger Database** (**QLDB**).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Amazon Neptune
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon Neptune is a fully managed graph database service and a type of NoSQL
    database. Graph databases are designed to store data as nodes (person, place,
    location, and so on) and directions. Each node would have some property and nodes
    have relationships between them. So, for example, **Alice** lives in **London**,
    and in **London**, there is a resident called **Alice**. This is a simple example,
    but you can start to imagine how complex your nodes and their relationships can
    become. These kinds of complex relationships between the nodes are just as important
    as the data itself and are ideal for a graph database solution. Traditional relational
    databases would require you to define complex joins between tables and even then,
    this would result in inefficiencies when trying to extract data.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Neptune support well-known graph models such as Property Graph and W3C's
    RDF and their respective query languages such as Apache TinkerPop, Gremlin, and
    SPARQL. Amazon Neptune is a highly available database solution that offers point-in-time
    recovery and continuous backups to Amazon S3 with Availability Zone replication.
    Typical use cases for Amazon Neptune include applications such as fraud detection,
    knowledge graphs, drug discovery, and network security.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon QLDB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some types of data are highly sensitive and maintaining data integrity is of
    paramount importance. Examples of this include bank transaction records, where
    you need to track the history of credits and debits, or insurance claim applications
    that require you to maintain a verifiable history of the claim process. Another
    example is that of having to trace the movement of parts in a supply chain network
    and being able to prove the journey those items took to reach the customer.
  prefs: []
  type: TYPE_NORMAL
- en: Although you can use relational databases to host these ledger types of data,
    you would need to build in an audit trail, which can be very cumbersome and prone
    to errors. Furthermore, because data stored in relational databases is not inherently
    immutable, it can become difficult to verify if data has been altered or deleted.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative solution is to build a **blockchain** network. Blockchain frameworks
    such as Hyperledger Fabric and Ethereum enable you to build decentralized databases
    where the data stored is immutably and is cryptographically verifiable. However,
    blockchain networks are very complex and are designed on a decentralized model
    where you have multiple nodes that need to verify each record before it is committed
    to the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon **QLDB** is a fully managed ledger database that enables you to store
    immutable records with cryptographically verifiable transaction logs in a centralized
    database model. Amazon QLDB can maintain a history of all data changes. The following
    are the key benefits of Amazon QLDB:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Immutable and transparent**: It enables you to track and maintain a sequence
    transaction log (journal) of every single change you make to your data. With QLDB,
    this transaction log is immutable, which means it cannot be altered or deleted.
    QLDB tracks each application data change and maintains a complete and verifiable
    history of all changes over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cryptographically verifiable**: You can use a SHA 256 cryptographic hash
    function to generate secure output files of your data''s change history. This
    is also known as a *digest*, which acts as proof of any changes that have been
    made to your data. This can validate the integrity of all your data changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy to use**: It uses a flexible document data model. You can use a SQL-like
    query language to query your data known as PartiQL. Amazon QLDB transactions are
    ACID-compliant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Serverless**: Amazon QLDB is a fully managed database service with no need
    to provision database instances or worry about capacity restraints. You start
    by creating a ledger and defining your tables. At this point, QLDB will automatically
    scale as required by your application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we examined a couple of additional database solutions designed
    for niche applications. In the next section, we will look at the database migration
    services offered by AWS, enabling you to move your on-premises databases to the
    cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Database Migration Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon offers a **Database Migration Service** (**DMS**) that can be used to
    migrate data from one database to another. Often, this is used as part of an on-premises
    to cloud migration strategy, where you need to migrate database services located
    in your data center to your AWS account in the cloud. AWS DMS offers support for
    both homogeneous migrations, such as from MySQL to MySQL or Oracle to Oracle,
    as well as heterogeneous migrations between engines, such as Oracle to Microsoft
    SQL Server or Amazon Aurora.
  prefs: []
  type: TYPE_NORMAL
- en: An important point to be aware of is that, while migrating, you can continue
    to use your source database, which minimizes downtime for your business operations.
    In addition, you can also use DMS to perform continuous data replication from
    your on-premises environment to the cloud to offer high availability or disaster
    recovery capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.1 – Extending your VPC to host database subnets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B17124_07_Final_SK_ePub.xhtml#_idTextAnchor157), *AWS Compute
    Services*, you expanded your VPC to include both private subnets and public subnets.
    Generally, you would only host services in a public subnet that would need direct
    exposure on the internet. Examples include the bastion host server we deployed
    earlier in [*Chapter 7*](B17124_07_Final_SK_ePub.xhtml#_idTextAnchor157), *AWS
    Compute Services* (which we will discuss in the next chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Most applications are deployed across tiers – so, for example, you can have
    a web tier, an application tier, and a database tier. These different tiers are
    designed to separate different components of your application stack, allowing
    you to create a degree of isolation, as well as benefit from a layered security
    model. In [*Chapter 7*](B17124_07_Final_SK_ePub.xhtml#_idTextAnchor157), *AWS
    Compute Services* , as part of *Exercise 7.1 – Expanding ProductionVPC so that
    it includes two public subnets and two private subnets*, you also configured two
    private subnets across two Availability Zones to host your application servers.
    In this example, the application tier and web tier are the same. However, in many
    real-world scenarios, they would be separate.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you will be extending your VPC to add an additional tier,
    known as the database tier, within which you will be able to launch an Amazon
    RDS database. Like EC2 instances, Amazon RDS needs to be deployed in a VPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following diagram, you can see that your VPC now has three tiers – a
    public (DMZ) tier to host bastion host servers, NAT gateways, and Elastic Load
    Balancers, an application tier comprised of the **Private Subnet One – App** and
    **Private Subnet Two – App** subnets, and finally, a database tier comprised of
    the **Private Subnet Three – Data** and **Private Subnet Four – Data** subnets.
    Note that the subnets are spread across two Availability Zones to enable you to
    offer high availability of services in the event of an Availability Zone failure.
    We will discuss high availability in more detail in the next chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Extending the VPC to include a database tier'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.10 – Extending the VPC to include a database tier
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by extending your VPC so that it includes our database tier:'
  prefs: []
  type: TYPE_NORMAL
- en: Log back into your AWS account as our administrator, **Alice**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the **VPC** dashboard and ensure you are in the **US-East-1** Region.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the left-hand menu, click on **Subnets**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click the **Create subnet** button in the top right-hand corner of the
    screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will be presented with the **Create subnet** wizard page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **VPC ID**, select **ProductionVPC** from the drop-down menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Subnet settings** section, under **Subnet 1 of 1**, provide a name
    for your first database subnet. For this exercise, name your subnet **Private
    Subnet Three – Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Availability Zone**, select the **us-east-1a** Availability Zone.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, for `10.0.5.0/24`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, rather than create this subnet and repeat the wizard to create the second
    database subnet, simply click on the **Add new subnet** button, as per the following
    screenshot:![Figure 8.11 – Creating multiple subnets
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_08_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.11 – Creating multiple subnets
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A new subsection, **Subnet 2 of 2**, will appear, allowing you to create an
    additional subnet in the same wizard. Under **Subnet name**, type in **Private
    Subnet Four – Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For **Availability Zone**, select the **us-east-1b** Availability Zone from
    the drop-down list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For `10.0.6.0/24`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Create subnet** button at the bottom of this page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'AWS will successfully create two new subnets, which you will use to host your
    Amazon RDS database. In the right-hand menu, click on **Subnets** to view all
    the subnets now associated with your **ProductionVPC**, as per the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Subnets in ProductionVPC'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.12 – Subnets in ProductionVPC
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have created an additional two subnets for your **ProductionVPC**,
    you can proceed with the next part of this exercise. Like EC2 instances, Amazon
    RDS databases require you to configure the necessary security groups that will
    permit traffic to the database instances.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our layered security model, we wish to ensure that only our application
    servers will be able to communicate with the databases in the backend. In this
    part of the exercise, you will create a new security group that will be configured
    to allow database-relevant traffic from any application servers you deploy later.
    To do this, you must configure an inbound rule on the new database security group
    to accept traffic on port `3306` for MySQL traffic from the security group of
    the application servers, specifically from the **AppServers-SG** security group.
    Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure you are currently in the **VPC** dashboard. Then, from the left-hand
    menu, click on **Security Groups**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Create security group** button in the top right-hand corner of the
    screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For `Database-SG`. Under description, type in `Allow MYSQL traffic from AppServer-SG`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **VPC**, ensure you select **ProductionVPC** from the drop-down list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, in the **Inbound rules** section, click on the **Add rule** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Type**, select **MySQL/Aurora**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that `sg-`. You should see that a list of all security groups shows up
    in a list. Select the **AppServers-SG** security group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide an optional description if required.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Create security group** button in the bottom right-hand corner
    of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS will now confirm that the security group has been created successfully.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you extended your VPC to host two additional private subnets
    that we will use to host our Amazon RDS database. You also created a new security
    group, `3306` from any EC2 instance that is associated with the **AppServer-SG**
    security group.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, we will configure an Amazon RDS database subnet group
    that will be used to inform Amazon RDS of which subnets it can deploy our databases
    to.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.2 – Creating a database subnet group
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you can launch an RDS database in your VPC, you need to define a DB subnet
    group. A **DB subnet group** is a collection of two or more subnets within the
    VPC where you want to deploy your database instance. When creating your DB subnet
    group, at least two subnets must be selected in the VPC that are associated with
    two separate Availability Zones in a Region. Amazon RDS uses the subnet group's
    IP address CIDR block to assign your RDS database instance(s) with an IP address.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon RDS can then deploy the database instance on one of your chosen subnets
    that is part of the group. In the case of a Multi-AZ deployment, the master copy
    will be deployed in one subnet in a particular Availability Zone, while the standby
    copy will be deployed in another subnet that is hosted within another Availability
    Zone.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the subnets in a DB subnet group are either public or private, but
    they cannot be a mix of both public and private subnets. Ideally, you want to
    configure private subnets as part of your subnet group because you want to deploy
    any backend databases in the private subnets of your VPC. Your databases should
    only be accessible from web/application servers and not directly from the internet.
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up the DB subnet group, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you are logged into your **AWS Management Console** as the IAM user
    **Alice**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the top left-hand menu, click on the **Services** drop-down arrow and select
    **RDS** located under the **Database** category. This will take you to the Amazon
    RDS dashboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that you are in the **us-east-1** Region and from the left-hand menu,
    click on **Subnet groups**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, in the main pane of the screen, click the **Create DB Subnet Group** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the page that appears, you will need to define your DB subnet group details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide a name for your DB subnet group; for example, `ProductionVPC-DBSubnet`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For the description, type in `DB Subnet Group to host RDS Database in Production
    VPC`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Under **VPC**, select **ProductionVPC** from the drop-down menu.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, under **Availability Zone**, choose the Availability Zones that include
    the subnets you want to add. For this exercise, select the checkboxes next to
    **us-east-1a** and **us-east-1b**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, under `10.0.5.0/24` and `10.0.6.0/24` Ipv4 CIDR blocks, as per the following
    screenshot:![Figure 8.13 – Creating database subnet groups
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_08_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.13 – Creating database subnet groups
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, click the **Create** button at the bottom right-hand corner of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'AWS will create your DB subnet group using the details you provided, as per
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14 – Successfully creating a database subnet group'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.14 – Successfully creating a database subnet group
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you learned about RDS DB subnet groups, which allow you to
    define a minimum of two subnets across two Availability Zones, where Amazon RDS
    can deploy your RDS DB instance when you choose to launch your database.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, we will launch our RDS database in **ProductionVPC**.
    We will also use this database to host the backend data of our web application,
    which we will then deploy in the fourth exercise of this next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.3 – Launching your Amazon RDS database in ProductionVPC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this exercise, you will launch an Amazon RDS MySQL database in the DB subnet
    group of **ProductionVPC**. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you are logged into your AWS account as the IAM user **Alice**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the Amazon RDS dashboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the left-hand menu, select **Databases**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the right-hand side of the pane, click the **Create database** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, you will be presented with the `t2.micro` database instance running the
    MySQL engine as part of the Free Tier offering, which comes with the following
    features for up to 12 months:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 750 hours of Amazon RDS in a Single-AZ db.t2.micro instance.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 20 GB of General Purpose storage (SSD).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 20 GB for automated backup storage and any user-initiated DB snapshots.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For **Choose a database creation method**, select the option next to **Standard
    create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, for the database engine option, select **MySQL**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave the **Edition** and **Version** settings as-is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Templates**, select the **Free Tier** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, you need to provide some settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the DB instance identifier, type in `productiondb`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Under **Credential Settings**, leave the **Master** username set to **admin**
    and provide a password of your choice. Make sure that you note this password down;
    otherwise, you will not be able to connect to the database.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Under **Database instance class**, leave the settings as-is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Storage**, leave the settings as-is except for **Storage autoscaling**,
    where you should *disable* the option for **Enable storage autoscaling**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Availability & durability**, you will note that the option to enable
    **Multi-AZ** is grayed out. This is because Multi-AZ is not available in the Free
    Tier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, under `productionvpc-dbsubnet`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under `3306`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Database authentication options**, ensure that **Password authentication**
    is enabled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under `productiondb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave **DB parameters group** and **Options group** as-is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Backups**, ensure that **Enable automatic backups** is enabled and then
    set **Backup retention period** to **1 Day**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Backup window**, select the **No preference** option. For real-world
    applications, you may wish to set the backup window to a period outside of normal
    business hours.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under the **Maintenance** subheading, leave the settings as-is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, click the **Create database** button at the bottom right-hand corner
    of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your RDS database will take a few minutes to launch. As part of the launch
    process, an initial backup will also be performed. Once the database has been
    successfully launched and ready to use, you will see that its **Status** will
    be set to **Available**, as per the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15 – RDS database created successfully notification'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.15 – RDS database created successfully notification
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, you will learn how to deploy a DynamoDB table.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 8.4 – Deploying an Amazon DynamoDB table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this exercise, you will deploy a very simple DynamoDB table. Let''s get
    started:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you are logged into your AWS account as the IAM user known as **Alice**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, navigate to the DynamoDB dashboard. You can search for `DynamoDB` from
    the top search box of **AWS Management Console**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If this is the first time you have visited the **DynamoDB console** page, you
    will be presented with a splash screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Create table** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide a name for your table in the text box next to `Recipes`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `RecipeName` and ensure that the type is set to **String**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Table settings**, uncheck the box next to **Use default settings**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Read/write capacity mode** section, select the **On-demand** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Create** button at the bottom of the page. DynamoDB will create
    a new table for you in a few seconds, as per the following screenshot:![Figure
    8.16 – DynamoDB table – Recipes
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_08_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.16 – DynamoDB table – Recipes
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Items** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can start adding items in the **Items** tab. Click the **Create item** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will see a dialog box in which you can add a new item (record) to your database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the text box next to `Vegan Sausage Rolls`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Save** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that the new item has been added and that the value of the primary key
    for this item is the name of the recipe, `Vegan Sausage Rolls`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Create item** button again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the text box next to `Vegan Peri Peri Burger`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the *plus* sign and select the `Ingredients`. You will also notice
    that an additional entry appears below this **StringSet**, which is where you
    would input the values for the field you just created. Click on the *plus* sign
    next to the *empty array* line and select **Append**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Lettuce` `Tomato` `Cucumber`. Click on a different part of the screen
    to update the values, as per the following screenshot:![Figure 8.17 – DymanoDB
    item entry
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17124_08_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 8.17 – DymanoDB item entry
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Save** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At this point, your table has been updated with a new record. You will see
    the two items in your table. The **Vegan Sausage Roll** item only has one field
    with a value in it, namely the primary key. The **Vegan Peri Peri Burger** item
    has two fields associated with it, which are the primary key and an attribute
    called **Ingredients**. Review the following screenshot for reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.18 – DynamoDB Recipes table'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17124_08_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.18 – DynamoDB Recipes table
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, DynamoDB offers lots of flexibility in not requiring a rigid
    schema definition before inputting data.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will conclude by summarizing this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the various database services offered by Amazon,
    comprising both relational and non-relational databases services. You learned
    how AWS enables you to quickly deploy new RDS databases and offers full management
    of your database as a service, rather than you having to provision EC2 instances
    that you will install database software on.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon RDS comes with six engines – MySQL, PostgreSQL, Microsoft SQL, Oracle,
    MariaDB, and Amazon Aurora. Amazon RDS is a regional service and must be deployed
    in your VPC. You have options to configure for high availability using services
    such as Multi-AZ and backup and restore strategies. You can also scale out read
    copies of your RDS database to offload read queries away from the primary master
    copy of your database.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Aurora comes with a lot more features and addresses some of the limitations
    of traditional RDS engines out of the box, including features such as self-healing
    and high availability.
  prefs: []
  type: TYPE_NORMAL
- en: We then looked at Amazon DynamoDB, which is a non-relational database designed
    for the modern web, mobiles, and IoT applications that can read and write thousands
    of requests per second. Amazon DynamoDB is offered as a completely serverless
    solution – you do not need to provision database instances or storage yourself.
    You simply specify **WCUs** and **RCUs** and AWS will provision the underlying
    infrastructure for you.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we looked at two in-memory caching engines offered by the Amazon
    Elasticache service – Redis and Memcached – and compared which engine to use in
    what scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we examined AWS DMS3, which offers both homogenous migrations such
    as Oracle to Oracle migrations and heterogenous migration such as Oracle to Microsoft
    SQL type migrations. AWS DMS can be used to migrate on-premises databases to the
    cloud very easily.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss concepts related to high availability and
    scalability. In addition, we will carry out various lab exercises that will enable
    you to learn how to combine the various core services we have learned about so
    far. You will do this by deploying a multi-tier application architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A company plans to migrate its on-premises MySQL database to Amazon RDS. Which
    AWS service should they use for this task?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Snowball
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Database Migration Service (AWS DMS)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS VM Import/Export
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Server Migration Service
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is the primary benefit of using an Amazon RDS database
    instead of installing a MySQL-compatible database on your EC2 instance?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Managing the database, including patching and backups, is taken care of by Amazon.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Managing the database, including patching and backups, is taken care of by the
    customer.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You have full access to the operating system layer that the RDS database runs
    on.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You can choose which drive and partition to install the RDS database on.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS RDS supports six database engines. From the following list, choose *three*
    engines supported by Amazon RDS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Microsoft SQL
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Oracle
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: MySQL
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: FoxPro
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Db2
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You are building an application for a wealth asset management company that will
    be used to store portfolio data and transactions of stocks, mutual funds, and
    forex purchased. To that end, you need a backend database solution that will ensure
    a ledger-like functionality because they want to maintain an accurate history
    of their applications' data, for example, tracking the history of credits and
    debits for its customers. Which AWS database solution would you recommend for
    this business requirement?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon RDS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon DynamoDB
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon QLDB
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Redshift
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS database solution enables you to build a complete data warehousing
    solution, capable of handling complex analytic queries against petabytes of structured
    data using standard SQL and industry-recognized business intelligence tools?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS DynamoDB
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Redshift
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Neptune
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Pluto
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You are looking to host a production-grade enterprise relational database solution
    that offers high-end features such as self-healing storage systems that are capable
    of scaling up to 128 TB per database instance. Which of the following AWS database
    solutions fulfills the requirement?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon DynamoDB
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Aurora
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Redshift
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Neptune
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS feature of Amazon Redshift enables you to run SQL queries against
    data stored directly on Amazon S3 buckets?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Redshift DaX
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Athena
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Redshift Spectrum
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Redshift Cache
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service enables you to migrate an on-premises MySQL database to an
    Amazon RDS database running the Oracle Engine?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Cross-Region Replication
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS SMS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS DMS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS EFS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You are running a single RDS DB instance. Which configuration would you recommend
    so that you can avoid I/O suspension issues when performing backups?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure RDS read replicas.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure RDS Multi-AZ.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure RDS Cross Region Backup.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure DynamoDB DaX.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
