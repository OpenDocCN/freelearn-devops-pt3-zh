- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running It Without Breaking It
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll explore the operational challenges that come with managing
    cloud environments and how to keep systems running smoothly, no matter what. We’ll
    cover everything from understanding cloud provider SLAs to building resilience
    through multi-region deployments, failover architectures, and automated scaling.
    We’ll dive into the importance of proactive planning, redundancy, and automation
    to minimize downtime and ensure business continuity. Whether it’s preparing for
    cloud provider outages, updating runbooks and documentation, or adapting to the
    cultural shifts required for successful cloud operations, this chapter will arm
    us with the strategies and tools needed to keep our cloud infrastructure strong
    and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll address this within the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Assuming the Cloud is Just ‘Business as Usual’
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inadequate Disaster Recovery & Backup Plans
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Out-of-Date Runbooks and Documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ignoring the Cultural Shift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing Around CSP SLAs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assuming the Cloud is Just ‘Business as Usual’
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When businesses shift to the cloud, it’s all too common to overlook the complexity
    and steep learning curve that comes with it. Cloud operations need a whole different
    skill set compared to traditional IT, and without the right planning, teams can
    quickly find themselves in over their heads.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will gain a deep understanding of the complexities that
    come with cloud adoption and learn how to prepare our team for the challenges
    ahead. We’ll dive into the nitty-gritty of cloud infrastructure, automation, scaling,
    and cost management, so we can plan and avoid common pitfalls.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Cloud Complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When making the decision to move to the Cloud, we’ve generally got a very good
    reason to do so. We want to;
  prefs: []
  type: TYPE_NORMAL
- en: Avoid replacing expensive legacy hardware on premise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modernize our product to use more up-to-date technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take advantage of the flexibility in varying technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Infinitely scale our storage solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have an offsite backup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This list is neither exhaustive nor limited, but for whatever reason we decide
    to move to the Cloud, we can expect there to be a learning curve.
  prefs: []
  type: TYPE_NORMAL
- en: When businesses transition to the cloud, they often assume it’s just another
    IT upgrade. But the truth is, it’s a whole new ballgame. Let’s break down some
    of the things that catch teams off guard.
  prefs: []
  type: TYPE_NORMAL
- en: '**Infrastructure as Code (IaC)**: In traditional IT, setting up infrastructure
    might have involved physically installing servers or clicking through a UI to
    provision resources. In the cloud, we’re potentially dealing with Infrastructure
    as Code (IaC). This means we’re writing scripts—using tools like AWS CloudFormation,
    Terraform, or Azure ARM templates—to define our entire environment. If our team
    isn’t used to thinking about infrastructure as something we version control and
    manage like software, we’re already behind. The flexibility IaC provides is powerful,
    but it also requires developers and ops teams to be on the same page, understanding
    every line of code that affects the environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automation and CI/CD Pipelines**: Another area that’s often underestimated
    is the role of automation and continuous integration/continuous deployment (CI/CD)
    pipelines. In the cloud, manual deployments are not scalable. We need pipelines
    that automatically build, test, and deploy our applications. Teams that aren’t
    experienced in setting up automated workflows will quickly find themselves drowning
    in manual processes, facing delays, and risking inconsistencies between environments.
    What seems like a quick deployment can end up being a troubleshooting marathon
    when it’s done manually.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-Region Redundancy and Scalability**: Cloud environments give us the
    ability to run our applications in multiple regions, ensuring uptime even if one
    location goes down. But setting this up isn’t as simple as flicking a switch.
    It requires careful planning and a deep understanding of how our application and
    data need to be replicated across regions. If our team doesn’t have the experience
    or hasn’t thought through the design properly, we could be left vulnerable during
    an outage, with data that’s inconsistent or difficult to recover.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost Management**: Cloud services are pay-as-you-go, which can be a double-edged
    sword. While we’re not paying for hardware upfront, poor resource management can
    quickly lead to unexpected costs spiraling out of control. Teams that aren’t used
    to thinking about cost optimization—like scaling down non-essential services when
    they’re not needed—can find themselves hit with massive bills at the end of the
    month. It’s not just about building a solution; it’s about building one that’s
    cost-efficient from day one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In short, cloud operations are an entirely different beast compared to traditional
    IT. If our team isn’t equipped to deal with this complexity, we’re setting ourselves
    up for a rough ride. Proper planning, training and a deep understanding of the
    tools at our disposal aren’t just “*nice to haves*”—they’re critical if we want
    to succeed in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Training and Upskilling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When a business is planning to move to the cloud, it’s not as simple as flipping
    a switch. We need a solid plan that covers everything, from the technical side
    to getting the whole organization on board. Here’s how we do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Start with a Cloud Readiness Check**: Before we dive in, we’ve got to figure
    out where we stand. A cloud readiness check is all about understanding what we
    have in our current setup—what can move easily, what might need some work, and
    what the potential costs and risks are. And it’s not just IT that should be involved.
    Business leaders need to understand how this move could impact their departments—operations,
    budgets, everything.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: When we did our cloud readiness check, we found some of our legacy
    systems needed major reworking to even consider running in the cloud. But on the
    flip side, our databases? They were practically begging for a lift-and-shift,
    which saved us both time and money from the get-go.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Education and Training for Everyone**: The skills gap is real when it comes
    to the cloud. Sure, our IT staff will need to get cloud certifications but don’t
    stop there. Finance, marketing, risk teams, and even legal teams need to understand
    what the cloud means for them—cost structures, compliance, security, and so on.
    Invest in workshops, training programs, and external consultants to make sure
    everyone’s on the same page.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: We didn’t just train IT. Finance learned how cloud billing really
    works and set up alerts to avoid those nasty surprises at the end of the month.
    Meanwhile, marketing got a crash course on cloud compliance, making sure they
    didn’t trip over data privacy in our shiny new environment.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Set Clear, Measurable Goals**: We need to know why we’re making this move.
    Are we doing it to cut capital expenditure costs? Improve scalability? Improve
    on our disaster recovery plan? Whatever our goals are, make them measurable and
    align them with our business priorities. This way, we will know if we’re on track,
    and our teams will have something concrete to aim for.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: One of our big goals? Cutting infrastructure costs by 30% within
    the year. We made sure it was tied to the business and tracked it every quarter,
    holding ourselves accountable to make sure the cloud was pulling its weight.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Build a Solid Migration Strategy**: Once we’ve got our goals set, we need
    a strategy that outlines how we’re going to get there. What’s the approach—lift
    and shift, re-platform, or something else? Who’s responsible for what? Do we go
    with a single cloud, multi-cloud, or hybrid model? These are the decisions that
    will shape our migration. Make sure our strategy accounts for things like vendor
    lock-in, interoperability, and security.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: Our migration strategy wasn’t a one-size-fits-all. We started with
    a phased approach, lifting and shifting non-critical apps while re-platforming
    the core services to tap into cloud-native features like auto-scaling. We also
    kept one eye on the future by planning a multi-cloud approach to avoid vendor
    lock-in.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Communication is Key**: This isn’t just an IT project—it’s a shift for the
    entire business. We need to keep everyone in the loop. Explain why we’re moving
    to the cloud and how it’s going to benefit the business. Regular updates can help
    avoid resistance and ensure everyone knows what’s coming and how it affects them.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: Every two weeks, we ran company-wide updates, explaining where we
    were in the migration and what was coming next. This open dialogue helped reduce
    resistance and kept everyone on the same page, no surprises, just progress.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Set Up Governance and Compliance Early**: The cloud gives us flexibility,
    but without the right governance, things can spiral. Set up policies from the
    start to define who can access resources, how data is handled, and how everything
    is monitored. Get our legal, compliance, and security teams involved early to
    make sure everything is in line with regulations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: We got the legal team involved early, working side by side with
    IT to set up access policies and make sure data handling met specific client required
    standards. Regular audits were built into the process so compliance was baked
    in as we scaled.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Test Everything**: Before we flip the switch, make sure we’ve tested everything—performance,
    security, backup and recovery processes. Run pilots or proof of concept projects
    to iron out any kinks before the full migration. This is our chance to catch potential
    issues, so don’t skip it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: Before we pulled the trigger on migrating our customer-facing app,
    we ran it in parallel with our on-prem system for a month. That gave us time to
    iron out a few latency kinks and ensure everything was solid before switching
    users over.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Post-Migration Support**: The work doesn’t end when we’ve moved our data
    or apps. We will need a plan for ongoing support—monitoring, cost optimization,
    and troubleshooting. Make sure we’ve got a team or partner ready to handle the
    day-to-day cloud management and keep things running smoothly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Example*: After the migration, we had a cloud operatations team ready to go,
    handling monitoring and troubleshooting. Automated cost alerts were set up to
    catch any spikes, and a weekly review kept us in check, making sure our environment
    stayed optimized.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In short, moving to the cloud requires more than just technical planning. It’s
    about getting the whole business on board, setting clear goals, and having a solid
    strategy in place. If we cover all our bases, we will make the transition smooth
    and avoid surprises down the line.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative learning is key
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In summary, encouraging collaboration is key to closing the skills gap and keeping
    our team sharp. Set up internal training sessions, invest in cloud certifications,
    and make sure documentation is easy to access and up to date. When everyone shares
    knowledge and works together, we will avoid the bottlenecks and confusion that
    can come from working in silos. Make sure the whole team is moving forward with
    the same understanding—it’ll pay off in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will discuss how your team should be working together
    to form the appropriate disaster recovery plans and ensure your data is backed
    up safely.
  prefs: []
  type: TYPE_NORMAL
- en: Inadequate Disaster Recovery & Backup Plans
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Disaster recovery** (**DR**) often gets pushed to the back burner in cloud
    operations, with many businesses thinking their cloud provider will handle it
    all. But that’s a dangerous assumption. While cloud providers offer some built-in
    redundancy, the responsibility for disaster recovery falls on you. Without a solid
    DR plan that’s regularly tested, we’re opening the door to massive downtime and
    potential data loss. We can’t just hope our cloud setup will bounce back after
    a failure, we need a clear, tested strategy in place.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll walk through the essential components of building a comprehensive disaster
    recovery and backup plan, the critical difference between **Recovery Point Objective**
    (**RPO**) and **Recovery Time Objective** (**RTO**), and strategies for tackling
    data loss, instance failures, and availability zone outages. The goal is to ensure
    our systems can bounce back faster and keep running, even when things go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Building a Comprehensive Backup Plan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our DR strategy isn’t just a nice-to-have; it’s essential to keeping our business
    running when things go sideways. We need to think beyond basic backups and start
    building redundancies across multiple regions. Use cloud native tools like AWS
    Elastic Disaster Recovery, Azure Site Recovery, or GCP Backup & Restore to ensure
    that if one region fails, our services can seamlessly switch to another. Think
    about failover mechanisms, automatic scaling, and how fast we can get critical
    systems back online.
  prefs: []
  type: TYPE_NORMAL
- en: There are many considerations to be made when formulating a comprehensive backup
    plan.
  prefs: []
  type: TYPE_NORMAL
- en: RPO vs RTO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Firstly, let’s start with the definition of both terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Recovery Point Objective (RPO)**: This is the maximum amount of data loss
    that we can sustain in the event of some sort of failure. Ask yourself, “*how
    much data can my business afford* *to lose?*”.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A retail store can probably afford to have a high RPO. That is, in the event
    of a failure, they can support a data loss going back to the previous day’s close
    of business.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A financial institution, on the other hand, cannot afford the loss of data and
    needs the RPO to be as low as possible, into the minutes, or even zero in some
    cases.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Recovery Time Objective (RTO)**: This is the maximum amount of time that
    can elapse whilst we are restoring our environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask ourselves, “How much business do I want to lose in the event of a failure?”.
    And really, we don’t want to lose any but in the event of a failure, time is a
    factor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Looking back at our two examples above, a retail store that may trade Monday
    - Friday, 9:00 am until 5:00 pm may be able to sustain an RTO of 24 - 48 hours
    (about 2 days). After all, system failures only happen on a Friday afternoon right,
    just as we’re about to go for a relaxing weekend? Joking aside, in our retail
    example, a large RTO can be absorbed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Our financial institution, on the other hand, will need a very low RTO, in some
    cases lower than an hour.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There are many ways we can build on our RPO and RTO strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer **Service Level Agreements** (**SLA**) / **Service Level** **Objectives**
    (**SLO**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical objectives and constraints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Industry-level compliance and regulatory requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, it would not be recommended to decide our disaster recovery plan on
    just one of these factors. It’s important to ensure that all three factors are
    considered in a collaborative approach.
  prefs: []
  type: TYPE_NORMAL
- en: The Customer SLA / SLO’s are decided at a high level and placed into contracts
    by executives and sales representatives. However, these cannot be honored if the
    technical objectives are not aligned.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The technical team can set up a disaster recovery plan and configure backup
    plans, however, these cannot be effective without a set of clear goals. There
    may also be technical constraints binding the technical team from delivering the
    correct result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The technical and executive teams also need to be across industry-level requirements
    for fear of commercial penalties or loss of certain accreditations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaboration is key to building a comprehensive, clear, concise disaster recovery
    plan.
  prefs: []
  type: TYPE_NORMAL
- en: Disaster Recovery Strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having a DR plan is only half the battle, testing it is where the real work
    begins. We can’t just set it and forget it. Run regular disaster recovery drills
    and simulate outages to see how our team and infrastructure respond. Test our
    backups, run failover scenarios, and make sure everything works as expected. It’s
    better to find out now that something’s broken rather than when an actual disaster
    hits. If our backups are out of date or corrupted, we will be in for a nasty surprise
    when we need them most.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s important to ensure that we are planned and practiced across some of the
    most common scenarios. Testing disaster recovery strategies are critical for making
    sure our workloads can bounce back when things go wrong. It’s not just about having
    a plan—it’s about reducing downtime and getting everything back online faster
    when issues hit. Consider the following three main scenarios and ask yourself
    the rhetorical question of, “*How am I going to recover from this?*” as you form
    your strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: Accidental data loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If someone drops the wrong table in the database or a customer record is corrupted
    in production, how do we recover the data? Data loss isn’t just constrained to
    databases either. Think about object storage in Amazon S3, Azure BLOB Storage
    or Google Cloud Storage. What about file storage on server-attached volumes such
    as Amazon EBS, Azure Disk Storage, or a Google Persistent Disk?
  prefs: []
  type: TYPE_NORMAL
- en: For databases, we need to consider some level of **Point In Time Restore** (**PITR**).
    This can help protect against accidents, deletes, or writes on our database, allowing
    us to restore to a particular point in time, to a granularity of minutes. PITR
    uses database features such as transaction logs within the relevant database technology
    to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling PITR on our database can bring our RPO down to as minimal as possible,
    in the range of 0 - 15 minutes, depending on the choice of database engine.
  prefs: []
  type: TYPE_NORMAL
- en: For object storage, protecting against accidental deletion or writing of data
    has a simple but powerful setup. Enabling versioning on our object store and enabling
    multi-factor authentication on deletion of objects are just two ways to protect
    our data. If someone accidentally overwrites a copy of our object, we can revert
    to the previous version. This has a very similar effect to PITR with databases,
    lowering our RPO for object store to practically zero.
  prefs: []
  type: TYPE_NORMAL
- en: Block storage is far more difficult to protect than objects or databases. As
    it’s a block system based on snapshots in time, we’re restricted to just what’s
    available in the last snapshot in time. For this reason, it would be recommended
    to offload persistent data into managed shared data services such as Amazon EFS
    or FSX, Azure Files, or Google Cloud File Store. These act in a similar way to
    NAS devices attached to our servers which can then be backed up separately with
    more granular backup policies. Block storage should only be used for ephemeral
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Instance Loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Within your architecture, you probably have a number of compute or database
    instances. This section applies to any of the below instances, but is not limited
    to:'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Web Services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EC2 Instances
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: ECS Containers
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: EKS Nodes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda Functions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RDS Instances
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Virtual Machine
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Service (AKS)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Container Instances (ACI)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Functions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Database
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud Platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute Engine Instances
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes Engine (GKE) Nodes
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Run Containers
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Functions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Cloud SQL
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider in our architecture what happens when any of these items go down.
  prefs: []
  type: TYPE_NORMAL
- en: It’s always a good idea to plan this in detail. Draw out the architecture in
    a diagram and start to consider what happens if we take out a single resource.
    What’s the impact on our architecture? Do we have a single point of failure?
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22364_11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1-Reviewing an architecture for single points of failure
  prefs: []
  type: TYPE_NORMAL
- en: For most compute-level services there are a couple of simple but effective ways
    of protecting against the loss of an instance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Load Balancing**: By placing a Load Balancer in front of our workload, we
    can take advantage of many features that can help protect our workload.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Separating load across multiple instances.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: SSL offloading
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Edge-level network protection (WAF, DDoS protection, etc)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By using a load balancer, even in a single instance situation, we are shielding
    our instance from direct internet traffic, applying protection in layers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Auto Scaling Groups**: If our service is ephemeral by design then placing
    it into an auto scaling group can really help our disaster recovery efforts. An
    auto scaling group (provided by Amazon EC2 Auto Scaling, Azure Virtual Machine
    Scale Sets, Google Compute Engine Autoscaler) can add an extra instance as required
    should our instance become overwhelmed with load. It can also monitor the health
    of our instance whilst it’s launched and then in the event it is considered unhealthy,
    will replace it with a fresh instance providing a level of auto-healing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like the load balancer, using an autoscaling group, even in a single instance
    environment, can provide essential protection.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Combining both services together can provide a strategy that can apply our workload
    across multiple network subnets or availability zones.
  prefs: []
  type: TYPE_NORMAL
- en: 'For database instances, this should be less complicated. Most managed database
    instances can be protected:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AWS RDS**: Uses multi-AZ configurations to automatically replicate our database
    across multiple Availability Zones for high availability and automatic failover.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure SQL Database**: Offers Zone Redundant Configurations to replicate data
    across Availability Zones, ensuring resilience and high availability. For more
    advanced setups, we’ve got geo-replication and failover groups with Azure SQL
    Managed Instance and Azure Database for MySQL/PostgreSQL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Cloud SQL**: Provides high availability configurations by replicating
    our database across multiple zones within a region. If one zone goes down, failover
    kicks in automatically. For distributed workloads, Cloud Spanner and Bigtable
    offer built-in replication across zones and even regions for global resilience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each provider has its own approach to multi-zone and multi-region setups, but
    the goal’s the same: *keeping our databases running even when things* *go sideways*.'
  prefs: []
  type: TYPE_NORMAL
- en: Availability Zone failure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The third and final type of scenario to be considered is the major failure without
    the local data center or provider.
  prefs: []
  type: TYPE_NORMAL
- en: Global Cloud Infrastructure Explained
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Web Services (AWS)**: AWS has Regions, which are geographically separated
    areas, and each region has multiple Availability Zones (AZs). These AZs are isolated
    data centers that give us high availability and redundancy.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Google Cloud (GCP)**: GCP follows a similar setup with Regions that are geographically
    distinct, and inside those regions, we’ve got Zones, which work just like AWS’s
    AZs. Each zone is its own isolated location for failover and redundancy.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Microsoft Azure**: Azure also has Regions and Availability Zones (AZs), just
    like AWS and GCP, to ensure our workloads stay resilient. But Azure also adds
    something called Availability Sets. These help us spread our VMs across different
    hardware clusters within a data center, giving us an extra layer of protection
    against localized failures.'
  prefs: []
  type: TYPE_NORMAL
- en: When we’re building our architecture, we will need to consider how we spread
    the workload across varying locations. Ensuring that we have at least the ability
    to fail over to another Zone / AZ is important and some services account for this
    in their feature sets.
  prefs: []
  type: TYPE_NORMAL
- en: Database services allow for Multi-AZ or Redundant zone configurations. This
    means that if a zone fails our database will fail over within the shortest possible
    time. This is an optional configuration and often has cost implications, but the
    cost is to cover the extra instances that are configured in the background and
    then replicated in real-time. In most cases, this is a transparent configuration,
    once the option is selected, it then just happens and is often easy to take for
    granted and consider disabling to save costs. This is the insurance policy we
    didn’t know we needed and sometimes didn’t realize got utilized, as there are
    many reasons to use Multi-AZ configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic failover of an AZ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less downtime during configuration changes by applying them to the standby instance
    first and then switching over
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to take backups without impacting the performance of the primary
    node by taking them from the standby instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other options to consider for databases could be a read replica instance instead.
    This is an instance that we would purposefully configure and use as a read-only
    data source for things like Business Intelligence reporting or backups, or maybe
    even customer access. These can be promoted to primary nodes in the event of a
    failure, so it makes sense to run our read replica in another AZ/Zone too.
  prefs: []
  type: TYPE_NORMAL
- en: For compute instance types, the methods discussed in instance loss are generally
    the same for AZ/Zone failure. Just make sure we configure our Load Balancers and
    Scaling groups to be spread across 2 or more Zones. This will ensure they are
    highly available and don’t create a single point of failure.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up Disaster Recovery and Backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In short, disaster recovery is something we can’t afford to leave unplanned
    or untested. It’s about more than just data backups—it’s ensuring that when things
    fail, our services can recover quickly and seamlessly. By focusing on a comprehensive
    strategy that covers RPO, RTO, and multi-zone redundancy, we will be far better
    prepared to handle any disaster that comes our way.
  prefs: []
  type: TYPE_NORMAL
- en: Whilst a disaster recovery plan is important, it’s also just as important to
    ensure you have up to date runbooks and documentation available for your team
    at the right time. We go into that in more detail in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Out-of-Date Runbooks and Documentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud environments evolve at breakneck speed. Infrastructure changes, new services
    are added, scaling happens on the fly, and security updates roll out frequently.
    With so much in motion, it’s easy for documentation and runbooks to fall out of
    date. When that happens, we open the door to operational inefficiencies, miscommunication,
    and mistakes during critical moments. Outdated documentation can lead teams down
    the wrong path when troubleshooting, wasting time, and possibly causing even bigger
    problems. Keeping runbooks and documentation up to date is crucial to maintaining
    smooth operations and ensuring everyone is on the same page when issues arise.
  prefs: []
  type: TYPE_NORMAL
- en: Through this section, we will review the main best practices for ensuring we
    maintain maximum operational efficiency by looking after our documentation and
    runbooks. We will review both the concept of and then some practical steps we
    can take to help keep things well documented.
  prefs: []
  type: TYPE_NORMAL
- en: Maintaining Updated Documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Documentation isn’t something we write once and forget about, it’s a living,
    breathing asset that needs regular care. As infrastructure changes happen, whether
    it’s new deployments, scaling, or changes in architecture, our runbooks and documentation
    should reflect those updates immediately. When documentation is out of sync with
    the current environment, teams are more likely to follow outdated procedures,
    which can lead to slow incident response times or, worse, operational failures.
  prefs: []
  type: TYPE_NORMAL
- en: One of the best ways to manage this is by setting up a documentation review
    schedule, tied directly to key operational events. After every major infrastructure
    update, teams should review relevant runbooks and technical documents to ensure
    they align with the current setup. This review process can be built into change
    management procedures, ensuring that updates to our infrastructure automatically
    trigger documentation reviews. It’s about creating a habit of continuous review
    and alignment across teams to avoid confusion down the line.
  prefs: []
  type: TYPE_NORMAL
- en: Another more engaging method of ensuring that documentation is up to scratch
    is to utilize a “Game Day”. This could be considered a tabletop exercise or even
    fictional scenarios that are played out in a safe environment. [*Chapter 8*](B22364_08.xhtml#_idTextAnchor224)
    references Game Day’s in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Implementing ISO 9001 can greatly enhance the process of keeping runbooks, SOPs,
    and documentation up to date in cloud environments. By focusing on document control,
    regular reviews, and continuous improvement through the Plan-Do-Check-Act (PDCA)
    cycle, ISO 9001 ensures consistency and accountability. With its emphasis on risk-based
    thinking and audits, it helps mitigate the risks of outdated documentation, aligning
    well with automation tools like AWS CloudFormation and Azure ARM Templates to
    streamline updates and maintain accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: ISO 9001 is an international standard for quality management systems (QMS).
    It provides a framework for organizations to ensure that their processes consistently
    meet customer and regulatory requirements. Focused on improving efficiency and
    maintaining high-quality standards, ISO 9001 emphasizes principles like customer
    focus, leadership, risk-based thinking, continuous improvement, and document control,
    making it a valuable tool for ensuring reliable, repeatable outcomes across any
    industry.
  prefs: []
  type: TYPE_NORMAL
- en: Automating Documentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Manual documentation updates? That’s a fast track to disaster. In fast-moving
    cloud environments, manual updates just won’t cut it. When someone comes to fix
    an incident, that’s time critical, they need to understand why the architecture
    is in the current state it is, before trying to fix something that may make things
    worse. That’s where automation comes in. Tools like AWS CloudFormation, Azure
    ARM templates, and GCP Deployment Manager automatically keep our documentation
    in sync with infrastructure changes, cutting down on human error and ensuring
    we’re always working with up-to-date information.
  prefs: []
  type: TYPE_NORMAL
- en: Take AWS CloudFormation, for example. When we use CloudFormation templates to
    manage our infrastructure, the templates themselves serve as a form of documentation,
    showing exactly how our resources are configured. Similarly, Azure ARM templates
    and GCP Deployment Manager perform the same function. These tools generate real-time
    infrastructure updates, and by using them, we ensure that our documentation is
    never lagging.
  prefs: []
  type: TYPE_NORMAL
- en: Automating documentation also reduces the human error that comes with manual
    updates. As our cloud infrastructure grows in complexity, keeping track of every
    change manually becomes unmanageable. Automation tools help us streamline this
    process and keep our documentation accurate, up to date, and aligned with our
    current infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Standard Operating Procedures (SOPs)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our **Standard Operating Procedures** (**SOPs**) are critical to keeping our
    cloud environment running efficiently, but they are only as good as their relevance.
    Like runbooks, SOPs should not be written once and forgotten—they need to evolve
    alongside our infrastructure and workflows. This is especially true in cloud environments
    where rapid changes to architecture or services can render old procedures obsolete.
  prefs: []
  type: TYPE_NORMAL
- en: A regular SOP review process is essential. Every time our cloud architecture
    evolves, whether it’s new services being deployed or scaling changes, our SOPs
    should be revisited to ensure they are still relevant. Procedures that were effective
    when we were managing a smaller infrastructure might no longer apply as we scale
    up. Regularly reviewing and updating SOPs ensures that our teams are working with
    the most current information and can execute tasks quickly and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Also, when updating SOPs, make sure to include any lessons learned from incidents
    or outages. If a failure occurs because of a procedural gap or oversight, update
    our SOPs to prevent that from happening again. SOPs aren’t just about handling
    day-to-day operations, they reflect our organization’s continuous improvement
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The AWS Well-Architected Framework was born out of lessons learned from a large-scale
    outage, where early cloud adopters faced significant challenges in designing resilient,
    scalable architectures.
  prefs: []
  type: TYPE_NORMAL
- en: The AWS Well-Architected Framework constitutes a set of documented best practices
    (or SOPs) to get the most out of our cloud architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at this more practically.
  prefs: []
  type: TYPE_NORMAL
- en: Documentation and Runbooks in practical terms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, we’ve talked about the common principles around documentation and SOPs,
    but what practical steps can we take in order to ensure we are following best
    practices around documentation? What technical guidance can we follow?
  prefs: []
  type: TYPE_NORMAL
- en: Implement Infrastructure-as-Code (IaC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tooling**: Use tools like AWS CloudFormation, Azure ARM Templates, and Google
    Cloud Deployment Manager to define and manage our infrastructure as code. These
    tools automatically create templates that serve as live documentation for our
    environment.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version Control**: Store these templates in version control systems such
    as Git to track all infrastructure changes over time, allowing for easy rollback
    if necessary and providing an accurate record of changes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benefits**: Infrastructure-as-Code keeps our documentation aligned with the
    current state of our infrastructure and eliminates the need for manual updates.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate Documentation Updates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tooling**: Integrate tools like Terraform Cloud or CloudFormation Drift Detection
    to automatically detect changes in our infrastructure and update our documentation
    in real-time.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scripts**: Set up automated scripts that pull changes from infrastructure
    and update documentation in platforms like Confluence or SharePoint.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benefits**: Automation ensures our documentation is always current without
    relying on manual processes, reducing the likelihood of outdated information causing
    errors.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Monitoring and Alerting Systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tooling**: Leverage AWS CloudWatch, Azure Monitor, or Google Cloud Operations
    Suite to monitor infrastructure health and changes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automation**: Automatically trigger reviews of documentation when infrastructure
    changes or alerts are detected. This can be tied into our IT service management
    (ITSM) tools like ServiceNow or Jira.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benefits**: Continuous monitoring ensures that teams are aware of any critical
    changes in infrastructure, providing a chance to proactively update documentation
    or SOPs as needed.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Centralized Knowledge Management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tooling**: Implement centralized documentation tools such as Confluence,
    Notion, or Azure DevOps Wiki to store and organize all runbooks, SOPs, and technical
    documentation in one place.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Searchable Database**: Ensure that all documentation is easily searchable
    and accessible to teams.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benefits**: Centralizing documentation ensures all teams are referencing
    the same up-to-date information, which reduces confusion and miscommunication
    during operations.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Embed Documentation into Change Management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Change Management**: Ensure every infrastructure change includes a review
    of the associated documentation, so updates happen as part of the change process.
    This can also be useful to ensure there is no unintentional drift from the original
    design.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ownership**: Assign responsibility for documentation updates to specific
    team members to create accountability.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benefits**: Embedding documentation into change management ensures that no
    change is made without the necessary updates to runbooks and SOPs, preventing
    misalignment between infrastructure and documentation.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping runbooks, documentation, and SOPs up to date is about more than just
    following best practices. It’s about avoiding costly mistakes, reducing downtime,
    and ensuring that our teams can respond effectively in real-time when things go
    wrong. In cloud environments, where things change rapidly, outdated documentation
    is a ticking time bomb that can lead to slow responses, confusion, and even failure
    to resolve critical issues.
  prefs: []
  type: TYPE_NORMAL
- en: By regularly reviewing and automating updates to our documentation, we’re not
    only improving operational efficiency but also making sure that our teams have
    the right information at their fingertips when they need it most. It’s an investment
    in resilience, agility, and long-term cloud success.
  prefs: []
  type: TYPE_NORMAL
- en: Runbooks and documentation should start to form part of your culture as you
    shift to the cloud, ignoring this could be devasting to your cloud adoption efforts.
    We talk more about the cultural shift in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring the Cultural Shift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Operating in the cloud isn’t just about adopting shiny new tech—it’s about getting
    teams to work together in a whole new way. Too many organizations dive headfirst
    into cloud projects, thinking it’s all about the tools, but the real challenge
    lies in changing the way people collaborate. If we’re not encouraging cross-functional
    teamwork, our cloud strategy is going to hit a wall fast. Success in the cloud
    hinges not only on infrastructure but also on embracing a fundamental shift in
    how teams interact, share knowledge, and align their efforts to a common goal.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll get a clear understanding of why collaboration is key
    to making the cloud work. We’ll learn how breaking down silos and getting dev,
    ops, and security teams working together can prevent mistakes and speed things
    up. We’ll also dive into why cross-functional teams and a DevSecOps mindset are
    essential for improving efficiency and security. Plus, we’ll talk about the importance
    of knowledge sharing and keeping everyone in the loop as our cloud setup evolves.
    Lastly, we’ll see how to manage resistance to change and make sure our shift to
    the cloud is smooth and effective.
  prefs: []
  type: TYPE_NORMAL
- en: Encouraging Collaboration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloud environments thrive when teams are talking to each other. In traditional
    IT setups, development, operations, and security are often siloed. Developers
    push code, ops handle infrastructure, and security keeps an eye on vulnerabilities—everyone’s
    in their own bubble. But in the cloud, we can’t afford that kind of separation.
    Dev, Ops, and Security must always be in sync. Open those lines of communication
    and ensure these teams are working together from the start.
  prefs: []
  type: TYPE_NORMAL
- en: Why is this so important? Cloud environments are dynamic, and things change
    fast. Code gets deployed quicker, resources scale up or down, and security threats
    evolve constantly. If our teams aren’t collaborating, one group can make changes
    that might inadvertently cause issues for another. A developer might introduce
    new code that inadvertently weakens security. The operations team might roll out
    changes without knowing how they affect the overall infrastructure. When teams
    are isolated, these changes can slip through the cracks, leading to inefficiencies,
    downtime, or worse—security breaches.
  prefs: []
  type: TYPE_NORMAL
- en: Collaboration isn’t just a “nice to have.” It’s the backbone of effective cloud
    operations. Teams need to break down barriers and work as a unit, aligning around
    shared objectives. One of the most effective ways to foster this kind of collaboration
    is through regular check-ins, cross-team meetings, and collaborative problem-solving
    sessions. By creating these open lines of communication, we’re giving the teams
    the space to discuss issues early, share knowledge, and catch problems before
    they become major headaches.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking Down Silos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Silos within an organization are a major barrier to collaboration. In the traditional
    IT world, it’s common for teams to have rigidly defined roles and responsibilities.
    Development teams focus on writing code, operations teams handle the deployment
    and maintenance of infrastructure, and security teams monitor for threats and
    vulnerabilities. While this division of labor made sense in the era of on-premises
    infrastructure, it doesn’t align with the flexibility and speed of cloud environments.
  prefs: []
  type: TYPE_NORMAL
- en: In the cloud, we need everyone working together throughout the lifecycle of
    a project. The development team can’t just throw code over the wall to operations
    and walk away. Security can’t afford to stay out of the loop until the end of
    the process. Cloud environments require constant coordination. The flexibility
    and scale that the cloud offers are great, but they also increase complexity—and
    with complexity comes risk. Silos only compound these risks because they lead
    to miscommunication, disjointed workflows, and duplication of effort.
  prefs: []
  type: TYPE_NORMAL
- en: So how do we break down these silos? Start by fostering a DevSecOps culture,
    where development, security, and operations work together from day one. The key
    here is shared responsibility. Each team should understand how their work impacts
    the broader system and how they can contribute to a shared goal. We can also implement
    more formal processes like integrated project management systems and regular cross-functional
    team meetings. Breaking down silos takes time, but once teams start collaborating
    more closely, we’ll see fewer bottlenecks, faster problem resolution, and a much
    smoother cloud operation.
  prefs: []
  type: TYPE_NORMAL
- en: Think back - Conway’s Law
  prefs: []
  type: TYPE_NORMAL
- en: As we dive into breaking down silos and pushing for more collaboration across
    teams, it’s worth keeping Conway’s Law in mind (which we covered back in Chapter
    1). This idea reminds us that the way our teams communicate will directly shape
    how our systems turn out. If we’re not working together as one, our cloud architecture
    is going to reflect those gaps. So, getting development, ops, and security on
    the same page isn’t just a nice-to-have, it’s essential if we want to build systems
    that are truly resilient.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Functional Teams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The creation of cross-functional teams is one of the most effective ways to
    promote collaboration in cloud operations. These teams bring together members
    from development, operations, and security, ensuring that all aspects of the project
    are covered right from the start. No more waiting until the last minute for the
    security team to weigh in on vulnerabilities, or for ops to figure out how to
    scale a new deployment. Everyone is involved from day one, which leads to better
    alignment, faster decision-making, and fewer surprises down the road.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-functional teams aren’t just about getting things done faster—they’re
    about doing them better. Each team member brings their unique expertise to the
    table, and by working together, they can address challenges more holistically.
    For instance, developers know the code, but they may not be aware of the infrastructure
    limitations. Ops knows how to scale, but they might not understand the security
    implications of certain configurations. Security understands vulnerabilities but
    may not be aware of the newest development frameworks. By combining these perspectives,
    we create a more resilient, well-rounded cloud operation.
  prefs: []
  type: TYPE_NORMAL
- en: This approach also fosters a DevSecOps mindset, which is key to cloud success.
    DevSecOps is all about continuous integration and continuous delivery (CI/CD),
    where development and operations work hand-in-hand to automate and streamline
    deployments. This mindset eliminates the friction between development and deployment,
    making it easier to roll out updates and reduce downtime. Security needs to be
    baked into this process from the start, so a DevSecOps approach—where security
    is integrated into development and operations—is essential for protecting our
    cloud environment.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge Sharing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloud technology is always evolving, and keeping up can feel like a never-ending
    race. If our teams aren’t sharing knowledge, we’ll quickly fall behind. Every
    new tool, every update to our infrastructure, and every security threat needs
    to be understood by everyone involved. That’s where knowledge sharing comes in.
  prefs: []
  type: TYPE_NORMAL
- en: It’s not enough for one person or team to be an expert. Information needs to
    flow freely between teams so that everyone stays up to speed on what’s happening.
    This can be done through formal channels like training sessions, but it’s often
    more effective to create a culture of informal knowledge sharing. Regular team
    meetings where people can talk about the challenges they’re facing, the new tools
    they’ve found, or the lessons they’ve learned are invaluable.
  prefs: []
  type: TYPE_NORMAL
- en: The cloud is complex, and nobody knows everything. But by encouraging our teams
    to share what they know, we can build a stronger, more cohesive operation. When
    one team learns something new, make sure they pass that knowledge on to others.
    This not only helps the team grow but also ensures that knowledge silos don’t
    form. The more our teams share, the more resilient our cloud operations become.
  prefs: []
  type: TYPE_NORMAL
- en: Promoting a DevSecOps Mindset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The DevSecOps mindset is all about breaking down barriers between development
    and operations. In a traditional IT setup, these two teams often work in isolation,
    which can lead to delays, miscommunication, and inefficiencies. However, in a
    cloud environment, development and operations need to work together continuously.
    This approach fosters collaboration, improves efficiency, and allows for faster,
    more reliable deployments.
  prefs: []
  type: TYPE_NORMAL
- en: In a DevSecOps world, developers don’t just write code and hand it off to ops—they’re
    responsible for how that code performs in production too. And ops aren’t just
    there to maintain infrastructure—they’re involved in the development process to
    ensure that everything runs smoothly once it’s deployed. This shared responsibility
    helps catch issues earlier and ensures that the entire team is aligned on the
    goals of the project.
  prefs: []
  type: TYPE_NORMAL
- en: Automation plays a huge role here. By automating repetitive tasks—like testing,
    deployment, and monitoring—we free up our teams to focus on higher-level problems.
    Automation also reduces the risk of human error, which is critical in fast-moving
    cloud environments. When everything is automated, we can move faster and deploy
    updates more frequently without worrying about things falling through the cracks.
  prefs: []
  type: TYPE_NORMAL
- en: Overcoming Resistance to Change
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even when we know collaboration is essential, it’s not always easy to implement.
    Teams that are used to working in silos might resist the shift toward collaboration.
    They may feel like it’s more work or that their expertise isn’t being respected.
    This resistance is natural, but it needs to be addressed if our cloud strategy
    is going to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome resistance to change, we need more than just words—we need to demonstrate
    the benefits in real time. One of the most effective ways to do this is by rolling
    out a pilot project. A pilot allows us to test the waters on a smaller scale while
    showing everyone how cross-functional teams can drive real results. By choosing
    a key project, we bring development, operations, and security together from day
    one, breaking down silos and showing how collaboration leads to quicker deployments
    and fewer headaches down the road.
  prefs: []
  type: TYPE_NORMAL
- en: As we see faster problem resolution and smoother operations, it’s easier to
    get buy-in from the rest of the organization. The beauty of a pilot project is
    that it’s low-risk but high-impact—giving us the evidence we need to prove that
    working together isn’t just more efficient, it’s essential for building resilient
    systems. Once the pilot proves successful, we can expand this approach across
    more teams, making collaboration the new standard.
  prefs: []
  type: TYPE_NORMAL
- en: Leadership also plays a key role here. Leaders need to set the tone for collaboration,
    showing that it’s not just a passing trend but an essential part of how the organization
    operates. They need to encourage open communication, provide the necessary tools
    and support, and be patient as teams adjust to the new way of working. The cultural
    shift doesn’t happen overnight, but with the right approach, it can transform
    the way our teams operate.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring the cultural shift when moving to the cloud is one of the biggest mistakes
    an organization can make. It’s not enough to just have the right tools in place,
    we need our teams to work together seamlessly if we want to succeed in the cloud.
    Collaboration, cross-functional teams, continuous learning, and a DevSevOps mindset
    are all crucial to building a resilient cloud operation. Break down silos, foster
    communication, and make sure everyone is aligned on the same goals. Only then
    will we unlock the true potential of the cloud and ensure long-term success.
  prefs: []
  type: TYPE_NORMAL
- en: As we bring this chapter to a close, we finally look around some of the pitfalls
    and misunderstandings around cloud service providers service level agreements
    and why they should not be your first crutch to lean on.
  prefs: []
  type: TYPE_NORMAL
- en: Developing Around CSP SLAs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cloud Service Provider** (**CSP**) SLAs might promise high availability,
    but relying solely on these guarantees can leave us vulnerable. Developing resilient
    architectures beyond what the SLAs offer is critical for maintaining uptime and
    ensuring business continuity.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll dive into why relying solely on cloud provider SLAs isn’t
    enough for real resilience. We’ll break down how to build redundancy with multi-region
    deployments, failover systems, and load balancing to keep everything running smoothly,
    even when the provider hits a bump. We’ll learn how to protect our systems with
    multi-cloud strategies, third-party redundancy, and offsite backups, ensuring
    our data is safe and our operations stay live. Finally, we’ll explore how automating
    failover, load balancing, and autoscaling gives us an edge, minimizing downtime
    and keeping our infrastructure responsive without relying on manual fixes.
  prefs: []
  type: TYPE_NORMAL
- en: What is a CSP SLA?
  prefs: []
  type: TYPE_NORMAL
- en: A **Cloud Service Provider** (**CSP**) SLA is essentially the contract between
    us and our cloud provider, laying out what kind of performance, availability,
    and uptime we can expect from their services. It’s the provider’s way of saying,
    “Here’s what we guarantee,” but with plenty of fine print. These agreements typically
    cover metrics like uptime guarantees, say 99.9% availability, and define the limits
    of the provider’s responsibility. It’s important to understand exactly what’s
    in an SLA because anything outside those boundaries becomes our responsibility,
    not theirs. So, if things go south, we need to know where the line is between
    their liability and what we’re expected to handle.
  prefs: []
  type: TYPE_NORMAL
- en: Building Redundancy Beyond SLAs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just relying on our cloud provider’s SLA isn’t enough if we want true resilience.
    Sure, they promise high availability, but even a 99.9% uptime guarantee still
    leaves room for downtime, over eight hours a year, in fact. For mission-critical
    systems, we can’t afford to leave it at that. We need to build our own layers
    of redundancy on top of what the CSP guarantees. That means having backup plans
    for when things inevitably go wrong because the question isn’t if, but when. Redundancy
    ensures that our systems stay up and running, even when our provider’s services
    aren’t living up to their promises.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some key steps on how we can build true redundancy and ensure our
    systems stay up, even when our provider’s SLAs fall short:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deploy Across Multiple Availability Zones**: Start by spreading our resources
    across multiple availability zones within a single region. This gives us protection
    against zone-level failures, like hardware issues or localized outages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Go Multi-Region**: Take it a step further by deploying across multiple regions.
    If one region goes down, our services can automatically failover to another, keeping
    our global operations running smoothly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Set Up Failover Architectures**: Implement failover systems like hot or cold
    standbys. These systems kick in automatically when a failure occurs, so we don’t
    lose valuable time trying to fix things manually.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use Load Balancers**: Distribute traffic across multiple instances using
    load balancers to avoid overloading any one server. If an instance goes down,
    the load balancer will shift traffic to healthy instances, maintaining service
    availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implement Auto-Scaling**: Use auto-scaling to ensure we always have enough
    resources. When demand spikes or systems fail, auto-scaling kicks in, adding more
    instances or resources as needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Leverage Backups for Critical Data**: Regularly back up data, and store copies
    in different regions. If the primary storage fails or becomes corrupted, we can
    quickly restore it from another location without losing vital information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor and Alert Proactively**: Use tools like CloudWatch or Azure Monitor
    to keep an eye on systems. Set up alerts so we get notified immediately when something
    goes wrong, allowing for faster response times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test Failover and Redundancy Plans**: Regularly test failover and redundancy
    setups. Don’t wait for an actual outage to see if systems work, run drills to
    make sure everything functions as expected when failure happens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it comes to building reliable cloud systems, we can’t just rely on the
    provider’s SLA and hope for the best. True resilience means layering in our own
    redundancy, deploying across multiple availability zones, setting up failover
    systems, and ensuring our infrastructure can handle failures without skipping
    a beat. By taking these practical steps, load balancing, auto-scaling, multi-region
    deployments, etc, we are not just reacting to problems, we are proactively building
    an architecture that can withstand them. The key is to anticipate failure and
    be ready before it happens. That’s how we keep our cloud environment running smoothly,
    no matter what.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing for Provider Downtime
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even the biggest cloud providers face outages from time to time, and when that
    happens, we don’t want to be caught flat-footed. Preparing for downtime isn’t
    about waiting for something to go wrong, it’s about building an architecture that
    can handle failure and keep running no matter what. This is where multi-cloud
    architecture, third-party redundancy, and offsite backups come into play. These
    strategies help ensure that, when our provider experiences downtime, our operations
    don’t.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Cloud Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Relying solely on one cloud provider is convenient but can sometimes be seen
    as risky when it comes to requiring a tight set of high availability conditions.
    With multi-cloud architecture, we end up spreading our resources across multiple
    cloud providers, think AWS, Azure, and GCP. If one provider goes down, the others
    can pick up the slack, keeping our services live. The key here is not just duplicating
    everything across different clouds but designing the applications to be cloud-agnostic,
    so they can run smoothly on whichever platform is available. It’s not a one-size-fits-all
    approach, but for mission-critical services, it’s a safeguard we can’t afford
    to skip.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Cloud Technologies
  prefs: []
  type: TYPE_NORMAL
- en: 'When thinking about going multi-cloud, we will need to consider building on
    frameworks and technologies that are not vendor locked, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compute: Terraform/OpenToFu, Docker, Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: 'Monitoring: Grafana, Prometheus, ELK Stack'
  prefs: []
  type: TYPE_NORMAL
- en: 'Devops: Github actions, Gitlab, Jenkins'
  prefs: []
  type: TYPE_NORMAL
- en: 'Identity: Auth0, Okta'
  prefs: []
  type: TYPE_NORMAL
- en: Most database technologies are transferable between Cloud providers, especially
    those using more open standards like MySQL and postgresql that are not license
    bound.
  prefs: []
  type: TYPE_NORMAL
- en: Third-Party Redundancy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way to protect against provider downtime is by integrating third-party
    redundancy. This means using external services or vendors to back up critical
    functions. For example, if our primary cloud provider manages the database, consider
    using a third-party service to handle backups or key pieces of infrastructure.
    This way, even if the provider goes down, the data remains secure and accessible.
    The goal is to reduce reliance on any single vendor so that all critical operations
    are always covered from multiple angles.
  prefs: []
  type: TYPE_NORMAL
- en: Offsite Backup in Other Cloud / Hybrid Solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For ultimate peace of mind, look beyond just one cloud provider and assess the
    viability of offsite backups in another cloud or a hybrid solution. This is the
    last line of defense, storing data or essential resources in a different environment
    altogether. By maintaining backups on a separate cloud provider or even on-premises,
    we ensure that if our main provider suffers a major outage or loss, our data and
    systems are still recoverable from a separate location. Hybrid solutions can also
    come into play here, giving us a mix of on-prem and cloud resources to work with.
  prefs: []
  type: TYPE_NORMAL
- en: The key takeaway? Never rely on just one provider to keep everything running.
    By implementing a multi-cloud strategy, integrating third-party redundancy, and
    maintaining offsite backups, we are preparing for the inevitable hiccups in cloud
    availability. That way, when provider downtime hits, our systems won’t even flinch.
  prefs: []
  type: TYPE_NORMAL
- en: Trade Offs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Like any solution or strategy, there are some pros and cons of running a highly
    available multi-cloud architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Pros** | **Cons** |'
  prefs: []
  type: TYPE_TB
- en: '| Increased Resilience and AvailabilityBy leveraging multiple cloud providers,
    we reduce the risk of downtime since a failure in one provider can be mitigated
    by resources from another. | Increased ComplexityManaging workloads across multiple
    providers adds layers of complexity, especially in terms of architecture, monitoring,
    and security. |'
  prefs: []
  type: TYPE_TB
- en: '| Avoid Vendor Lock-InUsing multiple cloud platforms prevents us from becoming
    too dependent on a single provider, giving us more flexibility to switch services
    or negotiate pricing. | Higher Learning CurveTeams need to be proficient in multiple
    cloud platforms, which can mean additional training and expertise are required.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Optimized PerformanceWe can choose the best provider for specific tasks,
    optimizing for speed, latency, or other performance metrics based on the strengths
    of each platform. | Challenging IntegrationIntegrating services and ensuring seamless
    communication between different platforms can be difficult, especially when using
    cloud native tools that aren’t universally compatible. |'
  prefs: []
  type: TYPE_TB
- en: '| Cost ManagementDifferent providers may offer more competitive pricing for
    specific services, allowing us to optimize costs by spreading workloads based
    on pricing models. | Higher Operational CostsWhile multi-cloud may reduce costs
    in certain areas, the added complexity can increase operational overhead, requiring
    more tools, staff, and management. |'
  prefs: []
  type: TYPE_TB
- en: '| Compliance and Geographic FlexibilityMulti-cloud allows us to meet regional
    compliance requirements by distributing data and services across various geographic
    locations and providers. | Latency and Performance VariabilityRunning applications
    across multiple clouds may introduce latency or performance issues when services
    from different providers need to communicate in real-time. |'
  prefs: []
  type: TYPE_TB
- en: Table 11.1 - Pros and Cons of a Highly Available Multi Cloud Architecture
  prefs: []
  type: TYPE_NORMAL
- en: Real-World Example
  prefs: []
  type: TYPE_NORMAL
- en: By way of example, a popular highly regulated Australian financial institution
    attempted to balance their architecture across two cloud providers and ended up
    with a cost factor of 10.4x more than being in a single cloud and, also, created
    latency issues that impacted their RPO and RTO.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to assess the trade-off in these situations.
  prefs: []
  type: TYPE_NORMAL
- en: Automation for Resilience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Resilience in the cloud isn’t just about preparing for the worst, it’s about
    automating key processes, so our systems stay ahead of potential issues. By integrating
    failover, load balancing, and autoscaling into our architecture, we ensure that
    services keep running without manual intervention. Here’s how we can blend automation
    with smart architecture choices to build a truly resilient cloud environment.
  prefs: []
  type: TYPE_NORMAL
- en: Automate Failover
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When a service or instance goes down, the last thing we want is to scramble
    for a fix. Automating failover allows traffic to reroute seamlessly, minimizing
    downtime and keeping things running smoothly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Health checks for proactive monitoring**: Services like AWS Route 53 health
    checks, Azure Traffic Manager, and Google Cloud Load Balancer continuously monitor
    the health of critical endpoints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These tools detect when a service is down and automatically reroutes traffic
    to healthy instances. This instant failover means no disruption in service, something
    manual intervention can’t guarantee.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We should set up health checks for all mission-critical services. For example,
    configuring Route 53 in AWS to reroute traffic to a backup instance if the primary
    fails. Regularly testing these checks ensures they’re working as expected.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Automated DNS failover**: Leveraging DNS failover ensures that traffic automatically
    shifts to backup regions or resources when issues arise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated failover keeps traffic flowing, even if an entire region goes offline.
    Instead of manually switching DNS records during an outage, automation reroutes
    traffic instantly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Setting up DNS failover policies that shift traffic to backup resources when
    needed. In AWS, we can configure weighted routing policies in Route 53 to distribute
    traffic evenly between primary and secondary resources.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Load Balancing and Autoscaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Balancing traffic and scaling resources automatically is crucial for preventing
    overloads and maintaining performance during spikes in demand. Let’s unpack each
    option:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load balancing for seamless traffic distribution**: Load balancers, such
    as Elastic Load Balancing (ELB) in AWS, Azure Load Balancer, and Google Cloud
    Load Balancer, spread traffic across multiple instances to ensure no single instance
    is overwhelmed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By distributing traffic, load balancers keep systems running smoothly, even
    during high-traffic periods. They prevent bottlenecks and ensure better availability
    by routing requests to healthy instances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We should implement load balancers in our cloud architecture. For example, configuring
    AWS ELB to distribute traffic across multiple availability zones. This way, if
    one instance goes down, traffic is automatically routed to another.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Autoscaling for dynamic resource management**: Autoscaling ensures that resources
    adjust to demand, scaling up during traffic spikes and scaling down during quieter
    periods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoscaling optimizes both performance and cost-efficiency. When demand increases,
    it automatically adds resources to handle the load. When things calm down, it
    scales back to avoid unnecessary costs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Setting up autoscaling rules based on traffic or resource thresholds. In AWS,
    configuring Auto Scaling Groups to add instances when CPU usage exceeds a certain
    percentage. Regularly reviewing these thresholds ensures they align with our actual
    needs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Why Automation is Key for Resilience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Automation gives us a proactive edge. By setting up failover and autoscaling
    in advance, we ensure that systems react instantly to issues, minimizing downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Automated systems can detect issues and reroute traffic or scale resources instantly.
    This not only reduces the risk of human error but also ensures that the response
    time is faster than any manual fix.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling helps manage costs by only using the resources needed, while load
    balancing prevents performance issues by evenly distributing traffic.
  prefs: []
  type: TYPE_NORMAL
- en: By automating failover, load balancing, and autoscaling, we build a resilient
    cloud architecture that handles challenges in real time. The combination of proactive
    monitoring, automatic traffic distribution, and dynamic resource management ensures
    our systems stay responsive and efficient, no matter what happens.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a deep dive into the operational challenges of managing
    cloud environments and learned how to keep systems running smoothly under pressure.
    We covered everything from breaking down cloud provider SLAs to building resilience
    with multi-region deployments, failover setups, and automated scaling. We also
    looked at the value of proactive planning, redundancy, and automation to cut downtime
    and keep the business ticking. Along the way, we explored how to handle provider
    outages, keep documentation up to date, and adapt to the cultural shifts that
    cloud operations demand. Now, we’re equipped with the strategies and tools needed
    to keep our cloud infrastructure resilient and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be looking at migration strategies from on premise
    architecture to the cloud and even from one cloud provider to another and the
    risks of not addressing cloud security in a cloud native way.
  prefs: []
  type: TYPE_NORMAL
