<html><head></head><body>
		<div id="_idContainer094">
			<h1 id="_idParaDest-104" class="hapter-number"><a id="_idTextAnchor142"/>7</h1>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor143"/>Automating Tasks</h1>
			<p class="author-quote">The goal of the future is full unemployment. So that we can play.</p>
			<p class="author-quote">– Arthur C Clarke</p>
			<p>This is probably going to be my favorite chapter. Seriously, once you have drunk the sweet nectar of automation, you won’t look back. Well, I guess I’m getting ahead of myself. I will start with the concept of time. The only way you control your destiny, the way you live, and what you do is by controlling your own time, by choosing what you do. And to do that, you need to choose what it is that you do with <span class="No-Break">your time.</span></p>
			<p>All human advancement correlates to doing something in a way that requires fewer and fewer workers and continually <a id="_idTextAnchor144"/>decreased effort so that greater effort can then be applied elsewhere. All of this defines the concept of automation. It is inventing ways to reduce time investment in the boring stuff so that you can move on and do more exciting or <span class="No-Break">engaging stuff.</span></p>
			<p>Human beings invented agriculture so that they wouldn’t have to spend so much time hunting and gathering food. They could grow their own; the food, in many ways, grew itself (automatically some would say) and a little bit of tinkering led to the food that we eat to this day. The creation of farming automated the food creation process, which kickstarted towns and owning property and most of <span class="No-Break">human civilization.</span></p>
			<p>During the Industrial Revolution, the automation of manufacturing processes resulted in cheap, mass-manufactured goods being brought to practically every household. The ability to create identical goods that were of high quality and worked perfectly was revolutionary. It meant that the labor required to create something was greatly reduced meaning that that labor could be focused elsewhere. The invention of the steam engine, electricity, and motor vehicles also reduced labor in a number of different areas while saving time in <span class="No-Break">many others.</span></p>
			<p><em class="itali">Around the World in Eighty Days</em> by <em class="itali">Jules Verne</em> was a novel symbolizing how far human innovation had gone toward shortening trips around the globe. Within a hundred years of the publication of that novel, man had conquered all forms of terrestrial travel, making the book trivial. The next question that was then asked was how the human mind could be made faster and more automated. This is where computers came in. Computers turn the human brain into the most efficient tool in the world. They have automated a lot of our menial mental workload, allowing the human brain to be freed up for more <span class="No-Break">leisurely tasks.</span></p>
			<p>However, this process is a never-ending one. There is always some way to get better and to do something faster and without taking up any more of one’s focus. In the DevOps field, we have made it into one of our core principles because of how much innovation, creativity, and coming up with new ideas are valued in the field of technology. You cannot stay in the same place you were yesterday. You must automate and <span class="No-Break">move on.</span></p>
			<p>And that is what this chapter will be about. It will concern <em class="itali">Automating the Boring Stuff with Python</em> (another great Python book by<em class="itali"> Al Sweigart</em>) and letting you use your mind and your creativity to maximum utilization. You do not want to be stuck in the causal loop of doing the same upload, running the same script manually, or fixing that recurring server issue manually even though it only takes about 5 seconds but logging into it takes 10 minutes. All of these are problems where automation is <span class="No-Break">the answer.</span></p>
			<p>In this chapter, you will learn about <span class="No-Break">the following:</span></p>
			<ul>
				<li>Automation of server maintenance within the server and outside <span class="No-Break">of it</span></li>
				<li>Automation of container creation through managed services <span class="No-Break">and otherwise</span></li>
				<li>Automated launching of a playbook using <span class="No-Break">Google Forms</span></li>
			</ul>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor145"/>Automating server maintenance and patching</h1>
			<p>I once had <a id="_idIndexMarker271"/>a friend whose only job most days was to wait for a website to go down, check why it had gone done, and do one of two things or commands that he had been given to bring it back up again. I had another friend whose job was to manually restart an NGINX server whenever it went down. I once met a man whose job largely involved just downloading CSVs from one place, putting them somewhere else, and clicking a start button. Now, to some of you, that might sound like a swell gig (to me, it doesn’t sound half bad either), but the thing about it is that it is a waste of time for both that individual’s employers and that individual themselves. There is no growth or improvement for either, and in my experience of life, that is a waste of <span class="No-Break">human life.</span></p>
			<p>In the coming samples, we are going to see how we can maintain multiple instance fleets based <a id="_idIndexMarker272"/>on a series of common commands and then we are going to find a way to patch an OS after we have discovered the type of OS it is running. We are going to do all of this with the help <span class="No-Break">of Python.</span></p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor146"/>Sample 1: Running fleet maintenance on multiple instance fleets at once</h2>
			<p>Maintaining a server involves a lot of work – a lot of repetitive work. This is why server maintenance <a id="_idIndexMarker273"/>was initially automated. It minimizes human err<a id="_idTextAnchor147"/>or and also makes sure that the process occurs the same way every time. A fleet of servers works similarly. It is just about using the automation script for all of them since they are copies of an original server. But what about multiple instance fleets with different needs? Here, Python can be of assistance. All you need to do is associate each fleet with the correct script for maintaining it. This can allow you to manage multiple fleets over multiple clouds if you want to. So, without further ado, let’s see how we can <span class="No-Break">do that:</span></p>
			<ol>
				<li>Let’s first write the code for AWS instances to find the instances that <span class="No-Break">are running:</span><pre class="sour e- ode"><strong class="bold">import boto3</strong>
ec2_client = boto3.client('ec2')
response = ec2.describe_instances(Filters=[{'Name': 'instance-state-name', 'Values': ['running']}])
aws_instances = response['Reservations']</pre><p class="list-inset">This will give us a list of instances from EC2 to use. You can use a number of identifiers to define your fleet. You can even use a pre-defined system <span class="No-Break">manager fleet.</span></p></li>
				<li>Let’s now do the same thing for Google Cloud Compute <span class="No-Break">Engine instances:</span><pre class="sour e- ode">from google.cloud import compute_v1
instance_client = compute_v1.InstancesClient()
request = compute_v1.AggregatedListInstancesRequest()
request.project = "ID of GCP project that you are using"
gcp_instances= instance_client.aggregated_list(request=request, filter="status:RUNNING")</pre><p class="list-inset">In the <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) code, there are a few differences because <a id="_idIndexMarker274"/>you need to specify the GCP project ID and you have to define the request to the API along with the <span class="No-Break">API itself.</span></p></li>
				<li>Now, let’s <a id="_idIndexMarker275"/>find a command to run through these instances. It can be any placeholder command. You can later use the commands you want <span class="No-Break">for it:</span><pre class="sour e- ode">command = "sudo reboot"
#for AWS
ssm.send_command(InstanceIds=aws_instances, DocumentName="&lt;Whatever you want to name it&gt;",
    Comment='Run a command on an EC2 instance',
    Parameters={
        'commands': [command]
    }
)
#for Google Cloud
import os
import subprocess
from google.oauth2 import service_account
from googleapiclient import discovery
# Load the service account credentials
service_account_file = '&lt;file_name_here&gt;.json'
credentials = service_account.Credentials.from_service_account_file(
    service_account_file, scopes=['https://www.googleapis.com/auth/cloud-platform']
)
# Create a Compute Engine API client
compute = discovery.build('compute', 'v1', credentials=credentials)
# Get the public IP address of the VM instance
request = compute.instances().get(project="&lt;your_project&gt;",instance="your_instance_name")
response = request.execute()
public_ip = response['networkInterfaces'][0]['accessConfigs'][0]['natIP']
# SSH into the VM instance and run the command
ssh_command = f'gcloud compute ssh {instance_name} --zone {zone} --command "{command}"'
try:
    subprocess.run(ssh_command, shell=True, check=True)
except subprocess.CalledProcessError:
    print("Error executing SSH command.")</pre><p class="list-inset">The preceding code for GCP and AWS differs a bit because of the way that the APIs have been developed for it. However, they both will produce the result of executing an SSH command on <span class="No-Break">their servers.</span></p><p class="list-inset">So, if we iterate through the lists that we previously produced through the function to update them with a command, we can make a mass change or update to our entire <span class="No-Break">instance fleet.</span></p></li>
			</ol>
			<p>This <a id="_idIndexMarker276"/>method is good for a generic fleet where we presume that all the OS are the same or that they run the same commands. But what if we were in an environment where the OS could be different? How would we then go about using commands? In the next section, we will explore <span class="No-Break">this possibility.</span></p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor148"/>Sample 2: Centralizing OS patching for critical updates</h2>
			<p>OS are like any brand, really. Well, at least among most of the tech community, it’s like Coke and Pepsi – except if Coke or Pepsi was your belligerent pet who <a id="_idIndexMarker277"/>constantly wanted your attention and needed maintenance. What I’m trying to say is the flavor you want is your preference. But, if you’re going to share a fridge, there will probably be flavors that you are not familiar with. So, the fridge needs to be accommodating to all flavors. This is a rather long-winded analogy, but you’ll get what I’m saying as we keep going. This fridge sorting is even more difficult (and important) when dealing with servers, which can have a similar diversity. To patch OS correctly, we must first understand which OS we are operating on. Then, we need to apply the correct command to ensure that the patching is done correctly for that OS. This again is where Python comes in. It has libraries that can do both and when combined can be a <span class="No-Break">powerful asset.</span></p>
			<p>Let’s start off <a id="_idIndexMarker278"/>with the process of patching a single OS. We will use a <strong class="bold">Debian OS</strong> with the <strong class="sour e-inline">apt</strong> package manager for <span class="No-Break">this case:</span></p>
			<pre class="sour e- ode">import subprocessupdate_command = "sudo apt update &amp;&amp; sudo apt upgrade -y"subprocess.run(update_command, shell=True)</pre>
			<p>As you <a id="_idIndexMarker279"/>can see in the code, it’s simply a matter of running an <strong class="sour e-inline">update</strong> command using Python’s <strong class="sour e-inline">subprocess</strong> module, which once again reinforces the incredible connection that Python has with the OS that it is <span class="No-Break">working on.</span></p>
			<p>But this is just for a Debian Linux instance. What would happen if that instance was, say, Red Hat or CentOS? What if the script had to function for both? Then we just need to add an additional library: <strong class="sour e-inline">platform</strong>. This library will give us the knowledge we need to distinguish between the platforms and the ability to write all the patch code in <span class="No-Break">one script:</span></p>
			<pre class="sour e- ode">import subprocessimport platformdef update_os():    system = platform.system().lower()    if system == 'linux' or system == 'linux2':        if 'debian' in platform.linux_distribution()[0].lower() or 'ubuntu' in platform.linux_distribution()[0].lower():            update_command = "sudo apt update &amp;&amp; sudo apt upgrade -y"        else:            update_command = "sudo dnf update -y" 	subprocess.run(update_command, shell=True)    elif system == 'windows':        update_command = 'powershell -Command "Start-Service -Name wuauserv; Get-WindowsUpdate; Install-WindowsUpdate;"'        subprocess.run(update_command, shell=True)if __name__ == "__main__":    update_os()</pre>
			<p>The <a id="_idIndexMarker280"/>preceding code works for Debian distributions, the latest RedHat distributions (older ones use <strong class="sour e-inline">yum</strong> instead), and Windows PowerShell. The script will determine which OS you are currently running on and run an update accordingly. Since the command can be modified, you can change it and make the update whatever you’d like it to be. You<a id="_idTextAnchor149"/> can also add on OS such as Darwin for macOS or more obscure <span class="No-Break">Linux distributions.</span></p>
			<p>You may now be thinking “<em class="itali">Patching an OS is going to break my server.</em>” Fair enough. That can happen a lot, especially for older dependencies. And in the case of a lot of Linux servers, the latest versions of OS can take years to become approved server versions. If you feel that this is a hassle, then maybe you should try out containers. There’s plenty of opportunity there for the automation enthusiast <span class="No-Break">as well.</span></p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor150"/>Automating container creation</h1>
			<p><strong class="bold">Containers</strong> – in the <a id="_idIndexMarker281"/>eyes of many – are magic. You can put <a id="_idIndexMarker282"/>all the stuff you need for a smaller application or a section of a larger application into an environment solely catered to it where it can function on its own. It’s like creating a separate planet where polar bears can live in their native environment forever free from the terrors of global warming. In this way, containers are amazing since they can help maintain nearly extinct technologies in environments that can sustain them. That is truly magic. But casting the spell is rather bothersome, which is why we <span class="No-Break">automate stuff.</span></p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor151"/>Sample 1: Creating containers based on a list of requirements</h2>
			<p>Containers change between initialization and stoppage based on changes in the state of the files <a id="_idIndexMarker283"/>and configurations within the container. Capturing an image from this changed container will give an image that has several layers added on top of the initial layer. This is a way to create custom containers as well. This can be useful when the containers that we find are largely what our requirements are but are not exactly our requirements. We can add a few steps (and a few layers) to make our container just as we would like it. We can then turn this into an image, which can then be replicated for other containers. We can do all of this with Python (big <span class="No-Break">surprise, amirite?):</span></p>
			<ol>
				<li>Let’s once again start off with some simple code to start a container based on <span class="No-Break">an image:</span><pre class="sour e- ode"><strong class="bold">import docker</strong>
<strong class="bold">client = docker.from_env()</strong>
<strong class="bold">container = client.containers.run('ubuntu:latest', detach=True, command='/bin/bash')</strong>
<strong class="bold">container_id = container.id</strong>
<strong class="bold">print("Container ID:" + container_id)</strong></pre><p class="list-inset">This set of commands will run a container containing the latest version of Ubuntu. It will also give us the ID of the container, which will be important in the next step. This will be our <span class="No-Break">starting point.</span></p></li>
				<li>Now, let’s add on <span class="No-Break">to it:</span><pre class="sour e- ode"><strong class="bold">#you can put in any command you want as long as it works</strong>
<strong class="bold">new_command = "ls"</strong>
<strong class="bold">new_image = client.containers.get(container_id).commit()</strong>
<strong class="bold">new_image_tag = "&lt;whatever_you_want&gt;:latest"</strong>
<strong class="bold">new_container = client.containers.run(new_image_tag, detach=True, command=new_command)</strong></pre><p class="list-inset">Now, we have a new container that has the new command added on top of everything else in Ubuntu. This container is different from the original one but built upon <span class="No-Break">the original.</span></p></li>
				<li>Next, we <a id="_idIndexMarker284"/>need to export this image for <span class="No-Break">later use:</span><pre class="sour e- ode"><strong class="bold">image = client.images.get("&lt;whatever_you_want&gt;:latest")</strong>
<strong class="bold">image.save("&lt;insert_file_path_here&gt;")</strong></pre><p class="list-inset">This will save your image in the desired file path. Putting all of this code together, we get <span class="No-Break">the following:</span></p><pre class="sour e- ode"><strong class="bold">import docker</strong>
#Step 1: Intialize and run a container
<strong class="bold">client = docker.from_env()</strong>
<strong class="bold">container = client.containers.run('ubuntu:latest', detach=True, command='/bin/bash')</strong>
<strong class="bold">container_id = container.id</strong>
<strong class="bold">print("Container ID:" + container_id)</strong>
#Step 2: Add a layer
<strong class="bold">#you can put in any command you want as long as it works</strong>
<strong class="bold">new_command = "ls"</strong>
<strong class="bold">new_image = client.containers.get(container_id).commit()</strong>
<strong class="bold">new_image_tag = "&lt;whatever_you_want&gt;:latest"</strong>
<strong class="bold">new_container = client.containers.run(new_image_tag, detach=True, command=new_command)</strong>
#Step 3: Export layered container as an image
<strong class="bold">image = client.images.get("&lt;whatever_you_want&gt;:latest")</strong>
<strong class="bold">image.save("&lt;insert_file_path_here&gt;")</strong></pre><p class="list-inset">The full <a id="_idIndexMarker285"/>code gives us the complete picture and shows us that all of this can be done in just a few short steps. Adding layers simply means adding more commands. You can even start with an empty template that has nothing in it if <span class="No-Break">you want.</span></p></li>
			</ol>
			<p>This is all good if you are creating individual customized images, but another complicated aspect of containers is orchestrating multiple containers together to perform a task. This requires a lot of work and is why Kubernetes was created. Kubernetes clusters – even though they simplify container orchestration a lot – can be quite a handful. This is another area of container automation, then, that Python can be <span class="No-Break">useful for.</span></p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor152"/>Sample 2: Spinning up Kubernetes clusters</h2>
			<p>I will start <a id="_idIndexMarker286"/>off with a personal note: when I first got into Kubernetes, it was probably the hardest thing in the world for me. I came from a <a id="_idIndexMarker287"/>development background and something like container orchestration was completely alien to me at the time. Kubernetes was born out of a very complicated need because of the rise in popularity of microservices. It was created to make life simpler for larger projects that were a mishmash of smaller projects. When it finally clicked for me, I realized how important Kubernetes was. It didn’t stop me from still being confused, though. So, I went to the coding well and it turns out there are a bunch of resources for guys like me. Once again, Python was a <span class="No-Break">big help.</span></p>
			<p>Creating a Kubernetes cluster usually involves using it in a cloud service. For this exercise, we are <a id="_idIndexMarker288"/>going to write code for setting <a id="_idIndexMarker289"/>up clusters in Google Cloud and <span class="No-Break">Microsoft Azure:</span></p>
			<pre class="sour e- ode">from google.cloud import container_v1# Specify your project ID and cluster detailsproject_id = "&lt;YOUR_PROJECT_ID&gt;"zone = "&lt;PREFERRED_ZONE&gt;"cluster_name = "&lt;YOUR_CLUSTER&gt;"node_pool_name = 'default-pool'node_count = 1     client = container_v1.ClusterManagerClient()    # Create a GKE cluster    cluster = container_v1.Cluster(        name=cluster_name,        initial_node_count=node_count,        node_config=container_v1.NodeConfig(            machine_type='n1-standard-2',        ),    )    operation = client.create_cluster(project_id, zone, cluster)</pre>
			<p>This operation will create a Kubernetes cluster in your Google Cloud project. Now let’s look at a way to do it <span class="No-Break">in Azure:</span></p>
			<pre class="sour e- ode">from azure.mgmt.containerservice.models import ManagedCluster, ManagedClusterAgentPoolProfileresource_group = '&lt;RESOURCE_GROUP_HERE&gt;'cluster_name = '&lt;CLUSTER_NAME_HERE&gt;'location = '&lt;LOCATION_HERE&gt;' agent_pool_profile = ManagedClusterAgentPoolProfile(    name='agentpool',    count=3,    vm_size='Standard_DS2_v2',) aks_cluster = ManagedCluster(location=location, kubernetes_version='1.21.0', agent_pool_profiles = [agent_pool_profile])aks_client.managed_clusters.begin_create_or_update(resource_group, cluster_name, aks_cluster).result()</pre>
			<p>This creation <a id="_idIndexMarker290"/>code is fairly standard as well; it is simply a change in terminology. This is probably not the most efficient way to write <a id="_idIndexMarker291"/>code for this function (that will come later with Infrastructure as Code), but it gets the <span class="No-Break">job done.</span></p>
			<p>A lot of what we have looked at so far is gibberish to the layman, and sometimes the layman is the one most frequently operating resources. So let’s now look at a process that can be a blueprint for automating more complex processes to involve the layman more in the resource <span class="No-Break">creation process.</span></p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor153"/>Automated launching of playbooks based on parameters</h1>
			<p>Most of the time, even the most basic tasks when automated can become difficult to understand. If you have to automate or trigger multiple tasks, the complexity starts to increase. Not everyone can understand them, and it shouldn’t be the job of everyone to understand them. That is why even a lot of modern servers have user interfaces that make the processing of information easier <span class="No-Break">for many.</span></p>
			<p>However, in many cases, even this level of abstraction isn’t enough. It may be necessary to create a <a id="_idIndexMarker292"/>tool in which users can simply enter their inputs and the server handles the creation of complex workflows and resources automatically. In short, you can make playbooks with parameters that will create resources based on an overview given to it by someone who would like the creation of the resource but does not want to bother with the intricacies behind it (in most places, these rather whimsical folk are called customers). Let’s see how to <span class="No-Break">do that:</span></p>
			<ol>
				<li>We will start by making a Google Form (yes, seriously). Go to <a href="http://forms.google.com">forms.google.com</a> and click on the big plus (+) <span class="No-Break">button.</span></li>
			</ol>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B21320_07_1.jpg" alt="Figure 7.1 – Instance selection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Instance selection</p>
			<p class="list-inset">It’s a simple Google Form for two different sizes of <span class="No-Break">EC2 instances.</span></p>
			<ol>
				<li value="2">Now, we are going to write a Google Apps Script script and an AWS <span class="No-Break">Lambda function:</span><pre class="sour e- ode">import boto3
ec2 = boto3.client('ec2')
def lambda_handler(event, context):
    instance_size = event['instance_size']
    response = ec2.run_instances(
        ImageId='&lt;INSERT_AMI_HERE&gt;',
        InstanceType=instance_size,
        MinCount=1,
        MaxCount=1,
        SecurityGroupIds=['&lt;INSERT_SECURITY_GROUP_HERE'],
        SubnetId='&lt;INSERT_SUBNET_HERE&gt;'
    )
    return response</pre><p class="list-inset">This Lambda <a id="_idIndexMarker293"/>function takes an input consisting of the size of the EC2 instance to be created and then creates that instance. We can define an endpoint for it using the Lambda URL or the <span class="No-Break">API gateway.</span></p></li>
				<li>Once this function and this endpoint have been made, you can then call the endpoint from Apps Script and make the trigger and the input from the form. In the form editor, click on the three dots at the top right and click on <span class="No-Break"><strong class="bold">Script editor</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B21320_07_2.jpg" alt="Figure 7.2 – Accessing Script editor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Accessing Script editor</p>
			<ol>
				<li value="4">You can <a id="_idIndexMarker294"/>now write the API script in what is <span class="No-Break">essentially JavaScript:</span><pre class="sour e- ode">function submitForm(e) {
var responses = e.values;
var size = responses[0];
var apiUrl = '&lt;YOUR_LAMBDA_URL&gt;';
var requestData = {
'instance_size': size,
};
var requestBody = JSON.stringify(requestData);
var options = {
'method': 'get',
'contentType': 'application/json',
'payload': requestBody,
};
var response = UrlFetchApp.fetch(apiUrl, options);
}</pre><p class="list-inset">This will <a id="_idIndexMarker295"/>run the Lambda function, though there is a final step to trigger it by adding a trigger. On the left pane of the Apps Script project, click on the <span class="No-Break"><strong class="bold">Triggers</strong></span><span class="No-Break"> option.</span></p></li>
			</ol>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B21320_07_3.jpg" alt="Figure 7.3 – Calling Lambda using Apps Script"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Calling Lambda using Apps Script</p>
			<ol>
				<li value="5">At the <a id="_idIndexMarker296"/>bottom right, click on <strong class="bold">Add Trigger</strong>, which will open the form to create a trigger where you can define all the <span class="No-Break">necessary parameters:</span></li>
			</ol>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/B21320_07_4.jpg" alt="Figure 7.4 – Adding a trigger for when the form is submitted…"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – Adding a trigger for when the form is submitted…</p>
			<p class="list-inset">Here, we can <a id="_idIndexMarker297"/>add the source of the event, and the function, and select the <span class="No-Break">event type.</span></p>
			<p class="list-inset">In doing so, we will create a workflow that will trigger a function when form data is submitted and use the data provided to the function to trigger an <span class="No-Break">API URL.</span></p>
			<p>And there you have it, that’s one way to connect all of the machinations that happen behind the scenes in a Lambda function with a simple <span class="No-Break">Google Form.</span></p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor154"/>Summary</h1>
			<p>In this chapter, we discussed the beauty of automation along with the means to achieve it. We learned how to automate virtual machine maintenance and container operations. We even learned how to add a layer of automation on top of that that would allow us to get people who are significantly less in the know involved in our process. Automation is a good thing. People will often believe otherwise and fear the automation of a lot of tasks, but the point of automation is to ensure that it is easier for people to live their lives. A life is not meant for boring repetitive tasks, it is meant for exploration. Automation is key to free up time for exploration. You control your life by controlling your time. Automation lets you <span class="No-Break">do that.</span></p>
			<p>In the next chapter, we will discuss the events that drive not only automation but most DevOps infrastructure in general. We will look into event-driven architecture and use cases where it is advantageous, as well as – of course – how Python <span class="No-Break">can help.</span></p>
		</div>
	</body></html>