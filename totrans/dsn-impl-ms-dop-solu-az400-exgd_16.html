<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer208">
<h1 class="chapter-number" id="_idParaDest-364"><a id="_idTextAnchor1144"/>16</h1>
<h1 id="_idParaDest-365"><a id="_idTextAnchor1145"/>Containers</h1>
<p>Over the last couple of years, containers have become a hot topic. They allow you to package any application or any tool, written in any language, and deploy it on a basic host or cluster. When implementing DevOps, containers can be of tremendous value. That is why DevOps and containers are often mentioned in the same breath. However, they are not the same thing. While DevOps is a cultural thing, containers are a type of technology, an alternative way of hosting your applications.</p>
<p>In this chapter, you will learn more about containers and how they work. This is achieved by exercises wherein custom container images are created and run on different hosting platforms, such as Azure Container Instances and Kubernetes.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>An introduction to containers</li>
<li>Building a container image</li>
<li>Building images in Azure DevOps and running them in Azure</li>
<li>An introduction to Kubernetes</li>
<li>Kubernetes in action</li>
<li>Upgrading containers</li>
<li>Scaling containers and Kubernetes</li>
<li>Deploying to Kubernetes with Azure DevOps</li>
</ul>
<h1 id="_idParaDest-366"><a id="_idTextAnchor1146"/><a id="_idTextAnchor1147"/>Technical requirements</h1>
<p>To experiment with the techniques described in this chapter, you need one or more of the following:</p>
<ul>
<li>Docker Desktop</li>
<li>Visual Studio 2019/Visual Studio Code</li>
<li>An Azure subscription</li>
<li>The Azure CLI</li>
</ul>
<p>All these are available for free or can be obtained for a limited period for free for evaluation <a id="_idTextAnchor1148"/>purposes.</p>
<h1 id="_idParaDest-367"><a id="_idTextAnchor1149"/>An introduction to containers</h1>
<p>Containers are the evolution<a id="_idIndexMarker1253"/> of virtualization. With virtualization, the resources of physical machines are shared among several virtual machines. Sharing those resources also means that all virtual machines have their own operating system. This is different when using containers. With containers, not only are the resources shared but also the operating system kernel, making it very small in comparison with a virtual machine image.</p>
<p>Since the operating system kernel is shared, containers are also very portable. Images can be deployed on any type of host environment that supports running containers. This works because all the application’s binaries and configurations are stored inside the container. As a result, environment variables outside the container do not impact the application.</p>
<p>Naturally, there are a <a id="_idIndexMarker1254"/>number of caveats, however – a container shares the operating system kernel. </p>
<p>Containers provide the ability to virtualize an operating system in order to run multiple workloads on a single operating system. This is visualized in the following diagram, where you can see the difference between regular hosting, virtual machine hosting, and containers:</p>
<div>
<div class="IMG---Figure" id="_idContainer190">
<img alt="Figure 16.1 – Virtualization to containers " height="559" src="image/B18655_16_01.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.1 – Virtualization to containers<a id="_idTextAnchor1150"/></p>
<p>If you have ever<a id="_idIndexMarker1255"/> heard of containers, you almost certainly have also heard of Docker. This is because Docker is one of the most well-known container engines that can be used for running containers. </p>
<p>The next section will delve into DevOps and containers, while th<a id="_idTextAnchor1151"/>e remainder of the chapter will go into more technical detail regarding containers<a id="_idTextAnchor1152"/>.</p>
<h2 id="_idParaDest-368"><a id="_idTextAnchor1153"/>DevOps and containers</h2>
<p>As mentioned in the introduction, DevOps and containers are not the same thing. Containers are the technology that<a id="_idIndexMarker1256"/> makes DevOps easier. This is because containers have benefits that make them <em class="italic">the</em> perfect tool for DevOps:</p>
<ul>
<li><strong class="bold">Consistent</strong>: Because you<a id="_idIndexMarker1257"/> build the container images, the hurdle of “<em class="italic">it works on my machine”</em> is eliminated.</li>
<li><strong class="bold">Separation of concerns</strong>: When using containers, your application will be distributed between separate containers, which makes it easier to maintain and separate the processes.</li>
<li><strong class="bold">Platform</strong>: The solution can be run on different platforms. It does not matter whether this is in Microsoft Azure, on Amazon Web Services, on Google Cloud, or in an on-premises environment, including even on your development machine.</li>
</ul>
<p>That aside, DevOps is more cultural than technical and, as mentioned in <a href="B18655_01.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to DevOps</em>, technical components are used to support DevOps. In the remainder of this chapter, we will focus on the technical side of thin<a id="_idTextAnchor1154"/><a id="_idTextAnchor1155"/><a id="_idTextAnchor1156"/>gs.</p>
<h2 id="_idParaDest-369"><a id="_idTextAnchor1157"/>Hosting options</h2>
<p>As mentioned previously, one <a id="_idIndexMarker1258"/>of the benefits of containers is that they are extremely portable. This also means that containers can be hosted on numerous platforms and technologies.</p>
<p>To run the containers, there are a lot of options that will vary according to your use case. Some of these options are as follows:</p>
<ul>
<li>Azure App Service</li>
<li>Azure Service Fabric</li>
<li>Docker Swarm</li>
<li>Docker Desktop</li>
<li>Kubernetes</li>
</ul>
<p>Depending on the demands of the application/container, it could run on all the options mentioned in the preceding list.</p>
<p>The images used to run containers (container images) also need to be hosted. These images are hosted in a so-called container registry. In a container registry, they are published privately or publicly. The two most well-known registries are Docker Registry and Azure Container Registry within the Azure platform.</p>
<p>Now that we have gone through some of the background information regarding containers, we are ready to go more deeply into the techniques behind containers and find out wha<a id="_idTextAnchor1158"/>t is needed to create a custom container im<a id="_idTextAnchor1159"/>age.</p>
<h1 id="_idParaDest-370"><a id="_idTextAnchor1160"/>Building a container image</h1>
<p>This section will<a id="_idIndexMarker1259"/> take you through the process of building a container image and executing it on your local system. To do this, we will first have to create an application and then add Docker support to it before we create an image and finally test it. So, let’s b<a id="_idTextAnchor1161"/><a id="_idTextAnchor1162"/><a id="_idTextAnchor1163"/>egin!</p>
<h2 id="_idParaDest-371"><a id="_idTextAnchor1164"/>Creating an application</h2>
<p>To be able to test and <a id="_idIndexMarker1260"/>check what is running on the container, an application is required. For this, a new application can be created, or you can use an existing application.</p>
<p>When creating a new application, the easiest option is to use the default ASP.NET Core website template within Visual Studio 2019. Container support can be added in a few clicks. This is simply done by checking the <strong class="bold">Enable Docker</strong> box when creating the project:</p>
<div>
<div class="IMG---Figure" id="_idContainer191">
<img alt="Figure 16.2 – An ASP.Net Core new application with Docker support " height="639" src="image/B18655_16_02.jpg" width="1073"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.2 – An ASP.Net Core new application with Docker support</p>
<p>Keep the new application open or open your existing application. In the next section, we will investigate how Docker support can be added to an existing applica<a id="_idTextAnchor1165"/><a id="_idTextAnchor1166"/><a id="_idTextAnchor1167"/>tion.</p>
<h2 id="_idParaDest-372"><a id="_idTextAnchor1168"/>Adding Docker support to an existing application</h2>
<p>Adding Docker<a id="_idIndexMarker1261"/> support to an existing application requires a couple of simple steps:</p>
<ol>
<li value="1">Open the project/solution in Visual Studio 2019 and right-click on the project.</li>
<li>Choose <strong class="bold">Add</strong> and select <strong class="bold">Docker Support</strong>:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer192">
<img alt="Figure 16.3 – An ASP.Net Core existing application with Docker support " height="534" src="image/B18655_16_03.jpg" width="963"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.3 – An ASP.Net Core existing application with Docker su<a id="_idTextAnchor1169"/>pport</p>
<p>Depending on your client tools and Visual Studio configuration, there may also be a <strong class="bold">Container Orchestrator Support</strong> option. With this option, the cloud orchestrator of your choice can be chosen. In this sample, we used Docker Compose because this format is supported <a id="_idIndexMarker1262"/>by the major container orchestrators. Other cloud orchestrator options do exist, however:</p>
<ul>
<li>Docker Swarm</li>
<li>Kubernetes</li>
<li>Mesos Marathon</li>
</ul>
<p>Depending on the cloud orchestrator used, a file is added to the project in the specific format for that orchestrator.</p>
<p>By adding Docker support, a new file is added to the project named <strong class="source-inline">Dockerfile</strong>. The Dockerfile is the specification of a container image. This file can be read by Docker, which sees it as<a id="_idIndexMarker1263"/> instructions. The file is a text document that contains separate commands that can also be called within a command-line tool to assemble an image:</p>
<pre class="source-code">
FROM mcr.microsoft.com/dotnet/aspnet:3.1 AS base
WORKDIR /app
EXPOSE 80
EXPOSE 443
EXPOSE 555
FROM mcr.microsoft.com/dotnet/sdk:3.1 AS build
WORKDIR /src
COPY ["WebApplication2.csproj", "."]
RUN dotnet restore "WebApplication2.csproj"
COPY . .
WORKDIR "/src/"
RUN dotnet build "WebApplication2.csproj" -c Release -o /app/build
FROM build AS publish
RUN dotnet publish "WebApplication2.csproj" -c Release -o /app/publish
FROM base AS final
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT ["dotnet", "WebApplication2.dll"]</pre>
<p>The example uses a<a id="_idIndexMarker1264"/> technique called a multi-stage build file. This is because the file uses multiple <strong class="source-inline">FROM</strong> statements where there is a reference to a specific image.</p>
<p>Prior to the multi-stage build, it wasn’t possible to use multiple <strong class="source-inline">FROM</strong> statements. During this time, it <a id="_idIndexMarker1265"/>was hard to build efficient container images. Each statement in the file represented an additional layer on the image that resulted in it becoming larger an<a id="_idTextAnchor1170"/>d larger.</p>
<p>During this build process, it was also necessary to remove any components that were required during this process. For this reason, it was very common to have separate Dockerfiles for development and production.</p>
<p>As mentioned, the Dockerfile comprises instructions and the most commonly used instructions are as follows:</p>
<ul>
<li><strong class="bold">FROM</strong>: The <strong class="source-inline">FROM</strong> command is <a id="_idIndexMarker1266"/>used to specify on which operating system or base image the image will be based. In the preceding example, the<strong class="source-inline"> mcr.microsoft.com/dotnet/aspnet:3.1 AS</strong> base image is used to build the production version of the application.</li>
<li><strong class="bold">RUN</strong>: The <strong class="source-inline">RUN</strong> command is <a id="_idIndexMarker1267"/>used to install components or perform operations during the build process of the container image.</li>
<li><strong class="bold">ENTRYPOINT</strong>: The <strong class="source-inline">ENTRYPOINT</strong> command specifies what the entry point for a container image needs to be. In<a id="_idIndexMarker1268"/> the preceding example, the entry point is specified as a .NET application that references the library that was built during the compilation process.</li>
</ul>
<p>So far, we’ve created our application and added Docker support. Next, we’l<a id="_idTextAnchor1171"/>l see how to create an image with the <a id="_idTextAnchor1172"/>application.</p>
<h2 id="_idParaDest-373"><a id="_idTextAnchor1173"/>Creating an image with the application</h2>
<p>To be able to create a <a id="_idIndexMarker1269"/>Docker image, Docker Desktop needs to be installed, as Visual Studio uses this to construct the image. With a complete Dockerfile, the image can be built using the following steps:</p>
<p>Right-click the Dockerfile in Visual Studio and select <strong class="bold">Build Docker Image</strong>:</p>
<div>
<div class="IMG---Figure" id="_idContainer193">
<img alt="Figure 16.4 – An Asp.Net Core application build Docker Image " height="418" src="image/B18655_16_04.jpg" width="1297"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.4 – An Asp.Net Core application build <a id="_idTextAnchor1174"/>Docker Image</p>
<p>During the compilation and building of the image, take a look at the output window. Looking at it will provide more insights into the layered approach of container images.</p>
<p>Docker Desktop also makes it possible to run and store images locally. After building the image, open a terminal and run the following command:</p>
<pre class="source-code">
<strong class="bold">docker images</strong></pre>
<p>The command displays all images currently on the machine. In this list, the base images that are downloaded during the creation of images are also listed:</p>
<div>
<div class="IMG---Figure" id="_idContainer194">
<img alt="Figure 16.5 – A Docker image list " height="250" src="image/B18655_16_05.jpg" width="1338"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.5 – A Docker image list</p>
<p>We looked at how to add Docker support and make Docker images for current and new ASP.NET Core apps. The <a id="_idIndexMarker1270"/>next part will explore how to run conta<a id="_idTextAnchor1175"/><a id="_idTextAnchor1176"/><a id="_idTextAnchor1177"/>iner images.</p>
<h2 id="_idParaDest-374"><a id="_idTextAnchor1178"/>Running the container image</h2>
<p>The container image <a id="_idIndexMarker1271"/>can be started locally by running it within Docker. As we now have a container image, a container can be created:</p>
<ol>
<li value="1">Run the following <strong class="source-inline">docker container run</strong> command:<p class="source-code"><strong class="bold">docker container run --publish 8123:80 --detach --name [container name] [image name]</strong></p></li>
</ol>
<p>The preceding command will start the container image specified at the end of the command. In addition, different arguments are specified:</p>
<ul>
<li><strong class="bold">Publish</strong>: The <strong class="source-inline">publish</strong> argument opens a port from the host to the container. As mentioned in the example in the preceding section, this will open port <strong class="source-inline">8123</strong> and route traffic to port <strong class="source-inline">80</strong> within the container.</li>
<li><strong class="bold">Detach</strong>: The <strong class="source-inline">detach</strong> argument will run the container in the background and print out its specific ID.</li>
<li><strong class="bold">Name</strong>: The name for the container within Docker.</li>
</ul>
<ol>
<li value="2">To list all running containers, use the <strong class="bold">docker ps</strong> command within the terminal.</li>
<li>With the container running, open a browser and navigate to <strong class="source-inline">http://localhost:8123</strong>. If everything works fine, this should show a default ASP.NET Core web page:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer195">
<img alt="Figure 16.6 – The ASP.Net Core default welcome page " height="149" src="image/B18655_16_06.jpg" width="529"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.6 – The ASP.Net Core default welcome page</p>
<p>Since building stuff locally and running it on your machine is not really the DevOps way of doing things, we will <a id="_idIndexMarker1272"/>move to a different hosting platform in the upcom<a id="_idTextAnchor1179"/><a id="_idTextAnchor1180"/><a id="_idTextAnchor1181"/>ing sections.</p>
<h1 id="_idParaDest-375"><a id="_idTextAnchor1182"/>Building images in Azure DevOps and running them  in Azure</h1>
<p>To support continuous integration and <a id="_idIndexMarker1273"/>continuous delivery, the source files need to be shared in a repository. So, let’s share the resources in Azure Repos <a id="_idIndexMarker1274"/>and try to build our container by using Azure Pipelines. After building the container image, a place to store the images and run the container is also required. Within the Azure platform, there are two perfect services for this scenario:</p>
<ul>
<li><strong class="bold">Azure Container Registry</strong> (<strong class="bold">ACR</strong>): This service is a managed private Docker registry based on the open <a id="_idIndexMarker1275"/>source Docker Registry. Here, you can maintain and register container images.</li>
<li><strong class="bold">Azure Container Instance</strong>: <strong class="bold">Azure Container Instances</strong>, also referred to as <strong class="bold">ACI</strong>, is a solution for running <a id="_idIndexMarker1276"/>isolated containers without a lot of management.</li>
</ul>
<p class="callout-heading">Important Note</p>
<p class="callout">For the simplicity of this guide, the files are already added to the repository and the Azure resource is already created.</p>
<p>In the next section, we will explore how to create images in ACR and run them in ACI thro<a id="_idTextAnchor1183"/><a id="_idTextAnchor1184"/>ugh Azure DevOps.</p>
<h2 id="_idParaDest-376"><a id="_idTextAnchor1185"/>Creating a service endpoint</h2>
<p>As already discussed within<a id="_idIndexMarker1277"/> the book, connections within Azure DevOps with external services such as Azure and container registries are configured within a service endpoint. Because an image needs to be available in order for ACI to retrieve it, it needs to be published to a container registry. The connection from Azure DevOps to the registry is configured within a service connection.</p>
<p>Perform the following steps to configure the service connection:</p>
<ol>
<li value="1">In the Azure DevOps project, open the project settings.</li>
<li>Within the project settings, click on <strong class="bold">Service connections</strong>.</li>
<li>In the service connection overview, click on <strong class="bold">Create service connection</strong> and choose <strong class="bold">Docker Registry</strong>.</li>
<li>In the fly-out that appears, fill in the correct information and save the connection:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer196">
<img alt="Figure 16.7 – A new Azure Container Registry service connection " height="432" src="image/B18655_16_07.jpg" width="440"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.7 – A new Azure Container Registry s<a id="_idTextAnchor1186"/>ervice connection</p>
<p>Saving the connection will <a id="_idIndexMarker1278"/>add a service connection to the project that can be used by the pipelines we will create, or that you will cre<a id="_idTextAnchor1187"/><a id="_idTextAnchor1188"/><a id="_idTextAnchor1189"/>ate in the future.</p>
<h2 id="_idParaDest-377"><a id="_idTextAnchor1190"/>Creating a new pipeline</h2>
<p>To be able to <a id="_idIndexMarker1279"/>start building the container image and publish it to the registry, we will create a new pipeline. For this example, we will make use of the YAML pipeline experience.</p>
<p>Perform the following steps to get started with the pipeline:</p>
<ol>
<li value="1">Open your Azure DevOps project and click on <strong class="bold">Pipelines</strong>.</li>
<li>In the pipelines overview, click on <strong class="bold">New Pipeline</strong>.</li>
<li>Select <strong class="bold">Azure Repos Git</strong>, choose the correct repository, and then choose <strong class="bold">Starter pipeline</strong>:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer197">
<img alt="Figure 16.8 – Azure DevOps – configuring a new pipeline " height="608" src="image/B18655_16_08.jpg" width="621"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.8 – Azure DevOps – configur<a id="_idTextAnchor1191"/>ing a new pipeline</p>
<ol>
<li value="4">From the starter pipeline, remove the two dummy script tasks and open the assistant.</li>
<li>In the assistant, search<a id="_idIndexMarker1280"/> for the Docker tasks and add the tasks to the pipeline.</li>
<li>Choose the service connection created for the container registry and keep the other information as the default.</li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">Make sure to change the <strong class="source-inline">buildContext</strong> property of the tasks to point to the correct directory. This is required for Docker to be able to reference the correct paths when building your image.</p>
<p>When added, the YAML should look like this:</p>
<p class="source-code">- task: Docker@2 </p>
<p class="source-code">  inputs:</p>
<p class="source-code">    containerRegistry: 'MSFT Container Registry' </p>
<p class="source-code">    repository: 'azuredevops'</p>
<p class="source-code">    command: 'buildAndPush' </p>
<p class="source-code">    Dockerfile:'**/Dockerfile' </p>
<p class="source-code">    buildContext:</p>
<p class="source-code">'$(System.DefaultWorkingDirectory)/ExistingDevOpsProject'</p>
<ol>
<li value="7">Save and run the pipeline. After the first run, the container image is created and published to the container registry.</li>
</ol>
<p>The images in the container registry can be retrieved by using a predefined URL. This URL comprises a few specific components:</p>
<p class="source-code">[container registry]/[repository]:[tag]:</p>
<ul>
<li><strong class="bold">Container registry</strong>: The base URL of the container registry.</li>
<li><strong class="bold">Repository</strong>: The repository as specified during the process of publishing the image.</li>
<li><strong class="bold">Tag</strong>: The tag for the specific version of the image. By default, the Docker t<a id="_idTextAnchor1192"/>ag used is <strong class="source-inline">BuildId</strong>.</li>
</ul>
<ol>
<li value="8">Now that we have a<a id="_idIndexMarker1281"/> reference to the container image, ACI should be able to retrieve the container and run it. The only thing needed for this is an Azure CLI command:<p class="source-code">az container create --resource-group [resource group] --name [ACI name] --location westeurope --image [Image reference] --dns- name-label [dns reference] --ports 80 --registry-username [username of the registry] --registry-password [password of the registry]</p></li>
</ol>
<p>Since the reference to the image is different for each build (<strong class="source-inline">BuildId</strong> for the tag value), <strong class="source-inline">BuildId</strong> is retrieved in the Azure CLI command via the <strong class="source-inline">$(Build.BuildId)</strong> variable:</p>
<p class="source-code">az container create --resource-group aci-rg-devops --name aci- demo-app --location westeurope --image msftazuredevops.azurecr.io/azuredevops:$(Build.BuildId) --dns- name-label aci-msft-demo --ports 80 --registry-username</p>
<p class="source-code">$(username) --registry-password $(password)</p>
<p>To execute the preceding script, the Azure CLI task is added to the pipeline. In this task, we configure the correct subscription via the service endpoint and set the inline script.</p>
<p>The script will create a container instance in the <strong class="source-inline">aci-rg-devops</strong> resource group with the name <strong class="source-inline">aci-demo-app</strong> and retrieve the <strong class="source-inline">azuredevops</strong> container image from the <strong class="source-inline">msftazuredevops.azurecr.io</strong> repository.</p>
<p>The complete YAML for this task looks like this:</p>
<p class="source-code">- task: AzureCLI@2 </p>
<p class="source-code">  inputs:</p>
<p class="source-code">  azureSubscription: 'Subscription MPN' </p>
<p class="source-code">  scriptType: 'bash'</p>
<p class="source-code">  scriptLocation: 'inlineScript'</p>
<p class="source-code">  inlineScript: 'az container create --resource-group aci-rg- devops -</p>
<p class="source-code">name aci-demo-app --location westeurope --image msftazuredevops.azurecr.io/azuredevops:$(Build.BuildId) --dns- name-label aci-msft-demo --ports 80 --registry-username</p>
<p class="source-code">$(username) --registry-p<a id="_idTextAnchor1193"/>assword $(password)'</p>
<p>Running this pipeline will result in an Azure container instance in Azure. That container will be running the exact same application that was running locally:</p>
<div>
<div class="IMG---Figure" id="_idContainer198">
<img alt="Figure 16.9 – An aci-demo-app instance running in ACI " height="65" src="image/B18655_16_09.jpg" width="595"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.9 – An aci-demo-app instance running in ACI</p>
<p>When opening the <a id="_idIndexMarker1282"/>Azure container instance in the Azure portal, you will see that it is a running instance and that there is a <strong class="bold">Fully Qualified Domain Name</strong> (<strong class="bold">FQDN</strong>) attached to the<a id="_idIndexMarker1283"/> Azure container instance based on the value supplied, <strong class="source-inline">dns-name-label</strong>, within the Azure CLI command, <strong class="source-inline">aci-msft- demo.westeurope.azurecontainer.io</strong>. Open the URL in your browser and see the application we have pushed to the container:</p>
<div>
<div class="IMG---Figure" id="_idContainer199">
<img alt="Figure 16.10 – The aci-demo-app welcome page " height="312" src="image/B18655_16_10.jpg" width="762"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.10 – The aci-demo-app welcome page</p>
<p>It shows the same content as the container that was started locally. This is because, in both places, the same container image was started.</p>
<p>In this section, we<a id="_idIndexMarker1284"/> started the container on ACI, but how will we manage running containers and restart them when there are problems? This is where<a id="_idTextAnchor1194"/><a id="_idTextAnchor1195"/><a id="_idTextAnchor1196"/> Kubernetes comes in.</p>
<h1 id="_idParaDest-378"><a id="_idTextAnchor1197"/>An introduction to Kubernetes</h1>
<p>Kubernetes is another<a id="_idIndexMarker1285"/> service for running your containers. Kubernetes is a cluster orchestration technology first developed by Google. It is now an open source platform for automating deployment, scaling, and operations of application contain<a id="_idTextAnchor1198"/>ers across clusters of hosts, thereby providing a container-centric infrastructure. The term Kubernetes is often abbreviated as <em class="italic">K8s</em>. This is generated by substituting the eight letters of <em class="italic">ubernete</em> in the wo<a id="_idTextAnchor1199"/>rd with the numeral 8.</p>
<h2 id="_idParaDest-379"><a id="_idTextAnchor1200"/>The functionalities of Kubernetes</h2>
<p>As mentioned earlier, containers offer you a great way to package your applications. When running the applications, you<a id="_idIndexMarker1286"/> need to make sure that applications keep running and this is where Kubernetes comes in, as it has the following core functionalities:</p>
<ul>
<li><strong class="bold">Service discovery and load balancing</strong>: How a container is exposed is controlled within Kubernetes and, in addition, it is also capable of balancing the traffic within the orchestration.</li>
<li><strong class="bold">Storage orchestration</strong>: The ability to mount different kinds of storage providers to the platform.</li>
<li><strong class="bold">Rollouts and rollbacks</strong>: Kubernetes can automatically create and restart containers for the specified deployment.</li>
<li><strong class="bold">Self-healing</strong>: Kubernetes can heal containers when they are failing.</li>
<li><strong class="bold">Secret and configuration management</strong>: Kubernetes has a built-in functionality to manage secrets such as token<a id="_idTextAnchor1201"/>s, passwords, and keys.</li>
</ul>
<p>In order to provide these functionalities, Kubernetes consists of <a id="_idTextAnchor1202"/>a number of components.</p>
<h2 id="_idParaDest-380"><a id="_idTextAnchor1203"/>Kubernetes core components and services</h2>
<p>Kubernetes consists of <a id="_idIndexMarker1287"/>a few core components that make it run. These components together make a great and stable product for running and managing containers. The next few subsections will go over each of these <a id="_idTextAnchor1204"/><a id="_idTextAnchor1205"/><a id="_idTextAnchor1206"/>components individually.</p>
<h3>Master node</h3>
<p>One of the important <a id="_idIndexMarker1288"/>components within Kubernetes is the master node. The node manages the cluster. It contains all the Kubernetes core components in order to manage the cluster:</p>
<ul>
<li><strong class="bold">kube-apiserver</strong>: A component <a id="_idIndexMarker1289"/>for exposing the Kubernetes API. This API is used by the management tools of Kubernetes, such as <strong class="source-inline">kubectl</strong>, and the Kubernetes dashboard.</li>
<li><strong class="bold">etcd</strong>: Used to maintain<a id="_idIndexMarker1290"/> the state of the Kubernetes cluster.</li>
<li><strong class="bold">kube-scheduler</strong>: A component <a id="_idIndexMarker1291"/>that selects nodes for the Pods to run on. </li>
<li><strong class="bold">kube-controller-manager</strong>: The controller <a id="_idIndexMarker1292"/>manager oversees a number of smaller controllers that perform actions such as replicating Pods and managing node operations.</li>
</ul>
<p>By using these components, the master node can maintain the desired state for the cluster. It is good to know that when you are interacting with Kubernetes, you are communicating with the master node. The master node will th<a id="_idTextAnchor1207"/>en communicate with the other c<a id="_idTextAnchor1208"/>omponents within the cluster.</p>
<h3>Regular nodes</h3>
<p>These are the nodes that <a id="_idIndexMarker1293"/>will run the containers. Sometimes, they are referred to as worker nodes. They<a id="_idIndexMarker1294"/> can be virtual machines or even physical machines. On these machines, the so-called <strong class="source-inline">kubelet</strong> is installed. <strong class="source-inline">kubelet</strong> is the agent that’s used to run Pods/containers within the nodes.</p>
<p>As you may have noticed in the preceding sections, there are <a id="_idTextAnchor1209"/>also other core services within Kubernetes, <a id="_idTextAnchor1210"/>and we will discuss them next.</p>
<h3>Pod</h3>
<p>Within Kubernetes, Pods are used to run the applications. Within the Pods, it is specified which resources are required to run<a id="_idIndexMarker1295"/> the application. The scheduler (<strong class="source-inline">kube-schedular</strong>) within Kubernetes checks where to run the application, depending on the demands and the nodes coupled to the cluster.</p>
<p>Pods have a limited lifespan and are removed when new versions are deployed. Also, when a node fails, Pods can be replaced by other P<a id="_idTextAnchor1211"/><a id="_idTextAnchor1212"/><a id="_idTextAnchor1213"/>ods on the same or another node.</p>
<h3>Service</h3>
<p>The service is<a id="_idIndexMarker1296"/> sometimes referred to as the load balancer and is used to provide a logical grouping of Pods and furnish them with connectivity (a way to connect).</p>
<p>The three major services are as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer200">
<img alt="Figure 16.11 – The K8s services relationship " height="603" src="image/B18655_16_11.jpg" width="1084"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.11 – The K8s services relationship</p>
<p>The three major services are as follows:</p>
<ul>
<li><strong class="bold">Cluster IP</strong>: Adding an internal IP to a service. By selecting this option, the service is only accessible from within the <a id="_idIndexMarker1297"/>cluster. This is the standard service type.</li>
<li><strong class="bold">Node port</strong>: The node <a id="_idIndexMarker1298"/>port service establishes a port on each cluster node, hence the name, and routes traffic arriving on that port to the underlying service. It exposes services to external clients. </li>
<li><strong class="bold">Load balancer</strong>: This service <a id="_idIndexMarker1299"/>adds a load balancer resource and configures an external IP address on the load balancer. On the external side, the load balancer will route traffic to the specific nodes based on the rules configured in the load balancer and internally to the correct Pod.</li>
</ul>
<p>With these services, the internal and external con<a id="_idTextAnchor1214"/>nections for Pods are arranged. The services and Pods are<a id="_idTextAnchor1215"/> all specified within a deployment.</p>
<h3>Deployment</h3>
<p>A Kubernetes deployment is a resource object that outlines an application’s expected state. It specifies the number <a id="_idIndexMarker1300"/>of replicas as well as the update strategy for that application. Kubernetes will monitor the health of the Pods and will remove or add Pods as needed to reach the desired state specified in the deployment.</p>
<p>These deployments are specified in a YAML file. For example, when running a container in Kubernetes, you must specify a replica set. A replica se<a id="_idTextAnchor1216"/>t ensures that a specified number of Pod rep<a id="_idTextAnchor1217"/>licas are running at any given time.</p>
<h2 id="_idParaDest-381"><a id="_idTextAnchor1218"/>Operation of Kubernetes</h2>
<p>When you are new to <a id="_idIndexMarker1301"/>containers, and especially to Kubernetes, it is hard to figure things out immediately. However, to aid your understanding of the concept, take a look at the following diagram:</p>
<div>
<div class="IMG---Figure" id="_idContainer201">
<img alt="Figure 16.12 – An overview of Kubernetes operations " height="473" src="image/B18655_16_12.jpg" width="760"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.12 – <a id="_idTextAnchor1219"/>An overview of Kubernetes operations</p>
<p>Deployments of containers<a id="_idIndexMarker1302"/> to a Kubernetes cluster are defined in the so-called deployment file (<strong class="bold">1</strong>). In these deployment files, the desired state of the application is described. This desired state is described as a YAML file.</p>
<p>In this example, the desired state is a load balancer service and three Pods (<strong class="bold">2</strong>). These Pods are divided by the Kubernetes API on the nodes that run the containers (<strong class="bold">3</strong>). The service defined in the deployment file ensures that the traffic is routed to the specific Pods. The deployment can be changed by updating it.</p>
<p>The scheduler can also change deployments when, for example, automatic scaling is configured for the application. In that kind of scenario, a fourth Pod could be added to the cluster. In the service, there can also be an external load balancer to route traffic to the inte<a id="_idTextAnchor1220"/><a id="_idTextAnchor1221"/><a id="_idTextAnchor1222"/>rnal load balancer of Kubernetes (<strong class="bold">4</strong>).</p>
<h2 id="_idParaDest-382"><a id="_idTextAnchor1223"/>Azure Kubernetes Service</h2>
<p><strong class="bold">Azure Kubernetes Service</strong>, or <strong class="bold">AKS</strong>, is the <a id="_idIndexMarker1303"/>Microsoft implementation of Kubernetes. Setting up a regular Kubernetes cluster is a lot of work, but with AKS, it has been made easier. This is because AKS is a managed platform and the reason why almost all operational tasks are handled by the platform itself.</p>
<p>Some key functionalities of AKS are as follows:</p>
<ul>
<li>Azure manages<a id="_idIndexMarker1304"/> critical tasks, such as health monitoring, scaling, and maintenance, including Kubernetes version upgrades and patching according to configuration and management requirements.</li>
<li>The master node of Kubernetes is fully managed.</li>
<li>Master nodes are free, and you only pay for running agent nodes. You only have to pay for the worker nodes; the master node is free because the Kubernetes cluster master is managed by Azure. You administer the cluster’s agent<a id="_idIndexMarker1305"/> nodes and only pay for the <strong class="bold">virtual machines</strong> (<strong class="bold">VM s</strong>) on which your nodes run.</li>
</ul>
<p>By using AKS, a Kubernetes cluster can be operational within minutes and the master node is managed by Azure, so the focus will be on application development<a id="_idTextAnchor1224"/> and deployment. Now, let’s try to run <a id="_idTextAnchor1225"/>a Kubernetes cluster with custom images.</p>
<h1 id="_idParaDest-383"><a id="_idTextAnchor1226"/>Kubernetes in action</h1>
<p>In the first few sections <a id="_idIndexMarker1306"/>of this chapter, we created a container and deployed it to an Azure container instance. Let’s now deploy this container to a Kubernetes cluster.</p>
<p>Creating a cluster can be done via the<a id="_idIndexMarker1307"/> Azure CLI or an <strong class="bold">Azure Resource Manager</strong> (<strong class="bold">ARM</strong>) template. For ease of demonstration, the Azure CLI will be used.</p>
<p>First, a new resource group needs to be created to host the Azure Kubernetes cluster:</p>
<pre class="source-code">
<strong class="bold">az group create --na<a id="_idTextAnchor1227"/>me mpn-rg-kubernetes --location westeurope</strong></pre>
<p><a id="_idTextAnchor1228"/>Now, we can create our Kubernetes cluster.</p>
<h2 id="_idParaDest-384"><a id="_idTextAnchor1229"/>Creating a Kubernetes cluster</h2>
<p>When the resource group is<a id="_idIndexMarker1308"/> created, a new Kubernetes cluster can be added to the group:</p>
<pre class="source-code">
<strong class="bold">az aks create --resource-group mpn-rg-kubernetes --name mykubernetescluster</strong>
<strong class="bold">--node-count 1 --en<a id="_idTextAnchor1230"/>able-addons monitoring --generate-ssh-keys</strong></pre>
<p>This command creates a new Kubernetes cluster with the name <strong class="source-inline">mykubernetescluster</strong> and with a single node. This means that there will be one VM created in the Azure portal that is configured as a node for the Kubernetes cluster. In addition, the monitoring <a id="_idIndexMarker1309"/>add-ons will be enabled on the cluster.</p>
<p>The creation of this cluster will take a couple of minutes. In Azure, the <strong class="source-inline">mykubernetescluster</strong> service will be create<a id="_idTextAnchor1231"/>d in the specified resource group. Alongside this resource group, another group w<a id="_idTextAnchor1232"/>ill be created by the Azure platform itself.</p>
<h2 id="_idParaDest-385"><a id="_idTextAnchor1233"/>Kubernetes infrastructure</h2>
<p>In this resource group, all<a id="_idIndexMarker1310"/> virtualized infrastructure that is needed to run the cluster is created. This also means that in the future, new components can be added to this resource group depending on the demands of the application:</p>
<div>
<div class="IMG---Figure" id="_idContainer202">
<img alt="Figure 16.13 – The mpn-rg-kubernetes resource group " height="132" src="image/B18655_16_13.jpg" width="495"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.13 – The mpn-rg-kubernetes resource group</p>
<p>In the resource group created, you will find all the aforementioned resources to run the cluster:</p>
<div>
<div class="IMG---Figure" id="_idContainer203">
<img alt="Figure 16.14 – A list of a few resources required to run a cluster " height="185" src="image/B18655_16_14.jpg" width="452"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.14 – A list of a few resources required to run a cluster</p>
<p>With the Kubernetes infrastructure now up and running, the management and deployment of <a id="_idIndexMarker1311"/>resources can begin.</p>
<h2 id="_idParaDest-386"><a id="_idTextAnchor1234"/>Managing Kubernetes</h2>
<p>To manage <a id="_idIndexMarker1312"/>Kubernetes, the <strong class="source-inline">kubectl</strong> command line is used and installed locally (or used in Azure Cloud Shell). This is command-line interface tooling that will communicate with the Kubernetes API. Let’s see how to work with Kubernetes with this command line:</p>
<ol>
<li value="1">First, download and install <strong class="source-inline">kubectl</strong>, and if you do not already have the Azure CLI installed, run the following command to install the Azure CLI on your machine:<p class="source-code"><strong class="bold">az aks install-cli</strong></p></li>
<li>To connect to the cluster, the credentials need to be retrieved and saved to the local system. This can be done by using the <strong class="source-inline">az aks get-credentials</strong> command and specifying the resource group and cluster name:<p class="source-code"><strong class="bold">az aks get-credentials --resource-group mpn-rg-kubernetes -- name mykubernetescluster</strong></p></li>
<li>With all the prerequisites configured, a lot of the base functionality can be run against the Kubernetes cluster. Take a look at these two commands for example:<ul><li>Retrieve the nodes of the cluster:<p class="source-code"><strong class="bold">kubectl get nodes</strong></p></li><li>Get the Pods in the cluster:<p class="source-code"><strong class="bold">kubectl get Pods</strong></p></li></ul></li>
<li>As well as to the preceding commands, you can also try the following Azure CLI command to open up the Kubernetes dashboard. This dashboard is a management interface built on top of the Kubernetes API that can be used next to the <strong class="source-inline">kubectl</strong> command line:<p class="source-code"><strong class="bold">az aks browse --resource-group mpn-rg-kubernetes --name mykubernetescluster</strong></p></li>
</ol>
<p>The dashb<a id="_idTextAnchor1235"/>oard is<a id="_idIndexMarker1313"/> shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer204">
<img alt="Figure 16.15 – Viewing the Kubernetes dashboard " height="964" src="image/B18655_16_15.jpg" width="1440"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.15 – Viewing the Kubernetes dashboard</p>
<p>A deployment file needs to be created to be able to<a id="_idTextAnchor1236"/> run containers with<a id="_idTextAnchor1237"/>in the cluster. So, let’s see how to do this.</p>
<h2 id="_idParaDest-387"><a id="_idTextAnchor1238"/>Deploying a container image</h2>
<p>We will create a deployment<a id="_idIndexMarker1314"/> file and deploy it to Kubernetes. To do this, perform the following steps:</p>
<ol>
<li value="1">Make a new file in your favorite text editor and call it <strong class="source-inline">deploy.yaml</strong>. Add the following information to the <strong class="source-inline">deploy.yaml</strong> file:<p class="source-code">apiVersion: apps/v1 </p><p class="source-code">kind: Deployment </p><p class="source-code">metadata:</p><p class="source-code">  name: kubernetes-deployment </p><p class="source-code">  labels:</p><p class="source-code">    app: customapplication </p><p class="source-code">spec:</p><p class="source-code">replicas: 3</p><p class="source-code">selector:</p><p class="source-code">  matchLabels:</p><p class="source-code">    app: customapplication </p><p class="source-code">template:</p><p class="source-code">  metadata: </p><p class="source-code">    labels:</p><p class="source-code">      app: customapplication </p><p class="source-code">  spec:</p><p class="source-code">    containers:</p><p class="source-code">    - name: azuredevops</p><p class="source-code">      image: msftazuredevops.azurecr.io/azuredevo<a id="_idTextAnchor1239"/>ps:586 </p><p class="source-code">      ports:</p><p class="source-code">      - containerPort: 80</p></li>
</ol>
<p>In this example, the <a id="_idIndexMarker1315"/>following is specified:</p>
<ul>
<li>A deployment is created with the name <strong class="source-inline">kubernetes-deployment</strong> (<strong class="source-inline">metadata.name</strong>).</li>
<li>The deployment will create three replicas of the specified container (<strong class="source-inline">spec.replicas</strong>).</li>
<li>The selector, in combination with the <strong class="source-inline">labels</strong> tag, is used to specify which components this deployment file will manage within Kubernetes.</li>
<li>The deployment file will create a container for the <strong class="source-inline">msftazuredevops.azurecr.io/azuredevops:586</strong> image file.</li>
</ul>
<ol>
<li value="2">To deploy this file to Kubernetes, we will again use the <strong class="source-inline">kubectl</strong> command line and make use of the <strong class="source-inline">apply</strong> command:<p class="source-code"><strong class="bold">kubectl apply -f deploy.yaml</strong></p></li>
</ol>
<p>The <strong class="source-inline">-f</strong> argument is<a id="_idIndexMarker1316"/> used to specify that a local path is used as a reference to a deployment file. After executing the command, you can open the Kubernetes dashboard to see the status and maybe even observe errors.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">It is possible that you encounter an error stating that pulling the image from your location failed. This could be a security issue. Under the hood, AKS is using a service principal. You should also see this when creating a new Kubernetes cluster. Make sure to give this service principa<a id="_idTextAnchor1240"/>l access rights on the Azure Container Registry.</p>
<ol>
<li value="3">Following a successful execution, try the <strong class="source-inline">get Pods</strong> command to see whether there are three Pods within the system. If everything proceeded correctly, there should be three Pods running within Kubernetes, but the application is still not available to the outside world.</li>
</ol>
<p>To make it available, we need to add a service to the deployment file.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">If you want to add a service to the same file, add a line with the <strong class="source-inline">---</strong> characters between the deployments. This is not required when you also define separate files for deployment.</p>
<p>In the <strong class="source-inline">deploy.yaml</strong> file, add the<a id="_idIndexMarker1317"/> following section:</p>
<p class="source-code">---</p>
<p class="source-code">apiVersion: v1 </p>
<p class="source-code">kind: Service </p>
<p class="source-code">metadata:</p>
<p class="source-code">  name: customapplication-service </p>
<p class="source-code">spec:</p>
<p class="source-code">  type: LoadBalancer </p>
<p class="source-code">  ports:</p>
<p class="source-code">  - port: 80 </p>
<p class="source-code">  selector:</p>
<p class="source-code">    app: customapplication</p>
<p>This YAML section creates a load balancer and attaches it to the specified selector (<strong class="source-inline">spec.selector.app</strong>), meaning it will be used for the Pods, as we previously specified.</p>
<p>In the background, Kubernetes will create an Azure load balancer and a public IP address for connection to the Pods.</p>
<ol>
<li value="4">To retrieve the external IP address of the service, use the following command until it displays the external IP address:<p class="source-code"><strong class="bold">kubectl get service</strong></p></li>
</ol>
<p>This will return all services and their external IP addresses if they are present. Also, take a quick look at the additional resource group of Kubernetes to see which Azure resources are created.</p>
<p>Well done! In this <a id="_idIndexMarker1318"/>section, you learned how to create a Kubernetes cluster and deploy a container image on it via <strong class="source-inline">kubectl</strong> and deployment files. In the next section, we will take this <a id="_idTextAnchor1241"/><a id="_idTextAnchor1242"/><a id="_idTextAnchor1243"/>forward and learn how to upgrade these containers.</p>
<h1 id="_idParaDest-388"><a id="_idTextAnchor1244"/>Upgrading containers</h1>
<p>In Kubernetes, applications are very easily updated. For this, Kubernetes uses rolling updates, which means that traffic to a<a id="_idIndexMarker1319"/> container is first drained before the container is replaced. During an upgrade of the application, Kubernetes will deploy an additional Pod and run it through some specified probes.</p>
<p>A probe is a diagnostic that is periodically performed on a Pod to check its status. During the upgrading or creation of a Pod, Kubernetes brings up the additional Pod and makes sure that it passes the liveness and readiness probes.</p>
<p>If the newly created Pod succeeds with both probes, the traffic to a single, old Pod is terminated and traffic to the new Pod is opened. For this termination, Kubernetes uses a termination grace period. During this period, the connection to the load balancer is stopped and active connections are processed successfully, and new traffic is routed to a running Pod. During the 30-second default grace period, the Pod is in a termination state and all previous traffic to it is diverted to the other Pods.</p>
<p>This process continues until all Pods are replaced with the new version. All of this is default behavior within Azure Kubernetes. Deployment is simply triggered by adjusting the deployment file and applying it with the same command as used previously:</p>
<pre class="source-code">
<strong class="bold">Kubectl apply -f [file]</strong></pre>
<p>By default, <strong class="source-inline">httpGet</strong> probes are added to Pods that are being exposed, but they can also be customized by adding the readiness probe or liveness probe to the deployment:</p>
<pre class="source-code">
readinessProbe:
    httpGet:
        scheme: HTTPS
        path: /index.xhtml
        port: 8483 
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1</pre>
<p>This readiness probe performs an <strong class="source-inline">httpGet</strong> request on the Pod and has the following options:</p>
<ul>
<li><strong class="source-inline">path</strong>: The path it should call for the <strong class="source-inline">httpGet</strong> request.</li>
<li><strong class="source-inline">port</strong>: The port number it should use for the call. This is also configured in our deployment file.</li>
<li><strong class="source-inline">initialDelaySeconds</strong>: The seconds it waits bef<a id="_idTextAnchor1245"/>ore running the probe once the container is started.</li>
<li><strong class="source-inline">periodSeconds</strong>: The number of seconds the probe waits before it times out.</li>
<li><strong class="source-inline">successThreshold</strong>: The minimum amount of success necessary for the probe is <strong class="source-inline">1</strong>.</li>
</ul>
<p>As mentioned, a deployment<a id="_idIndexMarker1320"/> has a default rolling upgrade scenario configured. The configuration of the rolling deployment can be retrieved by using the following command:</p>
<pre class="source-code">
<strong class="bold">kubectl describe deployment kubernetes-deployment</strong></pre>
<p class="callout-heading">Important Note</p>
<p class="callout">If you are interested in doing so, build a new version of your container and upgrade it within Kubernetes. Before running the upgrade, make sure you have the dashboard open, refresh the page during the update, and you will see extra Pods coming up and old Pods being terminated.</p>
<p>In this section, we learned how to upgrade containers, which will help you stay up to date with the latest version. Moving forward<a id="_idTextAnchor1246"/>, in the next section, we will look fu<a id="_idTextAnchor1247"/>rther into the scaling of containers and Kubernetes.</p>
<h1 id="_idParaDest-389"><a id="_idTextAnchor1248"/>Scaling containers and Kubernetes</h1>
<p>As the demand for <a id="_idIndexMarker1321"/>your application grows, you will need to scale the application. Scaling the application <a id="_idIndexMarker1322"/>can be done in multiple ways and different components can be scaled:</p>
<div>
<div class="IMG---Figure" id="_idContainer205">
<img alt="Figure 16.16 – The autoscaler in AKS " height="211" src="image/B18655_16_16.jpg" width="555"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.16 – The autoscaler in AKS</p>
<p>The preceding diagram shows you <a id="_idIndexMarker1323"/>the different ways to scale your application or <a id="_idIndexMarker1324"/>cluste<a id="_idTextAnchor1249"/><a id="_idTextAnchor1250"/><a id="_idTextAnchor1251"/>r, which we will discuss over the upcoming subsections.</p>
<h2 id="_idParaDest-390"><a id="_idTextAnchor1252"/>Scaling Pods manually</h2>
<p>Pods can easily be scaled by <a id="_idIndexMarker1325"/>updating the number of replicas. Try getting your Pods by using the <strong class="source-inline">kubectl get Pods</strong> command, and increase the number of replicas by using the following command:</p>
<pre class="source-code">
<strong class="bold">kubectl scale --replicas=[number of Pods] deployment/[deploymentname]</strong></pre>
<p>This command scales the Pods up or down, based on the number of replicas. The sca<a id="_idTextAnchor1253"/>l<a id="_idTextAnchor1254"/>e is adjusted, as shown in the deployment configuration.</p>
<h3>Autoscaling Pods</h3>
<p>AKS also<a id="_idIndexMarker1326"/> supports autoscaling. The scheduler will then update the number of Pods, depending on CPU utilization or other metrics that are available.</p>
<p>Kubernetes uses the metrics server for this. The metrics server collects metrics from the summary API of the kubelet agents that run on the nodes within the cluster.</p>
<p>The autoscale functionality also requires some configuration on the deployment side of Kubernetes. For deployment, you need to specify the requests and limits for the running container. These values are specified for a specific metric – for example, the CPU.</p>
<p>In the following <a id="_idIndexMarker1327"/>example, there are requests and limits specified for the CPU metric. The CPU metric is measured in CPU units. In Azure, one unit stands for one core. On different platforms, a unit can have a different meanings:</p>
<pre class="source-code">
resources: 
  requests:
    cpu: 0.25 
limits:
    cpu: 0.5</pre>
<p>This part can be added to the container in the deployment file, and this will make sure that the Pods can be a<a id="_idTextAnchor1255"/>utoscaled when large numbers of requests need to be served.</p>
<p>With the updated deployment file, deploy it and make an autoscale rule within the Kubernetes cluster:</p>
<pre class="source-code">
<strong class="bold">kubectl autoscale deployment [deployment name] --cpu-percent=60 --min=1 --max=10</strong></pre>
<p>This rule will update the deployment with autoscale functionality. If average CPU utilization across all Pods exceeds 60% of their requested usage, the autoscaler increases the Pods up to a maximum of 10 instances. A minimum of one instance is then defined for the deployment:</p>
<p>After creating the autoscaler, you can check it by running the following command:</p>
<pre class="source-code">
<strong class="bold">kubectl get hpa</strong></pre>
<p class="callout-heading">Tip</p>
<p class="callout"><strong class="bold">HPA</strong> stands for <strong class="bold">Horizontal Pod Autoscaler</strong>.</p>
<p>Try creating a CPU-intensive <a id="_idIndexMarker1328"/>operation within an application and checking automatic Pod creation during execution. The Kubernetes cluster will notice the significant amount of CPU usage and will scale out the cluster automatically by creating multiple Pods.</p>
<p>Once the intensive operation is<a id="_idTextAnchor1256"/> finished, Ku<a id="_idTextAnchor1257"/>bernetes will scale the number of Pods down to the minimum.</p>
<h2 id="_idParaDest-391"><a id="_idTextAnchor1258"/>Scaling nodes</h2>
<p>Alongside scaling<a id="_idIndexMarker1329"/> Pods, Kubernetes can also scale the number of nodes that run within the Kubernetes cluster. The number of nodes can be scaled using the following commands:</p>
<ol>
<li value="1">First, get the information pertaining to the current environment by requesting the number of nodes:<p class="source-code"><strong class="bold">az aks show --resource-group mpn-rg-kubernetes --name mykubernetescluster --query agentPoolProfiles</strong></p></li>
<li>Then, use this command to update <strong class="source-inline">nodepool</strong>. Extract the name of <strong class="source-inline">nodepool</strong> from the result of the last command:<p class="source-code"><strong class="bold">az aks scale --resource-group mpn-rg-kubernetes --name<a id="_idTextAnchor1259"/> mykubernetescluster --node-count 2 --nodepool-name nodepool1</strong></p></li>
</ol>
<p>Scaling the number of nodes up can increase the performance drastically. This will also make the cluster more expensive. By scaling the number of cluster nodes down, costs can decrease, and you are<a id="_idTextAnchor1260"/> only using the resources that are actually required by your applicati<a id="_idTextAnchor1261"/>on. To keep track of this, the nodes can also be autoscaled.</p>
<h2 id="_idParaDest-392"><a id="_idTextAnchor1262"/>Autoscaling nodes</h2>
<p>Alongside the manual <a id="_idIndexMarker1330"/>scaling of nodes, nodes can also scale automatically by updating the Kubernetes cluster. This can be done by using the <strong class="source-inline">az aks update</strong> command. With this command, you can set the minimum and maximum node counts. The autoscaler will then make sure that nodes are created when needed:</p>
<pre class="source-code">
<strong class="bold">az aks update --resource-group mmpn-rg-kubernetes --name mykubernetescluster  --update-cluster-autoscaler --min-count 1 --max-count 5</strong></pre>
<p>AKS also has the option to scale out with ACI. To use this option, a specific configuration needs to be applied when creating the AKS cluster. This is mainly required because ACI needs a specific subnet within the virtual network.</p>
<p>In this section, we<a id="_idIndexMarker1331"/> learned to scale containers and the cluster to drastically increase performance. Ne<a id="_idTextAnchor1263"/>xt up is dep<a id="_idTextAnchor1264"/>loyment from Azure DevOps to facilitate continuous deployment.</p>
<h1 id="_idParaDest-393"><a id="_idTextAnchor1265"/>Deploying to Kubernetes with Azure DevOps</h1>
<p>We have seen <a id="_idIndexMarker1332"/>a lot of options for deploying and configuring<a id="_idIndexMarker1333"/> the Kubernetes cluster via the command line. When working with DevOps, however, changes need to be applied in a continuous way.</p>
<p>For this, there is the Kubernetes manifest task within Azure DevOps, which contains a lot of functionalities to manage a Kubernetes cluster:</p>
<pre class="source-code">
task: KubernetesManifest@0 
  inputs:
  action: 'deploy'
  kubernetesServiceConnection: '[service connection name]' 
  manifests: '[path to your deployment file]'
  containers: 'msftazuredevops.azurecr.io/azuredevops:$(Build.BuildID)'</pre>
<p>In the preceding example, the following is configured:</p>
<ul>
<li><strong class="source-inline">action</strong>: The kind of action we want to perform. In this example, the <strong class="source-inline">deploy</strong> action is used because we want to deploy/apply a deployment file.</li>
<li><strong class="source-inline">kubernetesServiceConnection</strong>: The service connection to the Kubernetes cluster.</li>
<li><strong class="source-inline">manifests</strong>: The path to the manifest file. As we are using the deploy action, this should be a reference to the deployment file.</li>
<li><strong class="source-inline">containers</strong>: A special field where you can override the version of the container being deployed. By specifying the preceding, every image is specified in the deployment manifest with the <strong class="source-inline">msftazuredevops.azurecr.io</strong> reference, and the <strong class="source-inline">azuredevops</strong> repository is replaced by the new value as configured in this field.</li>
</ul>
<p>Using a<a id="_idIndexMarker1334"/> Kubernetes destination environment<a id="_idIndexMarker1335"/> within Azure DevOps pipelines also has the advantage of seeing the environment running within Azure DevOps. This will show the number of running Pods within the cluster.</p>
<p>Try it out with the following stage configuration for a build that will publish the deployment files to the artifact location of Azure DevOps:</p>
<pre class="source-code">
stages:
  - stage : Build 
    displayName : Build 
    jobs:
    - job:
      pool:
        vmImage: 'ubuntu-latest' 
      continueOnError: false 
      steps:
      - task: Docker@2 
      inputs:
        containerRegistry: '[Container Registry service connection]' 
        repository: 'azuredevops'
        command: 'buildAndPush' 
        Dockerfile: '**/Dockerfile'
        buildContext: '$(System.DefaultWorkingDirectory)/[folder path for docker]'
    - task: CopyFiles@2 
      inputs:
        SourceFolder: '$(system.defaultworkingdirectory)/[path to the deployment manifest files]'
        Contents: '*'
        TargetFolder: '$(build.artifactstagingdirectory)' flattenFolders: true
    - task: PublishBuildArtifacts@1 
      inputs:
        PathtoPublish: '$(Build.ArtifactStagingDirectory)' <a id="_idTextAnchor1266"/>
        ArtifactName: 'drop'
        publishLocation: 'Container'</pre>
<p>Next to the <a id="_idIndexMarker1336"/>build stage, add the following release<a id="_idIndexMarker1337"/> stage. Following the initial execution of the pipeline, a new environment will be available within Azure DevOps. In the environment created by the release, attach the Kubernetes cluster to see information on the running Pods:</p>
<pre class="source-code">
- stage : Release 
  displayName : Release 
  jobs:
  - deployment: KubernetesDeploy 
    displayName: Deploy Kubernetes 
    pool:
      vmImage: 'ubuntu-latest' 
    environment: 'Kubernetes' 
    strategy:
      runOnce: 
        deploy:
          steps:
          - task: DownloadPipelineArtifact@2 
            displayName: 'Download pipeline artifacts' 
            inputs:
              buildType: 'current'
              targetPath: '$(Pipeline.Workspace)'
          - task: KubernetesManifest@0 
            inputs:
              action: 'deploy'
              kubernetesServiceConnection: '[Kubernetes service connection]'
              manifests: '$(Pipeline.Workspace)[deployment manifest]' 
              containers: '[container registry]:$(Build.BuildID)</pre>
<p>In the<a id="_idIndexMarker1338"/> example, two stages are specified for a<a id="_idIndexMarker1339"/> multi-stage pipeline. The first stage will build the container image via the Docker task and publish it to a container registry. After publishing the image, it also publishes<a id="_idTextAnchor1267"/> a number of build artifacts – in this case, the Kubernetes manifests.</p>
<p>The second stage deploys to a specific environment called Kubernetes. This environment will also be created in Azure DevOps if it has not already been added. During the remainder of the process<a id="_idTextAnchor1268"/>, it retrieves the published artifacts of the build stage and<a id="_idTextAnchor1269"/> uses the Kubernetes manifest task to deploy the Kubernetes resources.</p>
<h1 id="_idParaDest-394"><a id="_idTextAnchor1270"/>Summary</h1>
<p>In this chapter, you have learned what containers are and how they relate to DevOps. Where DevOps is more of a cultural thing, containers are a way to support it technically. You have also learned how to create container images via a Dockerfile, specifically by using a multi-stage build file. Finally, we dived into Kubernetes, where we learned a way to host containers and also manage the running containers by using the <strong class="source-inline">kubectl</strong> command.</p>
<p>Using the knowledge acquired in this chapter, you are now able to deploy applications to Kubernetes and make sure that it scales with the number of requests it receives.</p>
<p>In the next chapter, you will learn more about facilitating the DevOps process by using Azure DevOps. You will learn what works for your organization and team and what doesn’t, and<a id="_idTextAnchor1271"/> how to implement that structure and your approach using Azure DevOps.</p>
<h1 id="_idParaDest-395"><a id="_idTextAnchor1272"/>Questions</h1>
<p>As we conclude, here is a list of questions for you to test your knowledge regarding the material covered in this chapter. You will find the answers in the <em class="italic">Assessments</em> section of the <em class="italic">Appendix</em> chapter: </p>
<ol>
<li value="1">What are the benefits of containers for DevOps?</li>
<li>A specific container can be hosted on different platforms (Azure/<strong class="bold">Amazon web Services</strong> (<strong class="bold">AWS</strong>)/<strong class="bold">Google Cloud platform</strong> (<strong class="bold">GCP</strong>)) – true or false?</li>
<li>Is it possible to add container support to an existing application?</li>
<li>What is the RUN command used for within a Dockerfil<a id="_idTextAnchor1273"/><a id="_idTextAnchor1274"/>e?</li>
<li>Kubernetes can be scaled on different components. What are they?</li>
</ol>
<h1 id="_idParaDest-396"><a id="_idTextAnchor1275"/>Exercises</h1>
<ul>
<li>Let’s create and publish an image of our application into Azure Container Registry and deploy it on an Azure Kubernetes cluster.  </li>
<li>The following Azure resources need to be configured for this lab:<ul><li>ACR</li><li>AKS</li></ul></li>
<li>Set up the environment – create AKS and ACR:<p class="source-code">az aks create  --resource-group az400-dev --name  packtsbookaci --generate-ssh-keys --location eastus </p><p class="source-code">az acr create --resource-group  az400-dev  --name packtbookacr --sku Standard --location eastus </p></li>
<li>Configure ACR integration with an existing AKS cluster:<p class="source-code">az aks update -n <strong class="bold">'packtsbookaci' </strong>-g <strong class="bold">'az400-dev'</strong> --attach-acr <strong class="bold">'packtbookacr'</strong></p></li>
<li>Refer to <strong class="source-inline">azurecontainercluster-pipelines.yml</strong> in the repository or create a new YAML file with the following contents:<p class="source-code">trigger:</p><p class="source-code">- main</p><p class="source-code">pool:</p><p class="source-code">  vmImage: ubuntu-latest</p><p class="source-code">variables:</p><p class="source-code">  buildConfiguration: 'Release'</p><p class="source-code">steps:</p><p class="source-code">- script: echo Hello, world!</p><p class="source-code">  displayName: 'Run a one-line script'</p><p class="source-code"># Authenticate nuget.exe, dotnet, and MSBuild with Azure Artifacts and optionally other repositories</p><p class="source-code">- task: NuGetAuthenticate@1</p><p class="source-code">  #inputs:</p><p class="source-code">    #nuGetServiceConnections: MyOtherOrganizationFeed, MyExternalPackageRepository # Optional</p><p class="source-code">    #forceReinstallCredentialProvider: false # Optional</p><p class="source-code">    </p><p class="source-code">- task: DotNetCoreCLI@2 </p><p class="source-code">  displayName: Restore</p><p class="source-code">  inputs:</p><p class="source-code">    command: restore</p><p class="source-code">    projects: '**/*.csproj'</p><p class="source-code">    feedsToUse: config</p><p class="source-code">    nugetConfigPath: $(Build.SourcesDirectory)/nugget.config</p><p class="source-code">- task: DotNetCoreCLI@2 </p><p class="source-code">  displayName: Build</p><p class="source-code">  inputs:</p><p class="source-code">    command: build</p><p class="source-code">    projects: '**/*.csproj'</p><p class="source-code">    arguments: '--configuration $(buildConfiguration)' # Update this to match your need</p><p class="source-code">- task: Docker@2</p><p class="source-code">  displayName: Build an image to container registry</p><p class="source-code">  inputs:</p><p class="source-code">    command: build</p><p class="source-code">    repository: 'SampleStarter'</p><p class="source-code">    dockerfile: '**/Dockerfile'</p><p class="source-code">    containerRegistry: 'packtbookacr'</p><p class="source-code">    tags: $(Build.BuildId)</p><p class="source-code">    arguments: '--build-arg FEED_ACCESSTOKEN=$(VSS_NUGET_ACCESSTOKEN)'</p><p class="source-code">- task: Docker@2</p><p class="source-code">  displayName: Build and push an image to container registry</p><p class="source-code">  inputs:</p><p class="source-code">    command: push</p><p class="source-code">    repository: 'SampleStarter'</p><p class="source-code">    dockerfile: '**/Dockerfile'</p><p class="source-code">    containerRegistry: 'packtbookacr'</p><p class="source-code">    tags: $(Build.BuildId)</p></li>
<li>Note that the containerRegistry name is <strong class="source-inline">packtbookacr</strong>, which is the same as when you created AKS and ACR. The containerRegistry name <strong class="source-inline">packtbookacr</strong> must be globally unique, so you won’t be able to use the same name.</li>
<li>Update <strong class="source-inline">dockerfile</strong> with the following contents:</li>
</ul>
<p class="callout-heading">Important Note </p>
<p class="callout">The endpoint is masked with <strong class="source-inline">***</strong> in the following example. Please use an appropriate and valid endpoint for your NuGet feed.</p>
<p class="source-code">#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.</p>
<p class="source-code">FROM mcr.microsoft.com/dotnet/aspnet:6.0 AS base</p>
<p class="source-code">WORKDIR /app</p>
<p class="source-code">EXPOSE 80</p>
<p class="source-code">EXPOSE 443</p>
<p class="source-code">FROM mcr.microsoft.com/dotnet/sdk:6.0 AS build</p>
<p class="source-code">WORKDIR /src</p>
<p class="source-code">RUN curl -L https://raw.githubusercontent.com/Microsoft/artifacts-credprovider/master/helpers/installcredprovider.sh  | sh</p>
<p class="source-code">COPY ["packtbookslibrary-api.csproj", "."]</p>
<p class="source-code">COPY ./nuget.config .</p>
<p class="source-code">ARG FEED_ACCESSTOKEN</p>
<p class="source-code">ENV VSS_NUGET_EXTERNAL_FEED_ENDPOINTS="{\"endpointCredentials\": [{\"endpoint\":\"https://pkgs.dev.azure.com/*****/PacktBookLibrary/_packaging/PacktBooksLibraryFeed/nuget/v3/index.json\", \"password\":\"${FEED_ACCESSTOKEN}\"}]}"</p>
<p class="source-code">RUN dotnet restore "./packtbookslibrary-api.csproj" --interactive</p>
<p class="source-code">COPY . .</p>
<p class="source-code">WORKDIR "/src/."</p>
<p class="source-code">RUN dotnet build "packtbookslibrary-api.csproj" -c Release -o /app/build</p>
<p class="source-code">FROM build AS publish</p>
<p class="source-code">RUN dotnet publish "packtbookslibrary-api.csproj" -c Release -o /app/publish</p>
<p class="source-code">FROM base AS final</p>
<p class="source-code">WORKDIR /app</p>
<p class="source-code">COPY --from=publish /app/publish .</p>
<p class="source-code">ENTRYPOINT ["dotnet", "packtbookslibrary-api.dll"]</p>
<ul>
<li>We use <strong class="bold">Azure Artifact Credential Provider</strong> here to automate the acquisition of the credentials required to restore NuGet packages.</li>
</ul>
<ul>
<li>After successfully executing the <strong class="source-inline">azurecontainercluster-pipelines.yml</strong> file through the Azure DevOps build pipeline, you will notice that an image with tags is created in ACR:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer206">
<img alt="Figure 16.17 – An ACR list " height="593" src="image/B18655_16_17.jpg" width="1628"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.17 – An ACR list</p>
<ul>
<li>You may need to establish and authorize an Azure DevOps Service connection with ACR, as created in the preceding paragraph, to successfully execute a build pipeline:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer207">
<img alt="Figure 16.18 – Establishing an ACR service connection " height="668" src="image/B18655_16_18.jpg" width="541"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.18 – Establishing an ACR service connection</p>
<h1 id="_idParaDest-397"><a id="_idTextAnchor1276"/>Further reading</h1>
<ul>
<li>Information on installing the Azure CLI: <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">https://docs.microsoft.com/en-us/cli/azure/install-azure-cli</a>.</li>
<li>Information on installing Docker Desktop: <a href="https://docs.docker.com/desktop/windows/install/">https://docs.docker.com/desktop/windows/install/</a>.</li>
<li>More information on Kubernetes: <a href="https://kubernetes.io/docs/home/">https://kubernetes.io/docs/home/</a></li>
<li>You can find more information regarding Azure Kubernetes at the following link: <a href="https://azure.microsoft.com/en-us/topic/what-is-kubernetes/">https://azure.microsoft.com/en-us/topic/what-is-kubernetes/</a>.</li>
<li>Information on ACR: <a href="https://docs.microsoft.com/en-in/azure/container-registry/container-registry-get-started-portal">https://docs.microsoft.com/en-in/azure/container-registry/container-registry-get-started-portal</a>.</li>
<li>More information regarding multi-stage builds: <a href="https://docs.docker.com/develop/develop-images/multistage-build/">https://docs.docker.com/develop/develop-images/multistage-build/</a>.</li>
</ul>
</div>
</div></body></html>