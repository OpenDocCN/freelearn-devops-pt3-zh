<html><head></head><body>
		<div id="_idContainer131">
			<h1 id="_idParaDest-134" class="hapter-number"><a id="_idTextAnchor189"/>10</h1>
			<h1 id="_idParaDest-135"><a id="_idTextAnchor190"/>Common DevOps Use Cases in Some of the Biggest Companies in the World</h1>
			<p class="author-quote">I take great satisfaction in seeing people and organizations achieve goals they might have originally believed to be beyond their reach.</p>
			<p class="author-quote">– Don W. Wilson</p>
			<p>Throughout this book, I have asked you to have a lot of faith in me and the things that I write. I have asked you to have an even greater amount of faith in the process of <strong class="bold">DevOps</strong> and the <a id="_idIndexMarker319"/>fruits that it will eventually yield. With the start of this new section, I suppose it is time for me to put my money where my mouth is and show you a few things under <span class="No-Break">the hood.</span></p>
			<p>All of this chapter is based on public information either provided by the company that implemented the use case or the company that consulted on it. They can be found publicly in each of the major cloud companies’ customer success story pages. This business information has been willingly put out there in order to serve as an example of how other businesses and people in the industry can make their own <span class="No-Break">workloads better.</span></p>
			<p>I’m going to use these use cases as an example of what you can do with DevOps and how you can support their use using Python. I didn’t want to use hypotheticals for this part because that would have been disingenuous. However, the way I have used these cases is meant to represent how they can be replicated using Python as opposed to whether they have used Python or not. They may have, but that’s <span class="No-Break">not pertinent.</span></p>
			<p>The primary motivation behind this chapter is to show you that there are real places where the philosophies of DevOps have been used in order to create genuine value for customers. This is a justification of the skills that you have been learning during your DevOps journey and during the course of <span class="No-Break">this book.</span></p>
			<p>So, without further ado, in this chapter, you will learn about <span class="No-Break">the following:</span></p>
			<ul>
				<li>An <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) use case<a id="_idIndexMarker320"/> that helped bridge the divide between business analysts and <span class="No-Break">data engineers</span></li>
				<li>An Azure use case that saved a lot of coding time and helped make deployments <span class="No-Break">more efficient</span></li>
				<li>Two <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) use cases<a id="_idIndexMarker321"/> involving sports leagues finding solutions that made their league <span class="No-Break">more accessible</span></li>
			</ul>
			<h1 id="_idParaDest-136"><a id="_idTextAnchor191"/>AWS use case – Samsung electronics</h1>
			<p>Samsung uses cloud and<a id="_idIndexMarker322"/> DevOps principles for a lot of stuff. That’s pretty obvious since Samsung is massive. It is why I haven’t given them a proper introduction, because, well, you know what Samsung is. The particular case that we will be talking about is an interesting one: one that involves getting the layman business analyst involved<a id="_idIndexMarker323"/> in <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) while also allowing the people who know how to write ML algorithms and applications in code to have their abilities maximized. It is a two-pronged approach playing to the abilities of both, enhancing the feedback from both of them and increasing collaboration between them. The following figure shows Samsung’s original workflow for <span class="No-Break">data analytics:</span></p>
			<div>
				<div id="_idContainer123" class="IMG---Figure">
					<img src="image/B21320_10_1.jpg" alt="Figure 10.1 – Samsung’s original workflow for data analytics"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – Samsung’s original workflow for data analytics</p>
			<p>So, let’s <a id="_idIndexMarker324"/>break down the scenario that Samsung was confronted with and the methods that they used to <span class="No-Break">resolve it.</span></p>
			<h2 id="_idParaDest-137"><a id="_idTextAnchor192"/>Scenario</h2>
			<p>Samsung’s<a id="_idIndexMarker325"/> analytical team consisted of two different sections: business analysts and data scientists. The business analysts looked at the problem and data provided by Samsung’s consumer electronics from the perspective of people who could understand human behavior and how it could be used to improve products and predict <span class="No-Break">customer behavior.</span></p>
			<p>To do this, they required data, lots of data, and the ability to process it. This is where the data scientists came in; they turned the hunches that the analysts had into cases that could be solved to provide concrete data. They created data analytics and ML algorithms to provide insights that the business analysts would use to provide recommendations and advice on how to continue with their products. They would also provide feedback to the data <span class="No-Break">science team.</span></p>
			<p>However, this partnership was not as smooth as one would believe; there was a gap between the two teams because of a number of factors, the primary factor being that there was a disparity between how the two teams did their jobs despite being dependent on <span class="No-Break">each other.</span></p>
			<p>In addition to that, data scientists had to do repetitive tasks on different datasets in order to ensure that the correct output was being given back to the business analysts. This resulted in the data scientists not having the time to experiment with other ML algorithms and various techniques that they might have wanted to implement. It also resulted in the business analysts having significantly less control over the data that they were responsible for, meaning that they didn’t have the full picture to make an <span class="No-Break">effective analysis.</span></p>
			<p>The need<a id="_idIndexMarker326"/> became to find a way to coordinate the data and the algorithms in such a way that the more common algorithms could be used by the business analysts while being tweaked by the data scientists at the same time. This would create an environment where the data scientists did not have to wait on the business analysts and vice versa, freeing up time and resources <span class="No-Break">for both.</span></p>
			<h2 id="_idParaDest-138"><a id="_idTextAnchor193"/>Brainstorming</h2>
			<p>Now, you<a id="_idIndexMarker327"/> may ask, if you are unfamiliar with the process, in the modern world, what is a business analyst doing if they don’t know how to write code? Well, that’s a lot more common than you think. An analyst’s job is not to write code or parse through data (though this can often be something they do); their job is to analyze the information put in front of them and use that to provide some sort of recommendation, insight, <span class="No-Break">or solution.</span></p>
			<p>The crux of the problem here is the fact that there is a gap in communication and understanding between the two teams concerned that is quite difficult to bridge without major personnel upheaval. And that kind of upheaval is usually not in the best interests of <span class="No-Break">the company.</span></p>
			<p>You need to make it so that one team is not dependent upon the other and can operate on the information that they receive as opposed to the people that they receive it from (loosely coupled, remember?). So, an ideal solution would be to find a way to allow both teams to work on the same data at the same time without hindering each other through unnecessary communication, and that is exactly the solution that <span class="No-Break">they found.</span></p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor194"/>Solution</h2>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/B21320_10_2.jpg" alt="Figure 10.2 – Samsung’s new workflow for data analytics"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2 – Samsung’s new workflow for data analytics</p>
			<p>The <a id="_idIndexMarker328"/>solution was essentially this: there would be a single source of data that both the analysts and the data scientists could work from; the data scientists would give the analysts access to a user interface from which they could perform the data operations that they wanted. The scientists would then tweak those operations and algorithms, trying to get better results without the analysts having to contact them to get results on the version of the algorithm that was currently running. This was essentially like creating an application for internal use for data analysts that was built by the <span class="No-Break">data scientists.</span></p>
			<p>Different skills and mindsets exist for a reason, and this is why there needs to be different people with varied roles and perspectives on a team. The only thing to do in such a scenario is to ensure that all of these roles are put in a position to succeed. By giving both these roles a platform and a workflow in which they would be comfortable, a reasonable way was found for the whole team to work optimally. Samsung did this by making the data centralized, with both teams having access to it and with neither team needing to be dependent on the other to make forward progress, and yet at the same time finding a <a id="_idIndexMarker329"/>way in which they could complement and support <span class="No-Break">each other.</span></p>
			<p>Next, we will look at a use case where the company had to deal with managing people who have similar skill sets with varying levels of experience, while also juggling business needs <span class="No-Break">and productivity.</span></p>
			<h1 id="_idParaDest-140"><a id="_idTextAnchor195"/>Azure Use Case – Intertech</h1>
			<p>While searching through<a id="_idIndexMarker330"/> use cases and scenarios, I absolutely fell in love with what Intertech did through the power of DevOps transformation. The fact that it used Azure is not as relevant as what it did with Azure and how it used the Azure and GitHub services to modernize and revolutionize its pipelines. This use case is all that DevOps is supposed to bring to a company in terms of value. It also addresses something that will become very relevant in the later parts of this book (where we are now): generative AI. Let’s take a look at the old <span class="No-Break">Intertech workflow:</span></p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/B21320_10_3.jpg" alt="Figure 10.3 – Old Intertech workflow"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3 – Old Intertech workflow</p>
			<p>This figure represents a sort of sunk cost fallacy, one that can lead to a severe loss of productivity. It represents how Intertech operated suboptimally and wasted much of their critical personnel in tasks that should have not been their concern in the first place. So, let’s look at how Intertech approaches <span class="No-Break">this problem.</span></p>
			<p>Let’s start with who <a id="_idIndexMarker331"/>Intertech are. They are an IT operations company that supports some of the largest business clients in Turkey with their infrastructure and operational needs. Now, you can imagine that this kind of operation would be pretty difficult to manage on a lot of levels. The pains are not very big; in fact, they are tiny cuts and pinpricks, but those are often the most annoying kinds of pain. They are irritating and distracting, and if you let them, they will steal your attention. In this section, we will talk about mental and physical anguish and how the fine people at Intertech worked to <span class="No-Break">reduce it.</span></p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor196"/>Scenario</h2>
			<p>Intertech<a id="_idIndexMarker332"/> worked in creating and maintaining solutions for some of the biggest companies in Turkey. Make a mental note of those two words: creating and maintaining. Those are two of the fundamental parts of developing any software solution, but they are very different from each other. To create something is to give it life; you’re giving birth, it’s painful, and it’s long, but it’s wonderful. Maintaining something is changing the diapers on the thing you gave birth to. It’s disgusting, but you are responsible for it and the toddler isn’t just going to take care of itself, no matter how prepared or independent it may be (and most toddlers are not). Keep this analogy in mind as it’ll follow us throughout the subsections. Years down the line, if I’m changing the diapers on this book to write a second edition, I will keep this in mind <span class="No-Break">as well.</span></p>
			<p>So, this was the difficulty facing Intertech: the balance of developing new projects while maintaining old ones. And the tasks to maintain the old ones were mundane, but they required man-hours, manpower, and a lot of power hours that could’ve been spent coming up with new ways to deliver value. The cycle of thought that runs between the initial problem and finally finding its solution requires precious time and intellectual effort that is usually significantly less than the capacity of the person solving it. Basically, it forces intelligent people to do <span class="No-Break">dumb tasks.</span></p>
			<p>So, when thinking about the solution to this, what should be the first thing we think of? Perhaps there is a way in which solutions can be found without having to think about and research them too much. Not, of course, for critical, vital tasks that require actual focus but for mundane tasks that require several Googles of a bunch of terms to get to the appropriate Stack Overflow page and then copying and pasting that into a solution and running it a couple of times to make sure it works. Maybe there’s a tool that will collate all of this information and generate a simple concise solution for a simple mundane problem and save us all some time. Perhaps one that rhymes with <em class="itali">hartificial fintelligence</em>? Alright, nothing rhymes with artificial intelligence. AI, that’s what I’m <span class="No-Break">talking about.</span></p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor197"/>Brainstorming</h2>
			<p>Well, by now, you <a id="_idIndexMarker333"/>probably know where this is heading, so let me share my personal experience on how I usually use generative AI in my daily life. It is a useful tool, as most of you who read this book will attest to unless you are staunchly against AI or have all the information in the world stored in your head. If you have the latter, contact me and tell me what actually happened with <em class="itali">The </em><span class="No-Break"><em class="itali">Sopranos</em></span><span class="No-Break"> ending.</span></p>
			<p>I use generative AI to lay down the steps towards a solution and frame it in a way that I can understand and modify according to the context I may have given, or ones which it hasn’t been trained on yet. This is so much easier than having to look at a tutorial whenever I have to find a way to fix something, and then when that tutorial is incomplete, having to find another one. With generative AIs such as ChatGPT, the tables are turned; it is my prerogative now to be impatient and that of the generative AI to be persistent and patient with my requests. This is amazing because, honestly, thinking is exhausting, especially if you have to think about the same thing over and over again. It makes your mind go numb, and it reduces your productivity. The people of Intertech came to the <span class="No-Break">same conclusion.</span></p>
			<p>If you want to follow along<a id="_idIndexMarker334"/> with the child analogy, this is like having a magical force that will change the diaper and wrap it around the child just waiting for you to put the pin on it. So, in that vein, if there is a repetitive task that comes in and is simple enough, it can hamper productivity through all of these ways. In such cases, it is generative AI that can come to the rescue. Any of you who have ever used it know how useful ChatGPT is at this. In fact, in my personal experience, the most useful thing that ChatGPT does for me is explaining lines of code that I paste into it. It would take me more than the several seconds that it takes ChatGPT to do it because I simply cannot collect the information as fast as the AI can. So, now that we have justified our generative AI solution, let’s see how Intertech – who came to a similar conclusion – used these concepts and integrated them into their DevOps and Azure workloads <span class="No-Break">and tasks.</span></p>
			<h2 id="_idParaDest-143"><a id="_idTextAnchor198"/>Solution</h2>
			<p>The <a id="_idIndexMarker335"/>solution that was created by Intertech revolved around the use of GitHub Copilot and Azure’s OpenAI integration. Copilot, once trained on the code for a particular repository that was in need of maintenance, could simply write the required scripts if given the correct prompts. Intertech integrated Copilot into <a id="_idIndexMarker336"/>the <strong class="bold">integrated development environments</strong> (<strong class="bold">IDEs</strong>) used by their developers so that once they wrote a line or two, Copilot simply inferred what their intentions were and wrote much of the rest. The developers simply had to verify a couple of tests and voilà, an efficient code delivery <a id="_idIndexMarker337"/>system, one that frees up time and thinking power. The following figure demonstrates <span class="No-Break">the solution:</span></p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/B21320_10_4.jpg" alt="Figure 10.4 – New Intertech workflow with generative AI"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.4 – New Intertech workflow with generative AI</p>
			<p>The solution in the diagram can be broken down into the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>When a junior developer performs maintenance on a legacy system, they use an instance of Copilot which has been trained on the system’s <span class="No-Break">code base.</span></li>
				<li>This allows them to query and find the answers about the code base that they are looking for in a <span class="No-Break">human-readable form.</span></li>
				<li>Copilot also helps autocomplete their code in the style of the rest of the code base, <span class="No-Break">maintaining consistency.</span></li>
				<li>The senior developer is, for the most part, removed from this process, allowing them to work on newer projects <span class="No-Break">and systems.</span></li>
			</ol>
			<p>Since most of the maintenance operations were being done on the time of the senior developers as they had worked on the older projects, these developers (whose time is more precious because of their depth of experience) were the ones who needed to get hands-on with a lot of the issues to solve them. Even when these issues were handed off to junior developers, they still asked the senior developers for a large amount of advice, which while not negative behavior at all, still hindered the senior developers to <span class="No-Break">an extent.</span></p>
			<p>To make the junior developers less reliant on seniors for advice on the code base, the company integrated Azure OpenAI chatbots into their IDEs. These chatbots could scrape and infer information from the code and the documentation for projects and answer questions about them to the satisfaction of the junior developers most of the time. This reduced the amount of time taken by senior personnel in maintaining the code and it guided the junior developers through the code base using their very own personalized babysitter, if you will. One incredible consequence of this was that the number of emails sent within the company was reduced by 50%, which is a remarkable number. Wouldn’t you like 50% fewer emails for the same if not greater amount of productivity? Not to mention all of the time that is freed up by not being in meetings and having to retread old stuff. This is the kind of value multiplier that can take companies to the <span class="No-Break">next level.</span></p>
			<p>Speaking of value, so far the<a id="_idIndexMarker338"/> value that we have seen has been values on fact sheets and computer code, but in our next section, we will see the value that DevOps can generate in a more physically tangible environment using sports as <span class="No-Break">an example.</span></p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor199"/>Google Cloud use case – MLB and AFL</h1>
			<p>If there is one thing that you should <a id="_idIndexMarker339"/>know about me, it is that I am a massive sports fan. I am, and I love learning about new sports just as much as following the old ones that I have followed <span class="No-Break">for years.</span></p>
			<p>I have been following <strong class="bold">Major League Baseball</strong> (<strong class="bold">MLB</strong>) for years, and in those years, baseball has always been the sport of<a id="_idIndexMarker340"/> analytics. Most modern teams in their team selection are driven by analytics and the performance of players is measured through statistical analysis of a number of metrics that are collected when they play their games. You may have seen the film <em class="itali">Moneyball</em> (or read the book by Michael Lewis), which chronicles the introduction of statistical methods in the choice of baseball players and how they led to the success of the Oakland Athletics baseball team in the late 90s and <span class="No-Break">early 2000s.</span></p>
			<p>In the MLB, one<a id="_idIndexMarker341"/> of the results of the introduction of analytical data is the analysis of the gameplay itself and the time taken to finish a game. In order to streamline the game, MLB introduced the pitch clock, giving players only 15 seconds to throw a pitch. The clock, as seen in the following figure, needs to synchronize throughout the arena and with the clock that is being broadcast over television as well. This synchronization presents a unique challenge for MLB to implement its <span class="No-Break">newest rule:</span></p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/B21320_10_5.jpg" alt="Figure 10.5 – Original MLB play clock system"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.5 – Original MLB play clock system</p>
			<p>I wanted to also look at some other sports leagues that may have used data analytics and Google Cloud in some way and integrated it into their league’s infrastructure (perhaps in a way that was different from MLB’s approach). In my search, I found the perfect example with<a id="_idIndexMarker342"/> the <strong class="bold">Australian Football League</strong> (<strong class="bold">AFL</strong>). The following diagram shows the AFL’s broadcast situation <span class="No-Break">for coaching:</span></p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/B21320_10_6.jpg" alt="Figure 10.6 – The AFL broadcast situation for coaching"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.6 – The AFL broadcast situation for coaching</p>
			<p>When I started this, I <a id="_idIndexMarker343"/>knew practically nothing about Australian rules football (also known as Aussie rules football) or the AFL other than the fact that the day of the Grand Final is a public holiday in Australia. However, one thing that I did figure out during my research was that both of these companies were using advanced analytics in order to find ways to improve the way that the play was seen and to analyze if there was a way to make the gameplay and the players <span class="No-Break">even better.</span></p>
			<p>Given my passion for sports and all the nerd stuff surrounding sports, this little section now seems inevitable to me. So, let’s dive in and see what DevOps and data insights we can find in these <span class="No-Break">use cases.</span></p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor200"/>Scenario</h2>
			<p>Let’s start <a id="_idIndexMarker344"/>with baseball; I love baseball. It is the sport of the stoic man; it is the sport where time stands still. If you ever have 23 hours to spare, do yourself a favor and watch Ken Burns’ <em class="itali">Baseball</em> documentary series; you will not regret it. But baseball as a whole and MLB in particular suffered from a few setbacks the past few years. There was a cheating scandal involving the Houston Astros and live attendance and viewership were down because of the excessive length of the games. To solve these problems while maintaining the integrity of the game, MLB turned to data. They turned to the analytics that the teams individually used and decided to turn it toward the league as a whole. They collected statistics related to gameplay, attendance, and viewer engagement from all of the available games throughout the season (2,430 games plus playoffs) and decided to create infrastructure solutions to bolster the solutions that they would implement. They used Google Cloud for this: both for the data analytics and the implementation of the <span class="No-Break">solution itself.</span></p>
			<p>Aussie rules football is the number one sport in Australia. In the land down under, it is the sport that has the greatest viewership and the biggest audience. It is also the most physical sport played in Australia and as someone who watches a lot of sports and does a lot of data science, the more physical a sport is in terms of physical contact between human beings, the more difficult it becomes to analyze that sport. Here, the data needs to be broken down on a more physical level, looking toward the human body itself. This approach allowed the AFL to develop a system that used ML with human coaching to develop systems of training for the underprivileged and differently able people who were still passionate about <span class="No-Break">the sport.</span></p>
			<p>Two very different problems were faced by these two sports leagues, both of which required completely different approaches, but both of which were solved in Google Cloud using the principles of DevOps. Let’s see how they <span class="No-Break">did it.</span></p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor201"/>Brainstorming</h2>
			<p>MLB<a id="_idIndexMarker345"/> problem was one that affected the game and people’s enjoyment of it. People hate it when you waste their time, and they hate slow games. Anyone who has ever watched the last two minutes of a close NBA playoff game knows. MLB approached this problem by looking at the time taken every inning and what were the longest aspects of those innings. They realized that pickoffs and the time taken by pitchers to wind up their pitch were slowing down the game. This led to the creation of the pitch clock, a timer for how long a pitcher can wait between pitches thrown. They had determined that this time between pitches was the main reason that the game had slowed down and they believed that the clock would rectify the situation. It was implemented using GCP and DevOps principles combining the GCP services with on-premises timing hardware. And as a fan, I am very grateful for it as well. We will discuss the full extent of the solution in the <span class="No-Break">next section.</span></p>
			<p>The problem with the AFL was one of youth outreach and the physical limitations that some people have when attempting to play the sport. Australia is also a massive country with a very widespread populace, meaning that people in rural areas who needed training in Aussie rules football would need to have their training and coaching administered remotely. The goal then became to reach as many people as possible and to do so with as much data as possible so that it would be accurate, and also to reach people who are impaired in some form of communication. This problem required an approach of communication between devices as well as the use of ML algorithms, particularly for use in tracking the ball used in the sport with respect to the player who is <span class="No-Break">being coached.</span></p>
			<p>So, looking at these problems, and the approaches we could potentially take to solve them, we can now start coming up with a couple of solutions that might help these organizations achieve their goals. Let’s see what exactly it was that they did to achieve <span class="No-Break">these goals.</span></p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor202"/>Solution</h2>
			<p>The <a id="_idIndexMarker346"/>solution to MLB’s problems involved using Google Cloud’s Anthos service mesh to coordinate all the pitch clocks together. Centralized yet distributed time clocks added to the integrity of the game and these <span class="No-Break">new rules.</span></p>
			<p>The <a id="_idIndexMarker347"/>problem with MLB was one of synchronization. The goal was to synchronize the play clocks that were running throughout the stadium, to coordinate their timing. Here, Google used their Anthos service mesh (as shown in the following diagram) as a sort of connector between a number of devices in the cloud and on-premises devices at baseball stadiums. This allowed the timer for pitchers to be visible and accurate everywhere with no delays, ensuring the fairness of the <span class="No-Break">new system.</span></p>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/B21320_10_7.jpg" alt="Figure 10.7 – Anthos synchronized game clock for MLB"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.7 – Anthos synchronized game clock for MLB</p>
			<p>The introduction of the play clock reduced the time of games for the average baseball game by 24 minutes. That is significant and I think it is the most significant application of the DevOps philosophy that I have seen in such a non-tech scenario. Let’s do the math here: 24 minutes was reduced from every game, which increased the average attendance of games from 26,843 to 29,295, which is a significant achievement. So, how much time was really saved? Well, that is 24 minutes x 29,295 people x 2,430 regular season games. That is 1,708,484,400 minutes in total saved, which is 28,474,740 hours, 1,186,447.5 days, or 3,250 years. That is quite the saving, and the fans have felt it too, which is why the attendance is up. All of this is because of the ability to coordinate loosely <span class="No-Break">coupled infrastructure.</span></p>
			<p>The<a id="_idIndexMarker348"/> approach to the AFL’s problem required the delivery of ML models that could perform motion tracking over networks that were not always reliable. This meant that any sort of ML model that was used would have to use the computing power on the side of the mobile device and be lightweight enough to not affect the functioning of that device. Google’s development team had helped facilitate a similar<a id="_idIndexMarker349"/> teaching solution with cricket in the <strong class="bold">Indian Premier League</strong> (<strong class="bold">IPL</strong>). So, the solution that they ended up with was an application called the Footy <span class="No-Break">Skills app.</span></p>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/B21320_10_8.jpg" alt="Figure 10.8 – Instruction broadcast system for AFL coaching"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.8 – Instruction broadcast system for AFL coaching</p>
			<p>The <a id="_idIndexMarker350"/>application used two ML models: one to detect an Aussie rules ball based on size, shape, and color, and another to determine its spatial depth and location. They also added features that would assist the hearing and visually impaired as well as wheelchair-using athletes who played <span class="No-Break">the sport.</span></p>
			<h1 id="_idParaDest-148">Summary<a id="_idTextAnchor203"/></h1>
			<p>This chapter was quite the journey. It was unique, even among some of the weird stuff I have written in this book. But I can honestly say that it was an enjoyable chapter to write simply because of all of the unique solutions that I got to research while I was <span class="No-Break">writing it.</span></p>
			<p>We started with the AWS solution and that was a great demonstration of what can happen when you put people in a position where their skills can be valued and used with other skills as opposed to clashing with them. It also showed us how DevOps solutions don’t just facilitate technologies, but the people behind those technologies <span class="No-Break">as well.</span></p>
			<p>In the Azure use case, we learned about how AI and ML mixed with DevOps can increase the productivity of a team that engages in creative endeavors. We saw how generative AI is being used to facilitate developers, reduce the amount of mundane and redundant work that key personnel have to do, and free up time and communication channels to make teams <span class="No-Break">more productive.</span></p>
			<p>In the first GCP use case, MLB needed a way to justify changing rules in baseball that had been around for over a century. They used solid data and hard facts to do this. These facts were provided through the collation of data from an entire season of baseball. They then used this and other loosely coupled coordination technology to implement their vision of changed rules. Through data and technological coordination, they achieved the creation of a rule that was profitable to them but also popular with the fans: a feat that is practically <span class="No-Break">unheard of.</span></p>
			<p>In the second GCP use case, the AFL extended its range of availability and inclusivity using ML models delivered with DevOps principles directly onto devices that were spread throughout Australia, giving people in even the most remote areas of Australia access to great coaching and instruction to help them improve in the sport. This gave the AFL an invaluable platform for growth and outreach amongst their fans and <span class="No-Break">future players.</span></p>
			<p>So, in conclusion, this DevOps stuff is pretty useful in real life. A lot of these solutions couldn’t have been done without Python either, especially the ones that involved ML and AI. And that is just the beginning of how high you can go with DevOps. In the next chapter, we will dive even deeper into the data science aspect of DevOps, Python with data, <span class="No-Break">and </span><span class="No-Break"><strong class="bold">MLOps</strong></span><span class="No-Break">.</span></p>
		</div>
	</body></html>