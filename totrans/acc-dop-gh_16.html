<html><head></head><body>
		<div id="_idContainer171">
			<h1 id="_idParaDest-284"><em class="italic"><a id="_idTextAnchor284"/>Chapter 13</em>: Shift-Left Security and DevSecOps</h1>
			<p>The total number of losses caused by cyber-crimes that have been reported to the <strong class="bold">Internet Crime Complaint Center</strong> (<strong class="bold">IC3</strong>) of the <strong class="bold">Federal Bureau of Investigation</strong> (<strong class="bold">FBI</strong>) has increased to an all-time high, from 3.5 billion <strong class="bold">United States dollars</strong> (<strong class="bold">USD</strong>) in 2019 to 4.1 billion USD in 2020 (<em class="italic">IC3</em>, 2019 and 2020). This continues the trend with a strong increase over the last years (<em class="italic">see Figure 13.1</em>): </p>
			<div>
				<div id="_idContainer160" class="IMG---Figure">
					<img src="image/B17827_13_001.jpg" alt="Figure 13.1 – Total losses caused by cyber-crimes reported to IC3&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.1 – Total losses caused by cyber-crimes reported to IC3</p>
			<p>Among the affected companies are start-ups, as well as <em class="italic">Fortune 500</em> enterprises. Affected are tech giants such as Facebook, Twitter, T-Mobile, and Microsoft, as well as public institutions such as San Francisco International Airport or security companies such as FireEye. No company can claim that cyber-crimes are not a threat to them!</p>
			<p>In this chapter, we take a broader look at the role of security in development and how you can bake it into your process and enable a zero-trust culture.</p>
			<p>These are the key points that we will cover in this chapter:</p>
			<ul>
				<li>Shift-left security</li>
				<li>Assume-breach, zero-trust, and security-first mindset</li>
				<li>Attack simulations</li>
				<li>Red team-blue team exercises</li>
				<li>Attack scenarios</li>
				<li>GitHub Codespaces</li>
			</ul>
			<h1 id="_idParaDest-285"><a id="_idTextAnchor285"/>Shift-left security</h1>
			<p>In classical software<a id="_idIndexMarker856"/> development, security was handled downstream: when the software was ready to be released, a security department or external company would perform a security review. The problem with this approach is that it's hard to fix architectural problems at that point. In general, the later you fix a security vulnerability, the more expensive it gets; and if you don't fix vulnerabilities, the costs can be many millions, which can lead to bankruptcy for some companies. The earlier you fix a security vulnerability in the development life cycle, the cheaper it is (<em class="italic">see Figure 13.2</em>): </p>
			<div>
				<div id="_idContainer161" class="IMG---Figure">
					<img src="image/B17827_13_002.jpg" alt="Figure 13.2 – Costs for fixing security vulnerabilities in the development life cycle&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.2 – Costs for fixing security vulnerabilities in the development life cycle</p>
			<p>That's what we call <strong class="bold">shift-left security</strong>: baking security into the development life cycle and making it an essential part of all activities. </p>
			<p>The problem is that there are not enough security specialists<a id="_idIndexMarker857"/> out there to put them in every engineering team. Shifting security left is about educating engineers and creating a security-first mindset.</p>
			<h1 id="_idParaDest-286"><a id="_idTextAnchor286"/>Assume-breach, zero-trust, and security-first mindset</h1>
			<p>The classical approach<a id="_idIndexMarker858"/> to security was to <strong class="bold">prevent breaches</strong>. The most important measures were these:</p>
			<ul>
				<li><strong class="bold">Layers of trust</strong>: The internal network was considered secure<a id="_idIndexMarker859"/> and protected with firewalls. Access to the network was only allowed by<a id="_idIndexMarker860"/> company-owned devices and <strong class="bold">virtual private network</strong> (<strong class="bold">VPN</strong>) tunnels. The public internet was<a id="_idIndexMarker861"/> not trusted—and in between were <strong class="bold">demilitarized zones</strong> (<strong class="bold">DMZs</strong>).</li>
				<li><strong class="bold">Risk analysis</strong>: Risk analysis with threat <a id="_idIndexMarker862"/>modeling.</li>
				<li><strong class="bold">Security reviews</strong>: Architecture and code reviews<a id="_idIndexMarker863"/> from security experts.</li>
				<li><strong class="bold">Security testing</strong>: External security testing<a id="_idIndexMarker864"/> with a specific scope.</li>
			</ul>
			<p>But with the prevent-breach approach, the question as to whether a company was already under attack could basically not be answered.</p>
			<p>In an interview in 2012, General Michael Hayden, former director of the <strong class="bold">National Security Agency</strong> (<strong class="bold">NSA</strong>) and the <strong class="bold">Central Intelligence Agency</strong> (<strong class="bold">CIA</strong>), said the following:</p>
			<p class="author-quote">"Fundamentally, if somebody wants to get in, they're getting in… accept that."</p>
			<p>This is the basis of the<a id="_idIndexMarker865"/> assume-breach paradigm: you are most probably already under attack, whether you know it or not. Always assume that you already have been breached. This way of thinking identifies gaps in the prevent-breach approach. How do you do the following?</p>
			<ul>
				<li><strong class="bold">Detect</strong> attacks and penetrations?</li>
				<li><strong class="bold">Respond</strong> to attacks?</li>
				<li><strong class="bold">Recover</strong> from data leakage or tampering?</li>
			</ul>
			<p>This shifts the measures for security and adds a completely new focus. With the assume-breach paradigm, you need<a id="_idIndexMarker866"/> the following:</p>
			<ul>
				<li>A central <strong class="bold">security monitoring</strong> or <strong class="bold">security information and event management</strong> (<strong class="bold">SIEM</strong>) system to<a id="_idIndexMarker867"/> detect <a id="_idIndexMarker868"/>anomalies.</li>
				<li>Ongoing live<a id="_idIndexMarker869"/> site testing of your <strong class="bold">incident response</strong> (<strong class="bold">IR</strong>) (<strong class="bold">fire drills</strong>).</li>
				<li>War games (<strong class="bold">red team-blue team simulations</strong>) to detect vulnerabilities, create awareness, learn<a id="_idIndexMarker870"/> to think like attackers, and train your responses.</li>
				<li><strong class="bold">Live site penetration tests</strong>: Sophisticated attack simulations<a id="_idIndexMarker871"/> including phishing, social engineering, and physical security.</li>
				<li>Don't trust identities<a id="_idIndexMarker872"/> and devices, even when in your network (<strong class="bold">zero trust</strong>).</li>
			</ul>
			<p>If your security is mainly based upon layers, once a hacker is inside your network—through phishing, social engineering, or a physical attack—it's child's play for them to advance. In a trusted network, you normally find unprotected<a id="_idIndexMarker873"/> file shares, unpatched servers without <strong class="bold">Secure Sockets Layer</strong> (<strong class="bold">SSL</strong>) protection, weak passwords, and <strong class="bold">single-factor authentication</strong> (<strong class="bold">SFA</strong>) in most systems. In a cloud-first<a id="_idIndexMarker874"/> world, this makes absolutely no sense.</p>
			<p>With zero-trust access to your services, you always<a id="_idIndexMarker875"/> verify the identity—for example, with <strong class="bold">multi-factor authentication</strong> (<strong class="bold">MFA</strong>), you verify the device, access, and services involved in transactions. <em class="italic">Figure 13.3</em> shows an example of how zero-trust access can be implemented for your services:</p>
			<div>
				<div id="_idContainer162" class="IMG---Figure">
					<img src="image/B17827_13_003.jpg" alt="Figure 13.3 – Zero-trust access to your company services&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.3 – Zero-trust access to your company services</p>
			<p>If you are using <strong class="bold">software-as-a-service</strong> (<strong class="bold">SaaS</strong>) cloud services in your company, you're probably familiar<a id="_idIndexMarker876"/> with zero trust. You must authenticate using MFA but can trust your browser and device for more comfort. If you travel, you get notified or must approve your login attempts from an unusual location. If you install third-party apps, you must grant the apps permissions to access information, and you're probably not allowed to access highly confidential information from a public, not-trusted device.</p>
			<p>Zero trust<a id="_idIndexMarker877"/> means applying the same principles to all your services, independently of whether you access them from within your internal network or not.</p>
			<h1 id="_idParaDest-287"><a id="_idTextAnchor287"/>Attack simulations</h1>
			<p>To know what to do in case<a id="_idIndexMarker878"/> of an incident, you should regularly perform<a id="_idIndexMarker879"/> drills to practice your <strong class="bold">standard operating procedures</strong> (<strong class="bold">SOPs</strong>) for IR and improve your response times. As with fire drills in your offices, if you do not practice these drills, you don't know if your security measures will really work in the event of a real fire.</p>
			<p>You should try to improve on the following metrics:</p>
			<ul>
				<li><strong class="bold">Mean Time To Detect</strong> (<strong class="bold">MTTD</strong>)</li>
				<li><strong class="bold">Mean Time To Recover</strong> (<strong class="bold">MTTR</strong>)</li>
			</ul>
			<p>In such a drill, you would simulate an attack scenario, practice your IR process, and conduct a <strong class="bold">post-mortem</strong> with the learnings of the drill.</p>
			<p>Here are some example attack scenarios:</p>
			<ul>
				<li>Service compromise</li>
				<li>Inside attacker</li>
				<li>Remote code execution</li>
				<li>Malware outbreak</li>
				<li>Customer data compromised</li>
				<li><strong class="bold">Denial of service</strong> (<strong class="bold">DoS</strong>) attack</li>
			</ul>
			<p>Practicing these drills will give<a id="_idIndexMarker880"/> you confidence that your SOPs work and let you react in case of a real incident quickly and efficiently.</p>
			<h1 id="_idParaDest-288"><a id="_idTextAnchor288"/>Red team-blue team exercises</h1>
			<p>A special form of these drills is <strong class="bold">red team-blue team</strong> exercises, also known as <strong class="bold">war games</strong>, whereby two teams with insider know-how play<a id="_idIndexMarker881"/> against each other. The red team<a id="_idIndexMarker882"/> is the attacker and tries to access a production system or capture user data, and the blue team defends against the attack. If the blue team detects the attack and can prevent it, the blue team wins. If the red team has proof that they could access production or capture data, the red team wins.</p>
			<h2 id="_idParaDest-289"><a id="_idTextAnchor289"/>Team constellation</h2>
			<p>The difference from a normal attack simulation<a id="_idIndexMarker883"/> is the insights the team has on your systems, so it's easier to find vulnerabilities. Red team-blue team simulations are the most sophisticated attacks with the most insights compared to all other efforts you can do to reduce your security risks (<em class="italic">see Figure 13.4</em>): </p>
			<div>
				<div id="_idContainer163" class="IMG---Figure">
					<img src="image/B17827_13_004.jpg" alt="Figure 13.4 – Risk reduction by insights of the attacker and depth of the attack&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.4 – Risk reduction by insights of the attacker and depth of the attack</p>
			<p>The teams should be mixed from different organizational units. Do not just pick one team for red and one team<a id="_idIndexMarker884"/> for blue. The composition of the team is the key to a successful game.</p>
			<p>For the red team, do the following:</p>
			<ul>
				<li>Use creative engineers from different teams that already have an interest in security.</li>
				<li>Add security experts with experience from within your organization, or get external support.</li>
			</ul>
			<p>For the blue team, do the following:</p>
			<ul>
				<li>Take ops-minded engineers that are familiar with logging, monitoring, and site reliability.</li>
				<li>Add engineers that have knowledge of your network security and identity.</li>
			</ul>
			<p>Both teams should have the possibility to ask experts<a id="_idIndexMarker885"/> for help. If, for example, the red team needs to write a <strong class="bold">Structured Query Language</strong> (<strong class="bold">SQL</strong>) statement to perform a sophisticated SQL injection attack, they can get help from the <strong class="bold">database administrator</strong> (<strong class="bold">DBA</strong>) team; or, when the blue team<a id="_idIndexMarker886"/> needs insider information on how an application works or it needs the application to log additional data, it can directly approach the team that builds and maintains the application.</p>
			<h2 id="_idParaDest-290"><a id="_idTextAnchor290"/>Rules of the game</h2>
			<p>The main goal of the game<a id="_idIndexMarker887"/> is the learning of all participants—learning to think like an attacker, learning to detect and respond to an incident, and learning which vulnerabilities exist in the company that can be exploited. The second goal is fun. As with a hackathon, the exercise should be a team-building event that is fun for all that participate.</p>
			<p>But to be successful without harming anyone, you need some ground rules for the game.</p>
			<h3>Duration</h3>
			<p>A red team-blue team exercise can last for days, weeks, or even months. Choose a period in which the attack can happen and the duration of the attack itself. A good starting point would be a 3-week period and a 3-day attack. Adjust the time to your needs.</p>
			<h3>Codex and rules</h3>
			<p>To make the exercise successful, you must establish some rules and a code of conduct that players must adhere to, as outlined here:</p>
			<ul>
				<li>Both teams may not cause real harm. This also means the red team should not do more than is necessary to achieve their goal, and physical attacks should follow common sense (do not harass or threaten anyone, don't steal keys or badges from your coworkers, and so on).</li>
				<li>Don't expose the names of persons compromised.</li>
				<li>Don't cause downtime for paying customers or breach their data!</li>
				<li>Compromised data must be stored encrypted and protected and not be exposed to real attackers.</li>
				<li>The security of the production system must not be weakened to expose customers to risk. If, for example, the red team could modify the source code to disable authentication for all production systems, then leave a comment in the code and claim victory when the deployment is done. However, you cannot disable authentication for the production system that real customers are using.</li>
			</ul>
			<p>This might seem all obvious, but if you have competitive<a id="_idIndexMarker888"/> teams, they might get carried away with the game. It's better to state the obvious and lay out some ground rules.</p>
			<h3>Delivery items</h3>
			<p>At the end of the game, the teams deliver<a id="_idIndexMarker889"/> the following items:</p>
			<ul>
				<li>A backlog with vulnerabilities that must be fixed. Critical vulnerabilities must be fixed right away.</li>
				<li>A backlog with items to improve the forensic and analytic capabilities.</li>
				<li>An open report for the entire organization about the learnings from the exercise.</li>
			</ul>
			<p>Remember to make this all blameless, and don't expose the names of people that have been compromised.</p>
			<h2 id="_idParaDest-291"><a id="_idTextAnchor291"/>Where to start</h2>
			<p>I know a lot of people think that red team-blue team exercises<a id="_idIndexMarker890"/> are only suited to companies with a very high maturity level, but I believe red team-blue team exercises are a great way for each company to create awareness and to learn and grow, especially when they're still preventing breaches and consider their intranet safe. If your maturity level is not so high, attacks are much easier. If the maturity is very high, attacks need to be much more sophisticated, and it is a lot harder to perform successful attacks without causing real harm.</p>
			<p>I would prefer red team-blue team exercises over normal attack simulations—they are more fun and a better way to learn. Get external help if you don't know where to start.</p>
			<p>If you have many findings in your first game and it was really easy for the red team to win, you might want to consider doing the exercises more often. If not, once a year is a good rhythm I see companies doing successfully, but it depends a lot on your situation.</p>
			<p>Just do your first exercise—the rest will follow automatically.</p>
			<h1 id="_idParaDest-292"><a id="_idTextAnchor292"/>Attack scenarios</h1>
			<p>The first attack scenarios<a id="_idIndexMarker891"/> most people think<a id="_idIndexMarker892"/> of in the context of DevOps and DevSecOps are code execution on production<a id="_idIndexMarker893"/> systems<a id="_idIndexMarker894"/> using vulnerabilities<a id="_idIndexMarker895"/> such as <strong class="bold">SQL injection</strong>, <strong class="bold">cross-site scripting</strong> (<strong class="bold">XSS</strong>), or <strong class="bold">memory leaks</strong> such as <strong class="bold">buffer overflows</strong>. In <a href="B17827_14_Epub.xhtml#_idTextAnchor296"><em class="italic">Chapter 14</em></a>, <em class="italic">Securing Your Code</em>, we'll have a closer look<a id="_idIndexMarker896"/> at how you can hunt for these kinds<a id="_idIndexMarker897"/> of vulnerabilities and how you can integrate this into your delivery pipeline.</p>
			<p>But there are far easier attack scenarios, such as the following:</p>
			<ul>
				<li><strong class="bold">Unprotected file shares</strong> and repositories</li>
				<li><strong class="bold">Secrets in text files</strong>, config files, and source code (such as test accounts, <strong class="bold">personal access tokens</strong> (<strong class="bold">PATs</strong>), connection strings, and so on)</li>
				<li><strong class="bold">Phishing attacks</strong></li>
			</ul>
			<p>Phishing attacks are an especially easy way to start<a id="_idIndexMarker898"/> an attack. According to a study from 2021, 19.8% of recipients of a phishing mail clicked on a link in an email, and 14.4% downloaded the attached document (see <em class="italic">Terranova and Microsoft</em>, 2021), and in companies that regularly do phishing campaigns, the numbers are more or less the same. At one of my customers, nearly 10% of employees who received an email during a phishing campaign entered their credentials in the login dialog that was displayed after they clicked the link in the phishing mail! And this was a company that had already been practicing phishing campaigns for years.</p>
			<p>The problem with phishing<a id="_idIndexMarker899"/> is a psychological effect called <strong class="bold">priming</strong>. Even if you know in general what phishing attacks look like and the signs to look for to detect them, the moment you are expecting a mail or you think the mail belongs to some context you are in, the more likely you are not to look for those signs. A good example would be a phishing mail at the end of the month that claims to be from your <strong class="bold">human resources</strong> (<strong class="bold">HR</strong>) department and says there was a problem with the payment of your salary. Since it is the end of the month and you are expecting your salary, the mail does not seem strange. Maybe you had problems before. Maybe you just checked, and the money was not there yet. It also generates some urgency. If you are in a hurry, you may want to quickly solve this so that your salary comes on time. If you send a phishing mail such as this at the end of the month, chances are much higher that people will then click for the rest of the month. Another example is a shared document. If you were just on the phone with a colleague that said they'll share a file with you, you may just wonder why they're choosing this way, but you're not suspicious as you are expecting a file anyway. The more phishing mails you send, the higher the possibility someone has just the right context and that you will fall for it.</p>
			<p>Once an attacker has managed to compromise<a id="_idIndexMarker900"/> the first victim and has company credentials or access to the victim's machine, the game<a id="_idIndexMarker901"/> changes completely. Now, the attack is performed by an <strong class="bold">inside attacker</strong>, and they can target specific people in the company<a id="_idIndexMarker902"/> from an internal address. This is called <strong class="bold">spear phishing</strong> and is extremely hard to detect.</p>
			<p>A good target for spear phishing is administrators or engineers. If you don't practice <strong class="bold">least-privilege</strong> user rights, the attacker might<a id="_idIndexMarker903"/> already have access to a production system or is a domain administrator, and the game is over. But if they compromise a developer, they have also a variety of options, as outlined here:</p>
			<ul>
				<li><strong class="bold">Development environments</strong>: Development environments are the dream of every attacker. Most developers<a id="_idIndexMarker904"/> work as local administrators, and you can already find a ton of tools preinstalled that help an attacker to progress. Chances are high they can find secrets in text files to access various systems. Or, as they<a id="_idIndexMarker905"/> are administrators, they can use a tool called <strong class="source-inline">mimikatz</strong> (see https://github.com/gentilkiwi/mimikatz/wiki) to read credentials from memory. </li>
				<li><strong class="bold">Test environments</strong>: Many developers have access <a id="_idIndexMarker906"/>to test environments, often as administrators. Attackers can log in and use mimikatz to steal other credentials.</li>
				<li><strong class="bold">Modify code</strong>: One line of code<a id="_idIndexMarker907"/> is usually enough to disable authentication. The attacker can try to modify code or change the version of a dependency to one with a known vulnerability that can be exploited.</li>
				<li><strong class="bold">Execute scripts</strong>: If the developer can modify pipeline<a id="_idIndexMarker908"/> code or scripts that get executed during deployment, the attacker can insert code that gets executed during deployment.</li>
			</ul>
			<p>That's why it is so important in engineering to be extra cautious when it comes to security. There is much more attack surface than in most other departments in an organization.</p>
			<p>To get from one compromised account<a id="_idIndexMarker909"/> to the domain administrator or at least an administrator with production<a id="_idIndexMarker910"/> access, you can use a tool called <strong class="bold">BloodHound</strong> (<a href="https://github.com/BloodHoundAD/BloodHound">https://github.com/BloodHoundAD/BloodHound</a>). It supports <strong class="bold">Active Directory</strong> (<strong class="bold">AD</strong>) and <strong class="bold">Azure AD</strong> (<strong class="bold">AAD</strong>) and reveals all the hidden<a id="_idIndexMarker911"/> relationships: Who has a session<a id="_idIndexMarker912"/> on which machines? Who is a member of which group? Who is an administrator of a certain machine?</p>
			<p>Both blue teams and red teams can use this tool to analyze relationships in an AD environment.</p>
			<h1 id="_idParaDest-293"><a id="_idTextAnchor293"/>GitHub Codespaces</h1>
			<p>Since development environments<a id="_idIndexMarker913"/> are a big problem when it comes to security, it's a good idea to virtualize them and have a specific machine for each product. This way, you can implement least-privilege user rights and your engineers do not have to work with local administrator rights on their machines. You also can limit the number of tools that are needed for a specific product and minimize the attack surface.</p>
			<p>Of course, you<a id="_idIndexMarker914"/> can use classical <strong class="bold">virtual desktop infrastructure</strong> (<strong class="bold">VDI</strong>) images for that, but you can also use<a id="_idIndexMarker915"/> a more lightweight option: <strong class="bold">dev containers</strong> (see <a href="https://code.visualstudio.com/docs/remote/containers">https://code.visualstudio.com/docs/remote/containers</a>, which is an extension for <strong class="bold">Visual Studio Code</strong> (<strong class="bold">VS Code</strong>) that is built on top of its client-server<a id="_idIndexMarker916"/> architecture). You can connect VS Code to a running container or instantiate a new instance. The complete configuration is stored in the repository (config as code), and you can share the same config for the dev container with your team.</p>
			<p>A special form of dev containers is <strong class="bold">GitHub Codespaces</strong>, which is a virtual development environment hosted in Azure. You can pick different <strong class="bold">virtual machine</strong> (<strong class="bold">VM</strong>) sizes between 2-core/4 <strong class="bold">gigabytes</strong> (<strong class="bold">GB</strong>) <strong class="bold">random-access memory</strong> (<strong class="bold">RAM</strong>)/32 GB storage and 32 core/64 GB RAM/128 GB storage. The start time of the VM is blasting fast. The default image is more than 35 GB and starts in less than 10 seconds!</p>
			<p>The base image contains everything necessary to develop with Python, Node.js, JavaScript, TypeScript, C, C++, Java, .NET, <strong class="bold">PHP: Hypertext Preprocessor</strong> (<strong class="bold">PHP</strong>), PowerShell, Go, Ruby, Rust, and Jekyll. It also includes a ton of other developer tools and utilities such as <strong class="source-inline">git</strong>, <strong class="bold">Oh My Zsh</strong>, <strong class="bold">GitHub command-line interface</strong> (<strong class="bold">GitHub CLI</strong>), <strong class="source-inline">kubectl</strong>, Gradle, Maven, and <strong class="source-inline">vim</strong>. Run <strong class="source-inline">devcontainer-info content-url</strong> inside your codespace and open the <strong class="bold">Uniform Resource Locator</strong> (<strong class="bold">URL</strong>) that it returns for a complete list of all preinstalled tools.</p>
			<p>But you don't have to use the base image—you can completely customize your codespace using<a id="_idIndexMarker917"/> dev containers. You can work with a codespace using either VS Code in the browser, your local VS Code instance, or using <strong class="bold">Secure Shell</strong> (<strong class="bold">SSH</strong>) from a terminal. If you run your application<a id="_idIndexMarker918"/> inside the codespace, you can forward ports to test it from your local machine. <em class="italic">Figure 13.5</em> shows the architecture of GitHub Codespaces:</p>
			<div>
				<div id="_idContainer164" class="IMG---Figure">
					<img src="image/B17827_13_005.jpg" alt="Figure 13.5 – Architecture of GitHub Codespaces&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.5 – Architecture of GitHub Codespaces</p>
			<p>You can open, for example, the <a href="https://github.com/wulfland/AccelerateDevOps">https://github.com/wulfland/AccelerateDevOps</a> repository in a new codespace under <strong class="bold">Code</strong> | <strong class="bold">Codespaces</strong> | <strong class="bold">New codespace</strong> (<em class="italic">see Figure 13.6</em>), if you have Codespaces enabled for your account. The repository<a id="_idIndexMarker919"/> does not have a dev container configuration, so it will load the default image:</p>
			<div>
				<div id="_idContainer165" class="IMG---Figure">
					<img src="image/B17827_13_006.jpg" alt="Figure 13.6 – Opening a repository in a codespace&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.6 – Opening a repository in a codespace</p>
			<p>You can see in the preceding screenshot<a id="_idIndexMarker920"/> that I already have a codespace running on the <strong class="source-inline">main</strong> branch. Instead of creating a new one, I could also open the existing one. Pick the VM size (<em class="italic">see Figure 13.7</em>):</p>
			<div>
				<div id="_idContainer166" class="IMG---Figure">
					<img src="image/B17827_13_007.jpg" alt="Figure 13.7 – Picking the VM size for your codespace&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.7 – Picking the VM size for your codespace</p>
			<p>In the terminal, change<a id="_idIndexMarker921"/> the directory to <strong class="source-inline">ch9_release/src/Tailwind.Traders.Web</strong> and build and run the application with the following commands:</p>
			<p class="source-code">$ cd ch9_release/src/Tailwind.Traders.Web</p>
			<p class="source-code">$ dotnet build </p>
			<p class="source-code">$ dotnet run</p>
			<p>This will start a web server listening on ports <strong class="source-inline">5000</strong> and <strong class="source-inline">5001</strong>. Codespaces automatically detects<a id="_idIndexMarker922"/> this and forwards port <strong class="source-inline">5000</strong> to a local port. Just click <strong class="bold">Open in Browser</strong> to see the application that is running inside your codespace in your local browser (<em class="italic">see Figure 13.8</em>): </p>
			<div>
				<div id="_idContainer167" class="IMG---Figure">
					<img src="image/B17827_13_008.jpg" alt="Figure 13.8 – Forwarding a port to your machine&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.8 – Forwarding a port to your machine</p>
			<p>You can also add ports that should be forwarded manually in the <strong class="bold">PORTS</strong> tab and change the visibility if you want to share a link with your coworkers—for example, to let them try a new feature (<em class="italic">see Figure 13.9</em>):  </p>
			<div>
				<div id="_idContainer168" class="IMG---Figure">
					<img src="image/B17827_13_009.jpg" alt="Figure 13.9 – Configuring port forwarding in your codespace&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.9 – Configuring port forwarding in your codespace</p>
			<p>If you want more control over your development environment, you can create a dev container in your codespace. Open the <em class="italic">Command Palette</em> in VS Code by clicking the green <strong class="bold">Codespaces</strong> button in the bottom-left corner or by pressing <em class="italic">Shift</em> + <em class="italic">Command</em> + <em class="italic">P</em> on Mac or <em class="italic">Ctrl</em> + <em class="italic">Shift</em> + <em class="italic">P</em> on Windows. Select <strong class="source-inline">Codespaces: Add Development Container Configuration Files….</strong> and follow the wizard to select languages and features that get installed. The wizard will create a <strong class="source-inline">.devcontainer</strong> folder in the root of your repository and, in it, two files: a <strong class="source-inline">devcontainer.json</strong> file and a <strong class="source-inline">Dockerfile</strong> file.</p>
			<p>The <strong class="source-inline">Dockerfile</strong> file defines the container<a id="_idIndexMarker923"/> that is created when your codespace is initialized. The <strong class="source-inline">Dockerfile</strong> file can be really simple—it is enough if it contains a <strong class="source-inline">FROM</strong> clause that indicates from which base image it inherits.</p>
			<p>In the <strong class="source-inline">devcontainer.json</strong> file, you can pass arguments to the image creation, you can define VS Code settings that are shared with all teammates, you can use VS Code extensions that are installed per default, and you can run commands that are run after the container was created (<em class="italic">see Figure 13.10</em>): </p>
			<div>
				<div id="_idContainer169" class="IMG---Figure">
					<img src="image/B17827_13_010.jpg" alt="Figure 13.10 – Example Dockerfile file and devcontainer.json file&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 13.10 – Example Dockerfile file and devcontainer.json file</p>
			<p>See <a href="https://code.visualstudio.com/docs/remote/devcontainerjson-reference">https://code.visualstudio.com/docs/remote/devcontainerjson-reference</a> for a complete reference<a id="_idIndexMarker924"/> on how you can customize your <strong class="source-inline">devcontainer.json</strong> file.</p>
			<p>If you change either the <strong class="source-inline">Dockerfile</strong> file or the <strong class="source-inline">devcontainer.json</strong> file, you can rebuild the container by opening the Command Palette and executing <strong class="source-inline">Rebuild Container</strong>.</p>
			<p>If you need secrets inside your codespace, you can create them—as with all other secrets—under <strong class="bold">Settings</strong> | <strong class="bold">Secrets</strong> | <strong class="bold">Codespaces</strong> (<strong class="source-inline">settings/secrets/codespaces</strong>) in the organization or repository level. Secrets are available as environment variables inside the codespace container. If you add a new secret, you have to stop the current codespace—a rebuild container is not enough.</p>
			<p>Of course, GitHub Codespaces<a id="_idIndexMarker925"/> is not available for free—you have to pay for the uptime minutes of your instances. The minutes are reported to billing daily and billed monthly. The rate depends on the size of your VM (<em class="italic">see Table 13.1</em>): </p>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="image/Table_013.jpg" alt="Table 13.1 – Pricing for GitHub Codespaces&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Table 13.1 – Pricing for GitHub Codespaces</p>
			<p>Additionally, you pay $0.07 per GB and month<a id="_idIndexMarker926"/> for the storage used.</p>
			<p><em class="italic">Codespaces do not get terminated if you close your browser</em>. If they are still running in the background, you can connect much faster, but you must still pay for them. The default idle timeout is 30 minutes, which is equivalent to $0.18 for the 4-core machine. That's really cheap, but it is still money. You should always stop your codespace if you don't need it anymore. You can change the default idle timeout under <strong class="bold">Settings</strong> | <strong class="bold">Codespaces</strong>.</p>
			<p>GitHub Codespaces is not only great for security—it can also boost your onboarding time and productivity. GitHub itself uses it for its development, and it reduced onboarding time for new engineers from days to under 10 seconds! And that for a repository with almost 13 GB on disk that normally takes 20 minutes to clone (Cory Wilkerson, 2021).</p>
			<p>Codespaces might not be suited for all products, but for web applications, it's the future, and it will revolutionize how we think of managing developer machines. It also helps you to close a security gap in your development pipeline—your local developer machines.</p>
			<h1 id="_idParaDest-294"><a id="_idTextAnchor294"/>Summary</h1>
			<p>In this chapter, you've learned how important security is for your development process and how you can start to <strong class="bold">shift security left</strong> and implement an <strong class="bold">assume-breach</strong> and <strong class="bold">zero-trust</strong> culture. I introduced you to <strong class="bold">attack simulations</strong> and <strong class="bold">red team-blue team</strong> exercises to raise awareness for security, find vulnerabilities, and practice your IR.</p>
			<p>I've also shown you how <strong class="bold">GitHub Codespaces</strong> can help you to reduce the risk of local development environments and make you more productive.</p>
			<p>In the next chapter, you'll learn how to secure your code and your software supply chain.</p>
			<h1 id="_idParaDest-295"><a id="_idTextAnchor295"/>Further reading</h1>
			<p>You can use the following references from this chapter to get more information on the topics covered:</p>
			<ul>
				<li><em class="italic">IC3</em> (2020). <em class="italic">Internet Crime Report 2020</em>: <a href="https://www.ic3.gov/Media/PDF/AnnualReport/2020_IC3Report.pdf">https://www.ic3.gov/Media/PDF/AnnualReport/2020_IC3Report.pdf</a></li>
				<li><em class="italic">IC3</em> (2019). <em class="italic">Internet Crime Report 2019</em>: <a href="https://www.ic3.gov/Media/PDF/AnnualReport/2019_IC3Report.pdf">https://www.ic3.gov/Media/PDF/AnnualReport/2019_IC3Report.pdf</a></li>
				<li>Data breaches in 2020: <a href="https://www.identityforce.com/blog/2020-data-breaches">https://www.identityforce.com/blog/2020-data-breaches</a></li>
				<li>Data breaches in 2021: <a href="https://www.identityforce.com/blog/2021-data-breaches">https://www.identityforce.com/blog/2021-data-breaches</a></li>
				<li><em class="italic">Terranova</em> and <em class="italic">Microsoft</em> (2021). <em class="italic">Gone Phishing Tournament – Phishing Benchmark Global Report 2021</em>: <a href="https://terranovasecurity.com/gone-phishing-tournament/">https://terranovasecurity.com/gone-phishing-tournament/</a></li>
				<li><em class="italic">GitHub Codespaces</em>: <a href="https://docs.github.com/en/codespaces/">https://docs.github.com/en/codespaces/</a></li>
				<li><strong class="source-inline">devcontainer.json</strong> <em class="italic">reference</em>: <a href="https://code.visualstudio.com/docs/remote/devcontainerjson-reference">https://code.visualstudio.com/docs/remote/devcontainerjson-reference</a></li>
				<li><em class="italic">Introduction to dev containers</em>: <a href="https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/configuring-codespaces-for-your-project">https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/configuring-codespaces-for-your-project</a></li>
				<li><em class="italic">Cory Wilkerson</em> (2021). <em class="italic">GitHub's Engineering Team has moved to Codespaces</em>: <a href="https://github.blog/2021-08-11-githubs-engineering-team-moved-codespaces/">https://github.blog/2021-08-11-githubs-engineering-team-moved-codespaces/</a></li>
			</ul>
		</div>
	</body></html>