- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What Not to Do about Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is about the ways in which your data layer can be compromised on
    the Salesforce platform. Throughout this chapter, we cover four data domain anti-patterns
    that occur with some frequency in Salesforce environments and give you pointers
    on how to recognize and avoid them. In addition, we have added a new section on
    AI-related anti-patterns to help you navigate these new developments.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Why treating Salesforce as a relational database won’t lead to acceptable results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How failing to coordinate activities can lead to a disconnected data model with
    serious negative repercussions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The negative consequences of failing to plan for growth in your database, especially
    when you should know better
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why data synchronization can be a great solution on a small scale, but a nightmare
    on a larger scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to approach AI architecture in the context of Salesforce
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After completing this chapter, you will have a good understanding of how Salesforce
    is different from a traditional relational database and why that matters greatly.
    You will also know the importance of good governance, planning for data modeling
    and growth, and what can go wrong when you don’t have governance in place. Finally,
    you will have a deeper insight into the complexities of data synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: Mistaking Salesforce for a regular database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many people come to the Salesforce ecosystem from other technology backgrounds,
    and they often come with preconceptions about how architecture should be done
    based on their past experiences. While that can be enriching to the platform,
    there are also cases where it can lead you astray, architecturally speaking. Perhaps
    the most frequent of these is the mistake of using Salesforce as though it were
    some other kind of database—generally a relational one.
  prefs: []
  type: TYPE_NORMAL
- en: Salesforce as a Relational Database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*The Salesforce as a Relational Database anti-pattern consists of mistaking
    the Salesforce data layer for a* *relational database.*'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: UmbrellaCo is the largest global manufacturer of umbrellas for the tourism industry.
    They use Salesforce for managing their B2B sales channel, including opportunity
    management, quoting, and ordering.
  prefs: []
  type: TYPE_NORMAL
- en: However, in the overall systems landscape within UmbrellaCo, Salesforce is a
    relatively minor component. Overall, the landscape is dominated by a set of bespoke
    lines of business systems that have been developed and maintained in-house and
    an aging **Manufacturing Resource Planning** ( **MRP** ) system.
  prefs: []
  type: TYPE_NORMAL
- en: There is also a relatively modern middleware platform and UmbrellaCo’s approach
    to enterprise IT relies heavily on integrating, translating, and combining data
    from various systems within the middleware. This allows them some additional agility
    that they otherwise would not be able to have, given their aging and bespoke systems
    portfolio.
  prefs: []
  type: TYPE_NORMAL
- en: Rishi is the responsible manager for Salesforce at UmbrellaCo. He is an external
    hire who only recently joined the company from a mid-size ecosystem partner. One
    of the first things he has to deal with in settling into his new role is a series
    of complaints from the middleware team about the Salesforce data model.
  prefs: []
  type: TYPE_NORMAL
- en: UmbrellaCo has longstanding practices for modeling certain kinds of data, such
    as different types of accounts, for example, SME accounts versus large corporate
    accounts, and strict standards for modeling addresses. The Salesforce model does
    not accommodate this model in the standard way, leading to substantial work on
    the middleware team in mapping the data to other systems.
  prefs: []
  type: TYPE_NORMAL
- en: John, an integration architect long employed by UmbrellaCo, is assigned to the
    Salesforce team in order to align the Salesforce data model. Rishi is immediately
    quite uncomfortable in the collaboration with John. John displays a high degree
    of distaste for the Salesforce data model and thinks it fundamentally fails to
    conform to good data modeling practices.
  prefs: []
  type: TYPE_NORMAL
- en: The standard within UmbrellaCo is to use relational databases, normalized to
    **Third Normal Form** ( **3NF** ), and follow the corporate conventions for key
    data types. Salesforce does not meet these expectations and cannot easily be made
    to do so. Rishi tries to explain that the Salesforce data model shouldn’t be thought
    of as a classical relational database, whatever superficial resemblance it might
    have to one, but his objections fall on deaf ears.
  prefs: []
  type: TYPE_NORMAL
- en: After a month of work, John puts forward his proposal for reworking the Salesforce
    data model. It involves replacing the standard Salesforce address field with a
    new set of custom objects incorporating the address and an arbitrary number of
    address lines linked to the master account object. Different types of accounts
    will get their own individual custom objects and refer back to the master account
    object using an inheritance-like interface.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Proposal for refactoring account model](img/B30991_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Proposal for refactoring account model
  prefs: []
  type: TYPE_NORMAL
- en: This will require both rework on the user interface and an internal data migration
    exercise within Salesforce to accomplish, but John is adamant that this will bring
    the system into line with corporate standards and make life easier on the middleware
    team.
  prefs: []
  type: TYPE_NORMAL
- en: Rishi vehemently objects and even gets his Salesforce account executive to bring
    in a senior solution engineer from Salesforce, trying to explain why following
    this plan is a surefire way to cripple the Salesforce platform and make additional
    projects more complex and expensive. The objections make their way to the company’s
    architecture forum but are rejected as conformance to corporate standards is considered
    a more important imperative.
  prefs: []
  type: TYPE_NORMAL
- en: Going forward, data modeling on Salesforce should follow the normal UmbrellaCo
    standards and deliver well-normalized data models that meet the specifications
    set out in the enterprise data model. Rishi draws a deep breath and consigns himself
    to having to do mostly bespoke solutions on Salesforce going forward.
  prefs: []
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The problem addressed by Salesforce as a Relational Database is the general
    one of modeling business entities in the context of a software system. In this
    case, use the most commonly used modeling paradigm in the software industry: relational
    database models.'
  prefs: []
  type: TYPE_NORMAL
- en: In this approach, you map a logical model of a business domain into a set of
    database tables, using a process called **normalization** . The details of what
    normalization is do not need to concern us much, but it is fundamentally concerned
    with the elimination of redundancy within the database. That is to say, each piece
    of information should be held once and uniquely within the database and then referenced
    in all of the places that it’s used.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, there should not be repeating fields, such as multiple address
    lines, and all the fields in an entity should rely explicitly on the primary key:
    the ID field in Salesforce. You should always have one and only one unique key
    for the entity.'
  prefs: []
  type: TYPE_NORMAL
- en: By applying these and a few more elaborate rules with greater or lesser stringency,
    you get to a certain normal form, the name for models of normalization. The strictest
    application is something called the **Sixth Normal Form** ( **6NF** ) where you
    end up with tables consisting of only a primary key and one other attribute. However,
    most enterprise applications strive for 3NF, which meets the criteria we outlined
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Hierarchy of normal forms](img/B30991_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Hierarchy of normal forms
  prefs: []
  type: TYPE_NORMAL
- en: This is all well and good and is the accepted way to do things for systems based
    on relational databases. However, Salesforce, while it has a number of surface
    similarities to a relational database (namely tables, called objects) and relationships
    (in the form of lookup and master/detail relationships that enable its use as
    a relational database), is not a relational database and should not be treated
    as such.
  prefs: []
  type: TYPE_NORMAL
- en: Proposed solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Salesforce as a Relational Database ignores the distinctive nature of the data
    modeling used on the Salesforce platform and replaces it with a model that bases
    itself on relational databases. This means using custom objects freely to serve
    as tables and relationships of either type to serve as foreign key relations.
  prefs: []
  type: TYPE_NORMAL
- en: It explicitly ignores Salesforce’s standard ways of dealing with record differentiation,
    such as record types and page layouts, in favor of a relational model with a larger
    number of unique custom objects. In addition, this anti-pattern tends to make
    scant use of standard objects as these do not fit with a well-normalized data
    model.
  prefs: []
  type: TYPE_NORMAL
- en: This solution makes a lot of sense to many experienced architects coming to
    Salesforce from other platforms without a lot of understanding or training. It
    is, after all, the accepted way for things to be done in all traditional enterprise
    systems, and consistency with an accepted standard is extremely valuable in enterprise
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: However, bending a system so out of shape as this pattern does to Salesforce
    goes to show that every standard has exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we saw in the earlier example, the result of introducing this anti-pattern
    is fundamentally increasing the complexity of your Salesforce solution, resulting
    in additional costs both for solutioning and maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: By relying on custom objects for nearly everything, you reduce your ability
    to leverage out-of-the-box features, because relational models tend to require
    a larger number of smaller objects, which makes some commonly used Salesforce
    features (for example, cross-object reporting or cross-object formula fields)
    nearly impossible to use.
  prefs: []
  type: TYPE_NORMAL
- en: That means you’ll most likely need to write more custom code or construct complex
    custom flows, which is where you take a real hit in terms of both upfront implementation
    cost and time and the maintenance and extensibility of the solution afterward.
  prefs: []
  type: TYPE_NORMAL
- en: There is also the opportunity cost of not being able to use standard functionality
    to the same extent and not being able to adopt newly released features with the
    same frequency to consider. All in all, this is a high price to pay for consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Better solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data domain is an area where you should adopt the Salesforce way to get
    the best results. While sometimes there are exceptions to Salesforce’s good practices,
    when it comes to data modeling, the guidance should be followed nearly without
    exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: That means modeling broad-based business objects directly in the system rather
    than going through a normalization process and relying on the platform to manage
    and optimize the data or at least give you the tools to do so. It also means using
    standard objects whenever you can, avoiding custom objects whenever possible,
    and ensuring that the data model is well governed to avoid issues with data integrity
    and redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: This is obvious to many people who have grown their careers in the Salesforce
    ecosystem, but it is counterintuitive to most traditional architects. This, then,
    is one of the few anti-patterns that is more likely to be initiated by a highly
    experienced architect than a brand-new one. It’s also more common in AppExchange
    applications than in standard implementations as these are closer to the traditional
    development models found on other platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Forgetting about governance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Governance is important in all architecture domains, but perhaps a few domains
    can go wrong where governance is missing as the data domain. In the following
    sections, we will explore two examples of this phenomenon, starting with what
    happens when you fail to coordinate data models on a common platform.
  prefs: []
  type: TYPE_NORMAL
- en: Disconnected Entities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Disconnected Entities is an anti-pattern characterized by unconnected data
    entities proliferating in a common database, often with multiple database representations
    of the same* *business-level entity.*'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SmileCo is a major provider of dental supplies operating in several global cities.
    They have been using Salesforce for several years, using a departmental strategy,
    where each department is run independently on Salesforce without central oversight.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three departments that use Salesforce in a serious way, and they
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Finance** , which uses it for debt collection using a home-grown application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logistics** , which uses it for vendor management using an application that
    has been developed by a small ecosystem partner'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sales** , which uses a standard Sales Cloud implementation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The information in these apps is spread out and there is no cross-visibility
    or collaboration between the teams. Kimmy is a consulting manager at a Salesforce
    Summit partner who is brought in with a small team to enable a comprehensive view
    of the underlying data.
  prefs: []
  type: TYPE_NORMAL
- en: She, however, soon discovers that the job is bigger than she bargained for.
    The finance application uses a flat, denormalized data model to model debt collection.
    All information is held in a giant debt custom object, including all contact and
    account information. This data is not validated and the data quality at a glance
    seems problematic.
  prefs: []
  type: TYPE_NORMAL
- en: The logistics application effectively mirrors the standard Salesforce data model
    using custom objects to represent vendors, vendor contacts, and information about
    quotes and purchases made from vendors. The fields differ substantially from the
    standard Salesforce data model but could be made to fit with standard objects
    such as the account and contact with a bit of creative data mapping.
  prefs: []
  type: TYPE_NORMAL
- en: The Sales Cloud implementation is relatively standard but uses quite a few additional
    custom fields that in no way match up with the way data is modeled in the other
    two platform apps. Kimmy reports her findings to the client, who after some hesitation
    requests that she continue with a plan for consolidation nonetheless.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Three different ways of representing an account and contact](img/B30991_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Three different ways of representing an account and contact
  prefs: []
  type: TYPE_NORMAL
- en: The plan she proposes seeks to standardize the use of the Account and Contact
    objects, using the standard objects, across all three departments, and on that
    basis write a set of reports and dashboards giving the required overview. She
    gives up on trying to consolidate additional objects as they are too far away
    from any standard objects for the attempt to be likely to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: For the finance application, she suggests renormalizing the account and contact
    parts of the gigantic debt object. This requires a data migration exercise as
    well as significant work to deduplicate and improve data quality. Rework on the
    application itself, thankfully, is relatively minor due to the simple declarative
    features used for its implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The logistics application presents a larger problem. Most of the functionality
    is in custom code and requires substantial rework. The partner is reluctant to
    make the changes Kimmy suggested as they prefer working in their own space, but
    after some pushing, they relent. However, the changes are quite expensive and
    take several months to implement.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, what was meant to be a small consulting engagement lasting a few weeks
    ended up taking more than three months, incurring substantial costs. Upon leaving
    the client, Kimmy sends a new proposal for introducing some basic Salesforce governance
    functions within SmileCo. They take the proposal under advisement and promise
    to get back to Kimmy in good time.
  prefs: []
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Disconnected Entities is another anti-pattern that happens when you fail to
    recognize that certain practices carried out without oversight or governance can
    result in serious issues at a higher level of operation. It is caused by a lack
    of awareness rather than by the attempt to achieve something specific.
  prefs: []
  type: TYPE_NORMAL
- en: It tends to occur in smaller or highly decentralized organizations where different
    groups may share the same infrastructure, in this case, a Salesforce org, but
    do not really coordinate activities beyond the absolute basics. It also requires
    an environment where IT maturity is low and governance of IT is minimal.
  prefs: []
  type: TYPE_NORMAL
- en: Proposed solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, if we were to frame what the Disconnected Entities anti-pattern proposes
    as a solution, it would be something along the lines of “don’t worry about the
    data model; any design will be good enough.” At least that is how it may be interpreted
    because there will be no standards, practices, or guidelines to follow.
  prefs: []
  type: TYPE_NORMAL
- en: Lack of governance can have bad effects in many domains, but in the data domain,
    the Disconnected Entities anti-pattern is one of the worst. It means that teams
    build in isolation with no awareness of what else exists on the same platform
    or how other teams are using the same elements (even the same standard objects).
  prefs: []
  type: TYPE_NORMAL
- en: That means that you can have a cross-organizational impact without realizing
    it. Also, at the very least, the anti-pattern leads to the kind of scenario sketched
    in our earlier example where cross-departmental initiatives are hampered or blocked
    by the data model.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the Disconnected Entities anti-pattern, the results can be as chaotic as
    the process that produces them. For the small teams whose uncoordinated work eventually
    causes the anti-pattern, it usually works out just fine in the short term.
  prefs: []
  type: TYPE_NORMAL
- en: When you are working in isolation on your own thing, there really isn’t any
    short-term impact to doing things badly or idiosyncratically. The impact only
    comes with scale, coordination requirements, or a need to extend the application
    to new use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The specific negative consequences can therefore vary considerably, but some
    common ones include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An inability to achieve 360 visibility of contacts or accounts, or any other
    relevant business entity for that matter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An inability to do cross-departmental or cross-application reporting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increased cost of new development and maintenance due to variability and complexity
    in the data layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An inability to connect applications or create cross-departmental workflows
    without incurring substantial rework costs to bring different areas in line with
    each other
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duplication of effort between different areas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less scope for adopting new standard features as they are released because of
    inconsistencies in the data models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, then, this anti-pattern has many of the same characteristics in the
    data domain that Big Ball of Mud had in the system domain or the Spaghetti Sharing
    model had in the security domain.
  prefs: []
  type: TYPE_NORMAL
- en: Better solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unsurprisingly, the key to avoiding an anti-pattern caused by missing governance
    and awareness is to institute the appropriate governance- and awareness-generating
    mechanisms. That means first and foremost having the appropriate governance forums
    in place, where different areas can coordinate their activities in a structured
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'This needs to be supported by good data governance standards and practices
    to support the work done in the relevant forums. These can take different forms
    depending on the organization and its culture, but to avoid Disconnected Entities,
    a list such as the following is a starting point:'
  prefs: []
  type: TYPE_NORMAL
- en: Rigidly enforce the use of standard objects and fields wherever possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that teams use standard objects and fields consistently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have an approval process for creating new custom objects that teams must follow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have a lighter approval process for creating custom fields
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define ownership of all objects and ensure that object owners are consulted
    about all changes to their objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have an architect or two take a global view of the data model and offer ongoing
    advice on its evolution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having now covered what happens when you fail to coordinate your activities
    in the data domain, we will move on to look at what can happen if you fail to
    plan for growth.
  prefs: []
  type: TYPE_NORMAL
- en: Unplanned Growth
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*The Unplanned Growth anti-pattern happens when organizations fail to plan
    for growth in the data to be stored, although they could or should have* *known
    better.*'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: HappyWorkoutCo is a sportswear retailer with more than 200 shops globally. They
    have developed a customized retail management application based on Salesforce
    Industries but with a large amount of customization and some bespoke development.
    The application has been developed in an agile, iterative fashion and that is
    also the way they are proposing to go live.
  prefs: []
  type: TYPE_NORMAL
- en: Martin is in charge of the rollout to the stores. Initially, they will roll
    out the product for only three small product categories to a handful of stores
    in major markets. While the product tests well, Martin still has butterflies as
    the first stores go live.
  prefs: []
  type: TYPE_NORMAL
- en: But this time, the rollout is a great success. The product works flawlessly
    and the staff at the stores love the new capabilities the software gives them
    for greater individual engagement with customers across channels.
  prefs: []
  type: TYPE_NORMAL
- en: Buoyed by the initial success, Martin and his team start a program of incremental
    rollouts to both more stores and product categories. Everything initially continues
    to go well, but after a while, complaints start coming in about system performance.
    There is a noticeable slowdown on a number of screens in the system and some key
    reports take minutes to run.
  prefs: []
  type: TYPE_NORMAL
- en: A task force consisting of members of Martin’s team as well as technical resources
    from the development partner is put together to have a look at the issue. However,
    the decision is made to continue the rollout of both new products and new stores.
  prefs: []
  type: TYPE_NORMAL
- en: The task force gets underway, but soon after it begins its work, a major incident
    occurs following a major go-live where 20 new shops and several thousands of products
    were being brought online. The system creeps to a halt and several screens stop
    working altogether.
  prefs: []
  type: TYPE_NORMAL
- en: Martin’s team conducts an emergency rollback, which restores the system to an
    operational state, but now all eyes are on the performance task force. The team
    works quickly with renewed vigor and intensity and discovers what they believe
    to be the root cause.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the package containing the core retail management application, there
    is a junction object that contains a record for each product configuration available
    at a given retail store. When the system went live, there were 5 stores, 100 products,
    and about 10 configurations each, for a total of 5,000 records.
  prefs: []
  type: TYPE_NORMAL
- en: After the big go-live, there were 150 stores with 17,000 products, each with
    an average of 35 configurations for a total of 89,250,000 records. What’s worse
    is that the object didn’t only contain current records but also historical ones
    that had been overwritten during the rollout process, leading to more than 117,000,000
    records in the junction object.
  prefs: []
  type: TYPE_NORMAL
- en: The object is used in a number of automations, batch jobs, and reports and is
    also queried frequently by custom user interface components. The design seems
    to have been mainly a matter of development convenience and no one seems to have
    ever done any calculations around the amount of data to be stored in the object.
  prefs: []
  type: TYPE_NORMAL
- en: The task force presents its conclusion and recommends a number of stopgap measures,
    including removing the automations, archiving all of the historical records, removing
    rare product configurations, tuning some reports, and implementing some caching
    and optimizations in the user interface.
  prefs: []
  type: TYPE_NORMAL
- en: This program of work puts out the immediate fire, but the system still doesn’t
    perform up to expectations. Martin starts negotiations with the development partner
    about how to redesign the system to eliminate the root cause.
  prefs: []
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is another anti-pattern that tends to be instigated not by an active choice
    but by a deprioritization of certain practices in order to deliver on a specific
    goal. In the case of unplanned growth, the team deprioritizes the ability to scale
    in order to achieve greater speed in the initial delivery.
  prefs: []
  type: TYPE_NORMAL
- en: This can be appropriate in some cases, for example, if you are a start-up trying
    to prove product-market fit on a shoestring budget, and for this reason, it can
    be subtly seductive. Many large organizations these days want to see themselves
    in the mold of an agile start-up, adopting many practices from this world.
  prefs: []
  type: TYPE_NORMAL
- en: However, for large, well-established organizations that already have a certain
    scale, failing to acknowledge this fact upfront is a recipe for disaster.
  prefs: []
  type: TYPE_NORMAL
- en: Proposed solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Unplanned Growth anti-pattern proposes that a team should get on with the
    important business of delivering without paying much attention to the issues that
    may arise due to increasing scale down the road. Effectively, the proposal is
    to make small-scale progress and then adapt later, should the scale be required.
  prefs: []
  type: TYPE_NORMAL
- en: This anti-pattern is different from others such as Disconnected Entities as
    it is not an absence of awareness that causes it, but rather an active choice
    to deprioritize planning for scale. Again, it is worth noting that this is not
    always an anti-pattern.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, starting small and then taking the hit on rework later is a justifiable
    strategy. Typically, this is the case if you don’t know upfront whether your idea
    will work or how many users it will need to accommodate when you are building
    the application partially to get more information.
  prefs: []
  type: TYPE_NORMAL
- en: But it is always an anti-pattern when done by a large organization that knows
    the application it is building will eventually need to reach a certain definable
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The results of Unplanned Growth encompass a fairly large number of scaling
    issues, determined by the nature of the application in question. Most commonly,
    you will see **Large Data Volume** ( **LDV** ) type issues such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Slowdowns in reports and dashboards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slowdowns in list views
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Locking issues on data loads or even in normal use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timeouts when loading custom components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Errors cropping up about governor limits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third-party packages failing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may also see the general user experience crawl to a halt, especially if
    it uses many custom pages and components. Integrations can also be affected by
    the same issues, leading to serious errors across systems. Even automations that
    were working perfectly may start to fail, although not necessarily in a systematic
    way.
  prefs: []
  type: TYPE_NORMAL
- en: All in all, if the unplanned growth is significant enough, it can bring your
    entire solution to its knees.
  prefs: []
  type: TYPE_NORMAL
- en: Better solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The number one thing you need to do to avoid this anti-pattern is to be clear
    from the start about what scale you are building for. If you are planning to build
    something that works on a small scale to test out an idea, then that’s fine, but
    be explicit about it and have a plan to take a step back and redesign if it turns
    out you are successful and need to scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you know for a fact that you need to hit a certain scale, it is nearly criminal
    not to design for it upfront. That means incorporating LDV mitigation tactics
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Using selective queries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing your queries with the platform query optimizer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding synchronous automations on LDV objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding synchronous code running queries on LDV objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using skinny tables to optimize specific queries and reports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using custom indices to optimize specific queries and reports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Archiving non-current data continuously
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using external objects to store data externally when possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing for growth also means designing the data model in a way that reduces
    LDV issues in the first place. In our preceding example, there would most likely
    be many alternative data models that did not have to hold a complete record of
    all product configurations by store in a single junction object.
  prefs: []
  type: TYPE_NORMAL
- en: Having now considered what happens when you fail to consider scale in the data
    domain, we will move on to the last anti-pattern in this chapter, which is Unconstrained
    Data Synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing excessively
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data synchronization is hard to get right but extremely useful when it works.
    It is, however, easy to get carried away when starting to put synchronization
    methods in place, which can cause a plethora of problems. We’ll see how in the
    following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Unconstrained Data Synchronization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Unconstrained Data Synchronization is an anti-pattern characterized by an
    overly ambitious approach to synchronizing data between systems without fully
    appreciating all the things that can* *go wrong.*'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: BusyCo, a large vendor of productivity-related products, has recently implemented
    a B2B omnichannel digital experience spanning web, social, call center, and partner
    channels. They have implemented the web application using a bespoke approach based
    on Microsoft Azure and use Salesforce to manage any manual processing steps for
    quotes and orders as well as opportunity management and any quotes or orders originating
    via calls or field sales.
  prefs: []
  type: TYPE_NORMAL
- en: All of the information eventually goes into the **Enterprise Resource Planning**
    ( **ERP** ) system, which handles the fulfillment and financial side of the ordering
    process as well as serving as the source of truth for financial forecasts. Because
    of its role in producing financial information, the information in the ERP must
    always be of the highest possible quality.
  prefs: []
  type: TYPE_NORMAL
- en: Oleg, the lead architect on the Salesforce side, recommends a structured approach
    to data governance with clearly defined roles and responsibilities for each system
    in relation to the core data model objects. Also, there should be clearly defined
    ownership in place for key fields and objects, so the source of truth is always
    known.
  prefs: []
  type: TYPE_NORMAL
- en: BusyCo, however, goes with the approach that any piece of information can be
    modified in any system at any point in time and all systems will be updated with
    the modified data in near-real time. To achieve this goal, they have put in place
    bidirectional data synchronization between all three systems.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – BusyCo synchronization scenario](img/B30991_04_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – BusyCo synchronization scenario
  prefs: []
  type: TYPE_NORMAL
- en: No problems are found during the acceptance testing phase, but Oleg is not particularly
    reassured. The testing scenarios do not begin to cover all of the things that
    can go wrong once the synchronization functions are out in the wild. The business
    users, however, love the flexibility of being able to change anything in whatever
    system context they happen to find themselves in.
  prefs: []
  type: TYPE_NORMAL
- en: After the go-live, things start to crop up. No showstoppers, but a number of
    annoying errors begin to emerge. One day, the link between the website and the
    other systems is down for a few hours and afterward a number of records fail to
    synchronize correctly. What’s worse is that a few days later, it is discovered
    that some address updates were never synchronized to the ERP, so some customer
    orders were shipped to the wrong addresses.
  prefs: []
  type: TYPE_NORMAL
- en: There is also a recurring problem with quotes that seem to go back and forth
    between statuses in Salesforce and the ERP. The cause seems to be a batch job
    running in the ERP doing some routine maintenance. As the job can’t be turned
    off, the only solution in the short term is a manual workaround where the support
    team takes a daily task to reclassify quotes with a wrong status.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, there are some fringe cases around the synchronization of manually
    inputted quotes and orders. They don’t seem to reliably trigger the data synchronization
    in all cases and therefore some orders hang in Salesforce and never get shipped.
  prefs: []
  type: TYPE_NORMAL
- en: As the errors compound, business leadership starts to pay more attention to
    voices such as Oleg’s that advocate simpler patterns for managing the data between
    the systems. However, as the system is already live and works at least partially,
    any refactoring will need to be done without requiring major downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Oleg accepts the challenge of finding a way to refactor the system to use simpler
    data integration patterns while instituting better data governance. It won’t be
    easy, but with time and effort, he believes BusyCo can succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In contrast to the last couple of anti-patterns that happened due to a lack
    of awareness or a failure to act, the Unconstrained Data Synchronization anti-pattern
    happens because you’re trying your best to give the business what it wants. Sometimes,
    you can have the best intentions and still end up causing a terrible mess.
  prefs: []
  type: TYPE_NORMAL
- en: The problem you’d be trying to solve in this case is how to have all the relevant
    business data available and editable in different systems at the same time. Users
    hate switching between contexts. If they are in System A, then they want to be
    able to edit all the relevant fields in System A. If they are in System B, then
    they want to be able to edit all the relevant fields in System B. If the fields
    they want to edit are the same from a master data perspective, say, an address
    or the name of a customer, that requirement will force you to synchronize data.
  prefs: []
  type: TYPE_NORMAL
- en: From a user experience perspective, this is perfectly rational. Switching between
    systems and screens in order to update data is a pain, as is not having the information
    you need available where you need it. Equally, you usually need this information
    to be available in near-real time across systems to avoid processing errors.
  prefs: []
  type: TYPE_NORMAL
- en: Near-real-time data synchronization can seem like a panacea, and it would be
    if it weren’t so fiendishly complicated from a technical point of view.
  prefs: []
  type: TYPE_NORMAL
- en: Proposed solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The solution proposed by Unconstrained Data Synchronization is to bidirectionally
    synchronize all relevant data points between all relevant systems in something
    near real time. As noted, this can be considered somewhat of a silver bullet and
    there are plenty of vendors willing to capitalize on this by promising you tools
    that will make synchronization easy.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that there are many failure modes in synchronization. These failures
    compound that the more data synchronization is used, no tool will reduce away
    the fundamental complexity. Small differences in processing on different systems
    or even within the same system can create unforeseen results, as can even minor
    outages or errors on some of the platforms involved. These errors compound the
    more systems and objects you are synchronizing.
  prefs: []
  type: TYPE_NORMAL
- en: Unless you can confidently say you have a complete grasp of all the ways your
    systems and processes can fail and you are certain you have full control of all
    your operational processes, then Unconstrained Data Synchronization will cause
    you grief.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data synchronization tends to work just fine in small-scale scenarios. Synchronizing
    a specific type of data between two systems is rarely a problem, and neither is
    synchronizing a relatively large amount of data unidirectionally.
  prefs: []
  type: TYPE_NORMAL
- en: The problems come when you have some combination of multiple systems, multiple
    objects, and bidirectional connectivity. Here, you will start to see scenarios
    such as those in our example where small errors compound over time to create a
    major problem.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, what you’ll get is a continuous stream of small-scale remediation
    activities that need to be handled by a technical support team coupled with a
    number of workarounds on the business level to avoid known synchronization issues.
    The more complex your scenario, the more of these kinds of issues you will have.
  prefs: []
  type: TYPE_NORMAL
- en: Occasionally, this anti-pattern can lead to outright disasters, such as when
    a synchronization link fails silently for an extended period of time, leading
    to data between systems becoming catastrophically out of sync and business errors
    proliferating without anyone knowing until the complaints start coming.
  prefs: []
  type: TYPE_NORMAL
- en: Mostly, however, you just see a trickle of small issues that never seem to stop.
  prefs: []
  type: TYPE_NORMAL
- en: Better solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You might be expecting us to say something to the effect that you should generally
    avoid data synchronization. We won’t. That would be naïve and unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we are going to say is that you should be cautious about the kinds of
    data synchronization you do, particularly in the following cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing a data point bidirectionally between two systems is fine. Don’t,
    however, add a third.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need to synchronize to more than one system, make sure that you are doing
    it unidirectionally and that you have defined who owns the master data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Middleware and synchronization tools can help with implementation, but they
    do not solve the fundamental problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple synchronizations in the same org are fine as long as they are non-overlapping;
    be cautious about having multiple synchronizations running for the same object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronizations that need to run in near-real time are much more complex than
    those that can be processed in a batch manner.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now proceed to cover some AI-specific anti-patterns that occur frequently
    when organizations start adopting AI.
  prefs: []
  type: TYPE_NORMAL
- en: Too much AI is not always a good thing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section covers two AI-related anti-patterns that describe what happens
    when you don’t think properly about how AI is different and when it makes sense
    to use it in your solution.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s Add AI to It
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*This is an anti-pattern that occurs when you use AI for its coolness factor
    rather than for good* *business reasons.*'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MediCorp, a mid-sized life sciences manufacturing company, has been grappling
    with pricing consistency across its product lines. Their sales team, particularly
    the account managers handling incoming orders, often struggle to apply correct
    discounts and adhere to the company’s pricing strategy. After much deliberation,
    leadership decides to implement a new pricing solution combining an off-platform
    pricing engine with Salesforce CPQ.
  prefs: []
  type: TYPE_NORMAL
- en: The project begins with great enthusiasm. The team meticulously maps existing
    pricing processes, identifies pain points, and designs a solution promising to
    streamline pricing decisions while maintaining flexibility for complex deals.
    But six months into the implementation, everything changes.
  prefs: []
  type: TYPE_NORMAL
- en: Sarah, the VP of sales, attends a high-profile tech conference where AI is the
    hot topic. She sits through a dazzling presentation about AI-powered pricing optimization
    that promises to boost revenue by 15% and reduce pricing errors to near zero.
    Excited by the possibilities, she returns to MediCorp determined to incorporate
    this cutting-edge technology into their ongoing project.
  prefs: []
  type: TYPE_NORMAL
- en: Despite concerns raised by the project manager and lead architect about scope
    creep and increased complexity, the executive team is won over by Sarah’s enthusiasm.
    They green-light the addition of an off-platform AI pricing tool, convinced it
    will give them a competitive edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'The project team now faces the challenge of integrating three separate systems:
    Salesforce CPQ, the original pricing engine, and the new AI tool. The AI is supposed
    to provide pricing guidance to CPQ and feed into the pricing engine’s calculations.
    What was once a relatively straightforward integration has become a complex web
    of data flows and decision points.'
  prefs: []
  type: TYPE_NORMAL
- en: As the go-live date approaches, testing reveals numerous inconsistencies. Sometimes
    the AI suggests prices that contradict the rules in the pricing engine. Other
    times, discounts applied in CPQ aren’t reflected in the final price. The team
    works overtime to iron out these issues, but the root cause is often difficult
    to pinpoint due to the black-box nature of the AI’s decision-making process.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the red flags, MediCorp pushes ahead with the launch, partly driven
    by the sunk cost fallacy and partly by the allure of being an “AI-driven company.”
    The sales team receives extensive training on the new system, with particular
    emphasis on the AI-powered features that promise to make their jobs easier.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, there is a buzz of excitement. Account managers marvel at the sleek
    interface and the purportedly intelligent pricing recommendations. However, as
    weeks pass, problems begin to surface. Sales reps find themselves second-guessing
    the AI’s suggestions, often reverting to their old methods of calculating prices.
    Customers start questioning the inconsistencies in pricing across similar orders.
  prefs: []
  type: TYPE_NORMAL
- en: The finance team notices that while some deals are priced higher, overall margins
    are actually decreasing. They suspect that the AI is sometimes suggesting overly
    aggressive discounts to win deals, without fully accounting for MediCorp’s cost
    structures.
  prefs: []
  type: TYPE_NORMAL
- en: Most worryingly, due to the complexity of the three-way integration and the
    opaqueness of the AI’s decision-making, no one can confidently audit the pricing
    decisions. When discrepancies are found, it is nearly impossible to determine
    whether the issue stems from CPQ, the pricing engine, or the AI tool.
  prefs: []
  type: TYPE_NORMAL
- en: Six months after go-live, MediCorp’s CFO calls for a full audit of the pricing
    system. The results are sobering. Not only has the promised 15% revenue boost
    failed to materialize, but pricing errors have actually increased. The complexity
    of the system has led to a lack of transparency that makes it difficult for sales
    reps to explain pricing decisions to customers, eroding trust.
  prefs: []
  type: TYPE_NORMAL
- en: In a difficult but necessary move, MediCorp’s leadership decides to roll back
    the AI component of the system. They go back to the drawing board, planning a
    reimplementation that would focus on the core functionalities of CPQ and the pricing
    engine, with a more measured approach to incorporating AI in the future.
  prefs: []
  type: TYPE_NORMAL
- en: The “Let’s Add AI to It” initiative, which seemed so promising, ultimately led
    to increased costs, decreased efficiency, and a temporary loss of pricing integrity.
    MediCorp learned the hard way that AI, despite its potential, is not a magic solution
    to be casually added to existing projects without careful consideration and planning.
  prefs: []
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Let’s Add AI to It anti-pattern stems from the widespread belief that AI
    can universally enhance and optimize existing processes or products. This belief
    is fueled by several factors, including the hype and media attention surrounding
    AI, misunderstanding of AI capabilities, fear of missing out, and the desire for
    innovation.
  prefs: []
  type: TYPE_NORMAL
- en: Many decision-makers have a superficial understanding of AI, leading them to
    overestimate its abilities or applicability to their specific use cases. There’s
    often pressure from stakeholders to adopt AI without fully understanding the implications
    or necessary groundwork. The proliferation of AI platforms and tools makes it
    seemingly easy to incorporate AI into existing systems.
  prefs: []
  type: TYPE_NORMAL
- en: The core problem this anti-pattern attempts to address is how to improve existing
    products, services, or processes. AI is seen as a universal enhancer that can
    be applied to any situation to yield better results, higher efficiency, or improved
    user experience. However, this perspective often overlooks the complexity of AI
    implementation, the need for high-quality data, the potential for increased system
    complexity, and the importance of clear use cases and expected outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Proposed solution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Let’s Add AI to It anti-pattern proposes a seemingly straightforward solution
    to enhance existing systems or processes: integrate AI capabilities wherever possible.
    This typically involves identifying potential AI integration points, selecting
    AI tools or platforms, integrating AI components, training the AI models, and
    launching the AI-enhanced system.'
  prefs: []
  type: TYPE_NORMAL
- en: This solution suggests that by following these steps, organizations can reap
    numerous benefits. It’s believed that AI will improve decision-making, increase
    efficiency, enhance user experience, provide a competitive advantage, reduce costs,
    and offer scalability. The AI components are expected to improve their performance
    over time as they process more data, potentially uncovering new insights that
    humans might miss.
  prefs: []
  type: TYPE_NORMAL
- en: The proposed solution appears attractive because it promises to leverage cutting-edge
    technology to solve existing problems and create new opportunities. It seems to
    offer a way to quickly upgrade current systems without the need for a complete
    overhaul. Moreover, it often comes with the allure of being relatively easy to
    implement, especially with the rise of AI-as-a-service platforms and pre-trained
    models.
  prefs: []
  type: TYPE_NORMAL
- en: However, this solution often oversimplifies the challenges of AI implementation
    and integration. It assumes that AI can be easily plugged into existing systems
    and immediately provide value, without considering the potential disruptions to
    current processes or the need for significant changes in data management and decision-making
    frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Result
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When organizations succumb to the Let’s Add AI to It anti-pattern, the results
    often fall far short of expectations and can lead to a range of negative outcomes.
    The most immediate impact is usually an increase in overall system complexity.
    Adding AI components to existing systems typically makes the architecture more
    complicated and harder to maintain, debug, and update.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality issues often come to the forefront. Many organizations discover
    too late that their existing data is insufficient, biased, or of poor quality,
    leading to unreliable AI outputs. Integration challenges are common, with the
    process of connecting AI components to legacy systems proving far more difficult
    than anticipated, leading to project delays and budget overruns.
  prefs: []
  type: TYPE_NORMAL
- en: The lack of explainability in many AI models, particularly deep learning ones,
    can be problematic. When AI operates as a “black box,” it becomes difficult to
    understand or explain its decisions. This can be especially challenging in regulated
    industries or when transparency is crucial for user trust or legal compliance.
  prefs: []
  type: TYPE_NORMAL
- en: User experience often suffers. If the AI components don’t perform as expected
    or make obvious mistakes, it can lead to frustration and rejection of the system.
    There’s also a risk of overreliance on AI, where users may over-trust AI recommendations,
    leading to a decline in critical thinking or the ability to handle exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical and privacy concerns may arise, especially if the AI implementation
    is hasty and doesn’t adequately address these important considerations. This can
    potentially lead to reputational damage or legal problems.
  prefs: []
  type: TYPE_NORMAL
- en: From a resource perspective, AI projects can become a significant drain, consuming
    substantial computational and human resources. This can divert attention and funding
    from other important initiatives. Maintenance of AI systems often proves more
    challenging and resource-intensive than anticipated, with ongoing needs for monitoring,
    retraining, and updating.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of performance and reliability, hastily implemented AI solutions may
    lead to inconsistent results across different scenarios or user groups. They may
    introduce new security vulnerabilities or fail to scale as expected. In some cases,
    the complexity introduced by AI can make it difficult to trace the logic behind
    certain outcomes, leading to a lack of accountability.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps most disappointingly, many organizations find it difficult to measure
    the return on investment for their AI initiatives. The complex nature of AI systems,
    combined with their impact on various aspects of the business, can make it challenging
    to accurately assess their value.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, the Let’s Add AI to It anti-pattern often results in a system that
    is more complex, less reliable, and harder to manage than its predecessor. Instead
    of enhancing the existing product or process, it can introduce new problems and
    inefficiencies. The promise of easy improvements through AI integration proves
    to be an illusion, as organizations find themselves grappling with unexpected
    challenges and disappointing results.
  prefs: []
  type: TYPE_NORMAL
- en: Better solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To avoid falling into the Let’s Add AI to It anti-pattern, organizations should
    adopt a more measured and strategic approach to AI implementation. The key is
    to start with a clear problem statement. Before considering AI, it’s crucial to
    clearly define the problem you’re trying to solve. This helps ensure that AI is
    genuinely the best solution, not just the trendiest one.
  prefs: []
  type: TYPE_NORMAL
- en: Conducting thorough due diligence is essential. Organizations should research
    and understand the capabilities and limitations of AI in their specific domain.
    This might involve consulting with experts and examining case studies of similar
    implementations. It’s also important to assess data readiness. The quality, quantity,
    and relevance of available data should be evaluated, and investments in data infrastructure
    and governance may be necessary before implementing AI.
  prefs: []
  type: TYPE_NORMAL
- en: Starting small and iterating is a prudent approach. Beginning with a pilot project
    or proof of concept allows organizations to learn and adjust with minimal risk
    before scaling up. Throughout this process, it’s crucial to focus on user needs.
    Conducting user research helps ensure that AI features truly enhance the user
    experience and solve real pain points.
  prefs: []
  type: TYPE_NORMAL
- en: Organizations should prioritize explainability in their AI implementations.
    Choosing AI models and approaches that offer transparency in decision-making is
    especially important in critical applications. This goes hand in hand with considering
    ethical implications. Developing an AI ethics framework can guide implementation
    and ensure responsible use of the technology.
  prefs: []
  type: TYPE_NORMAL
- en: Investing in AI literacy across the organization is valuable. Educating stakeholders,
    including executives and end users, about AI’s capabilities, limitations, and
    implications can help manage expectations and facilitate smoother adoption.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to plan for the long term. Organizations should consider the
    ongoing maintenance, updating, and scaling of AI systems in their planning and
    budgeting. This includes establishing clear metrics to assess the AI’s performance
    and impact over time.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the best solution is to enhance existing processes before adding
    AI. Simple improvements to current systems and workflows can sometimes yield better
    results than complex AI solutions. When AI is implemented, maintaining human oversight
    is crucial. Systems should be designed to augment human decision-making rather
    than completely replacing it, especially in critical areas.
  prefs: []
  type: TYPE_NORMAL
- en: AI Architecture Is Like Normal Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*This is an anti-pattern that occurs when Salesforce architects treat an AI
    project like any* *other project.*'
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CloudForce Solutions, a successful Salesforce **Independent Software Vendor**
    ( **ISV** ), had been developing apps for Salesforce AppExchange for years. Their
    portfolio includes various tools for sales analytics, customer management, and
    marketing automation. When Salesforce announces new AI capabilities, CloudForce
    sees an opportunity to create an AI-powered lead scoring and prioritization app.
  prefs: []
  type: TYPE_NORMAL
- en: The project, dubbed “LeadGenius,” is led by Sarah, CloudForce’s senior Salesforce
    architect. Sarah and her team have a track record of creating robust, successful
    Salesforce apps using traditional development approaches. They decide to apply
    the same methodologies to LeadGenius, viewing the AI components as just another
    set of features to implement.
  prefs: []
  type: TYPE_NORMAL
- en: 'They begin by gathering requirements from potential customers and creating
    detailed specifications. Sarah designs a familiar architecture: Apex classes for
    business logic, Lightning components for the user interface, and custom objects
    for data storage. The team plans to use Salesforce Einstein features for the AI
    functionality, treating them as black-box components that could be easily integrated
    into their existing patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: As development progresses, the team encounters its first challenge. Einstein
    Prediction Builder, which they are using to score leads, isn’t performing as consistently
    as they anticipated. Sometimes, it assigns unexpectedly low scores to leads that
    sales representatives know are promising. Sarah’s team treats this like a typical
    bug, attempting to add more fields to the prediction model and creating complex
    Apex logic to “correct” the AI’s output.
  prefs: []
  type: TYPE_NORMAL
- en: The next hurdle comes when they try to integrate LeadGenius with various **Customer
    Relationship Management** ( **CRM** ) systems for testing. The AI model struggles
    with the diverse, often messy data from different organizations, producing inconsistent
    results. The team’s solution is to implement more data cleaning and transformation
    steps in their Apex code, essentially trying to force the data to fit their predefined
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: As the project nears its launch date, CloudForce runs into serious issues with
    the app’s lead prioritization logic. In complex sales scenarios, the AI sometimes
    makes recommendations that seem counterintuitive to experienced sales managers.
    The team’s response is to add more **if-then** statements and decision trees in
    their Apex code, attempting to account for every possible scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these challenges, CloudForce pushes forward with the AppExchange launch,
    confident that their thorough architecture and rigorous testing would ensure success.
    Initially, LeadGenius receives positive feedback from early adopters who are excited
    about the prospect of AI-powered lead scoring.
  prefs: []
  type: TYPE_NORMAL
- en: However, as weeks pass, problems begin to surface. The app’s performance degrades
    over time, struggling with new types of leads and industries that hadn’t been
    in the initial training data. The team finds it difficult to diagnose issues,
    as the AI’s decision-making process isn’t as transparent as their traditional
    Apex code.
  prefs: []
  type: TYPE_NORMAL
- en: Customers report frustration with the app’s inability to adapt to their specific
    sales processes or handle nuanced lead qualification criteria. Some notice that
    LeadGenius is sometimes giving higher scores to leads from larger companies, regardless
    of actual fit or interest, reflecting biases present in the training data that
    the team hadn’t anticipated or accounted for.
  prefs: []
  type: TYPE_NORMAL
- en: Most alarmingly, there are instances where the app makes ethically questionable
    suggestions, such as prioritizing leads based on factors that could be seen as
    discriminatory.
  prefs: []
  type: TYPE_NORMAL
- en: Six months after the launch, CloudForce faces a growing number of customer complaints
    and cancellations. They request a comprehensive review of LeadGenius. The results
    are disappointing. Sales teams using the app aren’t seeing the promised increase
    in conversion rates and, in some cases, are missing out on valuable opportunities
    due to misclassified leads.
  prefs: []
  type: TYPE_NORMAL
- en: In a difficult meeting with key customers, Sarah and her team have to admit
    that their traditional approach to Salesforce app development has failed to address
    the unique challenges of AI systems. They realize too late that AI-powered apps
    require a fundamentally different mindset, focusing on data quality, model behavior,
    ethical considerations, and continuous learning—aspects they had overlooked in
    their conventional Salesforce development approach.
  prefs: []
  type: TYPE_NORMAL
- en: CloudForce decides to pause new sales of LeadGenius and initiate a complete
    redesign of the app. They are forced to go back to the drawing board, this time
    with a much better understanding of the unique requirements of AI architecture
    within the Salesforce ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The AI Architecture Is Like Normal Architecture anti-pattern stems from the
    misconception that AI-powered Salesforce solutions can be designed and implemented
    using the same principles and methodologies as traditional Salesforce development.
    This belief is often rooted in familiarity with Salesforce development practices
    and an underestimation of AI complexity. Many teams feel more comfortable applying
    techniques they’ve used successfully in past Salesforce projects, without fully
    grasping the fundamental differences between deterministic Apex code and probabilistic
    AI systems such as Einstein.
  prefs: []
  type: TYPE_NORMAL
- en: There’s also often pressure within organizations to rapidly implement AI features
    to stay competitive and maximize their Salesforce investment. This urgency, combined
    with a tendency to view Einstein features as simple plug-and-play components,
    can lead to an oversimplification of AI capabilities within the Salesforce ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: The core problem this anti-pattern attempts to address is how to efficiently
    integrate AI capabilities into Salesforce implementations. The assumption is that
    by treating AI architecture like normal Salesforce architecture, teams can leverage
    their existing skills and processes to deliver AI solutions effectively on the
    platform. However, this approach fails to account for the distinct characteristics
    of AI systems within Salesforce, such as their probabilistic nature, dependence
    on data quality and quantity, the potential for autonomous behavior, the opacity
    of decision-making processes, and ethical implications.
  prefs: []
  type: TYPE_NORMAL
- en: Result
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When organizations succumb to the AI Architecture Is Like Normal Architecture
    anti-pattern in their Salesforce implementations, the results often fall far short
    of expectations and can lead to a range of negative outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: The most immediate impact is usually poor AI performance. The AI models may
    not perform as expected in real-world scenarios, leading to inaccurate predictions
    or recommendations. This is often due to insufficient consideration of data quality
    and quantity, or a lack of understanding of the model’s limitations within the
    Salesforce ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Adaptability also becomes a significant issue. The AI components may fail to
    adapt to new data or changing business conditions, as the traditional architecture
    doesn’t account for the need for continuous learning and model updates in Salesforce.
    As the Salesforce org grows and data volumes increase, the AI solutions may struggle
    to handle diverse datasets and use cases, leading to performance degradation.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical concerns can arise when proper consideration isn’t given to AI ethics.
    Salesforce AI implementations may make biased or unfair decisions, potentially
    exposing the organization to reputational or legal risks. This is compounded by
    the difficulty in troubleshooting AI issues. When problems occur, Salesforce administrators
    and developers may struggle to diagnose the root cause due to the opacity of AI
    decision-making processes, which aren’t as transparent as traditional Salesforce
    configurations or Apex code.
  prefs: []
  type: TYPE_NORMAL
- en: User satisfaction often suffers as a result. Salesforce users may become frustrated
    with the AI features’ inability to handle nuanced scenarios or adapt to specific
    business processes, leading to poor adoption rates. Maintenance becomes increasingly
    challenging as the Salesforce org evolves, with teams finding it difficult to
    update AI components without unintended consequences.
  prefs: []
  type: TYPE_NORMAL
- en: Resource drain is another common outcome. Attempts to “fix” AI issues using
    traditional Salesforce customization approaches can lead to increasingly complex
    configurations and code, consuming more compute resources and potentially hitting
    Salesforce governor limits.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps most disappointing is the missed opportunity for innovation. By treating
    AI as just another feature, organizations may fail to leverage the full potential
    of Salesforce’s AI capabilities, missing out on chances to truly transform their
    business processes.
  prefs: []
  type: TYPE_NORMAL
- en: Integration difficulties often arise, with AI solutions struggling to work smoothly
    with other Salesforce features or third-party tools. This is typically due to
    the unique requirements of AI systems not being properly addressed in the initial
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, the AI Architecture Is Like Normal Architecture anti-pattern often
    results in Salesforce AI implementations that fail to deliver on their promise.
    Instead of enhancing business processes and providing valuable insights, they
    can introduce new problems and inefficiencies. The initial allure of easy AI integration
    proves to be an illusion, as organizations find themselves grappling with unexpected
    challenges and disappointing AI performance within their Salesforce environment.
  prefs: []
  type: TYPE_NORMAL
- en: Better solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To avoid falling into the AI Architecture Is Like Normal Architecture anti-pattern,
    organizations should adopt a more nuanced and AI-aware approach to Salesforce
    development and implementation.
  prefs: []
  type: TYPE_NORMAL
- en: First and foremost, investing in AI education is crucial. The entire Salesforce
    team, including admins, developers, and architects, should have a solid understanding
    of AI concepts, particularly in the context of Salesforce Einstein’s capabilities.
    This knowledge foundation is essential for making informed decisions about AI
    integration.
  prefs: []
  type: TYPE_NORMAL
- en: Embracing a data-centric design approach is key. Organizations should start
    with a thorough analysis of available data within their Salesforce org. AI solutions
    should be designed around data quality, quantity, and relevance for AI models,
    taking into account how Salesforce data structures and relationships impact AI
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Planning for model monitoring and retraining is another critical aspect. Mechanisms
    should be implemented to track model performance over time and retrain models
    as needed. This might involve creating custom objects in Salesforce to store model
    metadata and performance metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Adopting an iterative development approach allows for the continuous refinement
    of AI models based on real-world performance and feedback within the Salesforce
    environment. This agile methodology is better suited to the evolving nature of
    AI systems than traditional waterfall approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Robust data preprocessing is essential. Organizations should develop Apex classes
    or leverage Salesforce Flow specifically for cleaning and preparing data for AI
    models, considering the unique requirements of machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Designing for explainability is crucial for user trust and compliance. Where
    possible, Einstein features that provide insight into model decisions should be
    used. For custom models, additional logging or visualization features can help
    users understand AI outputs within their Salesforce workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical considerations should be prioritized. Guidelines for ethical AI use
    within Salesforce should be developed, including mechanisms to detect and mitigate
    bias. This might involve creating custom validation rules or Apex triggers to
    flag potentially problematic decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Organizations should make full use of Salesforce’s AI infrastructure, such as
    Einstein Platform Services, which is designed to integrate smoothly with other
    Salesforce features and respect platform governance. However, it’s also important
    to plan for graceful degradation, ensuring that the Salesforce architecture can
    fall back to rule-based decision-making if AI components fail or produce low-confidence
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Comprehensive testing strategies should be implemented, going beyond traditional
    unit tests to include techniques such as A/B testing of model performance and
    scenario-based testing with diverse datasets, all within the Salesforce testing
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: User education is vital for successful AI adoption. In-app guidance and external
    documentation should be developed to help Salesforce users understand the capabilities
    and limitations of AI features, setting realistic expectations.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, maintaining human oversight is crucial. Salesforce workflows should
    be designed to allow for human review and override of AI decisions where appropriate,
    especially for high-stakes scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: By following these best practices, organizations can create AI-powered Salesforce
    solutions that truly leverage the potential of AI while addressing the unique
    challenges of AI systems within the Salesforce ecosystem. This approach helps
    ensure that AI truly adds value to Salesforce users, rather than just adding complexity
    or following a trend.
  prefs: []
  type: TYPE_NORMAL
- en: We have now covered anti-patterns and are ready to move on to looking at our
    key takeaways for the data domain.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will abstract a bit from the specific patterns and instead
    try to pull out the wider learning points you can use in your day-to-day work
    as a Salesforce architect or in preparing for the CTA Review Board.
  prefs: []
  type: TYPE_NORMAL
- en: 'When architecting Salesforce solutions, you should be mindful of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Salesforce has a unique approach to data modeling that does not easily map to
    traditional methods, such as relational database design.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trying to shoehorn Salesforce into such approaches will only end in tragedy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instead, you should follow the good practices established by Salesforce themselves
    and exemplified by the data model that comes with the platform out of the box.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This includes modeling using broad business objects rather than a normalized
    model, relying heavily on standard objects, and limiting the amount of custom
    work you put into the data layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Failing to coordinate activities between teams can cause serious issues at the
    data model layer and really reduce your ability to get things done in future projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Therefore, always promote appropriate coordination or governance forums that
    ensure teams understand what each one is doing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If possible, add to this coordination forum other data governance mechanisms
    such as data ownership, standards and guidance for data modeling, and approval
    processes for decisions that have serious data-layer consequences, such as adding
    a new custom object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a cardinal sin to know that you need to scale to a certain level and not
    do the necessary calculations that tell you whether that scale should be actively
    mitigated in your project or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you decide not to take active steps toward mitigating potential consequences
    of scale, you need to do so with your eyes fully open and with a plan to refactor
    and redesign later if needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, failing to take scale into account can be appropriate for start-ups
    and experimental projects, but it is rarely appropriate in an enterprise systems
    context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business users often love the idea of data synchronization because it enables
    a much superior user experience. However, they rarely appreciate the technical
    complexities involved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Small-scale data synchronization is often a good way to solve a problem, but
    beware of scaling them too much in both size and complexity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid synchronizing the same data points bidirectionally between more than two
    systems and be cautious about synchronizing large amounts of objects and fields
    unless it’s for strictly one-way use cases, such as data going to a data warehouse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resist the urge to add AI features without a clear business case and understanding
    of data requirements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Treat AI components as fundamentally different from traditional Salesforce customizations,
    requiring unique architectural considerations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prioritize data quality and quantity when designing AI-powered solutions in
    Salesforce.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement robust monitoring and retraining mechanisms for AI models within your
    Salesforce org.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design Salesforce processes that allow for graceful degradation if AI components
    fail or produce low-confidence results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In preparing for the CTA review board, you should be mindful of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand and follow good modeling practices when creating your data model
    for your scenario.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That means modeling things the “Salesforce way” and not taking too many liberties
    that you’ll have to explain and defend.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use standard objects first, and only if you are entirely convinced that no standard
    object will suffice should you turn to using a custom object in your solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be clear about what objects are used for what purpose and avoid having the same
    data in multiple places.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporate data ownership for all non-detail objects at the role level in your
    data model overview.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may want to put in a couple of words about good data governance when describing
    your governance model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do the math on data volumes for the key objects in the scenario and clearly
    identify any that may have LDV requirements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, these are junction objects between key entities in the system, but there
    are exceptions to this rule.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a clear and well-thought-out LDV mitigation approach for the objects
    in question. Simply reciting a list of common LDV mitigation techniques is not
    sufficient in and of itself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be careful when specifying data flows between systems. You need to be realistic
    in what data you propose to move back and forth and how.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prefer one-directional synchronizations and integrations to bidirectional ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prefer data virtualization to data synchronization whenever possible in the
    scenario at hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrate an understanding of the fundamental differences between traditional
    Salesforce architecture and AI-driven solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Articulate strategies for ensuring data quality and relevance for AI models
    within Salesforce orgs of varying sizes and complexities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain approaches to monitoring and maintaining AI model performance over time
    in a Salesforce context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discuss methods for integrating AI components with existing Salesforce features
    and third-party systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outline architectural considerations for scaling AI solutions as Salesforce
    org data and the user base grow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have now covered the material for this chapter and are ready to proceed with
    the solution architecture domain. First, however, we will summarize our learning.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have covered a lot of things that can go wrong in the data
    domain if you aren’t careful. The things that go wrong in the data layer tend
    to affect everything in the layers above, so if you fall into any of these anti-patterns,
    consequences will be serious for all aspects of your future configuration, integration,
    and development work.
  prefs: []
  type: TYPE_NORMAL
- en: It is, therefore, especially important to learn the lessons of good structure,
    good practice, and sound governance when it comes to the data domain. Not that
    they are unimportant elsewhere, but if you get your data layer wrong, then it
    is very hard to get everything else right.
  prefs: []
  type: TYPE_NORMAL
- en: This applies both in real life and in the CTA exam. As many aspiring or current
    CTAs will tell you, if you get any element of your data model for a scenario substantially
    wrong, that tends to ripple through the other domains, making it very hard to
    pass the overall scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Having now covered the data domain, we will proceed to solution architecture—an
    area so rife with anti-patterns that we’ll have to be quite selective in which
    we choose to include.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2: Solution Anti-Patterns'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part will teach you how to identify and mitigate anti-patterns in the functional
    domain of solution architecture as well as integration architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B30991_05.xhtml#_idTextAnchor069) , *Unpicking Solution Architecture
    Troubles*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B30991_06.xhtml#_idTextAnchor085) , *Keeping Integration Straight*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
