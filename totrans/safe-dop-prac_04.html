<html><head></head><body>
		<div id="_idContainer055">
			<h1 id="_idParaDest-87" class="chapter-number"><a id="_idTextAnchor086"/>4</h1>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor087"/>Leveraging Lean Flow to Keep the Work Moving</h1>
			<p>In <a href="B18756_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introducing SAFe® and DevOps</em>, we saw the inclusion of Lean thinking approaches such as Lean software development and Kanban into the Agile movement. Jez Humble saw it as important enough to include it in the CAMS model, creating the CALMS model from which we base the SAFe® CALMR model. Scaled Agile talks about that Lean-Agile mindset with an emphasis on both Lean thinking and an Agile mindset derived from the Agile Manifesto. How does this focus on Lean thinking manifest itself in DevOps <span class="No-Break">and SAFe?</span></p>
			<p>In this chapter, we will see that keeping product development moving at a predictable pace requires the establishment of a Lean flow. Proper flow allows automation to succeed. To that end, we will look at the following practices to establish <span class="No-Break">Lean flow:</span></p>
			<ul>
				<li>Making sure all work and work progress <span class="No-Break">is visible</span></li>
				<li>Limiting our <strong class="bold">Work in </strong><span class="No-Break"><strong class="bold">Progress/Process</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">WIP</strong></span><span class="No-Break">)</span></li>
				<li>Keeping the size of each batch of work <span class="No-Break">appropriately small</span></li>
				<li>Monitoring our <span class="No-Break">work queues</span></li>
				<li>Employing systems thinking to change the traditional definitions of project <span class="No-Break">and teams</span></li>
			</ul>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor088"/>Making the work visible</h1>
			<p>Work could be defined as the effort the team or <strong class="bold">Agile Release Train</strong> (<strong class="bold">ART</strong>) (as a team of teams) may <a id="_idIndexMarker271"/>put forth to develop a product or solution. But not all that <a id="_idIndexMarker272"/>work may be focused on <span class="No-Break">customer value.</span></p>
			<p><em class="italic">The Phoenix Project: A Novel about IT, DevOps, and Helping your Business Win</em> by Gene Kim, Kevin Behr, and George Spafford identifies four kinds of work. These are summarized <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Business projects</strong>: Requests for new features that will bring value to <span class="No-Break">the customer</span></li>
				<li><strong class="bold">Internal projects</strong>: Work that helps organizations continue to develop <span class="No-Break">products efficiently</span></li>
				<li><strong class="bold">Maintenance</strong>: Work needed to maintain <span class="No-Break">existing products</span></li>
				<li><strong class="bold">Unplanned work</strong>: Bugs, defects, and <a id="_idIndexMarker273"/>emergencies that occur from time <span class="No-Break">to time</span></li>
			</ul>
			<p>SAFe takes a few of these work categories and places them in <strong class="bold">enablers</strong>. The idea here is that enablers help create <a id="_idIndexMarker274"/>future business value. The four kinds of enablers defined by SAFe are <span class="No-Break">listed here:</span></p>
			<ul>
				<li><strong class="bold">Infrastructure</strong>: This enabler <a id="_idIndexMarker275"/>exists to enhance how products can be <a id="_idIndexMarker276"/>developed and delivered. Examples include new automated tests to include in the <strong class="bold">continuous delivery</strong> (<span class="No-Break"><strong class="bold">CD</strong></span><span class="No-Break">) pipeline.</span></li>
				<li><strong class="bold">Architectural</strong>: This enabler exists to enhance the architecture that business features and user <a id="_idIndexMarker277"/>stories rely on. SAFe defines the sequence of architectural enablers as an architectural runway that drives future business value. Examples include <a id="_idIndexMarker278"/>creating a new database server <strong class="bold">virtual machine</strong> (<strong class="bold">VM</strong>) for the staging and <span class="No-Break">production environments.</span></li>
				<li><strong class="bold">Compliance</strong>: This enabler <a id="_idIndexMarker279"/>describes additional work that may be <a id="_idIndexMarker280"/>needed in certain regulated industries. Examples include <strong class="bold">Verification and Validation</strong> (<strong class="bold">V&amp;V</strong>), approvals, <span class="No-Break">and documentation.</span></li>
				<li><strong class="bold">Exploration</strong>: Sometimes, additional research is required to understand the optimal approach, learn about <a id="_idIndexMarker281"/>new technologies, or refine customer desires. Exploration enablers are created to identify the work that research requires. An example of this is a Spike, used by Agile teams to research new technologies or evaluate a development option, such as determining the correct technology for <span class="No-Break">web streaming.</span></li>
			</ul>
			<p>Given the different categories of work that is done, it’s important to have a uniform way of displaying all the work of <a id="_idIndexMarker282"/>a team or ART. Traditionally, enterprising people, often with a technical background, have resorted to spreadsheets whose arrangement is flexible to allow for additional information such as work category or status. In addition, sharing spreadsheets among team members becomes difficult as there may be changes that need to <span class="No-Break">be synchronized.</span></p>
			<p>Dominica DeGrandis, in her book <em class="italic">Making Work Visible, Exposing Time Theft to Optimize Work &amp; Flow</em>, notes that the majority of people are visual-spatial learners, in that they are able to understand and respond to information presented visually. This is one of the reasons for setting up a <span class="No-Break">Kanban board.</span></p>
			<p>A Kanban board is a space divided into columns. Each column represents a state in the workflow of an item <a id="_idIndexMarker283"/>of work. Items of work are represented by note cards and color-coded to represent the appropriate <span class="No-Break">work category.</span></p>
			<p>A simple Kanban board is illustrated in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.1</em>. Note the three columns, representing work to be done (<strong class="bold">Backlog</strong>), WIP (<strong class="bold">Doing</strong>), and work <span class="No-Break">completed (</span><span class="No-Break"><strong class="bold">Done</strong></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B18756_04_01.jpg" alt="Figure 4.1 – Simple Kanban board"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Simple Kanban board</p>
			<p>Additional features on a Kanban board <a id="_idIndexMarker284"/>can help teams manage the work they do. Let’s take a look at those other features on a <span class="No-Break">Kanban board.</span></p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor089"/>Specifying workflow with additional columns</h2>
			<p>Often, having a single <em class="italic">in-progress</em> column doesn’t provide visibility into everything that a team or ART is doing, especially <a id="_idIndexMarker285"/>if there are bottlenecks in the overall process. It makes sense to break up the <em class="italic">in-progress</em> column to highlight major steps in the development so that bottlenecks are easy <span class="No-Break">to identify.</span></p>
			<p>While having discrete process steps separated into separate WIP columns is generally done, it’s important to remember that teams shouldn’t be taking all issues and moving all of them from column to column as that devolves the process into Waterfall. The movement of the issues happens in a <span class="No-Break">continuous fashion.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.2</em> shows an illustration <a id="_idIndexMarker286"/>of separating our <strong class="bold">Doing</strong> column with stages for analysis, implementation, <span class="No-Break">and review:</span></p>
			<div>
				<div id="_idContainer037" class="IMG---Figure">
					<img src="image/B18756_04_02.jpg" alt="Figure 4.2 – Expansion of the Doing column into several stages"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Expansion of the Doing column into several stages</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor090"/>Flagging impediments and urgent issues</h2>
			<p>Sometimes a work issue may be blocked due to some external event or dependency. As these impediments <a id="_idIndexMarker287"/>or blockers come up, an icon can be attached <a id="_idIndexMarker288"/>to the work issue as an indicator to the teams to continue to pay attention to the issue until the blocker <span class="No-Break">is removed.</span></p>
			<p>In the same way, any urgent issue may need the attention of the entire team. The team may need to swarm on the urgent issue until it is resolved. Urgent issues may be identified by a special indicator put on the issue or by its position in an <em class="italic">expedite</em> swimlane that cuts horizontally across all columns of the Kanban board. In the following screenshot, an example <a id="_idIndexMarker289"/>of an urgent issue highlighted by a <a id="_idIndexMarker290"/>special indicator in the expedite lane <span class="No-Break">is illustrated:</span></p>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/B18756_04_03.jpg" alt="Figure 4.3 – Work issue with an urgent indicator in the expedite lane"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Work issue with an urgent indicator in the expedite lane</p>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor091"/>Policies for specifying exit criteria</h2>
			<p>For every stage in the process, the team needs to have a clear agreement on the exit criteria. Having <a id="_idIndexMarker291"/>clear exit criteria avoids confusion as to whether an issue is truly finished at that stage. This agreement for each column is known as <span class="No-Break">a policy.</span></p>
			<p>Column policies have their place in a team charter or working agreement so that these are explicit and agreed upon. Examples of this include a <strong class="bold">Definition of Ready</strong> (<strong class="bold">DoR</strong>), where any questions <a id="_idIndexMarker292"/>are answered, and requirements are detailed enough that development can begin. Another example is a <strong class="bold">Definition of Done</strong> (<strong class="bold">DoD</strong>), which is an <a id="_idIndexMarker293"/>agreement by the team of the criteria that determine when a story is complete and development work on that story can stop. These policies avoid any confusion about whether a piece of work is truly complete as opposed to <span class="No-Break"><em class="italic">done done</em></span><span class="No-Break">.</span></p>
			<p>Other additions to the Kanban board will be identified as we look at other practices to ensure that Lean flow <a id="_idIndexMarker294"/>occurs. In the following section, we will examine the problem of having too much WIP and how a Kanban board can help by providing visibility and enforcing constraints on <span class="No-Break">team behavior.</span></p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor092"/>Limiting WIP</h1>
			<p>WIP is the work a team <a id="_idIndexMarker295"/>or ART has in process. It has been <a id="_idIndexMarker296"/>started but is not complete. If we were to view WIP on our Kanban board, it would resemble the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/B18756_04_04.jpg" alt="Figure 4.4 – Kanban board highlighting WIP"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – Kanban board highlighting WIP</p>
			<p>It is important to make sure that the work within these columns is monitored so that it doesn’t overwhelm the teams or ART. According to Dominica DeGrandis, the effects of too much WIP may include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Too much multitasking, which will cause teams to spend too much time doing context switching and prevent them from <span class="No-Break">finishing work</span></li>
				<li>New work items are started before existing work <span class="No-Break">is finished</span></li>
				<li>Work takes a long time to finish (long lead <span class="No-Break">times/cycle times)</span></li>
			</ul>
			<p>A key way of ensuring that a team is not letting WIP go unchecked is by setting up WIP limits or constraints on <a id="_idIndexMarker297"/>each column between the <strong class="bold">Backlog</strong> column (where work has not been accepted yet) and the <strong class="bold">Done</strong> column (where completed work goes). An example of WIP limits on a Kanban board is shown in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="image/B18756_04_05.jpg" alt="Figure 4.5 – WIP limits on columns"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – WIP limits on columns</p>
			<p>To understand how WIP limits can help a team achieve Lean flow, consider the following comparison of <span class="No-Break">team behavior.</span></p>
			<p>First, imagine a Kanban board with no WIP limits. A developer on the team has just finished the development of a user story. It meets the policy criteria for the column and could be pulled to the next column. If the developer moves that story to the next column and pulls a story to work, has that developer done anything to lower the amount of work that’s in progress? This may be acceptable if there is flow already established, but if there is a bottleneck in the team’s process, this action may exacerbate the bottleneck and prevent the entire team from actually delivering. This situation is captured on our Kanban board in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="image/B18756_04_06.jpg" alt="Figure 4.6 – Scenario with no WIP limits, resulting in no reduction in WIP"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.6 – Scenario with no WIP limits, resulting in no reduction in WIP</p>
			<p>Now, let’s imagine the same Kanban board with WIP limits in place. That developer who has finished the user story cannot move anything into the <strong class="bold">Implement/Test</strong> column. Also, no one can move anything from <strong class="bold">Implement/Test</strong> into <strong class="bold">Review</strong>. To help get the bottlenecks fixed, the developer acts to assist other team members to move a story from <strong class="bold">Review</strong> to <strong class="bold">Done</strong>. This has <a id="_idIndexMarker298"/>the effect of introducing throughput and establishing flow. We can view this scenario in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B18756_04_07.jpg" alt="Figure 4.7 – Scenario with WIP limits, resulting in flow"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Scenario with WIP limits, resulting in flow</p>
			<p>Teams can select initial WIP limits as they start work. After a period of time, if bottlenecks are still seen, they can lower the WIP limits until the bottlenecks disappear, and flow at that point is achieved. Even with that bottleneck gone, other bottlenecks will appear. The Theory of Constraints, as written by Eliyahu M. Goldratt in his book <em class="italic">The Goal</em>, specifies that you move to the subsequent bottlenecks, removing them one by one, to optimize the flow for the <span class="No-Break">entire process.</span></p>
			<p>WIP limits are a necessary mechanism according to David J. Anderson in his book <em class="italic">Kanban: Successful Evolutionary Change for Your Technology Business</em>. WIP limits create tension for a team, encouraging the team to act in order to work and enable flow, as seen in <a id="_idIndexMarker299"/>our previous scenario. The tension also may highlight constraints and systemic impediments in the organization. Open discussion of these constraints and impediments to finding solutions leads to <span class="No-Break">continuous improvement.</span></p>
			<p>We’ve seen how limiting WIP by imposing column constraints or WIP limits may help us address bottlenecks in our development process. One other source of bottlenecks in our process is the size of our items of work. Let’s take a look at keeping those at an appropriate size to attain and <span class="No-Break">maintain flow.</span></p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor093"/>Keeping batch sizes small</h1>
			<p>Batch size commonly refers to the size of a standard unit of work. One of the accomplishments of the Agile <a id="_idIndexMarker300"/>movement was the success of focusing delivery on smaller increments. That forced a look at reducing the batch size that could be accomplished for delivery. Reducing batch sizes in addition to limiting WIP are important parts of accomplishing Lean flow. Donald Reinertsen noted the effects of batch size in his book <em class="italic">The Principles of Product Development Flow: Second Generation Lean Product Development</em>. Let’s examine what role small batch <span class="No-Break">sizes play.</span></p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor094"/>Small batch sizes decrease cycle time</h2>
			<p>A key takeaway from Agile development was the delivery of value in short cycles. This had the effect of shortening the <a id="_idIndexMarker301"/>cycle time a team had to deliver an increment of value, allowing the team to look at delivering only what it could deliver by the end of the cycle. This allows us to say that batch size is directly related to the <span class="No-Break">cycle time.</span></p>
			<p>Keeping to large batches of work has several adverse effects. The work may not be delivered by the end of the cycle. What may be delivered may have defects that need to be fixed or reworked, increasing cycle time. The appearance of these defects also increases batch sizes, creating a <em class="italic">snowball effect</em>. The growth of the batch size and cycle time leads to cost overruns and <span class="No-Break">schedule slippages.</span></p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor095"/>Small batch sizes decrease risk</h2>
			<p>As we saw in the previous subsection, a large batch of work may carry with it defects that need to be fixed, impacting both the overall batch size and cycle time. Working in small batches will not eliminate the possibility of defects but will keep the number of possible defects small so that they can be <span class="No-Break">managed easily.</span></p>
			<p>A side effect of small batch sizes is that they result in short cycle times. This short cycle time provides opportunities for customer feedback. The opportunity for feedback negates any risk that the team is moving in the wrong direction in terms of <span class="No-Break">delivering value.</span></p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor096"/>Small batch sizes limit WIP</h2>
			<p>Batch sizes and WIP are directly related to each other. Directly changing one changes the other in a correlated fashion. Let’s look at a few examples of this correlation <span class="No-Break">at work.</span></p>
			<p>A large batch size will mean there is a large number of items of WIP. As mentioned before, large numbers of WIP increase multitasking, preventing work from finishing because of increased context switching. This effect is another factor that increases cycle time. </p>
			<p>The large batch size <a id="_idIndexMarker302"/>also creates a bottleneck in the system. This variability in flow impedes work from effectively moving, increasing <span class="No-Break">cycle time.</span></p>
			<p>Reinertsen also advocates in his book <em class="italic">The Principles of Product Development Flow: Second Generation Lean Product Development</em> that when optimizing between batch sizes and limiting WIP by attacking bottlenecks, start with reducing batch sizes first. This is often an easier step to implement. Reducing bottlenecks to allow for adequate flow may involve deeper changes in both process <span class="No-Break">and technology.</span></p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor097"/>Small batch sizes improve performance</h2>
			<p>As counter-intuitive as it may seem, large batch sizes do not create efficiencies with overhead. Time processing overhead activities are actually greater with large batches as opposed to smaller batches. The overhead compounds on large batches. Overhead costs on small batches can be reduced easily because of the shorter <span class="No-Break">cycle times.</span></p>
			<p>Small batch sizes improve efficiency. This may seem to also be counter-intuitive, but because small batch sizes receive fast feedback, subsequent batches of work are able to take advantage of that feedback, reducing rework. A large batch of work exposes all those problems at once, creating more work and removing any <span class="No-Break">implied efficiency.</span></p>
			<p>We’ve seen the advantages of working with small batch sizes and what happens when you work with a large batch size. The question then becomes, “How do I make sure I’m not working with a large batch size?” Let’s take a look at finding out what your optimal batch <span class="No-Break">size is.</span></p>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor098"/>Finding the ideal batch size</h2>
			<p>We have identified the <a id="_idIndexMarker303"/>benefits of working with small batch sizes. The question then becomes, “What would be an adequate enough <span class="No-Break">batch size?”</span></p>
			<p>Reinertsen proposes looking at batch size in terms of economics. When approaching the cost of development <a id="_idIndexMarker304"/>and determining what size of work is ideal, you need to consider <span class="No-Break">two costs:</span></p>
			<ul>
				<li><strong class="bold">Holding cost</strong>: The cost of <a id="_idIndexMarker305"/>keeping (and not releasing) what <span class="No-Break">you develop</span></li>
				<li><strong class="bold">Transaction cost</strong>: The cost <a id="_idIndexMarker306"/>to develop <span class="No-Break">your work</span></li>
			</ul>
			<p>An example of this comes from releasing work to a production environment. The following diagram shows <a id="_idIndexMarker307"/>the relationship between the <a id="_idIndexMarker308"/>transaction and holding cost curves if we were to look at the cost of releasing a change versus the cost of waiting to collect changes at an <span class="No-Break">optimal time:</span></p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/B18756_04_08.jpg" alt="Figure 4.8 – Transaction and holding cost curves"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.8 – Transaction and holding cost curves</p>
			<p>In our preceding diagram, an example of a small change—such as a single line of software code to release—is represented by point <strong class="bold">A</strong>. At point <strong class="bold">A</strong>, we incur a very low holding cost to <a id="_idIndexMarker309"/>immediately release, but the high cost at point <strong class="bold">A</strong> comes from the transaction cost. We are spending a lot of time performing testing and deployment for a simple line <span class="No-Break">of code.</span></p>
			<p>Does this mean we should always look to consolidate changes to incur less cost? Let’s look at point <strong class="bold">B</strong> in our <a id="_idIndexMarker310"/>preceding diagram, which collects our changes <a id="_idIndexMarker311"/>over a larger time period—say, a month. Now, the costs are reversed. The transaction cost is low as we are performing testing and releasing a large number of changes, but now our holding cost is high. Perhaps in delaying the release of our change, we missed an important market window and lost sales because our competitors released an equivalent <span class="No-Break">change first.</span></p>
			<p>If we wanted to figure out the <em class="italic">break-even</em> point of when to actually release a collection of changes, we would perform a <em class="italic">u-curve optimization</em>. We would take the sum of the holding cost and the <a id="_idIndexMarker312"/>transaction cost and plot it on the same graph as shown in the preceding diagram. On the graph of the total cost curve (sum of holding cost and transaction cost), find the lowest point on the curve. That’s the ideal number of items to have in <span class="No-Break">your batch.</span></p>
			<p>How can we improve on this ideal number of items per batch? If we introduce new ways of doing things or new technology, that can affect the transaction cost, giving us a new total cost curve with which to perform a u-curve optimization. Extending our example of releasing changes into production, the use of automated testing and deployment tools that enable faster, more reliable deployments with more frequent testing in a CD pipeline reduces transaction costs, giving us the confidence to release stories more frequently within a sprint. The new cost curves would probably resemble the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/B18756_04_09.jpg" alt="Figure 4.9 – New cost curves after optimization"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.9 – New cost curves after optimization</p>
			<p>We can see from the preceding diagram at point <strong class="bold">A</strong>, the holding cost remains the same but the transaction cost has decreased. Also, we can see that the low point of the total cost curve has shifted to the left, moving our ideal point “left," to smaller <span class="No-Break">batch sizes.</span></p>
			<p>So, what can our teams and ARTs do that will yield lower transaction cost curves? Adopting practices and <a id="_idIndexMarker313"/>technology such as automated testing and automated deployment is one example that certainly fits the bill. They allow for smaller batch sizes to go through and <span class="No-Break">encourage flow.</span></p>
			<p>In this section and the previous section, we looked at WIP and batch size as factors for achieving Lean flow. In the next section, we will see how those factors work with other factors to determine whether your system has <span class="No-Break">Lean flow.</span></p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor099"/>Monitoring queues</h1>
			<p>To enable Lean flow, you need to closely examine queueing theory, the mathematical field behind the behavior of queues and waiting in line (think Starbucks or the <a id="_idIndexMarker314"/>checkout area of your local supermarket!). A number <a id="_idIndexMarker315"/>of mathematical formulas will be useful in helping us make sure we understand what we have to do to ensure Lean flow. <span class="No-Break">These are:</span></p>
			<ul>
				<li><span class="No-Break">Little’s Law</span></li>
				<li><span class="No-Break">Kingman’s Formula</span></li>
			</ul>
			<p>Let’s see how we can use these elements of queueing theory to enable <span class="No-Break">Lean flow.</span></p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor100"/>Where are our queues?</h2>
			<p>A key difference between product development queues and product manufacturing queues is that the <a id="_idIndexMarker316"/>artifacts of product development (particularly software development) are not physical and it is <a id="_idIndexMarker317"/>difficult to grasp the progress until completion, whereas in manufacturing, you can visually ascertain the completeness of a product while on the factory floor. This <em class="italic">invisibility factor</em> makes it easy to ignore these queues, often at your <span class="No-Break">own peril.</span></p>
			<p>Long queues unrestrained by WIP limits or small batch sizes create an array of problems, as summarized by Reinertsen. These problems include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Longer <span class="No-Break">cycle times</span></li>
				<li><span class="No-Break">More risk</span></li>
				<li><span class="No-Break">More overhead</span></li>
				<li><span class="No-Break">More variability</span></li>
				<li><span class="No-Break">Lower quality</span></li>
				<li><span class="No-Break">Lower motivation</span></li>
			</ul>
			<p>We’ve talked about problems with overhead, risk, and quality when talking about large batch sizes. If we consider the size of our work as the queue for our system, then the mathematical formulas that we will examine later are applicable and can model the state of our <span class="No-Break">Lean flow.</span></p>
			<p>How can long queues lower workplace motivation? Imagine a scenario where you were preparing work and <a id="_idIndexMarker318"/>the next part of the process was ready whenever you finished it. There would be a sense of urgency to finish your part of the work. That sense of urgency would not be there if, after you delivered your work, it sat behind a queue of other items and wouldn’t be seen <span class="No-Break">for weeks.</span></p>
			<p>Now that we’ve established our batch sizes and WIP as queues, it’s time to see how mathematical formulas illustrate the relationship between our queues and cycle time <span class="No-Break">and variability.</span></p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor101"/>Little’s Law and cycle time</h2>
			<p>We have seen how both WIP and batch size correlate to cycle time, or the time it takes to deliver work once we’ve accepted it. Mathematically, cycle time, WIP, and batch size are tied using <span class="No-Break">Little’s Law.</span></p>
			<p>Little’s Law is an expression <a id="_idIndexMarker319"/>tying cycle time, WIP or batch size, and throughput. This expression <a id="_idIndexMarker320"/>for Little’s Law is <span class="No-Break">presented here:</span></p>
			<p><img src="image/Formula_04_001.png" alt=""/></p>
			<p><em class="italic">L</em> stands for the length of the queue. This can be thought of as either WIP or batch size. <em class="italic">L</em> is the throughput <a id="_idIndexMarker321"/>of work processed by the teams or ART. <em class="italic">W</em> gives you the cycle time or the wait time for <span class="No-Break">a customer.</span></p>
			<p>At this point, it’s simple mathematics if we’re concerned about finding out our cycle time. Written in the following manner, you can see that cycle time (<em class="italic">W</em>) is directly related to the size of our <span class="No-Break">queue (</span><span class="No-Break"><em class="italic">L</em></span><span class="No-Break">):</span></p>
			<p><img src="image/Formula_04_002.png" alt=""/></p>
			<p>A simple illustration of this is a backlog for a Scrum team. If their backlog has 9 user stories, each estimated at 5 story points, and their velocity (the measure of how many story points’ <a id="_idIndexMarker322"/>worth of work they have been able to deliver per sprint) is 15 story points per sprint, we can take Little’s Law to predict how many sprints it will take to complete that set of stories in the backlog, as illustrated in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/B18756_04_10.jpg" alt="Figure 4.10 – Illustration of Little’s Law"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.10 – Illustration of Little’s Law</p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor102"/>Kingman’s Formula </h2>
			<p>Kingman’s Formula is a <a id="_idIndexMarker323"/>mathematical model to describe how wait time <a id="_idIndexMarker324"/>equates to cycle time, variability, and utilization. The formula is <span class="No-Break">illustrated here:</span></p>
			<p><img src="image/Formula_04_003_-Part_1.png" alt=""/></p>
			<p>Each term in the formula represents an individual quantity. The first term <img src="image/Formula_04_003_-Part_11.png" alt=""/> represents the utilization of the people doing the work. The second term (<img src="image/Formula_04_003_-Part_2.png" alt=""/>) represents the variability of the system. The third term (<em class="italic">t</em>) represents the service time or the cycle time. </p>
			<p>We want to examine the relationship between wait time, utilization, variability, and cycle time. If we substitute a letter for each term, we get the following (simpler) equation, commonly referred to as the <span class="No-Break"><em class="italic">VUT equation</em></span><span class="No-Break">:</span></p>
			<p><img src="image/Formula_04_004.png" alt=""/></p>
			<p>So, this equation shows us that the total wait time for a customer is directly proportional to the utilization, variability, and <span class="No-Break">cycle time.</span></p>
			<p>We have <a id="_idIndexMarker325"/>previously looked at how queue size, batch sizes, and limiting WIP have an effect on cycle time. Let’s take a look at the other variables of Kingman’s Formula to see how utilization and variability can affect the <span class="No-Break">wait time.</span></p>
			<h3>Utilization and its effects</h3>
			<p>Let’s start with utilization. When we refer to utilization, we look at the percentage of the overall capacity of <a id="_idIndexMarker326"/>the system. A high utilization may be desired by <a id="_idIndexMarker327"/>management—after all, we don’t want our workers to goof off. But after <a id="_idIndexMarker328"/>looking at Kingman’s Formula, we see that wait time increases as utilization increases. We can see this effect by plotting out utilization in comparison to the queue size. The resulting curve is a nonlinear graph that starts to ascend around 60% utilization and approaches infinity at 100% utilization. This is seen in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B18756_04_11.jpg" alt="Figure 4.11 – Utilization compared to queue size"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.11 – Utilization compared to queue size</p>
			<p>Another way of looking at this percentage utilization is seeing it as a load/capacity. If load looks at the rate at which new work comes in, capacity looks at the rate at which work leaves and is delivered to the customer. This ensures adequate utilization so that we do not take in more work than we <span class="No-Break">can process.</span></p>
			<p>The idea that for <a id="_idIndexMarker329"/>Lean flow to occur, scheduling slack or idle time must be <a id="_idIndexMarker330"/>introduced to keep utilization at a reasonable level (for example, not at 100%) has its roots in the Toyota Production System. <em class="italic">Muri</em> or overburdening was seen as one of the three <em class="italic">wastes</em> to eliminate in Lean. We will look at another waste: <em class="italic">Mura</em>, or unevenness. We also call <span class="No-Break">this variability.</span></p>
			<h3>Variability, its effects, and actions</h3>
			<p>Let’s explain what variability is. So far, we’ve been making the assumption that, as <a id="_idIndexMarker331"/>with manufacturing products on a factory floor, all <a id="_idIndexMarker332"/>work involves the same effort. But this is often not <a id="_idIndexMarker333"/>the case. Each piece of work may involve different levels of effort or even different efforts. Some work may have unknowns that require a more detailed investigation. Some work may have defects. Variability is the quality that describes the <em class="italic">individuality</em> of each piece <span class="No-Break">of work.</span></p>
			<p>From Kingman’s Formula, we see that the effects of variability have a compounding effect on wait time. The curve in the following diagram shows the effects of high variability versus low variability when looking <span class="No-Break">at utilization:</span></p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B18756_04_12.jpg" alt="Figure 4.12 – Effects of variability on utilization and queue size"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.12 – Effects of variability on utilization and queue size</p>
			<p>We can see from the preceding diagram that this effect is linear, but the combination produces an undesired result. With high variability, working at somewhat lower utilization will not stem the growth of your queue. You’d have to work at much lower utilization to keep your queue in control. What can <span class="No-Break">you do?</span></p>
			<p>It’s important to <a id="_idIndexMarker334"/>understand that not all variability is bad. Some may <a id="_idIndexMarker335"/>be necessary to learn new things. So, the key is really to <a id="_idIndexMarker336"/>manage variability so that it doesn’t affect the queue size and, consequently, the wait time. Ways to do that include <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break">Limiting WIP</span></li>
				<li>Working with smaller <span class="No-Break">batch sizes</span></li>
				<li>Setting up buffers in <span class="No-Break">your system</span></li>
				<li>Establishing <span class="No-Break">standard processes</span></li>
			</ul>
			<p>We’ve spoken before about the benefits of limiting WIP and working with smaller batch sizes, so let’s examine some of the other ways we can <span class="No-Break">manage variability.</span></p>
			<h4>Setting up process buffers</h4>
			<p>Lean manufacturing <a id="_idIndexMarker337"/>looks to limit variability by setting up buffers. These buffers are used to limit the <span class="No-Break">following factors:</span></p>
			<ul>
				<li><span class="No-Break">Inventory</span></li>
				<li><span class="No-Break">Capacity</span></li>
				<li><span class="No-Break">Time</span></li>
			</ul>
			<p>In product development, WIP limits and small batch sizes act as inventory and capacity buffers accordingly. To set up a time buffer, you can establish buffer states on those WIP columns on your Kanban board where variability exists in your process. An example on our Kanban board is shown in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer054" class="IMG---Figure">
					<img src="image/B18756_04_13.jpg" alt="Figure 4.13 – Kanban board with buffer states in the Implement/Test column"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.13 – Kanban board with buffer states in the Implement/Test column</p>
			<p>Note that WIP limits <a id="_idIndexMarker338"/>are established in each buffer state to ensure throughput <span class="No-Break">is maintained.</span></p>
			<h4>Establishing standard processes</h4>
			<p>In the previous <a id="_idIndexMarker339"/>section, we discussed using several types of buffers to ensure that variability is managed at several stages of the process. The variability managed by buffers is often the type that is tolerated, even encouraged by the nature of <span class="No-Break">the work.</span></p>
			<p>Some variability, however, may exist due to inefficiencies in the development process. An example of this is encouraging one type of test to be automated—for example, unit tests for code—without striving to automate <strong class="bold">behavior-driven development</strong> (<strong class="bold">BDD</strong>) tests to ensure <a id="_idIndexMarker340"/>correctness. This has the effect of keeping cycle <span class="No-Break">times long.</span></p>
			<p>Establishing standard processes ensures the reduction of needless variability of cycle time. Standardizing processes includes establishing a standard, detecting any possible problems, and discovering the root cause of these <span class="No-Break">problems continuously.</span></p>
			<p>We’ve seen the practices you can use to model your development process to ensure that the work is progressing to completion. These practices need to be anchored by people that <a id="_idIndexMarker341"/>look at the entire process from start to finish. In the next section, we’ll take a closer look at establishing that viewpoint and the systemic <span class="No-Break">changes needed.</span></p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor103"/>Moving from project-based to product-based work</h1>
			<p>When adopting value stream thinking, it’s important to change the view and mindset of development <a id="_idIndexMarker342"/>from project-based management to <span class="No-Break">product-based management.</span></p>
			<p>In <em class="italic">Project to Product: How to Survive and Thrive in the Age of Digital Disruption with the Flow Framework</em>, Mik Kersten contrasts the success of integrating IT and software in assembling BMW models in Leipzig, Germany, with the failure of Nokia to continue its dominance in the smartphone industry as the iPhone and Android phones were introduced. He notes that although Nokia had successfully adopted Agile practices, it did not appear to foster change to the entire product development process or affect the entire organization. He identifies that for this <em class="italic">Age of Software</em>, product-oriented development using value streams allows for the creation and maintenance of <span class="No-Break">successful products.</span></p>
			<p>Mik Kersten highlights seven key categories where the differences between project-based management and product-based management are apparent. These differences are illustrated <span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break">Budgeting</span></li>
				<li><span class="No-Break">Timeframe</span></li>
				<li><span class="No-Break">Success</span></li>
				<li><span class="No-Break">Risk</span></li>
				<li><span class="No-Break">Team assignments</span></li>
				<li><span class="No-Break">Prioritization</span></li>
				<li><span class="No-Break">Visibility</span></li>
			</ul>
			<p>Let’s individually look at these <span class="No-Break">differences now.</span></p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor104"/>Project budgets versus value stream funding</h2>
			<p>In project management, the <em class="italic">iron triangle</em> is a well-known construct. In management, you look at <a id="_idIndexMarker343"/>three factors or <em class="italic">sides</em> to see whether you can fix one or more of them to bring a project or product to <a id="_idIndexMarker344"/>completion. These three factors are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Resources (people, equipment, facilities, and <span class="No-Break">so on)</span></li>
				<li><span class="No-Break">Scope</span></li>
				<li><span class="No-Break">Time</span></li>
			</ul>
			<p>A project budget is often a bet. Can the project do everything required (scope) in the projected timeframe (time) and <a id="_idIndexMarker345"/>with the projected resources? Because this budget is necessary for approvals, it is often a guess of the largest number of resources for the other parts of the triangle. Sometimes these guesses fall short, resulting in cost overruns and possibly another project (with <span class="No-Break">another budget).</span></p>
			<p>Funding for value streams is easier. Resources and time are kept constant over the period of the budget. At the <a id="_idIndexMarker346"/>end of the timeframe for the budget (often less than an annual basis; typically, quarterly) the results of the development and the customer feedback determine whether continued effort and capacity are needed to match the demand for delivered features. If so, a new budget with an increased allocation is created for the new <span class="No-Break">time period.</span></p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor105"/>Defined endpoint versus product life cycle</h2>
			<p>A defining characteristic of the project is its life cycle There is a beginning, with a flurry of activity to organize teams and get started. This then proceeds along with development, continuing until the project reaches its conclusion: the delivery of a product. At this point, the project is over. With the project and its funding at an end, the teams that <a id="_idIndexMarker347"/>developed the product are dispersed. The product goes to a dedicated maintenance team that may not have had a role in its development, consequently preventing learning from reaching the <span class="No-Break">entire organization.</span></p>
			<p>Value streams approach the timeline of the entire product <em class="italic">from cradle to grave</em>. The same teams and ARTs that develop and release the initial features of a product become responsible for its maintenance and ongoing health. Part of maintenance includes identifying and removing technical debt, resulting in keeping the product viable. This occurs until the product reaches the end of <span class="No-Break">its life.</span></p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor106"/>Cost centers versus business outcomes</h2>
			<p>Measurement of progress in project-based development is often aligned with how the cost centers that comprise teams are performing. This disjointed view of progress focuses on the performance of individual silos rather than the <span class="No-Break">entire system.</span></p>
			<p>Another consequence of this cost-center approach is that because the budgets tend to be large, the project stakeholders are drawn to create large projects as opposed to viewing the value of efforts <span class="No-Break">once delivered.</span></p>
			<p>Value streams use a different metric for success. They look at the outcomes produced by efforts delivered. By allowing for incremental delivery and learning from customer feedback, the value stream can adjust to deliver better <span class="No-Break">business outcomes.</span></p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor107"/>Upfront risk identification versus spreading risks</h2>
			<p>In project-based development, risks to delivery are identified as early as possible to create contingencies. But frequently, there are risks not identified due to the unknowns yet to be discovered when development <span class="No-Break">is underway.</span></p>
			<p>With product-based development, risks are identified as more learning occurs. Incremental <a id="_idIndexMarker348"/>delivery allows for pivots to occur at regular checkpoints. Although there may be overhead involved in these pivots, this overhead is spread out over the product life cycle and becomes a small fraction as it is distributed over that long period <span class="No-Break">of time.</span></p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor108"/>Moving people to the work versus moving work to the people</h2>
			<p>Project-based development creates teams from cost-center-based resource pools. This method of creating teams to work on projects assumes that individuals from the resource pools have identical talents and skills. This assumption is <span class="No-Break">never true.</span></p>
			<p>Another consequence of this reallocation of these individuals interferes with the team’s well-being <a id="_idIndexMarker349"/>and productivity. In 1965, psychologist Bruce Tuckman created the <strong class="bold">Forming, Storming, Norming, Performing, and Adjourning</strong> (<strong class="bold">FSNPA</strong>) model of team creation, illustrating the stages teams go through as they become high-performing. Constant reassignments and team shakeups impede the ability of the team to achieve a high-performing status where the team works as <span class="No-Break">one unit.</span></p>
			<p>Product-based development emphasizes long lifespans for teams. This allows teams to focus on acquiring product knowledge and grow together as one team. This improves the ability of the team to deliver and the <span class="No-Break">team’s morale.</span></p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor109"/>Performing to plan versus learning</h2>
			<p>In project-based development, adherence to the project plan is paramount. Adjustments to the plan result in cost overruns and reallocation of resources due to the overhead cost of performing <span class="No-Break">any changes.</span></p>
			<p>Product-based development welcomes changes by setting up piecemeal delivery of features and creates a space for learning and the validation of hypotheses. After the delivery of each increment of value, feedback and outcomes are collected and necessary adjustments <span class="No-Break">are made.</span></p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor110"/>Misalignment versus transparent business objectives</h2>
			<p>In project-based development, there is often a disconnect between the business stakeholders <a id="_idIndexMarker350"/>and the IT departments that develop products. This disconnect stems from IT’s focus on the product and the business side’s focus on completing the project through a progression of steps with no runway <span class="No-Break">for readjustment.</span></p>
			<p>With product-based development, the goals for both the business and IT development sides are the same: the fulfillment of business objectives. This transparency of the goal allows for alignment to occur and for easier sharing of progress <span class="No-Break">and feedback.</span></p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor111"/>Summary</h1>
			<p>In this chapter, we looked at Lean flow as part of the CALMR model. We know that achieving a Lean flow of work where the progression of work is steady and teams are neither overburdened nor underburdened allows for the success of the other parts of the model. To that end, we took a close look at Lean practices that allow teams to achieve <span class="No-Break">Lean flow.</span></p>
			<p>The first practice we investigated was to make sure that all the work a team commits to and its progress are visible. To ensure this visibility, we looked at the types of work a team could do. We then mapped that work to a Kanban board, highlighting the features of the board that allow us to see the progress for any one piece of work and where urgent work could go. We saw how we can visualize WIP on the Kanban board and how to keep WIP in check using <span class="No-Break">WIP limits.</span></p>
			<p>From there, we took a look at the size of the work or batch size. We strove to understand the importance of making sure the batch size was as small as possible. We looked at the relationship batch size had with cycle time, WIP, and performance. With this in mind, we looked at the economics of batch size and how you could determine the ideal batch size through <span class="No-Break">u-curve optimization.</span></p>
			<p>We then looked at other factors at play by looking closely at queueing theory. We saw how Little’s Law describes the relationship between cycle time and WIP or batch size.  We saw the other factors and how they related to cycle time by examining Kingman’s Formula. Approaching one of these factors, utilization, we saw how cycle times increased with high utilization. We also learned more about the other factor, variability, and how to <span class="No-Break">manage it.</span></p>
			<p>Finally, to allow value streams to deliver work through Lean flow, we looked at the differences between project-based development and product-based development. These differences create stronger teams and stronger products in shorter <span class="No-Break">cycle times.</span></p>
			<p>To ensure that work is progressing in Lean flow, we need to take regular measurements. We also want to make sure that whatever is delivered does not adversely affect the staging and production environments. To do this, we will examine measurement, the next element of our CALMR model, in the <span class="No-Break">next chapter.</span></p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor112"/>Questions</h1>
			<p>Test your knowledge of the concepts in this chapter by answering <span class="No-Break">these questions.</span></p>
			<ol>
				<li>Which of these are types of enablers in SAFe (<span class="No-Break">pick two)?</span><ol><li><span class="No-Break">Exploration</span></li><li><span class="No-Break">Measurement</span></li><li><span class="No-Break">Visualization</span></li><li><span class="No-Break">Compliance</span></li><li><span class="No-Break">Actual</span></li></ol></li>
				<li>Which feature of a Kanban board can be used to visualize work that <span class="No-Break">is urgent?</span><ol><li><span class="No-Break">WIP limits</span></li><li>An <span class="No-Break">expedite lane</span></li><li><span class="No-Break">Column policy</span></li><li>Expanded <span class="No-Break">workflow columns</span></li></ol></li>
				<li>What is a consequence of too <span class="No-Break">much WIP?</span><ol><li>Too <span class="No-Break">much multitasking</span></li><li>Reduced <span class="No-Break">cycle times</span></li><li>Newer work gets started after older work <span class="No-Break">is completed</span></li><li><span class="No-Break">Short queues</span></li></ol></li>
				<li>What results from large <span class="No-Break">batch sizes?</span><ol><li><span class="No-Break">Low WIP</span></li><li><span class="No-Break">Decreased risk</span></li><li>High <span class="No-Break">cycle times</span></li><li><span class="No-Break">High performance</span></li></ol></li>
				<li>According to Reinertsen, long queues lead to which problems (<span class="No-Break">pick two)?</span><ol><li>Shorter <span class="No-Break">cycle times</span></li><li><span class="No-Break">Higher overhead</span></li><li><span class="No-Break">Less risk</span></li><li><span class="No-Break">Higher quality</span></li><li><span class="No-Break">More variability</span></li></ol></li>
				<li>Which of these is a method for <span class="No-Break">managing variability?</span><ol><li>Larger <span class="No-Break">batch sizes</span></li><li><span class="No-Break">Establishing buffers</span></li><li>“<span class="No-Break">One-off” processes</span></li><li><span class="No-Break">Increasing WIP</span></li></ol></li>
				<li>According to Mik Kersten, which of these is present in <span class="No-Break">product-based development?</span><ol><li>Moving the people to <span class="No-Break">the work</span></li><li>Identifying all <span class="No-Break">risks upfront</span></li><li>Focus on <span class="No-Break">business outcomes</span></li><li><span class="No-Break">Project planning</span></li></ol></li>
			</ol>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor113"/>Further reading</h1>
			<p>Here are some resources for you to explore this <span class="No-Break">topic further:</span></p>
			<ul>
				<li><em class="italic">Making Work Visible: Exposing Time Theft to Optimize Work and Flow</em> by <em class="italic">Dominica DeGrandis</em>: A look at five time thieves and how Lean practices can remove them. Too much WIP is identified as one of these <span class="No-Break">time thieves.</span></li>
				<li><em class="italic">The Goal</em> by <em class="italic">Eliyahu M. Goldratt</em>: A look at the Theory of Constraints and how to eliminate bottlenecks in <span class="No-Break">your process.</span></li>
				<li><em class="italic">Kanban: Successful Evolutionary Change for Your Technology Business</em> by <em class="italic">David J. Anderson</em>: The authoritative source on Kanban.  Further exploration of the Kanban board and limiting WIP can be <span class="No-Break">found here.</span></li>
				<li><em class="italic">The Principles of Product Development Flow: Second Generation Lean Product Development</em> by <em class="italic">Donald Reinertsen</em>: An exhaustive look at the economics behind Lean practices in this chapter, whether limiting WIP, identifying the ideal batch size, or the effects of utilization and variability the effects of utilization <span class="No-Break">and variability.</span></li>
				<li><em class="italic">Project to Product: How to Survive and Thrive in the Age of Digital Disruption with the Flow Framework</em> by <em class="italic">Mik Kersten</em>: A look at value streams and measuring <span class="No-Break">their performance.</span></li>
				<li>A look at teamwork models including the FSNPA model from Bruce <span class="No-Break">Tuckman: </span><a href="https://www.atlassian.com/blog/teamwork/what-strong-teamwork-looks-like"><span class="No-Break">https://www.atlassian.com/blog/teamwork/what-strong-teamwork-looks-like</span></a></li>
			</ul>
		</div>
	</body></html>