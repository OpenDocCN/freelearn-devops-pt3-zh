- en: 'Chapter 9: Observability with OpenTelemetry'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第九章：使用 OpenTelemetry 进行可观察性
- en: In the early hours of the morning as you are sleeping in bed, your phone starts
    to ring. It's not the normal ring that you've set for friends and family but the
    red-alert ring you set for emergencies. As you are startled awake by the noise,
    you begin to come to your senses. You think of the recent release of your company's
    application. A sense of dread fills you as you pick up the call to be greeted
    by the automated voice on the other end, informing you that you've been requested
    to join a priority video conference with a team debugging a live site problem
    with the new release. You get out of bed quickly and join the call.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在清晨，你正安然入睡时，手机突然响起。这不是你为朋友和家人设置的正常铃声，而是你为紧急情况设置的红色警报铃声。被铃声惊醒后，你开始逐渐清醒。你想到公司最近发布了新的应用程序，心中充满了一种不祥的预感。你接起电话，自动语音告知你需要加入一个优先级视频会议，会议中有一个团队正在调试新发布版本的在线问题。你迅速起床并加入了会议。
- en: Once you are on the call, you are greeted by the on-call triage team. The triage
    team informs you that the application is experiencing a service outage affecting
    one of your largest customers, which represents a substantial portion of your
    company's revenue. This outage has been escalated by the customer to the highest
    levels of your company. Even your CEO is aware of the outage. The triage team
    is unable to determine the cause of the downtime and has called you in to help
    mitigate the issue and determine the root cause of the outage.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦接到电话，你会看到接诊团队的成员正在等待你。接诊团队告诉你，应用程序正遇到一次影响公司最大客户之一的服务故障，而该客户的损失占公司收入的很大一部分。这个故障已经被客户上报到了公司最高层，连
    CEO 都知道这件事。接诊团队无法确定故障的原因，已经请你来帮助缓解问题，并找出故障的根本原因。
- en: You go to work to determine the root cause. You open your administrative dashboard
    for the application but find no information about the application. There are no
    logs, no traces, and no metrics. The application is not emitting telemetry to
    help you to debug the outage. You are effectively blind to the runtime behavior
    of the application and what is causing the outage. A feeling of overwhelming terror
    fills you as you fear this could be the end of your company if you are unable
    to determine what is causing the outage.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你去工作是为了确定根本原因。你打开应用程序的管理仪表盘，却发现没有关于应用程序的任何信息。没有日志，没有追踪，没有指标。应用程序没有发送遥测数据来帮助你调试故障。你基本上对应用程序的运行时行为以及造成故障的原因一无所知。你感到一种无法抗拒的恐惧，害怕如果找不到故障原因，这可能意味着公司将面临终结。
- en: Right about then is when I wake up. What I've just described is a reoccurring
    nightmare I have about waking up to an outage and not having the information I
    need to determine the runtime state of my application.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 就在这时，我醒了过来。我刚才描述的，正是我经常做的噩梦：醒来时发现系统出现故障，而我没有足够的信息来确定应用程序的运行时状态。
- en: Without being able to introspect the runtime state of your application, you
    are effectively blind to what may be causing abnormal behaviors in the application.
    You are unable to diagnose and quickly mitigate issues. It is a profoundly helpless
    and terrifying position to be in during an outage.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果无法查看应用程序的运行时状态，你就无法洞察可能导致应用程序异常行为的原因。你无法诊断并迅速缓解问题。在故障发生时，这种情况会让你感到非常无助和恐惧。
- en: 'Observability is the ability to measure the internal state of an application
    by measuring outputs from that application and infrastructure. We will focus on
    three outputs from an application: logs, traces, and metrics. In this chapter,
    you will learn how to instrument, generate, collect, and export telemetry data
    so that you will never find yourself in a situation where you do not have insight
    into the runtime behavior of your application. We will use OpenTelemetry SDKs
    to instrument a Go client and server so that the application will emit telemetry
    to the OpenTelemetry Collector service. The OpenTelemetry Collector service will
    transform and export that telemetry data to backend systems to enable visualization,
    analysis, and alerting.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性是通过测量应用程序和基础设施的输出，来了解应用程序的内部状态。我们将重点关注应用程序的三种输出：日志、追踪和指标。在这一章中，你将学习如何为应用程序添加监控，生成、收集并导出遥测数据，这样你就再也不会陷入无法了解应用程序运行时行为的境地。我们将使用
    OpenTelemetry SDK 来为 Go 客户端和服务器添加监控，使应用程序能将遥测数据发送到 OpenTelemetry Collector 服务。OpenTelemetry
    Collector 服务将转换并导出这些遥测数据到后端系统，便于可视化、分析和告警。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: An introduction to OpenTelemetry
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenTelemetry 简介
- en: Logging with context
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带上下文的日志记录
- en: Instrumenting for distributed tracing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于分布式追踪的工具化
- en: Instrumenting for metrics
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于指标的工具化
- en: Alerting on metrics abnormalities
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对指标异常的告警
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter will require Docker and Docker Compose.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要 Docker 和 Docker Compose。
- en: Let's get started by learning about OpenTelemetry, its components, and how OpenTelemetry
    can enable a vendor-agnostic approach to observability. The code used in this
    chapter is derived from [https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo)
    with some changes made to provide additional clarity.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解 OpenTelemetry、其组件以及 OpenTelemetry 如何使得观察性采取与供应商无关的方式开始。本章中使用的代码源自 [https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo)，并进行了一些更改，以提供额外的清晰度。
- en: The code files for this chapter can be downloaded from [https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以从 [https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9)
    下载
- en: An introduction to OpenTelemetry
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenTelemetry 简介
- en: OpenTelemetry began as a project to merge the OpenTracing and OpenCensus projects
    to create a single project to achieve their shared mission of high-quality telemetry
    for all. OpenTelemetry is a vendor-agnostic set of specifications, APIs, SDKs,
    and tooling designed for the creation and management of telemetry data. OpenTelemetry
    empowers projects to collect, transform, and export telemetry data such as logs,
    traces, and metrics to the backend systems of choice.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 最初是一个将 OpenTracing 和 OpenCensus 项目合并的项目，旨在创建一个单一项目，完成它们共同的使命——为所有提供高质量的遥测数据。OpenTelemetry
    是一套与供应商无关的规范、API、SDK 和工具，旨在用于遥测数据的创建和管理。OpenTelemetry 使项目能够收集、转换并导出日志、追踪和指标等遥测数据到所选择的后端系统。
- en: 'OpenTelemetry features the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 具备以下功能：
- en: Instrumentation libraries for the most popular programming languages with both
    automatic and manual instrumentation
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为最流行的编程语言提供的工具库，支持自动和手动工具化
- en: A single collector binary that can be deployed in a variety of ways
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以以多种方式部署的单一采集器二进制文件
- en: Pipelines for collecting, transforming, and exporting telemetry data
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于收集、转换和导出遥测数据的管道
- en: A set of open standards to protect against vendor lock-in
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一套开放标准，防止供应商锁定
- en: In this section, we will learn about the OpenTelemetry stack and the components
    we can use to make our complex systems observable.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解 OpenTelemetry 技术栈以及我们可以用来使复杂系统可观测的组件。
- en: Reference architecture for OpenTelemetry
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenTelemetry 的参考架构
- en: 'Next, let''s take a look at a conceptual reference architecture diagram for
    **OpenTelemetry** (**OTel**):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看**OpenTelemetry**（**OTel**）的概念性参考架构图：
- en: '![Figure 9.1 – OpenTelemetry reference architecture'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.1 – OpenTelemetry 参考架构'
- en: '](img/B17626_09_001.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17626_09_001.jpg)'
- en: Figure 9.1 – OpenTelemetry reference architecture
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – OpenTelemetry 参考架构
- en: The preceding reference architecture diagram shows two applications instrumented
    with the OTel libraries running on hosts, with the OTel Collector deployed as
    an agent on the hosts. The OTel Collector agents are collecting traces and metrics
    from the applications as well as logs from the host. The OTel Collector on the
    left host is exporting telemetry to Backend 1 and Backend 2\. On the right side,
    the OTel Collector agent is receiving telemetry from the OTel instrumented application,
    collecting telemetry from the host, and then forwarding the telemetry to an OTel
    Collector running as a service. The OTel Collector running as a service is exporting
    telemetry to Backend 1 and Backend 2\. This reference architecture illustrates
    how the OTel Collector can be deployed as both an agent on a host and a service
    for collecting, transforming, and exporting telemetry data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 上述参考架构图展示了两个应用程序，这些应用程序使用 OTel 库并运行在主机上，同时 OTel Collector 被部署为主机上的代理。OTel Collector
    代理收集来自应用程序的跟踪和度量数据以及来自主机的日志数据。左侧主机上的 OTel Collector 正在将遥测数据导出到 Backend 1 和 Backend
    2。在右侧，OTel Collector 代理从 OTel 仪表化的应用程序接收遥测数据，收集来自主机的遥测数据，然后将遥测数据转发给作为服务运行的 OTel
    Collector。作为服务运行的 OTel Collector 将遥测数据导出到 Backend 1 和 Backend 2。此参考架构图示了 OTel
    Collector 如何既可以作为主机上的代理部署，也可以作为服务部署，用于收集、转换和导出遥测数据。
- en: The wire protocol the telemetry is being transmitted on is intentionally missing
    from the reference architecture diagram, since the OTel Collector is capable of
    accepting multiple telemetry input formats. For existing applications, accepting
    existing formats such as Prometheus, Jaeger, and Fluent Bit can make it easier
    to migrate to OpenTelemetry. For new applications, the OpenTelemetry wire protocol
    is preferred and simplifies collector configuration for ingesting telemetry data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 参考架构图中故意没有显示遥测数据传输所用的网络协议，因为 OTel Collector 能够接收多种遥测输入格式。对于现有应用程序，接受如 Prometheus、Jaeger
    和 Fluent Bit 等现有格式，可以使迁移到 OpenTelemetry 更加容易。对于新应用程序，推荐使用 OpenTelemetry 网络协议，它简化了遥测数据摄取的收集器配置。
- en: OpenTelemetry components
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenTelemetry 组件
- en: OpenTelemetry is composed of several components that form the telemetry stack.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 由几个组件组成，构成了遥测堆栈。
- en: OpenTelemetry specification
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenTelemetry 规范
- en: 'The OpenTelemetry specification describes the expectations and requirements
    for cross-language implementations using the following terms:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 规范描述了跨语言实现的期望和要求，并使用以下术语进行说明：
- en: '**API**: Defines the data types and operations for generating and correlating
    tracing, metrics, and logging.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API**：定义了用于生成和关联跟踪、度量和日志的数据类型和操作。'
- en: '**SDK**: Defines the implementation of the API in a specific languages. This
    includes configuration, processing, and exporting.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SDK**：定义了在特定语言中实现 API 的方式，包括配置、处理和导出。'
- en: '**Data**: Defines the **OpenTelemetry Line Protocol** (**OTLP**), a vendor-agnostic
    protocol for communicating telemetry.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据**：定义了 **OpenTelemetry 行协议**（**OTLP**），这是一个与供应商无关的用于传输遥测数据的协议。'
- en: For more information about the specification, see [https://opentelemetry.io/docs/reference/specification/](https://opentelemetry.io/docs/reference/specification/).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于规范的信息，请参见 [https://opentelemetry.io/docs/reference/specification/](https://opentelemetry.io/docs/reference/specification/)。
- en: OpenTelemetry Collector
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenTelemetry Collector
- en: 'The OTel Collector is a vendor-agnostic proxy that can receive telemetry data
    in multiple formats, transform and process it, and export it in multiple formats
    to be consumed by multiple backends (such as Jaeger, Prometheus, other open source
    backends, and many proprietary backends). The OTel Collector is composed of the
    following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: OTel Collector 是一个与供应商无关的代理，可以接收多种格式的遥测数据，进行转换和处理，并以多种格式导出，以供多个后端（例如 Jaeger、Prometheus、其他开源后端以及许多专有后端）使用。OTel
    Collector 由以下部分组成：
- en: '**Receivers**: Push- or pull-based processors for collecting data'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**接收器**：用于收集数据的推送或拉取型处理器'
- en: '**Processors**: Responsible for transforming and filtering data'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理器**：负责转换和过滤数据'
- en: '**Exporters**: Push- or pull-based processors for exporting data'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**出口器**：用于导出数据的推送或拉取型处理器'
- en: Each of the preceding components is enabled through pipelines described in YAML
    configurations. To learn more about data collection, see [https://opentelemetry.io/docs/concepts/data-collection/](https://opentelemetry.io/docs/concepts/data-collection/).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上述每个组件都通过 YAML 配置中描述的管道来启用。要了解更多关于数据收集的信息，请参见 [https://opentelemetry.io/docs/concepts/data-collection/](https://opentelemetry.io/docs/concepts/data-collection/)。
- en: Language SDKs and automatic instrumentation
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言 SDK 和自动仪表化
- en: Each supported language in OpenTelemetry offers an SDK that enables application
    developers to instrument their applications to emit telemetry data. The SDKs also
    offer some common components that aid in instrumenting applications. For example,
    in the Go SDK, there are wrappers for HTTP handlers that will provide instrumentation
    out of the box. Additionally, some language implementations also offer automatic
    instrumentation that can take advantage of language-specific features to collect
    telemetry data, without the need of manually instrumenting application code.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 中支持的每种语言都提供一个 SDK，帮助应用程序开发人员将他们的应用程序仪表化以发出遥测数据。SDK 还提供一些常见组件，帮助仪表化应用程序。例如，在
    Go SDK 中，有用于 HTTP 处理程序的包装器，能够开箱即用地提供仪表化功能。此外，一些语言实现还提供自动仪表化，能够利用特定语言的特性收集遥测数据，而无需手动仪表化应用程序代码。
- en: For more information about instrumenting applications, see [https://opentelemetry.io/docs/concepts/instrumenting-library/](https://opentelemetry.io/docs/concepts/instrumenting-library/).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有关应用程序仪表化的更多信息，请参见 [https://opentelemetry.io/docs/concepts/instrumenting-library/](https://opentelemetry.io/docs/concepts/instrumenting-library/)。
- en: The correlation of telemetry
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 遥测的关联性
- en: 'The correlation of telemetry is a killer feature for any telemetry stack. The
    correlation of telemetry data enables us to determine what events are related
    to each other across application boundaries and is the key to building insights
    into complex systems. For example, imagine we have a system composed of multiple
    interdependent micro-services. Each of these services could be running on multiple
    different hosts and possibly authored using different languages. We need to be
    able to correlate a given HTTP request and all subsequent requests across our
    multiple services. This is what correlation in OpenTelemetry enables. We can rely
    on OpenTelemetry to establish a correlation ID across these disparate services
    and provide a holistic view of events taking place within a complex system:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 遥测数据的关联性是任何遥测堆栈的核心特性。遥测数据的关联使我们能够确定跨越应用边界的事件之间的关系，这是构建复杂系统洞察的关键。例如，假设我们有一个由多个相互依赖的微服务组成的系统。每个服务可能运行在多个不同的主机上，并且可能使用不同的编程语言开发。我们需要能够关联一个给定的
    HTTP 请求以及随后的所有请求，跨越我们的多个服务。这就是 OpenTelemetry 中遥测关联的作用。我们可以依靠 OpenTelemetry 在这些不同的服务之间建立一个关联
    ID，并提供对复杂系统中发生事件的整体视图：
- en: '![Figure 9.2 – Correlated telemetry'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.2 – 关联遥测'
- en: '](img/B17626_09_002.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17626_09_002.jpg)'
- en: Figure 9.2 – Correlated telemetry
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 关联遥测
- en: In this section, we have introduced the main concepts in the OpenTelemetry stack.
    In the next sections, we will learn more about logging, tracing, and metrics and
    how we can use OpenTelemetry to create an observable system.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了 OpenTelemetry 堆栈中的主要概念。在接下来的章节中，我们将深入学习日志记录、追踪和度量，以及如何使用 OpenTelemetry
    创建一个可观察的系统。
- en: Logging with context
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带上下文的日志记录
- en: Logging is probably the most familiar form of telemetry. You probably started
    logging in the first program you ever authored when you printed `Hello World!`
    to `STDOUT`. Logging is the most natural first step in providing some data about
    the internal state of an application to an observer. Think about how many times
    you have added a print statement to your application to determine the value of
    a variable. You were logging.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录可能是最熟悉的遥测形式。当你第一次编写程序时，可能就通过打印 `Hello World!` 到 `STDOUT` 来开始记录日志。日志记录是向观察者提供应用程序内部状态数据的最自然的第一步。想想你有多少次在应用程序中添加打印语句来确定变量的值。你在做的就是日志记录。
- en: Printing simple log statements such as `Hello World!` can be helpful for beginners,
    but it does not provide the critical data we require to operate complex systems.
    Logs can be powerful sources of telemetry data when they are enriched with data
    to provide context for the events they are describing. For example, if our log
    statements include a correlation ID in the log entry, we can use that data to
    associate the log entry with other observability data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 打印简单的日志语句，例如 `Hello World!`，对初学者可能有帮助，但它并没有提供我们操作复杂系统所需的关键数据。当日志被丰富以提供描述事件的上下文时，日志可以成为遥测数据的强大来源。例如，如果我们的日志条目中包含一个关联
    ID，我们可以使用该数据将日志条目与其他可观察性数据关联起来。
- en: Application or system logs often consist of timestamped text records. These
    records come in a variety of structures, ranging from completely unstructured
    text to highly structured schemas with attached metadata. Logs are output in a
    variety of ways – single files, rotated files, or even to `STDOUT`. We need to
    be able to gather logs from multiple sources, transform and extract log data in
    a consumable format, and then export that transformed data for consumption/indexing.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序或系统日志通常由带时间戳的文本记录组成。这些记录具有不同的结构，从完全无结构的文本到附带元数据的高度结构化模式都有。日志可以通过多种方式输出——单个文件、旋转文件，甚至输出到`STDOUT`。我们需要能够从多个来源收集日志，转换并提取可消费格式的日志数据，然后将转换后的数据导出以供消费/索引。
- en: In this section, we will discuss how to improve our logging, moving from plain
    text to structured log formats, and how to consume and export various log formats
    using OpenTelemetry. We will learn using Go, but the concepts presented are applicable
    to any language.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何改进日志记录，从纯文本到结构化日志格式的过渡，以及如何使用OpenTelemetry消费和导出各种日志格式。我们将使用Go语言进行学习，但所介绍的概念适用于任何语言。
- en: Our first log statement
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的第一条日志语句
- en: 'Let''s start by using the standard Go log and write `Hello World!`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从使用标准的Go日志开始，输出`Hello World!`：
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding `Println` statement outputs `2009/11/10 23:00:00 Hello World!`
    when run in [https://go.dev/play/p/XH5JstbL7Ul](https://go.dev/play/p/XH5JstbL7Ul).
    Observe the plain text structure of the output and think about what you would
    need to do to parse the text to extract a structured output. It would be a relatively
    simple regular expression to parse, but with the addition of new data, the parse
    structure would change, breaking the parser. Additionally, there is very little
    context regarding the event or the context in which this event occurred.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的`Println`语句在[https://go.dev/play/p/XH5JstbL7Ul](https://go.dev/play/p/XH5JstbL7Ul)中运行时输出`2009/11/10
    23:00:00 Hello World!`。观察输出的纯文本结构，并思考需要做什么才能解析文本并提取结构化的输出。解析起来可能是一个相对简单的正则表达式，但随着新数据的加入，解析结构会发生变化，导致解析器出错。此外，输出中几乎没有关于事件或该事件发生时上下文的任何信息。
- en: The Go standard library logger has several other functions available, but we
    will not dive deeply into them here. If you are interested in learning more, I
    suggest you read [https://pkg.go.dev/log](https://pkg.go.dev/log). For the rest
    of this section, we will focus on structured and leveled loggers as well as the
    API described by [https://github.com/go-logr/logr](https://github.com/go-logr/logr).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Go标准库的日志记录器有几个其他可用的功能，但我们在这里不会深入探讨。如果你有兴趣了解更多，我建议你阅读[https://pkg.go.dev/log](https://pkg.go.dev/log)。在本节的其余部分，我们将专注于结构化和分级日志记录器以及由[https://github.com/go-logr/logr](https://github.com/go-logr/logr)描述的API。
- en: Structured and leveled logs with Zap
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Zap的结构化和分级日志
- en: Structured loggers have several benefits over text loggers. Structured logs
    have a defined schema of keys and values that can be more easily parsed than plain
    text. You can take advantage of the keys and values to embed rich information
    such as a correlation ID or other useful contextual information. Additionally,
    you can filter out keys that might not be applicable given the log context.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化日志记录器相比文本日志记录器有几个优势。结构化日志具有定义的键值模式，比纯文本更容易解析。你可以利用这些键值嵌入丰富的信息，例如关联ID或其他有用的上下文信息。此外，你可以过滤掉在特定日志上下文中可能不适用的键。
- en: V-levels are an easy way to control the amount of information in a log. For
    example, an application may output extremely verbose debug logs at the -1 log
    level but only critical errors at a log level of 4.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: V级别是控制日志中信息量的简单方法。例如，一个应用程序可能在-1级别输出极为冗长的调试日志，而在4级别时仅输出关键错误。
- en: There has been a movement in the Go community to standardize the structured
    and leveled log interface via [https://github.com/go-logr/logr](https://github.com/go-logr/logr).
    There are many libraries that implement the API described in the `logr` project.
    For our purposes, we'll focus on a single structured logging library, Zap, which
    also has a `logr` API implementation ([https://github.com/go-logr/zapr](https://github.com/go-logr/zapr)).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go社区中，已有一个运动旨在通过[https://github.com/go-logr/logr](https://github.com/go-logr/logr)标准化结构化和分级日志接口。许多库实现了`logr`项目中描述的API。为了我们的目的，我们将专注于一个结构化日志库——Zap，它也实现了`logr`
    API（[https://github.com/go-logr/zapr](https://github.com/go-logr/zapr)）。
- en: 'Let''s take a look at the key functions in the Zap logger interface:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下Zap日志记录器接口中的关键功能：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding interface provides an easy-to-use strongly typed set of logging
    primitives. Let''s see an example of structured logging with Zap:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 上述接口提供了一组易于使用且强类型的日志记录原语。让我们看看使用 Zap 进行结构化日志记录的示例：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The JSON structured output of the logger provides helpful, easy-to-parse, and
    contextual information through strongly typed keys and values. In the tracing
    section of this chapter, we will use these additional keys and values to embed
    correlation IDs to link our distributed traces with our logs. If you'd like to
    give it a go, see [https://go.dev/play/p/EVQPjTdAwX_U](https://go.dev/play/p/EVQPjTdAwX_U).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录器的 JSON 结构化输出通过强类型的键值对提供有用、易于解析的上下文信息。在本章的追踪部分，我们将使用这些额外的键值对来嵌入关联 ID，以便将我们的分布式追踪与日志关联。如果你想尝试一下，可以查看[https://go.dev/play/p/EVQPjTdAwX_U](https://go.dev/play/p/EVQPjTdAwX_U)。
- en: We will not dive deeply into where to output logs (such as a filesystem, `STDOUT`,
    and `STDERR`) but instead assume that the application logs we wish to ingest will
    have a file representation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入讨论日志输出的位置（如文件系统、`STDOUT`和`STDERR`），而是假设我们希望摄取的应用程序日志将具有文件表示形式。
- en: Now that we are producing structured logs in our application, we can shift gears
    to ingesting, transforming, and exporting logs using OpenTelemetry.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在应用程序中生成了结构化日志，可以切换到使用 OpenTelemetry 来摄取、转换和导出日志。
- en: Ingesting, transforming, and exporting logs using OpenTelemetry
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 OpenTelemetry 摄取、转换和导出日志
- en: In this example of using OpenTelemetry for ingesting, transforming, and exporting
    logs, we will use `docker-compose` to set up an environment that will simulate
    a Kubernetes host, with logs stored under `/var/logs/pods/*/*/*.log`. The OTel
    Collector will act as an agent running on the host. The logs will be ingested
    from the files in the log path, routed to appropriate operators in the `filelog`
    receiver, parsed per their particular format, have parsed attributes standardized,
    and then exported to `STDOUT` through the `logging` exporter.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个使用 OpenTelemetry 来摄取、转换和导出日志的示例中，我们将使用`docker-compose`来设置一个环境，模拟一个 Kubernetes
    主机，日志存储在`/var/logs/pods/*/*/*.log`路径下。OTel Collector 将作为在主机上运行的代理。日志将从日志路径中的文件中摄取，路由到`filelog`接收器中的适当操作员，按其特定格式进行解析，解析后的属性将标准化，然后通过`logging`导出器导出到`STDOUT`。
- en: 'For this demo we will using the code at: [https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/logging](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/logging).
    Now let’s take a quick look at the layout of the demo directory:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本次演示将使用以下代码：[https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/logging](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/logging)。现在，让我们快速查看一下演示目录的布局：
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `docker-compose.yml` file contains the service definition where we will
    run the OTel Collector and mount the collector configuration and log files directory,
    `varlogpods`, to simulate the collector running on a Kubernetes host. Let''s take
    a look at `docker-compose.yml`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-compose.yml`文件包含了我们将运行 OTel Collector 的服务定义，并且挂载了 Collector 配置文件和日志文件目录`varlogpods`，以模拟
    Collector 在 Kubernetes 主机上的运行。让我们来看看`docker-compose.yml`：'
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To run this demo, move to the chapter source code, `cd` into the `logging` directory,
    and run `docker-compose up`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此演示，请进入章节的源代码，`cd`进入`logging`目录，然后运行`docker-compose up`。
- en: OTel Collector configuration
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OTel Collector 配置
- en: 'The OTel Collector configuration file contains the directives for how the agent
    is to ingest, process, and export the logs. Let''s dive into the configuration
    and break it down:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: OTel Collector 配置文件包含了代理如何摄取、处理和导出日志的指令。让我们深入了解配置并逐步解析：
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `receivers` section contains a single `filelog` receiver that specifies
    the directories to include and exclude. The `filelog` receiver will start from
    the beginning of each log file and include the file path for metadata extraction
    in the operators. Next, let''s continue to the operators:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`receivers`部分包含一个单一的`filelog`接收器，指定了要包含和排除的目录。`filelog`接收器将从每个日志文件的开头开始，并在操作符中包含文件路径以提取元数据。接下来，让我们继续看看操作符部分：'
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The filelog operators define a series of steps for processing the log files.
    The initial step is a router operation that will determine, based on the body
    of the log file, which parser will handle the log body entry specified in the
    output of the operator. Each parser operator will extract the timestamp from each
    record, according to the particular format of the log entry. Let''s now continue
    to the parsers to see how the parser will extract information from each log entry
    once routed:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: filelog 操作符定义了一系列用于处理日志文件的步骤。初始步骤是一个路由操作，它将根据日志文件的主体内容，确定哪个解析器处理操作符输出中指定的日志主体条目。每个解析器操作符将根据日志条目的特定格式，从每个记录中提取时间戳。现在让我们继续看解析器，看看一旦路由完成，解析器如何从每个日志条目中提取信息：
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For example, the `parser-crio` operator will perform a regular expression on
    each log entry, parsing a time variable from the entry and specifying the time
    format for the extracted string. Contrast `parser-crio` with the `parser-docker`
    operator, which uses a JSON structured log format that has a JSON key of `time`
    in each log entry. The `parser-docker` operator only provides the key for the
    JSON entry and the layout of the string. No regex is needed with the structured
    log. Each of the parsers outputs to the `extract_metadata_from_filepath`, which
    extracts attributes from the file path using a regular expression. Following the
    parsing and extraction of file path information, the `metadata` operation executes
    adding attributes gathered from the parsing steps to enrich the context for future
    querying. Finally, the `restructure` operation moves the log key extracted from
    each parsed log entry to the `Body` attribute for the extracted structure.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`parser-crio` 操作符将对每个日志条目执行正则表达式，从条目中解析出时间变量，并指定提取字符串的时间格式。将 `parser-crio`
    与 `parser-docker` 操作符进行对比，后者使用 JSON 结构化日志格式，每个日志条目中都有一个 `time` 的 JSON 键。`parser-docker`
    操作符只提供 JSON 条目的键和字符串的布局。结构化日志不需要正则表达式。每个解析器的输出都传送到 `extract_metadata_from_filepath`，该操作通过正则表达式从文件路径中提取属性。在解析并提取文件路径信息之后，`metadata`
    操作会执行，将从解析步骤中收集的属性添加到上下文中，以便将来查询。最后，`restructure` 操作将从每个解析日志条目中提取的日志键移到提取结构的 `Body`
    属性中。
- en: 'Let''s take a look at the CRI-O log format:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 CRI-O 日志格式：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, let''s look at the Docker log format:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看 Docker 日志格式：
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When running the example, you should see output like the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行示例时，你应该会看到如下输出：
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see from the preceding output, the OTel Collector has extracted the
    timestamp, body, and specified attributes from the `metadata` operator, building
    a normalized structure for the exported logging data, and exported the normalized
    structure to `STDOUT`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从前面的输出中看到的，OTel 收集器已经从 `metadata` 操作符中提取了时间戳、主体和指定的属性，构建了导出日志数据的标准化结构，并将标准化结构导出到
    `STDOUT`。
- en: We have accomplished our goal of ingesting, transforming, and extracting log
    telemetry, but you should also be asking yourself how we can build a stronger
    correlation with this telemetry. As of now, the only correlations we have are
    time, pod, and container. We would have a difficult time determining the HTTP
    request or other specific information that led to this log entry. Note that `Trace
    ID` and `Span ID` are empty in the preceding output. In the next section, we will
    discuss tracing and see how we can build a stronger correlation between the logs
    and requests processed in our applications.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了日志遥测的摄取、转换和提取目标，但你还应该问自己，我们如何才能与这些遥测数据建立更强的关联性。到目前为止，我们唯一的关联是时间、Pod 和容器。我们很难确定导致该日志条目的
    HTTP 请求或其他具体信息。请注意，在前面的输出中，`Trace ID` 和 `Span ID` 是空的。在接下来的部分，我们将讨论追踪，并看看如何在我们的应用程序中建立日志与请求之间更强的关联。
- en: Instrumenting for distributed tracing
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于分布式追踪的仪器化
- en: Traces track the progression of a single activity in an application. For example,
    an activity can be a user making a request in your application. If a trace only
    tracks the progression of that activity in a single process or a single component
    of a system composed of many components, its value is limited. However, if a trace
    can be propagated across multiple components in a system, it becomes much more
    useful. Traces that can propagate across components in a system are called **distributed
    traces**. Distributed tracing and correlation of activities is a powerful tool
    for determining causality within a complex system.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪用于追踪应用程序中单个活动的进展。例如，一个活动可以是用户在应用程序中发起一个请求。如果一个跟踪仅仅追踪单个进程或系统中一个组件的活动进展，那么它的价值是有限的。然而，如果一个跟踪可以跨多个组件传播，它将变得更加有用。能够在系统中跨组件传播的跟踪被称为**分布式跟踪**。分布式跟踪和活动相关性分析是确定复杂系统中因果关系的强大工具。
- en: A trace is composed of spans that represent units of work within an application.
    Each trace and span can be uniquely identified, and each span contains a context
    consisting of `Request`, `Error`, and `Duration` metrics. A trace contains a tree
    of spans with a single root span. For example, imagine a user clicking on the
    checkout button on your company's commerce site. The root span would encompass
    the entire request/response cycle as perceived by the user clicking on the checkout
    button. There would likely be many child spans for that single root span, such
    as a query for product data, charging a credit card, and updating a database.
    Perhaps there would also be an error associated with one of the underlying spans
    within that root span. Each span has metadata associated with it, such as a name,
    start and end timestamps, events, and status. By creating a tree of spans with
    this metadata, we are able to deeply inspect the state of complex applications.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪（Trace）由表示应用程序内工作单元的跨度（span）组成。每个跟踪和跨度都可以被唯一标识，每个跨度包含一个上下文，该上下文包括`请求`、`错误`和`持续时间`等度量。一个跟踪包含一个具有单一根跨度的跨度树。例如，假设用户在你公司电商网站上点击结账按钮。根跨度将包含整个请求/响应周期，正如用户点击结账按钮时所感知的那样。对于这个单一根跨度，可能会有许多子跨度，例如查询产品数据、信用卡支付和数据库更新。也许其中还会有一个与根跨度中的某个底层跨度相关的错误。每个跨度都有与之相关的元数据，如名称、开始和结束时间戳、事件和状态。通过创建一个包含这些元数据的跨度树，我们能够深入检查复杂应用程序的状态。
- en: In this section, we will learn to instrument Go applications with OpenTelemetry
    to emit distributed tracing telemetry, which we will inspect using Jaeger, an
    open source tool for visualizing and querying distributed traces.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用OpenTelemetry对Go应用程序进行仪器化，以发出分布式跟踪遥测数据，并使用Jaeger（一款用于可视化和查询分布式跟踪的开源工具）来检查这些数据。
- en: The life cycle of a distributed trace
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式跟踪的生命周期
- en: Before we get into the code, let's first discuss how distributed tracing works.
    Let's imagine we have two services, A and B. Service A serves web pages and makes
    requests for data from service B. When service A receives a request for a page,
    the service starts a root span. Service A then requests some data from service
    B to fulfill the request. Service A encodes the trace and span context in request
    headers to service B. When service B receives the request, service B extracts
    the trace and span information from the request headers and creates a child span
    from the request. If service B received no trace/span headers, it will create
    a new root span. Service B continues processing the request, creating new child
    spans along the way as it requests data from a database. After service B has collected
    the requested information, it responds to service A and sends its spans to the
    trace aggregator. Service A then receives the response from service B, and service
    A responds to the user with the page. At the end of the activity, service A marks
    the root span as complete and sends its spans to the trace aggregator. The trace
    aggregator builds a tree with the shared correlation of the spans from both service
    A and service B, and we have a distributed trace.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入代码之前，让我们首先讨论分布式跟踪的工作原理。假设我们有两个服务，A和B。服务A提供网页并从服务B请求数据。当服务A收到页面请求时，服务启动一个根span。然后，服务A请求服务B的一些数据来完成请求。服务A将跟踪和span上下文编码到请求头中，以发送给服务B。当服务B收到请求时，服务B从请求头中提取跟踪和span信息，并从请求创建一个子span。如果服务B没有收到跟踪/span头，则会创建一个新的根span。服务B继续处理请求，根据需要从数据库请求数据创建新的子span。服务B收集完所请求的信息后，响应服务A并将其span发送给跟踪聚合器。然后服务A收到来自服务B的响应，并向用户响应页面。活动结束时，服务A标记根span为完成，并将其span发送给跟踪聚合器。跟踪聚合器构建一个树，其中包含来自服务A和服务B的span的共享相关性，从而形成分布式跟踪。
- en: For more details of the OpenTelemetry tracing specification, see [https://opentelemetry.io/docs/reference/specification/overview/#tracing-signal](https://opentelemetry.io/docs/reference/specification/overview/#tracing-signal).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解OpenTelemetry跟踪规范的更多细节，请参阅 [https://opentelemetry.io/docs/reference/specification/overview/#tracing-signal](https://opentelemetry.io/docs/reference/specification/overview/#tracing-signal)。
- en: Client/server-distributed tracing with OpenTelemetry
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用OpenTelemetry进行客户端/服务器分布式跟踪
- en: 'In this example, we will deploy and examine a client/server application that
    is instrumented with OpenTelemetry for distributed tracing, and view the distributed
    traces using Jaeger. The client application sends periodic requests to the server
    that will populate the traces in Jaeger. The [https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/tracing](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/tracing)
    directory contains the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将部署并检查一个使用OpenTelemetry进行分布式跟踪的客户端/服务器应用程序，并使用Jaeger查看分布式跟踪。客户端应用程序定期向服务器发送请求，这些请求将在Jaeger中生成跟踪。
    [https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/tracing](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/tracing)
    目录包含以下内容：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To run this demo, move to the chapter source code, `cd` into the `tracing` directory,
    run `docker-compose up -d`, and open `http://localhost:16686` to view the Jaeger-distributed
    traces.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此演示，请转到章节源代码，`cd`到`tracing`目录，运行 `docker-compose up -d`，并打开 `http://localhost:16686`
    查看Jaeger分布式跟踪。
- en: 'Let''s explore the `docker-compose.yaml` file first to see each of the services
    we are deploying:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先浏览 `docker-compose.yaml` 文件，看看我们正在部署的每个服务：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding `docker-compose.yaml` file deploys a Jaeger *all-in-one* instance,
    an OTel Collector, a client Go application, and a server Go application. These
    components are a slight derivation from the OpenTelemetry demo: [https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的 `docker-compose.yaml` 文件部署了一个Jaeger *all-in-one* 实例，一个OTel收集器，一个客户端Go应用程序，以及一个服务器Go应用程序。这些组件略有不同于OpenTelemetry演示：[https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/examples/demo)。
- en: 'Next, let''s take a look at the OTel Collector configuration to get a better
    understanding of its deployment model and configured behaviors:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查看OTel收集器的配置，以更好地理解其部署模型和配置行为：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The preceding OTel Collector configuration specifies that the collector will
    listen for `14250`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 前述OTel收集器配置指定收集器将侦听`14250`端口。
- en: 'Next, let''s break down the significant parts of the client `main.go`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们分解客户端 `main.go` 的重要部分：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`func main()` initializes the tracing provider, which returns a shutdown function
    that is deferred until `func main()` exits. The `main()` func then calls `continuouslySendRequests`
    to send a continuous, periodic stream of requests to the server application. Next,
    let''s look at the `initTraceProvider` function:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`func main()` 初始化跟踪提供者，并返回一个关闭函数，该函数将在 `func main()` 退出时延迟执行。`main()` 函数接着调用
    `continuouslySendRequests` 向服务器应用发送一个连续的、定期的请求流。接下来，让我们看看 `initTraceProvider`
    函数：'
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '`initTraceProvider()` looks up the OTLP trace endpoint from an environment
    variable or defaults to `0.0.0.0:4317`. After setting up the trace endpoint address,
    the code calls `initTracer` to initialize the tracer, returning a function named
    `closeTraces`, which will be used to shut down the tracer. Finally, the `initTraceProvider()`
    returns a function that can be used to flush and close the tracer. Next, let''s
    look at what is happening in `initTracer()`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`initTraceProvider()` 从环境变量中查找 OTLP 跟踪端点，或者默认为 `0.0.0.0:4317`。在设置好跟踪端点地址后，代码调用
    `initTracer` 来初始化跟踪器，并返回一个名为 `closeTraces` 的函数，该函数用于关闭跟踪器。最后，`initTraceProvider()`
    返回一个可用于刷新和关闭跟踪器的函数。接下来，让我们看看 `initTracer()` 中发生了什么：'
- en: '[PRE16]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`initTracer()` builds a trace client that connects to the OTLP endpoint over
    gRPC. The trace client is then used to build a trace exporter, which is used to
    batch process and export spans. The batch span processor is then used to create
    a trace provider, configured to trace all spans, and is identified with the `"demo-client"`
    resource. Trace providers can be configured to sample stochastically or with custom
    sampling strategies. The trace provider is then added to the global OTel context.
    Finally, a function is returned that will shut down and flush the trace exporter.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`initTracer()` 构建了一个连接到 OTLP 端点的 trace 客户端。然后，使用该 trace 客户端构建一个 trace 导出器，该导出器用于批量处理和导出
    spans。批量 span 处理器随后用于创建一个跟踪提供者，该提供者被配置为跟踪所有 spans，并且被标识为 `"demo-client"` 资源。跟踪提供者可以配置为以随机方式或使用自定义采样策略进行采样。然后，跟踪提供者被添加到全局
    OTel 上下文中。最后，返回一个函数，该函数将关闭并刷新 trace 导出器。'
- en: 'Now that we have explored how to set up a tracer, let''s move on to sending
    and tracing requests in the `continuouslySendRequests` func:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了如何设置跟踪器，接下来让我们继续讨论在 `continuouslySendRequests` 函数中发送和跟踪请求：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As the name suggests, the `continuouslySendRequests` func creates a named tracer
    from the global OTel context, which we initialized earlier in the chapter. The
    `otel.Tracer` interface only has one function, `Start(ctx context.Context, spanName
    string, opts ...SpanStartOption) (context.Context, Span)`, which is used to start
    a new span if one does not already exist in the `context.Context` values bag.
    The `for` loop in main will continue infinitely creating a new span, making a
    request to the server, doing a bit of work, and finally, sleeping for 1 second:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，`continuouslySendRequests` 函数从全局 OTel 上下文中创建一个命名的跟踪器，我们在本章早些时候已经初始化了它。`otel.Tracer`
    接口只有一个函数，`Start(ctx context.Context, spanName string, opts ...SpanStartOption)
    (context.Context, Span)`，用于在 `context.Context` 值包中没有现有 span 时启动一个新的 span。`main`
    中的 `for` 循环将无限期地创建新的 span，向服务器发出请求，进行一些工作，最后休眠 1 秒：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '`makeRequest()` should look pretty familiar to those of you who have used the
    Go `http` library. There is one significant difference from non-OTel instrumented
    HTTP requests: the transport for the `client` has been wrapped with `otelhttp.NewTransport()`.
    The `otelhttp` transport uses `request.Context()` in the `Roundtrip` implementation
    to extract the existing span from the context, and then the `otelhttp.Transport`
    adds the span information to the HTTP headers to enable the propagation of span
    data to the server application.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`makeRequest()` 对那些使用过 Go `http` 库的人来说应该很熟悉。与未进行 OTel 仪表化的 HTTP 请求相比，有一个显著的区别：`client`
    的传输已被包装在 `otelhttp.NewTransport()` 中。`otelhttp` 传输在 `Roundtrip` 实现中使用 `request.Context()`
    来提取上下文中的现有 span，然后 `otelhttp.Transport` 将 span 信息添加到 HTTP 头中，以便将 span 数据传播到服务器应用。'
- en: 'Now that we have covered the client, let''s see the server `main.go`. The code
    for this section can be found here: [https://github.com/PacktPublishing/Go-for-DevOps/blob/rev0/chapter/9/tracing/server/main.go](https://github.com/PacktPublishing/Go-for-DevOps/blob/rev0/chapter/9/tracing/server/main.go):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了客户端部分，接下来让我们看看服务器端的 `main.go`。该部分的代码可以在这里找到：[https://github.com/PacktPublishing/Go-for-DevOps/blob/rev0/chapter/9/tracing/server/main.go](https://github.com/PacktPublishing/Go-for-DevOps/blob/rev0/chapter/9/tracing/server/main.go)：
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`func main.go` calls `initTraceProvider` and `shutdown` in a similar manner
    to the client `main.go`. After initializing the trace provider, the server `main.go`
    code creates an HTTP server, handling requests to `"/hello"` on port `7080`. The
    significant bit is `wrappedHandler := otelhttp.NewHandler(handler, "/hello")`.
    `wrappedHandler()` extracts the span context from the HTTP headers and populates
    the request `context.Context` with a span derived from the client span. Within
    `handleRequestWithRandomSleep()`, the code uses the propagated span context to
    continue the distributed trace. Let''s explore `handleRequestWithRandomSleep()`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`func main.go` 以类似于客户端 `main.go` 的方式调用 `initTraceProvider` 和 `shutdown`。在初始化追踪提供者后，服务器
    `main.go` 代码创建了一个 HTTP 服务器，处理端口 `7080` 上的 `"/hello"` 请求。关键部分是 `wrappedHandler
    := otelhttp.NewHandler(handler, "/hello")`。`wrappedHandler()` 从 HTTP 头中提取跨度上下文，并将从客户端跨度派生的跨度填充到请求的
    `context.Context` 中。在 `handleRequestWithRandomSleep()` 中，代码使用传播的跨度上下文继续分布式追踪。让我们来探讨一下
    `handleRequestWithRandomSleep()`：'
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In `handleRequestWithRandomSleep()`, the request is handled, introducing a random
    sleep to simulate latency. `trace.SpanFromContext(ctx)` uses the span populated
    by `wrappedHandler` to then set attributes on the distributed span.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `handleRequestWithRandomSleep()` 中，请求被处理，同时引入了一个随机延迟以模拟延迟。`trace.SpanFromContext(ctx)`
    使用由 `wrappedHandler` 填充的跨度，然后在分布式跨度上设置属性。
- en: 'The viewable result in Jaeger at `http://localhost:16686` is the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jaeger 中可查看的结果位于 `http://localhost:16686`，如下所示：
- en: '![Figure 9.3 – The Jaeger client/server-distributed trace'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.3 – Jaeger 客户端/服务器分布式追踪](img/B17626_09_003.jpg)'
- en: '](img/B17626_09_003.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17626_09_003.jpg)'
- en: Figure 9.3 – The Jaeger client/server-distributed trace
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – Jaeger 客户端/服务器分布式追踪
- en: In the preceding screenshot, you can see the distributed trace between the client
    and the server, including each span that was created in the request/response cycle.
    This is a simple example, but you can imagine how this simple example can be extrapolated
    into a more complex system to provide insight into the difficult-to-debug scenarios.
    The trace provides the information needed to gain insight into errors as well
    as more subtle performance issues.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，你可以看到客户端和服务器之间的分布式追踪，包括在请求/响应周期中创建的每个跨度。这是一个简单的例子，但你可以想象如何将这个简单的例子扩展到更复杂的系统中，从而提供对难以调试场景的洞察。追踪提供了获取错误以及更细微的性能问题所需的信息。
- en: Correlating traces and logs
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关联追踪与日志
- en: 'In the *Logging with context* section, we discussed the correlation of log
    entries with activities. Without correlation to a given trace and span, you would
    not be able to determine which log events originated from a specific activity.
    Remember, log entries do not contain the trace and span data that enables us to
    build correlated trace views, as we see in Jaeger. However, we can extend our
    log entries to include this data and enable robust correlation with a specific
    activity:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *上下文日志记录* 部分，我们讨论了日志条目与活动的关联。如果没有与特定追踪和跨度的关联，你将无法确定哪些日志事件源自特定的活动。请记住，日志条目本身并不包含追踪和跨度数据，这些数据帮助我们构建关联的追踪视图，正如我们在
    Jaeger 中所看到的那样。然而，我们可以扩展日志条目以包括这些数据，并启用与特定活动的强关联：
- en: '[PRE21]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the preceding code, we use the `zap` structured logger to add the span and
    trace IDs to the logger, so each log entry written by a logger enhanced with `WithCorrelation()`
    will contain a strong correlation to a given activity.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用 `zap` 结构化日志记录器将跨度和追踪 ID 添加到日志记录器中，因此每个由增强了 `WithCorrelation()`
    的日志记录器写入的日志条目将与给定的活动保持强关联。
- en: Adding log entries to spans
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向跨度添加日志条目
- en: 'Correlating logs with traces is effective for building correlations of logs
    with activities, but you can take it a step further. You can add your log events
    directly to the spans, instead of or in combination with correlating logs:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 关联日志与追踪对于构建日志与活动的关联非常有效，但你可以更进一步。你可以将日志事件直接添加到跨度中，而不是仅仅依赖于日志的关联：
- en: '[PRE22]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`SuccessfullyFinishedRequestEvent()` will decorate the span with an event entry
    that shows as a log entry in Jaeger. If we were to call this function in the client''s
    `main.go` after we complete the request, a log event would be added to the client
    request span:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`SuccessfullyFinishedRequestEvent()` 将会用一个事件条目装饰跨度，这个事件会作为日志条目出现在 Jaeger 中。如果我们在客户端的
    `main.go` 中调用这个函数，在完成请求后，会向客户端请求的跨度添加一个日志事件：'
- en: '![Figure 9.4 – The Jaeger client/server-distributed trace with the log entry'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.4 – Jaeger 客户端/服务器分布式追踪与日志条目](img/B17626_09_003.jpg)'
- en: '](img/B17626_09_004.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17626_09_004.jpg)'
- en: Figure 9.4 – The Jaeger client/server-distributed trace with the log entry
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – Jaeger 客户端/服务器分布式追踪与日志条目
- en: As you can see, the log entry is embedded within the span visualized in Jaeger.
    Adding log entries to spans adds even more context to your distributed traces,
    making it easier to understand what is happening with your application.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，日志条目被嵌入到 Jaeger 中可视化的跨度内。将日志条目添加到跨度中为分布式追踪提供了更多上下文，帮助你更容易理解应用程序的运行状况。
- en: In the next section, we will instrument this example with metrics to provide
    an aggregated view of the application using Prometheus.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将通过度量仪表化这个示例，使用 Prometheus 提供应用程序的聚合视图。
- en: Instrumenting for metrics
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行度量仪表化
- en: Metrics are measurements at a given moment of a particular aspect of an application
    during runtime. An individual capture is called a **metric event** and consists
    of a timestamp, a measurement, and associated metadata. Metric events are used
    to provide an aggregated view of the behavior of an application at runtime. For
    example, a metric event can be a counter incremented by 1 when a request is handled
    by a service. The individual event is not especially useful. However, when aggregated
    into a sum of requests over a period of time, you can see how many requests are
    made to a service over that period of time.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 度量是应用程序在运行时某个特定方面在某一时刻的测量值。每次捕获的结果称为 **度量事件**，它由时间戳、测量值和相关的元数据组成。度量事件用于提供应用程序运行时行为的聚合视图。例如，度量事件可以是每当服务处理请求时，计数器加
    1。单个事件本身并不特别有用，但当它们聚合成一段时间内的请求总数时，就能反映出服务在该时间段内处理了多少请求。
- en: The OpenTelemetry API does not allow for custom aggregations but does provide
    some common aggregations, such as sum, count, last value, and histograms, which
    are supported by backend visualization and analysis software such as Prometheus.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry API 不允许自定义聚合，但提供了一些常见的聚合方法，如求和、计数、最后一个值和直方图，这些方法被 Prometheus 等后端可视化和分析软件所支持。
- en: 'To give you a better idea of when metrics are useful, here are some example
    scenarios:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你更清楚地了解度量何时有用，以下是一些示例场景：
- en: Providing the aggregate total number of bits read or written in a process
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一个进程中读取或写入的位数的总和
- en: Providing CPU or memory utilization
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供 CPU 或内存使用情况
- en: Providing the number of requests over a period of time
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一段时间内的请求数量
- en: Providing the number of errors over a period of time
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一段时间内的错误数量
- en: Providing the duration of requests to form a statistical distribution of the
    request processing time
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供请求持续时间以形成请求处理时间的统计分布
- en: 'OpenTelemetry offers three types of metrics:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 提供三种类型的度量：
- en: '`counter`: To count a value over time, such as the number of requests'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`counter`：在一段时间内计数一个值，例如请求的数量'
- en: '`measure`: To sum or otherwise aggregate a value over a period of time, such
    as how many bytes are read per minute'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`measure`：对一段时间内的值进行求和或其他聚合，例如每分钟读取多少字节'
- en: '`observer`: To periodically capture a value, such as memory utilization every
    minute'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`observer`：定期捕获某个值，例如每分钟的内存使用情况'
- en: In this section, we will learn to instrument Go applications with OpenTelemetry
    to emit metrics telemetry, which we will inspect using Prometheus, an open source
    tool for visualizing and analyzing metrics.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用 OpenTelemetry 对 Go 应用进行仪表化，以发出度量遥测数据，并使用 Prometheus 这一开源工具进行可视化和分析。
- en: The life cycle of a metric
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 度量的生命周期
- en: 'Before we get into the code, let''s first discuss how metrics are defined and
    used. Before you can record or observe a metric, it must be defined. For example,
    a histogram of request latency would be defined as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入代码之前，让我们先讨论度量是如何定义和使用的。在你可以记录或观察一个度量之前，它必须被定义。例如，请求延迟的直方图可以这样定义：
- en: '[PRE23]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The preceding code fetches a global meter named `demo-client-meter` and then
    registers a new histogram instrument named `demo_client/reqeust_latency` and `demo_client/request_counts`,
    a counter instrument, both of which have a description of what is being collected.
    It's important to provide descriptive names and descriptions for your metrics,
    as it can become confusing later when analyzing your data.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码获取一个名为 `demo-client-meter` 的全局计量器，然后注册一个新的直方图仪表 `demo_client/reqeust_latency`
    和一个计数器仪表 `demo_client/request_counts`，这两个仪表都包含了它们所收集内容的描述。为度量提供描述性名称和说明非常重要，因为在后续分析数据时，如果没有清晰的命名，可能会导致混淆。
- en: 'Once the instrument has been defined, it can be used to record measurements,
    as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦仪表已定义，就可以用来记录度量数据，具体如下：
- en: '[PRE24]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The preceding code uses the global meter we defined previously to record two
    measurements, the request latency and an increment for the number of requests.
    Note that `ctx` was included, which will contain correlation information to correlate
    the activity to the measurement.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码使用了我们之前定义的全局计量器来记录两个度量值：请求延迟和请求数量的增量。请注意，`ctx`被包括在内，它将包含关联信息，用以将活动与度量值关联起来。
- en: After events have been recorded, they will be exported based on the configuration
    of `MeterProvider`, which which we will explore next.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件被记录后，它们将根据`MeterProvider`的配置进行导出，接下来我们将探讨这一部分。
- en: Client/server metrics with OpenTelemetry
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用OpenTelemetry的客户端/服务器指标
- en: 'We will extend the same client/server application described in the *Instrumenting
    for distributed tracing* section. Code for this section can be found here: [https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/metrics](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/metrics).
    The directory has the following layout:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将扩展在*为分布式追踪仪表化*部分中描述的相同客户端/服务器应用程序。此部分的代码可以在这里找到：[https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/metrics](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/metrics)。该目录的结构如下：
- en: '[PRE25]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The only addition to the preceding is the `prometheus.yaml` file, which contains
    the following:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 上述内容中唯一的新增部分是`prometheus.yaml`文件，内容如下：
- en: '[PRE26]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding configuration informs Prometheus of the endpoint to scrape to
    gather metrics data from the OTel Collector. Let''s next look at the updates needed
    to add Prometheus to the `docker-compose.yaml` file:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 上述配置告知Prometheus抓取OTel收集器中的端点以收集指标数据。接下来，让我们看一下需要更新的内容，以将Prometheus添加到`docker-compose.yaml`文件中：
- en: '[PRE27]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'As you can see from the preceding, we have added some additional ports for
    Prometheus to scrape on the OTel Collector, and the Prometheus service with `prometheus.yaml`
    mounted in the container. Next, let''s take a look at the updated OTel Collector
    configuration:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们已经为OTel收集器添加了一些额外的端口供Prometheus抓取，并且Prometheus服务已经将`prometheus.yaml`挂载到容器中。接下来，让我们查看更新后的OTel收集器配置：
- en: '[PRE28]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The preceding configuration has omitted the Jaeger config used in the *Instrumenting
    for distributed tracing* section for brevity. The additions are the exporter for
    Prometheus as well as the metrics pipeline. The Prometheus exporter will expose
    port `8889` so that Prometheus can scrape metrics data collected by the OTel Collector.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 上述配置省略了在*为分布式追踪仪表化*部分中使用的Jaeger配置，为了简洁起见。新增的部分是Prometheus的导出器以及指标管道。Prometheus导出器将暴露端口`8889`，以便Prometheus抓取OTel收集器收集的指标数据。
- en: 'Next, let''s break down the significant parts of the client `main.go`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们分解客户端`main.go`中的重要部分：
- en: '[PRE29]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The only difference between the tracing version we explored earlier in the
    chapter is that instead of calling `initTraceProvider`, the code now calls `initTraceAndMetricsProvdier`
    to initialize both the trace and metrics providers. Next, let''s explore `initTraceAndMetricsProvider()`:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前在本章中探讨的追踪版本与此处的唯一区别是，代码现在调用`initTraceAndMetricsProvider`来初始化追踪和指标提供者，而不是调用`initTraceProvider`。接下来，让我们探讨`initTraceAndMetricsProvider()`：
- en: '[PRE30]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The code in `initTraceAndMetricsProvider` establishes the OTel agent address
    and goes on to initialize the metrics and tracing providers. Finally, a function
    to close and flush both metrics and traces is returned. Next, let''s explore `initMetrics()`:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`initTraceAndMetricsProvider`中的代码建立了OTel代理地址，并初始化了指标和追踪提供者。最后，返回一个关闭并刷新指标和追踪的函数。接下来，让我们探讨`initMetrics()`：'
- en: '[PRE31]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In `initMetrics()`, we create a new `metricClient` to transmit metrics from
    the client to the OTel Collector in the OTLP format. After setting up the `metricClient`,
    we then create `pusher` to manage the export of the metrics to the OTel Collector,
    register `pusher` as the global `MeterProvider`, and start `pusher` to export
    metrics to the OTel Collector. Finally, we create a closure to shut down `pusher`.
    Now, let''s move on to explore `continuouslySendRequests()` from client''s `main.go`:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在`initMetrics()`中，我们创建了一个新的`metricClient`来将指标从客户端以OTLP格式传输到OTel收集器。设置好`metricClient`后，我们创建`pusher`来管理将指标导出到OTel收集器，注册`pusher`为全局的`MeterProvider`，并启动`pusher`以将指标导出到OTel收集器。最后，我们创建一个闭包来关闭`pusher`。现在，让我们继续探讨客户端`main.go`中的`continuouslySendRequests()`：
- en: '[PRE32]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We first create a metrics meter with the name `demo-client-meter`, metric instruments
    to be used to measure metrics in this function, and a set of common labels to
    be added to the metrics collected. These labels enable scoped querying of metrics.
    After initializing the random number generator for artificial latency, the client
    enters the `for` loop, stores the start time of the request, makes a request to
    the server, and stores the duration of `makeRequest` as the latency in milliseconds.
    Following the execution of `makeRequest`, the client executes a random number
    of iterations between 0 and 7 to generate a random line length, recording a batch
    of metric events during each iteration, and measuring the count of executions
    and the random line length. Finally, the client records a batch of metric events,
    measuring the latency of `makeRequest` and a count for one request.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个名为 `demo-client-meter` 的度量计量器，定义用于测量此函数中度量的仪表，并添加一组公共标签到收集到的度量数据中。这些标签使得可以按范围查询度量数据。初始化人工延迟的随机数生成器后，客户端进入
    `for` 循环，记录请求的开始时间，向服务器发起请求，并将 `makeRequest` 的持续时间作为延迟（以毫秒为单位）记录下来。在执行 `makeRequest`
    后，客户端执行 0 到 7 次的随机迭代以生成一个随机行长度，并在每次迭代中记录一批度量事件，测量执行次数和随机行长度。最后，客户端记录一批度量事件，测量
    `makeRequest` 的延迟和一次请求的计数。
- en: 'So, how did we define the instruments used in the preceding code? Let''s explore
    `NewClientInstruments` and learn how to define counter and histogram instruments:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们是如何定义前面代码中使用的仪表的呢？让我们来探索一下 `NewClientInstruments`，并了解如何定义计数器和直方图仪表：
- en: '[PRE33]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`NewClientInstruments()` takes a meter and returns a struct of instruments
    used by the client. An instrument is used to record and aggregate measurements.
    This func sets up the two `Int64Counter` and `Int64Histogram` instruments. Each
    instrument is defined with a well-described name for easier analysis in the backend
    metric system. The `Int64Counter` instrument will monotonically increase and `Int64Histogram`
    will record `int64` the values and pre-aggregate values before pushing to the
    metrics backend.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`NewClientInstruments()` 接受一个计量器并返回一个客户端使用的仪表结构。一个仪表用于记录和聚合测量值。这个函数设置了两个 `Int64Counter`
    和 `Int64Histogram` 仪表。每个仪表都以一个描述清晰的名称来定义，以便于在后端度量系统中进行分析。`Int64Counter` 仪表会单调递增，而
    `Int64Histogram` 会记录 `int64` 类型的值并在推送到度量后端之前进行预聚合。'
- en: 'Now that we have covered the client, let''s look at the server''s `main.go`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了客户端的部分，让我们来看看服务器的 `main.go`：
- en: '[PRE34]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The server''s `main.go` calls `initProvider()` and `shutdown()` in a similar
    manner to the client''s `main.go`. The interesting metric measures happen within
    `handleRequestWithRandomSleep()`. Next, let''s export `handleRequestWithRandomSleep()`:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器的 `main.go` 以类似于客户端 `main.go` 的方式调用 `initProvider()` 和 `shutdown()`。有趣的度量指标发生在
    `handleRequestWithRandomSleep()` 中。接下来，让我们导出 `handleRequestWithRandomSleep()`：
- en: '[PRE35]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In the preceding code, `handleRequestWithRandomSleep()` creates a named meter
    from the global OTel context, initializes the server instruments in a similar
    way to the client example, and defines a slice of custom attributes. Finally,
    the function returns a handler function, which introduces a random sleep and records
    the request count.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`handleRequestWithRandomSleep()` 从全局的 OTel 上下文中创建了一个命名的计量器，类似于客户端示例的方式初始化了服务器的仪表，并定义了一组自定义属性。最后，该函数返回一个处理函数，它引入了一个随机延迟并记录请求计数。
- en: 'The result is viewable in Prometheus at `http://localhost:9090/graph?g0.expr=rate(demo_server_request_counts%5B2m%5D)&g0.tab=0&g0.stacked=0&g0.show_exemplars=0&g0.range_input=1h`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以在 Prometheus 中查看，网址为 `http://localhost:9090/graph?g0.expr=rate(demo_server_request_counts%5B2m%5D)&g0.tab=0&g0.stacked=0&g0.show_exemplars=0&g0.range_input=1h`：
- en: '![Figure 9.5 – The Prometheus server request rate'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.5 – Prometheus 服务器请求速率'
- en: '](img/B17626_09_005.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17626_09_005.jpg)'
- en: Figure 9.5 – The Prometheus server request rate
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – Prometheus 服务器请求速率
- en: In the preceding screenshot, you can see the average requests per second for
    the server application in Prometheus. At the bottom of the screenshot, you will
    see the common labels and other associated metadata that was added in the server
    `main.go`. Prometheus provides a powerful query language to analyze and alert
    on metrics. Take some time and explore what you can do in the Prometheus UI. If
    you'd like to learn more about Prometheus, see [https://prometheus.io/docs/introduction/overview/](https://prometheus.io/docs/introduction/overview/).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，你可以看到 Prometheus 中服务器应用程序的平均每秒请求数。在截图的底部，你会看到在 `main.go` 文件中为服务器添加的常用标签和其他关联的元数据。Prometheus
    提供了强大的查询语言来分析和对指标进行警报。花点时间探索一下你在 Prometheus UI 中能做些什么。如果你想了解更多关于 Prometheus 的信息，请参见[https://prometheus.io/docs/introduction/overview/](https://prometheus.io/docs/introduction/overview/)。
- en: In this section, we learned how to instrument a Go application, export metrics
    to the OTel Collector, configure Prometheus to scrape metrics from the OTel Collector,
    and start to analyze metrics telemetry in Prometheus. With these newly gained
    skills, you will be able to understand more about the runtime characteristics
    of your applications.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何为 Go 应用程序添加监控代码，将指标导出到 OTel 收集器，配置 Prometheus 从 OTel 收集器抓取指标，并开始分析
    Prometheus 中的指标遥测数据。通过这些新获得的技能，你将能够更深入地了解应用程序的运行时特性。
- en: Next up, let’s look at how you can add alerting when your metrics are showing
    abnormalities that could indicate a problem.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看看如何在指标显示出可能指示问题的异常时添加警报。
- en: Alerting on metrics abnormalities
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对指标异常进行警报
- en: Metrics provide time-series measurements of the behavior of our applications
    and infrastructure, but they provide no notification when those measurements deviate
    from the expected behavior of our applications. To be able to react to abnormal
    behaviors in our applications, we need to establish rules about what is normal
    behavior in our applications and how we can be notified when our applications
    deviate from that behavior.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 指标提供了我们应用程序和基础设施行为的时间序列测量，但它们在这些测量偏离应用程序预期行为时并不会发出通知。为了能够对应用程序中的异常行为做出反应，我们需要建立关于什么是应用程序正常行为的规则，并且在我们的应用程序偏离这些行为时如何接收通知。
- en: Alerting on metrics enables us to define behavioral norms and specify how we
    should be notified when our applications exhibit abnormal behavior. For example,
    if we expect HTTP responses from our application to respond in under 100 milliseconds
    and we observe a time span of 5 minutes when our application is responding in
    greater than 100 milliseconds, we would want to be notified of the deviation from
    the expected behavior.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 对指标进行警报可以让我们定义行为规范，并指定在我们的应用程序表现出异常行为时应该如何接收通知。例如，如果我们预期应用程序的 HTTP 响应时间在 100
    毫秒以内，而我们观察到 5 分钟的时间段内应用程序的响应时间超过了 100 毫秒，那么我们希望能够收到偏离预期行为的通知。
- en: In this section, we will learn how to extend our current configuration of services
    to include an Alertmanager ([https://prometheus.io/docs/alerting/latest/alertmanager/](https://prometheus.io/docs/alerting/latest/alertmanager/))
    service to provide alerts when observed behavior deviates from expected norms.
    We'll learn how to define alerting rules and specify where to send those notifications
    when our application experiences abnormal behaviors.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何扩展当前的服务配置，加入一个 Alertmanager ([https://prometheus.io/docs/alerting/latest/alertmanager/](https://prometheus.io/docs/alerting/latest/alertmanager/))
    服务，以便在观察到的行为偏离预期规范时提供警报。我们将学习如何定义警报规则，并指定在应用程序出现异常行为时将通知发送到何处。
- en: 'The code for this section is here: [https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/alerting](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/alerting).'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的代码在这里：[https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/alerting](https://github.com/PacktPublishing/Go-for-DevOps/tree/rev0/chapter/9/alerting)。
- en: Adding and configuring Alertmanager
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加和配置 Alertmanager
- en: 'We will start by adding the Alertmanager service to the `docker-compose.yaml`
    file. Let''s look at the updates needed to add Prometheus to the `docker-compose.yaml`
    file:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从将 Alertmanager 服务添加到 `docker-compose.yaml` 文件开始。让我们看看需要更新哪些内容来将 Prometheus
    添加到 `docker-compose.yaml` 文件中：
- en: '[PRE36]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'As you can see from the preceding, we have added a `rules` folder to the `prometheus`
    service, a new service called `alertmanager`, and a volume to store the `alertmanager`
    data called `alertmanager-data`. We will discuss the Prometheus `./rules` volume
    mount and contents later in this section, but for now, know that it contains our
    alerting rules for Prometheus. The new `alertmanager` service exposes an HTTP
    endpoint at `http://localhost:9093` and mounts an `alertmanager.yml` configuration
    as well as a data directory. Next, let''s explore the contents of the `alertmanager.yml`
    file to see how Alertmanager is configured:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们为`prometheus`服务添加了一个`rules`文件夹，一个新的服务`alertmanager`，以及一个名为`alertmanager-data`的卷，用于存储`alertmanager`的数据。我们稍后将在本节中讨论Prometheus的`./rules`卷挂载及其内容，但目前知道它包含我们为Prometheus定义的警报规则。新的`alertmanager`服务暴露了一个HTTP端点`http://localhost:9093`，并挂载了一个`alertmanager.yml`配置文件以及一个数据目录。接下来，让我们探索`alertmanager.yml`文件的内容，看看Alertmanager是如何配置的：
- en: '[PRE37]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Alertmanager configuration consists mainly of routes and receivers. A route
    describes where to send an alert based on it either being default or by some criteria.
    For example, we have a default route and a specialized route in the preceeding
    Alertmanager configuration. The default route will send alerts to the default
    receiver if they do not match `exported_job` attribute with the value "`demo-server"`.
    If alerts match the `exported_job` attribute with value `"demo-server"`, they
    are routed to the `demo-server` receiver, described in the receivers section.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Alertmanager的配置主要由路由（routes）和接收器（receivers）组成。路由描述了根据是否为默认路由或符合某些条件将警报发送到哪里。例如，在前面的Alertmanager配置中，我们有一个默认路由和一个专门的路由。默认路由将在警报的`exported_job`属性与值"`demo-server`"不匹配时，将警报发送到默认接收器。如果警报的`exported_job`属性与值`"demo-server"`匹配，则警报将被路由到`demo-server`接收器，该接收器在接收器部分中描述。
- en: In this example of Alertmanager receivers, we are using PagerDuty ([https://www.pagerduty.com](https://www.pagerduty.com)),
    but there are many other receivers that can be configured. For example, you can
    configure receivers for Slack, Teams, Webhooks, and so on. Note that the `service_key`
    values for each of the receivers requires a PagerDuty integration key, which can
    be set up by following the docs for integrating Prometheus with PagerDuty ([https://www.pagerduty.com/docs/guides/prometheus-integration-guide/](https://www.pagerduty.com/docs/guides/prometheus-integration-guide/)).
    If you wish to use another receiver such as email, feel free to mutate the receivers
    with email by following the Prometheus guide for email configuration ([https://prometheus.io/docs/alerting/latest/configuration/#email_config](https://prometheus.io/docs/alerting/latest/configuration/#email_config)).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个Alertmanager接收器的示例中，我们使用了PagerDuty（[https://www.pagerduty.com](https://www.pagerduty.com)），但还有许多其他接收器可以进行配置。例如，你可以为Slack、Teams、Webhooks等配置接收器。请注意，每个接收器的`service_key`值需要一个PagerDuty集成密钥，设置方法可以参考将Prometheus与PagerDuty集成的文档（[https://www.pagerduty.com/docs/guides/prometheus-integration-guide/](https://www.pagerduty.com/docs/guides/prometheus-integration-guide/)）。如果你希望使用其他接收器，比如电子邮件，可以按照Prometheus的电子邮件配置指南（[https://prometheus.io/docs/alerting/latest/configuration/#email_config](https://prometheus.io/docs/alerting/latest/configuration/#email_config)）随意更改接收器配置为电子邮件。
- en: 'Next, we will look at the changes that we need to make to the Prometheus configuration
    in `./prometheus.yaml` to make Prometheus aware of the Alertmanager service and
    the rules for sending alerts to the Alertmanager service:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看需要对Prometheus配置文件`./prometheus.yaml`进行的更改，以便让Prometheus识别Alertmanager服务和将警报发送到Alertmanager服务的规则：
- en: '[PRE38]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: In the preceding `./prometheus.yaml`, we see the original `scrape_config` and
    two new keys, `alerting` and `rule_files`. The `alerting` key describes the `alertmanager`
    services to send alerts and the connection details for connecting to those services.
    The `rules_files` key describes the glob rules for selecting files containing
    alerting rules. These rules can be set up in the Prometheus UI, but it is good
    practice to define these rules declaratively in code so that they are clear and
    visible to the rest of your team as source code.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的`./prometheus.yaml`中，我们看到了原始的`scrape_config`和两个新的键，`alerting`和`rule_files`。`alerting`键描述了`alertmanager`服务以发送警报以及连接到这些服务的连接细节。`rule_files`键描述了选择包含警报规则文件的glob规则。这些规则可以在Prometheus的UI中设置，但最佳实践是以声明式代码的方式定义这些规则，这样它们对团队的其他成员来说既清晰又可见，像源代码一样。
- en: 'Next, let''s look at the `rules` file and see how we describe rules for alerting
    in `./rules/demo-server.yml`:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查看`rules`文件，看看我们是如何在`./rules/demo-server.yml`中描述警报规则的：
- en: '[PRE39]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Rules in `rule_files` are categorized into groups. In the preceding example,
    we can see a single group named `demo-server` specifying a single rule named `HighRequestLatency`.
    The rule specifies an expression, which is a Prometheus query. The preceding query
    triggers when the mean request latency is exceeding 200,000 microseconds, or 0.2
    seconds. The alert is triggered with a severity label of `page` and an annotation
    summary of `High request latency`.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`rule_files` 中的规则按组分类。在前面的示例中，我们看到一个名为 `demo-server` 的组，指定了一个名为 `HighRequestLatency`
    的规则。该规则指定了一个表达式，这是一个 Prometheus 查询。前面的查询在平均请求延迟超过 200,000 微秒或 0.2 秒时触发。告警会触发，并标记为
    `page` 严重性，并附有 `High request latency` 的注释摘要。'
- en: 'Now, let''s run the following to start the services:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行以下命令来启动服务：
- en: '[PRE40]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'After the services start, we should see the following in Prometheus at `http://localhost:9090/alerts`:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 服务启动后，我们应该能在 Prometheus 的 `http://localhost:9090/alerts` 页面看到如下内容：
- en: '![Figure 9.6 – The Prometheus alert for HighRequestLatency'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.6 – Prometheus 中的 HighRequestLatency 告警'
- en: '](img/B17626_09_006.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17626_09_006.jpg)'
- en: Figure 9.6 – The Prometheus alert for HighRequestLatency
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6 – Prometheus 中的 HighRequestLatency 告警
- en: The preceding screenshot shows the alert rules registered in Prometheus. As
    you can see, the `HighRequestLatency` alert is registered with the command we
    configured in the `./rules/demo-server` file.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图显示了在 Prometheus 中注册的告警规则。如您所见，`HighRequestLatency` 告警是通过我们在 `./rules/demo-server`
    文件中配置的命令注册的。
- en: 'After roughly 5 minutes of running the service, you should see the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 大约运行 5 分钟后，您应该能看到如下内容：
- en: '![Figure 9.7 – The Prometheus alert for HighRequestLatency triggered'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.7 – HighRequestLatency 告警触发'
- en: '](img/B17626_09_007.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17626_09_007.jpg)'
- en: Figure 9.7 – The Prometheus alert for HighRequestLatency triggered
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 – HighRequestLatency 告警触发
- en: In the preceding screenshot, you can see the triggered alert for `HighRequestLatency`.
    This is Prometheus triggering the alert for the mean request latency rising above
    0.2 seconds. This will then trigger an alert that is sent to the Alertmanager
    which delegates to the appropriate receiver. The receiver will then send the alert
    on to the service configured to notify PagerDuty or, perhaps, another receiver
    you have configured. You have now established a flow for alerting yourself or
    others on your team that your application has entered into an aberrant state of
    behavior.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的截图中，您可以看到 `HighRequestLatency` 告警被触发。这是 Prometheus 在平均请求延迟超过 0.2 秒时触发告警。告警随后会发送到
    Alertmanager，Alertmanager 会将其委派给相应的接收器。接收器将告警发送到配置的服务，可能是 PagerDuty，或者是您配置的其他接收器。您现在已经建立了一个告警流程，当您的应用程序进入异常状态时，能够通知您或团队的其他成员。
- en: In this section, you learned to configure Prometheus alerting rules, deploy
    Alertmanager, and configure Alertmanager to send alerts to the notification service
    of your choice. With this knowledge, you should be able to establish rules for
    defining the normative behavior of your applications and alert you or your team
    when an application is behaving outside of those bounds.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，您学习了如何配置 Prometheus 告警规则，部署 Alertmanager，并配置 Alertmanager 将告警发送到您选择的通知服务。通过这些知识，您应该能够为应用程序定义规范行为的规则，并在应用程序行为超出这些范围时提醒您或您的团队。
- en: Alerting is a key component of reacting to aberrant behaviors in applications.
    With proper metrics in place, you are now empowered to proactively respond when
    your applications are not meeting expectations, rather than responding to customer
    complaints.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 告警是响应应用程序异常行为的关键组成部分。通过适当的指标，您现在可以在应用程序未达到预期时主动响应，而不是在收到客户投诉时才做出反应。
- en: Summary
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the basics of OpenTelemetry, how to instrument
    your applications and infrastructure, and how to export that telemetry into backend
    visualization and analysis tools such as Jaeger and Prometheus. We also extended
    the benefits of metrics by integrating alerting rules to proactively notify us
    when an application is operating outside of expected behavioral parameters. With
    the application of what you have learned, you will never be caught blind during
    a support call. You will have the data to diagnose and resolve issues in your
    complex system. Better yet, you will know about these problems before issues are
    raised by your customers.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了OpenTelemetry的基础知识，如何对您的应用程序和基础设施进行监控，并如何将这些遥测数据导出到后端可视化和分析工具，如Jaeger和Prometheus。我们还通过集成告警规则扩展了指标的优势，以便在应用程序操作超出预期行为参数时，主动通知我们。通过应用所学知识，您将在支持电话中避免措手不及。您将拥有数据来诊断和解决复杂系统中的问题。更棒的是，您将能在客户提出问题之前就了解这些问题。
- en: We also established some relatively simple metrics, traces, and alerts. With
    this knowledge, you will be able to implement your own traces, metrics, and alerts
    to empower you and your team to react quickly and efficiently to failures in production.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还建立了一些相对简单的指标、追踪和告警。通过这些知识，您将能够实现自己的追踪、指标和告警，帮助您和您的团队在生产环境中迅速有效地应对故障。
- en: In the next chapter, we will discuss how to automate workflows with GitHub Actions.
    We will learn about the basics of GitHub actions and build upon that to create
    our own Go-based GitHub actions to empower you to author any automation allowable
    by a Turing-complete language.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讨论如何使用GitHub Actions自动化工作流。我们将了解GitHub Actions的基础，并在此基础上构建自己的基于Go的GitHub
    Actions，赋能您使用任何图灵完备语言编写自动化任务。
