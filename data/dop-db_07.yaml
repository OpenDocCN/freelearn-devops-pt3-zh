- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: AI, ML, and Big Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能、机器学习与大数据
- en: '**Artificial intelligence** (**AI**), **machine learning** (**ML**), and **big
    data** are three of the most talked-about technologies in the modern world. While
    they are distinct from one another, they are often used together to create powerful
    solutions that can automate complex tasks, extract insights, and improve decision-making.
    In this chapter, we will provide a brief overview of each of these technologies
    and how they relate to one another.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）、**机器学习**（**ML**）和**大数据**是现代世界中最常讨论的三项技术。虽然它们相互独立，但通常一起使用，以创造能够自动化复杂任务、提取见解并改善决策的强大解决方案。在本章中，我们将简要概述这些技术的基本概念以及它们之间的关系。'
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The definitions and application of AI, ML, and big data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI、ML和大数据的定义与应用
- en: A deep dive into big data as a DevOps data expert
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨作为DevOps数据专家的大数据
- en: A deep dive into ML as a DevOps data expert
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨作为DevOps数据专家的机器学习（ML）
- en: A deep dive into AI as a DevOps data expert
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨作为DevOps数据专家的人工智能（AI）
- en: Definitions and applications of AI, ML, and big data
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI、ML和大数据的定义与应用
- en: AI is a branch of computer science that focuses on creating intelligent machines
    that can perform tasks that would typically require human intelligence. AI systems
    can analyze data, recognize patterns, and make decisions based on that analysis.
    Some examples of AI applications include speech recognition, computer vision,
    natural language processing, robotics, and expert systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）是计算机科学的一个分支，专注于创建能够执行通常需要人类智慧的任务的智能机器。AI系统能够分析数据、识别模式，并根据分析结果做出决策。AI应用的例子包括语音识别、计算机视觉、自然语言处理、机器人技术和专家系统。
- en: ML is a branch of AI that concentrates on creating algorithms that can learn
    from given data and enhance their efficiency as time progresses. ML algorithms
    can automatically identify patterns in data and use them to make predictions or
    decisions. Some examples of ML applications include predictive analytics, fraud
    detection, recommender systems, image recognition, and autonomous vehicles.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）是人工智能（AI）的一部分，专注于创建可以从给定数据中学习并随着时间推移提高效率的算法。ML算法能够自动识别数据中的模式，并利用这些模式做出预测或决策。ML应用的例子包括预测分析、欺诈检测、推荐系统、图像识别和自动驾驶汽车。
- en: Big data refers to the large and complex sets of data that are generated by
    modern technology. This data is often unstructured, diverse, and difficult to
    process using traditional methods. Big data technologies are used to store, manage,
    and analyze these large datasets. Some examples of big data applications include
    social media analytics, customer profiling, supply chain optimization, and cybersecurity.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据是由现代技术生成的大规模复杂数据集。这些数据通常是非结构化的、多样化的，并且使用传统方法很难处理。大数据技术用于存储、管理和分析这些庞大的数据集。大数据应用的例子包括社交媒体分析、客户画像、供应链优化和网络安全。
- en: The relationship between AI, ML, and big data
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能、机器学习与大数据之间的关系
- en: AI, ML, and big data are all closely related and often used together to create
    powerful solutions. Big data provides the fuel for AI and ML algorithms, which
    are used to extract insights and make predictions from the data. AI and ML, in
    turn, can be used to automate the processing of large datasets, making it possible
    to analyze and extract insights from massive amounts of data quickly and accurately.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）、机器学习（ML）和大数据彼此密切相关，常常一起使用来创造强大的解决方案。大数据为AI和ML算法提供了动力，这些算法用于从数据中提取见解并做出预测。而AI和ML又可以用来自动化处理大规模数据集，从而快速且准确地分析和提取数据中的见解。
- en: One of the most common use cases for AI, ML, and big data is in the field of
    predictive analytics. **Predictive analytics** is the practice of using data,
    statistical algorithms, and ML techniques to identify the likelihood of future
    outcomes, based on historical data. In this context, big data provides the raw
    data that is used to train ML models, while AI is used to develop predictive models
    that can analyze the data and make accurate predictions.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: AI、ML和大数据的一个最常见应用场景是预测分析领域。**预测分析**是利用数据、统计算法和机器学习技术，通过历史数据识别未来结果可能性的实践。在这个过程中，大数据提供了用于训练ML模型的原始数据，而AI则用于开发预测模型，分析数据并做出准确预测。
- en: Another use case for AI, ML, and big data is in the field of **natural language
    processing** (**NLP**). NLP is a subset of AI that focuses on analyzing and understanding
    human language. Big data is used to train NLP models on large datasets of text
    data, while ML is used to develop algorithms that can recognize patterns in language
    and extract meaning from text. NLP applications include chatbots, sentiment analysis,
    and language translation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: AI、ML 和大数据的另一个应用场景是在**自然语言处理**（**NLP**）领域。NLP 是 AI 的一个子集，专注于分析和理解人类语言。大数据用于在大量文本数据集上训练
    NLP 模型，而 ML 被用来开发能够识别语言模式并从文本中提取意义的算法。NLP 应用包括聊天机器人、情感分析和语言翻译。
- en: AI, ML, and big data are also used in the field of computer vision, which is
    the study of how computers can interpret and understand visual data from the world
    around them. Computer vision applications include facial recognition, object detection,
    and self-driving cars. In this context, big data is used to train ML models on
    large datasets of images, while AI is used to develop algorithms that can recognize
    patterns in visual data and make decisions based on that analysis.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: AI、ML 和大数据也被应用于计算机视觉领域，计算机视觉研究的是计算机如何解释和理解来自周围世界的视觉数据。计算机视觉的应用包括人脸识别、物体检测和自动驾驶汽车。在这个背景下，大数据被用来训练
    ML 模型，处理大量图像数据集，而 AI 则用于开发能够识别视觉数据中的模式并基于此分析做出决策的算法。
- en: The role of DevOps and engineering in AI, ML, and big data
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps 和工程在 AI、ML 和大数据中的角色
- en: The development of AI, ML, and big data solutions requires a high degree of
    collaboration between different teams, including data scientists, software engineers,
    and DevOps professionals. DevOps is a methodology that emphasizes collaboration,
    automation, and communication between software development and IT operations teams.
    In the context of AI, ML, and big data, DevOps is used to streamline the development,
    deployment, and maintenance of these solutions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AI、ML 和大数据解决方案的开发需要不同团队之间高度的协作，包括数据科学家、软件工程师和 DevOps 专业人员。DevOps 是一种强调软件开发与
    IT 运维团队之间协作、自动化和沟通的方法。在 AI、ML 和大数据的背景下，DevOps 被用于简化这些解决方案的开发、部署和维护。
- en: Engineering teams are responsible for the design and development of the underlying
    infrastructure that supports AI, ML, and big data solutions. This includes building
    data pipelines, developing software frameworks, and managing cloud infrastructure.
    Engineering teams also work closely with data scientists and software developers
    to ensure that AI, ML, and big data solutions are deployed and scaled correctly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 工程团队负责设计和开发支持 AI、ML 和大数据解决方案的基础设施。这包括构建数据管道、开发软件框架和管理云基础设施。工程团队还与数据科学家和软件开发人员密切合作，确保
    AI、ML 和大数据解决方案能够正确部署并扩展。
- en: DevOps teams play a critical role in the development and deployment of AI, ML,
    and big data solutions. DevOps practices such as **continuous integration and
    continuous delivery** (**CI/CD**) are used to automate the deployment and testing
    of these solutions, ensuring that they are delivered quickly and with high quality.
    DevOps also helps to ensure that AI, ML, and big data solutions are highly available
    and scalable, allowing them to handle large volumes of data and traffic.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 团队在 AI、ML 和大数据解决方案的开发和部署中发挥着至关重要的作用。DevOps 实践，如**持续集成和持续交付**（**CI/CD**），用于自动化这些解决方案的部署和测试，确保它们快速且高质量地交付。DevOps
    还帮助确保 AI、ML 和大数据解决方案具有高度可用性和可扩展性，使其能够处理大量数据和流量。
- en: Another critical aspect of DevOps in the context of AI, ML, and big data is
    security. As these technologies become increasingly important in various industries,
    ensuring the security and privacy of the data they handle is of paramount importance.
    DevOps teams must work closely with security teams to implement robust security
    measures, including encryption, access controls, and monitoring.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI、ML 和大数据的背景下，DevOps 的另一个关键方面是安全性。随着这些技术在各行各业变得越来越重要，确保它们处理的数据的安全性和隐私性变得至关重要。DevOps
    团队必须与安全团队密切合作，实施强有力的安全措施，包括加密、访问控制和监控。
- en: Challenges of AI, ML, and big data
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI、ML 和大数据的挑战
- en: In the contemporary digital era, AI, ML, and big data stand out as transformative
    technologies, rendering unparalleled advantages in various sectors such as healthcare,
    finance, and e-commerce. However, the utilization of these sophisticated technologies
    is also entwined with a multitude of challenges that demand meticulous attention
    and comprehensive strategies.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在当代数字时代，AI、ML和大数据作为具有变革性的技术脱颖而出，为医疗、金融和电子商务等多个领域带来了无与伦比的优势。然而，利用这些复杂技术也伴随着许多需要细致关注和全面策略的挑战。
- en: A prominent challenge that has been conspicuous in the deployment of AI, ML,
    and big data solutions is the persistent issue of data quality. While big data
    solutions are inherently dependent on processing vast datasets to derive insightful
    analytics and predictions, the efficacy of these solutions is invariably tethered
    to the quality of the data being processed. Suboptimal data quality, characterized
    by inconsistencies, errors, or incompleteness, can severely undermine the precision
    and reliability of models developed through AI and ML. Therefore, ensuring the
    veracity and accuracy of data becomes imperative to safeguard the credibility
    of outcomes obtained through these technologies.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能（AI）、机器学习（ML）和大数据解决方案的部署中，一个突出的问题是数据质量的持续性问题。虽然大数据解决方案本质上依赖于处理庞大的数据集以得出有洞察力的分析和预测，但这些解决方案的有效性始终与所处理数据的质量息息相关。数据质量不佳，表现为不一致、错误或不完整，可能严重削弱通过AI和ML开发的模型的准确性和可靠性。因此，确保数据的真实性和准确性对于保障通过这些技术获得的结果的可信度变得至关重要。
- en: Complexity and skill scarcity in the domain of AI, ML, and big data also stand
    out as formidable challenges. The effective development, deployment, and maintenance
    of solutions harnessing these technologies mandate a nuanced understanding of
    diverse fields, including data science, software engineering, and DevOps practices.
    Skilled professionals who embody expertise in these domains are not only scarce
    but also increasingly sought after, thereby engendering a competitive environment
    where organizations vie to secure top talent. This emphasizes the importance of
    not only focusing on talent acquisition but also on nurturing and developing in-house
    expertise, through training and development initiatives.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI、ML和大数据领域的复杂性以及技能短缺问题也是突出挑战。有效的开发、部署和维护这些技术所需解决方案，要求对多个领域有深刻的理解，包括数据科学、软件工程和DevOps实践。具备这些领域专业知识的熟练人才不仅稀缺，而且需求日益增加，从而形成了一个竞争激烈的环境，组织争相争夺顶尖人才。这突显了不仅要关注人才招聘，还要通过培训和发展计划培养和发展内部专业知识的重要性。
- en: Simultaneously, the surge in the implementation of AI, ML, and big data technologies
    has catapulted ethical considerations into the spotlight, warranting earnest deliberation.
    Ethical challenges encompass diverse aspects such as privacy implications, potential
    biases in algorithmic decision-making, and overarching fairness. The ubiquitous
    infusion of these technologies into everyday life raises legitimate concerns regarding
    data privacy and the ethical dimensions of automated decisions, especially in
    critical areas such as healthcare and criminal justice. Ensuring that algorithms
    are free from biases and function in a manner that upholds fairness and justice
    necessitates a collaborative effort involving DevOps, engineering teams, data
    scientists, and ethical compliance specialists.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，AI、ML和大数据技术的实施激增使得伦理问题成为关注的焦点，值得深入讨论。伦理挑战涵盖了隐私问题、算法决策中的潜在偏见以及整体公平性等多个方面。这些技术在日常生活中的普及引发了关于数据隐私和自动决策伦理层面的合理担忧，尤其是在医疗保健和刑事司法等关键领域。确保算法不含偏见，并以公正和正义的方式运行，需DevOps、工程团队、数据科学家和伦理合规专家的共同努力。
- en: In a similar way, regulatory compliance emerges as a critical aspect, necessitating
    adherence to a myriad of legal frameworks and guidelines that govern the utilization
    of AI, ML, and big data across various jurisdictions. Ensuring that solutions
    conform to regulatory stipulations, such as the GDPR in Europe and the CCPA in
    California, is imperative to mitigate legal risks and uphold organizational repute.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，监管合规性作为一个关键方面浮现出来，要求遵守各种法律框架和指导方针，这些规定了AI、ML和大数据在不同司法管辖区的使用。确保解决方案符合监管要求，如欧洲的GDPR和加利福尼亚州的CCPA，对于降低法律风险和维护组织声誉至关重要。
- en: Conclusively, AI, ML, and big data, while heralding an era of technological
    advancements and innovative solutions, concurrently present a landscape fraught
    with challenges that demand deliberate, ethical, and strategic responses. The
    role of DevOps and engineering teams, in concert with data scientists and compliance
    specialists, is pivotal in navigating through these challenges and ensuring the
    responsible, ethical, and effective deployment of these technologies. It’s undeniable
    that the potential boons offered by AI, ML, and big data are colossal, but they
    must be pursued with a steadfast commitment to quality, ethical considerations,
    and continuous improvement, in order to truly harness their transformative power
    in the future.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，人工智能（AI）、机器学习（ML）和大数据在带来技术进步和创新解决方案的同时，也呈现出充满挑战的局面，要求我们做出深思熟虑、伦理且战略性的应对。DevOps和工程团队与数据科学家及合规专家携手合作，在应对这些挑战并确保这些技术的负责任、伦理和有效部署方面发挥着关键作用。毫无疑问，人工智能、机器学习和大数据带来的潜力巨大，但必须始终坚守质量、伦理考量和持续改进，才能真正利用其在未来的变革性力量。
- en: A deep dive into big data as a DevOps data expert
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作为DevOps数据专家对大数据的深度解析
- en: Big data refers to extremely large, complex, and diverse datasets that are generated
    at a high velocity and require advanced tools and techniques to process and analyze
    effectively. The amount of data being generated by businesses, organizations,
    and individuals is increasing exponentially, and this data can come from a variety
    of sources, including sensors, social media, and mobile devices.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据指的是极其庞大、复杂和多样的数据集，这些数据以高速生成，需要先进的工具和技术来有效地处理和分析。企业、组织和个人生成的数据量正呈指数级增长，这些数据可以来自各种来源，包括传感器、社交媒体和移动设备。
- en: 'The key characteristics of big data are commonly referred to as the **3Vs**
    – **volume**, **velocity**, and **variety**:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据的关键特征通常被称为**3V**——**规模**、**速度**和**多样性**：
- en: '**Volume**: Big data involves extremely large datasets, often in the petabyte
    or even exabyte range. These datasets can include both structured and unstructured
    data.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规模**：大数据涉及极其庞大的数据集，通常在PB（拍字节）甚至EB（艾字节）范围内。这些数据集可能包含结构化数据和非结构化数据。'
- en: '**Velocity**: Big data is generated at a high velocity, meaning that it is
    constantly being created and updated in real time. This requires tools and techniques
    that can handle the fast pace of data ingestion and processing.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：大数据以高速度生成，意味着它是实时不断创建和更新的。这要求使用能够应对快速数据摄取和处理速度的工具和技术。'
- en: '**Variety**: Big data includes a variety of data types and formats, including
    text, audio, video, and images. This requires tools and techniques that can handle
    a diverse range of data formats and structures.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样性**：大数据包括多种类型和格式的数据，包括文本、音频、视频和图像。这要求使用能够处理各种数据格式和结构的工具和技术。'
- en: 'To process and analyze big data, advanced tools and techniques are required.
    Some of the key technologies used in big data include the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理和分析大数据，需要先进的工具和技术。一些大数据中使用的关键技术包括：
- en: '**Distributed computing**: This involves breaking up the processing of large
    datasets into smaller tasks that can be distributed across a network of computers,
    allowing for faster processing and analysis.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式计算**：这涉及将大数据集的处理任务拆分成较小的任务，分配到计算机网络中，以实现更快的处理和分析。'
- en: '**Hadoop**: Hadoop is an open source framework that enables distributed storage
    and processing of large datasets. It is based on the MapReduce programming model
    and the **Hadoop Distributed File** **System** (**HDFS**).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop**：Hadoop是一个开源框架，支持大数据集的分布式存储和处理。它基于MapReduce编程模型和**Hadoop分布式文件系统**（**HDFS**）。'
- en: '**NoSQL databases**: NoSQL databases are designed to handle unstructured data
    and are often used in big data applications. Examples of NoSQL databases include
    MongoDB, Cassandra, and Couchbase.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NoSQL数据库**：NoSQL数据库旨在处理非结构化数据，通常用于大数据应用中。常见的NoSQL数据库包括MongoDB、Cassandra和Couchbase。'
- en: '**Data mining and ML**: These techniques are used to extract insights and patterns
    from big data. They can be used for tasks such as predictive modeling, anomaly
    detection, and clustering.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据挖掘和机器学习**：这些技术用于从大数据中提取洞察和模式。它们可用于预测建模、异常检测和聚类等任务。'
- en: '**Data visualization**: Data visualization tools are used to present the results
    of big data analysis in a way that is easy to understand and interpret.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据可视化**：数据可视化工具用于以易于理解和解释的方式呈现大数据分析的结果。'
- en: Big data is being used in a variety of industries and applications, from healthcare
    and finance to marketing and social media. By effectively processing and analyzing
    big data, organizations can gain insights and make data-driven decisions that
    can improve their operations and competitiveness.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据正在被广泛应用于多个行业和领域，从医疗保健、金融到营销和社交媒体。通过有效地处理和分析大数据，组织可以获得见解并做出数据驱动的决策，从而改善运营和增强竞争力。
- en: At the infrastructure level, big data relies on a combination of hardware and
    software components to store, process, and analyze data. As a DevOps engineer,
    it is important to understand how big data works at the infrastructure level and
    the common challenges you may encounter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在基础设施层面，大数据依赖硬件和软件组件的组合来存储、处理和分析数据。作为 DevOps 工程师，了解大数据在基础设施层面的工作方式以及可能遇到的常见挑战非常重要。
- en: Big data infrastructure
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大数据基础设施
- en: 'Big data infrastructure typically includes a combination of the following components:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据基础设施通常包括以下组件的组合：
- en: '**Storage**: Big data requires large-scale storage solutions that can store
    terabytes, petabytes, or even exabytes of data. Popular storage solutions include
    HDFS, Amazon S3, and Google Cloud Storage.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储**：大数据需要大规模的存储解决方案，以存储TB、PB，甚至EB的数据。常见的存储解决方案包括 HDFS、Amazon S3 和 Google
    Cloud Storage。'
- en: '**Processing**: Big data processing involves parallel processing of data across
    multiple servers. Distributed processing frameworks such as Apache Spark and Apache
    Hadoop are popular solutions to process big data.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理**：大数据处理涉及在多个服务器之间并行处理数据。分布式处理框架如 Apache Spark 和 Apache Hadoop 是处理大数据的常见解决方案。'
- en: '**Compute**: Big data workloads require significant compute resources to process
    and analyze data. Compute resources can be provided by on-premises servers or
    cloud-based solutions, such as Amazon EC2 and Google Compute Engine.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算**：大数据工作负载需要大量的计算资源来处理和分析数据。计算资源可以通过本地服务器或基于云的解决方案提供，例如 Amazon EC2 和 Google
    Compute Engine。'
- en: '**Networking**: Big data workloads often involve moving large amounts of data
    across networks. High-speed networks and low-latency connections are essential
    for efficient big data processing.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络**：大数据工作负载通常需要在网络中传输大量数据。高速网络和低延迟连接对于高效的大数据处理至关重要。'
- en: Challenges with big data
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大数据面临的挑战
- en: 'As a DevOps engineer working with big data, you may encounter several challenges.
    Here are some of the most common challenges and how to address them:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名处理大数据的 DevOps 工程师，你可能会遇到一些挑战。以下是一些常见的挑战及其解决方法：
- en: '**Data integration**: Big data often comes from multiple sources and in different
    formats. Integrating and processing data from multiple sources can be challenging.
    To address this, you can use data integration tools such as Apache NiFi, Talend,
    or Apache Beam.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集成**：大数据通常来自多个源并采用不同的格式。从多个源集成和处理数据可能具有挑战性。为了解决这个问题，可以使用数据集成工具，如 Apache
    NiFi、Talend 或 Apache Beam。'
- en: 'Here is an example of using Apache NiFi for data integration:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是使用 Apache NiFi 进行数据集成的示例：
- en: XML
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: XML
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Data security**: Big data can contain sensitive information that requires
    protection. To address this, you can implement security measures such as access
    control, encryption, and monitoring.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据安全**：大数据可能包含需要保护的敏感信息。为了解决这个问题，可以实施访问控制、加密和监控等安全措施。'
- en: 'Here is an example of using encryption with Amazon S3:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是使用 Amazon S3 进行加密的示例：
- en: PYTHON
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Performance**: Big data processing can be computationally intensive and require
    significant resources. To address this, you can use techniques such as distributed
    processing and caching.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：大数据处理可能计算密集型并需要大量资源。为了解决这个问题，可以使用分布式处理和缓存等技术。'
- en: 'Here is an example of using caching with Redis:'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是使用 Redis 进行缓存的示例：
- en: PYTHON
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Monitoring**: Big data processing can be complex, and monitoring is essential
    to ensure that the processing is running smoothly. To address this, you can use
    monitoring tools such as Nagios, Zabbix, or Grafana.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：大数据处理可能非常复杂，监控对于确保处理过程顺利运行至关重要。为了解决这个问题，可以使用 Nagios、Zabbix 或 Grafana
    等监控工具。'
- en: 'Here is an example of using Nagios for monitoring:'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是使用 Nagios 进行监控的示例：
- en: SHELL
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: SHELL
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Big data is a complex and diverse field that involves processing and analyzing
    large and complex datasets. At the infrastructure level, big data relies on a
    combination of hardware and software components to store, process, and analyze
    the data. As a DevOps engineer, it is important to understand how big data works
    on the infrastructure level and the common challenges you may encounter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据是一个复杂且多样化的领域，涉及处理和分析大规模且复杂的数据集。在基础设施层面，大数据依赖硬件和软件组件的结合来存储、处理和分析数据。作为DevOps工程师，了解大数据在基础设施层面的工作原理以及你可能遇到的常见挑战是非常重要的。
- en: Common challenges with big data include data integration, data security, performance,
    and monitoring. To address these challenges, DevOps engineers can use a combination
    of tools and techniques, such as data integration tools, encryption, caching,
    and monitoring tools.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据的常见挑战包括数据集成、数据安全、性能和监控。为了解决这些挑战，DevOps工程师可以使用多种工具和技术，例如数据集成工具、加密、缓存和监控工具。
- en: By understanding the common challenges with big data and implementing robust
    processes and tools, DevOps engineers can build effective and reliable big data
    solutions that deliver accurate and actionable results.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通过了解大数据的常见挑战，并实施健全的流程和工具，DevOps工程师可以构建出有效且可靠的大数据解决方案，提供准确且可操作的结果。
- en: A deep dive into ML as a DevOps data expert
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解作为DevOps数据专家的机器学习
- en: ML is a subset of AI that involves building systems that can automatically learn
    and improve from data without being explicitly programmed. ML algorithms are designed
    to identify patterns and relationships in data, using these patterns to make predictions
    or take actions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能（AI）的一个子集，涉及构建能够自动从数据中学习并改进的系统，而无需明确编程。机器学习算法旨在识别数据中的模式和关系，利用这些模式进行预测或采取行动。
- en: From a DevOps point of view, ML can be viewed as a software application that
    can learn and improve over time. This requires a different approach to software
    development and deployment than traditional applications. In this section, we
    will discuss how ML works and how it differs from traditional software applications.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从DevOps的角度来看，机器学习可以被视为一种能够学习和随着时间推移不断改进的软件应用。这需要一种不同于传统应用的软件开发和部署方式。在本节中，我们将讨论机器学习的工作原理以及它与传统软件应用的区别。
- en: How ML works
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的工作原理
- en: 'ML involves several key steps:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习包括几个关键步骤：
- en: '**Data collection**: The first step in ML is to collect data that can be used
    to train a model. This data can come from a variety of sources, including sensors,
    social media, or user interactions.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据收集**：机器学习的第一步是收集可以用于训练模型的数据。这些数据可以来自多种来源，包括传感器、社交媒体或用户互动。'
- en: '**Data preprocessing**: Once the data is collected, it needs to be preprocessed
    to ensure that it is in a suitable format to train the ML model. This may involve
    tasks such as data cleaning, data normalization, and feature engineering.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据预处理**：数据收集后，需要对数据进行预处理，以确保它适合用于训练机器学习模型。这可能涉及数据清洗、数据标准化和特征工程等任务。'
- en: '**Model training**: The next step is to train the ML model on the preprocessed
    data. This involves selecting an appropriate algorithm, setting hyperparameters,
    and training the model on the data.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：下一步是对预处理后的数据进行机器学习（ML）模型的训练。这包括选择合适的算法、设置超参数，并在数据上训练模型。'
- en: '**Model evaluation**: Once the model is trained, it needs to be evaluated to
    determine its accuracy and performance. This may involve testing the model on
    a separate dataset or using cross-validation techniques.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型评估**：一旦模型被训练完成，需要评估其准确性和性能。这可能涉及在独立数据集上测试模型或使用交叉验证技术。'
- en: '**Model deployment**: The final step is to deploy the model in a production
    environment, where it can make predictions or take actions based on new data.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型部署**：最后一步是将模型部署到生产环境中，在那里它可以根据新数据进行预测或采取行动。'
- en: How ML differs from traditional software applications
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习与传统软件应用的区别
- en: 'ML differs from traditional software applications in several ways:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习与传统软件应用在多个方面有所不同：
- en: '**ML applications are data-driven**: Unlike traditional software applications,
    which are designed to execute a predefined set of instructions, ML applications
    are designed to learn from data and improve over time.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习应用是数据驱动的**：与传统的软件应用不同，传统应用是设计用来执行预定义的一组指令，而机器学习应用则是设计用来从数据中学习，并随着时间的推移不断改进。'
- en: '**ML applications require continuous training and improvement**: ML models
    need to be continuously trained and improved over time to maintain their accuracy
    and reliability. This requires a different approach to software development and
    deployment than traditional applications.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习应用需要持续的训练和改进**：机器学习模型需要随着时间的推移不断训练和改进，以保持其准确性和可靠性。这要求与传统应用程序不同的软件开发和部署方法。'
- en: '**ML applications require a different infrastructure**: ML applications often
    require complex infrastructure and specific hardware and software configurations.
    This requires a different approach to infrastructure management than traditional
    applications.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习应用需要不同的基础设施**：机器学习应用通常需要复杂的基础设施以及特定的硬件和软件配置。这要求与传统应用程序不同的方法来进行基础设施管理。'
- en: '**ML applications require different testing and validation techniques**: ML
    models require different testing and validation techniques than traditional software
    applications. This may involve techniques such as cross-validation, confusion
    matrix analysis, and A/B testing.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习应用需要不同的测试和验证技术**：机器学习模型需要与传统软件应用程序不同的测试和验证技术。这可能涉及交叉验证、混淆矩阵分析和A/B测试等技术。'
- en: In conclusion, ML is a subset of AI that involves building systems that can
    automatically learn and improve from data. From a DevOps point of view, ML can
    be viewed as a software application that requires a different approach to development,
    deployment, infrastructure management, and testing and validation. By understanding
    the unique challenges and requirements of ML, DevOps teams can build effective
    and reliable ML solutions that deliver accurate and actionable results.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，机器学习是人工智能的一个子集，涉及构建能够从数据中自动学习和改进的系统。从DevOps的角度来看，机器学习可以被视为一种需要不同开发、部署、基础设施管理以及测试和验证方法的软件应用程序。通过了解机器学习的独特挑战和要求，DevOps团队可以构建有效且可靠的机器学习解决方案，从而提供准确且可操作的结果。
- en: Challenges with ML for a DevOps data expert
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps数据专家面临的机器学习挑战
- en: As a DevOps data expert, there are several challenges and technical aspects
    that you need to know about when working with ML. These include data preparation,
    model training, model deployment, monitoring, and maintenance. In this section,
    we will discuss these challenges and technical aspects, providing examples with
    code snippets to help you better understand them.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名DevOps数据专家，您在处理机器学习时需要了解多个挑战和技术方面。这些包括数据准备、模型训练、模型部署、监控和维护。在本节中，我们将讨论这些挑战和技术方面，并提供带有代码示例的帮助，帮助您更好地理解它们。
- en: Data preparation
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: Data preparation is the process of collecting, cleaning, and transforming data
    to make it suitable for use in ML models. This is a critical step, as the quality
    of the data used to train ML models has a direct impact on their accuracy and
    performance.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备是收集、清理和转换数据的过程，以使其适合用于机器学习模型。这是一个关键步骤，因为用于训练机器学习模型的数据质量直接影响其准确性和性能。
- en: 'One of the challenges of data preparation is dealing with missing data. There
    are several ways to handle missing data, including imputation, deletion, and using
    models that can handle missing values. Here is an example of how to handle missing
    data using Pandas in Python:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备的一个挑战是处理缺失数据。处理缺失数据的方法有多种，包括插补、删除和使用能够处理缺失值的模型。以下是使用Pandas在Python中处理缺失数据的示例：
- en: PYTHON
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE4]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This code imports the `pandas` and `numpy` libraries to handle and manipulate
    data. It then creates a DataFrame (`df`), with some missing values indicated by
    `np.nan`. Subsequently, it fills the missing values in the dataframe with the
    mean of each respective column.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码导入了`pandas`和`numpy`库来处理和操作数据。然后创建了一个数据框（`df`），其中一些缺失值由`np.nan`表示。随后，它使用每个相应列的均值填充数据框中的缺失值。
- en: 'Another challenge of data preparation is dealing with categorical variables.
    ML algorithms typically work with numerical data, so categorical variables must
    be encoded in some way. There are several encoding methods, including one-hot
    encoding, label encoding, and binary encoding. Here is an example of one-hot encoding
    using Scikit-Learn in Python:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备的另一个挑战是处理类别变量。机器学习算法通常处理数值数据，因此必须以某种方式对类别变量进行编码。有几种编码方法，包括独热编码、标签编码和二进制编码。以下是使用Python中的Scikit-Learn进行独热编码的示例：
- en: PYTHON
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE5]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Model training
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: Model training is the process of using data to train an ML model. This involves
    selecting an appropriate algorithm, setting hyperparameters, and training the
    model on the data. One of the challenges of model training is **overfitting**,
    which occurs when a model is too complex and fits the training data too closely,
    resulting in poor generalization to new data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练是使用数据来训练机器学习模型的过程。这涉及到选择合适的算法、设置超参数以及在数据上训练模型。模型训练的一大挑战是**过拟合**，即当模型过于复杂并且过度拟合训练数据时，导致对新数据的泛化能力差。
- en: 'To address overfitting, several regularization techniques can be used, including
    L1 regularization, L2 regularization, and dropout. Here is an example of L2 regularization,
    using Keras in Python:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决过拟合问题，可以使用几种正则化技术，包括L1正则化、L2正则化和丢弃法。以下是使用Python中的Keras实现L2正则化的示例：
- en: PYTHON
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Another challenge of model training is hyperparameter tuning. Hyperparameters
    are parameters that are set before training and determine the behavior of the
    algorithm. These include the learning rate, the batch size, and the number of
    hidden layers. Hyperparameter tuning involves selecting the best combination of
    hyperparameters for a given problem. Here is an example of hyperparameter tuning,
    using `GridSearchCV` in Scikit-Learn:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练的另一个挑战是超参数调优。超参数是在训练之前设置的参数，决定了算法的行为。这些参数包括学习率、批量大小和隐藏层的数量。超参数调优的过程是为特定问题选择最佳的超参数组合。以下是使用Scikit-Learn中的`GridSearchCV`进行超参数调优的示例：
- en: PYTHON
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Model deployment
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型部署
- en: Model deployment is the process of making ML models available for use in production
    environments. This involves creating an infrastructure that can support the model,
    such as a server or cloud environment, and integrating the model into an application
    or service.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署是将机器学习模型投入生产环境中使用的过程。这涉及到创建支持模型的基础设施，如服务器或云环境，并将模型集成到应用程序或服务中。
- en: 'One of the challenges of model deployment is scalability. As the number of
    users or requests increases, the infrastructure supporting the model must be able
    to handle the load. This can be addressed by using techniques such as load balancing,
    caching, and auto-scaling. Here is an example of using **Amazon Web Services**
    (**AWS**) to deploy an ML model with auto-scaling:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署的一个挑战是可扩展性。随着用户或请求数量的增加，支持模型的基础设施必须能够处理负载。可以通过使用负载均衡、缓存和自动扩展等技术来解决这一问题。以下是使用**亚马逊网络服务**（**AWS**）进行自动扩展部署机器学习模型的示例：
- en: PYTHON
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Another challenge of model deployment is versioning. As models are updated and
    improved, it is important to keep track of different versions and ensure that
    the correct version is used in production. This can be addressed by using version
    control systems and implementing versioning in the model deployment process.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署的另一个挑战是版本控制。随着模型的更新和改进，必须跟踪不同的版本并确保在生产环境中使用正确的版本。这可以通过使用版本控制系统以及在模型部署过程中实施版本管理来解决。
- en: Monitoring and maintenance
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控与维护
- en: Once an ML model is deployed, it is important to monitor its performance and
    maintain its accuracy. One of the challenges of monitoring is detecting drift,
    which occurs when the distribution of the data used to train the model changes
    over time. Drift can result in degraded performance and inaccurate predictions.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦机器学习模型部署完成，监控其性能和保持准确性是非常重要的。监控的一大挑战是检测漂移，漂移是指用于训练模型的数据分布随着时间发生变化。这种漂移可能导致性能下降和预测不准确。
- en: 'To detect drift, several techniques can be used, including statistical tests,
    divergence measures, and anomaly detection. Here is an example of using the Kolmogorov-Smirnov
    test to detect drift in Scikit-Learn:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测漂移，可以使用几种技术，包括统计检验、发散度度量和异常检测。以下是使用Kolmogorov-Smirnov检验在Scikit-Learn中检测漂移的示例：
- en: PYTHON
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Another challenge of monitoring and maintenance is retraining the model. As
    data changes or model performance degrades, it may be necessary to retrain the
    model on new data. This can be automated using techniques such as online learning
    and active learning.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 监控和维护的另一个挑战是重新训练模型。随着数据变化或模型性能下降，可能需要在新数据上重新训练模型。可以使用在线学习和主动学习等技术来实现自动化。
- en: In conclusion, there are several challenges and technical aspects to consider
    when working with ML as a DevOps data expert. These include data preparation,
    model training, model deployment, monitoring, and maintenance. By understanding
    these challenges and using the appropriate techniques and tools, DevOps data experts
    can create effective ML solutions that deliver accurate and reliable results.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，在作为DevOps数据专家使用机器学习时，有几个挑战和技术方面需要考虑。这些包括数据准备、模型训练、模型部署、监控和维护。通过理解这些挑战并使用适当的技术和工具，DevOps数据专家可以创建有效的机器学习解决方案，提供准确和可靠的结果。
- en: A deep dive into AI as a DevOps data- expert
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨作为DevOps数据专家的AI
- en: AI services are a type of cloud service that provides access to pre-trained
    models and algorithms, for use in ML and other AI applications. From a DevOps
    and infrastructure point of view, AI services can be a powerful tool to accelerate
    the development and deployment of AI applications.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: AI服务是一种云服务，提供对预训练模型和算法的访问，用于机器学习和其他AI应用。从DevOps和基础设施的角度来看，AI服务可以成为加速AI应用开发和部署的强大工具。
- en: Here are some examples of AI services and how they can be used.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些AI服务及其使用示例。
- en: Amazon SageMaker
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon SageMaker
- en: Amazon SageMaker is a fully managed service that provides developers and data
    scientists with the ability to build, train, and deploy ML models at scale.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker 是一项完全托管的服务，旨在为开发者和数据科学家提供构建、训练和大规模部署机器学习模型的能力。
- en: 'Here is an example of using Amazon SageMaker to train an ML model:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用Amazon SageMaker训练机器学习模型的示例：
- en: PYTHON
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE10]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This code interfaces with AWS’s SageMaker and S3 services to facilitate ML training.
    Firstly, it establishes a SageMaker session and creates an S3 bucket for data
    storage, specifying a CSV file for training. Then, it defines a training job with
    specified parameters, including the machine instance type and container image,
    and initiates the training using the provided data.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码与AWS的SageMaker和S3服务接口，便于进行机器学习训练。首先，它建立一个SageMaker会话，并为数据存储创建一个S3桶，指定一个CSV文件用于训练。接着，它定义了一个训练任务，指定了机器实例类型和容器镜像，并使用提供的数据启动训练。
- en: Google Cloud AI platform
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google Cloud AI平台
- en: The Google Cloud AI platform is a cloud-based service that provides tools and
    infrastructure to develop and deploy ML models.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud AI平台是一项基于云的服务，提供开发和部署机器学习模型的工具和基础设施。
- en: 'Here is an example of using Google Cloud AI platform to train an ML model:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用Google Cloud AI平台训练机器学习模型的示例：
- en: PYTHON
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE11]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This code interacts with Google Cloud’s AI platform to launch a custom training
    job. Using the provided credentials, it establishes a connection to AI Platform
    in the `us-central1` region and specifies a job that utilizes a Docker image named
    `my-image` to execute a Python script, `train.py`, with designated input and output
    paths in a Google Cloud Storage bucket. Once the job specification is set, it’s
    submitted to the platform for execution.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码与Google Cloud的AI平台交互，以启动一个自定义的训练任务。使用提供的凭证，它与`us-central1`区域的AI平台建立连接，并指定一个任务，利用名为`my-image`的Docker镜像执行Python脚本`train.py`，并在Google
    Cloud Storage存储桶中指定输入和输出路径。任务规格设置完成后，它将被提交到平台进行执行。
- en: Microsoft Azure Machine Learning
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Microsoft Azure Machine Learning
- en: Microsoft Azure Machine Learning is a cloud-based service that provides tools
    and infrastructure to build, train, and deploy ML models.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Azure Machine Learning 是一项基于云的服务，提供构建、训练和部署机器学习模型的工具和基础设施。
- en: 'Here is an example of using Microsoft Azure Machine Learning to train an ML
    model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用Microsoft Azure Machine Learning训练机器学习模型的示例：
- en: PYTHON
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE12]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: AI services are a powerful tool to accelerate the development and deployment
    of AI applications. From a DevOps and infrastructure point of view, AI services
    provide access to pre-trained models and algorithms, as well as tools and infrastructure
    to build, train, and deploy machines.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: AI服务是加速AI应用开发和部署的强大工具。从DevOps和基础设施的角度来看，AI服务提供了对预训练模型和算法的访问，并且提供了构建、训练和部署机器的工具和基础设施。
- en: Challenges with AI for a DevOps data expert
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps数据专家面临的AI挑战
- en: As a DevOps engineer responsible for AI services, there are several challenges
    that you may encounter on a day-to-day basis. These challenges can include managing
    infrastructure, managing ML models, ensuring security and compliance, and optimizing
    performance and scalability. Let’s review some examples of the most common challenges
    and suggest ways to overcome them.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 作为负责AI服务的DevOps工程师，你可能会遇到几个日常挑战。这些挑战可能包括管理基础设施、管理机器学习模型、确保安全性和合规性，以及优化性能和可扩展性。让我们回顾一些最常见的挑战，并提出克服它们的方法。
- en: Managing infrastructure
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理基础设施
- en: One of the primary challenges of managing AI services is managing the infrastructure
    required to support ML workflows. This can include setting up and configuring
    cloud-based resources such as virtual machines, databases, and storage solutions.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 管理AI服务的主要挑战之一是管理支持机器学习工作流的基础设施。这可能包括设置和配置基于云的资源，如虚拟机、数据库和存储解决方案。
- en: Example – provisioning infrastructure with AWS CloudFormation
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 示例 – 使用AWS CloudFormation配置基础设施
- en: To automate the process of setting up and managing infrastructure, you might
    use a tool such as AWS CloudFormation. **CloudFormation** is an infrastructure-as-code
    tool that allows you to define and manage AWS resources, using a high-level JSON
    or YAML configuration file.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了自动化设置和管理基础设施的过程，你可以使用AWS CloudFormation等工具。**CloudFormation**是一个基础设施即代码工具，它允许你使用高层次的JSON或YAML配置文件定义和管理AWS资源。
- en: 'Here is an example of using CloudFormation to create an Amazon SageMaker notebook
    instance:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用CloudFormation创建Amazon SageMaker笔记本实例的示例：
- en: YAML
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: YAML
- en: '[PRE13]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This CloudFormation template creates an Amazon SageMaker notebook instance with
    the specified instance type and IAM role.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这个CloudFormation模板会创建一个具有指定实例类型和IAM角色的Amazon SageMaker笔记本实例。
- en: To overcome the challenge of managing infrastructure, I recommend using infrastructure-as-code
    tools such as CloudFormation or Terraform to automate the provisioning and management
    of cloud resources. By using these tools, you can easily create, update, and delete
    resources as needed, reducing the risk of manual errors and ensuring consistency
    across environments.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服管理基础设施的挑战，我建议使用基础设施即代码工具，如CloudFormation或Terraform，来自动化云资源的配置和管理。通过使用这些工具，你可以轻松创建、更新和删除资源，从而减少手动错误的风险，并确保环境的一致性。
- en: Managing ML models
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理机器学习模型
- en: Another significant challenge of managing AI services is managing ML models.
    This can include building and training models, deploying models to production,
    and monitoring model performance.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 管理AI服务的另一个重要挑战是管理机器学习模型。这可能包括构建和训练模型、将模型部署到生产环境中以及监控模型性能。
- en: Example – building and training an ML model with TensorFlow
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 示例 – 使用TensorFlow构建和训练机器学习模型
- en: To build and train an ML model, I might use a popular deep learning framework
    such as TensorFlow. **TensorFlow** provides a range of tools and infrastructure
    to build and train ML models.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建和训练一个机器学习模型，我可能会使用一个流行的深度学习框架，例如TensorFlow。**TensorFlow**提供了一系列构建和训练机器学习模型的工具和基础设施。
- en: 'Here is an example of using TensorFlow to build and train a convolutional neural
    network for image classification:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用TensorFlow构建和训练一个卷积神经网络进行图像分类的示例：
- en: PYTHON
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This code defines a convolutional neural network for image classification, trains
    the model on the *Fashion MNIST* dataset, and evaluates the model’s performance.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码定义了一个用于图像分类的卷积神经网络，训练模型使用的是*Fashion MNIST*数据集，并评估模型的性能。
- en: To overcome the challenge of managing ML models, I recommend using a version
    control system such as **Git** to track changes to model code and configuration.
    This allows for easy collaboration, experimentation, and tracking of changes over
    time. Additionally, using automated testing and deployment processes can help
    ensure that models are working as expected and that changes are properly tested
    and deployed to production.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服管理机器学习模型的挑战，我建议使用版本控制系统，例如**Git**，来跟踪模型代码和配置的变化。这可以便于协作、实验以及追踪变化历史。此外，使用自动化测试和部署流程可以帮助确保模型按预期工作，并确保更改得到正确的测试和部署到生产环境中。
- en: Ensuring security and compliance
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确保安全性和合规性
- en: Security and compliance are critical concerns when managing AI services, especially
    when dealing with sensitive data such as personal or financial information. As
    DevOps engineers responsible for AI services, we must ensure that the infrastructure
    and processes we implement comply with relevant security and data protection regulations.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性和合规性在管理人工智能服务时至关重要，尤其是在处理个人或财务等敏感数据时。作为负责人工智能服务的 DevOps 工程师，我们必须确保我们实施的基础设施和流程符合相关的安全性和数据保护法规。
- en: Example – securing ML models with AWS SageMaker
  id: totrans-162
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 示例 – 使用 AWS SageMaker 保障机器学习模型安全
- en: Amazon SageMaker provides several tools and services to secure ML models. For
    example, you can use SageMaker’s built-in model encryption and data encryption
    features to ensure that models and data are encrypted both in transit and at rest.
    You can also use AWS **Key Management Service** (**KMS**) to manage encryption
    keys and control access to sensitive data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker 提供了多种工具和服务来保障机器学习模型的安全。例如，您可以使用 SageMaker 内置的模型加密和数据加密功能，确保模型和数据在传输和静态状态下都得到加密。您还可以使用
    AWS **密钥管理服务**（**KMS**）来管理加密密钥并控制对敏感数据的访问。
- en: 'Here is an example of using SageMaker’s encryption features to encrypt an ML
    model:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用 SageMaker 的加密功能对机器学习模型进行加密的示例：
- en: PYTHON
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE15]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This code creates a SageMaker model and then enables network isolation and VPC
    configuration, ensuring that the model is encrypted and secured.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码创建了一个 SageMaker 模型，并启用了网络隔离和 VPC 配置，确保模型被加密并且安全。
- en: To overcome the challenge of ensuring security and compliance, I recommend working
    closely with security and compliance teams to understand relevant regulations
    and best practices. Implementing secure infrastructure and processes, such as
    encrypting data and managing access control with AWS KMS, can help ensure that
    sensitive data is protected and that regulatory requirements are met.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服确保安全性和合规性的挑战，我建议与安全和合规团队紧密合作，理解相关的法规和最佳实践。实施安全的基础设施和流程，例如加密数据和使用 AWS KMS
    管理访问控制，可以帮助确保敏感数据得到保护，并满足合规要求。
- en: Optimizing performance and scalability
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化性能和可扩展性
- en: Finally, as a DevOps engineer responsible for AI services, I must ensure that
    the infrastructure and processes I implement are performant and scalable. This
    includes optimizing resource usage, identifying and resolving bottlenecks, and
    implementing efficient data processing pipelines.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，作为负责人工智能服务的 DevOps 工程师，我必须确保我实施的基础设施和流程具有良好的性能和可扩展性。这包括优化资源使用、识别并解决瓶颈问题，以及实现高效的数据处理管道。
- en: Example – scaling data processing with Apache Spark
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 示例 – 使用 Apache Spark 扩展数据处理
- en: Apache Spark is a popular distributed computing framework that can be used to
    process large datasets in parallel. To optimize performance and scalability, I
    can use Spark to preprocess and transform data for use in ML workflows.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 是一个流行的分布式计算框架，可以用于并行处理大数据集。为了优化性能和可扩展性，我可以使用 Spark 来预处理和转换数据，以便在机器学习工作流中使用。
- en: 'Here is an example of using Spark to preprocess a dataset for use in an ML
    pipeline:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用 Spark 预处理数据集以便用于机器学习管道的示例：
- en: PYTHON
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: PYTHON
- en: '[PRE16]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This code uses Spark to read in a dataset from a CSV file, assemble the features
    into a vector, and then apply a preprocessing pipeline to the data.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使用 Spark 从 CSV 文件读取数据集，将特征组合成向量，然后应用预处理管道对数据进行处理。
- en: To overcome the challenge of optimizing performance and scalability, I recommend
    using tools such as Apache Spark and Amazon EMR to distribute data processing
    and handle large-scale ML workloads. Additionally, using monitoring and logging
    tools such as AWS CloudWatch or the ELK Stack can help identify performance bottlenecks
    and debug issues as they arise.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服优化性能和可扩展性的挑战，我建议使用诸如 Apache Spark 和 Amazon EMR 等工具来分布式处理数据，并处理大规模的机器学习工作负载。此外，使用监控和日志工具，如
    AWS CloudWatch 或 ELK Stack，可以帮助识别性能瓶颈并调试出现的问题。
- en: As a DevOps engineer responsible for AI services, my day-to-day activities involve
    managing the infrastructure and processes to build, train, and deploy ML models.
    I face challenges such as managing infrastructure, managing ML models, ensuring
    security and compliance, and optimizing performance and scalability. However,
    by using best practices and tools such as infrastructure-as-code, version control,
    and distributed computing frameworks, I can overcome these challenges and build
    robust and efficient AI services.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 作为负责AI服务的DevOps工程师，我的日常工作包括管理基础设施和流程，以构建、训练和部署机器学习（ML）模型。我面临的挑战包括基础设施管理、机器学习模型管理、确保安全性和合规性，以及优化性能和可扩展性。然而，通过使用最佳实践和工具，如基础设施即代码、版本控制和分布式计算框架，我可以克服这些挑战，构建稳健且高效的AI服务。
- en: Summary
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In summary, AI, ML, and big data are technologies that have revolutionized the
    way we work with data and automation. They offer a wide range of benefits to organizations,
    such as improved efficiency, accuracy, and decision-making. However, integrating
    and managing these technologies can be challenging, particularly for DevOps and
    engineering teams who are responsible for building, deploying, and maintaining
    these solutions.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，AI、ML和大数据是彻底改变我们处理数据和自动化方式的技术。它们为组织提供了广泛的好处，例如提高效率、准确性和决策能力。然而，整合和管理这些技术可能会面临挑战，尤其是对于负责构建、部署和维护这些解决方案的DevOps和工程团队。
- en: One of the most significant challenges that DevOps engineers face when working
    with AI, ML, and big data is managing the infrastructure required to support these
    technologies. For example, building and maintaining cloud-based resources such
    as virtual machines, databases, and storage solutions can be complex and time-consuming.
    Infrastructure-as-code tools such as AWS CloudFormation and Terraform can help
    automate the process of setting up and managing cloud resources. Using these tools,
    DevOps engineers can easily create, update, and delete resources as needed, reducing
    the risk of manual errors, and ensuring consistency across environments.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps工程师在处理AI、ML和大数据时面临的最重大挑战之一是管理支持这些技术所需的基础设施。例如，构建和维护云资源（如虚拟机、数据库和存储解决方案）可能复杂且耗时。像AWS
    CloudFormation和Terraform这样的基础设施即代码工具可以帮助自动化云资源的设置和管理。使用这些工具，DevOps工程师可以轻松创建、更新和删除资源，减少手动错误的风险，并确保环境之间的一致性。
- en: Another challenge that DevOps engineers face when working with AI services is
    managing ML models. Building and training models, deploying them to production,
    and monitoring model performance are all complex tasks that require specialized
    knowledge and expertise. Version control systems such as Git can help track changes
    to model code and configuration, ensuring that changes are properly tested and
    deployed to production. Automated testing and deployment processes can also help
    ensure that models work as expected and that changes are properly tested and deployed
    to production.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个DevOps工程师在处理AI服务时面临的挑战是管理机器学习模型。构建和训练模型、将其部署到生产环境并监控模型性能，都是需要专业知识和技能的复杂任务。版本控制系统如Git可以帮助跟踪模型代码和配置的变更，确保变更经过适当的测试并部署到生产环境。自动化的测试和部署流程也可以确保模型按预期工作，并确保变更经过充分测试并顺利部署到生产环境。
- en: Ensuring security and compliance is another critical concern when managing AI
    services, especially when dealing with sensitive data such as personal or financial
    information. DevOps engineers must ensure that the infrastructure and processes
    they implement comply with relevant security and data protection regulations.
    Cloud-based services such as Amazon SageMaker provide several tools and services
    to secure ML models, including built-in model encryption and data encryption features.
    AWS KMS can also be used to manage encryption keys and control access to sensitive
    data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 确保安全性和合规性是管理AI服务时的另一个关键问题，尤其是在处理敏感数据（如个人信息或财务信息）时。DevOps工程师必须确保他们实施的基础设施和流程符合相关的安全和数据保护法规。像亚马逊SageMaker这样的云服务提供了多种工具和服务来保护机器学习模型，包括内置的模型加密和数据加密功能。AWS
    KMS也可用于管理加密密钥和控制对敏感数据的访问。
- en: Finally, DevOps engineers must ensure that the infrastructure and processes
    they implement are performant and scalable. This includes optimizing resource
    usage, identifying and resolving bottlenecks, and implementing efficient data
    processing pipelines. Distributed computing frameworks such as Apache Spark can
    help handle large-scale ML workloads, and monitoring and logging tools such as
    AWS CloudWatch or the ELK Stack can help identify performance bottlenecks and
    debug issues as they arise.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，DevOps 工程师必须确保他们实施的基础设施和流程具有高性能和可扩展性。这包括优化资源使用、识别和解决瓶颈，以及实现高效的数据处理管道。像 Apache
    Spark 这样的分布式计算框架有助于处理大规模的机器学习工作负载，而像 AWS CloudWatch 或 ELK Stack 这样的监控和日志工具可以帮助识别性能瓶颈并在问题出现时进行调试。
- en: To overcome these challenges, DevOps engineers must use best practices such
    as infrastructure-as-code, version control, and distributed computing frameworks.
    They must also work closely with other teams, such as data scientists and security
    teams, to ensure that AI services are delivered quickly, with high quality, and
    in a secure and ethical manner. DevOps engineers should also stay up to date with
    the latest developments in AI, ML, and big data and be prepared to adapt their
    skills and processes as these technologies evolve.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些挑战，DevOps 工程师必须使用最佳实践，例如基础设施即代码、版本控制和分布式计算框架。他们还必须与其他团队紧密合作，如数据科学家和安全团队，确保
    AI 服务能够快速、高质量地交付，并且以安全和合乎伦理的方式进行。DevOps 工程师还应时刻关注 AI、机器学习和大数据的最新发展，做好准备随着这些技术的演变而调整自己的技能和流程。
- en: In conclusion, AI, ML, and big data are technologies that have the potential
    to transform organizations and industries. However, to harness their benefits,
    it is essential to approach their integration and management strategically, working
    collaboratively across teams. With the right tools, practices, and mindset, DevOps
    engineers can play a critical role in realizing the potential of AI services and
    helping organizations succeed in the years to come.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，AI、机器学习和大数据是具有潜力改变组织和行业的技术。然而，要充分利用它们的优势，必须采取战略性的方法来整合和管理这些技术，并跨团队合作。通过使用正确的工具、实践和心态，DevOps
    工程师可以在实现 AI 服务的潜力和帮助组织在未来取得成功方面发挥关键作用。
- en: In the next chapter, we will learn about zero-touch operations.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习零触摸操作。
- en: 'Part 3: The Right Tool for the Job'
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：为任务选择合适的工具
- en: This part will demonstrate the multiple supporting tools you can leverage to
    build, monitor, test, and optimize or troubleshoot different types of databases
    in production systems. Choosing the right tools at the beginning can determine
    your level of success or failure. We will walk through the key characteristics
    of these tools, provide a baseline for reference, and give practical examples
    of how to use, build, and operate them alongside your databases.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分将展示你可以利用的多种支持工具，以便在生产系统中构建、监控、测试、优化或排除不同类型数据库的问题。在开始时选择正确的工具，可能决定你成功或失败的程度。我们将逐一介绍这些工具的关键特性，提供一个参考基准，并举出实际示例，说明如何与数据库一起使用、构建和操作这些工具。
- en: 'This part comprises the following chapters:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 8*](B19315_08.xhtml#_idTextAnchor158), *Zero-Touch Operations*'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B19315_08.xhtml#_idTextAnchor158)，*零触摸操作*'
- en: '[*Chapter 9*](B19315_09.xhtml#_idTextAnchor185), *Design and Implementation*'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B19315_09.xhtml#_idTextAnchor185)，*设计与实现*'
- en: '[*Chapter 10*](B19315_10.xhtml#_idTextAnchor211), *Tooling for Database Automation*'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B19315_10.xhtml#_idTextAnchor211)，*数据库自动化工具*'
