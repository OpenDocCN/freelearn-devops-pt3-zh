

# 第十二章：展望未来：与 Copilot、ChatOps 以及 AI 赋能应用一起前行

我们目前正处于一个时代，在这个时代，构建增强型应用程序变得非常简单，应用**人** **工智能**（**AI**）已经成为一种常态。 将**大** **型** **语言** **模型**（**LLMs**）接入我们的应用程序，并为其赋能 AI，正在开启新的选择，并使得组织能够创新并重新定义其业务流程。 本章将通过讨论 AI 赋能的低代码/零代码开发方法结束本书。 随着 LLM 的引入，如 OpenAI 的**生成预训练转换器**（**GPT**）模型，我们已经见证了在帮助创作者和开发者更高效完成工作并更快实现结果的工具上的巨大变化。 Microsoft Copilot 正在将 AI 注入每一款 Microsoft 产品，帮助创作者和开发者通过使用自然语言描述所需状态，利用零代码方法构建更多应用程序。 我们将深入探讨 Power Platform 中的 Copilot，以及 Copilot 如何在 Power Platform 产品中得到应用。 我们将查看 AI Builder 的功能，并了解如何通过使用自定义连接器，利用 Azure OpenAI 模型扩展 Power Platform 的能力。 本章将以讨论 ChatOps 作为结尾。 我们将探讨它如何丰富现有的 DevOps 流程，以及如何使用 Copilot Studio 来帮助我们在组织中实施 ChatOps。

我们将涵盖以下 主要话题：

+   AI 时代与 GPT 的崛起

+   Microsoft Copilot 与 Power Platform 中的 Copilot

+   从创作者的角度看 Copilot 的使用

+   通过 AI Builder 和 Azure OpenAI扩展业务解决方案

+   ChatOps 与 Copilot Studio

# 技术要求

要跟随本章内容，我们建议提前准备以下要求： 以便更好地进行学习：

+   **Power Platform 订阅**：我们可以注册 Power Platform 开发计划（[https://powerapps.microsoft.com/en-us/developerplan/](https://powerapps.microsoft.com/en-us/developerplan/)），如果我们已经拥有 Microsoft Entra ID 工作帐户，或者我们可以加入 Microsoft 365 开发者 计划（[https://developer.microsoft.com/en-us/microsoft-365/dev-program](https://developer.microsoft.com/en-us/microsoft-365/dev-program)）。

+   **Azure 订阅**：我们可以按照以下指南申请一个免费的 Azure 账户 [https://azure.microsoft.com/en-us/free](https://azure.microsoft.com/en-us/free)。一旦创建，Azure 门户可以通过以下链接访问 ：  [https://portal.azure.com/](https://portal.azure.com/)。

+   **Azure DevOps 服务组织**：我们可以随时创建一个 DevOps 组织，免费使用（[https://learn.microsoft.com/en-us/azure/devops/user-guide/sign-up-invite-teammates](https://learn.microsoft.com/en-us/azure/devops/user-guide/sign-up-invite-teammates)）。

+   **GitHub 用户名和一个代码仓库**：作为创建 DevOps 组织的替代方案，我们可以注册一个免费账户（[https://github.com/signup](https://github.com/signup)）。 要访问 GitHub 企业云，我们可以获得一个 30 天的试用版（https://docs.github.com/en/enterprise-cloud@latest/admin/overview/setting-up-a-trial-of-github-enterprise-cloud）。

+   **Microsoft 365 或 Teams 许可证**：要访问 Teams，需要一个 Microsoft 365 试用许可证或 Teams 许可证。 我们可以使用 Teams 试用版（[https://learn.microsoft.com/en-us/microsoftteams/teams-exploratory](https://learn.microsoft.com/en-us/microsoftteams/teams-exploratory)）。

+   **Visual Studio Code**：你可以选择使用其他的 IDE 或文本编辑工具。

# 人工智能时代与 GPT 的崛起

本节将 提供一个宏观视角，回顾我们如何走到今天，在这个阶段，AI 创新几乎已经成为一种商品。 我们将探索那些震撼世界并对社会和全球产业产生巨大影响的 GPTs。 现在，应用程序开发者甚至可以在 Power Platform 服务中使用这些 GPT 模型来提供商业解决方案，但我们稍后会详细讨论。 让我们首先从 开始讲起。

GPT 已经在市场上存在了一段时间。 它们已经颠覆了市场，带给人们一些恐惧，但也带来了创新的新思路。 由于每个人都可以访问这些模型，任何人都可以利用 AI 创新并构建鼓舞人心的解决方案。 这意味着，使用公开可获得的大型语言模型（LLM）构建的 AI 的竞争优势已经下降。 这促使公司在如何将这项新技术应用于商业流程方面进行创新。 然而，就像任何项目一样，在 AI 融入的项目中，如何快速将一个可靠且安全的解决方案推向市场也非常重要。 在这里，创新和开发应该遵循 DevSecOps 流程，这些流程允许组织将可靠的解决方案带入 市场。

为了理解当前的情况，我们需要回顾 过去。

## 人工智能简介

人工智能是一个智能 计算机系统，它利用数学算法和统计模型来模拟人类思维，在分析数据时做出决策。

1955 年，计算机科学家约翰·麦卡锡提出了“人工智能”（AI）这一术语。 这个术语描述了能够展示类似人类智慧的机器的概念。 然而，人工智能的起源甚至可以追溯得更早。 1940 年，艾伦·图灵创造了一种机器学习算法， 该算法被用于破解恩尼格码密码。 这导致了 **图灵测试** 的产生，后者出现在 1950 年。 这个测试用于判断机器在特定条件下是否能够模仿人类智能。 经过这么多年，AI 专家们现在辩论图灵测试是否仍然相关，因为 AI 模型和自然 语言理解的进展。

简单来说，人工智能背后是计算机科学和工程领域，它们创造出各种算法，驱动这些 AI 系统的运行。 算法被描述为 AI 系统按照一定规则和程序化指令处理和分析数据的一系列步骤。 这些算法可用于情感分析、物体检测等任务。 AI 模型遵循算法，并通过在大规模、具有代表性的数据集上进行训练，以便利用这些算法来解决特定的任务 或问题。

一旦 AI 模型在具有代表性的数据上训练完成，它就能理解数据中的关系，从而能够将所学应用于新的、未知的数据。 这种训练 AI 的常见做法是 在 **机器学习**中进行的。我们用于训练的更多数据和多样化的数据，训练出的模型效果就会更好。 例如，用更多的物体图片训练物体检测模型，并提供每张图片的准确描述信息，将导致该模型的更好效果。

AI 使计算机系统能够执行在许多应用中都有用的任务。 通过 **自然** **语言** **处理** **（NLP）**，这是机器学习的一个子领域，系统现在可以理解人类语言，并执行诸如语言检测、语言翻译和情感分析等操作。 通过扩展到语音，微软声称他们在 2016 年达到了人类对话语音识别的水平。 通过加入计算机视觉，借助 AI 的支持，机器甚至能够理解 视觉物体。

机器学习还有其他子集，如 **强化学习** 以及更进一步的 **神经网络**。神经网络是一种受人类大脑功能启发的模型。 神经网络由神经元组成，神经元是相互连接的节点，按层次分组。 神经元接收输入，这些输入用于计算函数，以确定数据将被发送到下一层哪个神经元。 神经网络可以用于非常复杂的 数据关系。

人们可能会问，为什么我们要讨论这些模型。 嗯，这就是 GPT 的作用所在。 它来了。

## GPT

AI 在 过去几年中的进展带来了生成式 AI。 生成式 AI 是一种使用 LLM 的 AI 类型。 生成式 AI 能够通过生成文本、图像、语音，甚至视频来响应提示并生成新内容。 有许多 LLM 可用；然而，其中最具代表性的是 GPT，得益于 OpenAI 的 **ChatGPT**的流行。看到某些技术需要多长时间才能达到 1 亿月均活跃用户，总是令人着迷。 ChatGPT 只用了 两个月就达到了 1 亿月均活跃用户。 这也表明，新的创新解决方案正在缩短达到这一 重大里程碑所需的时间。

GPT 是 LLM 或文本生成模型的一部分，能够生成新内容（因此， *生成式*），已在大量数据集上进行训练（因此， *预训练*），并使用神经网络处理输入请求并提供输出（因此，变压器*）。

如前所述，许多 LLM 可用，其中包括已向开源社区开放的模型。 目前，最著名和流行的 GPT 包括 OpenAI 的 GPT。 OpenAI 还提供了其他模型，这些模型用于各自的特定目的。 随着每个新版本的发布，我们可以看到 GPT 变得更加复杂和智能。 2024 年 5 月，OpenAI 推出了 **GPT-4o**，也被称为 **omni**，这是一个多模态模型，接受文本和图像作为输入，并可以生成文本作为输出。 在发布会上，OpenAI 强调了新的 GPT-4o 模型如何通过音频、视觉和文本与用户进行交互。 OpenAI 还展示了一种新模型，它能够 将文本转化为 视频，名为 **OpenAI Sora**，并于 2024 年 2 月发布。

当前已经可用的其他模型包括 以下几种：

+   **GPT-4 Turbo**、**GPT-4**和 **GPT-3.5 Turbo** 是 可以 理解自然语言指令并生成自然语言 或代码的模型

+   **DALL-E** (文本到图像) 是 用于根据提供的自然语言指令生成图像的模型

+   **Whisper** 是一个模型 用于将音频转换成文本

虽然 LLM 为生成 AI 铺平了道路，但我们也看到了小型语言模型的出现。 由于训练数据规模较小，这些模型体积较小，但能够在设备上本地运行，这为组织带来了新的创新思路。 。

AI 模型需要数据、AI 算法或模型以及大量的计算能力来运行。 微软与 OpenAI 合作，并开放 Microsoft Azure Cloud 供 OpenAI 利用其计算能力进行新模型的研发。 作为回报，合作规定 OpenAI GPT 模型独家在 Microsoft 平台上提供。 它们可以作为 Azure OpenAI 服务的一部分提供使用。 这使得已经在使用 Azure 或希望使用 Azure 的客户可以利用安全合规的平台构建利用 AI 能力的安全企业应用。 这项合作使得 Microsoft 能够将 OpenAI LLM 集成到其自己的产品中，并构建新功能以提升用户生产力。 这样一个产品的良好示例是 GitHub Copilot，它 就像一个 AI 的编程伴侣。 它帮助开发人员在使用诸如 Visual Studio、Visual Studio Code、JetBrains IDEs 和 Neovim 等 IDE 时理解和生成代码。 这种合作的另一个例子是为 Microsoft 产品和服务提供各种副驾驶的集成，这些副驾驶集成到各种工具中，通过帮助用户更快地实现结果，从而丰富用户体验。 更有效地。

## 负责任的 AI

随着 AI 的进步，对其潜在误用的担忧变得合理。 因此，负责任地使用 AI 至关重要。 微软以及其他公司、社区和个人已经意识到这一点，并开始积极倡导负责任使用的必要性。 微软在内部进行了重大投资，以确保其 AI 系统设计具有责任感。

微软已制定 其 **负责任 AI 标准**，该标准为确保组织负责任使用 AI 提供了实际指导。 它由六项负责任的 AI 原则定义，将指导 AI 的开发 和使用：

+   **公平性**: AI 系统应当平等对待所有人，不带偏见 或歧视

+   **可靠性和安全性**: AI 系统应当可靠运行，并优先考虑安全，以防止 不良后果

+   **隐私和安全**: AI 系统应当确保安全并通过保护 用户数据

+   **包容性**: AI 系统应当吸引广泛的用户，并通过考虑 多元化的视角

+   **透明度**: AI 决策和过程应该是可以理解的，并提供清晰的解释以便 提高信任

+   **问责制**: 开发者 和组织应对所开发的 AI 系统负责

除了负责任的 AI 原则之外，我们还应确保 AI 系统的开发符合合规性并遵循治理方式，以确保符合当地的监管要求。 微软更进一步，实施了一个五点蓝图，专注于治理 AI。 这些原则确保 AI 的使用符合政府的 AI 安全标准，并且是负责任的。 它们还确保我们保持对 AI 系统的控制，以便 AI 可以 安全使用。

微软已将 负责任的 AI 实践不仅融入了协助工具，还融入了其他工具和人们的文化中。 他们这样做是为了促进 AI 的安全和负责任使用。 AI 的使用。

# 微软协助工具与 Power Platform 中的协助工具

微软已在多个微软产品中嵌入了协助工具 以支持不同的场景。 本节将首先解释什么是协助工具，然后介绍一些可用的协助工具及其如何使用。 接着，我们将重点了解协助工具在 Power Platform 中的能力。

Microsoft 使用“copilot”一词来描述能够检索信息并执行特定任务（如摘要和内容生成）的 AI 助手。 Copilot 利用 LLM，例如 OpenAI 的 GPT 模型，来响应用户的提示。 并非所有 Copilot 的行为都相同。 一些 Copilot 较为通用，例如 Microsoft Copilot，而其他则是特定产品的，例如 **Microsoft 365 的 Copilot** 或 **Power Platform 的 Copilot**。这些 Copilot 在特定产品的上下文中运作，并且能够了解该产品中的数据和操作。

所有这些 Copilot 都共享与用户的共同对话式聊天体验。 然而，当我们查看这些 Copilot 时，我们可以看到一些 Copilot 是集成到产品本身中的，它们的主要任务是支持用户在使用特定产品时提高生产力，例如 Power Platform 中的 Copilot。 其他 Copilot 也是特定于产品的，例如 Microsoft 365 的 Copilot 或 Sales 的 Copilot，它们具有一组标准功能，包括 Copilot 组件，但也可以通过 Copilot Studio 的支持进行扩展。 最后一类 Copilot 是自定义 Copilot，用户可以在 Copilot Studio 或使用 Azure AI 服务上自行构建，并通过不同渠道向 用户提供。

Copilot 的示例包括 以下内容：

+   **Microsoft Copilot**：这款工具使用 OpenAI LLMs 来为用户的提示提供类似聊天的响应体验。 它可以在网络上搜索结果，并能总结针对特定问题的回答，同时提供相关 内容来源的链接。

+   **Microsoft 365 的 Copilot**：这个工具 生成基于用户有权限访问的组织数据的响应。 它利用 Microsoft Graph 和 LLMs，并集成于 Microsoft 365 套件（Word、Excel、Teams 等）中，旨在提升 个人生产力。

+   **GitHub Copilot**：这是一款 AI 配对程序员或代码补全工具，帮助开发人员在软件开发生命周期（SDLC）中。 它主要围绕编码相关话题，因此可以提供代码建议、解释代码、构建单元测试、 等等。

## Power Platform 中的 Copilot

AI 在 Power 平台中已经存在了几年。 2019 年，AI Builder 被引入 Power 平台，帮助将 AI 模型融入到业务流程中，并丰富了应用和流程。 2021 年，Power Apps 中推出了将自然语言提示转换为 Power Fx 函数的功能。 从那时起，新的 AI 功能每年都不断加入到 Power 平台中。 每年都有新的进展。

在 Power 平台中启用 copilot 功能将平台带入了无代码开发的领域，并且得到了 AI 的辅助。 这意味着，无论我们是专业开发者、低代码应用开发者，还是刚开始学习使用 Power 平台的人，Power 平台中的 copilot 都能提供通过自然语言生成有意义的面向业务的解决方案的能力。 这有助于开发者和组织节省时间并 提高生产力。

Power 平台家族中的每个产品都包括其专属的 copilot。 这些 copilot 作为 AI 助手，具备产品特定的功能，可以作为开发者或业务解决方案用户使用， 并在 Power 平台上构建。

Copilot 已集成到产品中，并始终共享产品的主屏幕，这使得 开发者或用户在解决方案工作时更加高效，因为它不需要他们离开当前工作 的上下文。 工作环境：

+   **Power Apps 中的 Copilot**：这使得 开发者可以通过自然语言描述来构建新的应用或编辑现有应用，并编写或理解 Power Fx 函数。 作为用户，我们可以在应用中使用 copilot 组件，帮助我们获取有关应用中数据的答案。

+   **Power Automate 中的 Copilot**：使用这个功能，开发者可以创建新的流程，并通过自然语言描述所需的连接器。 我们还可以修改现有的流程，并为业务流程获得灵感。 很快，我们将能够构建 AI 流程，LLMs 将创建动态的自动化流程，并通过语音记录指令利用多模态模型，构建 Power Automate 桌面流程。 用户能够深入了解由 Power Automate Process Mining 分析的流程。

+   **Copilot Studio 中的 Copilot**：开发者 可以通过对话式构建器创建新的自定义 copilot，还可以使用 自然语言创建和修改主题。

+   **Power Pages 中的 Copilot**：此功能 促进了外部网站和页面的创建，允许我们通过自然语言聊天界面添加表单、文本内容和 AI 生成的代码。 用户可以利用定制的 Copilot 聊天体验和通过生成式 AI 丰富的搜索体验进行推理， 从搜索结果中获取信息。

+   **Power BI 的 Copilot**：此功能 有助于构建跨云服务和 Power BI Desktop 的报告页面。 作为用户，我们可以获取有关模型中数据的问题答案，获取报告摘要， 以及更多内容。

Power Platform 中的 Copilot – 预览功能

需要注意的是，Power Platform 中的一些 Copilot 功能仍处于预览阶段。 这些功能不适用于生产环境。 为了访问这些功能，我们可能需要将环境 设置为 **提前发布周期** ([https://learn.microsoft.com/en-gb/power-platform/admin/early-release](https://learn.microsoft.com/en-gb/power-platform/admin/early-release))。 我们可以使用沙盒环境，并通过 **预览 URL** (Power Apps: [https://make.preview.powerapps.com/](https://make.preview.powerapps.com/)) 或通过启用 **体验新的数据体验** 在 Power Apps 主页屏幕中。

一些 Copilot 的配置设置可以在 **Power Platform 管理中心** | **设置**中打开或 关闭**租户设置**，我们可以根据组织的政策找到可以启用或禁用的配置设置，正如在 *图 12**.1*中所示：

![](img/B22208_12_1.jpg)

图 12.1 – 在 Power Platform 中启用或禁用 Copilot

这些 设置 包括启用数据收集、用户发送反馈的能力，以及在 Power Apps 中启用或禁用 Copilot 预览功能的能力。

# 从创建者角度看 Copilot 的使用

在本节中，我们 将了解如何在 Power Platform 中使用助手生成带有数据表的 Power Apps 画布应用，并通过 Power Automate 中的流进行支持。 这展示了 AI 如何帮助应用开发者在低代码开发过程中获得额外支持，并转向 无代码方法。

在 Power Platform 中使用助手的好处之一是，这种方法使开发者能够更快速地构建解决方案原型。 这是因为原型不需要具备应用的所有功能，只需要提供概念的外观和感觉。 借助 Power Platform 应用中的助手，开发者可以使用自然语言描述构建应用或流的模型，并快速验证业务应用构思的可行性。 对于助手提供的每个建议步骤，我们可以通过点击**撤销** 按钮撤回助手所做的更改。 这使得测试想法变得更加容易，并且在不满意建议的工作时可以快速恢复。

Power Platform 中的助手具有相同的用户体验。 在该服务的首页，我们可以找到一个大型文本输入组件，允许我们添加想要执行的操作描述。 我们写给助手的提示应该清晰且具体，因为这将帮助助手返回更相关的结果。 为了使用助手获得更好的结果，我们应提供更多关于请求的上下文，或者在需要时，提供一些如何实现某个功能的示例：

![](img/B22208_12_2.jpg)

图 12.2 – Power Platform 首页上的助手

在 Power Apps 首页（[https://make.powerapps.com/](https://make.powerapps.com/)）上，我们将首先描述我们希望构建的应用程序的构思。 由于几乎所有的业务应用都依赖于数据，助手将开始在 Dataverse 中创建一个数据架构，作为我们的数据源来管理数据。 在这个步骤中，助手会提取我们提示的上下文 并根据输入开始创建一个 实体关系图。

我们可以使用提示建议来更改数据架构、添加更多表格、配置它们之间的关系、向表格中添加更多测试数据等等。 此时， **查看提示** 按钮作为提示指南，提供了 Copilot 可以执行的操作建议。 这些操作包括创建表格和关系、修改表格和列，并作为灵感提供基于当前数据 架构设计的建议：

![](img/B22208_12_3.jpg)

图 12.3 – 丰富数据模型创建

一旦我们点击 **保存并打开应用**，Copilot 将使用此数据架构创建一个示例应用 ，该应用具有多个屏幕，包含表单用于操作表格，同时也有一个独立的欢迎屏幕，可作为屏幕之间的导航 。

在 Power Apps Studio 中，我们可以利用 Copilot 提问，了解如何在 Power Apps 中实现某些功能。 它利用 Bing 搜索来查找相关内容，并为我们提供指导。 例如，我们可以提问“*如何将图片添加到图像组件*？”它会提供与问题相关的回答。 在这种情况下，它会提供逐步的指导，教你如何实现此操作，并提供相关的文档链接，解释整个过程。 我们可以要求它向屏幕添加特定的组件，如按钮或文本标签，但此时我们可能仍然需要手动完成一些任务，因为它尚不能完成 所有任务。

构建 Power Fx 公式有时会很具挑战性，特别是对于第一次使用 Power Platform 的人。 类似于 GitHub Copilot 的功能，为了支持开发人员，现在我们可以使用自然语言的注释来生成 Power Fx 公式。 它也可以反向工作，帮助理解公式的作用，只需点击公式框旁的 Copilot 图标，然后选择 **解释** **此公式**：

![](img/B22208_12_4.jpg)

图 12.4 – 使用 Copilot 提供 Power Fx 公式建议

作为开发人员，我们还可以直接在 Power Apps Studio 中查看代码。 通过选择屏幕或组件旁边的三个点（或右键单击），我们现在可以看到一个 **查看代码（预览）** 选项，显示所选部分的 YAML 格式代码。 这使我们可以复制代码并与其他开发人员讨论，直接修改代码，甚至使用复制/粘贴将此部分放入另一个屏幕 或应用程序中。

如果我们转向 Power Automate，Copilot 也可以帮助我们完成类似的任务。 这意味着使用自然语言描述我们希望创建的流程，并对现有流程进行修改，例如向流程中添加操作、配置操作的参数， 等等。

随着人工智能的进步，我们很快就能构建 AI 流程，AI 将决定如何构建一个自动化计划，并满足实现要求所需的所有条件。 我们也很快能够使用语音记录构建 Power Automate 桌面流程的指令。

![](img/B22208_12_5.jpg)

图 12.5 – Power Automate 中的 Copilot

我们必须记住，目前一些 Copilot 功能仍处于预览阶段。 从 DevOps 的角度来看，我们当前能看到一个主要问题，那就是在 解决方案级别上，并未启用使用相同构建方法的能力。

我们在 *第四章* 中提到，我们应该从解决方案资源管理器内部开始构建我们的 Power 平台组件。 在那里，我们可以使用现有的解决方案或创建新的解决方案，因为解决方案使我们能够在不同环境之间移动应用程序并管理解决方案组件所需的依赖项。 当前的开发方法是从设计体验开始，而不是从解决方案资源管理器开始。 这种方式，通过 copilot 的初始设计体验创建的所有组件都将添加到 **默认解决方案** 并处于未管理状态。 目前，用于构建业务应用程序的 copilot-first 方法不支持从解决方案开始，这使我们只能选择将现有组件添加到新解决方案，并确保将所有必需的依赖项添加到解决方案。 但是，如果我们希望从手动创建 custom copilot 开始，我们可以首先创建一个解决方案，然后从那里创建新组件（如 Power Apps 应用程序）。 我们 希望 copilot 在初始创建应用程序和其他组件方面的体验也可以通过 解决方案方法启用。

# 通过 AI Builder 和 Azure OpenAI 扩展业务解决方案

现在，我们已经看到 AI 如何帮助我们构建 Power 平台组件，接下来，我们将寻找将 AI 能力融入我们的应用程序和流程中的方法。 本节将介绍 AI Builder 的能力，并比较它与 Azure OpenAI 的区别。 我们将看看如何设置自定义连接器以连接到 Azure OpenAI，在这里，我们将使用我们选择的 Azure OpenAI 模型来丰富用户体验或改进我们在 Power 平台中的业务流程。 Power 平台。

## 介绍 AI Builder

AI Builder 是一个 Power 平台服务，允许制作者在其解决方案内使用不同的 AI 模型和提示，无需编码或特殊的数据科学知识。 它允许组织通过添加额外的 AI 能力来改善其业务流程，这可以帮助自动化手动和重复的任务，并帮助实现更好的结果。

它可以通过 Power Fx 公式或使用 AI Builder 组件集成到 Power Apps 应用程序中。 通过使用 AI Builder 动作，AI Builder 还可以在 Power Automate 工作流中使用。 我们还可以选择在 Copilot Studio 内的插件中使用其功能。

### AI 模型

AI Builder 提供了一套预构建的模型，这些模型在许多业务流程中得到了广泛应用。 当我们需要更符合数据特定需求的自定义模型时，可以创建自定义模型，并在 自定义数据集上进行训练。

AI 模型可以根据它们使用的数据类型进行分组。 这些组可以同时包含预构建模型和 自定义模型：

+   **文档处理**：该组包含发票处理、文本识别、作为自定义模型的文档处理以及一个 名片识别器

+   **文本处理**：在这里，我们可以找到用于文本处理的模型，如关键词提取、情感分析、语言检测和 类别分类

+   **图像处理**：提取图像信息的模型，例如图像描述生成图像或物体检测的模型， 都可以在此找到

+   **结构化数据处理**：目前只有一个自定义模型能够使用数据进行预测并预测结果 。

每个模型都有其自身的特点和要求，以获得最佳结果。 要了解更多关于每个具体模型的信息，我们建议阅读以下 文档： [https://learn.microsoft.com/en-us/ai-builder/model-types](https://learn.microsoft.com/en-us/ai-builder/model-types)。

使用预构建模型时，我们无需进行任何特殊配置——它们是即开即用的，不需要任何训练。 我们可以使用组件或连接器操作，将其指向数据并接收输出。 在使用自定义模型时，我们构建的是一个特定于某个业务领域的模型。 它必须先使用历史数据进行训练，才能完成特定任务。 对于文档处理，我们 需要 至少五个具有相同布局的示例，才能准确训练一个 模型。

### AI 提示

AI 提示使得开发者可以构建指令，告诉大语言模型（LLM）需要执行的任务。指令越精准，任务的结果就会越好。AI Builder 提供了预构建的提示，可以更快速地将这些指令应用于 GPT，例如文本摘要、文本分类、情感分析、草拟回复等任务。然而，就像以前使用 AI 模型一样，开发者仍然有机会创建自定义 AI 提示。在**提示工程**的帮助下，我们可以提供指导 GPT 模型达到预期结果的指令。需要注意的是，指令的质量会直接影响输出结果。AI 提示允许我们提供输入变量和 Dataverse 数据，从而创建高度动态并与我们业务流程相关的提示。

AI Builder 目前使用 GPT-3.5-Turbo 或 GPT-4（预览版）进行 AI 提示的处理。这些都是由 Azure OpenAI 提供支持的。

创建提示非常重要，而且还有其他参数决定了模型的行为，例如模型选择和温度设置，因此了解如何构建 AI 提示是一个好主意，可以通过以下链接了解更多：[`learn.microsoft.com/en-us/ai-builder/create-a-custom-prompt`](https://learn.microsoft.com/en-us/ai-builder/create-a-custom-prompt)。

为了安全起见，我们建议在将响应用于重要的业务流程之前，先对其进行人工检查，**以防**错误或无关的响应带来危害或负面影响。

## 使用 AI 模型和 AI 提示

我们可以从**AI Hub**开始创建 AI 模型或 AI 提示：

1.  在 Power Apps 或 Power Automate 中，我们可以在左侧导航菜单中找到 AI Hub。如果暂时找不到，可以在**更多**中找到并将其固定到左侧导航栏，或者通过访问**更多** | **发现所有**，在其中找到**AI Hub**并将其固定到左侧导航菜单。

1.  一旦进入 **AI 中心**，我们可以开始构建 AI 提示和模型。 在那里，我们还可以找到一个文档自动化解决方案，结合 RPA 流程和 AI，从各种文档中提取信息，并继续执行文档 处理工作流。

1.  从 AI 提示开始 – 在 **AI 中心**，选择 **提示**。在这里，我们将看到所有预构建提示的列表，并有选项创建自定义提示 与 GPT。

    AI 提示由 **提示**组成，应该准确清晰，还有 **提示设置**。我们可以配置多个输入变量并将其添加到提示中，使其高度动态。 我们可以使用 Dataverse 中的数据，进一步为 GPT 模型提供知识来源。 输出可以是文本或 JSON，有时后者可能更合适，因为我们对展示层有更多控制。 在 **设置**中，我们可以选择我们想要使用的模型和温度设置。 来使用。

1.  现在我们已经创建了 AI 提示，可以将其添加到我们的应用程序或流程中。 在 Power Apps Studio 中开发画布应用时，我们可以在 **数据** 部分找到 AI 提示或 AI 模型。

1.  在左侧导航栏中，点击 **数据** | **添加数据**，这会打开一个选项以选择数据源。 在这里，我们可以使用搜索栏找到我们的 AI 提示或模型并将其添加 到 我们的应用程序中：

![](img/B22208_12_6.jpg)

图 12.6 – 将 AI 提示添加到画布应用程序中

1.  为了使用 AI 提示或 AI 模型，我们将通过 Power Fx 函数来触发它：

    ```
     Set(varComplaint, 'Example - Custom prompt Complaint Accommodation'.Predict(txtComplaint.Text,txtApartmentName.Text))
    ```

在前面的代码中，我们可以看到一个 Power Fx 函数的示例，它将 AI 提示的响应存储为一个变量，之后可以根据我们的业务流程在应用程序中使用该变量。 在 Power Apps 中，我们可以找到专注于特定 AI 模型的 AI Builder 组件，并可以通过组件将其实现到应用程序中，以启用一些额外的功能，如收据和表单处理器、物体检测等。

在 Power Automate 中添加 AI 提示和 AI 模型与添加任何其他操作一样简单，只需在 工作流中进行添加：

1.  在 Power Automate 设计器中，工作在我们的工作流时，点击 **添加操作** 在我们希望添加 AI 能力的地方。

1.  搜索 **AI Builder** 并从列表中选择一个模型或提示类型。

1.  首先选择模型类型，然后在下一步中，可以将一个连接器操作链接到我们的模型 或提示。

    与前面提到的示例相关，我们使用了自定义 AI 提示，我们可以通过以下 Power Automate 操作找到我们的自定义 AI 提示： **AI Builder** | **使用 GPT 创建文本，使用** **提示**。

1.  我们对连接器进行身份验证，并在 **参数** | **提示**中，从列表中选择我们的提示。

1.  我们提供必要的输入，并继续构建 我们的工作流。

在任何后续 操作中，我们 将能够使用前一操作的输出，这对于 AI Builder 操作也是相同的。 举个例子，在 *图 12**.7*中，我们正在使用由 GenAI 构建的生成的投诉回复的输出，在 **审批** 操作中，允许审核人员审查生成的投诉回复是否恰当。 如果是，我们将投诉消息发送给 客户：

![](img/B22208_12_7.jpg)

图 12.7 – 将 AI Builder 与 Power Automate 集成

重要说明

从 使用 打包我们业务应用程序的解决方案的角度来看，我们需要记住 AI 模型和提示不被视为应用程序的依赖项。 我们需要手动将 AI 提示和模型添加到我们的解决方案中，以便与应用程序 或工作流配合使用。

此外，AI 模型和提示使用 AI Builder 学分。 不同的模型类型消耗不同数量的学分，因此请确保查看许可指南（[https://go.microsoft.com/fwlink/?linkid=2085130](https://go.microsoft.com/fwlink/?linkid=2085130)）以更好地了解您的项目的学分使用情况。

### AI Builder ALM

每当我们 创建一个定制的 AI 模型或 AI 提示，我们希望在不同环境中重复使用时，我们可以应用已经在前几章中介绍过的应用生命周期管理原则，与其他 Power Platform 组件一样。

由于无法从解决方案资源管理器中创建 AI 模型或提示，首先需要使用 AI Builder 创建一个定制的 AI 模型或 AI 提示，在那里我们可以使用我们的数据集训练 AI 模型或构建定制的 AI 提示。 我们建议遵循环境策略，在开发或沙盒环境中开发定制模型，然后将其部署到其他目标环境。 一旦模型训练完成，我们需要发布它，以便将其添加到 解决方案中。

由于该模型不被视为应用程序或流程依赖项，我们需要手动添加定制的 AI 模型或 AI 提示以及将要使用它的应用程序或流程。 在此阶段，我们准备将现有模型添加到解决方案中。 我们需要意识到，当模型添加到解决方案时，只会添加模型可执行文件，而不会添加用于训练的数据。 这就是为什么当我们使用文档处理、对象检测或实体提取等模型时，在目标环境中无法修改模型，因为数据没有传输到目标环境。 在这种情况下，如果需要进行修改，应该在 目标环境中创建一个新模型。

作为 AI Builder 的 ALM 部分，我们还应该考虑实施一个 **持续改进过程** 以改进我们的模型。 到目前为止，我们可以仅通过现成功能为自定义文档处理模型自动化此方法。 但是，我们应该实施一个反馈循环，至少通过使用不同的度量标准来衡量模型的相关性和适用性，从而通知 AI 模型或提示的所有者。 其中之一可以是模型置信度评分。 然而，我们也可以结合人工审查过程，正如我们在之前的示例中所看到的。 为了实现自定义文档处理模型的持续改进，我们可以实施一个 Power Automate 流程，在现有 AI 模型的总置信度评分低于某个阈值时，使用 **保存文件到 AI Builder 反馈循环** 的 AI Builder 操作。 此过程的详细描述已记录在 此处： [https://learn.microsoft.com/en-us/ai-builder/feedback-loop](https://learn.microsoft.com/en-us/ai-builder/feedback-loop)。

当我们准备好解决方案后，可以使用我们在前几章中配置的 CI/CD 流水线来导出解决方案，并将源代码添加到一个代码库中。 之后，我们可以遵循 DevOps 流程，并在准备好后，使用我们的导入流水线将模型导入目标环境。 之后，模型和提示可以在应用程序和流程中使用。 如果我们使用的是托管流水线或全局流水线，我们只需确保已将 AI Builder 组件 添加到 解决方案中。

## 介绍 Azure OpenAI

有时，开发者和 组织可能希望使用最新版本的 GPT 模型，或者他们可能已经在 Azure OpenAI 上构建了模型，围绕公司数据构建了模型。 他们可能希望重用已经在 Azure OpenAI 上完成的工作，以便应用于其他应用程序，或者也许 Power Platform 中包含的 GPT 模型版本正是他们希望使用的版本。 幸运的是，Power Platform 是一个非常可扩展的平台，支持此类情况 。

正如我们在 *第九章*中提到的，Power Platform 支持 Azure 与 Power Platform 之间的多种专业开发集成场景。 构建融合开发团队将有助于我们将相关工程师带入项目。 然后，我们可以将任务分配给数据科学家、AI 架构师或类似角色，确保模型在 Azure OpenAI 中被设计和微调。 开发人员或经验更丰富的应用开发者将确保自定义连接器与 Azure OpenAI 集成。 最后，应用开发者将把自定义连接器作为业务应用或流程的一部分，来产生它们 被构建的结果。

Azure OpenAI 服务是一个 PaaS 服务，将 OpenAI 模型带到 Azure 云平台。 这些模型通过 REST API 端点进行暴露，借此我们可以使用这些 LLM，同时受益于 Azure 平台的安全性、可扩展性和可靠性。 这些模型支持跨越 NLP、计算机视觉、语音等不同任务。 以及更多。

Azure OpenAI 旨在为数据科学家和 AI 工程师设计，帮助他们更好地控制模型，允许他们微调模型、生成嵌入、应用内容过滤器等。 此外，在 AI Builder 中，我们可以使用 GPT-4 通过 AI 提示进行文本处理。 Azure OpenAI 提供了其他 LLM 模型，如果我们整体查看 Azure AI 服务，可以发现还有其他 LLM 模型以及 SLM 模型可供使用。 通过这种方式，我们可以超越文本，必要时获得多模态支持，比如最新的 GPT-4o 或其他模型，如 Whisper 或带有视觉功能的 GPT-4 Turbo。 随着 AI 的不断进步以及硬件和 AI 操作的优化，Power Platform 很快将会通过额外的 LLM 模型变得更加丰富，并且这些模型将开箱即用地支持多模态。

### 将 Azure OpenAI 与 Power Platform 集成

Azure OpenAI 提供了一种名为 **Azure OpenAI Studio**的用户界面体验，通过它 用户可以构建、测试并管理他们的 Azure OpenAI 部署。 要开始使用它，可以通过 Azure 门户手动配置 Azure OpenAI 服务，也可以使用 Azure CLI 或我们在 上一章中已经熟悉的基础设施即代码的方法。

为了更好地理解创建 Azure OpenAI 资源和模型部署的过程，我们建议阅读以下文档 文章： [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource)。

Azure OpenAI 模型可以围绕组织数据构建，确保数据在组织的 Azure 订阅内安全。 我们的新 Azure OpenAI 服务现在可以通过 REST API 和 SDK 在自定义开发的应用程序中使用。 在 Power Platform 中，可以通过 连接器进行集成。

访问 Azure OpenAI 服务

在我们的 Azure 订阅中第一次配置 Azure OpenAI 服务之前，我们必须提交申请，以获得访问 Azure OpenAI 服务的权限。 这可以通过一个可访问的表单完成， 表单链接为 [https://aka.ms/oai/access](https://aka.ms/oai/access)。

我们已经在 *第九章*中看到了一些构建自定义连接器的示例。 不过，我们将提供连接到 Azure OpenAI 服务时应考虑的具体事项。 所有所需的信息都可以在 Azure OpenAI Studio 中找到：

![](img/B22208_12_8.jpg)

图 12.8 – Azure OpenAI 聊天演示区

以下是 步骤：

1.  在 Power Apps 或 Power Automate 中，选择 **自定义连接器** 在左侧导航栏中，然后点击 **新建自定义连接器** | **从空白创建** **。

1.  除了其他数据外，我们需要提供 `<name>.openai.azure.com` 格式，如下所示： *图 12.8*。

1.  在 **安全** 选项卡中，我们指定 **API 密钥** 作为认证类型，它会添加到 **头部** 位置。 这个密钥是我们在 Power Platform 中创建连接时提供的。 它可以在端点 URL 旁边找到，如 *图 12**.8*所示，或者通过进入 Azure 门户，在 **Azure OpenAI 资源** | **资源管理** | **密钥** **和端点**中找到。

1.  在 **定义** 选项卡中，点击 **新建操作** 来定义聊天完成 API 操作。 在 **请求** 部分，我们可以使用 **从示例导入** 来创建 HTTP POST 请求。 在 **URL**部分，我们提供完整的端点 URL，该 URL 也可以在 **Azure OpenAI 聊天游乐场** | **查看代码**中找到，如 *图 12**.8*所示。聊天完成 API 还需要一个包含系统和用户角色内容的消息体。 我们可以包含来自 Azure OpenAI 聊天游乐场的示例有效载荷，以方便添加 参数。

    操作可以在 **定义** 选项卡中进一步自定义，以确保我们为 模型提供了所需的信息。

1.  一旦我们满意，就可以继续到 **测试** 选项卡，在这里我们将通过提供 Azure OpenAI 服务的 API 密钥来创建连接。 之后，我们可以测试 连接器。

1.  一旦我们有了一个有效的连接器，就可以像使用任何 其他连接器一样，在我们的 Power Platform 解决方案中使用它。

微软最近发布了一个高级版 **Azure OpenAI 连接器** (预览版)，适用于 Azure Logic Apps，并且它在 Power Platform 中也能使用。 我们预计，在某个时刻，它会作为 Azure OpenAI 的正式发布连接器进行宣布。 Azure OpenAI 连接器简化了 Azure OpenAI 服务与 Power Platform 解决方案之间的连接，允许开发者利用聊天补全操作与他们的 Azure OpenAI GPT 模型交互。 然而，由于该连接器仍处于预览阶段，我们建议仍然构建并使用连接到 Azure OpenAI 的自定义连接器：

![](img/B22208_12_9.jpg)

图 12.9 – 创建与 Azure OpenAI 的连接

一旦连接器正式发布并广泛可用，我们可以像使用任何其他连接器一样使用它，正如我们在 前面的例子中所看到的。

此外， 记得 使用 **连接引用** 在我们的 解决方案中，如 *第十章*中所提到的那样。通过使用部署设置文件（如下片段所示），可以更有效地将我们的解决方案在环境之间迁移：

```
 "ConnectionReferences": [
    {
      "LogicalName": "<CONNECTION-REFERENCE-NAME>",
      "ConnectionId": "<CONNECTION-ID-TARGET-ENVIRONMENT>",
      "ConnectorId": "/providers/Microsoft.PowerApps/apis/shared_azureopenai" }
  ]
```

通过这一点，我们已经看到，构建 AI 模型并将其集成到现有的商业解决方案中以改善我们的业务流程是多么容易。 使用 AI Builder 或者甚至是 Azure OpenAI 可以支持许多 业务流程：

+   通过提取附带发票 和文档中的信息自动生成费用报告

+   从产品评论中提取情感，以便做出相应的 回应

+   回复 客户投诉

+   总结会议内容 要点

+   利用语音转文本操作构建客户电话的文字记录

+   将文档翻译成 各种语言

+   识别 欺诈交易

现在我们将切换话题 ， 从 AI Builder 和 Azure Open AI 的具体内容转向自定义 Copilot 或虚拟 AI 助手，以及它们如何支持我们的 DevOps 流程。

# ChatOps 和 Copilot Studio

我们已经查看了嵌入产品中的各种副驾驶。 现在是时候看看我们如何创建一个自定义副驾驶了。 本节将重点介绍一个工具，帮助我们构建自定义副驾驶： **Copilot Studio**。从这里，我们将学习 关于 **ChatOps** 的内容，并通过一个示例，看看如何利用 Copilot Studio 构建一个帮助我们实现 ChatOps 实践的助手。 我们还将查看可以支持 ALM 的 PAC CLI 命令，用于 Copilot Studio。

## 深入了解 Copilot Studio

我们在本书的开头简要介绍了 Copilot Studio。 让我们回顾一下它是什么。 Copilot Studio 是一个低代码工具，用于管理自定义副驾驶。 它源自以前称为 **Power Virtual Agents** （**PVA**）的产品，该产品用于构建聊天机器人。 随着生成式 AI 的引入以及副驾驶的出现，微软扩展了 PVA 的功能，并将产品更名为 Copilot Studio。 这一变化恰到好处，因为这个工具不仅用于构建聊天机器人，还可以扩展现有的副驾驶，加入更多的自定义功能。 Copilot Studio 现在允许任何人利用生成式 AI 能力构建自定义副驾驶。

自定义副驾驶充当 AI 助手，可以处理各种请求，从执行由业务流程支持的特定操作，到仅仅使用基于业务数据的 GPT 模型回答问题。 由于其生成式 AI 能力，它们不仅仅是聊天机器人，尽管我们通常称它们为机器人。 组织可以构建不同的内部或外部机器人，支持内部团队，与客户合作，帮助推动内部流程，等等。 考虑到它是一个低代码工具，它使得组织能够快速开发符合业务需求并有助于提高投资回报率（ROI）的副驾驶。 。

Copilot Studio 提供了一套预定义的系统话题。 它还允许我们创建自己的自定义 话题。 话题 是 Copilot 的基础构建块。 它们定义了用户与 Copilot 之间对话的特定部分，允许自然的互动与交流。 每个话题包括一个触发器，触发器可以表示为一组触发短语和一组对话节点。 这些元素共同定义了话题可以遵循的对话路径。 节点可以表示一个消息或一个问题，机器人将向用户提出该问题。 节点可以执行一个动作，例如触发 Power Automate 工作流或利用 Power Platform 中的任何连接器。 它们还可以涉及话题管理功能，例如设置变量、检查某些值的条件、调用其他话题等。 创建话题使我们能够完全控制机器人和 用户之间的对话。

![](img/B22208_12_10.jpg)

图 12.10 – Copilot Studio 话题创建体验

从生成式 AI 的角度来看，Copilot Studio 允许组织通过启用生成式答案和 生成式动作 来提升用户生产力并改善对话流程。

生成式答案 是一项功能，GPT 使用不同的知识源，如公共网站、内部 SharePoint 网站、各种文档、自定义数据源等，生成对问题的回答。 当启用生成式答案功能时，我们可以将 GPT 驱动的答案添加到任何自定义话题，并使用一个回退系统话题，在没有其他话题匹配时触发。 Copilot Studio 还允许集成 Azure OpenAI 模型，而不是使用嵌入在 Copilot Studio 中的 GPT 模型。 在这种情况下，用户的问题会被发送到 Azure OpenAI，在那里生成一个答案并返回给 Copilot Studio，后者再将该答案展示给 用户。

**生成模式**，也被称为 **生成式动作**，允许我们通过将各种动作（连接器动作、Power Automate 流程、AI Builder 提示或 Bot Framework 技能）与我们的机器人连接，结合所有自定义和系统话题，并让生成式 AI 自动决定如何响应用户请求，选择最合适的动作或话题来继续 对话。

在开发完机器人之后，我们可以直接在 Copilot Studio 中测试其功能。 一旦我们对其工作结果满意，就可以通过不同的渠道公开自定义的 Copilot。 它们可以通过 Microsoft Teams 或自定义网站发布。 我们可以构建自己的自定义应用，结合自定义 Copilot 实现聊天功能，并将其发布到内部 SharePoint 或部署到其他各种沟通渠道，如 Facebook Messenger、Twilio、Slack、Direct Line API 等。

接下来，我们继续 了解什么是 ChatOps，然后看看如何使用 Copilot Studio 实现 ChatOps 过程。

## 什么是 ChatOps

ChatOps 这个术语 并不新颖；它已经存在超过 10 年，由 GitHub 引入。 ChatOps 在今天的 DevOps 社区中有所消散，因为人们不再频繁讨论它。 然而，我们可以看到，许多 DevOps 团队已经在 Teams 或 Slack 等沟通平台上实现了部分 ChatOps 实践。 尽管 DevOps 社区没有太多讨论 ChatOps，但我们可以看到 DevOps 工程师确实认识到 ChatOps 的好处，并且可能已经在团队频道中实现了一些 ChatOps 实践，甚至他们自己都未意识到这些实际上是 ChatOps 实践。

ChatOps 是一种也被称为 *以对话为驱动的 DevOps*的实践。它利用聊天机器人和沟通平台，如 Microsoft Teams 或 Slack，来通过自动化各种与 DevOps 相关的任务，支持开发人员和 IT 运维团队。 这些任务包括创建新的问题或工作项、提供基础设施、在代码库中创建新分支、批准拉取请求、部署应用程序、 等等。

ChatOps 有许多好处。 ChatOps 可以增加和改善团队之间的协作和沟通，这也有助于更好的知识共享和对 DevOps 过程与项目的可视化。 它允许某些过程被自动化，并通过统一的沟通平台提供给成员。 随着我们自动化任务，操作可以更快地完成。 这种方法也有助于减少过程中的潜在人为错误。 团队成员还可以查看其他成员执行的操作历史。 它促进了团队内部的分享，团队成员可以互相帮助。 就像 DevOps 一样，这里不仅仅是工具和过程，更关乎人 和文化。

ChatOps 可以 与聊天机器人结合，帮助提供自动化功能。 随着近期有关 Copilot Studio 中具备代理能力的自定义 Copilot 的宣布，我们相信，使用聊天机器人和自定义 Copilot 支持 DevOps 过程和 IT 运维的案例频率 只会增加。

一个 *具有代理能力的自定义 Copilot* 是 Copilot Studio 中的一项新功能（该功能在 Microsoft Build 2024 大会期间宣布，目前尚不可用），它使创作者能够创建由事件触发的 Copilot，而不仅仅是用户对话。 它们可以支持长时间运行和复杂的过程，减少人工干预。 我们可以创建一个自定义 Copilot，当 Azure DevOps 或 GitHub Enterprise 中发生特定事件时，能够响应该事件并理解事件的结果。 例如，如果新任务分配给了工程师，自定义 Copilot 可以为该工程师创建一个特性分支，并通知工程师有关计划工作的情况。 当构建失败时，它还可以执行一系列操作。 这两个例子都可以完全通过利用生成式 AI 能力和在 Copilot Studio 中注册的操作来处理。

让我们扩展一下，探讨支持 DevOps 过程的其他可能用例，利用今天在 Copilot Studio 中可访问的能力。 这些能力已经可以使用了。

### ChatOps 的使用案例

我们可以开始构建 我们的 ChatOps 实践，涵盖简单但 相关的案例。

第一组用例侧重于向团队成员通知特定活动。 通过使用通信平台，如 Microsoft Teams，我们可以开始从我们的版本控制系统和项目管理工具中引入信息。 当 DevOps 团队成员在进行项目工作时，他们有时可能会错过项目中一些重要的变更。 这就是为什么我们可以将信息带入他们的团队聊天室，并提供筛选过的内容，如有关新拉取请求、失败的流水线执行、任务或新错误创建的信息等。 我们还应考虑实施一种机制，通知团队成员有关 任何事件的发生。

在向团队聊天频道提供信息时，我们应该确保不会让他们接收到过多的所有信息。 我们应当筛选内容，发布相关的信息，这是团队可以决定设置的事情。 然而，这些活动本质上是信息性的，旨在告知某项活动。 每当我们想要基于这些信息或任务执行某个操作时，我们应该查看可以通过机器人或在我们案例中的 自定义副驾驶来提供的其他活动。

在通过 ChatOps 实现的活动第二部分中，我们可以放置任何团队希望自动化的活动。 由于自定义副驾驶可以通过 Copilot Studio 与许多第一方和第三方工具进行连接，借助连接器以及自定义连接器，选项几乎是无限的。 我们可以调用连接器或 API 获取与项目相关的信息，例如获取项目中的所有 bug，或允许团队成员询问如何执行某些活动的常规问题。 我们可以与 Azure DevOps 或 GitHub 等工具集成，以创建新的问题或 bug 工作项，或者我们可以调用 Terraform 或 Power Automate 流程，通过我们在前一章中讨论过的流程来配置新的环境。 我们可以设置诸如拉取请求审批等活动。 正如我们所见，选项 几乎 是无限的。

操作前的授权

聊天机器人可以在给定项目的所有团队成员之间共享。 使用 Microsoft Teams 和 Copilot Studio，我们可以利用 Microsoft Entra ID 作为身份管理系统。 我们注册的连接器和操作应该授权用户，以验证这些用户是否有权限在启动任务之前执行操作。 这可以防止他们执行一些 敏感操作。

## 将 Microsoft Teams 与 GitHub 和 Azure DevOps 集成

让我们来看看如何将 Microsoft Teams 与 Azure DevOps 或 GitHub 进行集成，以便项目中的更改能反映在公共团队频道中。 这两个工具都与 Microsoft Teams 有原生集成。 为了将 Azure DevOps 或 GitHub 的通知配置到 Microsoft Teams，我们需要在 Microsoft Teams 中安装一个连接器。 在 Microsoft Teams 团队频道中，我们右键点击一个频道并选择 **管理频道**。当进入频道设置时，我们可以看到 **连接器** 部分，点击 **编辑**，这会打开一个新屏幕，显示特定频道的所有连接器。 在这里，我们可以使用搜索功能找到 Azure DevOps 或 GitHub Enterprise。 点击 **配置** 并按照设置连接器的流程进行操作。

目前，对于 GitHub Enterprise，仅支持以下事件：问题、拉取请求、推送以及这些类别的评论。 在配置 GitHub 连接器时，我们还将获得非常详细的逐步指导，帮助我们配置 Webhook：

![](img/B22208_12_11.jpg)

图 12.11 - GitHub 通知在 Teams 中的示例

Azure DevOps 支持 有关已完成构建、推送代码和与拉取请求、发布及工作项相关操作的事件通知。 我们还可以对这些事件类型进行更精细的控制，例如仅在项目中添加了新的**Bug** 类型工作项时接收信息。 一旦添加连接器，向导将引导我们完成过程并在 Azure DevOps 中创建服务钩子订阅：

![](img/B22208_12_12.jpg)

图 12.12 - 通过 Azure DevOps 的连接器创建服务钩子订阅

除了接收通知，Azure DevOps 还通过允许我们向频道添加标签来与 MS Teams 集成。 这些标签可以显示 Azure DevOps 仪表板或 看板 ，提供项目当前状态的实时信息。 这样，团队成员无需切换上下文和工具，就能获得 这些信息。

GitHub 提供了与 Microsoft Teams 集成的额外功能。 我们可以使用 **GitHub 与 Microsoft Teams 的集成**，这会在 Microsoft Teams 中安装一个聊天机器人，我们也可以通过它接收项目通知、打开或关闭问题、评论拉取请求等。 安装链接可以在 以下找到： [https://teams.github.com/](https://teams.github.com/)。

![](img/B22208_12_13.jpg)

图 12.13 – 通过聊天机器人集成 GitHub 和 Microsoft Teams

GitHub 的机器人已经引导我们进入了支持聊天机器人的 ChatOps 实践。 让我们来看看 如何 构建 我们自己的自定义 copilot，以支持 ChatOps 并使用 Copilot Studio。

## 使用 Copilot Studio 为 Power Platform 构建 ChatOps

我们将通过创建一个简单的 ChatOps 聊天机器人，并使用 Copilot Studio 来演示如何利用 Copilot Studio 支持 DevOps 任务。

我们将前往 Copilot Studio，网址为 [https://copilotstudio.microsoft.com/](https://copilotstudio.microsoft.com/) 并点击 **创建** | **新建 copilot**：

![](img/B22208_12_14.jpg)

图 12.14 – 创建新的自定义 copilot

如果我们的环境位于美国地区，我们将提供一个对话式 创建方式。 然而，我们将点击 **跳过配置**，填写 我们的 **名称** 和 **描述** 字段，点击 **创建**。这将为我们的 copilot 配置 预构建的主题。

如果我们希望通过基于我们数据的生成式回答来增强我们的 copilot，可以选择顶部的 **知识** 标签，然后点击 **添加知识**：

![](img/B22208_12_15.jpg)

图 12.15 – 向我们的副驾驶添加知识

在这里，我们将使用 **文件** 选项 上传任何包含相关 信息的文件，这些信息可能对我们的团队有用。 这可以是包含一般指导或项目特定文档的文件。 我们可以通过拖放文件或使用 **点击浏览** 选项来上传文件。 这样，我们的副驾驶就能回答关于该文档主题的问题。 文档索引并准备好使用需要几分钟时间。 这些文档存储在 Dataverse 文件存储中。

一旦准备好，我们就可以使用 **测试你的** **副驾驶** 选项来测试这个功能。

在副驾驶 **概览** 部分，进入 **知识** | **允许 AI 使用其通用知识（预览）**，我们可以启用或禁用 GPT 模型所拥有的通用知识。 这些是 GPT 被训练时使用的数据。 目前，副驾驶工作室仍使用 GPT-3.5-Turbo，截止日期为 2021 年 9 月。 我们建议在这种情况下禁用它。

下一步是启用副驾驶中的某个操作。 无论我们希望启用什么场景，我们都需要创建一个主题或向副驾驶添加一个操作。 我们先从 主题开始。

我们从顶部菜单中选择 **主题** 选项。 在这里，我们可以看到一些预设的主题，分别命名为 **第一课**， **第二课**，和 **第三课**。这些是我们不需要的预设主题，因此我们可以删除或禁用它们。 我们可以通过点击每个主题旁边的三个点，将状态切换为禁用，或者直接 点击 **删除**。

我们将通过点击 **添加话题** | **从空白开始**来创建一个新话题。我们也可以在 Copilot Studio 中使用 Copilot，描述我们需要什么样的话题，并让 Copilot 根据提供的描述提出一个大致的对话流程。 现在我们进入了设计器，可以在这里创建话题。 我们可以通过点击 **编辑** 在 **短语** 的 **触发器** 节点中指定几个短语，这些短语将触发 这个话题。

一旦短语被 添加后，我们可以继续选择添加节点，点击 **+**号。 在这里，我们可以添加控制对话的对话节点。 在这个示例中，我们将前往 **调用一个动作** | **连接器（预览）** 并搜索 **Azure DevOps**。我们可以选择任何我们想要添加到我们的 Copilot 中，以支持 ChatOps 的动作。 例如，我们将选择 **创建工作项**。这会添加一个连接器动作，并包含我们需要配置的所有输入，以便此连接器动作能够 正常工作：

![](img/B22208_12_16.jpg)

图 12.16 – 向话题添加动作

我们可以在这个连接操作之前创建一条对话路径， 通过一系列问题来询问用户，并将回答存储到变量中，这些变量将作为连接操作的参数。 另一种方法是利用 Copilot Studio 中的生成模式，注册连接操作，并让生成式 AI 根据用户问题的上下文自动判断缺失的值。 生成式 AI 然后可以向用户提出一系列问题，来获取连接操作所需的缺失值。 我们使用 Copilot Studio 中的生成模式并添加生成式操作。 首先，我们需要启用生成模式。 我们需要进入 **设置** | **生成式 AI** | **生成式（预览）**。请注意，该功能目前仍处于预览阶段，不应在生产环境中使用。 目前它仅适用于 英文协助程序。

![](img/B22208_12_17.jpg)

图 12.17 – 在自定义协助程序中启用生成模式（预览）

选择后，点击 **保存** 该设置上方的按钮。 通过此操作，我们允许生成式 AI 根据用户的消息确定应该调用哪个操作或话题。 这也改变了我们触发 话题的方式。 它们不再是短语，而是转化为话题 描述。 话题描述包含了我们的话题所执行的操作信息。 话题描述的示例可以在 *图 12**.18*中看到。这由 GPT 模型使用来确定应该调用哪个操作或话题。 话题或操作描述越准确，GPT 模型就越有可能调用正确的操作 或话题：

![](img/B22208_12_18.jpg)

图 12.18 – 在生成模式下触发话题

我们可以通过点击 **X** 关闭副驾驶设置，点击位置在 Copilot Studio 右上角。 接下来，我们将点击 **操作** | **添加操作** 在顶部菜单栏中。 在这里，我们可以使用搜索框查找 Azure DevOps 或 GitHub 连接器的所有可用操作。 我们可以选择我们希望启用的连接器操作，例如 **从 GitHub 创建问题** ，并继续配置选项：

![](img/B22208_12_19.jpg)

图 12.19 – 在 Copilot Studio 中添加连接器操作

每个连接器操作都带有一组输入和输出。 我们可以静态设置输入值，或者让生成式 AI 理解用户消息的上下文，并尝试从消息中提取正确的实体，并将它们输入到参数中。 对于输出，我们可以让 AI 动态生成输出消息，或者手动配置它。 我们将保持默认设置，并允许 AI 针对每个必需的参数向我们提问。 在 **输出**中，我们将配置默认设置并让 AI 动态生成响应。 通过这种方式，我们现在已经在副驾驶中启用了 **创建新问题** 操作。 我们可以继续启用我们希望在 ChatOps 流程中使用的其他操作。

最后，我们将创建一个与 Power Automate 工作流的集成，以支持更复杂的流程。 流程可以像我们之前看到的那样注册为操作。 另外，我们可以构建一个主题，并添加一个节点来调用 Power Automate 流程。 由于我们已将副驾驶的生成式 AI 设置更改为生成模式，我们需要提供 关于我们主题的准确和清晰的信息。 在 描述完主题后，我们可以通过使用加号 | **调用操作** | **基本操作** | **创建流程**来添加一个流程。这将单独打开 Power Automate，并带有输入触发器和输出操作，二者都与副驾驶的集成相关 ：

![](img/B22208_12_20.jpg)

图 12.20 – 为副驾驶创建流程

我们可以继续这个过程，构建主题和流程，并与将支持我们的 ChatOps 流程的操作进行连接。

一旦我们对工作满意 并且希望将其部署到 Microsoft Teams，我们需要发布这个机器人。 在副驾驶的右上角，我们有 **发布** 选项。 会弹出一个窗口，我们需要确认发布过程，点击 **发布**。然后，我们可以返回到 **副驾驶工作室副驾驶** | **频道** | **Microsoft Teams**。我们可以点击 **启用 Teams** 来在 Teams 中启用这个机器人。 在这里，我们有 **可用性选项**，可以让我们将副驾驶分享到 Teams 应用商店中。 返回到 Teams 设置，我们有 **打开副驾驶** 选项，点击它会将副驾驶作为应用打开在 Teams 中。 我们的机器人 现在已准备好与用户互动并执行 DevOps 操作。 如果我们希望将副驾驶添加到 Teams 频道，我们可以在 **编辑详细信息** 中设置，允许同一租户的用户将此副驾驶添加到团队中。 但是，这样会使用户能够将副驾驶添加到他们所在的任何团队中。 我们建议查看 Teams 管理选项，并通过 Teams 管理副驾驶的推广过程 。

在下图中，我们 可以看到一个成功部署自定义副驾驶到 Microsoft Teams 的示例。 我们可以看到生成式 AI 功能如何在不同主题之间切换，执行操作，甚至通过提问来获取所有 必需的参数值：

![](img/B22208_12_21.jpg)

图 12.21 – 在 Microsoft Teams 中使用自定义副驾驶

## 副驾驶工作室的 ALM

副驾驶 工作室与其他 Power Platform 产品一样，通过解决方案支持应用生命周期管理。 我们应该从 前往 **解决方案** 并点击 **新建解决方案** 或打开一个现有的解决方案。 进入解决方案后，我们可以点击 **新建** | **聊天机器人** 开始在副驾驶工作室中创建我们的自定义副驾驶。 使用这种方式可以确保我们可能在副驾驶中作为操作使用并注册的任何潜在连接器，会作为 连接引用 添加到解决方案中。

我们可以按照前几章中展示的相同方法，使用 Azure DevOps 或 GitHub 导出和导入解决方案。

由于我们可以在 Copilot Studio 中使用不同的连接器，因此必须确保有有效的 DLP 策略，这将确保在任何给定的环境中，只能使用组织策略允许的连接器。 可以使用。

除了之前提到的方法，我们还可以专门利用 PAC CLI 来管理 copilot。 如果我们希望仅维护自定义 copilot 的 ALM，我们可以使用这些命令并将其打包成脚本。 自定义 copilots。

使用以下 PAC CLI 命令，我们可以导出我们 copilot 的 YAML 模板文件： 我们的 copilot：

```
 pac copilot extract-template --bot <BOT-ID> --templateFileName <templateName>.yaml
```

这有两个目的。 首先，我们可以将整个 copilots 作为代码导出，存储在代码库中，并通过代码进行协作。 其次，采用这种方法，我们可以为组织的 copilots 构建模板。 我们可以使用这种方法准备一个模板，作为组织各部门 copilots 外观的框架或起点。 这将包括一些预定义的主题作为起点。 然后，我们可以将这些 copilots 的定义导出为模板文件，并将这些文件存储在中央代码库中的某个地方。 当有人请求特定的 copilot 时，我们可以使用预先准备好的模板文件，创建一个包含这些预构建主题的 copilot，并与合适的人分享。 导入过程可以通过以下 PAC CLI 命令完成。

在我们能够将 copilot 导入目标环境之前，我们需要确保 `connectionReferences` 部分已正确更新，以反映目标环境中的适当值。 在创建的模板 YAML 文件中，在文件的底部，我们可以找到连接引用，如下所示： 以下片段：

```
 connectionReferences:
  - managedProperties:
      isCustomizable: false connectionId: <CONNECTION-ID-TARGET-ENVIRONMENT> connectorId: /providers/Microsoft.PowerApps/apis/shared_visualstudioteamservices
    connectionReferenceLogicalName: template.connectionreference.cr6a8_chatOpsDemo.cr.SyS11HJP
    displayName: cr6a8_chatOpsDemo.cr.SyS11HJP
connectorDefinitions:
  - connectorId: /providers/Microsoft.PowerApps/apis/shared_visualstudioteamservices
```

此外，我们 还需要确保在启动该命令之前，目标环境中已经准备好解决方案。 我们可以创建一个新的解决方案或使用现有的解决方案。 我们可以创建一个新的解决方案或使用现有的解决方案。

一旦所有这些设置完成，我们就可以启动导入命令： 导入命令：

```
 pac copilot create --environment <ENVIRONMENT_ID> --schemaName <SCHEMA_NAME> --templateFileName <TEMPLATE-FILE>.yaml --displayName <DISPLAY-NAME> --solution <SOLUTON-NAME>
```

如果出现任何错误，这将记录在 `pac-log.txt` 文件中，错误信息中已写明。

现在副驾驶已经配置好，我们可以与创作者组分享副驾驶。 如果我们单独与用户分享副驾驶，他们将获得创作者角色，以共同编辑机器人。 如果我们将副驾驶 分享给安全 组，那么安全组中的用户将获得 仅使用权限。

# 总结

在本章中，我们对 AI 进行了宏观概述，并讨论了过去两年的一个热门话题：GPTs。 AI 已经成为我们日常任务的不可或缺的一部分。 它无处不在，几乎在我们使用的每个应用程序中。 各组织正在寻求利用 AI 进行创新，或者仅仅是提高业务流程的效率。 无论是哪种方式，我们都必须确保以负责任、伦理和安全的方式构建 AI 解决方案，正如本章中所学。 接下来，我们了解了微软如何将 AI 助手，称为副驾驶，嵌入到每个产品中，以便我们在使用这些工具时能够更高效。 我们特别研究了 Power Platform 中的副驾驶，以及我们作为创作者，如何利用它快速设置数据架构、原型应用、流程 等。

随着各组织寻求通过 AI 进行创新，他们可能会面临一个问题：Power Platform 中有哪些 AI 服务可供使用。 下一部分重点介绍了 AI Builder 及其组件，如 AI 模型和 AI 提示。 我们了解了如何在应用程序中使用它们，并将 ALM 流程应用于 AI Builder 组件。 然而，AI Builder 并不是唯一可以用来增强我们业务应用程序的 AI 服务。 Azure OpenAI 为组织提供了安全可靠的 OpenAI 模型，可以在任何流程或应用程序中使用，正如 我们所学。

我们通过聚焦于使用 Copilot Studio 和 ChatOps 来定制助手，结束了这一章节。 我们介绍了 Copilot Studio，它使我们能够构建定制的助手或简单的聊天机器人。 通过将 AI 融入 Copilot Studio，我们可以在数小时内为内部或外部用户构建丰富的对话式 AI 体验，而不是数月。 Copilot Studio 是一个支持业务流程的平台，包括支持 ChatOps 相关的服务。 因此，在这一部分的结尾，我们探讨了 ChatOps，它通过提供与机器人对话的体验，扩展了 DevOps，能够执行与 DevOps 相关的操作。 最后，我们实际探讨了 ChatOps 流程如何通过 Copilot Studio 获得支持，以及在应用生命周期管理（ALM）中，Copilot Studio 有哪些小的特殊性。 Copilot Studio。

至此，我们将结束这本书。 这本书带我们走过了 DevOps 生命周期的不同阶段，从规划业务解决方案到构建管道、管理 DevSecOps、照料环境生命周期、理解最佳实践，最后以 AI 和 ChatOps 收尾。 我们希望到目前为止，我们已经成功地展示了 Microsoft Power Platform 是一个强大而成熟的平台，具有扩展性，能够帮助组织和个人构建应用并支持其业务流程，利用 Power Platform 中可用的服务和功能。 Power Platform。

# 进一步阅读

+   微软关于负责任 AI 的 实践： [https://www.microsoft.com/en-us/ai/responsible-ai](https://www.microsoft.com/en-us/ai/responsible-ai)

+   Azure OpenAI 服务： [https://learn.microsoft.com/en-us/azure/ai-services/openai/overview](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview)

+   Copilot Studio 指南： [https://learn.microsoft.com/en-us/microsoft-copilot-studio/guidance/](https://learn.microsoft.com/en-us/microsoft-copilot-studio/guidance/)

+   GitHub 和 Microsoft Teams 集成的文档： [https://github.com/integrations/microsoft-teams/blob/master/Readme.md](https://github.com/integrations/microsoft-teams/blob/master/Readme.md)

+   关于 Azure DevOps 和 Microsoft Teams 集成的详细信息： [https://learn.microsoft.com/en-us/azure/devops/service-hooks/services/teams?view=azure-devops](https://learn.microsoft.com/en-us/azure/devops/service-hooks/services/teams?view=azure-devops)

+   PAC CLI 命令用于 copilot： [https://learn.microsoft.com/en-us/power-platform/developer/cli/reference/copilot](https://learn.microsoft.com/en-us/power-platform/developer/cli/reference/copilot)
