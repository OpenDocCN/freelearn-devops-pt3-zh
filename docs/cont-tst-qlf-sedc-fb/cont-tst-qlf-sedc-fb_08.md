# <st c="0">8</st>

# <st c="2">将 AI/ML 应用于持续测试、质量、安全和反馈</st>

<st c="71">本章深入探讨了</st> **<st c="124">人工智能</st>** <st c="147">(</st>**<st c="149">AI</st>**<st c="151">) 和</st> **<st c="158">机器学习</st>** <st c="174">(</st>**<st c="176">ML</st>**<st c="178">) 在软件开发生命周期中的变革性作用，特别关注</st> <st c="246">如何提升持续测试、质量、安全和</st> <st c="302">反馈实践。</st>

<st c="321">本章开始时概述了 AI/ML 的应用。</st> <st c="381">它解释了这些技术如何重新塑造持续测试、质量、安全和反馈的领域。</st> <st c="501">每个部分深入探讨了旨在自动化和优化流程的 AI/ML 策略，从早期的代码测试到部署后的监控。</st> <st c="678">这些都是为了促进无缝、持续集成和交付管道的实现，借助</st> <st c="765">AI 驱动的工具链。</st>

<st c="786">本章为选择能在您的持续测试、质量、安全和反馈转型项目中有效整合的 AI/ML 工具提供了方法论。</st> <st c="953">的建议。</st>

<st c="977">通过本章的学习，您将全面了解适用于持续测试、质量、安全和反馈的 AI/ML 工具。</st> <st c="1153">您还将学会一种系统的方法来选择</st> <st c="1215">AI/ML 工具。</st>

<st c="1235">在本章中，我们将涵盖以下</st> <st c="1279">主要主题：</st>

+   <st c="1291">AI/ML 应用</st>

+   <st c="1310">用于</st> <st c="1321">持续测试的 AI/ML</st>

+   <st c="1339">用于</st> <st c="1350">持续质量的 AI/ML</st>

+   <st c="1368">用于</st> <st c="1379">持续安全的 AI/ML</st>

+   <st c="1398">用于</st> <st c="1409">持续反馈的 AI/ML</st>

+   <st c="1428">选择</st> <st c="1455">AI/ML 工具的方法</st>

<st c="1466">让我们</st> <st c="1473">开始吧！</st>

# <st c="1485">AI/ML 应用</st>

<st c="1504">在快速发展的</st> <st c="1542">软件开发和运维领域，AI 和 ML 正在改变组织如何看待持续测试、质量、安全、</st> <st c="1676">以及反馈。</st>

<st c="1689">如</st> *<st c="1708">图 8</st>**<st c="1716">.1</st>*<st c="1718">所示，这些技术已经成为帮助组织应对数字化转型复杂性的重要工具，尤其是在 DevOps、DevSecOps 和 SRE 等框架下。</st> <st c="1906">通过利用 AI/ML 的力量，企业不仅加速了开发周期，还以前所未有的方式增强了其应用的稳健性和安全性。</st> <st c="2078">。</st>

![图 8.1 – AI/ML 在持续测试、质量、安全性和反馈中的应用](img/B21936_figure_08.01.jpg)

<st c="2259">图 8.1 – AI/ML 在持续测试、质量、安全性和反馈中的应用</st>

<st c="2346">近年来，AI/ML 技术取得了显著进展，达到了能够有效</st> <st c="2477">集成到持续集成/持续部署</st> **<st c="2517">（CI/CD）</st>** <st c="2561">流水线的复杂程度，在这些流水线中，速度和效率的需求必须与质量和安全的要求相平衡。</st> <st c="2682">AI/ML 通过自动化复杂任务、预测潜在问题并提供可操作的见解，从而减少人工工作，促进了人力资源的更战略性使用。</st> <st c="2878">人力资源。</st>

<st c="2894">AI/ML 的应用</st> <st c="2920">包括从数据中学习、适应新信息并随着时间推移不断改进的能力。</st> <st c="3016">这一能力在识别模式、预见潜在漏洞和优化测试策略方面具有无价的价值。</st> <st c="3134">在质量保证中，AI 驱动的工具可以预测最可能出现故障的区域，并相应地定制测试工作。</st> <st c="3250">在安全性方面，ML 算法可以检测到表明潜在威胁的异常情况，而在操作中，AI 可以增强反馈机制，进而使系统更加稳健和</st> <st c="3417">响应迅速。</st>

<st c="3436">本章后续部分将深入探讨 AI/ML 在持续测试、质量、安全性和反馈领域中的具体应用案例。</st> <st c="3595">这些例子将展示 AI/ML 如何不仅简化流程，还提升软件开发和维护的标准。</st> <st c="3740">本章提供了 AI/ML 对致力于卓越的数字化转型组织的变革潜力的全面概述。</st> <st c="3882">转型之旅。</st>

# <st c="3906">AI/ML 在持续测试中的应用</st>

<st c="3935">将 AI 和 ML 集成到</st> <st c="3963">软件的持续测试活动中，可以显著简化流程，解决每个活动中可能出现的瓶颈，正如在</st> *<st c="4117">图 8</st>**<st c="4125">.2</st>*<st c="4127">中所示。</st>

![图 8.2 – AI/ML 在持续测试活动中的应用](img/B21936_figure_08.02.jpg)

<st c="4471">图 8.2 – AI/ML 在持续测试活动中的应用</st>

<st c="4523">以下是这些技术在各种</st> <st c="4584">测试活动中的应用：</st>

1.  **<st c="4603">需求分析</st>**<st c="4625">：</st>

    +   *<st c="4627">解释</st>*<st c="4638">：确保</st> <st c="4648">测试场景与业务需求以及</st> <st c="4706">用户需求一致。</st>

    +   *<st c="4717">瓶颈</st>*<st c="4728">: 错误的解读或不完整的分析可能导致不足的</st> <st c="4795">测试覆盖率。</st>

    +   *<st c="4809">AI/ML 解决方案</st>*<st c="4824">: NLP 可以自动提取和解释需求，确保全面且准确的</st> <st c="4931">测试覆盖率。</st>

1.  **<st c="4945">测试策略</st>**<st c="4959">:</st>

    +   *<st c="4961">解释</st>*<st c="4972">: 概述</st> <st c="4983">测试方法、目标</st> <st c="5018">和资源。</st>

    +   *<st c="5032">瓶颈</st>*<st c="5043">: 不清晰的策略可能导致测试工作效率低下和</st> <st c="5110">资源分配不当。</st>

    +   *<st c="5130">AI/ML 解决方案</st>*<st c="5145">: AI 可以分析历史数据，建议最有效的测试策略，并预测</st> <st c="5237">资源需求。</st>

1.  **<st c="5252">测试</st> <st c="5257">计划</st>**<st c="5263">:</st>

    +   *<st c="5265">解释</st>*<st c="5276">: 指导测试过程、时间表</st> <st c="5288">和责任的详细文档。</st>

    +   *<st c="5359">瓶颈</st>*<st c="5370">: 不灵活的计划可能难以适应项目变化，</st> <st c="5432">导致延迟。</st>

    +   *<st c="5447">AI/ML 解决方案</st>*<st c="5462">: ML 算法可以根据项目的持续发展和</st> <st c="5559">过去的结果建议调整测试计划。</st>

1.  **<st c="5573">测试用例</st>**<st c="5584">:</st>

    +   *<st c="5586">解释</st>*<st c="5597">: 执行测试的</st> <st c="5609">特定条件。</st>

    +   *<st c="5651">瓶颈</st>*<st c="5662">: 开发耗时且维护</st> <st c="5727">测试用例的工作量巨大。</st>

    +   *<st c="5738">AI/ML 解决方案</st>*<st c="5753">: AI 可以从需求</st> <st c="5818">文档中自动生成测试用例，提高效率</st> <st c="5851">和覆盖率。</st>

1.  **<st c="5864">测试脚本</st>**<st c="5877">:</st>

    +   *<st c="5879">解释</st>*<st c="5890">: 自动化</st> <st c="5903">脚本执行</st> <st c="5924">测试用例。</st>

    +   *<st c="5935">瓶颈</st>*<st c="5946">: 脚本开发和维护可能</st> <st c="5988">消耗大量资源。</st>

    +   *<st c="6010">AI/ML 解决方案</st>*<st c="6025">: AI 可以根据应用或测试用例的变化生成并更新测试脚本，减少</st> <st c="6128">维护工作量。</st>

1.  **<st c="6147">测试数据</st>**<st c="6157">:</st>

    +   *<st c="6159">解释</st>*<st c="6170">: 测试中使用的数据集，用于模拟</st> <st c="6181">现实世界场景。</st>

    +   *<st c="6235">瓶颈</st>*<st c="6246">: 创建、管理和维护准确的测试数据</st> <st c="6304">是一个挑战。</st>

    +   *<st c="6319">AI/ML 解决方案</st>*<st c="6334">: AI 可以自动生成和管理测试数据，确保其相关性</st> <st c="6416">和多样性。</st>

1.  **<st c="6428">测试环境</st>**<st c="6445">:</st>

    +   *<st c="6447">解释</st>*<st c="6458">: 测试进行的设置，尽可能地模拟生产环境。</st>

    +   *<st c="6556">瓶颈</st>*<st c="6567">: 测试环境的配置和维护</st> <st c="6621">非常复杂。</st>

    +   *<st c="6633">AI/ML 解决方案</st>*<st c="6648">: AI 可以根据测试需求预测并配置最优的测试环境，减少</st> <st c="6743">设置时间。</st>

1.  **<st c="6754">与</st>** **<st c="6773">依赖系统的协调</st>**<st c="6790">:</st>

    +   *<st c="6792">解释</st>*<st c="6803">: 确保被测试系统与数据库和</st> <st c="6876">其他应用程序正确交互。</st>

    +   *<st c="6895">瓶颈</st>*<st c="6906">: 依赖管理可能会</st> <st c="6935">导致延迟。</st>

    +   *<st c="6948">AI/ML 解决方案</st>*<st c="6963">: AI 可以自动检测并解决集成问题，提升</st> <st c="7044">协调效率。</st>

1.  **<st c="7068">测试</st>** **<st c="7074">活动设置</st>**<st c="7088">:</st>

    +   *<st c="7090">解释</st>*<st c="7101">: 组织并安排一系列</st> <st c="7114">测试执行。</st>

    +   *<st c="7158">瓶颈</st>*<st c="7169">: 需要精心规划，并可能受限于</st> <st c="7221">资源限制。</st>

    +   *<st c="7242">AI/ML 解决方案</st>*<st c="7257">: AI 可以根据风险和</st> <st c="7338">影响分析帮助安排和优先考虑测试活动。</st>

1.  **<st c="7354">测试执行</st>**<st c="7369">:</st>

    +   *<st c="7371">解释</st>*<st c="7382">: 运行测试用例和脚本的过程，包括自动化</st> <st c="7447">和手动。</st>

    +   *<st c="7458">瓶颈</st>*<st c="7469">: 耗时较长，尤其是对于</st> <st c="7505">手动测试。</st>

    +   *<st c="7518">AI/ML 解决方案</st>*<st c="7533">: AI 可以优先执行测试并识别不稳定的测试，简化</st> <st c="7608">过程。</st>

1.  **<st c="7620">测试判定报告</st>** **<st c="7626">:</st>**

    +   *<st c="7645">解释</st>*<st c="7656">: 确定并报告</st> <st c="7670">测试执行的结果。</st>

    +   *<st c="7716">瓶颈</st>*<st c="7727">: 手动判定结果可能</st> <st c="7763">很慢。</st>

    +   *<st c="7771">AI/ML 解决方案</st>*<st c="7786">: AI</st> <st c="7792">可以自动解读测试结果，加速</st> <st c="7844">报告。</st>

1.  **<st c="7857">数据日志记录</st>** **<st c="7866">:</st>**

    +   *<st c="7875">解释</st>*<st c="7886">: 记录与测试相关的数据，以便</st> <st c="7899">进一步分析。</st>

    +   *<st c="7946">瓶颈</st>*<st c="7957">: 广泛的数据收集可能会</st> <st c="7990">压垮资源。</st>

    +   *<st c="8010">AI/ML 解决方案</st>*<st c="8025">：AI 可以智能地过滤并记录相关数据，</st> <st c="8080">减少噪声。</st>

1.  **<st c="8095">测试</st>** **<st c="8101">结果分析</st>**<st c="8116">：</st>

    +   *<st c="8118">解释</st>*<st c="8129">：分析</st> <st c="8142">测试结果以识别缺陷</st> <st c="8176">和问题。</st>

    +   *<st c="8187">瓶颈</st>*<st c="8198">：需要大量时间</st> <st c="8227">和专业知识。</st>

    +   *<st c="8241">AI/ML 解决方案</st>*<st c="8256">：ML 算法可以快速识别测试结果中的模式和异常，突出</st> <st c="8347">潜在问题。</st>

1.  **<st c="8364">测试</st>** **<st c="8370">结果报告</st>**<st c="8386">：</st>

    +   *<st c="8388">解释</st>*<st c="8399">：向利益相关者</st> <st c="8415">传达发现</st> <st c="8425">的结果。</st>

    +   *<st c="8441">瓶颈</st>*<st c="8452">：编写报告</st> <st c="8473">非常耗时。</st>

    +   *<st c="8491">AI/ML 解决方案</st>*<st c="8506">：由 AI 驱动的自动化报告工具可以快速生成有洞察力和全面的</st> <st c="8591">报告。</st>

1.  **<st c="8607">等待资源修复</st>** **<st c="8637">失败的测试</st>**<st c="8649">：</st>

    +   *<st c="8651">解释</st>*<st c="8662">：等待修复</st> <st c="8673">已识别问题时的停机时间。</st>

    +   *<st c="8717">瓶颈：</st>* <st c="8729">阻碍</st> <st c="8736">测试进展。</st>

    +   *<st c="8753">AI/ML 解决方案：</st>* <st c="8769">AI 可以</st> <st c="8776">预测可能失败的领域，并提出</st> <st c="8820">潜在的修复方案。</st>

<st c="8836">将 AI/ML 应用于软件测试活动</st> <st c="8883">带来了许多优势，但也引入了一些挑战，正如</st> *<st c="8968">图 8</st>**<st c="8976">.3</st>*<st c="8978">所示。解决这些问题需要技术解决方案、流程调整和</st> <st c="9078">文化变革的结合。</st>

![图 8.3 – AI/ML 持续测试挑战](img/B21936_figure_08.03.jpg)

<st c="9097">图 8.3 – AI/ML 持续测试挑战</st>

<st c="9149">在这里，我们讨论一些</st> <st c="9171">常见问题及其克服策略：</st>

+   **<st c="9221">缺乏对正在测试应用程序的直观理解</st>** **<st c="9273">：</st>**

    +   *<st c="9287">问题</st>*<st c="9294">：AI/ML 模型可能无法完全理解应用程序的上下文或其功能的细微差别，从而导致测试场景的有效性降低。</st>

    +   *<st c="9436">解决方案</st>*<st c="9445">：通过更丰富的上下文数据增强 AI 模型，并引入反馈循环，允许测试人员细化和调整 AI 生成的测试用例。</st> <st c="9586">采用强化学习等技术还可以帮助 AI 模型随着时间推移更好地理解应用程序的上下文。</st>

+   **<st c="9711">测试会话之间的</st>** **<st c="9750">重复性和一致性</st>**<st c="9763">：</st>

    +   *<st c="9765">问题</st>*<st c="9772">：AI 驱动的测试可能会为相同的输入在不同的会话中生成不同的输出，从而使测试一致性</st> <st c="9896">和可追溯性变得复杂。</st>

    +   *<st c="9913">解决方案</st>*<st c="9922">：为 AI 模型及其训练数据实施版本控制，确保测试会话的一致性。</st> <st c="10028">采用确定性方法与 AI 结合，保持核心稳定、</st> <st c="10110">可重复的测试。</st>

+   **<st c="10127">对</st>** **<st c="10157">生成的测试的理解缺乏</st>**<st c="10172">：</st>

    +   *<st c="10174">问题</st>*<st c="10181">：测试人员可能会发现理解或信任 AI 生成的测试用例的合理性具有挑战性，这会影响他们有效评估测试</st> <st c="10326">结果的能力。</st>

    +   *<st c="10347">解决方案</st>*<st c="10356">：将可解释性功能纳入 AI/ML 模型，以提供对其决策过程的洞察。</st> <st c="10471">通过教育和透明度培养信任和理解文化，说明 AI</st> <st c="10567">模型的操作方式。</st>

+   **<st c="10582">测试覆盖率</st>**<st c="10596">：</st>

    +   *<st c="10598">问题</st>*<st c="10605">：AI/ML 可能无法充分覆盖所有测试场景，可能漏掉</st> <st c="10704">关键缺陷。</st>

    +   *<st c="10721">解决方案</st>*<st c="10730">：将 AI/ML 与传统的测试方法相结合，以确保全面覆盖。</st> <st c="10814">定期审查并调整 AI/ML 模型生成测试用例时使用的标准，确保它们与不断变化的应用功能</st> <st c="10955">和风险保持一致。</st>

+   **<st c="10965">与不同</st>** **<st c="10995">测试工具</st>**<st c="11005">的兼容性</st>**：

    +   *<st c="11007">问题</st>*<st c="11014">：AI/ML 模型可能无法与现有的测试工具和框架无缝集成，从而限制其</st> <st c="11114">实用性。</st>

    +   *<st c="11128">解决方案</st>*<st c="11137">：开发或使用具有广泛 API 支持和集成功能的 AI/ML 解决方案。</st> <st c="11228">与工具供应商合作或贡献开源项目，以</st> <st c="11292">提高兼容性。</st>

+   **<st c="11314">团队的接受度</st>** **<st c="11326">：</st>**<st c="11334">：

    +   *<st c="11336">问题</st>*<st c="11343">：测试人员</st> <st c="11353">和开发人员可能会对 AI 驱动的测试持怀疑或抵触态度，担心职位替代或不信任</st> <st c="11474">AI 的有效性。</st>

    +   *<st c="11493">解决方案</st>*<st c="11502">：教育</st> <st c="11512">并让团队参与 AI/ML 测试策略的开发和实施。</st> <st c="11598">展示 AI/ML 在增强他们角色而非取代它们方面的价值，重点将 AI 作为应对日常任务的工具，让团队能够专注于更复杂且</st> <st c="11779">更有成就感的工作。</st>

+   **<st c="11794">数据质量</st>** **<st c="11808">和可用性</st>**<st c="11824">：</st>

    +   *<st c="11826">问题</st>*<st c="11833">：AI/ML 模型需要大量高质量数据进行训练。</st> <st c="11906">不充分或低质量的数据可能导致</st> <st c="11950">无效的测试。</st>

    +   *<st c="11970">解决方案</st>*<st c="11979">：投资于数据策划和生成策略，例如合成数据创建，确保模型得到</st> <st c="12092">良好的训练。</st>

+   **<st c="12105">持续学习</st>** **<st c="12126">和适应性</st>**<st c="12140">：</st>

    +   *<st c="12142">问题</st>*<st c="12149">：随着应用的不断发展，AI/ML 模型可能会变得过时。</st>

    +   *<st c="12208">解决方案</st>*<st c="12217">：建立持续学习机制，使模型定期通过新数据和反馈进行更新，确保它们始终保持相关性</st> <st c="12359">和有效性。</st>

+   **<st c="12373">伦理与</st>** **<st c="12386">偏见考量</st>**<st c="12405">：</st>

    +   *<st c="12407">问题</st>*<st c="12414">：AI/ML</st> <st c="12422">测试模型可能会继承或放大其训练数据中的偏见，导致不公平或</st> <st c="12523">歧视性结果。</st>

    +   *<st c="12547">解决方案</st>*<st c="12556">：实施</st> <st c="12569">伦理准则和偏见检测方法，用于 AI/ML 模型的开发和使用。</st> <st c="12658">定期审计模型以发现偏见，并根据需要进行修正。</st>

<st c="12719">通过这些深思熟虑的策略来应对挑战，组织可以最大限度地发挥 AI/ML 在测试活动中的优势，同时减轻潜在的负面影响，从而实现更高效、更有效和更值得信赖的</st> <st c="12942">测试流程。</st>

## <st c="12960">AI/ML 辅助的持续测试在实际应用中的案例</st>

<st c="13018">一个实际应用案例是</st> <st c="13047">在使用如</st> **<st c="13081">Applitools</st>**<st c="13091">这样的工具时，该工具利用视觉 AI 来自动化并简化多个网页和移动应用程序中</st> **<st c="13163">用户界面</st>** <st c="13178">(</st>**<st c="13180">UI</st>**<st c="13183">)的验证工作。</st> <st c="13193">这种 AI 驱动的方法使团队能够通过将当前版本的应用 UI 与先前捕获并验证为正确的基准图像进行比较，来检测不一致或视觉回归</st> <st c="13444">问题。</st>

<st c="13455">这种方法通过自动检测布局问题、颜色不匹配或 UI 元素的意外变化等视觉问题，极大地减少了手动测试所需的时间和精力。</st> <st c="13662">AI 组件随着时间推移会适应 UI 的变化，从而保持其有效性，即使应用程序发生变化。</st> <st c="13789">通过将此类工具集成到开发管道中，组织可以确保更准确、高效和可扩展的测试过程，最终实现更快速的部署周期和更高质量的</st> <st c="13995">软件产品。</st>

# <st c="14013">AI/ML 用于持续质量</st>

<st c="14042">在开发、交付和生产生命周期中实施持续质量涉及若干活动，旨在确保稳定的发布并提升用户满意度，如</st> *<st c="14247">图 8</st>**<st c="14255">.4</st>*<st c="14257">所示。</st>

![图 8.4 – 用于持续质量活动的 AI/ML](img/B21936_figure_08.04.jpg)

<st c="14482">图 8.4 – 用于持续质量活动的 AI/ML</st>

<st c="14534">以下是此方法所需的活动列表，列出了潜在的瓶颈以及 AI/ML 如何解决</st> <st c="14652">这些挑战：</st>

1.  **<st c="14669">质量</st>** **<st c="14678">指标集成</st>**<st c="14697">：</st>

    +   *<st c="14699">描述</st>*<st c="14710">：将</st> <st c="14723">质量指标嵌入到软件开发生命周期的每个阶段，以持续监控和改进</st> <st c="14818">质量。</st>

    +   *<st c="14839">瓶颈</st>*<st c="14851">：手动收集和分析质量指标可能会耗时且容易出错，可能会拖慢</st> <st c="14976">开发过程。</st>

    +   *<st c="14996">AI/ML 应用</st>*<st c="15014">：AI 可以自动化从各种工具和平台中提取、监控和分析质量指标，提供实时洞察和预测，以防止</st> <st c="15183">质量问题。</st>

1.  **<st c="15198">自动化</st>** **<st c="15209">代码审查</st>**<st c="15221">：</st>

    +   *<st c="15223">描述</st>*<st c="15234">：利用</st> <st c="15246">工具自动审查代码中的潜在问题、遵循编码标准和安全漏洞，代码一旦</st> <st c="15378">提交，就会立即进行检查。</st>

    +   *<st c="15391">瓶颈</st>*<st c="15403">：自动化代码审查工具中的高误报率可能会导致开发人员疲劳，并减缓</st> <st c="15511">审查过程。</st>

    +   *<st c="15526">AI/ML 应用</st>*<st c="15544">：机器学习模型可以从历史代码审查数据中学习，以减少误报并突出最相关的问题，从而简化</st> <st c="15683">审查过程。</st>

1.  **<st c="15698">持续测试</st>**<st c="15717">：</st>

    +   *<st c="15719">描述</st>*<st c="15730">：在 CI/CD 流水线中运行自动化测试，以尽早识别缺陷</st> <st c="15816">尽可能早。</st>

    +   *<st c="15828">瓶颈</st>*<st c="15840">：创建和维护覆盖应用各个方面的综合测试套件可能会消耗大量资源，并可能导致发布速度变慢。</st>

    +   *<st c="15987">AI/ML 应用</st>*<st c="16005">：AI 可以根据代码库的变化和用户行为生成测试用例，确保相关且高效的</st> <st c="16132">测试覆盖。</st>

1.  **<st c="16146">实时用户</st>** **<st c="16162">反馈分析</st>**<st c="16179">：</st>

    +   *<st c="16181">描述</st>*<st c="16192">：实时收集和分析来自多个渠道的用户反馈，以识别问题和改进领域。</st>

    +   *<st c="16314">瓶颈</st>*<st c="16326">：手动分析来自多个来源的用户反馈可能会不堪重负，并延迟识别</st> <st c="16436">关键问题。</st>

    +   *<st c="16452">AI/ML 应用</st>*<st c="16470">：NLP 和情感分析算法可以自动对用户反馈进行分类和优先级排序，从而加快对关键问题</st> <st c="16614">和趋势的响应。</st>

1.  **<st c="16625">预测漏洞与</st>** **<st c="16645">问题检测</st>**<st c="16660">：</st>

    +   *<st c="16662">描述</st>*<st c="16673">：基于历史数据和代码变更模式预测潜在的漏洞和问题。</st>

    +   *<st c="16785">瓶颈</st>*<st c="16797">：在没有历史背景的情况下识别潜在问题可能是具有挑战性的，可能导致问题在发布后未被注意到</st> <st c="16942">直到发布后。</st>

    +   *<st c="16956">AI/ML 应用</st>*<st c="16974">：ML 模型可以分析代码变更、提交历史和问题跟踪器，预测最可能引入缺陷的代码区域，从而采取</st> <st c="17125">预防措施。</st>

1.  **<st c="17143">部署</st>** **<st c="17155">风险评估</st>**<st c="17170">：</st>

    +   *<st c="17172">描述</st>*<st c="17183">：根据质量指标、测试结果和历史</st> <st c="17290">部署数据评估新发布的风险。</st>

    +   *<st c="17306">瓶颈</st>*<st c="17318">：手动风险评估可能具有主观性和不一致性，可能导致不必要的延迟或</st> <st c="17426">被忽视的问题。</st>

    +   *<st c="17444">AI/ML 应用</st>*<st c="17462">：AI 算法可以通过分析大量数据集提供客观的风险评估，帮助团队做出明智的决策</st> <st c="17589">关于发布。</st>

1.  **<st c="17604">生产监控与</st>** **<st c="17631">异常检测</st>**<st c="17648">：</st>

    +   *<st c="17650">描述</st>*<st c="17661">：监控生产环境中的意外行为、性能问题和</st> <st c="17748">安全威胁。</st>

    +   *<st c="17765">瓶颈</st>*<st c="17777">：筛选大量监控数据以识别异常可能会延迟问题的检测和解决</st> <st c="17889">。</st>

    +   *<st c="17899">AI/ML 应用</st>*<st c="17917">：机器学习模型可以持续分析监控数据，实时检测异常，减少检测时间并提高</st> <st c="18043">响应</st> <st c="18052">效率。</st>

<st c="18063">通过将这些活动整合到开发、交付和生产生命周期中，组织可以显著增强其持续质量策略。</st> <st c="18230">AI/ML 应用在克服与这些活动相关的瓶颈方面起着至关重要的作用，使发布更加稳定，并提高</st> <st c="18370">用户满意度。</st>

<st c="18388">将 AI/ML 应用于</st> <st c="18406">持续质量活动带来了显著的优势，但也带来了可能妨碍其有效性的挑战，正如在</st> *<st c="18559">图 8</st>**<st c="18567">.5</st>*<st c="18569">中所示。</st>

![图 8.5 – AI/ML 在持续质量中的挑战](img/B21936_figure_08.05.jpg)

<st c="18694">图 8.5 – AI/ML 在持续质量中的挑战</st>

<st c="18746">识别这些问题对于制定应对策略至关重要。</st> <st c="18829">以下是将 AI/ML 融入持续质量工作中的一些常见问题，以及</st> <st c="18935">建议的解决方案：</st>

+   **<st c="18954">缺乏对</st>** **<st c="18994">客户心态的直观理解</st>**<st c="19012">：</st>

    +   *<st c="19014">问题</st>*<st c="19021">：AI/ML</st> <st c="19030">模型可能无法自然地理解客户期望的细微差异或用户与应用程序的交互方式，这可能导致质量改进不一致。</st>

    +   *<st c="19198">策略</st>*<st c="19207">：为了弥合这一差距，将 AI/ML 洞察与直接的客户反馈机制和用户行为分析相结合。</st> <st c="19322">利用自然语言处理（NLP）分析客户评论和反馈，可以提供有助于模型训练和调整的定性见解，使 AI 驱动的质量改进与</st> <st c="19498">用户期望保持一致。</st>

+   **<st c="19516">关于</st>** **<st c="19539">客户环境的不确定性</st>**<st c="19561">：</st>

    +   *<st c="19563">问题</st>*<st c="19570">：AI/ML 模型可能难以预测和测试各种用户环境（设备、操作系统和网络条件），可能会忽略关键的</st> <st c="19742">质量问题。</st>

    +   *<st c="19757">策略</st>*<st c="19766">: 实施合成数据生成和仿真技术可以帮助创建多样化的场景，模拟各种客户环境。</st> <st c="19918">结合真实世界的使用数据，可以训练 AI/ML 模型更好地预测并解决特定环境中的</st> <st c="20037">质量问题。</st>

+   **<st c="20052">数据隐私和</st>** **<st c="20070">安全问题</st>**<st c="20087">:</st>

    +   *<st c="20089">问题</st>*<st c="20096">: 收集和使用 AI/ML 的数据，尤其是用户反馈和行为数据，引发了关于隐私和</st> <st c="20218">数据安全的担忧。</st>

    +   *<st c="20232">策略</st>*<st c="20241">: 使用隐私保护的数据分析技术，如差分隐私和联邦学习，训练模型而不泄露用户个人数据。</st> <st c="20408">通过采用数据治理框架，确保符合数据保护法规，优先考虑用户同意和</st> <st c="20533">数据最小化。</st>

+   **<st c="20551">模型偏差</st>** **<st c="20563">与公平性</st>**<st c="20575">:</st>

    +   *<st c="20577">问题</st>*<st c="20584">: AI/ML</st> <st c="20592">模型可能会无意中</st> <st c="20618">学习到训练数据中的偏差，从而导致质量改进中的不公平或歧视性结果。</st>

    +   *<st c="20732">策略</st>*<st c="20741">: 定期审查 AI/ML 模型的偏差，并实施公平意识的机器学习实践。</st> <st c="20825">这包括多样化训练数据、应用去偏差技术，并设定公平性标准来评估</st> <st c="20940">模型输出。</st>

+   **<st c="20954">适应性</st>** **<st c="20971">对快速变化的响应</st>**<st c="20984">:</st>

    +   *<st c="20986">问题</st>*<st c="20993">: 基于历史数据训练的 AI/ML 模型可能无法迅速适应用户行为、市场趋势或新特性引入的快速变化。</st>

    +   *<st c="21144">策略</st>*<st c="21153">: 将持续学习机制融入 AI/ML 模型中，允许根据新数据进行频繁的再训练和更新。</st> <st c="21281">采用在线学习等技术可以使模型实时适应</st> <st c="21368">变化。</st>

+   **<st c="21378">AI/ML 模型的复杂性</st>** **<st c="21399">及其可解释性</st>**<st c="21421">:</st>

    +   *<st c="21423">问题</st>*<st c="21430">: 一些 AI/ML 模型的“黑箱”性质使得团队难以理解和信任其预测和推荐，尤其是在</st> <st c="21595">质量改进方面。</st>

    +   *<st c="21616">策略</st>*<st c="21625">：专注于开发和</st> <st c="21652">应用</st> **<st c="21662">可解释的 AI</st>** <st c="21676">(</st>**<st c="21678">XAI</st>**<st c="21681">)方法，提供对 AI 模型决策过程的洞察。</st> <st c="21760">通过提供培训和资源，促进透明文化，帮助团队成员理解 AI/ML 模型如何促进</st> <st c="21893">质量成果。</st>

+   **<st c="21910">与现有工具</st>** **<st c="21943">和工作流的集成</st>**<st c="21956">：</st>

    +   *<st c="21958">问题</st>*<st c="21965">：将 AI/ML 解决方案无缝集成到现有的持续质量流程和工具中可能会遇到挑战，可能导致中断</st> <st c="22115">和低效。</st>

    +   *<st c="22134">策略</st>*<st c="22143">：采用提供广泛 API 支持、插件和与现有质量保证及开发平台集成能力的 AI/ML 工具。</st> <st c="22295">考虑逐步集成策略，允许渐进式适应</st> <st c="22373">和学习。</st>

<st c="22386">解决这些</st> <st c="22404">挑战需要一种深思熟虑的方法</st> <st c="22445">，结合技术解决方案、流程调整和持续学习。</st> <st c="22527">通过认识并战略性地解决这些问题，组织可以充分利用 AI/ML 的潜力，提升持续质量的倡议，从而提高用户满意度并降低生产</st> <st c="22744">失败率。</st>

## <st c="22758">AI/ML 辅助的持续质量的实际应用场景</st>

<st c="22816">一个实际的</st> <st c="22828">使用 AI/ML 辅助工具维护软件开发中持续质量的例子可以在</st> **<st c="22939">SonarQube</st>**<st c="22948">中看到，SonarQube 是一个开源平台，利用 ML 增强代码质量分析。</st> <st c="23026">SonarQube 通过使用静态分析方法并结合 ML 算法扫描代码库中的漏洞、缺陷和代码异味。</st> <st c="23160">这些算法通过学习大量的代码数据集，能够更好地识别传统方法可能遗漏的复杂编码问题。</st> <st c="23276">可能错过的复杂编码问题。</st>

<st c="23287">这一 ML 能力使 SonarQube 能够随着时间的推移自适应地提高其分析准确性，从各种代码库中的模式和修正中进行学习。</st> <st c="23451">通过将 SonarQube 集成到 CI/CD 管道中，开发人员可以实时获得代码质量反馈，确保质量检查成为开发过程的一个核心部分，而不是事后的补充。</st> <st c="23662">这种持续的自动化审查有助于保持高标准的编码规范，减少技术债务和生产环境中缺陷的可能性。</st> <st c="23803">生产环境中的缺陷。</st>

# <st c="23826">AI/ML 在持续安全中的应用</st>

<st c="23856">实施持续的</st> <st c="23880">安全性涉及在开发、交付和运维生命周期中无缝集成主动和被动的安全措施。</st> <st c="24024">这种方法旨在最大限度减少安全事件的频率和影响。</st> *<st c="24107">图 8</st>**<st c="24115">.6</st>* <st c="24117">展示了实现</st> <st c="24163">持续安全所需的关键活动。</st>

![图 8.6 – 用于持续安全活动的 AI/ML](img/B21936_figure_08.06.jpg)

<st c="24464">图 8.6 – 用于持续安全活动的 AI/ML</st>

<st c="24517">以下解释了潜在的瓶颈以及 AI/ML 如何缓解</st> <st c="24590">这些挑战：</st>

1.  **<st c="24607">安全性</st>** **<st c="24617">需求分析</st>**<st c="24638">：</st>

    +   *<st c="24640">描述</st>*<st c="24651">：定义</st> <st c="24663">并理解特定于应用程序及其运行环境的安全需求。</st>

    +   *<st c="24770">瓶颈</st>*<st c="24782">：耗时的分析以及可能忽略</st> <st c="24839">关键需求。</st>

    +   *<st c="24861">AI/ML 应用</st>*<st c="24879">：AI 驱动的工具可以分析项目文档和代码，自动识别适用于项目的安全需求和规范，加快过程并</st> <st c="25061">减少遗漏。</st>

1.  **<st c="25081">安全编码</st>** **<st c="25096">实践培训</st>**<st c="25114">：</st>

    +   *<st c="25116">描述</st>*<st c="25127">：培训</st> <st c="25139">开发团队掌握安全编码实践，防止</st> <st c="25195">引入漏洞。</st>

    +   *<st c="25223">瓶颈</st>*<st c="25235">：保持培训材料的更新，并确保所有开发人员都掌握最新知识可能</st> <st c="25334">具有挑战性。</st>

    +   *<st c="25349">AI/ML 应用</st>*<st c="25367">：ML 算法可以根据代码库中最常见的安全错误定制个性化的培训内容，确保相关且</st> <st c="25519">及时的培训。</st>

1.  **<st c="25535">自动化</st>** **<st c="25546">漏洞扫描</st>**<st c="25568">：</st>

    +   *<st c="25570">描述</st>*<st c="25581">：定期使用</st> <st c="25594">自动化工具扫描代码库及依赖项，查找已知漏洞。</st>

    +   *<st c="25682">瓶颈</st>*<st c="25694">：高误报率可能会压倒开发人员，且扫描可能会拖慢</st> <st c="25780">CI/CD 流水线。</st>

    +   *<st c="25795">AI/ML 应用</st>*<st c="25813">：AI 模型可以根据历史数据优先处理漏洞，减少误报的干扰，并将精力集中在最</st> <st c="25954">关键的问题上。</st>

1.  **<st c="25970">动态应用安全</st>** **<st c="26000">测试</st>** <st c="26007">（</st>**<st c="26009">DAST</st>**<st c="26013">）：</st>

    +   *<st c="26016">描述</st>*<st c="26028">：对正在运行的应用程序进行自动化安全测试，以识别</st> <st c="26042">运行时漏洞。</st>

    +   *<st c="26129">瓶颈</st>*<st c="26141">：DAST 可能资源密集且速度较慢，可能会</st> <st c="26197">延迟部署。</st>

    +   *<st c="26218">AI/ML 应用</st>*<st c="26236">：AI 可以通过关注近期更改或已知漏洞的区域来优化测试运行，提高速度</st> <st c="26348">和效率。</st>

1.  **<st c="26363">威胁建模与</st>** **<st c="26384">风险评估</st>**<st c="26399">：</st>

    +   *<st c="26401">描述</st>*<st c="26412">：分析</st> <st c="26424">潜在威胁并评估风险，以优先考虑</st> <st c="26477">安全工作。</st>

    +   *<st c="26494">瓶颈</st>*<st c="26506">：手动威胁建模费时，且可能无法捕捉到不断变化的</st> <st c="26583">威胁格局。</st>

    +   *<st c="26600">AI/ML 应用</st>*<st c="26618">：AI 算法可以通过分析代码更改和外部威胁情报来自动化威胁建模，提供实时</st> <st c="26744">风险评估。</st>

1.  **<st c="26761">安全</st>** **<st c="26771">事件检测</st>**<st c="26789">：</st>

    +   *<st c="26791">描述</st>*<st c="26802">：使用</st> <st c="26816">自动化工具监控应用程序和基础设施中的安全事件。</st>

    +   *<st c="26893">瓶颈</st>*<st c="26905">：警报量可能会让安全团队不堪重负，从而导致威胁被遗漏或</st> <st c="26980">忽视。</st>

    +   *<st c="26996">AI/ML 应用</st>*<st c="27014">：机器学习（ML）可以增强异常检测，区分正常行为和潜在安全事件，减少误报和</st> <st c="27153">警报疲劳。</st>

1.  **<st c="27167">事件响应</st>** **<st c="27186">与修复</st>**<st c="27201">：</st>

    +   *<st c="27203">描述</st>*<st c="27214">：快速响应并减轻安全事件的影响，</st> <st c="27228">高效进行。</st>

    +   *<st c="27303">瓶颈</st>*<st c="27315">：手动响应过程可能较慢，从而延长</st> <st c="27377">解决时间。</st>

    +   *<st c="27391">AI/ML 应用</st>*<st c="27409">：AI 驱动的自动化可以为常见事件触发预定义响应动作，加快解决时间，并释放资源用于更</st> <st c="27558">复杂的分析。</st>

1.  **<st c="27575">持续</st>** **<st c="27587">反馈循环</st>**<st c="27600">：</st>

    +   *<st c="27602">描述</st>*<st c="27613">：将安全运营中的反馈纳入开发中，以防止</st> <st c="27697">未来的事件。</st>

    +   *瓶颈*：孤立的团队和流程可能妨碍有效的反馈沟通。

    +   *AI/ML 应用*：AI 工具可以分析事件报告和反馈，以识别模式并建议改进开发实践，推动持续改进的文化。

通过利用 AI/ML 应用程序支持每项活动，组织可以显著提升其持续的安全态势，确保安全措施与开发实践和新兴威胁同步演进。

将 AI/ML 应用于持续安全活动提供了显著的好处，例如自动化重复任务和增强检测能力。然而，这种整合也伴随一些挑战，如图 *8.7* 所示。

![图 8.7 – AI/ML 持续安全挑战](img/B21936_figure_08.07.jpg)

图 8.7 – AI/ML 持续安全挑战

解决这些问题对于在持续安全框架中有效利用 AI/ML 至关重要。以下是常见问题及应对策略：

+   **攻击者心态缺乏直观理解**：

    +   *问题*：AI/ML 模型可能未能充分捕捉人类攻击者的创造力和适应性，可能错过新颖或复杂的攻击路径。

    +   *策略*：结合对抗性 AI 技术和红队演练，训练 AI/ML 模型应对更广泛的攻击场景，包括需要类人直觉和创造力的情境。通过持续学习实践，AI/ML 系统定期更新，融入来自最新威胁情报和现实世界攻击模式的洞察。

+   **关于目标环境的不确定性**：

    +   *问题*：AI/ML 系统可能没有完全掌握目标环境的知识，导致威胁建模和漏洞评估不准确。

    +   *策略*：将 AI/ML 与动态发现工具结合使用，持续更新系统对环境的理解。实施混合模型，将 ML 洞察与安全专家输入结合，确保全面覆盖环境变量。

+   **数据质量** **和数量**：

    +   *问题*：AI/ML 模型需要大量高质量的数据才能有效训练。不充分或低质量的数据可能导致预测不准确和模型不稳定。

    +   *策略*：利用合成数据生成技术来增强训练数据集，确保 AI/ML 模型能够访问多样化和全面的数据。与可信实体建立合作伙伴关系和数据共享协议，进一步丰富数据集。

+   **不断发展的** **威胁环境**：

    +   *问题*：网络威胁环境的快速变化可能会超过 AI/ML 模型的学习能力，导致其随着时间推移变得不那么有效。

    +   *策略*：实施持续学习机制，使 AI/ML 模型能够实时适应新威胁。这包括集成自动化威胁情报流和使用无监督学习技术来检测新型模式。

+   **模型透明度** **和可解释性**：

    +   *问题*：某些 AI/ML 模型的“黑箱”特性使得安全团队难以理解某些决策背后的推理，从而影响信任和责任。

    +   *策略*：专注于开发和应用 XAI 技术，以提供对模型决策过程的洞察。这包括使用本身提供更多透明度的模型，或采用可以解释模型输出的工具。

+   **与现有安全工具** **和工作流的集成**：

    +   *问题*：将 AI/ML 无缝集成到现有的安全工具和工作流中可能面临挑战，可能导致操作效率低下。

    +   *策略*：优先考虑提供强大 API 支持并兼容标准安全工具和平台的 AI/ML 解决方案。采用分阶段集成方法，允许逐步调整和优化工作流。

+   **伦理考量** **和偏见**：

    +   *问题*：AI/ML 模型可能会继承其训练数据中的偏见，可能导致不道德的结果或在安全操作中产生歧视性行为。

    +   *<st c="31900">策略</st>*<st c="31909">：定期审计 AI/ML 模型，以识别和缓解偏见。</st> <st c="31984">在训练阶段融入多样化的数据集，并让跨学科团队参与开发过程，确保优先考虑伦理问题。</st>

<st c="32151">通过识别并战略性地解决这些挑战，组织可以更有效地利用 AI/ML 在持续安全工作中的力量，从而增强检测能力、改善响应时间，并提升</st> <st c="32406">安全态势的韧性。</st>

## <st c="32423">AI/ML 辅助的持续安全实际应用案例</st>

<st c="32482">AI/ML 辅助工具在持续安全中的一个显著的实际应用是通过</st> **<st c="32580">Darktrace</st>**<st c="32589">，这是一个</st> <st c="32593">由 AI 驱动的网络安全平台。</st> <st c="32628">Darktrace 利用机器学习算法学习组织网络的正常行为，从而实时检测和响应威胁。</st> <st c="32778">通过持续监控网络流量，并使用无监督学习来构建组织内每个设备、用户和网络的“自我”理解，Darktrace 能够识别出可能表明</st> <st c="33002">网络攻击的异常行为。</st>

<st c="33017">这种主动的方法使系统能够自主地迅速响应正在进行的网络威胁，通常在风险升级为严重漏洞之前就能进行有效的缓解。</st> <st c="33189">例如，如果 Darktrace 检测到一个未知设备试图进行异常的数据传输，它可以自动中断这些可能的恶意活动，从而有效保护敏感数据。</st> <st c="33397">这种增强了 AI 的监控和响应能力，较传统的基于规则的安全系统有了显著进展，使组织能够动态适应不断变化的安全</st> <st c="33582">环境。</st>

# <st c="33604">AI/ML 用于持续反馈</st>

<st c="33634">实施持续反馈</st> <st c="33667">涉及在开发、交付和生产生命周期中系统性地收集、分析并根据用户和利益相关者的反馈进行行动。</st> <st c="33830">这一过程旨在提升软件的可靠性以及团队对变化的响应能力。</st> *<st c="33935">图 8</st>**<st c="33943">.8</st>* <st c="33945">展示了持续反馈所需的关键活动。</st>

![图 8.8 – AI/ML 用于持续反馈活动](img/B21936_figure_08.08.jpg)

<st c="34193">图 8.8 – AI/ML 用于持续反馈活动</st>

<st c="34246">潜在的瓶颈以及 AI/ML 解决方案来应对这些挑战，详见下述清单：</st>

1.  **<st c="34353">反馈收集</st>**<st c="34373">：</st>

    +   *描述*：收集来自各种来源的反馈，包括用户调查、支持票据和社交媒体。

    +   *瓶颈*：反馈的数量和种类可能会让手动处理工作不堪重负，导致响应时间变慢。

    +   *AI/ML 应用*：自然语言处理和情感分析可以自动分类和优先排序反馈，帮助团队迅速识别和解决最关键的问题。

1.  **反馈分析**：

    +   *描述*：分析收集到的反馈，以识别共同的主题、用户痛点和潜在的改进点。

    +   *瓶颈*：手动分析耗时且可能无法准确捕捉到用户情感的全貌。

    +   *AI/ML 应用*：AI 驱动的文本分析和模式识别可以从大量反馈数据中揭示洞察，突出那些可能并不显而易见的改进领域。

1.  **集成到** **开发工作流程中**：

    +   *描述*：将可操作的反馈整合到开发积压工作中，并在冲刺中优先处理。

    +   *瓶颈*：将反馈整合到现有的开发工作流程中可能会打乱计划中的时间表和资源分配。

    +   *AI/ML 应用*：机器学习算法可以评估实施反馈的影响和工作量，自动建议优先级和调整开发路线图。

1.  **功能实现** **和测试**：

    +   *描述*：根据用户反馈开发和测试新功能或修复。

    +   *瓶颈*：根据反馈迅速实施和测试变更可能会加大资源压力，并可能引入新的问题。

    +   *AI/ML 应用*：由 AI 驱动的自动化测试工具可以快速验证新功能和修复，确保它们符合质量标准，同时不会显著拖慢开发进度。

1.  **发布** **和监控**：

    +   *描述*：将更新部署给用户，并监控变更对系统可靠性和用户满意度的影响。

    +   *<st c="36270">瓶颈</st>*<st c="36282">：持续部署变更可能会导致生产环境不稳定，进而影响</st> <st c="36379">系统可靠性。</st>

    +   *<st c="36398">AI/ML 应用</st>*<st c="36416">：基于 AI 的监控工具可以实时检测异常和回退情况，从而进行快速恢复操作，最大限度减少对</st> <st c="36563">用户的负面影响。</st>

1.  **<st c="36572">反馈</st>** **<st c="36582">闭环</st>**<st c="36594">：</st>

    +   *<st c="36596">描述</st>*<st c="36607">：通知</st> <st c="36620">利益相关者和用户关于他们反馈的响应措施，完成反馈</st> <st c="36710">闭环。</st>

    +   *<st c="36724">瓶颈</st>*<st c="36736">：有效地将反馈实施情况传达给大量用户可能是一个挑战，</st> <st c="36840">且需要大量资源。</st>

    +   *<st c="36863">AI/ML 应用</st>*<st c="36881">：自动化沟通工具，如聊天机器人或个性化电子邮件，可以通知用户关于他们反馈的状态，从而增强透明度</st> <st c="37032">和信任。</st>

1.  **<st c="37042">影响分析</st>**<st c="37058">：</st>

    +   *<st c="37060">描述</st>*<st c="37071">：通过分析与用户满意度和</st> <st c="37197">系统可靠性相关的指标，评估响应反馈所做变更的有效性。</st>

    +   *<st c="37216">瓶颈</st>*<st c="37228">：手动将反馈驱动的变更与系统性能和用户满意度的结果进行关联可能非常复杂</st> <st c="37349">且不准确。</st>

    +   *<st c="37363">AI/ML 应用：</st>* <st c="37382">高级分析和 ML 模型可以衡量特定变更对关键绩效指标的影响，为反馈实施的价值提供清晰的见解。</st>

<st c="37557">通过整合这些活动并利用 AI/ML 应用，组织可以显著提升其持续反馈流程。</st> <st c="37700">这种方法不仅加快了宝贵反馈的实施，还确保了变更对系统可靠性和</st> <st c="37846">用户满意度的正面影响。</st>

<st c="37864">将 AI/ML 应用到持续</st> <st c="37893">反馈流程中，可以改变组织收集、分析和处理反馈的方式。</st> <st c="37984">然而，正如</st> *<st c="38011">图 8</st>**<st c="38019">.9</st>*<st c="38021">所示，将这些技术集成进来也面临着一系列挑战。</st> <st c="38092">理解这些问题对于制定有效的策略以</st> <st c="38170">减少它们至关重要。</st>

![图 8.9 – AI/ML 在持续反馈中的挑战](img/B21936_figure_08.09.jpg)

<st c="38302">图 8.9 – AI/ML 在持续反馈中的挑战</st>

<st c="38355">以下是与利用 AI/ML 进行持续反馈活动相关的常见问题及</st> <st c="38458">提出的解决方案：</st>

+   **<st c="38477">数据质量</st>** **<st c="38491">和多样性</st>**<st c="38504">：</st>

    +   *<st c="38506">问题</st>*<st c="38513">：AI/ML</st> <st c="38522">模型需要高质量且多样化的数据才能准确分析反馈。</st> <st c="38558">低质量或有偏的数据可能导致不准确的洞察和</st> <st c="38660">误导性的决策。</st>

    +   *<st c="38682">策略</st>*<st c="38691">：实施强大的数据收集和预处理方法，以确保数据的质量和代表性。</st> <st c="38800">定期审查和更新数据收集策略，以减少偏差并提高</st> <st c="38907">反馈数据的多样性。</st>

+   **<st c="38921">误解</st>** **<st c="38940">反馈</st>**<st c="38951">：</st>

    +   *<st c="38953">问题</st>*<st c="38960">：AI/ML 模型，特别是基于自然语言处理（NLP）的模型，可能会误解用户反馈的细微差别和上下文，进而导致错误的优先级排序或对</st> <st c="39140">用户需求的误解。</st>

    +   *<st c="39151">策略</st>*<st c="39160">：将 AI/ML 分析与人工审查相结合，尤其是对于复杂或在决策中具有重大影响的反馈。</st> <st c="39297">采用混合方法可以确保 AI 驱动的洞察通过</st> <st c="39379">人工专业知识得到验证。</st>

+   **<st c="39395">适应不断变化的</st>** **<st c="39421">用户期望</st>**<st c="39438">：</st>

    +   *<st c="39440">问题</st>*<st c="39447">：用户期望和反馈的背景可能会迅速变化，这使得静态的 AI/ML 模型难以保持长期的准确性。</st> <st c="39581">随着时间推移，这种挑战更加明显。</st>

    +   *<st c="39591">策略</st>*<st c="39600">：采用持续学习的方法，使 AI/ML 模型能够定期更新数据。</st> <st c="39697">这可以涉及在线学习等技术，使模型能够实时适应反馈趋势</st> <st c="39812">和模式的变化。</st>

+   **<st c="39825">与</st>** **<st c="39843">现有系统的集成</st>**<st c="39859">：</st>

    +   *<st c="39861">问题</st>*<st c="39868">：将 AI/ML 无缝集成到现有的反馈和开发工作流程中可能在技术上具有挑战性，可能会导致</st> <st c="40023">反馈循环的中断。</st>

    +   *<st c="40037">策略</st>*<st c="40046">：关注那些提供灵活集成能力的 AI/ML 解决方案，以便与现有工具和平台兼容。</st> <st c="40154">采用分阶段实施的方法，逐步引入 AI/ML 功能，根据</st> <st c="40289">初步结果进行调整和优化。</st>

+   **<st c="40306">确保用户隐私</st>** **<st c="40329">和信任</st>**<st c="40338">：</st>

    +   *<st c="40340">问题</st>*<st c="40347">：利用</st> <st c="40360">AI/ML 分析用户反馈会引发关于用户隐私和数据安全的担忧，可能会削弱</st> <st c="40465">用户信任。</st>

    +   *<st c="40476">策略</st>*<st c="40485">：采用并</st> <st c="40497">明确传达严格的数据隐私政策，确保用户反馈在符合相关法规（例如 GDPR）的情况下进行分析。</st> <st c="40642">采用隐私保护的 AI/ML 技术，如联邦学习或差分隐私，分析数据而不侵犯</st> <st c="40775">个人隐私。</st>

+   **<st c="40794">过度依赖</st>** **<st c="40811">AI/ML 洞察</st>**<st c="40825">：</st>

    +   *<st c="40827">问题</st>*<st c="40834">：可能会过度依赖 AI/ML 进行决策，忽视了人类直觉和理解在</st> <st c="40965">解读反馈中的重要性。</st>

    +   *<st c="40987">策略</st>*<st c="40996">：制定指导方针，鼓励在决策中采取平衡的方式，将 AI/ML 生成的洞察与人工判断相结合。</st> <st c="41131">培养一种文化，重视技术与人类专业知识在提升产品和</st> <st c="41243">服务质量中的互补作用。</st>

+   **<st c="41259">反馈量</st>** **<st c="41276">与可扩展性</st>**<st c="41291">：</st>

    +   *<st c="41293">问题</st>*<st c="41300">：反馈量庞大可能会压倒 AI/ML 系统，尤其是在需要快速扩展的场景中。</st>

    +   *<st c="41421">策略</st>*<st c="41430">：设计具有可扩展性的 AI/ML 系统，利用基于云的解决方案和分布式计算技术有效处理大规模数据集。</st> <st c="41587">定期评估系统性能和可扩展性，必要时对基础设施进行调整，以</st> <st c="41659">满足需求。</st>

<st c="41704">通过积极解决这些挑战，组织可以有效地在持续反馈过程中利用 AI/ML，确保准确收集、分析并采取行动，推动持续改进</st> <st c="41960">和创新。</st>

## <st c="41975">AI/ML 辅助的持续反馈的实际应用案例</st>

<st c="42034">使用</st> <st c="42065">AI/ML 辅助工具进行持续反馈的实际示例由</st> **<st c="42128">Medallia</st>**<st c="42136">展示，</st> <st c="42140">这是一个利用 AI 实时分析来自多个渠道的客户反馈的平台。</st> <st c="42234">Medallia 的 AI 组件，称为 Medallia Athena，利用</st> **<st c="42290">自然语言处理</st>** <st c="42317">(</st>**<st c="42319">NLP</st>**<st c="42322">) 和机器学习理解、分类并优先处理</st> <st c="42373">来自调查、社交媒体和直接客户互动等渠道的客户情感、意见和行为。</st>

<st c="42496">这项技术使企业能够自动检测新兴趋势、情感变化以及客户体验中潜在的问题，并在其发生时作出响应，从而让公司迅速解决问题并利用反馈。</st> <st c="42727">例如，如果某些地区或群体的客户满意度出现负面趋势，Medallia 可以立即警告经理，帮助他们迅速采取行动解决问题，提升服务质量，并持续提高客户满意度。</st> <st c="43007">这种实时反馈处理和响应机制对希望在动态市场中保持高水平客户参与和满意度的企业至关重要。</st>

# <st c="43180">选择 AI/ML 工具的方法论</st>

<st c="43218">为</st> <st c="43254">持续测试、质量、安全性和反馈选择合适的 AI/ML 工具，需要一个全面的方法论，确保所选工具与组织目标一致，能够与现有系统无缝集成，并有效应对这些领域中的具体挑战。</st> <st c="43517">在区分生成性 AI 工具（生成新数据或内容）与预测性 AI 工具（根据输入数据预测结果）时，选择过程必须考虑到与这些技术的功能、应用和潜在影响相关的独特因素。</st>

*<st c="43819">图 8</st>**<st c="43828">.10</st>* <st c="43831">展示了一个结构化的方法论，用于选择 AI/ML 工具，强调了选择生成性 AI 工具与预测性 AI 工具之间的差异。</st>

![图 8.10 – 选择 AI/ML 工具的方法论](img/B21936_figure_08.10.jpg)

<st c="44061">图 8.10 – 选择 AI/ML 工具的方法论</st>

<st c="44112">每个步骤在</st> <st c="44133">以下列表中</st> <st c="44151">进行了描述：</st>

1.  **<st c="44166">定义目标</st>** **<st c="44185">和需求</st>**<st c="44201">：</st>

    +   *<st c="44203">对于两者</st>*<st c="44211">：明确指出您希望通过将 AI/ML 工具集成到持续测试、质量、安全性和反馈流程中所要实现的目标。</st> <st c="44349">识别具体的挑战和需求，例如减少安全警报中的误报或加速</st> <st c="44468">反馈循环。</st>

    +   *<st c="44482">差异</st>*<st c="44494">：对于生成型 AI 工具，重点关注创意、内容生成能力以及工具生成多样化输出的能力。</st> <st c="44627">对于预测型 AI 工具，优先考虑准确性、可靠性，以及工具处理庞大数据集并提供</st> <st c="44746">可操作性洞察的能力。</st>

1.  **<st c="44766">评估兼容性</st>** **<st c="44788">与集成性</st>**<st c="44803">：</st>

    +   *<st c="44805">对于两者</st>*<st c="44813">：评估 AI/ML 工具与您现有的开发、测试和部署环境的集成效果。</st> <st c="44930">考虑与当前工作流程、数据格式</st> <st c="44995">和平台的兼容性。</st>

    +   *<st c="45009">差异</st>*<st c="45021">：生成型 AI 工具可能需要更强大的创意输入和输出处理能力，而预测型 AI 工具则通常需要强大的数据处理和分析功能，能够无缝集成您的数据源和</st> <st c="45253">分析平台。</st>

1.  **<st c="45274">评估性能</st>** **<st c="45296">与可扩展性</st>**<st c="45311">：</st>

    +   *<st c="45313">对于两者</st>*<st c="45321">：根据与目标相关的基准测试工具的性能，包括处理速度、准确性和可扩展性，以应对不断增长的数据量</st> <st c="45485">和复杂性。</st>

    +   *<st c="45500">差异</st>*<st c="45512">：对于生成型 AI 工具，评估生成内容的质量和相关性。</st> <st c="45595">对于预测型 AI 工具，关注预测的准确性、数据处理的速度以及模型在</st> <st c="45722">不同条件下的表现。</st>

1.  **<st c="45741">审查合规性和</st>** **<st c="45764">伦理考量</st>**<st c="45786">：</st>

    +   *<st c="45788">对于两者</st>*<st c="45796">：确保工具符合数据隐私、安全法规和伦理指南。</st> <st c="45893">考虑 AI/ML 模型的透明度以及</st> <st c="45943">它们的决策。</st>

    +   *<st c="45959">差异</st>*<st c="45971">：生成型 AI 工具可能需要额外审查生成内容的原创性和版权问题。</st> <st c="46101">预测型 AI 工具可能需要更深入地审视预测中的潜在偏差和</st> <st c="46199">决策过程。</st>

1.  **<st c="46225">进行</st>** **<st c="46234">试点测试</st>**<st c="46247">：</st>

    +   *<st c="46249">对于两者</st>*<st c="46257">：实施一个试点项目，在受控环境中测试选定的 AI/ML 工具。</st> <st c="46348">监测其对工作流效率、质量改进和</st> <st c="46417">用户满意度的影响。</st>

    +   *<st c="46435">差异</st>*<st c="46447">：对于</st> <st c="46454">生成式 AI 工具，试点测试应重点评估生成输出的创新性、种类和适用性。</st> <st c="46578">对于预测式 AI 工具，应强调预测的准确性、时效性和与</st> <st c="46687">实际场景的相关性。</st>

1.  **<st c="46708">分析</st>** **<st c="46717">成本效益</st>**<st c="46730">：</st>

    +   *<st c="46732">对于两者</st>*<st c="46740">：评估实施、培训和维护的成本与预期收益之间的关系，例如提高效率、增强安全性或加速产品</st> <st c="46908">开发周期。</st>

    +   *<st c="46927">差异</st>*<st c="46939">：生成式 AI 工具可能涉及与创造力和内容生成能力相关的成本，这可能会带来新的产品特性或内容策略。</st> <st c="47103">预测式 AI 工具通常需要在数据处理和分析能力上进行投资，从而显著改善</st> <st c="47242">决策过程。</st>

1.  **<st c="47268">收集反馈并</st>** **<st c="47289">优化选择</st>**<st c="47305">：</st>

    +   *<st c="47307">对于两者</st>*<st c="47315">：收集试点用户和利益相关者的反馈，以优化工具选择。</st> <st c="47400">考虑易用性、结果的满意度以及任何意外的</st> <st c="47472">挑战。</st>

    +   *<st c="47495">差异</st>*<st c="47507">：生成式 AI 工具的反馈可能集中在生成内容的创造力和实用性上。</st> <st c="47610">对于预测式 AI 工具，反馈可能侧重于预测的准确性、实用性和</st> <st c="47688">可操作性。</st>

<st c="47722">通过遵循这一方法论，并意识到选择生成式和预测式 AI 工具之间的细微差别，组织可以做出符合其战略目标的明智决策，推动持续的测试、质量、安全性和</st> <st c="47963">反馈计划。</st>

# <st c="47984">总结</st>

<st c="47992">本章描述了在持续测试、质量、安全性和反馈实践中集成的 AI 和 ML 启用工具。</st> <st c="48121">它解释了 AI/ML 技术如何大大提高开发和交付过程的效率、安全性和响应能力。</st> <st c="48261">讨论提供了一个实用的框架，用于通过</st> <st c="48346">AI/ML 启用工具自动化和增强任务。</st>

<st c="48366">选择合适的 AI/ML 工具是有效整合这些技术的关键步骤。</st> <st c="48471">生成性和预测性 AI 工具的区别强调了在工具选择中采取深思熟虑的方法的重要性，确保所选解决方案与组织目标一致，并应对持续过程中的挑战。</st> <st c="48729">本章识别了应用 AI/ML 所伴随的挑战和考虑因素。</st> <st c="48827">诸如数据质量、隐私问题以及在自动化与人工监管之间保持平衡的需求，都是战略实施 AI/ML 的基础。</st> <st c="48997">AI/ML 的战略实施。</st>

<st c="49006">展望未来，下章将展示持续测试、质量、安全和反馈在推动 DevOps、DevSecOps 和 SRE 实践的组织中的应用案例。</st> <st c="49191">通过实际示例和深入分析，它将展示 AI/ML 如何不仅简化操作，还提升软件开发和维护的标准，标志着向更敏捷、更具韧性和高效的数字化转型之旅迈出重要的一步。</st> <st c="49454">转型之旅。</st>

# <st c="0">第三部分：深入探讨路线图、实施模式和衡量标准</st>

*<st c="75">第三部分</st>* <st c="82">本书的这一部分将重点转向在 DevOps、DevSecOps 和 SRE 领域中应用持续测试、质量、安全和反馈的实际方面。</st> <st c="247">本部分的结构旨在为读者提供如何在其组织内实现这些持续战略的全面理解。</st> <st c="387">他们的组织。</st>

<st c="407">从真实世界的应用案例开始，展示了这些实践在不同操作环境中的变革性力量，提供了实现更高运营成熟度的见解。</st> <st c="612">随后，书中引导读者通过制定符合其组织目标的战略路线图的过程，确保数字化转型之旅的良好对接。</st> <st c="799">接下来，它探讨了各种实施模式，提供了结构化的方法，这些方法已被证明能提高这些战略路线图的成功率。</st> <st c="954">最后，本部分通过强调衡量进展和结果的重要性来结束，向读者提供了跟踪和评估其持续实践有效性的工具和框架。</st> <st c="1180">本书的这一部分对于任何希望在数字化转型过程中实际实施并受益于持续测试、质量、安全和反馈的读者来说都至关重要。</st> <st c="1345">转型工作。</st>

<st c="1368">本部分包括以下章节：</st>

+   *<st c="1411">第九章</st>**<st c="1421">，与 DevOps、DevSecOps 和 SRE 的集成用例</st>*

+   *<st c="1480">第十章</st>**<st c="1491">，制定实施路线图</st>*

+   *<st c="1529">第十一章</st>**<st c="1540">，理解转型实施模式</st>*

+   *<st c="1594">第十二章</st>**<st c="1605">，衡量进展和结果</st>*
